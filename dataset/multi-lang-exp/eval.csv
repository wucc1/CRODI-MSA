Unnamed: 0,language,commit,commit_url,maintenance_type,user,repo,feature,diffs,msgs
47,C++,3faae99c3d8e512f9d3f6e7fb0785c60d4bed654,https://github.com/bitcoin/bitcoin/commit/3faae99c3d8e512f9d3f6e7fb0785c60d4bed654,P,bitcoin,bitcoin,"[1, 2, 2, 1, 7, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/src/net.cpp b/src/net.cpp
index d1895b717..e19decbda 100644
--- a/src/net.cpp
+++ b/src/net.cpp
@@ -1722,17 +1722,20 @@ void CConnman::ThreadOpenConnections(const std::vector<std::string> connect)
                 if (pnode->IsBlockOnlyConn()) nOutboundBlockRelay++;
 
-                // Netgroups for inbound and manual peers are not excluded because our goal here
-                // is to not use multiple of our limited outbound slots on a single netgroup
-                // but inbound and manual peers do not use our outbound slots. Inbound peers
-                // also have the added issue that they could be attacker controlled and used
-                // to prevent us from connecting to particular hosts if we used them here.
+                // Make sure our persistent outbound slots belong to different netgroups.
                 switch (pnode->m_conn_type) {
+                    // We currently don't take inbound connections into account. Since they are
+                    // free to make, an attacker could make them to prevent us from connecting to
+                    // certain peers.
                     case ConnectionType::INBOUND:
+                    // Manually selected connections should not affect how we select outbound
+                    // peers from addrman.
                     case ConnectionType::MANUAL:
+                    // Short-lived outbound connections should not affect how we select outbound
+                    // peers from addrman.
+                    case ConnectionType::ADDR_FETCH:
+                    case ConnectionType::FEELER:
                         break;
                     case ConnectionType::OUTBOUND_FULL_RELAY:
                     case ConnectionType::BLOCK_RELAY:
-                    case ConnectionType::ADDR_FETCH:
-                    case ConnectionType::FEELER:
                         setConnected.insert(m_netgroupman.GetGroup(pnode->addr));
                 } // no default case, so the compiler can warn about missing cases
","p2p: Diversify connections only w.r.t *persistent* outbound peers

ADDR_FETCH and FEELER are short-lived connections,
and they should not affect our choice of peers.

Also, improve comments.

"
52,C++,8842d1a5d48bb6015030b12407ebd2060160c40f,https://github.com/bitcoin/bitcoin/commit/8842d1a5d48bb6015030b12407ebd2060160c40f,P,bitcoin,bitcoin,"[2, 5, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/contrib/devtools/check-doc.py b/contrib/devtools/check-doc.py
index 150f36851..3b7a8f9a6 100755
--- a/contrib/devtools/check-doc.py
+++ b/contrib/devtools/check-doc.py
@@ -22,5 +22,5 @@ REGEX_ARG = re.compile(r'(?:map(?:Multi)?Args(?:\.count\(|\[)|Get(?:Bool)?Arg\()
 REGEX_DOC = re.compile(r'HelpMessageOpt\(\""(\-[^\""=]+?)(?:=|\"")')
 # list unsupported, deprecated and duplicate args as they need no documentation
-SET_DOC_OPTIONAL = set(['-rpcssl', '-benchmark', '-h', '-help', '-socks', '-tor', '-debugnet', '-whitelistalwaysrelay', '-prematurewitness', '-walletprematurewitness', '-promiscuousmempoolflags', '-blockminsize', '-dbcrashratio'])
+SET_DOC_OPTIONAL = set(['-rpcssl', '-benchmark', '-h', '-help', '-socks', '-tor', '-debugnet', '-whitelistalwaysrelay', '-prematurewitness', '-walletprematurewitness', '-promiscuousmempoolflags', '-blockminsize', '-dbcrashratio', '-forcecompactdb'])
 
 def main():
diff --git a/src/dbwrapper.cpp b/src/dbwrapper.cpp
index ba9e21cc1..3626e0177 100644
--- a/src/dbwrapper.cpp
+++ b/src/dbwrapper.cpp
@@ -116,4 +116,10 @@ CDBWrapper::CDBWrapper(const fs::path& path, size_t nCacheSize, bool fMemory, bo
     LogPrintf(""Opened LevelDB successfully\n"");
 
+    if (GetBoolArg(""-forcecompactdb"", false)) {
+        LogPrintf(""Starting database compaction of %s\n"", path.string());
+        pdb->CompactRange(nullptr, nullptr);
+        LogPrintf(""Finished database compaction of %s\n"", path.string());
+    }
+
     // The base-case obfuscation key, which is a noop.
     obfuscate_key = std::vector<unsigned char>(OBFUSCATE_KEY_NUM_BYTES, '\000');
","Add undocumented -forcecompactdb to force LevelDB compactions

"
61,C++,d449ba104a068c92a931a68d782245bbcb92af6c,https://github.com/opencv/opencv/commit/d449ba104a068c92a931a68d782245bbcb92af6c,P,opencv,opencv,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1]","diff --git a/cmake/OpenCVFindLibsVideo.cmake b/cmake/OpenCVFindLibsVideo.cmake
index a5075b57f7..a797f04169 100644
--- a/cmake/OpenCVFindLibsVideo.cmake
+++ b/cmake/OpenCVFindLibsVideo.cmake
@@ -252,5 +252,5 @@ if (NOT IOS)
 endif()
 
-# --- Intel Perceptual Computing SSDK ---
+# --- Intel Perceptual Computing SDK ---
 if(WITH_INTELPERC)
   include(""${OpenCV_SOURCE_DIR}/cmake/OpenCVFindIntelPerCSDK.cmake"")
","Fix comment in the cmake file from SSDK to SDK

"
86,C++,00616360a35579a40e68b63dd4d938336b136fae,https://github.com/godotengine/godot/commit/00616360a35579a40e68b63dd4d938336b136fae,C,godotengine,godot,"[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/editor/editor_export.cpp b/editor/editor_export.cpp
index 455c889224..1a6188862f 100644
--- a/editor/editor_export.cpp
+++ b/editor/editor_export.cpp
@@ -1098,4 +1098,5 @@ void EditorExport::remove_export_preset(int p_idx) {
 
 	export_presets.remove(p_idx);
+	save_presets();
 }
 
","Fix #22588: missing preset save after removing a export preset.

"
89,C++,4b85ddabdaf8314238cfecb1fa74ccb08f5d67d3,https://github.com/godotengine/godot/commit/4b85ddabdaf8314238cfecb1fa74ccb08f5d67d3,P,godotengine,godot,"[1, 3, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/scene/main/node.cpp b/scene/main/node.cpp
index 42e9cec217..6db4eb5640 100755
--- a/scene/main/node.cpp
+++ b/scene/main/node.cpp
@@ -2064,8 +2064,12 @@ void Node::set_editable_instance(Node *p_node, bool p_editable) {
 	ERR_FAIL_COND(!is_a_parent_of(p_node));
 	NodePath p = get_path_to(p_node);
-	if (!p_editable)
+	if (!p_editable) {
 		data.editable_instances.erase(p);
-	else
+		// Avoid this flag being needlessly saved;
+		// also give more visual feedback if editable children is reenabled
+		set_display_folded(false);
+	} else {
 		data.editable_instances[p] = true;
+	}
 }
 
","Reset display folded for an instanced scene if editable children is toggled off
This avoids the display folded flag needlessly getting into the scene file (potentially forever) and also gives more visual feedback if the user re-enables editable children so it will display unfolded at first.

"
90,C++,056a418862f3288742b718983e60c04f4f410f61,https://github.com/godotengine/godot/commit/056a418862f3288742b718983e60c04f4f410f61,P,godotengine,godot,"[2, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 7, 0, 0, 0, 0, 0, 0]","diff --git a/doc/classes/EditorProperty.xml b/doc/classes/EditorProperty.xml
index 7bac4bf7ac..9170c449bf 100644
--- a/doc/classes/EditorProperty.xml
+++ b/doc/classes/EditorProperty.xml
@@ -10,4 +10,11 @@
 	</tutorials>
 	<methods>
+		<method name=""_set_read_only"" qualifiers=""virtual"">
+			<return type=""void"" />
+			<param index=""0"" name=""read_only"" type=""bool"" />
+			<description>
+				Called when the read-only status of the property is changed. It may be used to change custom controls into a read-only or modifiable state.
+			</description>
+		</method>
 		<method name=""_update_property"" qualifiers=""virtual"">
 			<return type=""void"" />
diff --git a/editor/editor_inspector.cpp b/editor/editor_inspector.cpp
index 413eb52556..fb819f418b 100644
--- a/editor/editor_inspector.cpp
+++ b/editor/editor_inspector.cpp
@@ -427,4 +427,7 @@ void EditorProperty::_set_read_only(bool p_read_only) {
 void EditorProperty::set_read_only(bool p_read_only) {
 	read_only = p_read_only;
+	if (GDVIRTUAL_CALL(_set_read_only, p_read_only)) {
+		return;
+	}
 	_set_read_only(p_read_only);
 }
@@ -986,4 +989,6 @@ void EditorProperty::_bind_methods() {
 
 	GDVIRTUAL_BIND(_update_property)
+	GDVIRTUAL_BIND(_set_read_only, ""read_only"")
+
 	ClassDB::bind_method(D_METHOD(""_update_editor_property_status""), &EditorProperty::update_editor_property_status);
 }
diff --git a/editor/editor_inspector.h b/editor/editor_inspector.h
index b7df5a8037..872007e637 100644
--- a/editor/editor_inspector.h
+++ b/editor/editor_inspector.h
@@ -121,4 +121,6 @@ private:
 
 	GDVIRTUAL0(_update_property)
+	GDVIRTUAL1(_set_read_only, bool)
+
 	void _update_pin_flags();
 
","Expose `EditorProperty._set_read_only` virtual method

"
97,C++,ced8f73ffc89880af353b2e0d8b5dd0c5f75267d,https://github.com/protocolbuffers/protobuf/commit/ced8f73ffc89880af353b2e0d8b5dd0c5f75267d,A,protocolbuffers,protobuf,"[8, 805, 10, 21, 102, 0, 0, 1, 13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 11, 0, 0]","diff --git a/src/google/protobuf/compiler/code_generator.cc b/src/google/protobuf/compiler/code_generator.cc
index 6bf101c3b..11d0f3343 100644
--- a/src/google/protobuf/compiler/code_generator.cc
+++ b/src/google/protobuf/compiler/code_generator.cc
@@ -35,4 +35,5 @@
 #include <google/protobuf/compiler/code_generator.h>
 
+#include <google/protobuf/compiler/plugin.pb.h>
 #include <google/protobuf/stubs/logging.h>
 #include <google/protobuf/stubs/common.h>
@@ -90,4 +91,11 @@ void GeneratorContext::ListParsedFiles(
 }
 
+void GeneratorContext::GetCompilerVersion(Version* version) const {
+  version->set_major(GOOGLE_PROTOBUF_VERSION / 1000000);
+  version->set_minor(GOOGLE_PROTOBUF_VERSION / 1000 % 1000);
+  version->set_patch(GOOGLE_PROTOBUF_VERSION % 1000);
+  version->set_suffix(GOOGLE_PROTOBUF_VERSION_SUFFIX);
+}
+
 // Parses a set of comma-delimited name/value pairs.
 void ParseGeneratorParameter(const string& text,
diff --git a/src/google/protobuf/compiler/code_generator.h b/src/google/protobuf/compiler/code_generator.h
index b8a5584c0..b917d3733 100644
--- a/src/google/protobuf/compiler/code_generator.h
+++ b/src/google/protobuf/compiler/code_generator.h
@@ -51,4 +51,5 @@ class FileDescriptor;
 
 namespace compiler {
+class Version;
 
 // Defined in this file.
@@ -144,4 +145,8 @@ class LIBPROTOC_EXPORT GeneratorContext {
   virtual void ListParsedFiles(std::vector<const FileDescriptor*>* output);
 
+  // Retrieves the version number of the protocol compiler associated with
+  // this GeneratorContext.
+  virtual void GetCompilerVersion(Version* version) const;
+
  private:
   GOOGLE_DISALLOW_EVIL_CONSTRUCTORS(GeneratorContext);
diff --git a/src/google/protobuf/compiler/command_line_interface.cc b/src/google/protobuf/compiler/command_line_interface.cc
index 78ceb68c0..bef0fe5a9 100644
--- a/src/google/protobuf/compiler/command_line_interface.cc
+++ b/src/google/protobuf/compiler/command_line_interface.cc
@@ -1620,4 +1620,11 @@ bool CommandLineInterface::GeneratePluginOutput(
   }
 
+  google::protobuf::compiler::Version* version =
+      request.mutable_compiler_version();
+  version->set_major(GOOGLE_PROTOBUF_VERSION / 1000000);
+  version->set_minor(GOOGLE_PROTOBUF_VERSION / 1000 % 1000);
+  version->set_patch(GOOGLE_PROTOBUF_VERSION % 1000);
+  version->set_suffix(GOOGLE_PROTOBUF_VERSION_SUFFIX);
+
   // Invoke the plugin.
   Subprocess subprocess;
diff --git a/src/google/protobuf/compiler/command_line_interface_unittest.cc b/src/google/protobuf/compiler/command_line_interface_unittest.cc
index d5b5b1850..b2ec84261 100644
--- a/src/google/protobuf/compiler/command_line_interface_unittest.cc
+++ b/src/google/protobuf/compiler/command_line_interface_unittest.cc
@@ -58,4 +58,5 @@
 #include <google/protobuf/unittest.pb.h>
 #include <google/protobuf/testing/file.h>
+#include <google/protobuf/stubs/stringprintf.h>
 #include <google/protobuf/stubs/strutil.h>
 #include <google/protobuf/stubs/substitute.h>
@@ -1583,4 +1584,19 @@ TEST_F(CommandLineInterfaceTest, PluginReceivesJsonName) {
 }
 
+TEST_F(CommandLineInterfaceTest, PluginReceivesCompilerVersion) {
+  CreateTempFile(""foo.proto"",
+    ""syntax = \""proto2\"";\n""
+    ""message MockCodeGenerator_ShowVersionNumber {\n""
+    ""  optional int32 value = 1;\n""
+    ""}\n"");
+
+  Run(""protocol_compiler --plug_out=$tmpdir --proto_path=$tmpdir foo.proto"");
+
+  ExpectErrorSubstring(
+      StringPrintf(""Saw compiler_version: %d %s"",
+                   GOOGLE_PROTOBUF_VERSION,
+                   GOOGLE_PROTOBUF_VERSION_SUFFIX));
+}
+
 TEST_F(CommandLineInterfaceTest, GeneratorPluginNotFound) {
   // Test what happens if the plugin isn't found.
diff --git a/src/google/protobuf/compiler/mock_code_generator.cc b/src/google/protobuf/compiler/mock_code_generator.cc
index 979814ecb..e82e6ae16 100644
--- a/src/google/protobuf/compiler/mock_code_generator.cc
+++ b/src/google/protobuf/compiler/mock_code_generator.cc
@@ -41,4 +41,5 @@
 #include <vector>
 
+#include <google/protobuf/compiler/plugin.pb.h>
 #include <google/protobuf/stubs/logging.h>
 #include <google/protobuf/stubs/common.h>
@@ -161,4 +162,13 @@ bool MockCodeGenerator::Generate(
                   << field_descriptor_proto.has_json_name() << std::endl;
         abort();
+      } else if (command == ""ShowVersionNumber"") {
+        Version compiler_version;
+        context->GetCompilerVersion(&compiler_version);
+        std::cerr << ""Saw compiler_version: ""
+                  << compiler_version.major() * 1000000 +
+                     compiler_version.minor() * 1000 +
+                     compiler_version.patch()
+                  << "" "" << compiler_version.suffix() << std::endl;
+        abort();
       } else {
         GOOGLE_LOG(FATAL) << ""Unknown MockCodeGenerator command: "" << command;
diff --git a/src/google/protobuf/compiler/plugin.cc b/src/google/protobuf/compiler/plugin.cc
index dcccb3d40..3848101d1 100644
--- a/src/google/protobuf/compiler/plugin.cc
+++ b/src/google/protobuf/compiler/plugin.cc
@@ -64,7 +64,10 @@ class GeneratorResponseContext : public GeneratorContext {
  public:
   GeneratorResponseContext(
+      const Version& compiler_version,
       CodeGeneratorResponse* response,
       const std::vector<const FileDescriptor*>& parsed_files)
-      : response_(response), parsed_files_(parsed_files) {}
+      : compiler_version_(compiler_version),
+        response_(response),
+        parsed_files_(parsed_files) {}
   virtual ~GeneratorResponseContext() {}
 
@@ -89,5 +92,10 @@ class GeneratorResponseContext : public GeneratorContext {
   }
 
+  void GetCompilerVersion(Version* version) const {
+    *version = compiler_version_;
+  }
+
  private:
+  Version compiler_version_;
   CodeGeneratorResponse* response_;
   const std::vector<const FileDescriptor*>& parsed_files_;
@@ -117,5 +125,6 @@ bool GenerateCode(const CodeGeneratorRequest& request,
   }
 
-  GeneratorResponseContext context(response, parsed_files);
+  GeneratorResponseContext context(
+      request.compiler_version(), response, parsed_files);
 
   string error;
diff --git a/src/google/protobuf/compiler/plugin.pb.cc b/src/google/protobuf/compiler/plugin.pb.cc
index 0239e05f3..bb78eff65 100644
--- a/src/google/protobuf/compiler/plugin.pb.cc
+++ b/src/google/protobuf/compiler/plugin.pb.cc
@@ -21,4 +21,6 @@ namespace google {
 namespace protobuf {
 namespace compiler {
+class VersionDefaultTypeInternal : public ::google::protobuf::internal::ExplicitlyConstructed<Version> {};
+VersionDefaultTypeInternal _Version_default_instance_;
 class CodeGeneratorRequestDefaultTypeInternal : public ::google::protobuf::internal::ExplicitlyConstructed<CodeGeneratorRequest> {};
 CodeGeneratorRequestDefaultTypeInternal _CodeGeneratorRequest_default_instance_;
@@ -30,5 +32,5 @@ CodeGeneratorResponseDefaultTypeInternal _CodeGeneratorResponse_default_instance
 namespace {
 
-::google::protobuf::Metadata file_level_metadata[3];
+::google::protobuf::Metadata file_level_metadata[4];
 
 }  // namespace
@@ -38,4 +40,16 @@ const ::google::protobuf::uint32* protobuf_Offsets_google_2fprotobuf_2fcompiler_
 const ::google::protobuf::uint32* protobuf_Offsets_google_2fprotobuf_2fcompiler_2fplugin_2eproto() {
   static const ::google::protobuf::uint32 offsets[] = {
+    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(Version, _has_bits_),
+    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(Version, _internal_metadata_),
+    ~0u,  // no _extensions_
+    ~0u,  // no _oneof_case_
+    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(Version, major_),
+    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(Version, minor_),
+    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(Version, patch_),
+    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(Version, suffix_),
+    1,
+    2,
+    3,
+    0,
     GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CodeGeneratorRequest, _has_bits_),
     GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CodeGeneratorRequest, _internal_metadata_),
@@ -45,7 +59,9 @@ const ::google::protobuf::uint32* protobuf_Offsets_google_2fprotobuf_2fcompiler_
     GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CodeGeneratorRequest, parameter_),
     GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CodeGeneratorRequest, proto_file_),
-    1,
-    0,
+    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CodeGeneratorRequest, compiler_version_),
     2,
+    0,
+    3,
+    1,
     GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CodeGeneratorResponse_File, _has_bits_),
     GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CodeGeneratorResponse_File, _internal_metadata_),
@@ -71,10 +87,12 @@ const ::google::protobuf::uint32* protobuf_Offsets_google_2fprotobuf_2fcompiler_
 
 static const ::google::protobuf::internal::MigrationSchema schemas[] = {
-  { 0, 7, sizeof(CodeGeneratorRequest)},
-  { 10, 17, sizeof(CodeGeneratorResponse_File)},
-  { 20, 26, sizeof(CodeGeneratorResponse)},
+  { 0, 8, sizeof(Version)},
+  { 12, 20, sizeof(CodeGeneratorRequest)},
+  { 24, 31, sizeof(CodeGeneratorResponse_File)},
+  { 34, 40, sizeof(CodeGeneratorResponse)},
 };
 
 static const ::google::protobuf::internal::DefaultInstanceData file_default_instances[] = {
+  {reinterpret_cast<const ::google::protobuf::Message*>(&_Version_default_instance_), NULL},
   {reinterpret_cast<const ::google::protobuf::Message*>(&_CodeGeneratorRequest_default_instance_), NULL},
   {reinterpret_cast<const ::google::protobuf::Message*>(&_CodeGeneratorResponse_File_default_instance_), NULL},
@@ -100,5 +118,5 @@ void protobuf_RegisterTypes(const ::std::string&) GOOGLE_ATTRIBUTE_COLD;
 void protobuf_RegisterTypes(const ::std::string&) {
   protobuf_AssignDescriptorsOnce();
-  ::google::protobuf::internal::RegisterAllTypes(file_level_metadata, 3);
+  ::google::protobuf::internal::RegisterAllTypes(file_level_metadata, 4);
 }
 
@@ -106,10 +124,12 @@ void protobuf_RegisterTypes(const ::std::string&) {
 
 void protobuf_ShutdownFile_google_2fprotobuf_2fcompiler_2fplugin_2eproto() {
-  _CodeGeneratorRequest_default_instance_.Shutdown();
+  _Version_default_instance_.Shutdown();
   delete file_level_metadata[0].reflection;
-  _CodeGeneratorResponse_File_default_instance_.Shutdown();
+  _CodeGeneratorRequest_default_instance_.Shutdown();
   delete file_level_metadata[1].reflection;
-  _CodeGeneratorResponse_default_instance_.Shutdown();
+  _CodeGeneratorResponse_File_default_instance_.Shutdown();
   delete file_level_metadata[2].reflection;
+  _CodeGeneratorResponse_default_instance_.Shutdown();
+  delete file_level_metadata[3].reflection;
 }
 
@@ -119,7 +139,10 @@ void protobuf_InitDefaults_google_2fprotobuf_2fcompiler_2fplugin_2eproto_impl()
   ::google::protobuf::protobuf_InitDefaults_google_2fprotobuf_2fdescriptor_2eproto();
   ::google::protobuf::internal::InitProtobufDefaults();
+  _Version_default_instance_.DefaultConstruct();
   _CodeGeneratorRequest_default_instance_.DefaultConstruct();
   _CodeGeneratorResponse_File_default_instance_.DefaultConstruct();
   _CodeGeneratorResponse_default_instance_.DefaultConstruct();
+  _CodeGeneratorRequest_default_instance_.get_mutable()->compiler_version_ = const_cast< ::google::protobuf::compiler::Version*>(
+      ::google::protobuf::compiler::Version::internal_default_instance());
 }
 
@@ -133,17 +156,20 @@ void protobuf_AddDesc_google_2fprotobuf_2fcompiler_2fplugin_2eproto_impl() {
       ""\n%google/protobuf/compiler/plugin.proto\022""
       ""\030google.protobuf.compiler\032 google/protob""
-      ""uf/descriptor.proto\""}\n\024CodeGeneratorRequ""
-      ""est\022\030\n\020file_to_generate\030\001 \003(\t\022\021\n\tparamet""
-      ""er\030\002 \001(\t\0228\n\nproto_file\030\017 \003(\0132$.google.pr""
-      ""otobuf.FileDescriptorProto\""\252\001\n\025CodeGener""
-      ""atorResponse\022\r\n\005error\030\001 \001(\t\022B\n\004file\030\017 \003(""
-      ""\01324.google.protobuf.compiler.CodeGenerat""
-      ""orResponse.File\032>\n\004File\022\014\n\004name\030\001 \001(\t\022\027\n""
-      ""\017insertion_point\030\002 \001(\t\022\017\n\007content\030\017 \001(\tB""
-      ""7\n\034com.google.protobuf.compilerB\014PluginP""
-      ""rotosZ\tplugin_go""
+      ""uf/descriptor.proto\""F\n\007Version\022\r\n\005major\030""
+      ""\001 \001(\005\022\r\n\005minor\030\002 \001(\005\022\r\n\005patch\030\003 \001(\005\022\016\n\006s""
+      ""uffix\030\004 \001(\t\""\272\001\n\024CodeGeneratorRequest\022\030\n\020""
+      ""file_to_generate\030\001 \003(\t\022\021\n\tparameter\030\002 \001(""
+      ""\t\0228\n\nproto_file\030\017 \003(\0132$.google.protobuf.""
+      ""FileDescriptorProto\022;\n\020compiler_version\030""
+      ""\003 \001(\0132!.google.protobuf.compiler.Version""
+      ""\""\252\001\n\025CodeGeneratorResponse\022\r\n\005error\030\001 \001(""
+      ""\t\022B\n\004file\030\017 \003(\01324.google.protobuf.compil""
+      ""er.CodeGeneratorResponse.File\032>\n\004File\022\014\n""
+      ""\004name\030\001 \001(\t\022\027\n\017insertion_point\030\002 \001(\t\022\017\n\007""
+      ""content\030\017 \001(\tB7\n\034com.google.protobuf.com""
+      ""pilerB\014PluginProtosZ\tplugin_go""
   };
   ::google::protobuf::DescriptorPool::InternalAddGeneratedFile(
-      descriptor, 456);
+      descriptor, 590);
   ::google::protobuf::MessageFactory::InternalRegisterGeneratedFile(
     ""google/protobuf/compiler/plugin.proto"", &protobuf_RegisterTypes);
@@ -166,8 +192,504 @@ struct StaticDescriptorInitializer_google_2fprotobuf_2fcompiler_2fplugin_2eproto
 // ===================================================================
 
+#if !defined(_MSC_VER) || _MSC_VER >= 1900
+const int Version::kMajorFieldNumber;
+const int Version::kMinorFieldNumber;
+const int Version::kPatchFieldNumber;
+const int Version::kSuffixFieldNumber;
+#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900
+
+Version::Version()
+  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
+  if (GOOGLE_PREDICT_TRUE(this != internal_default_instance())) {
+    protobuf_InitDefaults_google_2fprotobuf_2fcompiler_2fplugin_2eproto();
+  }
+  SharedCtor();
+  // @@protoc_insertion_point(constructor:google.protobuf.compiler.Version)
+}
+Version::Version(const Version& from)
+  : ::google::protobuf::Message(),
+      _internal_metadata_(NULL),
+      _has_bits_(from._has_bits_),
+      _cached_size_(0) {
+  _internal_metadata_.MergeFrom(from._internal_metadata_);
+  suffix_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
+  if (from.has_suffix()) {
+    suffix_.AssignWithDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), from.suffix_);
+  }
+  ::memcpy(&major_, &from.major_,
+    reinterpret_cast<char*>(&patch_) -
+    reinterpret_cast<char*>(&major_) + sizeof(patch_));
+  // @@protoc_insertion_point(copy_constructor:google.protobuf.compiler.Version)
+}
+
+void Version::SharedCtor() {
+  _cached_size_ = 0;
+  suffix_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
+  ::memset(&major_, 0, reinterpret_cast<char*>(&patch_) -
+    reinterpret_cast<char*>(&major_) + sizeof(patch_));
+}
+
+Version::~Version() {
+  // @@protoc_insertion_point(destructor:google.protobuf.compiler.Version)
+  SharedDtor();
+}
+
+void Version::SharedDtor() {
+  suffix_.DestroyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
+}
+
+void Version::SetCachedSize(int size) const {
+  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
+  _cached_size_ = size;
+  GOOGLE_SAFE_CONCURRENT_WRITES_END();
+}
+const ::google::protobuf::Descriptor* Version::descriptor() {
+  protobuf_AssignDescriptorsOnce();
+  return file_level_metadata[0].descriptor;
+}
+
+const Version& Version::default_instance() {
+  protobuf_InitDefaults_google_2fprotobuf_2fcompiler_2fplugin_2eproto();
+  return *internal_default_instance();
+}
+
+Version* Version::New(::google::protobuf::Arena* arena) const {
+  Version* n = new Version;
+  if (arena != NULL) {
+    arena->Own(n);
+  }
+  return n;
+}
+
+void Version::Clear() {
+// @@protoc_insertion_point(message_clear_start:google.protobuf.compiler.Version)
+  if (has_suffix()) {
+    GOOGLE_DCHECK(!suffix_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()));
+    (*suffix_.UnsafeRawStringPointer())->clear();
+  }
+  if (_has_bits_[0 / 32] & 14u) {
+    ::memset(&major_, 0, reinterpret_cast<char*>(&patch_) -
+      reinterpret_cast<char*>(&major_) + sizeof(patch_));
+  }
+  _has_bits_.Clear();
+  _internal_metadata_.Clear();
+}
+
+bool Version::MergePartialFromCodedStream(
+    ::google::protobuf::io::CodedInputStream* input) {
+#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
+  ::google::protobuf::uint32 tag;
+  // @@protoc_insertion_point(parse_start:google.protobuf.compiler.Version)
+  for (;;) {
+    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(127u);
+    tag = p.first;
+    if (!p.second) goto handle_unusual;
+    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
+      // optional int32 major = 1;
+      case 1: {
+        if (tag == 8u) {
+          set_has_major();
+          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
+                   ::google::protobuf::int32, ::google::protobuf::internal::WireFormatLite::TYPE_INT32>(
+                 input, &major_)));
+        } else {
+          goto handle_unusual;
+        }
+        break;
+      }
+
+      // optional int32 minor = 2;
+      case 2: {
+        if (tag == 16u) {
+          set_has_minor();
+          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
+                   ::google::protobuf::int32, ::google::protobuf::internal::WireFormatLite::TYPE_INT32>(
+                 input, &minor_)));
+        } else {
+          goto handle_unusual;
+        }
+        break;
+      }
+
+      // optional int32 patch = 3;
+      case 3: {
+        if (tag == 24u) {
+          set_has_patch();
+          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
+                   ::google::protobuf::int32, ::google::protobuf::internal::WireFormatLite::TYPE_INT32>(
+                 input, &patch_)));
+        } else {
+          goto handle_unusual;
+        }
+        break;
+      }
+
+      // optional string suffix = 4;
+      case 4: {
+        if (tag == 34u) {
+          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
+                input, this->mutable_suffix()));
+          ::google::protobuf::internal::WireFormat::VerifyUTF8StringNamedField(
+            this->suffix().data(), this->suffix().length(),
+            ::google::protobuf::internal::WireFormat::PARSE,
+            ""google.protobuf.compiler.Version.suffix"");
+        } else {
+          goto handle_unusual;
+        }
+        break;
+      }
+
+      default: {
+      handle_unusual:
+        if (tag == 0 ||
+            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
+            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
+          goto success;
+        }
+        DO_(::google::protobuf::internal::WireFormat::SkipField(
+              input, tag, mutable_unknown_fields()));
+        break;
+      }
+    }
+  }
+success:
+  // @@protoc_insertion_point(parse_success:google.protobuf.compiler.Version)
+  return true;
+failure:
+  // @@protoc_insertion_point(parse_failure:google.protobuf.compiler.Version)
+  return false;
+#undef DO_
+}
+
+void Version::SerializeWithCachedSizes(
+    ::google::protobuf::io::CodedOutputStream* output) const {
+  // @@protoc_insertion_point(serialize_start:google.protobuf.compiler.Version)
+  // optional int32 major = 1;
+  if (has_major()) {
+    ::google::protobuf::internal::WireFormatLite::WriteInt32(1, this->major(), output);
+  }
+
+  // optional int32 minor = 2;
+  if (has_minor()) {
+    ::google::protobuf::internal::WireFormatLite::WriteInt32(2, this->minor(), output);
+  }
+
+  // optional int32 patch = 3;
+  if (has_patch()) {
+    ::google::protobuf::internal::WireFormatLite::WriteInt32(3, this->patch(), output);
+  }
+
+  // optional string suffix = 4;
+  if (has_suffix()) {
+    ::google::protobuf::internal::WireFormat::VerifyUTF8StringNamedField(
+      this->suffix().data(), this->suffix().length(),
+      ::google::protobuf::internal::WireFormat::SERIALIZE,
+      ""google.protobuf.compiler.Version.suffix"");
+    ::google::protobuf::internal::WireFormatLite::WriteStringMaybeAliased(
+      4, this->suffix(), output);
+  }
+
+  if (_internal_metadata_.have_unknown_fields()) {
+    ::google::protobuf::internal::WireFormat::SerializeUnknownFields(
+        unknown_fields(), output);
+  }
+  // @@protoc_insertion_point(serialize_end:google.protobuf.compiler.Version)
+}
+
+::google::protobuf::uint8* Version::InternalSerializeWithCachedSizesToArray(
+    bool deterministic, ::google::protobuf::uint8* target) const {
+  (void)deterministic; // Unused
+  // @@protoc_insertion_point(serialize_to_array_start:google.protobuf.compiler.Version)
+  // optional int32 major = 1;
+  if (has_major()) {
+    target = ::google::protobuf::internal::WireFormatLite::WriteInt32ToArray(1, this->major(), target);
+  }
+
+  // optional int32 minor = 2;
+  if (has_minor()) {
+    target = ::google::protobuf::internal::WireFormatLite::WriteInt32ToArray(2, this->minor(), target);
+  }
+
+  // optional int32 patch = 3;
+  if (has_patch()) {
+    target = ::google::protobuf::internal::WireFormatLite::WriteInt32ToArray(3, this->patch(), target);
+  }
+
+  // optional string suffix = 4;
+  if (has_suffix()) {
+    ::google::protobuf::internal::WireFormat::VerifyUTF8StringNamedField(
+      this->suffix().data(), this->suffix().length(),
+      ::google::protobuf::internal::WireFormat::SERIALIZE,
+      ""google.protobuf.compiler.Version.suffix"");
+    target =
+      ::google::protobuf::internal::WireFormatLite::WriteStringToArray(
+        4, this->suffix(), target);
+  }
+
+  if (_internal_metadata_.have_unknown_fields()) {
+    target = ::google::protobuf::internal::WireFormat::SerializeUnknownFieldsToArray(
+        unknown_fields(), target);
+  }
+  // @@protoc_insertion_point(serialize_to_array_end:google.protobuf.compiler.Version)
+  return target;
+}
+
+size_t Version::ByteSizeLong() const {
+// @@protoc_insertion_point(message_byte_size_start:google.protobuf.compiler.Version)
+  size_t total_size = 0;
+
+  if (_internal_metadata_.have_unknown_fields()) {
+    total_size +=
+      ::google::protobuf::internal::WireFormat::ComputeUnknownFieldsSize(
+        unknown_fields());
+  }
+  if (_has_bits_[0 / 32] & 15u) {
+    // optional string suffix = 4;
+    if (has_suffix()) {
+      total_size += 1 +
+        ::google::protobuf::internal::WireFormatLite::StringSize(
+          this->suffix());
+    }
+
+    // optional int32 major = 1;
+    if (has_major()) {
+      total_size += 1 +
+        ::google::protobuf::internal::WireFormatLite::Int32Size(
+          this->major());
+    }
+
+    // optional int32 minor = 2;
+    if (has_minor()) {
+      total_size += 1 +
+        ::google::protobuf::internal::WireFormatLite::Int32Size(
+          this->minor());
+    }
+
+    // optional int32 patch = 3;
+    if (has_patch()) {
+      total_size += 1 +
+        ::google::protobuf::internal::WireFormatLite::Int32Size(
+          this->patch());
+    }
+
+  }
+  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
+  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
+  _cached_size_ = cached_size;
+  GOOGLE_SAFE_CONCURRENT_WRITES_END();
+  return total_size;
+}
+
+void Version::MergeFrom(const ::google::protobuf::Message& from) {
+// @@protoc_insertion_point(generalized_merge_from_start:google.protobuf.compiler.Version)
+  GOOGLE_DCHECK_NE(&from, this);
+  const Version* source =
+      ::google::protobuf::internal::DynamicCastToGenerated<const Version>(
+          &from);
+  if (source == NULL) {
+  // @@protoc_insertion_point(generalized_merge_from_cast_fail:google.protobuf.compiler.Version)
+    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
+  } else {
+  // @@protoc_insertion_point(generalized_merge_from_cast_success:google.protobuf.compiler.Version)
+    MergeFrom(*source);
+  }
+}
+
+void Version::MergeFrom(const Version& from) {
+// @@protoc_insertion_point(class_specific_merge_from_start:google.protobuf.compiler.Version)
+  GOOGLE_DCHECK_NE(&from, this);
+  _internal_metadata_.MergeFrom(from._internal_metadata_);
+  if (from._has_bits_[0 / 32] & 15u) {
+    if (from.has_suffix()) {
+      set_has_suffix();
+      suffix_.AssignWithDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), from.suffix_);
+    }
+    if (from.has_major()) {
+      set_major(from.major());
+    }
+    if (from.has_minor()) {
+      set_minor(from.minor());
+    }
+    if (from.has_patch()) {
+      set_patch(from.patch());
+    }
+  }
+}
+
+void Version::CopyFrom(const ::google::protobuf::Message& from) {
+// @@protoc_insertion_point(generalized_copy_from_start:google.protobuf.compiler.Version)
+  if (&from == this) return;
+  Clear();
+  MergeFrom(from);
+}
+
+void Version::CopyFrom(const Version& from) {
+// @@protoc_insertion_point(class_specific_copy_from_start:google.protobuf.compiler.Version)
+  if (&from == this) return;
+  Clear();
+  MergeFrom(from);
+}
+
+bool Version::IsInitialized() const {
+  return true;
+}
+
+void Version::Swap(Version* other) {
+  if (other == this) return;
+  InternalSwap(other);
+}
+void Version::InternalSwap(Version* other) {
+  suffix_.Swap(&other->suffix_);
+  std::swap(major_, other->major_);
+  std::swap(minor_, other->minor_);
+  std::swap(patch_, other->patch_);
+  std::swap(_has_bits_[0], other->_has_bits_[0]);
+  _internal_metadata_.Swap(&other->_internal_metadata_);
+  std::swap(_cached_size_, other->_cached_size_);
+}
+
+::google::protobuf::Metadata Version::GetMetadata() const {
+  protobuf_AssignDescriptorsOnce();
+  return file_level_metadata[0];
+}
+
+#if PROTOBUF_INLINE_NOT_IN_HEADERS
+// Version
+
+// optional int32 major = 1;
+bool Version::has_major() const {
+  return (_has_bits_[0] & 0x00000002u) != 0;
+}
+void Version::set_has_major() {
+  _has_bits_[0] |= 0x00000002u;
+}
+void Version::clear_has_major() {
+  _has_bits_[0] &= ~0x00000002u;
+}
+void Version::clear_major() {
+  major_ = 0;
+  clear_has_major();
+}
+::google::protobuf::int32 Version::major() const {
+  // @@protoc_insertion_point(field_get:google.protobuf.compiler.Version.major)
+  return major_;
+}
+void Version::set_major(::google::protobuf::int32 value) {
+  set_has_major();
+  major_ = value;
+  // @@protoc_insertion_point(field_set:google.protobuf.compiler.Version.major)
+}
+
+// optional int32 minor = 2;
+bool Version::has_minor() const {
+  return (_has_bits_[0] & 0x00000004u) != 0;
+}
+void Version::set_has_minor() {
+  _has_bits_[0] |= 0x00000004u;
+}
+void Version::clear_has_minor() {
+  _has_bits_[0] &= ~0x00000004u;
+}
+void Version::clear_minor() {
+  minor_ = 0;
+  clear_has_minor();
+}
+::google::protobuf::int32 Version::minor() const {
+  // @@protoc_insertion_point(field_get:google.protobuf.compiler.Version.minor)
+  return minor_;
+}
+void Version::set_minor(::google::protobuf::int32 value) {
+  set_has_minor();
+  minor_ = value;
+  // @@protoc_insertion_point(field_set:google.protobuf.compiler.Version.minor)
+}
+
+// optional int32 patch = 3;
+bool Version::has_patch() const {
+  return (_has_bits_[0] & 0x00000008u) != 0;
+}
+void Version::set_has_patch() {
+  _has_bits_[0] |= 0x00000008u;
+}
+void Version::clear_has_patch() {
+  _has_bits_[0] &= ~0x00000008u;
+}
+void Version::clear_patch() {
+  patch_ = 0;
+  clear_has_patch();
+}
+::google::protobuf::int32 Version::patch() const {
+  // @@protoc_insertion_point(field_get:google.protobuf.compiler.Version.patch)
+  return patch_;
+}
+void Version::set_patch(::google::protobuf::int32 value) {
+  set_has_patch();
+  patch_ = value;
+  // @@protoc_insertion_point(field_set:google.protobuf.compiler.Version.patch)
+}
+
+// optional string suffix = 4;
+bool Version::has_suffix() const {
+  return (_has_bits_[0] & 0x00000001u) != 0;
+}
+void Version::set_has_suffix() {
+  _has_bits_[0] |= 0x00000001u;
+}
+void Version::clear_has_suffix() {
+  _has_bits_[0] &= ~0x00000001u;
+}
+void Version::clear_suffix() {
+  suffix_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
+  clear_has_suffix();
+}
+const ::std::string& Version::suffix() const {
+  // @@protoc_insertion_point(field_get:google.protobuf.compiler.Version.suffix)
+  return suffix_.GetNoArena();
+}
+void Version::set_suffix(const ::std::string& value) {
+  set_has_suffix();
+  suffix_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
+  // @@protoc_insertion_point(field_set:google.protobuf.compiler.Version.suffix)
+}
+void Version::set_suffix(const char* value) {
+  set_has_suffix();
+  suffix_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
+  // @@protoc_insertion_point(field_set_char:google.protobuf.compiler.Version.suffix)
+}
+void Version::set_suffix(const char* value, size_t size) {
+  set_has_suffix();
+  suffix_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
+      ::std::string(reinterpret_cast<const char*>(value), size));
+  // @@protoc_insertion_point(field_set_pointer:google.protobuf.compiler.Version.suffix)
+}
+::std::string* Version::mutable_suffix() {
+  set_has_suffix();
+  // @@protoc_insertion_point(field_mutable:google.protobuf.compiler.Version.suffix)
+  return suffix_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
+}
+::std::string* Version::release_suffix() {
+  // @@protoc_insertion_point(field_release:google.protobuf.compiler.Version.suffix)
+  clear_has_suffix();
+  return suffix_.ReleaseNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
+}
+void Version::set_allocated_suffix(::std::string* suffix) {
+  if (suffix != NULL) {
+    set_has_suffix();
+  } else {
+    clear_has_suffix();
+  }
+  suffix_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), suffix);
+  // @@protoc_insertion_point(field_set_allocated:google.protobuf.compiler.Version.suffix)
+}
+
+#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS
+
+// ===================================================================
+
 #if !defined(_MSC_VER) || _MSC_VER >= 1900
 const int CodeGeneratorRequest::kFileToGenerateFieldNumber;
 const int CodeGeneratorRequest::kParameterFieldNumber;
 const int CodeGeneratorRequest::kProtoFileFieldNumber;
+const int CodeGeneratorRequest::kCompilerVersionFieldNumber;
 #endif  // !defined(_MSC_VER) || _MSC_VER >= 1900
 
@@ -192,4 +714,9 @@ CodeGeneratorRequest::CodeGeneratorRequest(const CodeGeneratorRequest& from)
     parameter_.AssignWithDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), from.parameter_);
   }
+  if (from.has_compiler_version()) {
+    compiler_version_ = new ::google::protobuf::compiler::Version(*from.compiler_version_);
+  } else {
+    compiler_version_ = NULL;
+  }
   // @@protoc_insertion_point(copy_constructor:google.protobuf.compiler.CodeGeneratorRequest)
 }
@@ -198,4 +725,5 @@ void CodeGeneratorRequest::SharedCtor() {
   _cached_size_ = 0;
   parameter_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
+  compiler_version_ = NULL;
 }
 
@@ -207,4 +735,7 @@ CodeGeneratorRequest::~CodeGeneratorRequest() {
 void CodeGeneratorRequest::SharedDtor() {
   parameter_.DestroyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
+  if (this != internal_default_instance()) {
+    delete compiler_version_;
+  }
 }
 
@@ -216,5 +747,5 @@ void CodeGeneratorRequest::SetCachedSize(int size) const {
 const ::google::protobuf::Descriptor* CodeGeneratorRequest::descriptor() {
   protobuf_AssignDescriptorsOnce();
-  return file_level_metadata[0].descriptor;
+  return file_level_metadata[1].descriptor;
 }
 
@@ -236,7 +767,13 @@ void CodeGeneratorRequest::Clear() {
   file_to_generate_.Clear();
   proto_file_.Clear();
-  if (has_parameter()) {
-    GOOGLE_DCHECK(!parameter_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()));
-    (*parameter_.UnsafeRawStringPointer())->clear();
+  if (_has_bits_[0 / 32] & 3u) {
+    if (has_parameter()) {
+      GOOGLE_DCHECK(!parameter_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()));
+      (*parameter_.UnsafeRawStringPointer())->clear();
+    }
+    if (has_compiler_version()) {
+      GOOGLE_DCHECK(compiler_version_ != NULL);
+      compiler_version_->::google::protobuf::compiler::Version::Clear();
+    }
   }
   _has_bits_.Clear();
@@ -285,4 +822,15 @@ bool CodeGeneratorRequest::MergePartialFromCodedStream(
       }
 
+      // optional .google.protobuf.compiler.Version compiler_version = 3;
+      case 3: {
+        if (tag == 26u) {
+          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
+               input, mutable_compiler_version()));
+        } else {
+          goto handle_unusual;
+        }
+        break;
+      }
+
       // repeated .google.protobuf.FileDescriptorProto proto_file = 15;
       case 15: {
@@ -343,4 +891,10 @@ void CodeGeneratorRequest::SerializeWithCachedSizes(
   }
 
+  // optional .google.protobuf.compiler.Version compiler_version = 3;
+  if (has_compiler_version()) {
+    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
+      3, *this->compiler_version_, output);
+  }
+
   // repeated .google.protobuf.FileDescriptorProto proto_file = 15;
   for (unsigned int i = 0, n = this->proto_file_size(); i < n; i++) {
@@ -381,4 +935,11 @@ void CodeGeneratorRequest::SerializeWithCachedSizes(
   }
 
+  // optional .google.protobuf.compiler.Version compiler_version = 3;
+  if (has_compiler_version()) {
+    target = ::google::protobuf::internal::WireFormatLite::
+      InternalWriteMessageNoVirtualToArray(
+        3, *this->compiler_version_, false, target);
+  }
+
   // repeated .google.protobuf.FileDescriptorProto proto_file = 15;
   for (unsigned int i = 0, n = this->proto_file_size(); i < n; i++) {
@@ -424,11 +985,20 @@ size_t CodeGeneratorRequest::ByteSizeLong() const {
   }
 
-  // optional string parameter = 2;
-  if (has_parameter()) {
-    total_size += 1 +
-      ::google::protobuf::internal::WireFormatLite::StringSize(
-        this->parameter());
-  }
+  if (_has_bits_[0 / 32] & 3u) {
+    // optional string parameter = 2;
+    if (has_parameter()) {
+      total_size += 1 +
+        ::google::protobuf::internal::WireFormatLite::StringSize(
+          this->parameter());
+    }
 
+    // optional .google.protobuf.compiler.Version compiler_version = 3;
+    if (has_compiler_version()) {
+      total_size += 1 +
+        ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
+          *this->compiler_version_);
+    }
+
+  }
   int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
   GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
@@ -459,7 +1029,12 @@ void CodeGeneratorRequest::MergeFrom(const CodeGeneratorRequest& from) {
   file_to_generate_.MergeFrom(from.file_to_generate_);
   proto_file_.MergeFrom(from.proto_file_);
-  if (from.has_parameter()) {
-    set_has_parameter();
-    parameter_.AssignWithDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), from.parameter_);
+  if (from._has_bits_[0 / 32] & 3u) {
+    if (from.has_parameter()) {
+      set_has_parameter();
+      parameter_.AssignWithDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), from.parameter_);
+    }
+    if (from.has_compiler_version()) {
+      mutable_compiler_version()->::google::protobuf::compiler::Version::MergeFrom(from.compiler_version());
+    }
   }
 }
@@ -492,4 +1067,5 @@ void CodeGeneratorRequest::InternalSwap(CodeGeneratorRequest* other) {
   proto_file_.UnsafeArenaSwap(&other->proto_file_);
   parameter_.Swap(&other->parameter_);
+  std::swap(compiler_version_, other->compiler_version_);
   std::swap(_has_bits_[0], other->_has_bits_[0]);
   _internal_metadata_.Swap(&other->_internal_metadata_);
@@ -499,5 +1075,5 @@ void CodeGeneratorRequest::InternalSwap(CodeGeneratorRequest* other) {
 ::google::protobuf::Metadata CodeGeneratorRequest::GetMetadata() const {
   protobuf_AssignDescriptorsOnce();
-  return file_level_metadata[0];
+  return file_level_metadata[1];
 }
 
@@ -644,4 +1220,49 @@ CodeGeneratorRequest::proto_file() const {
 }
 
+// optional .google.protobuf.compiler.Version compiler_version = 3;
+bool CodeGeneratorRequest::has_compiler_version() const {
+  return (_has_bits_[0] & 0x00000002u) != 0;
+}
+void CodeGeneratorRequest::set_has_compiler_version() {
+  _has_bits_[0] |= 0x00000002u;
+}
+void CodeGeneratorRequest::clear_has_compiler_version() {
+  _has_bits_[0] &= ~0x00000002u;
+}
+void CodeGeneratorRequest::clear_compiler_version() {
+  if (compiler_version_ != NULL) compiler_version_->::google::protobuf::compiler::Version::Clear();
+  clear_has_compiler_version();
+}
+const ::google::protobuf::compiler::Version& CodeGeneratorRequest::compiler_version() const {
+  // @@protoc_insertion_point(field_get:google.protobuf.compiler.CodeGeneratorRequest.compiler_version)
+  return compiler_version_ != NULL ? *compiler_version_
+                         : *::google::protobuf::compiler::Version::internal_default_instance();
+}
+::google::protobuf::compiler::Version* CodeGeneratorRequest::mutable_compiler_version() {
+  set_has_compiler_version();
+  if (compiler_version_ == NULL) {
+    compiler_version_ = new ::google::protobuf::compiler::Version;
+  }
+  // @@protoc_insertion_point(field_mutable:google.protobuf.compiler.CodeGeneratorRequest.compiler_version)
+  return compiler_version_;
+}
+::google::protobuf::compiler::Version* CodeGeneratorRequest::release_compiler_version() {
+  // @@protoc_insertion_point(field_release:google.protobuf.compiler.CodeGeneratorRequest.compiler_version)
+  clear_has_compiler_version();
+  ::google::protobuf::compiler::Version* temp = compiler_version_;
+  compiler_version_ = NULL;
+  return temp;
+}
+void CodeGeneratorRequest::set_allocated_compiler_version(::google::protobuf::compiler::Version* compiler_version) {
+  delete compiler_version_;
+  compiler_version_ = compiler_version;
+  if (compiler_version) {
+    set_has_compiler_version();
+  } else {
+    clear_has_compiler_version();
+  }
+  // @@protoc_insertion_point(field_set_allocated:google.protobuf.compiler.CodeGeneratorRequest.compiler_version)
+}
+
 #endif  // PROTOBUF_INLINE_NOT_IN_HEADERS
 
@@ -708,5 +1329,5 @@ void CodeGeneratorResponse_File::SetCachedSize(int size) const {
 const ::google::protobuf::Descriptor* CodeGeneratorResponse_File::descriptor() {
   protobuf_AssignDescriptorsOnce();
-  return file_level_metadata[1].descriptor;
+  return file_level_metadata[2].descriptor;
 }
 
@@ -1013,5 +1634,5 @@ void CodeGeneratorResponse_File::InternalSwap(CodeGeneratorResponse_File* other)
 ::google::protobuf::Metadata CodeGeneratorResponse_File::GetMetadata() const {
   protobuf_AssignDescriptorsOnce();
-  return file_level_metadata[1];
+  return file_level_metadata[2];
 }
 
@@ -1233,5 +1854,5 @@ void CodeGeneratorResponse::SetCachedSize(int size) const {
 const ::google::protobuf::Descriptor* CodeGeneratorResponse::descriptor() {
   protobuf_AssignDescriptorsOnce();
-  return file_level_metadata[2].descriptor;
+  return file_level_metadata[3].descriptor;
 }
 
@@ -1468,5 +2089,5 @@ void CodeGeneratorResponse::InternalSwap(CodeGeneratorResponse* other) {
 ::google::protobuf::Metadata CodeGeneratorResponse::GetMetadata() const {
   protobuf_AssignDescriptorsOnce();
-  return file_level_metadata[2];
+  return file_level_metadata[3];
 }
 
diff --git a/src/google/protobuf/compiler/plugin.pb.h b/src/google/protobuf/compiler/plugin.pb.h
index 11c837a3a..e1e999bcf 100644
--- a/src/google/protobuf/compiler/plugin.pb.h
+++ b/src/google/protobuf/compiler/plugin.pb.h
@@ -117,4 +117,7 @@ class CodeGeneratorResponse_File;
 class CodeGeneratorResponse_FileDefaultTypeInternal;
 extern CodeGeneratorResponse_FileDefaultTypeInternal _CodeGeneratorResponse_File_default_instance_;
+class Version;
+class VersionDefaultTypeInternal;
+extern VersionDefaultTypeInternal _Version_default_instance_;
 }  // namespace compiler
 }  // namespace protobuf
@@ -131,4 +134,137 @@ void LIBPROTOC_EXPORT protobuf_InitDefaults_google_2fprotobuf_2fcompiler_2fplugi
 // ===================================================================
 
+class LIBPROTOC_EXPORT Version : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:google.protobuf.compiler.Version) */ {
+ public:
+  Version();
+  virtual ~Version();
+
+  Version(const Version& from);
+
+  inline Version& operator=(const Version& from) {
+    CopyFrom(from);
+    return *this;
+  }
+
+  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
+    return _internal_metadata_.unknown_fields();
+  }
+
+  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
+    return _internal_metadata_.mutable_unknown_fields();
+  }
+
+  static const ::google::protobuf::Descriptor* descriptor();
+  static const Version& default_instance();
+
+  static inline const Version* internal_default_instance() {
+    return reinterpret_cast<const Version*>(
+               &_Version_default_instance_);
+  }
+
+  void Swap(Version* other);
+
+  // implements Message ----------------------------------------------
+
+  inline Version* New() const PROTOBUF_FINAL { return New(NULL); }
+
+  Version* New(::google::protobuf::Arena* arena) const PROTOBUF_FINAL;
+  void CopyFrom(const ::google::protobuf::Message& from) PROTOBUF_FINAL;
+  void MergeFrom(const ::google::protobuf::Message& from) PROTOBUF_FINAL;
+  void CopyFrom(const Version& from);
+  void MergeFrom(const Version& from);
+  void Clear() PROTOBUF_FINAL;
+  bool IsInitialized() const PROTOBUF_FINAL;
+
+  size_t ByteSizeLong() const PROTOBUF_FINAL;
+  bool MergePartialFromCodedStream(
+      ::google::protobuf::io::CodedInputStream* input) PROTOBUF_FINAL;
+  void SerializeWithCachedSizes(
+      ::google::protobuf::io::CodedOutputStream* output) const PROTOBUF_FINAL;
+  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
+      bool deterministic, ::google::protobuf::uint8* target) const PROTOBUF_FINAL;
+  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output)
+      const PROTOBUF_FINAL {
+    return InternalSerializeWithCachedSizesToArray(false, output);
+  }
+  int GetCachedSize() const PROTOBUF_FINAL { return _cached_size_; }
+  private:
+  void SharedCtor();
+  void SharedDtor();
+  void SetCachedSize(int size) const PROTOBUF_FINAL;
+  void InternalSwap(Version* other);
+  private:
+  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
+    return NULL;
+  }
+  inline void* MaybeArenaPtr() const {
+    return NULL;
+  }
+  public:
+
+  ::google::protobuf::Metadata GetMetadata() const PROTOBUF_FINAL;
+
+  // nested types ----------------------------------------------------
+
+  // accessors -------------------------------------------------------
+
+  // optional int32 major = 1;
+  bool has_major() const;
+  void clear_major();
+  static const int kMajorFieldNumber = 1;
+  ::google::protobuf::int32 major() const;
+  void set_major(::google::protobuf::int32 value);
+
+  // optional int32 minor = 2;
+  bool has_minor() const;
+  void clear_minor();
+  static const int kMinorFieldNumber = 2;
+  ::google::protobuf::int32 minor() const;
+  void set_minor(::google::protobuf::int32 value);
+
+  // optional int32 patch = 3;
+  bool has_patch() const;
+  void clear_patch();
+  static const int kPatchFieldNumber = 3;
+  ::google::protobuf::int32 patch() const;
+  void set_patch(::google::protobuf::int32 value);
+
+  // optional string suffix = 4;
+  bool has_suffix() const;
+  void clear_suffix();
+  static const int kSuffixFieldNumber = 4;
+  const ::std::string& suffix() const;
+  void set_suffix(const ::std::string& value);
+  void set_suffix(const char* value);
+  void set_suffix(const char* value, size_t size);
+  ::std::string* mutable_suffix();
+  ::std::string* release_suffix();
+  void set_allocated_suffix(::std::string* suffix);
+
+  // @@protoc_insertion_point(class_scope:google.protobuf.compiler.Version)
+ private:
+  void set_has_major();
+  void clear_has_major();
+  void set_has_minor();
+  void clear_has_minor();
+  void set_has_patch();
+  void clear_has_patch();
+  void set_has_suffix();
+  void clear_has_suffix();
+
+  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
+  ::google::protobuf::internal::HasBits<1> _has_bits_;
+  mutable int _cached_size_;
+  ::google::protobuf::internal::ArenaStringPtr suffix_;
+  ::google::protobuf::int32 major_;
+  ::google::protobuf::int32 minor_;
+  ::google::protobuf::int32 patch_;
+  friend void LIBPROTOC_EXPORT protobuf_InitDefaults_google_2fprotobuf_2fcompiler_2fplugin_2eproto_impl();
+  friend void LIBPROTOC_EXPORT protobuf_AddDesc_google_2fprotobuf_2fcompiler_2fplugin_2eproto_impl();
+  friend const ::google::protobuf::uint32* protobuf_Offsets_google_2fprotobuf_2fcompiler_2fplugin_2eproto();
+  friend void protobuf_ShutdownFile_google_2fprotobuf_2fcompiler_2fplugin_2eproto();
+
+};
+// -------------------------------------------------------------------
+
 class LIBPROTOC_EXPORT CodeGeneratorRequest : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:google.protobuf.compiler.CodeGeneratorRequest) */ {
  public:
@@ -245,8 +381,19 @@ class LIBPROTOC_EXPORT CodeGeneratorRequest : public ::google::protobuf::Message
       proto_file() const;
 
+  // optional .google.protobuf.compiler.Version compiler_version = 3;
+  bool has_compiler_version() const;
+  void clear_compiler_version();
+  static const int kCompilerVersionFieldNumber = 3;
+  const ::google::protobuf::compiler::Version& compiler_version() const;
+  ::google::protobuf::compiler::Version* mutable_compiler_version();
+  ::google::protobuf::compiler::Version* release_compiler_version();
+  void set_allocated_compiler_version(::google::protobuf::compiler::Version* compiler_version);
+
   // @@protoc_insertion_point(class_scope:google.protobuf.compiler.CodeGeneratorRequest)
  private:
   void set_has_parameter();
   void clear_has_parameter();
+  void set_has_compiler_version();
+  void clear_has_compiler_version();
 
   ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
@@ -256,4 +403,5 @@ class LIBPROTOC_EXPORT CodeGeneratorRequest : public ::google::protobuf::Message
   ::google::protobuf::RepeatedPtrField< ::google::protobuf::FileDescriptorProto > proto_file_;
   ::google::protobuf::internal::ArenaStringPtr parameter_;
+  ::google::protobuf::compiler::Version* compiler_version_;
   friend void LIBPROTOC_EXPORT protobuf_InitDefaults_google_2fprotobuf_2fcompiler_2fplugin_2eproto_impl();
   friend void LIBPROTOC_EXPORT protobuf_AddDesc_google_2fprotobuf_2fcompiler_2fplugin_2eproto_impl();
@@ -519,4 +667,134 @@ class LIBPROTOC_EXPORT CodeGeneratorResponse : public ::google::protobuf::Messag
 
 #if !PROTOBUF_INLINE_NOT_IN_HEADERS
+// Version
+
+// optional int32 major = 1;
+inline bool Version::has_major() const {
+  return (_has_bits_[0] & 0x00000002u) != 0;
+}
+inline void Version::set_has_major() {
+  _has_bits_[0] |= 0x00000002u;
+}
+inline void Version::clear_has_major() {
+  _has_bits_[0] &= ~0x00000002u;
+}
+inline void Version::clear_major() {
+  major_ = 0;
+  clear_has_major();
+}
+inline ::google::protobuf::int32 Version::major() const {
+  // @@protoc_insertion_point(field_get:google.protobuf.compiler.Version.major)
+  return major_;
+}
+inline void Version::set_major(::google::protobuf::int32 value) {
+  set_has_major();
+  major_ = value;
+  // @@protoc_insertion_point(field_set:google.protobuf.compiler.Version.major)
+}
+
+// optional int32 minor = 2;
+inline bool Version::has_minor() const {
+  return (_has_bits_[0] & 0x00000004u) != 0;
+}
+inline void Version::set_has_minor() {
+  _has_bits_[0] |= 0x00000004u;
+}
+inline void Version::clear_has_minor() {
+  _has_bits_[0] &= ~0x00000004u;
+}
+inline void Version::clear_minor() {
+  minor_ = 0;
+  clear_has_minor();
+}
+inline ::google::protobuf::int32 Version::minor() const {
+  // @@protoc_insertion_point(field_get:google.protobuf.compiler.Version.minor)
+  return minor_;
+}
+inline void Version::set_minor(::google::protobuf::int32 value) {
+  set_has_minor();
+  minor_ = value;
+  // @@protoc_insertion_point(field_set:google.protobuf.compiler.Version.minor)
+}
+
+// optional int32 patch = 3;
+inline bool Version::has_patch() const {
+  return (_has_bits_[0] & 0x00000008u) != 0;
+}
+inline void Version::set_has_patch() {
+  _has_bits_[0] |= 0x00000008u;
+}
+inline void Version::clear_has_patch() {
+  _has_bits_[0] &= ~0x00000008u;
+}
+inline void Version::clear_patch() {
+  patch_ = 0;
+  clear_has_patch();
+}
+inline ::google::protobuf::int32 Version::patch() const {
+  // @@protoc_insertion_point(field_get:google.protobuf.compiler.Version.patch)
+  return patch_;
+}
+inline void Version::set_patch(::google::protobuf::int32 value) {
+  set_has_patch();
+  patch_ = value;
+  // @@protoc_insertion_point(field_set:google.protobuf.compiler.Version.patch)
+}
+
+// optional string suffix = 4;
+inline bool Version::has_suffix() const {
+  return (_has_bits_[0] & 0x00000001u) != 0;
+}
+inline void Version::set_has_suffix() {
+  _has_bits_[0] |= 0x00000001u;
+}
+inline void Version::clear_has_suffix() {
+  _has_bits_[0] &= ~0x00000001u;
+}
+inline void Version::clear_suffix() {
+  suffix_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
+  clear_has_suffix();
+}
+inline const ::std::string& Version::suffix() const {
+  // @@protoc_insertion_point(field_get:google.protobuf.compiler.Version.suffix)
+  return suffix_.GetNoArena();
+}
+inline void Version::set_suffix(const ::std::string& value) {
+  set_has_suffix();
+  suffix_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
+  // @@protoc_insertion_point(field_set:google.protobuf.compiler.Version.suffix)
+}
+inline void Version::set_suffix(const char* value) {
+  set_has_suffix();
+  suffix_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
+  // @@protoc_insertion_point(field_set_char:google.protobuf.compiler.Version.suffix)
+}
+inline void Version::set_suffix(const char* value, size_t size) {
+  set_has_suffix();
+  suffix_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
+      ::std::string(reinterpret_cast<const char*>(value), size));
+  // @@protoc_insertion_point(field_set_pointer:google.protobuf.compiler.Version.suffix)
+}
+inline ::std::string* Version::mutable_suffix() {
+  set_has_suffix();
+  // @@protoc_insertion_point(field_mutable:google.protobuf.compiler.Version.suffix)
+  return suffix_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
+}
+inline ::std::string* Version::release_suffix() {
+  // @@protoc_insertion_point(field_release:google.protobuf.compiler.Version.suffix)
+  clear_has_suffix();
+  return suffix_.ReleaseNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
+}
+inline void Version::set_allocated_suffix(::std::string* suffix) {
+  if (suffix != NULL) {
+    set_has_suffix();
+  } else {
+    clear_has_suffix();
+  }
+  suffix_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), suffix);
+  // @@protoc_insertion_point(field_set_allocated:google.protobuf.compiler.Version.suffix)
+}
+
+// -------------------------------------------------------------------
+
 // CodeGeneratorRequest
 
@@ -660,4 +938,49 @@ CodeGeneratorRequest::proto_file() const {
 }
 
+// optional .google.protobuf.compiler.Version compiler_version = 3;
+inline bool CodeGeneratorRequest::has_compiler_version() const {
+  return (_has_bits_[0] & 0x00000002u) != 0;
+}
+inline void CodeGeneratorRequest::set_has_compiler_version() {
+  _has_bits_[0] |= 0x00000002u;
+}
+inline void CodeGeneratorRequest::clear_has_compiler_version() {
+  _has_bits_[0] &= ~0x00000002u;
+}
+inline void CodeGeneratorRequest::clear_compiler_version() {
+  if (compiler_version_ != NULL) compiler_version_->::google::protobuf::compiler::Version::Clear();
+  clear_has_compiler_version();
+}
+inline const ::google::protobuf::compiler::Version& CodeGeneratorRequest::compiler_version() const {
+  // @@protoc_insertion_point(field_get:google.protobuf.compiler.CodeGeneratorRequest.compiler_version)
+  return compiler_version_ != NULL ? *compiler_version_
+                         : *::google::protobuf::compiler::Version::internal_default_instance();
+}
+inline ::google::protobuf::compiler::Version* CodeGeneratorRequest::mutable_compiler_version() {
+  set_has_compiler_version();
+  if (compiler_version_ == NULL) {
+    compiler_version_ = new ::google::protobuf::compiler::Version;
+  }
+  // @@protoc_insertion_point(field_mutable:google.protobuf.compiler.CodeGeneratorRequest.compiler_version)
+  return compiler_version_;
+}
+inline ::google::protobuf::compiler::Version* CodeGeneratorRequest::release_compiler_version() {
+  // @@protoc_insertion_point(field_release:google.protobuf.compiler.CodeGeneratorRequest.compiler_version)
+  clear_has_compiler_version();
+  ::google::protobuf::compiler::Version* temp = compiler_version_;
+  compiler_version_ = NULL;
+  return temp;
+}
+inline void CodeGeneratorRequest::set_allocated_compiler_version(::google::protobuf::compiler::Version* compiler_version) {
+  delete compiler_version_;
+  compiler_version_ = compiler_version;
+  if (compiler_version) {
+    set_has_compiler_version();
+  } else {
+    clear_has_compiler_version();
+  }
+  // @@protoc_insertion_point(field_set_allocated:google.protobuf.compiler.CodeGeneratorRequest.compiler_version)
+}
+
 // -------------------------------------------------------------------
 
@@ -919,4 +1242,6 @@ CodeGeneratorResponse::file() const {
 // -------------------------------------------------------------------
 
+// -------------------------------------------------------------------
+
 
 // @@protoc_insertion_point(namespace_scope)
diff --git a/src/google/protobuf/compiler/plugin.proto b/src/google/protobuf/compiler/plugin.proto
index acaee1f49..6e4da2c19 100644
--- a/src/google/protobuf/compiler/plugin.proto
+++ b/src/google/protobuf/compiler/plugin.proto
@@ -54,4 +54,14 @@ option go_package = ""plugin_go"";
 import ""google/protobuf/descriptor.proto"";
 
+// The version number of protocol compiler.
+message Version {
+  optional int32 major = 1;
+  optional int32 minor = 2;
+  optional int32 patch = 3;
+  // A suffix for alpha, beta or rc release, e.g., ""alpha-1"", ""rc2"". It should
+  // be empty for mainline stable releases.
+  optional string suffix = 4;
+}
+
 // An encoded CodeGeneratorRequest is written to the plugin's stdin.
 message CodeGeneratorRequest {
@@ -76,4 +86,7 @@ message CodeGeneratorRequest {
   // memory at once before sending them to the plugin.
   repeated FileDescriptorProto proto_file = 15;
+
+  // The version number of protocol compiler.
+  optional Version compiler_version = 3;
 }
 
diff --git a/src/google/protobuf/stubs/common.h b/src/google/protobuf/stubs/common.h
index 43e88ff2d..c595e205f 100644
--- a/src/google/protobuf/stubs/common.h
+++ b/src/google/protobuf/stubs/common.h
@@ -99,4 +99,7 @@ namespace internal {
 #define GOOGLE_PROTOBUF_VERSION 3001000
 
+// A suffix string for alpha, beta or rc releases. Empty for stable releases.
+#define GOOGLE_PROTOBUF_VERSION_SUFFIX """"
+
 // The minimum library version which works with the current version of the
 // headers.
","Add version number to plugin protocol.

"
104,C++,e8310aa25940f9e062b8352e1d485bb804aba714,https://github.com/protocolbuffers/protobuf/commit/e8310aa25940f9e062b8352e1d485bb804aba714,P,protocolbuffers,protobuf,"[28, 0, 5295, 0, 0, 984, 0, 23, 0, 1399, 0, 0, 256, 0, 0, 3131, 0, 1, 0, 44, 0, 0, 0, 0, 0, 47, 0, 4492, 0]","diff --git a/csharp/csproj_templates/CF20.csproj b/csharp/csproj_templates/CF20.csproj
deleted file mode 100644
index 296841269..000000000
--- a/csharp/csproj_templates/CF20.csproj
+++ /dev/null
@@ -1,41 +0,0 @@
-<Project DefaultTargets=""Build"" xmlns=""http://schemas.microsoft.com/developer/msbuild/2003"" ToolsVersion=""3.5"">
-  <PropertyGroup>
-    <EnvironmentFlavor>COMPACT_FRAMEWORK</EnvironmentFlavor>
-    <EnvironmentTemplate>CF20</EnvironmentTemplate>
-    <ProjectTypeGuids>{4D628B5B-2FBC-4AA6-8C16-197242AEB884};{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}</ProjectTypeGuids>
-    <TargetFrameworkVersion>v2.0</TargetFrameworkVersion>
-    <PlatformFamilyName>Smartphone</PlatformFamilyName>
-    <PlatformID>f27da329-3269-4191-98e0-c87d3d7f1db9</PlatformID>
-    <!--<OSVersion>5.2</OSVersion>-->
-    <!--<DeployDirSuffix>CF20</DeployDirSuffix>-->
-    <!--<NativePlatformName>Windows Mobile 6 Standard SDK</NativePlatformName>-->
-    <!--<FormFactorID></FormFactorID>-->
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Debug|AnyCPU' "">
-    <OutputPath>bin\CF20\Debug</OutputPath>
-    <IntermediateOutputPath>obj\CF20\Debug\</IntermediateOutputPath>
-    <DefineConstants>$(DefineConstants);NOSERIALIZABLE;NOFILEVERSION;NOEXTENSIONS</DefineConstants>
-    <NoConfig>true</NoConfig>
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Release|AnyCPU' "">
-    <OutputPath>bin\CF20\Release</OutputPath>
-    <IntermediateOutputPath>obj\CF20\Release\</IntermediateOutputPath>
-    <DefineConstants>$(DefineConstants);NOSERIALIZABLE;NOFILEVERSION;NOEXTENSIONS</DefineConstants>
-    <NoConfig>true</NoConfig>
-  </PropertyGroup>
-  <Import Project=""$(MSBuildBinPath)\Microsoft.CompactFramework.CSharp.targets"" />
-  <ProjectExtensions>
-    <VisualStudio>
-      <FlavorProperties GUID=""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"">
-        <HostingProcess disable=""1"" />
-      </FlavorProperties>
-    </VisualStudio>
-  </ProjectExtensions>
-  <!-- To modify your build process, add your task inside one of the targets below and uncomment it. 
-       Other similar extension points exist, see Microsoft.Common.targets.
-  <Target Name=""BeforeBuild"">
-  </Target>
-  <Target Name=""AfterBuild"">
-  </Target>
-  -->
-</Project>
\ No newline at end of file
diff --git a/csharp/csproj_templates/CF35.csproj b/csharp/csproj_templates/CF35.csproj
deleted file mode 100644
index eae866f00..000000000
--- a/csharp/csproj_templates/CF35.csproj
+++ /dev/null
@@ -1,44 +0,0 @@
-<Project DefaultTargets=""Build"" xmlns=""http://schemas.microsoft.com/developer/msbuild/2003"" ToolsVersion=""3.5"">
-  <PropertyGroup>
-    <EnvironmentFlavor>COMPACT_FRAMEWORK</EnvironmentFlavor>
-    <EnvironmentTemplate>CF35</EnvironmentTemplate>
-    <ProjectTypeGuids>{4D628B5B-2FBC-4AA6-8C16-197242AEB884};{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}</ProjectTypeGuids>
-    <TargetFrameworkVersion>v3.5</TargetFrameworkVersion>
-    <PlatformFamilyName>Smartphone</PlatformFamilyName>
-    <PlatformID>f27da329-3269-4191-98e0-c87d3d7f1db9</PlatformID>
-    <!--<OSVersion>5.2</OSVersion>-->
-    <!--<DeployDirSuffix>CF35</DeployDirSuffix>-->
-    <!--<NativePlatformName>Windows Mobile 6 Standard SDK</NativePlatformName>-->
-    <!--<FormFactorID></FormFactorID>-->
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Debug|AnyCPU' "">
-    <OutputPath>bin\CF35\Debug</OutputPath>
-    <IntermediateOutputPath>obj\CF35\Debug\</IntermediateOutputPath>
-    <DefineConstants>$(DefineConstants);NOSERIALIZABLE;NOFILEVERSION</DefineConstants>
-    <NoConfig>true</NoConfig>
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Release|AnyCPU' "">
-    <OutputPath>bin\CF35\Release</OutputPath>
-    <IntermediateOutputPath>obj\CF35\Release\</IntermediateOutputPath>
-    <DefineConstants>$(DefineConstants);NOSERIALIZABLE;NOFILEVERSION</DefineConstants>
-    <NoConfig>true</NoConfig>
-  </PropertyGroup>
-  <ItemGroup>
-    <Reference Include=""System.Core"" />
-  </ItemGroup>
-  <Import Project=""$(MSBuildBinPath)\Microsoft.CompactFramework.CSharp.targets"" />
-  <ProjectExtensions>
-    <VisualStudio>
-      <FlavorProperties GUID=""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"">
-        <HostingProcess disable=""1"" />
-      </FlavorProperties>
-    </VisualStudio>
-  </ProjectExtensions>
-  <!-- To modify your build process, add your task inside one of the targets below and uncomment it. 
-       Other similar extension points exist, see Microsoft.Common.targets.
-  <Target Name=""BeforeBuild"">
-  </Target>
-  <Target Name=""AfterBuild"">
-  </Target>
-  -->
-</Project>
\ No newline at end of file
diff --git a/csharp/csproj_templates/NET20.csproj b/csharp/csproj_templates/NET20.csproj
deleted file mode 100644
index f9e939200..000000000
--- a/csharp/csproj_templates/NET20.csproj
+++ /dev/null
@@ -1,17 +0,0 @@
-<Project DefaultTargets=""Build"" xmlns=""http://schemas.microsoft.com/developer/msbuild/2003"" ToolsVersion=""3.5"">
-  <PropertyGroup>
-    <EnvironmentFlavor>CLIENTPROFILE</EnvironmentFlavor>
-    <EnvironmentTemplate>NET20</EnvironmentTemplate>
-    <TargetFrameworkVersion>v2.0</TargetFrameworkVersion>
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Debug|AnyCPU' "">
-    <OutputPath>bin\NET20\Debug</OutputPath>
-    <IntermediateOutputPath>obj\NET20\Debug\</IntermediateOutputPath>
-    <DefineConstants>$(DefineConstants);NOEXTENSIONS</DefineConstants>
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Release|AnyCPU' "">
-    <OutputPath>bin\NET20\Release</OutputPath>
-    <IntermediateOutputPath>obj\NET20\Release\</IntermediateOutputPath>
-    <DefineConstants>$(DefineConstants);NOEXTENSIONS</DefineConstants>
-  </PropertyGroup>
-</Project>
\ No newline at end of file
diff --git a/csharp/csproj_templates/NET35.csproj b/csharp/csproj_templates/NET35.csproj
deleted file mode 100644
index 80ef69aa3..000000000
--- a/csharp/csproj_templates/NET35.csproj
+++ /dev/null
@@ -1,20 +0,0 @@
-<Project DefaultTargets=""Build"" xmlns=""http://schemas.microsoft.com/developer/msbuild/2003"" ToolsVersion=""3.5"">
-  <PropertyGroup>
-    <EnvironmentFlavor>CLIENTPROFILE</EnvironmentFlavor>
-    <EnvironmentTemplate>NET35</EnvironmentTemplate>
-    <TargetFrameworkVersion>v3.5</TargetFrameworkVersion>
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Debug|AnyCPU' "">
-    <OutputPath>bin\NET35\Debug</OutputPath>
-    <IntermediateOutputPath>obj\NET35\Debug\</IntermediateOutputPath>
-    <DefineConstants>$(DefineConstants)</DefineConstants>
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Release|AnyCPU' "">
-    <OutputPath>bin\NET35\Release</OutputPath>
-    <IntermediateOutputPath>obj\NET35\Release\</IntermediateOutputPath>
-    <DefineConstants>$(DefineConstants)</DefineConstants>
-  </PropertyGroup>
-  <ItemGroup>
-    <Reference Include=""System.Core"" />
-  </ItemGroup>
-</Project>
\ No newline at end of file
diff --git a/csharp/csproj_templates/NET40.csproj b/csharp/csproj_templates/NET40.csproj
deleted file mode 100644
index 691845a65..000000000
--- a/csharp/csproj_templates/NET40.csproj
+++ /dev/null
@@ -1,20 +0,0 @@
-<Project DefaultTargets=""Build"" xmlns=""http://schemas.microsoft.com/developer/msbuild/2003"" ToolsVersion=""4.0"">
-  <PropertyGroup>
-    <EnvironmentFlavor>CLIENTPROFILE</EnvironmentFlavor>
-    <EnvironmentTemplate>NET40</EnvironmentTemplate>
-    <TargetFrameworkVersion>v4.0</TargetFrameworkVersion>
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Debug|AnyCPU' "">
-    <OutputPath>bin\NET40\Debug</OutputPath>
-    <IntermediateOutputPath>obj\NET40\Debug\</IntermediateOutputPath>
-    <DefineConstants>$(DefineConstants)</DefineConstants>
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Release|AnyCPU' "">
-    <OutputPath>bin\NET40\Release</OutputPath>
-    <IntermediateOutputPath>obj\NET40\Release\</IntermediateOutputPath>
-    <DefineConstants>$(DefineConstants)</DefineConstants>
-  </PropertyGroup>
-  <ItemGroup>
-    <Reference Include=""System.Core"" />
-  </ItemGroup>
-</Project>
\ No newline at end of file
diff --git a/csharp/csproj_templates/PL40.csproj b/csharp/csproj_templates/PL40.csproj
deleted file mode 100644
index 2618a79f4..000000000
--- a/csharp/csproj_templates/PL40.csproj
+++ /dev/null
@@ -1,51 +0,0 @@
-<Project ToolsVersion=""4.0"" DefaultTargets=""Build"" 
-         xmlns=""http://schemas.microsoft.com/developer/msbuild/2003""
-         xmlns:cs=""urn:schemas-csharp-project:template"">
-  <PropertyGroup>
-    <MinimumVisualStudioVersion>10.0</MinimumVisualStudioVersion>
-    <EnvironmentFlavor>PORTABLE_LIBRARY</EnvironmentFlavor>
-    <EnvironmentTemplate>PL40</EnvironmentTemplate>
-    <ProjectTypeGuids>{786C830F-07A1-408B-BD7F-6EE04809D6DB};{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}</ProjectTypeGuids>
-    <TargetFrameworkVersion>v4.0</TargetFrameworkVersion>
-    <TargetFrameworkProfile>Profile1</TargetFrameworkProfile>
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Debug|AnyCPU' "">
-    <OutputPath>bin\PL40\Debug</OutputPath>
-    <IntermediateOutputPath>obj\PL40\Debug\</IntermediateOutputPath>
-    <DefineConstants>$(DefineConstants);NOSERIALIZABLE;NOSORTEDLIST</DefineConstants>
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Release|AnyCPU' "">
-    <OutputPath>bin\PL40\Release</OutputPath>
-    <IntermediateOutputPath>obj\PL40\Release\</IntermediateOutputPath>
-    <DefineConstants>$(DefineConstants);NOSERIALIZABLE;NOSORTEDLIST</DefineConstants>
-  </PropertyGroup>
-  <ItemGroup>
-    <Reference Include=""System.Core"" />
-  </ItemGroup>
-  <Import cs:Precondition="" '$(EnvironmentProjectType)' != 'TEST' ""
-          Project=""$(MSBuildExtensionsPath32)\Microsoft\Portable\$(TargetFrameworkVersion)\Microsoft.Portable.CSharp.targets"" />
-  <!-- Portable Library will be tested as silverlight -->
-  <PropertyGroup cs:Precondition="" '$(EnvironmentProjectType)' == 'TEST' "">
-    <ProjectTypeGuids>{A1591282-1198-4647-A2B1-27E5FF5F6F3B};{fae04ec0-301f-11d3-bf4b-00c04f79efbc}</ProjectTypeGuids>
-    <ValidateXaml>false</ValidateXaml>
-    <ThrowErrorsInValidation>false</ThrowErrorsInValidation>
-    <TargetFrameworkProfile />
-  </PropertyGroup>
-  <cs:Import Project=""SLTest.targets"" cs:Precondition="" '$(EnvironmentProjectType)' == 'TEST' "" />
-  <Import cs:Precondition="" '$(EnvironmentProjectType)' == 'TEST' ""
-          Project=""$(MSBuildExtensionsPath32)\Microsoft\Silverlight\$(SilverlightVersion)\Microsoft.Silverlight.CSharp.targets"" />
-  <!-- To modify your build process, add your task inside one of the targets below and uncomment it. 
-       Other similar extension points exist, see Microsoft.Common.targets.
-  <Target Name=""BeforeBuild"">
-  </Target>
-  <Target Name=""AfterBuild"">
-  </Target>
-  -->
-  <ProjectExtensions cs:Precondition="" '$(EnvironmentProjectType)' == 'TEST' "">
-    <VisualStudio>
-      <FlavorProperties GUID=""{A1591282-1198-4647-A2B1-27E5FF5F6F3B}"">
-        <SilverlightProjectProperties />
-      </FlavorProperties>
-    </VisualStudio>
-  </ProjectExtensions>
-</Project>
\ No newline at end of file
diff --git a/csharp/csproj_templates/SL20.csproj b/csharp/csproj_templates/SL20.csproj
deleted file mode 100644
index 0abb104b1..000000000
--- a/csharp/csproj_templates/SL20.csproj
+++ /dev/null
@@ -1,44 +0,0 @@
-<Project ToolsVersion=""3.5"" DefaultTargets=""Build"" 
-         xmlns=""http://schemas.microsoft.com/developer/msbuild/2003""
-         xmlns:cs=""urn:schemas-csharp-project:template"">
-  <PropertyGroup>
-    <EnvironmentFlavor>SILVERLIGHT</EnvironmentFlavor>
-    <EnvironmentTemplate>SL20</EnvironmentTemplate>
-    <ProjectTypeGuids>{A1591282-1198-4647-A2B1-27E5FF5F6F3B};{fae04ec0-301f-11d3-bf4b-00c04f79efbc}</ProjectTypeGuids>
-    <TargetFrameworkVersion>v2.0</TargetFrameworkVersion>
-    <SilverlightApplication>false</SilverlightApplication>
-    <ValidateXaml>false</ValidateXaml>
-    <ThrowErrorsInValidation>false</ThrowErrorsInValidation>
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Debug|AnyCPU' "">
-    <OutputPath>bin\SL20\Debug</OutputPath>
-    <IntermediateOutputPath>obj\SL20\Debug\</IntermediateOutputPath>
-    <DefineConstants>$(DefineConstants);NOSERIALIZABLE;NOSORTEDLIST;NOEXTENSIONS</DefineConstants>
-    <NoConfig>true</NoConfig>
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Release|AnyCPU' "">
-    <OutputPath>bin\SL20\Release</OutputPath>
-    <IntermediateOutputPath>obj\SL20\Release\</IntermediateOutputPath>
-    <DefineConstants>$(DefineConstants);NOSERIALIZABLE;NOSORTEDLIST;NOEXTENSIONS</DefineConstants>
-    <NoConfig>true</NoConfig>
-  </PropertyGroup>
-  <!-- Preprocess include of silverlight testing -->
-  <cs:Import Project=""SLTest.targets"" cs:Precondition="" '$(EnvironmentProjectType)' == 'TEST' "" />
-  <Import Project=""$(MSBuildExtensionsPath32)\Microsoft\Silverlight\v2.0\Microsoft.Silverlight.CSharp.targets"" />
-  <!-- To modify your build process, add your task inside one of the targets below and uncomment it. 
-       Other similar extension points exist, see Microsoft.Common.targets.
-  <Target Name=""BeforeBuild"">
-  </Target>
-  <Target Name=""AfterBuild"">
-  </Target>
-  -->
-  <ProjectExtensions>
-    <VisualStudio>
-      <FlavorProperties GUID=""{A1591282-1198-4647-A2B1-27E5FF5F6F3B}"">
-        <SilverlightProjectProperties>
-          <StartAction>OfflineApplication</StartAction>
-        </SilverlightProjectProperties>
-      </FlavorProperties>
-    </VisualStudio>
-  </ProjectExtensions>
-</Project>
\ No newline at end of file
diff --git a/csharp/csproj_templates/SL30.csproj b/csharp/csproj_templates/SL30.csproj
deleted file mode 100644
index 82ea9a8ee..000000000
--- a/csharp/csproj_templates/SL30.csproj
+++ /dev/null
@@ -1,47 +0,0 @@
-<Project ToolsVersion=""3.5"" DefaultTargets=""Build"" 
-         xmlns=""http://schemas.microsoft.com/developer/msbuild/2003""
-         xmlns:cs=""urn:schemas-csharp-project:template"">
-  <PropertyGroup>
-    <EnvironmentFlavor>SILVERLIGHT</EnvironmentFlavor>
-    <EnvironmentTemplate>SL30</EnvironmentTemplate>
-    <ProjectTypeGuids>{A1591282-1198-4647-A2B1-27E5FF5F6F3B};{fae04ec0-301f-11d3-bf4b-00c04f79efbc}</ProjectTypeGuids>
-    <TargetFrameworkVersion>v3.5</TargetFrameworkVersion>
-    <SilverlightApplication>false</SilverlightApplication>
-    <ValidateXaml>false</ValidateXaml>
-    <ThrowErrorsInValidation>false</ThrowErrorsInValidation>
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Debug|AnyCPU' "">
-    <OutputPath>bin\SL30\Debug</OutputPath>
-    <IntermediateOutputPath>obj\SL30\Debug\</IntermediateOutputPath>
-    <DefineConstants>$(DefineConstants);NOSERIALIZABLE;NOSORTEDLIST</DefineConstants>
-    <NoConfig>true</NoConfig>
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Release|AnyCPU' "">
-    <OutputPath>bin\SL30\Release</OutputPath>
-    <IntermediateOutputPath>obj\SL30\Release\</IntermediateOutputPath>
-    <DefineConstants>$(DefineConstants);NOSERIALIZABLE;NOSORTEDLIST</DefineConstants>
-    <NoConfig>true</NoConfig>
-  </PropertyGroup>
-  <ItemGroup>
-    <Reference Include=""System.Core"" />
-  </ItemGroup>
-  <!-- Preprocess include of silverlight testing -->
-  <cs:Import Project=""SLTest.targets"" cs:Precondition="" '$(EnvironmentProjectType)' == 'TEST' "" />
-  <Import Project=""$(MSBuildExtensionsPath32)\Microsoft\Silverlight\v3.0\Microsoft.Silverlight.CSharp.targets"" />
-  <!-- To modify your build process, add your task inside one of the targets below and uncomment it. 
-       Other similar extension points exist, see Microsoft.Common.targets.
-  <Target Name=""BeforeBuild"">
-  </Target>
-  <Target Name=""AfterBuild"">
-  </Target>
-  -->
-  <ProjectExtensions>
-    <VisualStudio>
-      <FlavorProperties GUID=""{A1591282-1198-4647-A2B1-27E5FF5F6F3B}"">
-        <SilverlightProjectProperties>
-          <StartAction>OfflineApplication</StartAction>
-        </SilverlightProjectProperties>
-      </FlavorProperties>
-    </VisualStudio>
-  </ProjectExtensions>
-</Project>
\ No newline at end of file
diff --git a/csharp/csproj_templates/SL40.csproj b/csharp/csproj_templates/SL40.csproj
deleted file mode 100644
index 8a38e3d2e..000000000
--- a/csharp/csproj_templates/SL40.csproj
+++ /dev/null
@@ -1,48 +0,0 @@
-<Project ToolsVersion=""4.0"" DefaultTargets=""Build"" 
-         xmlns=""http://schemas.microsoft.com/developer/msbuild/2003""
-         xmlns:cs=""urn:schemas-csharp-project:template"">
-  <PropertyGroup>
-    <EnvironmentFlavor>SILVERLIGHT</EnvironmentFlavor>
-    <EnvironmentTemplate>SL40</EnvironmentTemplate>
-    <ProjectTypeGuids>{A1591282-1198-4647-A2B1-27E5FF5F6F3B};{fae04ec0-301f-11d3-bf4b-00c04f79efbc}</ProjectTypeGuids>
-    <TargetFrameworkVersion>v4.0</TargetFrameworkVersion>
-    <SilverlightApplication>false</SilverlightApplication>
-    <ValidateXaml>false</ValidateXaml>
-    <ThrowErrorsInValidation>false</ThrowErrorsInValidation>
-    <SilverlightVersion>$(TargetFrameworkVersion)</SilverlightVersion>
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Debug|AnyCPU' "">
-    <OutputPath>bin\SL40\Debug</OutputPath>
-    <IntermediateOutputPath>obj\SL40\Debug\</IntermediateOutputPath>
-    <DefineConstants>$(DefineConstants);NOSERIALIZABLE;NOSORTEDLIST</DefineConstants>
-    <NoConfig>true</NoConfig>
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Release|AnyCPU' "">
-    <OutputPath>bin\SL40\Release</OutputPath>
-    <IntermediateOutputPath>obj\SL40\Release\</IntermediateOutputPath>
-    <DefineConstants>$(DefineConstants);NOSERIALIZABLE;NOSORTEDLIST</DefineConstants>
-    <NoConfig>true</NoConfig>
-  </PropertyGroup>
-  <ItemGroup>
-    <Reference Include=""System.Core"" />
-  </ItemGroup>
-  <!-- Preprocess include of silverlight testing -->
-  <cs:Import Project=""SLTest.targets"" cs:Precondition="" '$(EnvironmentProjectType)' == 'TEST' "" />
-  <Import Project=""$(MSBuildExtensionsPath32)\Microsoft\Silverlight\$(SilverlightVersion)\Microsoft.Silverlight.CSharp.targets"" />
-  <!-- To modify your build process, add your task inside one of the targets below and uncomment it. 
-       Other similar extension points exist, see Microsoft.Common.targets.
-  <Target Name=""BeforeBuild"">
-  </Target>
-  <Target Name=""AfterBuild"">
-  </Target>
-  -->
-  <ProjectExtensions>
-    <VisualStudio>
-      <FlavorProperties GUID=""{A1591282-1198-4647-A2B1-27E5FF5F6F3B}"">
-        <SilverlightProjectProperties>
-          <StartAction>OfflineApplication</StartAction>
-        </SilverlightProjectProperties>
-      </FlavorProperties>
-    </VisualStudio>
-  </ProjectExtensions>
-</Project>
\ No newline at end of file
diff --git a/csharp/csproj_templates/SLTest.targets b/csharp/csproj_templates/SLTest.targets
deleted file mode 100644
index 29da2399c..000000000
--- a/csharp/csproj_templates/SLTest.targets
+++ /dev/null
@@ -1,34 +0,0 @@
-<Project ToolsVersion=""3.5"" DefaultTargets=""Build"" 
-         xmlns=""http://schemas.microsoft.com/developer/msbuild/2003""
-         xmlns:cs=""urn:schemas-csharp-project:template"">
-
-  <PropertyGroup>
-    <SilverlightApplication>true</SilverlightApplication>
-    <XapOutputs>true</XapOutputs>
-    <GenerateSilverlightManifest>true</GenerateSilverlightManifest>
-    <XapFilename>$(AssemblyName).xap</XapFilename>
-    <SilverlightManifestTemplate>Properties\AppManifest.xml</SilverlightManifestTemplate>
-    <SilverlightAppEntry>$(RootNamespace).App</SilverlightAppEntry>
-    <TestPageFileName>TestPage.html</TestPageFileName>
-    <CreateTestPage>true</CreateTestPage>
-    <SilverlightVersion>$(TargetFrameworkVersion)</SilverlightVersion>
-    <OutOfBrowserSettingsFile>Properties\OutOfBrowserSettings.xml</OutOfBrowserSettingsFile>
-    <EnableOutOfBrowser>true</EnableOutOfBrowser>
-  </PropertyGroup>
-  <ItemGroup>
-    <Reference Include=""System.Windows"" />
-    <Reference Include=""System.Windows.Browser"" />
-  </ItemGroup>
-  <ItemGroup>
-    <Compile Include=""App.xaml.cs"">
-      <DependentUpon>App.xaml</DependentUpon>
-    </Compile>
-    <None Include=""Properties\AppManifest.xml"" />
-    <None Include=""Properties\OutOfBrowserSettings.xml"" />
-    <ApplicationDefinition Include=""App.xaml"">
-      <Generator>MSBuild:Compile</Generator>
-      <SubType>Designer</SubType>
-    </ApplicationDefinition>
-  </ItemGroup>
-  
-</Project>
\ No newline at end of file
diff --git a/csharp/protos/benchmarks/google_size.proto b/csharp/protos/benchmarks/google_size.proto
deleted file mode 100644
index 1442ca237..000000000
--- a/csharp/protos/benchmarks/google_size.proto
+++ /dev/null
@@ -1,140 +0,0 @@
-import ""google/protobuf/csharp_options.proto"";
-option (google.protobuf.csharp_file_options).namespace = ""Google.ProtocolBuffers.ProtoBench"";
-option (google.protobuf.csharp_file_options).umbrella_classname = ""GoogleSizeProtoFile"";
-
-package benchmarks;
-
-option java_outer_classname = ""GoogleSize"";
-option optimize_for = CODE_SIZE;
-
-message SizeMessage1 {
-  required string field1 = 1;
-  optional string field9 = 9;
-  optional string field18 = 18;
-  optional bool field80 = 80 [default=false];
-  optional bool field81 = 81 [default=true];
-  required int32 field2 = 2;
-  required int32 field3 = 3;
-  optional int32 field280 = 280;
-  optional int32 field6 = 6 [default=0];
-  optional int64 field22 = 22;
-  optional string field4 = 4;
-  repeated fixed64 field5 = 5;
-  optional bool field59 = 59 [default=false];
-  optional string field7 = 7;
-  optional int32 field16 = 16;
-  optional int32 field130 = 130 [default=0];
-  optional bool field12 = 12 [default=true];
-  optional bool field17 = 17 [default=true];
-  optional bool field13 = 13 [default=true];
-  optional bool field14 = 14 [default=true];
-  optional int32 field104 = 104 [default=0];
-  optional int32 field100 = 100 [default=0];
-  optional int32 field101 = 101 [default=0];
-  optional string field102 = 102;
-  optional string field103 = 103;
-  optional int32 field29 = 29 [default=0];
-  optional bool field30 = 30 [default=false];
-  optional int32 field60 = 60 [default=-1];
-  optional int32 field271 = 271 [default=-1];
-  optional int32 field272 = 272 [default=-1];
-  optional int32 field150 = 150;
-  optional int32 field23 = 23 [default=0];
-  optional bool field24 = 24 [default=false];
-  optional int32 field25 = 25 [default=0];
-  optional SizeMessage1SubMessage field15 = 15;
-  optional bool field78 = 78;
-  optional int32 field67 = 67 [default=0];
-  optional int32 field68 = 68;
-  optional int32 field128 = 128 [default=0];
-  optional string field129 = 129 [default=""xxxxxxxxxxxxxxxxxxxxx""];
-  optional int32 field131 = 131 [default=0];
-}
-
-message SizeMessage1SubMessage {
-  optional int32 field1 = 1 [default=0];
-  optional int32 field2 = 2 [default=0];
-  optional int32 field3 = 3 [default=0];
-  optional string field15 = 15;
-  optional bool field12 = 12 [default=true];
-  optional int64 field13 = 13;
-  optional int64 field14 = 14;
-  optional int32 field16 = 16;
-  optional int32 field19 = 19 [default=2];
-  optional bool field20  = 20 [default=true];
-  optional bool field28 = 28 [default=true];
-  optional fixed64 field21 = 21;
-  optional int32 field22 = 22;
-  optional bool field23 = 23 [ default=false ];
-  optional bool field206 = 206 [default=false];
-  optional fixed32 field203 = 203;
-  optional int32 field204 = 204;
-  optional string field205 = 205;
-  optional uint64 field207 = 207;
-  optional uint64 field300 = 300;
-}
-
-message SizeMessage2 {
-  optional string field1 = 1;
-  optional int64 field3 = 3;
-  optional int64 field4 = 4;
-  optional int64 field30 = 30;
-  optional bool field75  = 75 [default=false];
-  optional string field6 = 6;
-  optional bytes field2 = 2;
-  optional int32 field21 = 21 [default=0];
-  optional int32 field71 = 71;
-  optional float field25 = 25;
-  optional int32 field109 = 109 [default=0];
-  optional int32 field210 = 210 [default=0];
-  optional int32 field211 = 211 [default=0];
-  optional int32 field212 = 212 [default=0];
-  optional int32 field213 = 213 [default=0];
-  optional int32 field216 = 216 [default=0];
-  optional int32 field217 = 217 [default=0];
-  optional int32 field218 = 218 [default=0];
-  optional int32 field220 = 220 [default=0];
-  optional int32 field221 = 221 [default=0];
-  optional float field222 = 222 [default=0.0];
-  optional int32 field63 = 63;
-
-  repeated group Group1 = 10 {
-    required float field11 = 11;
-    optional float field26 = 26;
-    optional string field12 = 12;
-    optional string field13 = 13;
-    repeated string field14 = 14;
-    required uint64 field15 = 15;
-    optional int32 field5 = 5;
-    optional string field27 = 27;
-    optional int32 field28 = 28;
-    optional string field29 = 29;
-    optional string field16 = 16;
-    repeated string field22 = 22;
-    repeated int32 field73 = 73;
-    optional int32 field20 = 20 [default=0];
-    optional string field24 = 24;
-    optional SizeMessage2GroupedMessage field31 = 31;
-  }
-  repeated string field128 = 128;
-  optional int64 field131 = 131;
-  repeated string field127 = 127;
-  optional int32 field129 = 129;
-  repeated int64 field130 = 130;
-  optional bool field205 = 205 [default=false];
-  optional bool field206 = 206 [default=false];
-}
-
-message SizeMessage2GroupedMessage {
-  optional float field1 = 1;
-  optional float field2 = 2;
-  optional float field3 = 3 [default=0.0];
-  optional bool field4 = 4;
-  optional bool field5 = 5;
-  optional bool field6 = 6 [default=true];
-  optional bool field7 = 7 [default=false];
-  optional float field8 = 8;
-  optional bool field9 = 9;
-  optional float field10 = 10;
-  optional int64 field11 = 11;
-}
diff --git a/csharp/protos/benchmarks/google_speed.proto b/csharp/protos/benchmarks/google_speed.proto
deleted file mode 100644
index 269eba809..000000000
--- a/csharp/protos/benchmarks/google_speed.proto
+++ /dev/null
@@ -1,140 +0,0 @@
-import ""google/protobuf/csharp_options.proto"";
-option (google.protobuf.csharp_file_options).namespace = ""Google.ProtocolBuffers.ProtoBench"";
-option (google.protobuf.csharp_file_options).umbrella_classname = ""GoogleSpeedProtoFile"";
-
-package benchmarks;
-
-option java_outer_classname = ""GoogleSpeed"";
-option optimize_for = SPEED;
-
-message SpeedMessage1 {
-  required string field1 = 1;
-  optional string field9 = 9;
-  optional string field18 = 18;
-  optional bool field80 = 80 [default=false];
-  optional bool field81 = 81 [default=true];
-  required int32 field2 = 2;
-  required int32 field3 = 3;
-  optional int32 field280 = 280;
-  optional int32 field6 = 6 [default=0];
-  optional int64 field22 = 22;
-  optional string field4 = 4;
-  repeated fixed64 field5 = 5;
-  optional bool field59 = 59 [default=false];
-  optional string field7 = 7;
-  optional int32 field16 = 16;
-  optional int32 field130 = 130 [default=0];
-  optional bool field12 = 12 [default=true];
-  optional bool field17 = 17 [default=true];
-  optional bool field13 = 13 [default=true];
-  optional bool field14 = 14 [default=true];
-  optional int32 field104 = 104 [default=0];
-  optional int32 field100 = 100 [default=0];
-  optional int32 field101 = 101 [default=0];
-  optional string field102 = 102;
-  optional string field103 = 103;
-  optional int32 field29 = 29 [default=0];
-  optional bool field30 = 30 [default=false];
-  optional int32 field60 = 60 [default=-1];
-  optional int32 field271 = 271 [default=-1];
-  optional int32 field272 = 272 [default=-1];
-  optional int32 field150 = 150;
-  optional int32 field23 = 23 [default=0];
-  optional bool field24 = 24 [default=false];
-  optional int32 field25 = 25 [default=0];
-  optional SpeedMessage1SubMessage field15 = 15;
-  optional bool field78 = 78;
-  optional int32 field67 = 67 [default=0];
-  optional int32 field68 = 68;
-  optional int32 field128 = 128 [default=0];
-  optional string field129 = 129 [default=""xxxxxxxxxxxxxxxxxxxxx""];
-  optional int32 field131 = 131 [default=0];
-}
-
-message SpeedMessage1SubMessage {
-  optional int32 field1 = 1 [default=0];
-  optional int32 field2 = 2 [default=0];
-  optional int32 field3 = 3 [default=0];
-  optional string field15 = 15;
-  optional bool field12 = 12 [default=true];
-  optional int64 field13 = 13;
-  optional int64 field14 = 14;
-  optional int32 field16 = 16;
-  optional int32 field19 = 19 [default=2];
-  optional bool field20  = 20 [default=true];
-  optional bool field28 = 28 [default=true];
-  optional fixed64 field21 = 21;
-  optional int32 field22 = 22;
-  optional bool field23 = 23 [ default=false ];
-  optional bool field206 = 206 [default=false];
-  optional fixed32 field203 = 203;
-  optional int32 field204 = 204;
-  optional string field205 = 205;
-  optional uint64 field207 = 207;
-  optional uint64 field300 = 300;
-}
-
-message SpeedMessage2 {
-  optional string field1 = 1;
-  optional int64 field3 = 3;
-  optional int64 field4 = 4;
-  optional int64 field30 = 30;
-  optional bool field75  = 75 [default=false];
-  optional string field6 = 6;
-  optional bytes field2 = 2;
-  optional int32 field21 = 21 [default=0];
-  optional int32 field71 = 71;
-  optional float field25 = 25;
-  optional int32 field109 = 109 [default=0];
-  optional int32 field210 = 210 [default=0];
-  optional int32 field211 = 211 [default=0];
-  optional int32 field212 = 212 [default=0];
-  optional int32 field213 = 213 [default=0];
-  optional int32 field216 = 216 [default=0];
-  optional int32 field217 = 217 [default=0];
-  optional int32 field218 = 218 [default=0];
-  optional int32 field220 = 220 [default=0];
-  optional int32 field221 = 221 [default=0];
-  optional float field222 = 222 [default=0.0];
-  optional int32 field63 = 63;
-
-  repeated group Group1 = 10 {
-    required float field11 = 11;
-    optional float field26 = 26;
-    optional string field12 = 12;
-    optional string field13 = 13;
-    repeated string field14 = 14;
-    required uint64 field15 = 15;
-    optional int32 field5 = 5;
-    optional string field27 = 27;
-    optional int32 field28 = 28;
-    optional string field29 = 29;
-    optional string field16 = 16;
-    repeated string field22 = 22;
-    repeated int32 field73 = 73;
-    optional int32 field20 = 20 [default=0];
-    optional string field24 = 24;
-    optional SpeedMessage2GroupedMessage field31 = 31;
-  }
-  repeated string field128 = 128;
-  optional int64 field131 = 131;
-  repeated string field127 = 127;
-  optional int32 field129 = 129;
-  repeated int64 field130 = 130;
-  optional bool field205 = 205 [default=false];
-  optional bool field206 = 206 [default=false];
-}
-
-message SpeedMessage2GroupedMessage {
-  optional float field1 = 1;
-  optional float field2 = 2;
-  optional float field3 = 3 [default=0.0];
-  optional bool field4 = 4;
-  optional bool field5 = 5;
-  optional bool field6 = 6 [default=true];
-  optional bool field7 = 7 [default=false];
-  optional float field8 = 8;
-  optional bool field9 = 9;
-  optional float field10 = 10;
-  optional int64 field11 = 11;
-}
diff --git a/csharp/protos/google/protobuf/compiler/plugin.proto b/csharp/protos/google/protobuf/compiler/plugin.proto
deleted file mode 100644
index 866fba118..000000000
--- a/csharp/protos/google/protobuf/compiler/plugin.proto
+++ /dev/null
@@ -1,147 +0,0 @@
-// Protocol Buffers - Google's data interchange format
-// Copyright 2008 Google Inc.  All rights reserved.
-// http://code.google.com/p/protobuf/
-//
-// Redistribution and use in source and binary forms, with or without
-// modification, are permitted provided that the following conditions are
-// met:
-//
-//     * Redistributions of source code must retain the above copyright
-// notice, this list of conditions and the following disclaimer.
-//     * Redistributions in binary form must reproduce the above
-// copyright notice, this list of conditions and the following disclaimer
-// in the documentation and/or other materials provided with the
-// distribution.
-//     * Neither the name of Google Inc. nor the names of its
-// contributors may be used to endorse or promote products derived from
-// this software without specific prior written permission.
-//
-// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-// ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
-// Author: kenton@google.com (Kenton Varda)
-//
-// WARNING:  The plugin interface is currently EXPERIMENTAL and is subject to
-//   change.
-//
-// protoc (aka the Protocol Compiler) can be extended via plugins.  A plugin is
-// just a program that reads a CodeGeneratorRequest from stdin and writes a
-// CodeGeneratorResponse to stdout.
-//
-// Plugins written using C++ can use google/protobuf/compiler/plugin.h instead
-// of dealing with the raw protocol defined here.
-//
-// A plugin executable needs only to be placed somewhere in the path.  The
-// plugin should be named ""protoc-gen-$NAME"", and will then be used when the
-// flag ""--${NAME}_out"" is passed to protoc.
-
-package google.protobuf.compiler;
-option java_package = ""com.google.protobuf.compiler"";
-option java_outer_classname = ""PluginProtos"";
-
-import ""google/protobuf/descriptor.proto"";
-
-// An encoded CodeGeneratorRequest is written to the plugin's stdin.
-message CodeGeneratorRequest {
-  // The .proto files that were explicitly listed on the command-line.  The
-  // code generator should generate code only for these files.  Each file's
-  // descriptor will be included in proto_file, below.
-  repeated string file_to_generate = 1;
-
-  // The generator parameter passed on the command-line.
-  optional string parameter = 2;
-
-  // FileDescriptorProtos for all files in files_to_generate and everything
-  // they import.  The files will appear in topological order, so each file
-  // appears before any file that imports it.
-  //
-  // protoc guarantees that all proto_files will be written after
-  // the fields above, even though this is not technically guaranteed by the
-  // protobuf wire format.  This theoretically could allow a plugin to stream
-  // in the FileDescriptorProtos and handle them one by one rather than read
-  // the entire set into memory at once.  However, as of this writing, this
-  // is not similarly optimized on protoc's end -- it will store all fields in
-  // memory at once before sending them to the plugin.
-  repeated FileDescriptorProto proto_file = 15;
-}
-
-// The plugin writes an encoded CodeGeneratorResponse to stdout.
-message CodeGeneratorResponse {
-  // Error message.  If non-empty, code generation failed.  The plugin process
-  // should exit with status code zero even if it reports an error in this way.
-  //
-  // This should be used to indicate errors in .proto files which prevent the
-  // code generator from generating correct code.  Errors which indicate a
-  // problem in protoc itself -- such as the input CodeGeneratorRequest being
-  // unparseable -- should be reported by writing a message to stderr and
-  // exiting with a non-zero status code.
-  optional string error = 1;
-
-  // Represents a single generated file.
-  message File {
-    // The file name, relative to the output directory.  The name must not
-    // contain ""."" or "".."" components and must be relative, not be absolute (so,
-    // the file cannot lie outside the output directory).  ""/"" must be used as
-    // the path separator, not ""\"".
-    //
-    // If the name is omitted, the content will be appended to the previous
-    // file.  This allows the generator to break large files into small chunks,
-    // and allows the generated text to be streamed back to protoc so that large
-    // files need not reside completely in memory at one time.  Note that as of
-    // this writing protoc does not optimize for this -- it will read the entire
-    // CodeGeneratorResponse before writing files to disk.
-    optional string name = 1;
-
-    // If non-empty, indicates that the named file should already exist, and the
-    // content here is to be inserted into that file at a defined insertion
-    // point.  This feature allows a code generator to extend the output
-    // produced by another code generator.  The original generator may provide
-    // insertion points by placing special annotations in the file that look
-    // like:
-    //   @@protoc_insertion_point(NAME)
-    // The annotation can have arbitrary text before and after it on the line,
-    // which allows it to be placed in a comment.  NAME should be replaced with
-    // an identifier naming the point -- this is what other generators will use
-    // as the insertion_point.  Code inserted at this point will be placed
-    // immediately above the line containing the insertion point (thus multiple
-    // insertions to the same point will come out in the order they were added).
-    // The double-@ is intended to make it unlikely that the generated code
-    // could contain things that look like insertion points by accident.
-    //
-    // For example, the C++ code generator places the following line in the
-    // .pb.h files that it generates:
-    //   // @@protoc_insertion_point(namespace_scope)
-    // This line appears within the scope of the file's package namespace, but
-    // outside of any particular class.  Another plugin can then specify the
-    // insertion_point ""namespace_scope"" to generate additional classes or
-    // other declarations that should be placed in this scope.
-    //
-    // Note that if the line containing the insertion point begins with
-    // whitespace, the same whitespace will be added to every line of the
-    // inserted text.  This is useful for languages like Python, where
-    // indentation matters.  In these languages, the insertion point comment
-    // should be indented the same amount as any inserted code will need to be
-    // in order to work correctly in that context.
-    //
-    // The code generator that generates the initial file and the one which
-    // inserts into it must both run as part of a single invocation of protoc.
-    // Code generators are executed in the order in which they appear on the
-    // command line.
-    //
-    // If |insertion_point| is present, |name| must also be present.
-    optional string insertion_point = 2;
-
-    // The file contents.
-    optional string content = 15;
-  }
-  repeated File file = 15;
-}
diff --git a/csharp/protos/google/protobuf/csharp_options.proto b/csharp/protos/google/protobuf/csharp_options.proto
deleted file mode 100644
index f09b96aaf..000000000
--- a/csharp/protos/google/protobuf/csharp_options.proto
+++ /dev/null
@@ -1,115 +0,0 @@
-// Extra options for C# generator
-
-import ""google/protobuf/descriptor.proto"";
-
-package google.protobuf;
-
-message CSharpFileOptions {
-
-  // Namespace for generated classes; defaults to the package.
-  optional string namespace = 1;
-  
-  // Name of the ""umbrella"" class used for metadata about all
-  // the messages within this file. Default is based on the name
-  // of the file.
-  optional string umbrella_classname = 2;
-  
-  // Whether classes should be public (true) or internal (false)
-  optional bool public_classes = 3 [default = true];
-
-  // Whether to generate a single file for everything within the
-  // .proto file (false), or one file per message (true).
-  // This option is not currently honored; please log a feature
-  // request if you really want it.
-  optional bool multiple_files = 4;
-
-  // Whether to nest messages within a single umbrella class (true)
-  // or create the umbrella class as a peer, with messages as
-  // top-level classes in the namespace (false)
-  optional bool nest_classes = 5;
-  
-  // Generate appropriate support for Code Contracts
-  // (Ongoing; support should improve over time)
-  optional bool code_contracts = 6;
-  
-  // Create subdirectories for namespaces, e.g. namespace ""Foo.Bar""
-  // would generate files within [output directory]/Foo/Bar
-  optional bool expand_namespace_directories = 7;
-
-  // Generate attributes indicating non-CLS-compliance
-  optional bool cls_compliance = 8 [default = true];
-  
-  // Generate messages/builders with the [Serializable] attribute
-  optional bool add_serializable = 9 [default = false];
-  
-  // Generates a private ctor for Message types
-  optional bool generate_private_ctor = 10 [default = true];
-
-  // The extension that should be appended to the umbrella_classname when creating files.
-  optional string file_extension = 221 [default = "".cs""];
-  
-  // A nested namespace for the umbrella class.  Helpful for name collisions caused by 
-  // umbrella_classname conflicting with an existing type.  This will be automatically
-  // set to 'Proto' if a collision is detected with types being generated.  This value
-  // is ignored when nest_classes == true
-  optional string umbrella_namespace = 222;
-  
-  // The output path for the source file(s) generated
-  optional string output_directory = 223 [default = "".""];
-
-  // Will ignore the type generations and remove dependencies for the descriptor proto
-  // files that declare their package to be ""google.protobuf""
-  optional bool ignore_google_protobuf = 224 [default = false];
-
-  // Controls how services are generated, GENERIC is the deprecated original implementation
-  // INTERFACE generates service interfaces only, RPCINTEROP generates interfaces and 
-  // implementations using the included Windows RPC interop libarary.
-  optional CSharpServiceType service_generator_type = 225 [default = NONE];
-  
-  // Used to add the System.Runtime.CompilerServices.CompilerGeneratedAttribute and 
-  // System.CodeDom.Compiler.GeneratedCodeAttribute attributes to generated code.
-  optional bool generated_code_attributes = 226 [default = false];
-}
-
-enum CSharpServiceType {
-  // Services are ignored by the generator
-  NONE = 0;
-  // Generates the original Java generic service implementations
-  GENERIC = 1;
-  // Generates an interface for the service and nothing else
-  INTERFACE = 2;
-  // Generates an interface for the service and client/server wrappers for the interface
-  IRPCDISPATCH = 3;
-}
-
-extend FileOptions {
-  optional CSharpFileOptions csharp_file_options = 1000;
-}
-
-extend FieldOptions {
-  optional CSharpFieldOptions csharp_field_options = 1000;
-}
-
-message CSharpFieldOptions {
-  // Provides the ability to override the name of the property
-  // generated for this field. This is applied to all properties
-  // and methods to do with this field, including HasFoo, FooCount,
-  // FooList etc.
-  optional string property_name = 1;
-}
-
-message CSharpServiceOptions {
-  optional string interface_id = 1;
-}
-
-extend ServiceOptions {
-  optional CSharpServiceOptions csharp_service_options = 1000;
-}
-
-message CSharpMethodOptions {
-  optional int32 dispatch_id = 1;
-}
-
-extend MethodOptions {
-  optional CSharpMethodOptions csharp_method_options = 1000;
-}
\ No newline at end of file
diff --git a/csharp/protos/google/protobuf/descriptor.proto b/csharp/protos/google/protobuf/descriptor.proto
deleted file mode 100644
index 233f87941..000000000
--- a/csharp/protos/google/protobuf/descriptor.proto
+++ /dev/null
@@ -1,533 +0,0 @@
-// Protocol Buffers - Google's data interchange format
-// Copyright 2008 Google Inc.  All rights reserved.
-// http://code.google.com/p/protobuf/
-//
-// Redistribution and use in source and binary forms, with or without
-// modification, are permitted provided that the following conditions are
-// met:
-//
-//     * Redistributions of source code must retain the above copyright
-// notice, this list of conditions and the following disclaimer.
-//     * Redistributions in binary form must reproduce the above
-// copyright notice, this list of conditions and the following disclaimer
-// in the documentation and/or other materials provided with the
-// distribution.
-//     * Neither the name of Google Inc. nor the names of its
-// contributors may be used to endorse or promote products derived from
-// this software without specific prior written permission.
-//
-// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-// ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
-// Author: kenton@google.com (Kenton Varda)
-//  Based on original Protocol Buffers design by
-//  Sanjay Ghemawat, Jeff Dean, and others.
-//
-// The messages in this file describe the definitions found in .proto files.
-// A valid .proto file can be translated directly to a FileDescriptorProto
-// without any other information (e.g. without reading its imports).
-
-
-
-package google.protobuf;
-option java_package = ""com.google.protobuf"";
-option java_outer_classname = ""DescriptorProtos"";
-
-// descriptor.proto must be optimized for speed because reflection-based
-// algorithms don't work during bootstrapping.
-option optimize_for = SPEED;
-
-// The protocol compiler can output a FileDescriptorSet containing the .proto
-// files it parses.
-message FileDescriptorSet {
-  repeated FileDescriptorProto file = 1;
-}
-
-// Describes a complete .proto file.
-message FileDescriptorProto {
-  optional string name = 1;       // file name, relative to root of source tree
-  optional string package = 2;    // e.g. ""foo"", ""foo.bar"", etc.
-
-  // Names of files imported by this file.
-  repeated string dependency = 3;
-
-  // All top-level definitions in this file.
-  repeated DescriptorProto message_type = 4;
-  repeated EnumDescriptorProto enum_type = 5;
-  repeated ServiceDescriptorProto service = 6;
-  repeated FieldDescriptorProto extension = 7;
-
-  optional FileOptions options = 8;
-
-  // This field contains optional information about the original source code.
-  // You may safely remove this entire field whithout harming runtime
-  // functionality of the descriptors -- the information is needed only by
-  // development tools.
-  optional SourceCodeInfo source_code_info = 9;
-}
-
-// Describes a message type.
-message DescriptorProto {
-  optional string name = 1;
-
-  repeated FieldDescriptorProto field = 2;
-  repeated FieldDescriptorProto extension = 6;
-
-  repeated DescriptorProto nested_type = 3;
-  repeated EnumDescriptorProto enum_type = 4;
-
-  message ExtensionRange {
-    optional int32 start = 1;
-    optional int32 end = 2;
-  }
-  repeated ExtensionRange extension_range = 5;
-
-  optional MessageOptions options = 7;
-}
-
-// Describes a field within a message.
-message FieldDescriptorProto {
-  enum Type {
-    // 0 is reserved for errors.
-    // Order is weird for historical reasons.
-    TYPE_DOUBLE         = 1;
-    TYPE_FLOAT          = 2;
-    TYPE_INT64          = 3;   // Not ZigZag encoded.  Negative numbers
-                               // take 10 bytes.  Use TYPE_SINT64 if negative
-                               // values are likely.
-    TYPE_UINT64         = 4;
-    TYPE_INT32          = 5;   // Not ZigZag encoded.  Negative numbers
-                               // take 10 bytes.  Use TYPE_SINT32 if negative
-                               // values are likely.
-    TYPE_FIXED64        = 6;
-    TYPE_FIXED32        = 7;
-    TYPE_BOOL           = 8;
-    TYPE_STRING         = 9;
-    TYPE_GROUP          = 10;  // Tag-delimited aggregate.
-    TYPE_MESSAGE        = 11;  // Length-delimited aggregate.
-
-    // New in version 2.
-    TYPE_BYTES          = 12;
-    TYPE_UINT32         = 13;
-    TYPE_ENUM           = 14;
-    TYPE_SFIXED32       = 15;
-    TYPE_SFIXED64       = 16;
-    TYPE_SINT32         = 17;  // Uses ZigZag encoding.
-    TYPE_SINT64         = 18;  // Uses ZigZag encoding.
-  };
-
-  enum Label {
-    // 0 is reserved for errors
-    LABEL_OPTIONAL      = 1;
-    LABEL_REQUIRED      = 2;
-    LABEL_REPEATED      = 3;
-    // TODO(sanjay): Should we add LABEL_MAP?
-  };
-
-  optional string name = 1;
-  optional int32 number = 3;
-  optional Label label = 4;
-
-  // If type_name is set, this need not be set.  If both this and type_name
-  // are set, this must be either TYPE_ENUM or TYPE_MESSAGE.
-  optional Type type = 5;
-
-  // For message and enum types, this is the name of the type.  If the name
-  // starts with a '.', it is fully-qualified.  Otherwise, C++-like scoping
-  // rules are used to find the type (i.e. first the nested types within this
-  // message are searched, then within the parent, on up to the root
-  // namespace).
-  optional string type_name = 6;
-
-  // For extensions, this is the name of the type being extended.  It is
-  // resolved in the same manner as type_name.
-  optional string extendee = 2;
-
-  // For numeric types, contains the original text representation of the value.
-  // For booleans, ""true"" or ""false"".
-  // For strings, contains the default text contents (not escaped in any way).
-  // For bytes, contains the C escaped value.  All bytes >= 128 are escaped.
-  // TODO(kenton):  Base-64 encode?
-  optional string default_value = 7;
-
-  optional FieldOptions options = 8;
-}
-
-// Describes an enum type.
-message EnumDescriptorProto {
-  optional string name = 1;
-
-  repeated EnumValueDescriptorProto value = 2;
-
-  optional EnumOptions options = 3;
-}
-
-// Describes a value within an enum.
-message EnumValueDescriptorProto {
-  optional string name = 1;
-  optional int32 number = 2;
-
-  optional EnumValueOptions options = 3;
-}
-
-// Describes a service.
-message ServiceDescriptorProto {
-  optional string name = 1;
-  repeated MethodDescriptorProto method = 2;
-
-  optional ServiceOptions options = 3;
-}
-
-// Describes a method of a service.
-message MethodDescriptorProto {
-  optional string name = 1;
-
-  // Input and output type names.  These are resolved in the same way as
-  // FieldDescriptorProto.type_name, but must refer to a message type.
-  optional string input_type = 2;
-  optional string output_type = 3;
-
-  optional MethodOptions options = 4;
-}
-
-// ===================================================================
-// Options
-
-// Each of the definitions above may have ""options"" attached.  These are
-// just annotations which may cause code to be generated slightly differently
-// or may contain hints for code that manipulates protocol messages.
-//
-// Clients may define custom options as extensions of the *Options messages.
-// These extensions may not yet be known at parsing time, so the parser cannot
-// store the values in them.  Instead it stores them in a field in the *Options
-// message called uninterpreted_option. This field must have the same name
-// across all *Options messages. We then use this field to populate the
-// extensions when we build a descriptor, at which point all protos have been
-// parsed and so all extensions are known.
-//
-// Extension numbers for custom options may be chosen as follows:
-// * For options which will only be used within a single application or
-//   organization, or for experimental options, use field numbers 50000
-//   through 99999.  It is up to you to ensure that you do not use the
-//   same number for multiple options.
-// * For options which will be published and used publicly by multiple
-//   independent entities, e-mail kenton@google.com to reserve extension
-//   numbers.  Simply tell me how many you need and I'll send you back a
-//   set of numbers to use -- there's no need to explain how you intend to
-//   use them.  If this turns out to be popular, a web service will be set up
-//   to automatically assign option numbers.
-
-
-message FileOptions {
-
-  // Sets the Java package where classes generated from this .proto will be
-  // placed.  By default, the proto package is used, but this is often
-  // inappropriate because proto packages do not normally start with backwards
-  // domain names.
-  optional string java_package = 1;
-
-
-  // If set, all the classes from the .proto file are wrapped in a single
-  // outer class with the given name.  This applies to both Proto1
-  // (equivalent to the old ""--one_java_file"" option) and Proto2 (where
-  // a .proto always translates to a single class, but you may want to
-  // explicitly choose the class name).
-  optional string java_outer_classname = 8;
-
-  // If set true, then the Java code generator will generate a separate .java
-  // file for each top-level message, enum, and service defined in the .proto
-  // file.  Thus, these types will *not* be nested inside the outer class
-  // named by java_outer_classname.  However, the outer class will still be
-  // generated to contain the file's getDescriptor() method as well as any
-  // top-level extensions defined in the file.
-  optional bool java_multiple_files = 10 [default=false];
-
-  // If set true, then the Java code generator will generate equals() and
-  // hashCode() methods for all messages defined in the .proto file. This is
-  // purely a speed optimization, as the AbstractMessage base class includes
-  // reflection-based implementations of these methods.
-  optional bool java_generate_equals_and_hash = 20 [default=false];
-
-  // Generated classes can be optimized for speed or code size.
-  enum OptimizeMode {
-    SPEED = 1;        // Generate complete code for parsing, serialization,
-                      // etc.
-    CODE_SIZE = 2;    // Use ReflectionOps to implement these methods.
-    LITE_RUNTIME = 3; // Generate code using MessageLite and the lite runtime.
-  }
-  optional OptimizeMode optimize_for = 9 [default=SPEED];
-
-
-
-
-  // Should generic services be generated in each language?  ""Generic"" services
-  // are not specific to any particular RPC system.  They are generated by the
-  // main code generators in each language (without additional plugins).
-  // Generic services were the only kind of service generation supported by
-  // early versions of proto2.
-  //
-  // Generic services are now considered deprecated in favor of using plugins
-  // that generate code specific to your particular RPC system.  Therefore,
-  // these default to false.  Old code which depends on generic services should
-  // explicitly set them to true.
-  optional bool cc_generic_services = 16 [default=false];
-  optional bool java_generic_services = 17 [default=false];
-  optional bool py_generic_services = 18 [default=false];
-
-  // The parser stores options it doesn't recognize here. See above.
-  repeated UninterpretedOption uninterpreted_option = 999;
-
-  // Clients can define custom options in extensions of this message. See above.
-  extensions 1000 to max;
-}
-
-message MessageOptions {
-  // Set true to use the old proto1 MessageSet wire format for extensions.
-  // This is provided for backwards-compatibility with the MessageSet wire
-  // format.  You should not use this for any other reason:  It's less
-  // efficient, has fewer features, and is more complicated.
-  //
-  // The message must be defined exactly as follows:
-  //   message Foo {
-  //     option message_set_wire_format = true;
-  //     extensions 4 to max;
-  //   }
-  // Note that the message cannot have any defined fields; MessageSets only
-  // have extensions.
-  //
-  // All extensions of your type must be singular messages; e.g. they cannot
-  // be int32s, enums, or repeated messages.
-  //
-  // Because this is an option, the above two restrictions are not enforced by
-  // the protocol compiler.
-  optional bool message_set_wire_format = 1 [default=false];
-
-  // Disables the generation of the standard ""descriptor()"" accessor, which can
-  // conflict with a field of the same name.  This is meant to make migration
-  // from proto1 easier; new code should avoid fields named ""descriptor"".
-  optional bool no_standard_descriptor_accessor = 2 [default=false];
-
-  // The parser stores options it doesn't recognize here. See above.
-  repeated UninterpretedOption uninterpreted_option = 999;
-
-  // Clients can define custom options in extensions of this message. See above.
-  extensions 1000 to max;
-}
-
-message FieldOptions {
-  // The ctype option instructs the C++ code generator to use a different
-  // representation of the field than it normally would.  See the specific
-  // options below.  This option is not yet implemented in the open source
-  // release -- sorry, we'll try to include it in a future version!
-  optional CType ctype = 1 [default = STRING];
-  enum CType {
-    // Default mode.
-    STRING = 0;
-
-    CORD = 1;
-
-    STRING_PIECE = 2;
-  }
-  // The packed option can be enabled for repeated primitive fields to enable
-  // a more efficient representation on the wire. Rather than repeatedly
-  // writing the tag and type for each element, the entire array is encoded as
-  // a single length-delimited blob.
-  optional bool packed = 2;
-
-
-  // Is this field deprecated?
-  // Depending on the target platform, this can emit Deprecated annotations
-  // for accessors, or it will be completely ignored; in the very least, this
-  // is a formalization for deprecating fields.
-  optional bool deprecated = 3 [default=false];
-
-  // EXPERIMENTAL.  DO NOT USE.
-  // For ""map"" fields, the name of the field in the enclosed type that
-  // is the key for this map.  For example, suppose we have:
-  //   message Item {
-  //     required string name = 1;
-  //     required string value = 2;
-  //   }
-  //   message Config {
-  //     repeated Item items = 1 [experimental_map_key=""name""];
-  //   }
-  // In this situation, the map key for Item will be set to ""name"".
-  // TODO: Fully-implement this, then remove the ""experimental_"" prefix.
-  optional string experimental_map_key = 9;
-
-  // The parser stores options it doesn't recognize here. See above.
-  repeated UninterpretedOption uninterpreted_option = 999;
-
-  // Clients can define custom options in extensions of this message. See above.
-  extensions 1000 to max;
-}
-
-message EnumOptions {
-
-  // The parser stores options it doesn't recognize here. See above.
-  repeated UninterpretedOption uninterpreted_option = 999;
-
-  // Clients can define custom options in extensions of this message. See above.
-  extensions 1000 to max;
-}
-
-message EnumValueOptions {
-  // The parser stores options it doesn't recognize here. See above.
-  repeated UninterpretedOption uninterpreted_option = 999;
-
-  // Clients can define custom options in extensions of this message. See above.
-  extensions 1000 to max;
-}
-
-message ServiceOptions {
-
-  // Note:  Field numbers 1 through 32 are reserved for Google's internal RPC
-  //   framework.  We apologize for hoarding these numbers to ourselves, but
-  //   we were already using them long before we decided to release Protocol
-  //   Buffers.
-
-  // The parser stores options it doesn't recognize here. See above.
-  repeated UninterpretedOption uninterpreted_option = 999;
-
-  // Clients can define custom options in extensions of this message. See above.
-  extensions 1000 to max;
-}
-
-message MethodOptions {
-
-  // Note:  Field numbers 1 through 32 are reserved for Google's internal RPC
-  //   framework.  We apologize for hoarding these numbers to ourselves, but
-  //   we were already using them long before we decided to release Protocol
-  //   Buffers.
-
-  // The parser stores options it doesn't recognize here. See above.
-  repeated UninterpretedOption uninterpreted_option = 999;
-
-  // Clients can define custom options in extensions of this message. See above.
-  extensions 1000 to max;
-}
-
-// A message representing a option the parser does not recognize. This only
-// appears in options protos created by the compiler::Parser class.
-// DescriptorPool resolves these when building Descriptor objects. Therefore,
-// options protos in descriptor objects (e.g. returned by Descriptor::options(),
-// or produced by Descriptor::CopyTo()) will never have UninterpretedOptions
-// in them.
-message UninterpretedOption {
-  // The name of the uninterpreted option.  Each string represents a segment in
-  // a dot-separated name.  is_extension is true iff a segment represents an
-  // extension (denoted with parentheses in options specs in .proto files).
-  // E.g.,{ [""foo"", false], [""bar.baz"", true], [""qux"", false] } represents
-  // ""foo.(bar.baz).qux"".
-  message NamePart {
-    required string name_part = 1;
-    required bool is_extension = 2;
-  }
-  repeated NamePart name = 2;
-
-  // The value of the uninterpreted option, in whatever type the tokenizer
-  // identified it as during parsing. Exactly one of these should be set.
-  optional string identifier_value = 3;
-  optional uint64 positive_int_value = 4;
-  optional int64 negative_int_value = 5;
-  optional double double_value = 6;
-  optional bytes string_value = 7;
-  optional string aggregate_value = 8;
-}
-
-// ===================================================================
-// Optional source code info
-
-// Encapsulates information about the original source file from which a
-// FileDescriptorProto was generated.
-message SourceCodeInfo {
-  // A Location identifies a piece of source code in a .proto file which
-  // corresponds to a particular definition.  This information is intended
-  // to be useful to IDEs, code indexers, documentation generators, and similar
-  // tools.
-  //
-  // For example, say we have a file like:
-  //   message Foo {
-  //     optional string foo = 1;
-  //   }
-  // Let's look at just the field definition:
-  //   optional string foo = 1;
-  //   ^       ^^     ^^  ^  ^^^
-  //   a       bc     de  f  ghi
-  // We have the following locations:
-  //   span   path               represents
-  //   [a,i)  [ 4, 0, 2, 0 ]     The whole field definition.
-  //   [a,b)  [ 4, 0, 2, 0, 4 ]  The label (optional).
-  //   [c,d)  [ 4, 0, 2, 0, 5 ]  The type (string).
-  //   [e,f)  [ 4, 0, 2, 0, 1 ]  The name (foo).
-  //   [g,h)  [ 4, 0, 2, 0, 3 ]  The number (1).
-  //
-  // Notes:
-  // - A location may refer to a repeated field itself (i.e. not to any
-  //   particular index within it).  This is used whenever a set of elements are
-  //   logically enclosed in a single code segment.  For example, an entire
-  //   extend block (possibly containing multiple extension definitions) will
-  //   have an outer location whose path refers to the ""extensions"" repeated
-  //   field without an index.
-  // - Multiple locations may have the same path.  This happens when a single
-  //   logical declaration is spread out across multiple places.  The most
-  //   obvious example is the ""extend"" block again -- there may be multiple
-  //   extend blocks in the same scope, each of which will have the same path.
-  // - A location's span is not always a subset of its parent's span.  For
-  //   example, the ""extendee"" of an extension declaration appears at the
-  //   beginning of the ""extend"" block and is shared by all extensions within
-  //   the block.
-  // - Just because a location's span is a subset of some other location's span
-  //   does not mean that it is a descendent.  For example, a ""group"" defines
-  //   both a type and a field in a single declaration.  Thus, the locations
-  //   corresponding to the type and field and their components will overlap.
-  // - Code which tries to interpret locations should probably be designed to
-  //   ignore those that it doesn't understand, as more types of locations could
-  //   be recorded in the future.
-  repeated Location location = 1;
-  message Location {
-    // Identifies which part of the FileDescriptorProto was defined at this
-    // location.
-    //
-    // Each element is a field number or an index.  They form a path from
-    // the root FileDescriptorProto to the place where the definition.  For
-    // example, this path:
-    //   [ 4, 3, 2, 7, 1 ]
-    // refers to:
-    //   file.message_type(3)  // 4, 3
-    //       .field(7)         // 2, 7
-    //       .name()           // 1
-    // This is because FileDescriptorProto.message_type has field number 4:
-    //   repeated DescriptorProto message_type = 4;
-    // and DescriptorProto.field has field number 2:
-    //   repeated FieldDescriptorProto field = 2;
-    // and FieldDescriptorProto.name has field number 1:
-    //   optional string name = 1;
-    //
-    // Thus, the above path gives the location of a field name.  If we removed
-    // the last element:
-    //   [ 4, 3, 2, 7 ]
-    // this path refers to the whole field declaration (from the beginning
-    // of the label to the terminating semicolon).
-    repeated int32 path = 1 [packed=true];
-
-    // Always has exactly three or four elements: start line, start column,
-    // end line (optional, otherwise assumed same as start line), end column.
-    // These are packed into a single field for efficiency.  Note that line
-    // and column numbers are zero-based -- typically you will want to add
-    // 1 to each before displaying to a user.
-    repeated int32 span = 2 [packed=true];
-
-    // TODO(kenton):  Record comments appearing before and after the
-    // declaration.
-  }
-}
diff --git a/csharp/protos/google/protobuf/unittest.proto b/csharp/protos/google/protobuf/unittest.proto
deleted file mode 100644
index 7f05cf809..000000000
--- a/csharp/protos/google/protobuf/unittest.proto
+++ /dev/null
@@ -1,636 +0,0 @@
-// Additional options required for C# generation. File from copyright
-// line onwards is as per original distribution.
-import ""google/protobuf/csharp_options.proto"";
-option (google.protobuf.csharp_file_options).namespace = ""Google.ProtocolBuffers.TestProtos"";
-option (google.protobuf.csharp_file_options).umbrella_classname = ""UnitTestProtoFile"";
-
-// Protocol Buffers - Google's data interchange format
-// Copyright 2008 Google Inc.  All rights reserved.
-// http://code.google.com/p/protobuf/
-//
-// Redistribution and use in source and binary forms, with or without
-// modification, are permitted provided that the following conditions are
-// met:
-//
-//     * Redistributions of source code must retain the above copyright
-// notice, this list of conditions and the following disclaimer.
-//     * Redistributions in binary form must reproduce the above
-// copyright notice, this list of conditions and the following disclaimer
-// in the documentation and/or other materials provided with the
-// distribution.
-//     * Neither the name of Google Inc. nor the names of its
-// contributors may be used to endorse or promote products derived from
-// this software without specific prior written permission.
-//
-// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-// ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
-// Author: kenton@google.com (Kenton Varda)
-//  Based on original Protocol Buffers design by
-//  Sanjay Ghemawat, Jeff Dean, and others.
-//
-// A proto file we will use for unit testing.
-
-
-// Some generic_services option(s) added automatically.
-// See:  http://go/proto2-generic-services-default
-option cc_generic_services = true;     // auto-added
-option java_generic_services = true;   // auto-added
-option py_generic_services = true;     // auto-added
-
-import ""google/protobuf/unittest_import.proto"";
-
-// We don't put this in a package within proto2 because we need to make sure
-// that the generated code doesn't depend on being in the proto2 namespace.
-// In test_util.h we do ""using namespace unittest = protobuf_unittest"".
-package protobuf_unittest;
-
-// Protos optimized for SPEED use a strict superset of the generated code
-// of equivalent ones optimized for CODE_SIZE, so we should optimize all our
-// tests for speed unless explicitly testing code size optimization.
-option optimize_for = SPEED;
-
-option java_outer_classname = ""UnittestProto"";
-
-// This proto includes every type of field in both singular and repeated
-// forms.
-message TestAllTypes {
-  message NestedMessage {
-    // The field name ""b"" fails to compile in proto1 because it conflicts with
-    // a local variable named ""b"" in one of the generated methods.  Doh.
-    // This file needs to compile in proto1 to test backwards-compatibility.
-    optional int32 bb = 1;
-  }
-
-  enum NestedEnum {
-    FOO = 1;
-    BAR = 2;
-    BAZ = 3;
-  }
-
-  // Singular
-  optional    int32 optional_int32    =  1;
-  optional    int64 optional_int64    =  2;
-  optional   uint32 optional_uint32   =  3;
-  optional   uint64 optional_uint64   =  4;
-  optional   sint32 optional_sint32   =  5;
-  optional   sint64 optional_sint64   =  6;
-  optional  fixed32 optional_fixed32  =  7;
-  optional  fixed64 optional_fixed64  =  8;
-  optional sfixed32 optional_sfixed32 =  9;
-  optional sfixed64 optional_sfixed64 = 10;
-  optional    float optional_float    = 11;
-  optional   double optional_double   = 12;
-  optional     bool optional_bool     = 13;
-  optional   string optional_string   = 14;
-  optional    bytes optional_bytes    = 15;
-
-  optional group OptionalGroup = 16 {
-    optional int32 a = 17;
-  }
-
-  optional NestedMessage                        optional_nested_message  = 18;
-  optional ForeignMessage                       optional_foreign_message = 19;
-  optional protobuf_unittest_import.ImportMessage optional_import_message  = 20;
-
-  optional NestedEnum                           optional_nested_enum     = 21;
-  optional ForeignEnum                          optional_foreign_enum    = 22;
-  optional protobuf_unittest_import.ImportEnum    optional_import_enum     = 23;
-
-  optional string optional_string_piece = 24 [ctype=STRING_PIECE];
-  optional string optional_cord = 25 [ctype=CORD];
-
-  // Repeated
-  repeated    int32 repeated_int32    = 31;
-  repeated    int64 repeated_int64    = 32;
-  repeated   uint32 repeated_uint32   = 33;
-  repeated   uint64 repeated_uint64   = 34;
-  repeated   sint32 repeated_sint32   = 35;
-  repeated   sint64 repeated_sint64   = 36;
-  repeated  fixed32 repeated_fixed32  = 37;
-  repeated  fixed64 repeated_fixed64  = 38;
-  repeated sfixed32 repeated_sfixed32 = 39;
-  repeated sfixed64 repeated_sfixed64 = 40;
-  repeated    float repeated_float    = 41;
-  repeated   double repeated_double   = 42;
-  repeated     bool repeated_bool     = 43;
-  repeated   string repeated_string   = 44;
-  repeated    bytes repeated_bytes    = 45;
-
-  repeated group RepeatedGroup = 46 {
-    optional int32 a = 47;
-  }
-
-  repeated NestedMessage                        repeated_nested_message  = 48;
-  repeated ForeignMessage                       repeated_foreign_message = 49;
-  repeated protobuf_unittest_import.ImportMessage repeated_import_message  = 50;
-
-  repeated NestedEnum                           repeated_nested_enum     = 51;
-  repeated ForeignEnum                          repeated_foreign_enum    = 52;
-  repeated protobuf_unittest_import.ImportEnum    repeated_import_enum     = 53;
-
-  repeated string repeated_string_piece = 54 [ctype=STRING_PIECE];
-  repeated string repeated_cord = 55 [ctype=CORD];
-
-  // Singular with defaults
-  optional    int32 default_int32    = 61 [default =  41    ];
-  optional    int64 default_int64    = 62 [default =  42    ];
-  optional   uint32 default_uint32   = 63 [default =  43    ];
-  optional   uint64 default_uint64   = 64 [default =  44    ];
-  optional   sint32 default_sint32   = 65 [default = -45    ];
-  optional   sint64 default_sint64   = 66 [default =  46    ];
-  optional  fixed32 default_fixed32  = 67 [default =  47    ];
-  optional  fixed64 default_fixed64  = 68 [default =  48    ];
-  optional sfixed32 default_sfixed32 = 69 [default =  49    ];
-  optional sfixed64 default_sfixed64 = 70 [default = -50    ];
-  optional    float default_float    = 71 [default =  51.5  ];
-  optional   double default_double   = 72 [default =  52e3  ];
-  optional     bool default_bool     = 73 [default = true   ];
-  optional   string default_string   = 74 [default = ""hello""];
-  optional    bytes default_bytes    = 75 [default = ""world""];
-
-  optional NestedEnum  default_nested_enum  = 81 [default = BAR        ];
-  optional ForeignEnum default_foreign_enum = 82 [default = FOREIGN_BAR];
-  optional protobuf_unittest_import.ImportEnum
-      default_import_enum = 83 [default = IMPORT_BAR];
-
-  optional string default_string_piece = 84 [ctype=STRING_PIECE,default=""abc""];
-  optional string default_cord = 85 [ctype=CORD,default=""123""];
-}
-
-message TestDeprecatedFields {
-  optional int32 deprecated_int32 = 1 [deprecated=true];
-}
-
-// Define these after TestAllTypes to make sure the compiler can handle
-// that.
-message ForeignMessage {
-  optional int32 c = 1;
-}
-
-enum ForeignEnum {
-  FOREIGN_FOO = 4;
-  FOREIGN_BAR = 5;
-  FOREIGN_BAZ = 6;
-}
-
-message TestAllExtensions {
-  extensions 1 to max;
-}
-
-extend TestAllExtensions {
-  // Singular
-  optional    int32 optional_int32_extension    =  1;
-  optional    int64 optional_int64_extension    =  2;
-  optional   uint32 optional_uint32_extension   =  3;
-  optional   uint64 optional_uint64_extension   =  4;
-  optional   sint32 optional_sint32_extension   =  5;
-  optional   sint64 optional_sint64_extension   =  6;
-  optional  fixed32 optional_fixed32_extension  =  7;
-  optional  fixed64 optional_fixed64_extension  =  8;
-  optional sfixed32 optional_sfixed32_extension =  9;
-  optional sfixed64 optional_sfixed64_extension = 10;
-  optional    float optional_float_extension    = 11;
-  optional   double optional_double_extension   = 12;
-  optional     bool optional_bool_extension     = 13;
-  optional   string optional_string_extension   = 14;
-  optional    bytes optional_bytes_extension    = 15;
-
-  optional group OptionalGroup_extension = 16 {
-    optional int32 a = 17;
-  }
-
-  optional TestAllTypes.NestedMessage optional_nested_message_extension = 18;
-  optional ForeignMessage optional_foreign_message_extension = 19;
-  optional protobuf_unittest_import.ImportMessage
-    optional_import_message_extension = 20;
-
-  optional TestAllTypes.NestedEnum optional_nested_enum_extension = 21;
-  optional ForeignEnum optional_foreign_enum_extension = 22;
-  optional protobuf_unittest_import.ImportEnum
-    optional_import_enum_extension = 23;
-
-  optional string optional_string_piece_extension = 24 [ctype=STRING_PIECE];
-  optional string optional_cord_extension = 25 [ctype=CORD];
-
-  // Repeated
-  repeated    int32 repeated_int32_extension    = 31;
-  repeated    int64 repeated_int64_extension    = 32;
-  repeated   uint32 repeated_uint32_extension   = 33;
-  repeated   uint64 repeated_uint64_extension   = 34;
-  repeated   sint32 repeated_sint32_extension   = 35;
-  repeated   sint64 repeated_sint64_extension   = 36;
-  repeated  fixed32 repeated_fixed32_extension  = 37;
-  repeated  fixed64 repeated_fixed64_extension  = 38;
-  repeated sfixed32 repeated_sfixed32_extension = 39;
-  repeated sfixed64 repeated_sfixed64_extension = 40;
-  repeated    float repeated_float_extension    = 41;
-  repeated   double repeated_double_extension   = 42;
-  repeated     bool repeated_bool_extension     = 43;
-  repeated   string repeated_string_extension   = 44;
-  repeated    bytes repeated_bytes_extension    = 45;
-
-  repeated group RepeatedGroup_extension = 46 {
-    optional int32 a = 47;
-  }
-
-  repeated TestAllTypes.NestedMessage repeated_nested_message_extension = 48;
-  repeated ForeignMessage repeated_foreign_message_extension = 49;
-  repeated protobuf_unittest_import.ImportMessage
-    repeated_import_message_extension = 50;
-
-  repeated TestAllTypes.NestedEnum repeated_nested_enum_extension = 51;
-  repeated ForeignEnum repeated_foreign_enum_extension = 52;
-  repeated protobuf_unittest_import.ImportEnum
-    repeated_import_enum_extension = 53;
-
-  repeated string repeated_string_piece_extension = 54 [ctype=STRING_PIECE];
-  repeated string repeated_cord_extension = 55 [ctype=CORD];
-
-  // Singular with defaults
-  optional    int32 default_int32_extension    = 61 [default =  41    ];
-  optional    int64 default_int64_extension    = 62 [default =  42    ];
-  optional   uint32 default_uint32_extension   = 63 [default =  43    ];
-  optional   uint64 default_uint64_extension   = 64 [default =  44    ];
-  optional   sint32 default_sint32_extension   = 65 [default = -45    ];
-  optional   sint64 default_sint64_extension   = 66 [default =  46    ];
-  optional  fixed32 default_fixed32_extension  = 67 [default =  47    ];
-  optional  fixed64 default_fixed64_extension  = 68 [default =  48    ];
-  optional sfixed32 default_sfixed32_extension = 69 [default =  49    ];
-  optional sfixed64 default_sfixed64_extension = 70 [default = -50    ];
-  optional    float default_float_extension    = 71 [default =  51.5  ];
-  optional   double default_double_extension   = 72 [default =  52e3  ];
-  optional     bool default_bool_extension     = 73 [default = true   ];
-  optional   string default_string_extension   = 74 [default = ""hello""];
-  optional    bytes default_bytes_extension    = 75 [default = ""world""];
-
-  optional TestAllTypes.NestedEnum
-    default_nested_enum_extension = 81 [default = BAR];
-  optional ForeignEnum
-    default_foreign_enum_extension = 82 [default = FOREIGN_BAR];
-  optional protobuf_unittest_import.ImportEnum
-    default_import_enum_extension = 83 [default = IMPORT_BAR];
-
-  optional string default_string_piece_extension = 84 [ctype=STRING_PIECE,
-                                                       default=""abc""];
-  optional string default_cord_extension = 85 [ctype=CORD, default=""123""];
-}
-
-message TestNestedExtension {
-  extend TestAllExtensions {
-    // Check for bug where string extensions declared in tested scope did not
-    // compile.
-    optional string test = 1002 [default=""test""];
-  }
-}
-
-// We have separate messages for testing required fields because it's
-// annoying to have to fill in required fields in TestProto in order to
-// do anything with it.  Note that we don't need to test every type of
-// required filed because the code output is basically identical to
-// optional fields for all types.
-message TestRequired {
-  required int32 a = 1;
-  optional int32 dummy2 = 2;
-  required int32 b = 3;
-
-  extend TestAllExtensions {
-    optional TestRequired single = 1000;
-    repeated TestRequired multi  = 1001;
-  }
-
-  // Pad the field count to 32 so that we can test that IsInitialized()
-  // properly checks multiple elements of has_bits_.
-  optional int32 dummy4  =  4;
-  optional int32 dummy5  =  5;
-  optional int32 dummy6  =  6;
-  optional int32 dummy7  =  7;
-  optional int32 dummy8  =  8;
-  optional int32 dummy9  =  9;
-  optional int32 dummy10 = 10;
-  optional int32 dummy11 = 11;
-  optional int32 dummy12 = 12;
-  optional int32 dummy13 = 13;
-  optional int32 dummy14 = 14;
-  optional int32 dummy15 = 15;
-  optional int32 dummy16 = 16;
-  optional int32 dummy17 = 17;
-  optional int32 dummy18 = 18;
-  optional int32 dummy19 = 19;
-  optional int32 dummy20 = 20;
-  optional int32 dummy21 = 21;
-  optional int32 dummy22 = 22;
-  optional int32 dummy23 = 23;
-  optional int32 dummy24 = 24;
-  optional int32 dummy25 = 25;
-  optional int32 dummy26 = 26;
-  optional int32 dummy27 = 27;
-  optional int32 dummy28 = 28;
-  optional int32 dummy29 = 29;
-  optional int32 dummy30 = 30;
-  optional int32 dummy31 = 31;
-  optional int32 dummy32 = 32;
-
-  required int32 c = 33;
-}
-
-message TestRequiredForeign {
-  optional TestRequired optional_message = 1;
-  repeated TestRequired repeated_message = 2;
-  optional int32 dummy = 3;
-}
-
-// Test that we can use NestedMessage from outside TestAllTypes.
-message TestForeignNested {
-  optional TestAllTypes.NestedMessage foreign_nested = 1;
-}
-
-// TestEmptyMessage is used to test unknown field support.
-message TestEmptyMessage {
-}
-
-// Like above, but declare all field numbers as potential extensions.  No
-// actual extensions should ever be defined for this type.
-message TestEmptyMessageWithExtensions {
-  extensions 1 to max;
-}
-
-message TestMultipleExtensionRanges {
-  extensions 42;
-  extensions 4143 to 4243;
-  extensions 65536 to max;
-}
-
-// Test that really large tag numbers don't break anything.
-message TestReallyLargeTagNumber {
-  // The largest possible tag number is 2^28 - 1, since the wire format uses
-  // three bits to communicate wire type.
-  optional int32 a = 1;
-  optional int32 bb = 268435455;
-}
-
-message TestRecursiveMessage {
-  optional TestRecursiveMessage a = 1;
-  optional int32 i = 2;
-}
-
-// Test that mutual recursion works.
-message TestMutualRecursionA {
-  optional TestMutualRecursionB bb = 1;
-}
-
-message TestMutualRecursionB {
-  optional TestMutualRecursionA a = 1;
-  optional int32 optional_int32 = 2;
-}
-
-// Test that groups have disjoint field numbers from their siblings and
-// parents.  This is NOT possible in proto1; only proto2.  When attempting
-// to compile with proto1, this will emit an error; so we only include it
-// in protobuf_unittest_proto.
-message TestDupFieldNumber {                        // NO_PROTO1
-  optional int32 a = 1;                             // NO_PROTO1
-  optional group Foo = 2 { optional int32 a = 1; }  // NO_PROTO1
-  optional group Bar = 3 { optional int32 a = 1; }  // NO_PROTO1
-}                                                   // NO_PROTO1
-
-
-// Needed for a Python test.
-message TestNestedMessageHasBits {
-  message NestedMessage {
-    repeated int32 nestedmessage_repeated_int32 = 1;
-    repeated ForeignMessage nestedmessage_repeated_foreignmessage = 2;
-  }
-  optional NestedMessage optional_nested_message = 1;
-}
-
-
-// Test an enum that has multiple values with the same number.
-enum TestEnumWithDupValue {
-  FOO1 = 1;
-  BAR1 = 2;
-  BAZ = 3;
-  FOO2 = 1;
-  BAR2 = 2;
-}
-
-// Test an enum with large, unordered values.
-enum TestSparseEnum {
-  SPARSE_A = 123;
-  SPARSE_B = 62374;
-  SPARSE_C = 12589234;
-  SPARSE_D = -15;
-  SPARSE_E = -53452;
-  SPARSE_F = 0;
-  SPARSE_G = 2;
-}
-
-// Test message with CamelCase field names.  This violates Protocol Buffer
-// standard style.
-message TestCamelCaseFieldNames {
-  optional int32 PrimitiveField = 1;
-  optional string StringField = 2;
-  optional ForeignEnum EnumField = 3;
-  optional ForeignMessage MessageField = 4;
-  optional string StringPieceField = 5 [ctype=STRING_PIECE];
-  optional string CordField = 6 [ctype=CORD];
-
-  repeated int32 RepeatedPrimitiveField = 7;
-  repeated string RepeatedStringField = 8;
-  repeated ForeignEnum RepeatedEnumField = 9;
-  repeated ForeignMessage RepeatedMessageField = 10;
-  repeated string RepeatedStringPieceField = 11 [ctype=STRING_PIECE];
-  repeated string RepeatedCordField = 12 [ctype=CORD];
-}
-
-
-// We list fields out of order, to ensure that we're using field number and not
-// field index to determine serialization order.
-message TestFieldOrderings {
-  optional string my_string = 11;
-  extensions 2 to 10;
-  optional int64 my_int = 1;
-  extensions 12 to 100;
-  optional float my_float = 101;
-}
-
-
-extend TestFieldOrderings {
-  optional string my_extension_string = 50;
-  optional int32 my_extension_int = 5;
-}
-
-
-message TestExtremeDefaultValues {
-  optional bytes escaped_bytes = 1 [default = ""\0\001\a\b\f\n\r\t\v\\\'\""\xfe""];
-  optional uint32 large_uint32 = 2 [default = 0xFFFFFFFF];
-  optional uint64 large_uint64 = 3 [default = 0xFFFFFFFFFFFFFFFF];
-  optional  int32 small_int32  = 4 [default = -0x7FFFFFFF];
-  optional  int64 small_int64  = 5 [default = -0x7FFFFFFFFFFFFFFF];
-
-  // The default value here is UTF-8 for ""\u1234"".  (We could also just type
-  // the UTF-8 text directly into this text file rather than escape it, but
-  // lots of people use editors that would be confused by this.)
-  optional string utf8_string = 6 [default = ""\341\210\264""];
-
-  // Tests for single-precision floating-point values.
-  optional float zero_float = 7 [default = 0];
-  optional float one_float = 8 [default = 1];
-  optional float small_float = 9 [default = 1.5];
-  optional float negative_one_float = 10 [default = -1];
-  optional float negative_float = 11 [default = -1.5];
-  // Using exponents
-  optional float large_float = 12 [default = 2E8];
-  optional float small_negative_float = 13 [default = -8e-28];
-
-  // Text for nonfinite floating-point values.
-  optional double inf_double = 14 [default = inf];
-  optional double neg_inf_double = 15 [default = -inf];
-  optional double nan_double = 16 [default = nan];
-  optional float inf_float = 17 [default = inf];
-  optional float neg_inf_float = 18 [default = -inf];
-  optional float nan_float = 19 [default = nan];
-
-  // Tests for C++ trigraphs.
-  // Trigraphs should be escaped in C++ generated files, but they should not be
-  // escaped for other languages.
-  // Note that in .proto file, ""\?"" is a valid way to escape ? in string
-  // literals.
-  optional string cpp_trigraph = 20 [default = ""? \? ?? \?? \??? ??/ ?\?-""];
-}
-
-message SparseEnumMessage {
-  optional TestSparseEnum sparse_enum = 1;
-}
-
-// Test String and Bytes: string is for valid UTF-8 strings
-message OneString {
-  optional string data = 1;
-}
-
-message OneBytes {
-  optional bytes data = 1;
-}
-
-// Test messages for packed fields
-
-message TestPackedTypes {
-  repeated    int32 packed_int32    =  90 [packed = true];
-  repeated    int64 packed_int64    =  91 [packed = true];
-  repeated   uint32 packed_uint32   =  92 [packed = true];
-  repeated   uint64 packed_uint64   =  93 [packed = true];
-  repeated   sint32 packed_sint32   =  94 [packed = true];
-  repeated   sint64 packed_sint64   =  95 [packed = true];
-  repeated  fixed32 packed_fixed32  =  96 [packed = true];
-  repeated  fixed64 packed_fixed64  =  97 [packed = true];
-  repeated sfixed32 packed_sfixed32 =  98 [packed = true];
-  repeated sfixed64 packed_sfixed64 =  99 [packed = true];
-  repeated    float packed_float    = 100 [packed = true];
-  repeated   double packed_double   = 101 [packed = true];
-  repeated     bool packed_bool     = 102 [packed = true];
-  repeated ForeignEnum packed_enum  = 103 [packed = true];
-}
-
-// A message with the same fields as TestPackedTypes, but without packing. Used
-// to test packed <-> unpacked wire compatibility.
-message TestUnpackedTypes {
-  repeated    int32 unpacked_int32    =  90 [packed = false];
-  repeated    int64 unpacked_int64    =  91 [packed = false];
-  repeated   uint32 unpacked_uint32   =  92 [packed = false];
-  repeated   uint64 unpacked_uint64   =  93 [packed = false];
-  repeated   sint32 unpacked_sint32   =  94 [packed = false];
-  repeated   sint64 unpacked_sint64   =  95 [packed = false];
-  repeated  fixed32 unpacked_fixed32  =  96 [packed = false];
-  repeated  fixed64 unpacked_fixed64  =  97 [packed = false];
-  repeated sfixed32 unpacked_sfixed32 =  98 [packed = false];
-  repeated sfixed64 unpacked_sfixed64 =  99 [packed = false];
-  repeated    float unpacked_float    = 100 [packed = false];
-  repeated   double unpacked_double   = 101 [packed = false];
-  repeated     bool unpacked_bool     = 102 [packed = false];
-  repeated ForeignEnum unpacked_enum  = 103 [packed = false];
-}
-
-message TestPackedExtensions {
-  extensions 1 to max;
-}
-
-extend TestPackedExtensions {
-  repeated    int32 packed_int32_extension    =  90 [packed = true];
-  repeated    int64 packed_int64_extension    =  91 [packed = true];
-  repeated   uint32 packed_uint32_extension   =  92 [packed = true];
-  repeated   uint64 packed_uint64_extension   =  93 [packed = true];
-  repeated   sint32 packed_sint32_extension   =  94 [packed = true];
-  repeated   sint64 packed_sint64_extension   =  95 [packed = true];
-  repeated  fixed32 packed_fixed32_extension  =  96 [packed = true];
-  repeated  fixed64 packed_fixed64_extension  =  97 [packed = true];
-  repeated sfixed32 packed_sfixed32_extension =  98 [packed = true];
-  repeated sfixed64 packed_sfixed64_extension =  99 [packed = true];
-  repeated    float packed_float_extension    = 100 [packed = true];
-  repeated   double packed_double_extension   = 101 [packed = true];
-  repeated     bool packed_bool_extension     = 102 [packed = true];
-  repeated ForeignEnum packed_enum_extension  = 103 [packed = true];
-}
-
-// Used by ExtensionSetTest/DynamicExtensions.  The test actually builds
-// a set of extensions to TestAllExtensions dynamically, based on the fields
-// of this message type.
-message TestDynamicExtensions {
-  enum DynamicEnumType {
-    DYNAMIC_FOO = 2200;
-    DYNAMIC_BAR = 2201;
-    DYNAMIC_BAZ = 2202;
-  }
-  message DynamicMessageType {
-    optional int32 dynamic_field = 2100;
-  }
-
-  optional fixed32 scalar_extension = 2000;
-  optional ForeignEnum enum_extension = 2001;
-  optional DynamicEnumType dynamic_enum_extension = 2002;
-
-  optional ForeignMessage message_extension = 2003;
-  optional DynamicMessageType dynamic_message_extension = 2004;
-
-  repeated string repeated_extension = 2005;
-  repeated sint32 packed_extension = 2006 [packed = true];
-}
-
-message TestRepeatedScalarDifferentTagSizes {
-  // Parsing repeated fixed size values used to fail. This message needs to be
-  // used in order to get a tag of the right size; all of the repeated fields
-  // in TestAllTypes didn't trigger the check.
-  repeated fixed32 repeated_fixed32 = 12;
-  // Check for a varint type, just for good measure.
-  repeated int32   repeated_int32   = 13;
-
-  // These have two-byte tags.
-  repeated fixed64 repeated_fixed64 = 2046;
-  repeated int64   repeated_int64   = 2047;
-
-  // Three byte tags.
-  repeated float   repeated_float   = 262142;
-  repeated uint64  repeated_uint64  = 262143;
-}
-
-
-// Test that RPC services work.
-message FooRequest  {}
-message FooResponse {}
-
-service TestService {
-  rpc Foo(FooRequest) returns (FooResponse);
-  rpc Bar(BarRequest) returns (BarResponse);
-}
-
-
-message BarRequest  {}
-message BarResponse {}
diff --git a/csharp/protos/google/protobuf/unittest_csharp_options.proto b/csharp/protos/google/protobuf/unittest_csharp_options.proto
deleted file mode 100644
index 376932929..000000000
--- a/csharp/protos/google/protobuf/unittest_csharp_options.proto
+++ /dev/null
@@ -1,52 +0,0 @@
-// Protocol Buffers - Google's data interchange format
-// Copyright 2008 Google Inc.  All rights reserved.
-// http://code.google.com/p/protobuf/
-//
-// Redistribution and use in source and binary forms, with or without
-// modification, are permitted provided that the following conditions are
-// met:
-//
-//     * Redistributions of source code must retain the above copyright
-// notice, this list of conditions and the following disclaimer.
-//     * Redistributions in binary form must reproduce the above
-// copyright notice, this list of conditions and the following disclaimer
-// in the documentation and/or other materials provided with the
-// distribution.
-//     * Neither the name of Google Inc. nor the names of its
-// contributors may be used to endorse or promote products derived from
-// this software without specific prior written permission.
-//
-// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-// ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
-// Author: jonskeet@google.com (Jon Skeet)
-//
-// A proto file for unit testing the custom C# options
-
-import ""google/protobuf/csharp_options.proto"";
-option (google.protobuf.csharp_file_options).namespace = ""Google.ProtocolBuffers.TestProtos"";
-option (google.protobuf.csharp_file_options).umbrella_classname = ""UnitTestCSharpOptionsProtoFile"";
-//option (google.protobuf.csharp_file_options).nest_classes = true;
-
-package protobuf_unittest;
-
-message OptionsMessage {
-
-  // Will be left as Normal
-  optional string normal = 1;
-
-  // Will be converted to OptionsMessage_
-  optional string options_message = 2;
-  
-  // Will be converted to CustomName
-  optional string customized = 3 [(google.protobuf.csharp_field_options).property_name = ""CustomName""];
-}
diff --git a/csharp/protos/google/protobuf/unittest_custom_options.proto b/csharp/protos/google/protobuf/unittest_custom_options.proto
deleted file mode 100644
index 201fb32a6..000000000
--- a/csharp/protos/google/protobuf/unittest_custom_options.proto
+++ /dev/null
@@ -1,372 +0,0 @@
-// Additional options required for C# generation. File from copyright
-// line onwards is as per original distribution.
-import ""google/protobuf/csharp_options.proto"";
-option (google.protobuf.csharp_file_options).namespace = ""Google.ProtocolBuffers.TestProtos"";
-option (google.protobuf.csharp_file_options).umbrella_classname = ""UnitTestCustomOptionsProtoFile"";
-
-// Protocol Buffers - Google's data interchange format
-// Copyright 2008 Google Inc.  All rights reserved.
-// http://code.google.com/p/protobuf/
-//
-// Redistribution and use in source and binary forms, with or without
-// modification, are permitted provided that the following conditions are
-// met:
-//
-//     * Redistributions of source code must retain the above copyright
-// notice, this list of conditions and the following disclaimer.
-//     * Redistributions in binary form must reproduce the above
-// copyright notice, this list of conditions and the following disclaimer
-// in the documentation and/or other materials provided with the
-// distribution.
-//     * Neither the name of Google Inc. nor the names of its
-// contributors may be used to endorse or promote products derived from
-// this software without specific prior written permission.
-//
-// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-// ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
-// Author: benjy@google.com (Benjy Weinberger)
-//  Based on original Protocol Buffers design by
-//  Sanjay Ghemawat, Jeff Dean, and others.
-//
-// A proto file used to test the ""custom options"" feature of proto2.
-
-
-// Some generic_services option(s) added automatically.
-// See:  http://go/proto2-generic-services-default
-option cc_generic_services = true;     // auto-added
-option java_generic_services = true;   // auto-added
-option py_generic_services = true;
-
-// A custom file option (defined below).
-option (file_opt1) = 9876543210;
-
-import ""google/protobuf/descriptor.proto"";
-
-// We don't put this in a package within proto2 because we need to make sure
-// that the generated code doesn't depend on being in the proto2 namespace.
-package protobuf_unittest;
-
-
-// Some simple test custom options of various types.
-
-extend google.protobuf.FileOptions {
-  optional uint64 file_opt1 = 7736974;
-}
-
-extend google.protobuf.MessageOptions {
-  optional int32 message_opt1 = 7739036;
-}
-
-extend google.protobuf.FieldOptions {
-  optional fixed64 field_opt1 = 7740936;
-  // This is useful for testing that we correctly register default values for
-  // extension options.
-  optional int32 field_opt2 = 7753913 [default=42];
-}
-
-extend google.protobuf.EnumOptions {
-  optional sfixed32 enum_opt1 = 7753576;
-}
-
-extend google.protobuf.EnumValueOptions {
-  optional int32 enum_value_opt1 = 1560678;
-}
-
-extend google.protobuf.ServiceOptions {
-  optional sint64 service_opt1 = 7887650;
-}
-
-enum MethodOpt1 {
-  METHODOPT1_VAL1 = 1;
-  METHODOPT1_VAL2 = 2;
-}
-
-extend google.protobuf.MethodOptions {
-  optional MethodOpt1 method_opt1 = 7890860;
-}
-
-// A test message with custom options at all possible locations (and also some
-// regular options, to make sure they interact nicely).
-message TestMessageWithCustomOptions {
-  option message_set_wire_format = false;
-
-  option (message_opt1) = -56;
-
-  optional string field1 = 1 [ctype=CORD,
-                              (field_opt1)=8765432109];
-
-  enum AnEnum {
-    option (enum_opt1) = -789;
-
-    ANENUM_VAL1 = 1;
-    ANENUM_VAL2 = 2 [(enum_value_opt1) = 123];
-  }
-}
-
-
-// A test RPC service with custom options at all possible locations (and also
-// some regular options, to make sure they interact nicely).
-message CustomOptionFooRequest {
-}
-
-message CustomOptionFooResponse {
-}
-
-service TestServiceWithCustomOptions {
-  option (service_opt1) = -9876543210;
-
-  rpc Foo(CustomOptionFooRequest) returns (CustomOptionFooResponse) {
-    option (method_opt1) = METHODOPT1_VAL2;
-  }
-}
-
-
-
-// Options of every possible field type, so we can test them all exhaustively.
-
-message DummyMessageContainingEnum {
-  enum TestEnumType {
-    TEST_OPTION_ENUM_TYPE1 = 22;
-    TEST_OPTION_ENUM_TYPE2 = -23;
-  }
-}
-
-message DummyMessageInvalidAsOptionType {
-}
-
-extend google.protobuf.MessageOptions {
-  optional         bool     bool_opt = 7706090;
-  optional        int32    int32_opt = 7705709;
-  optional        int64    int64_opt = 7705542;
-  optional       uint32   uint32_opt = 7704880;
-  optional       uint64   uint64_opt = 7702367;
-  optional       sint32   sint32_opt = 7701568;
-  optional       sint64   sint64_opt = 7700863;
-  optional      fixed32  fixed32_opt = 7700307;
-  optional      fixed64  fixed64_opt = 7700194;
-  optional     sfixed32 sfixed32_opt = 7698645;
-  optional     sfixed64 sfixed64_opt = 7685475;
-  optional        float    float_opt = 7675390;
-  optional       double   double_opt = 7673293;
-  optional       string   string_opt = 7673285;
-  optional        bytes    bytes_opt = 7673238;
-  optional DummyMessageContainingEnum.TestEnumType enum_opt = 7673233;
-  optional DummyMessageInvalidAsOptionType message_type_opt = 7665967;
-}
-
-message CustomOptionMinIntegerValues {
-  option     (bool_opt) = false;
-  option    (int32_opt) = -0x80000000;
-  option    (int64_opt) = -0x8000000000000000;
-  option   (uint32_opt) = 0;
-  option   (uint64_opt) = 0;
-  option   (sint32_opt) = -0x80000000;
-  option   (sint64_opt) = -0x8000000000000000;
-  option  (fixed32_opt) = 0;
-  option  (fixed64_opt) = 0;
-  option (sfixed32_opt) = -0x80000000;
-  option (sfixed64_opt) = -0x8000000000000000;
-}
-
-message CustomOptionMaxIntegerValues {
-  option     (bool_opt) = true;
-  option    (int32_opt) = 0x7FFFFFFF;
-  option    (int64_opt) = 0x7FFFFFFFFFFFFFFF;
-  option   (uint32_opt) = 0xFFFFFFFF;
-  option   (uint64_opt) = 0xFFFFFFFFFFFFFFFF;
-  option   (sint32_opt) = 0x7FFFFFFF;
-  option   (sint64_opt) = 0x7FFFFFFFFFFFFFFF;
-  option  (fixed32_opt) = 0xFFFFFFFF;
-  option  (fixed64_opt) = 0xFFFFFFFFFFFFFFFF;
-  option (sfixed32_opt) = 0x7FFFFFFF;
-  option (sfixed64_opt) = 0x7FFFFFFFFFFFFFFF;
-}
-
-message CustomOptionOtherValues {
-  option  (int32_opt) = -100;  // To test sign-extension.
-  option  (float_opt) = 12.3456789;
-  option (double_opt) = 1.234567890123456789;
-  option (string_opt) = ""Hello, \""World\"""";
-  option  (bytes_opt) = ""Hello\0World"";
-  option   (enum_opt) = TEST_OPTION_ENUM_TYPE2;
-}
-
-message SettingRealsFromPositiveInts {
-  option  (float_opt) = 12;
-  option (double_opt) = 154;
-}
-
-message SettingRealsFromNegativeInts {
-  option  (float_opt) = -12;
-  option  (double_opt) = -154;
-}
-
-// Options of complex message types, themselves combined and extended in
-// various ways.
-
-message ComplexOptionType1 {
-  optional int32 foo = 1;
-  optional int32 foo2 = 2;
-  optional int32 foo3 = 3;
-
-  extensions 100 to max;
-}
-
-message ComplexOptionType2 {
-  optional ComplexOptionType1 bar = 1;
-  optional int32 baz = 2;
-
-  message ComplexOptionType4 {
-    optional int32 waldo = 1;
-
-    extend google.protobuf.MessageOptions {
-      optional ComplexOptionType4 complex_opt4 = 7633546;
-    }
-  }
-
-  optional ComplexOptionType4 fred = 3;
-
-  extensions 100 to max;
-}
-
-message ComplexOptionType3 {
-  optional int32 qux = 1;
-
-  optional group ComplexOptionType5 = 2 {
-    optional int32 plugh = 3;
-  }
-}
-
-extend ComplexOptionType1 {
-  optional int32 quux = 7663707;
-  optional ComplexOptionType3 corge = 7663442;
-}
-
-extend ComplexOptionType2 {
-  optional int32 grault = 7650927;
-  optional ComplexOptionType1 garply = 7649992;
-}
-
-extend google.protobuf.MessageOptions {
-  optional protobuf_unittest.ComplexOptionType1 complex_opt1 = 7646756;
-  optional ComplexOptionType2 complex_opt2 = 7636949;
-  optional ComplexOptionType3 complex_opt3 = 7636463;
-  optional group ComplexOpt6 = 7595468 {
-    optional int32 xyzzy = 7593951;
-  }
-}
-
-// Note that we try various different ways of naming the same extension.
-message VariousComplexOptions {
-  option (.protobuf_unittest.complex_opt1).foo = 42;
-  option (protobuf_unittest.complex_opt1).(.protobuf_unittest.quux) = 324;
-  option (.protobuf_unittest.complex_opt1).(protobuf_unittest.corge).qux = 876;
-  option (complex_opt2).baz = 987;
-  option (complex_opt2).(grault) = 654;
-  option (complex_opt2).bar.foo = 743;
-  option (complex_opt2).bar.(quux) = 1999;
-  option (complex_opt2).bar.(protobuf_unittest.corge).qux = 2008;
-  option (complex_opt2).(garply).foo = 741;
-  option (complex_opt2).(garply).(.protobuf_unittest.quux) = 1998;
-  option (complex_opt2).(protobuf_unittest.garply).(corge).qux = 2121;
-  option (ComplexOptionType2.ComplexOptionType4.complex_opt4).waldo = 1971;
-  option (complex_opt2).fred.waldo = 321;
-  option (protobuf_unittest.complex_opt3).qux = 9;
-  option (complex_opt3).complexoptiontype5.plugh = 22;
-  option (complexopt6).xyzzy = 24;
-}
-
-// ------------------------------------------------------
-// Definitions for testing aggregate option parsing.
-// See descriptor_unittest.cc.
-
-message AggregateMessageSet {
-  option message_set_wire_format = true;
-  extensions 4 to max;
-}
-
-message AggregateMessageSetElement {
-  extend AggregateMessageSet {
-    optional AggregateMessageSetElement message_set_extension = 15447542;
-  }
-  optional string s = 1;
-}
-
-// A helper type used to test aggregate option parsing
-message Aggregate {
-  optional int32 i = 1;
-  optional string s = 2;
-
-  // A nested object
-  optional Aggregate sub = 3;
-
-  // To test the parsing of extensions inside aggregate values
-  optional google.protobuf.FileOptions file = 4;
-  extend google.protobuf.FileOptions {
-    optional Aggregate nested = 15476903;
-  }
-
-  // An embedded message set
-  optional AggregateMessageSet mset = 5;
-}
-
-// Allow Aggregate to be used as an option at all possible locations
-// in the .proto grammer.
-extend google.protobuf.FileOptions      { optional Aggregate fileopt    = 15478479; }
-extend google.protobuf.MessageOptions   { optional Aggregate msgopt     = 15480088; }
-extend google.protobuf.FieldOptions     { optional Aggregate fieldopt   = 15481374; }
-extend google.protobuf.EnumOptions      { optional Aggregate enumopt_renamed    = 15483218; }
-extend google.protobuf.EnumValueOptions { optional Aggregate enumvalopt = 15486921; }
-extend google.protobuf.ServiceOptions   { optional Aggregate serviceopt = 15497145; }
-extend google.protobuf.MethodOptions    { optional Aggregate methodopt  = 15512713; }
-
-// Try using AggregateOption at different points in the proto grammar
-option (fileopt) = {
-  s: 'FileAnnotation'
-  // Also test the handling of comments
-  /* of both types */ i: 100
-
-  sub { s: 'NestedFileAnnotation' }
-
-  // Include a google.protobuf.FileOptions and recursively extend it with
-  // another fileopt.
-  file {
-    [protobuf_unittest.fileopt] {
-      s:'FileExtensionAnnotation'
-    }
-  }
-
-  // A message set inside an option value
-  mset {
-    [protobuf_unittest.AggregateMessageSetElement.message_set_extension] {
-      s: 'EmbeddedMessageSetElement'
-    }
-  }
-};
-
-message AggregateMessage {
-  option (msgopt) = { i:101 s:'MessageAnnotation' };
-  optional int32 fieldname = 1 [(fieldopt) = { s:'FieldAnnotation' }];
-}
-
-service AggregateService {
-  option (serviceopt) = { s:'ServiceAnnotation' };
-  rpc Method (AggregateMessage) returns (AggregateMessage) {
-    option (methodopt) = { s:'MethodAnnotation' };
-  }
-}
-
-enum AggregateEnum {
-  option (enumopt_renamed) = { s:'EnumAnnotation' };
-  VALUE = 1 [(enumvalopt) = { s:'EnumValueAnnotation' }];
-}
diff --git a/csharp/protos/google/protobuf/unittest_embed_optimize_for.proto b/csharp/protos/google/protobuf/unittest_embed_optimize_for.proto
deleted file mode 100644
index 562553851..000000000
--- a/csharp/protos/google/protobuf/unittest_embed_optimize_for.proto
+++ /dev/null
@@ -1,56 +0,0 @@
-// Additional options required for C# generation. File from copyright
-// line onwards is as per original distribution.
-import ""google/protobuf/csharp_options.proto"";
-option (google.protobuf.csharp_file_options).namespace = ""Google.ProtocolBuffers.TestProtos"";
-option (google.protobuf.csharp_file_options).umbrella_classname = ""UnitTestEmbedOptimizeForProtoFile"";
-
-// Protocol Buffers - Google's data interchange format
-// Copyright 2008 Google Inc.  All rights reserved.
-// http://code.google.com/p/protobuf/
-//
-// Redistribution and use in source and binary forms, with or without
-// modification, are permitted provided that the following conditions are
-// met:
-//
-//     * Redistributions of source code must retain the above copyright
-// notice, this list of conditions and the following disclaimer.
-//     * Redistributions in binary form must reproduce the above
-// copyright notice, this list of conditions and the following disclaimer
-// in the documentation and/or other materials provided with the
-// distribution.
-//     * Neither the name of Google Inc. nor the names of its
-// contributors may be used to endorse or promote products derived from
-// this software without specific prior written permission.
-//
-// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-// ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
-// Author: kenton@google.com (Kenton Varda)
-//  Based on original Protocol Buffers design by
-//  Sanjay Ghemawat, Jeff Dean, and others.
-//
-// A proto file which imports a proto file that uses optimize_for = CODE_SIZE.
-
-import ""google/protobuf/unittest_optimize_for.proto"";
-
-package protobuf_unittest;
-
-// We optimize for speed here, but we are importing a proto that is optimized
-// for code size.
-option optimize_for = SPEED;
-
-message TestEmbedOptimizedForSize {
-  // Test that embedding a message which has optimize_for = CODE_SIZE into
-  // one optimized for speed works.
-  optional TestOptimizedForSize optional_message = 1;
-  repeated TestOptimizedForSize repeated_message = 2;
-}
diff --git a/csharp/protos/google/protobuf/unittest_empty.proto b/csharp/protos/google/protobuf/unittest_empty.proto
deleted file mode 100644
index f6b532a8d..000000000
--- a/csharp/protos/google/protobuf/unittest_empty.proto
+++ /dev/null
@@ -1,43 +0,0 @@
-// Additional options required for C# generation. File from copyright
-// line onwards is as per original distribution.
-import ""google/protobuf/csharp_options.proto"";
-option (google.protobuf.csharp_file_options).namespace = ""Google.ProtocolBuffers.TestProtos"";
-option (google.protobuf.csharp_file_options).umbrella_classname = ""UnitTestEmptyProtoFile"";
-
-// Protocol Buffers - Google's data interchange format
-// Copyright 2008 Google Inc.  All rights reserved.
-// http://code.google.com/p/protobuf/
-//
-// Redistribution and use in source and binary forms, with or without
-// modification, are permitted provided that the following conditions are
-// met:
-//
-//     * Redistributions of source code must retain the above copyright
-// notice, this list of conditions and the following disclaimer.
-//     * Redistributions in binary form must reproduce the above
-// copyright notice, this list of conditions and the following disclaimer
-// in the documentation and/or other materials provided with the
-// distribution.
-//     * Neither the name of Google Inc. nor the names of its
-// contributors may be used to endorse or promote products derived from
-// this software without specific prior written permission.
-//
-// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-// ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
-// Author: kenton@google.com (Kenton Varda)
-//  Based on original Protocol Buffers design by
-//  Sanjay Ghemawat, Jeff Dean, and others.
-//
-// This file intentionally left blank.  (At one point this wouldn't compile
-// correctly.)
-
diff --git a/csharp/protos/google/protobuf/unittest_enormous_descriptor.proto b/csharp/protos/google/protobuf/unittest_enormous_descriptor.proto
deleted file mode 100644
index fa97778e6..000000000
--- a/csharp/protos/google/protobuf/unittest_enormous_descriptor.proto
+++ /dev/null
@@ -1,1052 +0,0 @@
-// Additional options required for C# generation. File from copyright
-// line onwards is as per original distribution.
-import ""google/protobuf/csharp_options.proto"";
-option (google.protobuf.csharp_file_options).namespace = ""Google.ProtocolBuffers.TestProtos"";
-option (google.protobuf.csharp_file_options).umbrella_classname = ""UnitTestEnormousDescriptorProtoFile"";
-
-// Protocol Buffers - Google's data interchange format
-// Copyright 2008 Google Inc.  All rights reserved.
-// http://code.google.com/p/protobuf/
-//
-// Redistribution and use in source and binary forms, with or without
-// modification, are permitted provided that the following conditions are
-// met:
-//
-//     * Redistributions of source code must retain the above copyright
-// notice, this list of conditions and the following disclaimer.
-//     * Redistributions in binary form must reproduce the above
-// copyright notice, this list of conditions and the following disclaimer
-// in the documentation and/or other materials provided with the
-// distribution.
-//     * Neither the name of Google Inc. nor the names of its
-// contributors may be used to endorse or promote products derived from
-// this software without specific prior written permission.
-//
-// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-// ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
-// Author: kenton@google.com (Kenton Varda)
-//  Based on original Protocol Buffers design by
-//  Sanjay Ghemawat, Jeff Dean, and others.
-//
-// A proto file that has an extremely large descriptor.  Used to test that
-// descriptors over 64k don't break the string literal length limit in Java.
-
-
-package google.protobuf;
-option java_package = ""com.google.protobuf"";
-
-// Avoid generating insanely long methods.
-option optimize_for = CODE_SIZE;
-
-message TestEnormousDescriptor {
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_1 = 1 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_2 = 2 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_3 = 3 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_4 = 4 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_5 = 5 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_6 = 6 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_7 = 7 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_8 = 8 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_9 = 9 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_10 = 10 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_11 = 11 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_12 = 12 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_13 = 13 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_14 = 14 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_15 = 15 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_16 = 16 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_17 = 17 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_18 = 18 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_19 = 19 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_20 = 20 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_21 = 21 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_22 = 22 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_23 = 23 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_24 = 24 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_25 = 25 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_26 = 26 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_27 = 27 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_28 = 28 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_29 = 29 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_30 = 30 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_31 = 31 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_32 = 32 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_33 = 33 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_34 = 34 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_35 = 35 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_36 = 36 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_37 = 37 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_38 = 38 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_39 = 39 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_40 = 40 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_41 = 41 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_42 = 42 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_43 = 43 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_44 = 44 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_45 = 45 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_46 = 46 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_47 = 47 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_48 = 48 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_49 = 49 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_50 = 50 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_51 = 51 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_52 = 52 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_53 = 53 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_54 = 54 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_55 = 55 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_56 = 56 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_57 = 57 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_58 = 58 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_59 = 59 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_60 = 60 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_61 = 61 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_62 = 62 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_63 = 63 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_64 = 64 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_65 = 65 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_66 = 66 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_67 = 67 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_68 = 68 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_69 = 69 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_70 = 70 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_71 = 71 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_72 = 72 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_73 = 73 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_74 = 74 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_75 = 75 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_76 = 76 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_77 = 77 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_78 = 78 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_79 = 79 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_80 = 80 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_81 = 81 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_82 = 82 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_83 = 83 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_84 = 84 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_85 = 85 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_86 = 86 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_87 = 87 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_88 = 88 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_89 = 89 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_90 = 90 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_91 = 91 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_92 = 92 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_93 = 93 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_94 = 94 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_95 = 95 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_96 = 96 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_97 = 97 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_98 = 98 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_99 = 99 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_100 = 100 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_101 = 101 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_102 = 102 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_103 = 103 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_104 = 104 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_105 = 105 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_106 = 106 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_107 = 107 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_108 = 108 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_109 = 109 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_110 = 110 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_111 = 111 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_112 = 112 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_113 = 113 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_114 = 114 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_115 = 115 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_116 = 116 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_117 = 117 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_118 = 118 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_119 = 119 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_120 = 120 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_121 = 121 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_122 = 122 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_123 = 123 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_124 = 124 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_125 = 125 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_126 = 126 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_127 = 127 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_128 = 128 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_129 = 129 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_130 = 130 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_131 = 131 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_132 = 132 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_133 = 133 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_134 = 134 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_135 = 135 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_136 = 136 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_137 = 137 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_138 = 138 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_139 = 139 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_140 = 140 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_141 = 141 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_142 = 142 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_143 = 143 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_144 = 144 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_145 = 145 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_146 = 146 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_147 = 147 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_148 = 148 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_149 = 149 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_150 = 150 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_151 = 151 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_152 = 152 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_153 = 153 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_154 = 154 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_155 = 155 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_156 = 156 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_157 = 157 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_158 = 158 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_159 = 159 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_160 = 160 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_161 = 161 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_162 = 162 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_163 = 163 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_164 = 164 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_165 = 165 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_166 = 166 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_167 = 167 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_168 = 168 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_169 = 169 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_170 = 170 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_171 = 171 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_172 = 172 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_173 = 173 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_174 = 174 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_175 = 175 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_176 = 176 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_177 = 177 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_178 = 178 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_179 = 179 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_180 = 180 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_181 = 181 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_182 = 182 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_183 = 183 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_184 = 184 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_185 = 185 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_186 = 186 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_187 = 187 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_188 = 188 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_189 = 189 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_190 = 190 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_191 = 191 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_192 = 192 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_193 = 193 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_194 = 194 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_195 = 195 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_196 = 196 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_197 = 197 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_198 = 198 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_199 = 199 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_200 = 200 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_201 = 201 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_202 = 202 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_203 = 203 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_204 = 204 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_205 = 205 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_206 = 206 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_207 = 207 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_208 = 208 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_209 = 209 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_210 = 210 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_211 = 211 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_212 = 212 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_213 = 213 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_214 = 214 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_215 = 215 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_216 = 216 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_217 = 217 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_218 = 218 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_219 = 219 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_220 = 220 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_221 = 221 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_222 = 222 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_223 = 223 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_224 = 224 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_225 = 225 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_226 = 226 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_227 = 227 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_228 = 228 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_229 = 229 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_230 = 230 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_231 = 231 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_232 = 232 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_233 = 233 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_234 = 234 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_235 = 235 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_236 = 236 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_237 = 237 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_238 = 238 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_239 = 239 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_240 = 240 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_241 = 241 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_242 = 242 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_243 = 243 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_244 = 244 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_245 = 245 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_246 = 246 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_247 = 247 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_248 = 248 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_249 = 249 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_250 = 250 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_251 = 251 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_252 = 252 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_253 = 253 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_254 = 254 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_255 = 255 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_256 = 256 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_257 = 257 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_258 = 258 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_259 = 259 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_260 = 260 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_261 = 261 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_262 = 262 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_263 = 263 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_264 = 264 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_265 = 265 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_266 = 266 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_267 = 267 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_268 = 268 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_269 = 269 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_270 = 270 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_271 = 271 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_272 = 272 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_273 = 273 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_274 = 274 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_275 = 275 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_276 = 276 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_277 = 277 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_278 = 278 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_279 = 279 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_280 = 280 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_281 = 281 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_282 = 282 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_283 = 283 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_284 = 284 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_285 = 285 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_286 = 286 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_287 = 287 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_288 = 288 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_289 = 289 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_290 = 290 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_291 = 291 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_292 = 292 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_293 = 293 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_294 = 294 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_295 = 295 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_296 = 296 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_297 = 297 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_298 = 298 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_299 = 299 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_300 = 300 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_301 = 301 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_302 = 302 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_303 = 303 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_304 = 304 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_305 = 305 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_306 = 306 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_307 = 307 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_308 = 308 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_309 = 309 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_310 = 310 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_311 = 311 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_312 = 312 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_313 = 313 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_314 = 314 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_315 = 315 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_316 = 316 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_317 = 317 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_318 = 318 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_319 = 319 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_320 = 320 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_321 = 321 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_322 = 322 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_323 = 323 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_324 = 324 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_325 = 325 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_326 = 326 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_327 = 327 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_328 = 328 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_329 = 329 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_330 = 330 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_331 = 331 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_332 = 332 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_333 = 333 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_334 = 334 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_335 = 335 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_336 = 336 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_337 = 337 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_338 = 338 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_339 = 339 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_340 = 340 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_341 = 341 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_342 = 342 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_343 = 343 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_344 = 344 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_345 = 345 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_346 = 346 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_347 = 347 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_348 = 348 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_349 = 349 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_350 = 350 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_351 = 351 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_352 = 352 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_353 = 353 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_354 = 354 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_355 = 355 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_356 = 356 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_357 = 357 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_358 = 358 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_359 = 359 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_360 = 360 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_361 = 361 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_362 = 362 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_363 = 363 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_364 = 364 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_365 = 365 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_366 = 366 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_367 = 367 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_368 = 368 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_369 = 369 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_370 = 370 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_371 = 371 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_372 = 372 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_373 = 373 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_374 = 374 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_375 = 375 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_376 = 376 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_377 = 377 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_378 = 378 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_379 = 379 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_380 = 380 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_381 = 381 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_382 = 382 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_383 = 383 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_384 = 384 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_385 = 385 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_386 = 386 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_387 = 387 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_388 = 388 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_389 = 389 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_390 = 390 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_391 = 391 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_392 = 392 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_393 = 393 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_394 = 394 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_395 = 395 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_396 = 396 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_397 = 397 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_398 = 398 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_399 = 399 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_400 = 400 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_401 = 401 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_402 = 402 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_403 = 403 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_404 = 404 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_405 = 405 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_406 = 406 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_407 = 407 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_408 = 408 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_409 = 409 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_410 = 410 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_411 = 411 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_412 = 412 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_413 = 413 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_414 = 414 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_415 = 415 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_416 = 416 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_417 = 417 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_418 = 418 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_419 = 419 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_420 = 420 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_421 = 421 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_422 = 422 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_423 = 423 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_424 = 424 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_425 = 425 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_426 = 426 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_427 = 427 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_428 = 428 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_429 = 429 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_430 = 430 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_431 = 431 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_432 = 432 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_433 = 433 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_434 = 434 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_435 = 435 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_436 = 436 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_437 = 437 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_438 = 438 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_439 = 439 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_440 = 440 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_441 = 441 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_442 = 442 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_443 = 443 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_444 = 444 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_445 = 445 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_446 = 446 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_447 = 447 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_448 = 448 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_449 = 449 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_450 = 450 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_451 = 451 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_452 = 452 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_453 = 453 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_454 = 454 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_455 = 455 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_456 = 456 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_457 = 457 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_458 = 458 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_459 = 459 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_460 = 460 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_461 = 461 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_462 = 462 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_463 = 463 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_464 = 464 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_465 = 465 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_466 = 466 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_467 = 467 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_468 = 468 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_469 = 469 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_470 = 470 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_471 = 471 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_472 = 472 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_473 = 473 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_474 = 474 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_475 = 475 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_476 = 476 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_477 = 477 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_478 = 478 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_479 = 479 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_480 = 480 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_481 = 481 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_482 = 482 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_483 = 483 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_484 = 484 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_485 = 485 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_486 = 486 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_487 = 487 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_488 = 488 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_489 = 489 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_490 = 490 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_491 = 491 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_492 = 492 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_493 = 493 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_494 = 494 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_495 = 495 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_496 = 496 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_497 = 497 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_498 = 498 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_499 = 499 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_500 = 500 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_501 = 501 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_502 = 502 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_503 = 503 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_504 = 504 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_505 = 505 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_506 = 506 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_507 = 507 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_508 = 508 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_509 = 509 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_510 = 510 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_511 = 511 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_512 = 512 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_513 = 513 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_514 = 514 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_515 = 515 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_516 = 516 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_517 = 517 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_518 = 518 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_519 = 519 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_520 = 520 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_521 = 521 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_522 = 522 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_523 = 523 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_524 = 524 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_525 = 525 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_526 = 526 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_527 = 527 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_528 = 528 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_529 = 529 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_530 = 530 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_531 = 531 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_532 = 532 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_533 = 533 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_534 = 534 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_535 = 535 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_536 = 536 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_537 = 537 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_538 = 538 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_539 = 539 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_540 = 540 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_541 = 541 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_542 = 542 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_543 = 543 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_544 = 544 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_545 = 545 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_546 = 546 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_547 = 547 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_548 = 548 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_549 = 549 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_550 = 550 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_551 = 551 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_552 = 552 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_553 = 553 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_554 = 554 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_555 = 555 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_556 = 556 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_557 = 557 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_558 = 558 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_559 = 559 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_560 = 560 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_561 = 561 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_562 = 562 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_563 = 563 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_564 = 564 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_565 = 565 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_566 = 566 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_567 = 567 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_568 = 568 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_569 = 569 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_570 = 570 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_571 = 571 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_572 = 572 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_573 = 573 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_574 = 574 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_575 = 575 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_576 = 576 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_577 = 577 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_578 = 578 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_579 = 579 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_580 = 580 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_581 = 581 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_582 = 582 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_583 = 583 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_584 = 584 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_585 = 585 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_586 = 586 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_587 = 587 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_588 = 588 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_589 = 589 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_590 = 590 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_591 = 591 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_592 = 592 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_593 = 593 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_594 = 594 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_595 = 595 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_596 = 596 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_597 = 597 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_598 = 598 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_599 = 599 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_600 = 600 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_601 = 601 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_602 = 602 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_603 = 603 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_604 = 604 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_605 = 605 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_606 = 606 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_607 = 607 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_608 = 608 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_609 = 609 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_610 = 610 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_611 = 611 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_612 = 612 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_613 = 613 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_614 = 614 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_615 = 615 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_616 = 616 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_617 = 617 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_618 = 618 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_619 = 619 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_620 = 620 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_621 = 621 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_622 = 622 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_623 = 623 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_624 = 624 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_625 = 625 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_626 = 626 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_627 = 627 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_628 = 628 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_629 = 629 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_630 = 630 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_631 = 631 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_632 = 632 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_633 = 633 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_634 = 634 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_635 = 635 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_636 = 636 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_637 = 637 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_638 = 638 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_639 = 639 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_640 = 640 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_641 = 641 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_642 = 642 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_643 = 643 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_644 = 644 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_645 = 645 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_646 = 646 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_647 = 647 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_648 = 648 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_649 = 649 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_650 = 650 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_651 = 651 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_652 = 652 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_653 = 653 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_654 = 654 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_655 = 655 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_656 = 656 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_657 = 657 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_658 = 658 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_659 = 659 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_660 = 660 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_661 = 661 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_662 = 662 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_663 = 663 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_664 = 664 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_665 = 665 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_666 = 666 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_667 = 667 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_668 = 668 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_669 = 669 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_670 = 670 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_671 = 671 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_672 = 672 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_673 = 673 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_674 = 674 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_675 = 675 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_676 = 676 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_677 = 677 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_678 = 678 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_679 = 679 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_680 = 680 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_681 = 681 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_682 = 682 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_683 = 683 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_684 = 684 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_685 = 685 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_686 = 686 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_687 = 687 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_688 = 688 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_689 = 689 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_690 = 690 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_691 = 691 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_692 = 692 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_693 = 693 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_694 = 694 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_695 = 695 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_696 = 696 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_697 = 697 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_698 = 698 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_699 = 699 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_700 = 700 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_701 = 701 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_702 = 702 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_703 = 703 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_704 = 704 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_705 = 705 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_706 = 706 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_707 = 707 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_708 = 708 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_709 = 709 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_710 = 710 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_711 = 711 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_712 = 712 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_713 = 713 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_714 = 714 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_715 = 715 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_716 = 716 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_717 = 717 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_718 = 718 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_719 = 719 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_720 = 720 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_721 = 721 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_722 = 722 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_723 = 723 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_724 = 724 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_725 = 725 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_726 = 726 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_727 = 727 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_728 = 728 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_729 = 729 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_730 = 730 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_731 = 731 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_732 = 732 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_733 = 733 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_734 = 734 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_735 = 735 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_736 = 736 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_737 = 737 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_738 = 738 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_739 = 739 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_740 = 740 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_741 = 741 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_742 = 742 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_743 = 743 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_744 = 744 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_745 = 745 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_746 = 746 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_747 = 747 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_748 = 748 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_749 = 749 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_750 = 750 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_751 = 751 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_752 = 752 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_753 = 753 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_754 = 754 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_755 = 755 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_756 = 756 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_757 = 757 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_758 = 758 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_759 = 759 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_760 = 760 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_761 = 761 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_762 = 762 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_763 = 763 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_764 = 764 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_765 = 765 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_766 = 766 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_767 = 767 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_768 = 768 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_769 = 769 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_770 = 770 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_771 = 771 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_772 = 772 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_773 = 773 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_774 = 774 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_775 = 775 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_776 = 776 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_777 = 777 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_778 = 778 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_779 = 779 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_780 = 780 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_781 = 781 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_782 = 782 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_783 = 783 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_784 = 784 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_785 = 785 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_786 = 786 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_787 = 787 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_788 = 788 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_789 = 789 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_790 = 790 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_791 = 791 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_792 = 792 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_793 = 793 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_794 = 794 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_795 = 795 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_796 = 796 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_797 = 797 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_798 = 798 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_799 = 799 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_800 = 800 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_801 = 801 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_802 = 802 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_803 = 803 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_804 = 804 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_805 = 805 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_806 = 806 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_807 = 807 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_808 = 808 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_809 = 809 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_810 = 810 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_811 = 811 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_812 = 812 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_813 = 813 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_814 = 814 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_815 = 815 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_816 = 816 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_817 = 817 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_818 = 818 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_819 = 819 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_820 = 820 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_821 = 821 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_822 = 822 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_823 = 823 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_824 = 824 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_825 = 825 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_826 = 826 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_827 = 827 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_828 = 828 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_829 = 829 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_830 = 830 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_831 = 831 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_832 = 832 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_833 = 833 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_834 = 834 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_835 = 835 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_836 = 836 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_837 = 837 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_838 = 838 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_839 = 839 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_840 = 840 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_841 = 841 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_842 = 842 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_843 = 843 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_844 = 844 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_845 = 845 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_846 = 846 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_847 = 847 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_848 = 848 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_849 = 849 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_850 = 850 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_851 = 851 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_852 = 852 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_853 = 853 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_854 = 854 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_855 = 855 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_856 = 856 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_857 = 857 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_858 = 858 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_859 = 859 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_860 = 860 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_861 = 861 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_862 = 862 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_863 = 863 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_864 = 864 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_865 = 865 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_866 = 866 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_867 = 867 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_868 = 868 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_869 = 869 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_870 = 870 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_871 = 871 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_872 = 872 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_873 = 873 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_874 = 874 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_875 = 875 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_876 = 876 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_877 = 877 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_878 = 878 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_879 = 879 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_880 = 880 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_881 = 881 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_882 = 882 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_883 = 883 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_884 = 884 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_885 = 885 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_886 = 886 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_887 = 887 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_888 = 888 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_889 = 889 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_890 = 890 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_891 = 891 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_892 = 892 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_893 = 893 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_894 = 894 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_895 = 895 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_896 = 896 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_897 = 897 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_898 = 898 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_899 = 899 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_900 = 900 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_901 = 901 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_902 = 902 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_903 = 903 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_904 = 904 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_905 = 905 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_906 = 906 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_907 = 907 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_908 = 908 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_909 = 909 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_910 = 910 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_911 = 911 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_912 = 912 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_913 = 913 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_914 = 914 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_915 = 915 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_916 = 916 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_917 = 917 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_918 = 918 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_919 = 919 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_920 = 920 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_921 = 921 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_922 = 922 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_923 = 923 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_924 = 924 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_925 = 925 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_926 = 926 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_927 = 927 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_928 = 928 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_929 = 929 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_930 = 930 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_931 = 931 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_932 = 932 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_933 = 933 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_934 = 934 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_935 = 935 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_936 = 936 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_937 = 937 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_938 = 938 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_939 = 939 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_940 = 940 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_941 = 941 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_942 = 942 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_943 = 943 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_944 = 944 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_945 = 945 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_946 = 946 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_947 = 947 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_948 = 948 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_949 = 949 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_950 = 950 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_951 = 951 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_952 = 952 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_953 = 953 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_954 = 954 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_955 = 955 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_956 = 956 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_957 = 957 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_958 = 958 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_959 = 959 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_960 = 960 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_961 = 961 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_962 = 962 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_963 = 963 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_964 = 964 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_965 = 965 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_966 = 966 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_967 = 967 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_968 = 968 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_969 = 969 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_970 = 970 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_971 = 971 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_972 = 972 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_973 = 973 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_974 = 974 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_975 = 975 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_976 = 976 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_977 = 977 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_978 = 978 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_979 = 979 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_980 = 980 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_981 = 981 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_982 = 982 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_983 = 983 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_984 = 984 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_985 = 985 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_986 = 986 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_987 = 987 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_988 = 988 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_989 = 989 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_990 = 990 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_991 = 991 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_992 = 992 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_993 = 993 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_994 = 994 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_995 = 995 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_996 = 996 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_997 = 997 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_998 = 998 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_999 = 999 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-  optional string long_field_name_is_looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong_1000 = 1000 [default=""long default value is also loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong""];
-}
diff --git a/csharp/protos/google/protobuf/unittest_import.proto b/csharp/protos/google/protobuf/unittest_import.proto
deleted file mode 100644
index aa68c8645..000000000
--- a/csharp/protos/google/protobuf/unittest_import.proto
+++ /dev/null
@@ -1,67 +0,0 @@
-// Additional options required for C# generation. File from copyright
-// line onwards is as per original distribution.
-import ""google/protobuf/csharp_options.proto"";
-option (google.protobuf.csharp_file_options).namespace = ""Google.ProtocolBuffers.TestProtos"";
-option (google.protobuf.csharp_file_options).umbrella_classname = ""UnitTestImportProtoFile"";
-
-// Protocol Buffers - Google's data interchange format
-// Copyright 2008 Google Inc.  All rights reserved.
-// http://code.google.com/p/protobuf/
-//
-// Redistribution and use in source and binary forms, with or without
-// modification, are permitted provided that the following conditions are
-// met:
-//
-//     * Redistributions of source code must retain the above copyright
-// notice, this list of conditions and the following disclaimer.
-//     * Redistributions in binary form must reproduce the above
-// copyright notice, this list of conditions and the following disclaimer
-// in the documentation and/or other materials provided with the
-// distribution.
-//     * Neither the name of Google Inc. nor the names of its
-// contributors may be used to endorse or promote products derived from
-// this software without specific prior written permission.
-//
-// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-// ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
-// Author: kenton@google.com (Kenton Varda)
-//  Based on original Protocol Buffers design by
-//  Sanjay Ghemawat, Jeff Dean, and others.
-//
-// A proto file which is imported by unittest.proto to test importing.
-
-
-// We don't put this in a package within proto2 because we need to make sure
-// that the generated code doesn't depend on being in the proto2 namespace.
-// In test_util.h we do
-// ""using namespace unittest_import = protobuf_unittest_import"".
-package protobuf_unittest_import;
-
-option optimize_for = SPEED;
-
-// Excercise the java_package option.
-option java_package = ""com.google.protobuf.test"";
-
-// Do not set a java_outer_classname here to verify that Proto2 works without
-// one.
-
-message ImportMessage {
-  optional int32 d = 1;
-}
-
-enum ImportEnum {
-  IMPORT_FOO = 7;
-  IMPORT_BAR = 8;
-  IMPORT_BAZ = 9;
-}
-
diff --git a/csharp/protos/google/protobuf/unittest_import_lite.proto b/csharp/protos/google/protobuf/unittest_import_lite.proto
deleted file mode 100644
index d8755d0ee..000000000
--- a/csharp/protos/google/protobuf/unittest_import_lite.proto
+++ /dev/null
@@ -1,55 +0,0 @@
-// Additional options required for C# generation. File from copyright
-// line onwards is as per original distribution.
-import ""google/protobuf/csharp_options.proto"";
-option (google.protobuf.csharp_file_options).namespace = ""Google.ProtocolBuffers.TestProtos"";
-option (google.protobuf.csharp_file_options).umbrella_classname = ""UnitTestImportLiteProtoFile"";
-
-// Protocol Buffers - Google's data interchange format
-// Copyright 2008 Google Inc.  All rights reserved.
-// http://code.google.com/p/protobuf/
-//
-// Redistribution and use in source and binary forms, with or without
-// modification, are permitted provided that the following conditions are
-// met:
-//
-//     * Redistributions of source code must retain the above copyright
-// notice, this list of conditions and the following disclaimer.
-//     * Redistributions in binary form must reproduce the above
-// copyright notice, this list of conditions and the following disclaimer
-// in the documentation and/or other materials provided with the
-// distribution.
-//     * Neither the name of Google Inc. nor the names of its
-// contributors may be used to endorse or promote products derived from
-// this software without specific prior written permission.
-//
-// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-// ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
-// Author: kenton@google.com (Kenton Varda)
-//
-// This is like unittest_import.proto but with optimize_for = LITE_RUNTIME.
-
-package protobuf_unittest_import;
-
-option optimize_for = LITE_RUNTIME;
-
-option java_package = ""com.google.protobuf"";
-
-message ImportMessageLite {
-  optional int32 d = 1;
-}
-
-enum ImportEnumLite {
-  IMPORT_LITE_FOO = 7;
-  IMPORT_LITE_BAR = 8;
-  IMPORT_LITE_BAZ = 9;
-}
diff --git a/csharp/protos/google/protobuf/unittest_lite.proto b/csharp/protos/google/protobuf/unittest_lite.proto
deleted file mode 100644
index 823fa1dd1..000000000
--- a/csharp/protos/google/protobuf/unittest_lite.proto
+++ /dev/null
@@ -1,318 +0,0 @@
-// Additional options required for C# generation. File from copyright
-// line onwards is as per original distribution.
-import ""google/protobuf/csharp_options.proto"";
-option (google.protobuf.csharp_file_options).namespace = ""Google.ProtocolBuffers.TestProtos"";
-option (google.protobuf.csharp_file_options).umbrella_classname = ""UnitTestLiteProtoFile"";
-
-// Protocol Buffers - Google's data interchange format
-// Copyright 2008 Google Inc.  All rights reserved.
-// http://code.google.com/p/protobuf/
-//
-// Redistribution and use in source and binary forms, with or without
-// modification, are permitted provided that the following conditions are
-// met:
-//
-//     * Redistributions of source code must retain the above copyright
-// notice, this list of conditions and the following disclaimer.
-//     * Redistributions in binary form must reproduce the above
-// copyright notice, this list of conditions and the following disclaimer
-// in the documentation and/or other materials provided with the
-// distribution.
-//     * Neither the name of Google Inc. nor the names of its
-// contributors may be used to endorse or promote products derived from
-// this software without specific prior written permission.
-//
-// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-// ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
-// Author: kenton@google.com (Kenton Varda)
-//
-// This is like unittest.proto but with optimize_for = LITE_RUNTIME.
-
-package protobuf_unittest;
-
-import ""google/protobuf/unittest_import_lite.proto"";
-
-option optimize_for = LITE_RUNTIME;
-
-option java_package = ""com.google.protobuf"";
-
-// Same as TestAllTypes but with the lite runtime.
-message TestAllTypesLite {
-  message NestedMessage {
-    optional int32 bb = 1;
-  }
-
-  enum NestedEnum {
-    FOO = 1;
-    BAR = 2;
-    BAZ = 3;
-  }
-
-  // Singular
-  optional    int32 optional_int32    =  1;
-  optional    int64 optional_int64    =  2;
-  optional   uint32 optional_uint32   =  3;
-  optional   uint64 optional_uint64   =  4;
-  optional   sint32 optional_sint32   =  5;
-  optional   sint64 optional_sint64   =  6;
-  optional  fixed32 optional_fixed32  =  7;
-  optional  fixed64 optional_fixed64  =  8;
-  optional sfixed32 optional_sfixed32 =  9;
-  optional sfixed64 optional_sfixed64 = 10;
-  optional    float optional_float    = 11;
-  optional   double optional_double   = 12;
-  optional     bool optional_bool     = 13;
-  optional   string optional_string   = 14;
-  optional    bytes optional_bytes    = 15;
-
-  optional group OptionalGroup = 16 {
-    optional int32 a = 17;
-  }
-
-  optional NestedMessage      optional_nested_message  = 18;
-  optional ForeignMessageLite optional_foreign_message = 19;
-  optional protobuf_unittest_import.ImportMessageLite
-    optional_import_message = 20;
-
-  optional NestedEnum      optional_nested_enum     = 21;
-  optional ForeignEnumLite optional_foreign_enum    = 22;
-  optional protobuf_unittest_import.ImportEnumLite optional_import_enum = 23;
-
-  optional string optional_string_piece = 24 [ctype=STRING_PIECE];
-  optional string optional_cord = 25 [ctype=CORD];
-
-  // Repeated
-  repeated    int32 repeated_int32    = 31;
-  repeated    int64 repeated_int64    = 32;
-  repeated   uint32 repeated_uint32   = 33;
-  repeated   uint64 repeated_uint64   = 34;
-  repeated   sint32 repeated_sint32   = 35;
-  repeated   sint64 repeated_sint64   = 36;
-  repeated  fixed32 repeated_fixed32  = 37;
-  repeated  fixed64 repeated_fixed64  = 38;
-  repeated sfixed32 repeated_sfixed32 = 39;
-  repeated sfixed64 repeated_sfixed64 = 40;
-  repeated    float repeated_float    = 41;
-  repeated   double repeated_double   = 42;
-  repeated     bool repeated_bool     = 43;
-  repeated   string repeated_string   = 44;
-  repeated    bytes repeated_bytes    = 45;
-
-  repeated group RepeatedGroup = 46 {
-    optional int32 a = 47;
-  }
-
-  repeated NestedMessage      repeated_nested_message  = 48;
-  repeated ForeignMessageLite repeated_foreign_message = 49;
-  repeated protobuf_unittest_import.ImportMessageLite
-    repeated_import_message = 50;
-
-  repeated NestedEnum      repeated_nested_enum  = 51;
-  repeated ForeignEnumLite repeated_foreign_enum = 52;
-  repeated protobuf_unittest_import.ImportEnumLite repeated_import_enum = 53;
-
-  repeated string repeated_string_piece = 54 [ctype=STRING_PIECE];
-  repeated string repeated_cord = 55 [ctype=CORD];
-
-  // Singular with defaults
-  optional    int32 default_int32    = 61 [default =  41    ];
-  optional    int64 default_int64    = 62 [default =  42    ];
-  optional   uint32 default_uint32   = 63 [default =  43    ];
-  optional   uint64 default_uint64   = 64 [default =  44    ];
-  optional   sint32 default_sint32   = 65 [default = -45    ];
-  optional   sint64 default_sint64   = 66 [default =  46    ];
-  optional  fixed32 default_fixed32  = 67 [default =  47    ];
-  optional  fixed64 default_fixed64  = 68 [default =  48    ];
-  optional sfixed32 default_sfixed32 = 69 [default =  49    ];
-  optional sfixed64 default_sfixed64 = 70 [default = -50    ];
-  optional    float default_float    = 71 [default =  51.5  ];
-  optional   double default_double   = 72 [default =  52e3  ];
-  optional     bool default_bool     = 73 [default = true   ];
-  optional   string default_string   = 74 [default = ""hello""];
-  optional    bytes default_bytes    = 75 [default = ""world""];
-
-  optional NestedEnum default_nested_enum = 81 [default = BAR];
-  optional ForeignEnumLite default_foreign_enum = 82
-      [default = FOREIGN_LITE_BAR];
-  optional protobuf_unittest_import.ImportEnumLite
-      default_import_enum = 83 [default = IMPORT_LITE_BAR];
-
-  optional string default_string_piece = 84 [ctype=STRING_PIECE,default=""abc""];
-  optional string default_cord = 85 [ctype=CORD,default=""123""];
-}
-
-message ForeignMessageLite {
-  optional int32 c = 1;
-}
-
-enum ForeignEnumLite {
-  FOREIGN_LITE_FOO = 4;
-  FOREIGN_LITE_BAR = 5;
-  FOREIGN_LITE_BAZ = 6;
-}
-
-message TestPackedTypesLite {
-  repeated    int32 packed_int32    =  90 [packed = true];
-  repeated    int64 packed_int64    =  91 [packed = true];
-  repeated   uint32 packed_uint32   =  92 [packed = true];
-  repeated   uint64 packed_uint64   =  93 [packed = true];
-  repeated   sint32 packed_sint32   =  94 [packed = true];
-  repeated   sint64 packed_sint64   =  95 [packed = true];
-  repeated  fixed32 packed_fixed32  =  96 [packed = true];
-  repeated  fixed64 packed_fixed64  =  97 [packed = true];
-  repeated sfixed32 packed_sfixed32 =  98 [packed = true];
-  repeated sfixed64 packed_sfixed64 =  99 [packed = true];
-  repeated    float packed_float    = 100 [packed = true];
-  repeated   double packed_double   = 101 [packed = true];
-  repeated     bool packed_bool     = 102 [packed = true];
-  repeated ForeignEnumLite packed_enum  = 103 [packed = true];
-}
-
-message TestAllExtensionsLite {
-  extensions 1 to max;
-}
-
-extend TestAllExtensionsLite {
-  // Singular
-  optional    int32 optional_int32_extension_lite    =  1;
-  optional    int64 optional_int64_extension_lite    =  2;
-  optional   uint32 optional_uint32_extension_lite   =  3;
-  optional   uint64 optional_uint64_extension_lite   =  4;
-  optional   sint32 optional_sint32_extension_lite   =  5;
-  optional   sint64 optional_sint64_extension_lite   =  6;
-  optional  fixed32 optional_fixed32_extension_lite  =  7;
-  optional  fixed64 optional_fixed64_extension_lite  =  8;
-  optional sfixed32 optional_sfixed32_extension_lite =  9;
-  optional sfixed64 optional_sfixed64_extension_lite = 10;
-  optional    float optional_float_extension_lite    = 11;
-  optional   double optional_double_extension_lite   = 12;
-  optional     bool optional_bool_extension_lite     = 13;
-  optional   string optional_string_extension_lite   = 14;
-  optional    bytes optional_bytes_extension_lite    = 15;
-
-  optional group OptionalGroup_extension_lite = 16 {
-    optional int32 a = 17;
-  }
-
-  optional TestAllTypesLite.NestedMessage optional_nested_message_extension_lite
-      = 18;
-  optional ForeignMessageLite optional_foreign_message_extension_lite = 19;
-  optional protobuf_unittest_import.ImportMessageLite
-    optional_import_message_extension_lite = 20;
-
-  optional TestAllTypesLite.NestedEnum optional_nested_enum_extension_lite = 21;
-  optional ForeignEnumLite optional_foreign_enum_extension_lite = 22;
-  optional protobuf_unittest_import.ImportEnumLite
-    optional_import_enum_extension_lite = 23;
-
-  optional string optional_string_piece_extension_lite = 24
-      [ctype=STRING_PIECE];
-  optional string optional_cord_extension_lite = 25 [ctype=CORD];
-
-  // Repeated
-  repeated    int32 repeated_int32_extension_lite    = 31;
-  repeated    int64 repeated_int64_extension_lite    = 32;
-  repeated   uint32 repeated_uint32_extension_lite   = 33;
-  repeated   uint64 repeated_uint64_extension_lite   = 34;
-  repeated   sint32 repeated_sint32_extension_lite   = 35;
-  repeated   sint64 repeated_sint64_extension_lite   = 36;
-  repeated  fixed32 repeated_fixed32_extension_lite  = 37;
-  repeated  fixed64 repeated_fixed64_extension_lite  = 38;
-  repeated sfixed32 repeated_sfixed32_extension_lite = 39;
-  repeated sfixed64 repeated_sfixed64_extension_lite = 40;
-  repeated    float repeated_float_extension_lite    = 41;
-  repeated   double repeated_double_extension_lite   = 42;
-  repeated     bool repeated_bool_extension_lite     = 43;
-  repeated   string repeated_string_extension_lite   = 44;
-  repeated    bytes repeated_bytes_extension_lite    = 45;
-
-  repeated group RepeatedGroup_extension_lite = 46 {
-    optional int32 a = 47;
-  }
-
-  repeated TestAllTypesLite.NestedMessage repeated_nested_message_extension_lite
-      = 48;
-  repeated ForeignMessageLite repeated_foreign_message_extension_lite = 49;
-  repeated protobuf_unittest_import.ImportMessageLite
-    repeated_import_message_extension_lite = 50;
-
-  repeated TestAllTypesLite.NestedEnum repeated_nested_enum_extension_lite = 51;
-  repeated ForeignEnumLite repeated_foreign_enum_extension_lite = 52;
-  repeated protobuf_unittest_import.ImportEnumLite
-    repeated_import_enum_extension_lite = 53;
-
-  repeated string repeated_string_piece_extension_lite = 54
-      [ctype=STRING_PIECE];
-  repeated string repeated_cord_extension_lite = 55 [ctype=CORD];
-
-  // Singular with defaults
-  optional    int32 default_int32_extension_lite    = 61 [default =  41    ];
-  optional    int64 default_int64_extension_lite    = 62 [default =  42    ];
-  optional   uint32 default_uint32_extension_lite   = 63 [default =  43    ];
-  optional   uint64 default_uint64_extension_lite   = 64 [default =  44    ];
-  optional   sint32 default_sint32_extension_lite   = 65 [default = -45    ];
-  optional   sint64 default_sint64_extension_lite   = 66 [default =  46    ];
-  optional  fixed32 default_fixed32_extension_lite  = 67 [default =  47    ];
-  optional  fixed64 default_fixed64_extension_lite  = 68 [default =  48    ];
-  optional sfixed32 default_sfixed32_extension_lite = 69 [default =  49    ];
-  optional sfixed64 default_sfixed64_extension_lite = 70 [default = -50    ];
-  optional    float default_float_extension_lite    = 71 [default =  51.5  ];
-  optional   double default_double_extension_lite   = 72 [default =  52e3  ];
-  optional     bool default_bool_extension_lite     = 73 [default = true   ];
-  optional   string default_string_extension_lite   = 74 [default = ""hello""];
-  optional    bytes default_bytes_extension_lite    = 75 [default = ""world""];
-
-  optional TestAllTypesLite.NestedEnum
-    default_nested_enum_extension_lite = 81 [default = BAR];
-  optional ForeignEnumLite
-    default_foreign_enum_extension_lite = 82 [default = FOREIGN_LITE_BAR];
-  optional protobuf_unittest_import.ImportEnumLite
-    default_import_enum_extension_lite = 83 [default = IMPORT_LITE_BAR];
-
-  optional string default_string_piece_extension_lite = 84 [ctype=STRING_PIECE,
-                                                            default=""abc""];
-  optional string default_cord_extension_lite = 85 [ctype=CORD, default=""123""];
-}
-
-message TestPackedExtensionsLite {
-  extensions 1 to max;
-}
-
-extend TestPackedExtensionsLite {
-  repeated    int32 packed_int32_extension_lite    =  90 [packed = true];
-  repeated    int64 packed_int64_extension_lite    =  91 [packed = true];
-  repeated   uint32 packed_uint32_extension_lite   =  92 [packed = true];
-  repeated   uint64 packed_uint64_extension_lite   =  93 [packed = true];
-  repeated   sint32 packed_sint32_extension_lite   =  94 [packed = true];
-  repeated   sint64 packed_sint64_extension_lite   =  95 [packed = true];
-  repeated  fixed32 packed_fixed32_extension_lite  =  96 [packed = true];
-  repeated  fixed64 packed_fixed64_extension_lite  =  97 [packed = true];
-  repeated sfixed32 packed_sfixed32_extension_lite =  98 [packed = true];
-  repeated sfixed64 packed_sfixed64_extension_lite =  99 [packed = true];
-  repeated    float packed_float_extension_lite    = 100 [packed = true];
-  repeated   double packed_double_extension_lite   = 101 [packed = true];
-  repeated     bool packed_bool_extension_lite     = 102 [packed = true];
-  repeated ForeignEnumLite packed_enum_extension_lite = 103 [packed = true];
-}
-
-message TestNestedExtensionLite {
-  extend TestAllExtensionsLite {
-    optional int32 nested_extension = 12345;
-  }
-}
-
-// Test that deprecated fields work.  We only verify that they compile (at one
-// point this failed).
-message TestDeprecatedLite {
-  optional int32 deprecated_field = 1 [deprecated = true];
-}
diff --git a/csharp/protos/google/protobuf/unittest_lite_imports_nonlite.proto b/csharp/protos/google/protobuf/unittest_lite_imports_nonlite.proto
deleted file mode 100644
index 8f18f4d68..000000000
--- a/csharp/protos/google/protobuf/unittest_lite_imports_nonlite.proto
+++ /dev/null
@@ -1,49 +0,0 @@
-// Additional options required for C# generation. File from copyright
-// line onwards is as per original distribution.
-import ""google/protobuf/csharp_options.proto"";
-option (google.protobuf.csharp_file_options).namespace = ""Google.ProtocolBuffers.TestProtos"";
-option (google.protobuf.csharp_file_options).umbrella_classname = ""UnitTestLiteImportNonLiteProtoFile"";
-
-// Protocol Buffers - Google's data interchange format
-// Copyright 2008 Google Inc.  All rights reserved.
-// http://code.google.com/p/protobuf/
-//
-// Redistribution and use in source and binary forms, with or without
-// modification, are permitted provided that the following conditions are
-// met:
-//
-//     * Redistributions of source code must retain the above copyright
-// notice, this list of conditions and the following disclaimer.
-//     * Redistributions in binary form must reproduce the above
-// copyright notice, this list of conditions and the following disclaimer
-// in the documentation and/or other materials provided with the
-// distribution.
-//     * Neither the name of Google Inc. nor the names of its
-// contributors may be used to endorse or promote products derived from
-// this software without specific prior written permission.
-//
-// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-// ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
-// Author: kenton@google.com (Kenton Varda)
-//
-// Tests that a ""lite"" message can import a regular message.
-
-package protobuf_unittest;
-
-import ""google/protobuf/unittest.proto"";
-
-option optimize_for = LITE_RUNTIME;
-
-message TestLiteImportsNonlite {
-  optional TestAllTypes message = 1;
-}
diff --git a/csharp/protos/google/protobuf/unittest_mset.proto b/csharp/protos/google/protobuf/unittest_mset.proto
deleted file mode 100644
index 8c74ef4b3..000000000
--- a/csharp/protos/google/protobuf/unittest_mset.proto
+++ /dev/null
@@ -1,78 +0,0 @@
-// Additional options required for C# generation. File from copyright
-// line onwards is as per original distribution.
-import ""google/protobuf/csharp_options.proto"";
-option (google.protobuf.csharp_file_options).namespace = ""Google.ProtocolBuffers.TestProtos"";
-option (google.protobuf.csharp_file_options).umbrella_classname = ""UnitTestMessageSetProtoFile"";
-
-// Protocol Buffers - Google's data interchange format
-// Copyright 2008 Google Inc.  All rights reserved.
-// http://code.google.com/p/protobuf/
-//
-// Redistribution and use in source and binary forms, with or without
-// modification, are permitted provided that the following conditions are
-// met:
-//
-//     * Redistributions of source code must retain the above copyright
-// notice, this list of conditions and the following disclaimer.
-//     * Redistributions in binary form must reproduce the above
-// copyright notice, this list of conditions and the following disclaimer
-// in the documentation and/or other materials provided with the
-// distribution.
-//     * Neither the name of Google Inc. nor the names of its
-// contributors may be used to endorse or promote products derived from
-// this software without specific prior written permission.
-//
-// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-// ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
-// Author: kenton@google.com (Kenton Varda)
-//  Based on original Protocol Buffers design by
-//  Sanjay Ghemawat, Jeff Dean, and others.
-//
-// This file contains messages for testing message_set_wire_format.
-
-package protobuf_unittest;
-
-option optimize_for = SPEED;
-
-// A message with message_set_wire_format.
-message TestMessageSet {
-  option message_set_wire_format = true;
-  extensions 4 to max;
-}
-
-message TestMessageSetContainer {
-  optional TestMessageSet message_set = 1;
-}
-
-message TestMessageSetExtension1 {
-  extend TestMessageSet {
-    optional TestMessageSetExtension1 message_set_extension = 1545008;
-  }
-  optional int32 i = 15;
-}
-
-message TestMessageSetExtension2 {
-  extend TestMessageSet {
-    optional TestMessageSetExtension2 message_set_extension = 1547769;
-  }
-  optional string str = 25;
-}
-
-// MessageSet wire format is equivalent to this.
-message RawMessageSet {
-  repeated group Item = 1 {
-    required int32 type_id = 2;
-    required bytes message = 3;
-  }
-}
-
diff --git a/csharp/protos/google/protobuf/unittest_no_generic_services.proto b/csharp/protos/google/protobuf/unittest_no_generic_services.proto
deleted file mode 100644
index 5ab533bf4..000000000
--- a/csharp/protos/google/protobuf/unittest_no_generic_services.proto
+++ /dev/null
@@ -1,58 +0,0 @@
-// Additional options required for C# generation. File from copyright
-// line onwards is as per original distribution.
-import ""google/protobuf/csharp_options.proto"";
-option (google.protobuf.csharp_file_options).namespace = ""Google.ProtocolBuffers.TestProtos.NoGenericService"";
-option (google.protobuf.csharp_file_options).umbrella_classname = ""UnitTestNoGenericServicesProtoFile"";
-
-// Protocol Buffers - Google's data interchange format
-// Copyright 2008 Google Inc.  All rights reserved.
-// http://code.google.com/p/protobuf/
-//
-// Redistribution and use in source and binary forms, with or without
-// modification, are permitted provided that the following conditions are
-// met:
-//
-//     * Redistributions of source code must retain the above copyright
-// notice, this list of conditions and the following disclaimer.
-//     * Redistributions in binary form must reproduce the above
-// copyright notice, this list of conditions and the following disclaimer
-// in the documentation and/or other materials provided with the
-// distribution.
-//     * Neither the name of Google Inc. nor the names of its
-// contributors may be used to endorse or promote products derived from
-// this software without specific prior written permission.
-//
-// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-// ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
-// Author: kenton@google.com (Kenton Varda)
-
-package google.protobuf.no_generic_services_test;
-
-// *_generic_services are false by default.
-
-message TestMessage {
-  optional int32 a = 1;
-  extensions 1000 to max;
-}
-
-enum TestEnum {
-  FOO = 1;
-}
-
-extend TestMessage {
-  optional int32 test_extension = 1000;
-}
-
-service TestService {
-  rpc Foo(TestMessage) returns(TestMessage);
-}
diff --git a/csharp/protos/google/protobuf/unittest_optimize_for.proto b/csharp/protos/google/protobuf/unittest_optimize_for.proto
deleted file mode 100644
index 99efad647..000000000
--- a/csharp/protos/google/protobuf/unittest_optimize_for.proto
+++ /dev/null
@@ -1,67 +0,0 @@
-// Additional options required for C# generation. File from copyright
-// line onwards is as per original distribution.
-import ""google/protobuf/csharp_options.proto"";
-option (google.protobuf.csharp_file_options).namespace = ""Google.ProtocolBuffers.TestProtos"";
-option (google.protobuf.csharp_file_options).umbrella_classname = ""UnitTestOptimizeForProtoFile"";
-
-// Protocol Buffers - Google's data interchange format
-// Copyright 2008 Google Inc.  All rights reserved.
-// http://code.google.com/p/protobuf/
-//
-// Redistribution and use in source and binary forms, with or without
-// modification, are permitted provided that the following conditions are
-// met:
-//
-//     * Redistributions of source code must retain the above copyright
-// notice, this list of conditions and the following disclaimer.
-//     * Redistributions in binary form must reproduce the above
-// copyright notice, this list of conditions and the following disclaimer
-// in the documentation and/or other materials provided with the
-// distribution.
-//     * Neither the name of Google Inc. nor the names of its
-// contributors may be used to endorse or promote products derived from
-// this software without specific prior written permission.
-//
-// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-// ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
-// Author: kenton@google.com (Kenton Varda)
-//  Based on original Protocol Buffers design by
-//  Sanjay Ghemawat, Jeff Dean, and others.
-//
-// A proto file which uses optimize_for = CODE_SIZE.
-
-import ""google/protobuf/unittest.proto"";
-
-package protobuf_unittest;
-
-option optimize_for = CODE_SIZE;
-
-message TestOptimizedForSize {
-  optional int32 i = 1;
-  optional ForeignMessage msg = 19;
-
-  extensions 1000 to max;
-
-  extend TestOptimizedForSize {
-    optional int32 test_extension = 1234;
-    optional TestRequiredOptimizedForSize test_extension2 = 1235;
-  }
-}
-
-message TestRequiredOptimizedForSize {
-  required int32 x = 1;
-}
- 
-message TestOptionalOptimizedForSize {
-  optional TestRequiredOptimizedForSize o = 1;
-}
diff --git a/csharp/protos/google/test/google_size.proto b/csharp/protos/google/test/google_size.proto
deleted file mode 100644
index 2e777df26..000000000
--- a/csharp/protos/google/test/google_size.proto
+++ /dev/null
@@ -1,140 +0,0 @@
-package unittest_google_size;
-
-import ""google/protobuf/csharp_options.proto"";
-option (google.protobuf.csharp_file_options).namespace = ""Google.ProtocolBuffers.TestProtos"";
-option (google.protobuf.csharp_file_options).umbrella_classname = ""UnitTestGoogleSizeProtoFile"";
-
-option java_outer_classname = ""GoogleSize"";
-option optimize_for = CODE_SIZE;
-
-message SizeMessage1 {
-  required string field1 = 1;
-  optional string field9 = 9;
-  optional string field18 = 18;
-  optional bool field80 = 80 [default=false];
-  optional bool field81 = 81 [default=true];
-  required int32 field2 = 2;
-  required int32 field3 = 3;
-  optional int32 field280 = 280;
-  optional int32 field6 = 6 [default=0];
-  optional int64 field22 = 22;
-  optional string field4 = 4;
-  repeated fixed64 field5 = 5;
-  optional bool field59 = 59 [default=false];
-  optional string field7 = 7;
-  optional int32 field16 = 16;
-  optional int32 field130 = 130 [default=0];
-  optional bool field12 = 12 [default=true];
-  optional bool field17 = 17 [default=true];
-  optional bool field13 = 13 [default=true];
-  optional bool field14 = 14 [default=true];
-  optional int32 field104 = 104 [default=0];
-  optional int32 field100 = 100 [default=0];
-  optional int32 field101 = 101 [default=0];
-  optional string field102 = 102;
-  optional string field103 = 103;
-  optional int32 field29 = 29 [default=0];
-  optional bool field30 = 30 [default=false];
-  optional int32 field60 = 60 [default=-1];
-  optional int32 field271 = 271 [default=-1];
-  optional int32 field272 = 272 [default=-1];
-  optional int32 field150 = 150;
-  optional int32 field23 = 23 [default=0];
-  optional bool field24 = 24 [default=false];
-  optional int32 field25 = 25 [default=0];
-  optional SizeMessage1SubMessage field15 = 15;
-  optional bool field78 = 78;
-  optional int32 field67 = 67 [default=0];
-  optional int32 field68 = 68;
-  optional int32 field128 = 128 [default=0];
-  optional string field129 = 129 [default=""xxxxxxxxxxxxxxxxxxxxx""];
-  optional int32 field131 = 131 [default=0];
-}
-
-message SizeMessage1SubMessage {
-  optional int32 field1 = 1 [default=0];
-  optional int32 field2 = 2 [default=0];
-  optional int32 field3 = 3 [default=0];
-  optional string field15 = 15;
-  optional bool field12 = 12 [default=true];
-  optional int64 field13 = 13;
-  optional int64 field14 = 14;
-  optional int32 field16 = 16;
-  optional int32 field19 = 19 [default=2];
-  optional bool field20  = 20 [default=true];
-  optional bool field28 = 28 [default=true];
-  optional fixed64 field21 = 21;
-  optional int32 field22 = 22;
-  optional bool field23 = 23 [ default=false ];
-  optional bool field206 = 206 [default=false];
-  optional fixed32 field203 = 203;
-  optional int32 field204 = 204;
-  optional string field205 = 205;
-  optional uint64 field207 = 207;
-  optional uint64 field300 = 300;
-}
-
-message SizeMessage2 {
-  optional string field1 = 1;
-  optional int64 field3 = 3;
-  optional int64 field4 = 4;
-  optional int64 field30 = 30;
-  optional bool field75  = 75 [default=false];
-  optional string field6 = 6;
-  optional bytes field2 = 2;
-  optional int32 field21 = 21 [default=0];
-  optional int32 field71 = 71;
-  optional float field25 = 25;
-  optional int32 field109 = 109 [default=0];
-  optional int32 field210 = 210 [default=0];
-  optional int32 field211 = 211 [default=0];
-  optional int32 field212 = 212 [default=0];
-  optional int32 field213 = 213 [default=0];
-  optional int32 field216 = 216 [default=0];
-  optional int32 field217 = 217 [default=0];
-  optional int32 field218 = 218 [default=0];
-  optional int32 field220 = 220 [default=0];
-  optional int32 field221 = 221 [default=0];
-  optional float field222 = 222 [default=0.0];
-  optional int32 field63 = 63;
-
-  repeated group Group1 = 10 {
-    required float field11 = 11;
-    optional float field26 = 26;
-    optional string field12 = 12;
-    optional string field13 = 13;
-    repeated string field14 = 14;
-    required uint64 field15 = 15;
-    optional int32 field5 = 5;
-    optional string field27 = 27;
-    optional int32 field28 = 28;
-    optional string field29 = 29;
-    optional string field16 = 16;
-    repeated string field22 = 22;
-    repeated int32 field73 = 73;
-    optional int32 field20 = 20 [default=0];
-    optional string field24 = 24;
-    optional SizeMessage2GroupedMessage field31 = 31;
-  }
-  repeated string field128 = 128;
-  optional int64 field131 = 131;
-  repeated string field127 = 127;
-  optional int32 field129 = 129;
-  repeated int64 field130 = 130;
-  optional bool field205 = 205 [default=false];
-  optional bool field206 = 206 [default=false];
-}
-
-message SizeMessage2GroupedMessage {
-  optional float field1 = 1;
-  optional float field2 = 2;
-  optional float field3 = 3 [default=0.0];
-  optional bool field4 = 4;
-  optional bool field5 = 5;
-  optional bool field6 = 6 [default=true];
-  optional bool field7 = 7 [default=false];
-  optional float field8 = 8;
-  optional bool field9 = 9;
-  optional float field10 = 10;
-  optional int64 field11 = 11;
-}
diff --git a/csharp/protos/google/test/google_speed.proto b/csharp/protos/google/test/google_speed.proto
deleted file mode 100644
index eef2a07e5..000000000
--- a/csharp/protos/google/test/google_speed.proto
+++ /dev/null
@@ -1,140 +0,0 @@
-package unittest_google_speed;
-
-import ""google/protobuf/csharp_options.proto"";
-option (google.protobuf.csharp_file_options).namespace = ""Google.ProtocolBuffers.TestProtos"";
-option (google.protobuf.csharp_file_options).umbrella_classname = ""UnitTestGoogleSpeedProtoFile"";
-
-option java_outer_classname = ""GoogleSpeed"";
-option optimize_for = SPEED;
-
-message SpeedMessage1 {
-  required string field1 = 1;
-  optional string field9 = 9;
-  optional string field18 = 18;
-  optional bool field80 = 80 [default=false];
-  optional bool field81 = 81 [default=true];
-  required int32 field2 = 2;
-  required int32 field3 = 3;
-  optional int32 field280 = 280;
-  optional int32 field6 = 6 [default=0];
-  optional int64 field22 = 22;
-  optional string field4 = 4;
-  repeated fixed64 field5 = 5;
-  optional bool field59 = 59 [default=false];
-  optional string field7 = 7;
-  optional int32 field16 = 16;
-  optional int32 field130 = 130 [default=0];
-  optional bool field12 = 12 [default=true];
-  optional bool field17 = 17 [default=true];
-  optional bool field13 = 13 [default=true];
-  optional bool field14 = 14 [default=true];
-  optional int32 field104 = 104 [default=0];
-  optional int32 field100 = 100 [default=0];
-  optional int32 field101 = 101 [default=0];
-  optional string field102 = 102;
-  optional string field103 = 103;
-  optional int32 field29 = 29 [default=0];
-  optional bool field30 = 30 [default=false];
-  optional int32 field60 = 60 [default=-1];
-  optional int32 field271 = 271 [default=-1];
-  optional int32 field272 = 272 [default=-1];
-  optional int32 field150 = 150;
-  optional int32 field23 = 23 [default=0];
-  optional bool field24 = 24 [default=false];
-  optional int32 field25 = 25 [default=0];
-  optional SpeedMessage1SubMessage field15 = 15;
-  optional bool field78 = 78;
-  optional int32 field67 = 67 [default=0];
-  optional int32 field68 = 68;
-  optional int32 field128 = 128 [default=0];
-  optional string field129 = 129 [default=""xxxxxxxxxxxxxxxxxxxxx""];
-  optional int32 field131 = 131 [default=0];
-}
-
-message SpeedMessage1SubMessage {
-  optional int32 field1 = 1 [default=0];
-  optional int32 field2 = 2 [default=0];
-  optional int32 field3 = 3 [default=0];
-  optional string field15 = 15;
-  optional bool field12 = 12 [default=true];
-  optional int64 field13 = 13;
-  optional int64 field14 = 14;
-  optional int32 field16 = 16;
-  optional int32 field19 = 19 [default=2];
-  optional bool field20  = 20 [default=true];
-  optional bool field28 = 28 [default=true];
-  optional fixed64 field21 = 21;
-  optional int32 field22 = 22;
-  optional bool field23 = 23 [ default=false ];
-  optional bool field206 = 206 [default=false];
-  optional fixed32 field203 = 203;
-  optional int32 field204 = 204;
-  optional string field205 = 205;
-  optional uint64 field207 = 207;
-  optional uint64 field300 = 300;
-}
-
-message SpeedMessage2 {
-  optional string field1 = 1;
-  optional int64 field3 = 3;
-  optional int64 field4 = 4;
-  optional int64 field30 = 30;
-  optional bool field75  = 75 [default=false];
-  optional string field6 = 6;
-  optional bytes field2 = 2;
-  optional int32 field21 = 21 [default=0];
-  optional int32 field71 = 71;
-  optional float field25 = 25;
-  optional int32 field109 = 109 [default=0];
-  optional int32 field210 = 210 [default=0];
-  optional int32 field211 = 211 [default=0];
-  optional int32 field212 = 212 [default=0];
-  optional int32 field213 = 213 [default=0];
-  optional int32 field216 = 216 [default=0];
-  optional int32 field217 = 217 [default=0];
-  optional int32 field218 = 218 [default=0];
-  optional int32 field220 = 220 [default=0];
-  optional int32 field221 = 221 [default=0];
-  optional float field222 = 222 [default=0.0];
-  optional int32 field63 = 63;
-
-  repeated group Group1 = 10 {
-    required float field11 = 11;
-    optional float field26 = 26;
-    optional string field12 = 12;
-    optional string field13 = 13;
-    repeated string field14 = 14;
-    required uint64 field15 = 15;
-    optional int32 field5 = 5;
-    optional string field27 = 27;
-    optional int32 field28 = 28;
-    optional string field29 = 29;
-    optional string field16 = 16;
-    repeated string field22 = 22;
-    repeated int32 field73 = 73;
-    optional int32 field20 = 20 [default=0];
-    optional string field24 = 24;
-    optional SpeedMessage2GroupedMessage field31 = 31;
-  }
-  repeated string field128 = 128;
-  optional int64 field131 = 131;
-  repeated string field127 = 127;
-  optional int32 field129 = 129;
-  repeated int64 field130 = 130;
-  optional bool field205 = 205 [default=false];
-  optional bool field206 = 206 [default=false];
-}
-
-message SpeedMessage2GroupedMessage {
-  optional float field1 = 1;
-  optional float field2 = 2;
-  optional float field3 = 3 [default=0.0];
-  optional bool field4 = 4;
-  optional bool field5 = 5;
-  optional bool field6 = 6 [default=true];
-  optional bool field7 = 7 [default=false];
-  optional float field8 = 8;
-  optional bool field9 = 9;
-  optional float field10 = 10;
-  optional int64 field11 = 11;
-}
diff --git a/csharp/protos/npp.language.xml b/csharp/protos/npp.language.xml
deleted file mode 100644
index c6122180a..000000000
--- a/csharp/protos/npp.language.xml
+++ /dev/null
@@ -1,44 +0,0 @@
-<NotepadPlus>
-<!--
-Defines syntax highlighting for Notepad++.
-1. Install Notepad++ from http://notepad-plus-plus.org
-2. Open Notepad++, from the View menu, select ""User-Defined Dialog...""
-3. Click the ""Import..."" button and select this file
-4. Restart Notepad++
-5. Open and edit any *.proto file
--->
-    <UserLang name=""Proto Buffer"" ext=""proto"">
-        <Settings>
-            <Global caseIgnored=""no"" />
-            <TreatAsSymbol comment=""no"" commentLine=""yes"" />
-            <Prefix words1=""no"" words2=""no"" words3=""no"" words4=""yes"" />
-        </Settings>
-        <KeywordLists>
-            <Keywords name=""Delimiters"">[00]00</Keywords>
-            <Keywords name=""Folder+"">{</Keywords>
-            <Keywords name=""Folder-"">}</Keywords>
-            <Keywords name=""Operators"">=</Keywords>
-            <Keywords name=""Comment""> 1option 1package 1import 2; 0//</Keywords>
-            <Keywords name=""Words1"">message enum service extend</Keywords>
-            <Keywords name=""Words2"">required optional repeated extensions to rpc returns</Keywords>
-            <Keywords name=""Words3"">double float int32 int64 uint32 uint64 sint32 sint64 fixed32 fixed64 sfixed32 sfixed64 bool string bytes</Keywords>
-            <Keywords name=""Words4""></Keywords>
-        </KeywordLists>
-        <Styles>
-            <WordsStyle name=""DEFAULT"" styleID=""11"" fgColor=""000000"" bgColor=""FFFFFF"" fontStyle=""0"" />
-            <WordsStyle name=""FOLDEROPEN"" styleID=""12"" fgColor=""000000"" bgColor=""FFFFFF"" fontStyle=""1"" />
-            <WordsStyle name=""FOLDERCLOSE"" styleID=""13"" fgColor=""000000"" bgColor=""FFFFFF"" fontStyle=""1"" />
-            <WordsStyle name=""KEYWORD1"" styleID=""5"" fgColor=""0000FF"" bgColor=""FFFFFF"" fontStyle=""0"" />
-            <WordsStyle name=""KEYWORD2"" styleID=""6"" fgColor=""0080C0"" bgColor=""FFFFFF"" fontStyle=""0"" />
-            <WordsStyle name=""KEYWORD3"" styleID=""7"" fgColor=""0000FF"" bgColor=""FFFFFF"" fontStyle=""0"" />
-            <WordsStyle name=""KEYWORD4"" styleID=""8"" fgColor=""008040"" bgColor=""FFFFFF"" fontStyle=""0"" />
-            <WordsStyle name=""COMMENT"" styleID=""1"" fgColor=""008000"" bgColor=""FFFFFF"" fontStyle=""0"" />
-            <WordsStyle name=""COMMENT LINE"" styleID=""2"" fgColor=""949494"" bgColor=""FFFFFF"" fontStyle=""0"" />
-            <WordsStyle name=""NUMBER"" styleID=""4"" fgColor=""FF0000"" bgColor=""FFFFFF"" fontStyle=""0"" />
-            <WordsStyle name=""OPERATOR"" styleID=""10"" fgColor=""000000"" bgColor=""FFFFFF"" fontStyle=""0"" />
-            <WordsStyle name=""DELIMINER1"" styleID=""14"" fgColor=""800080"" bgColor=""FFFFFF"" fontStyle=""0"" />
-            <WordsStyle name=""DELIMINER2"" styleID=""15"" fgColor=""808080"" bgColor=""FFFFFF"" fontStyle=""0"" />
-            <WordsStyle name=""DELIMINER3"" styleID=""16"" fgColor=""000000"" bgColor=""FFFFFF"" fontStyle=""0"" />
-        </Styles>
-    </UserLang>
-</NotepadPlus>
diff --git a/csharp/protos/tutorial/addressbook.proto b/csharp/protos/tutorial/addressbook.proto
deleted file mode 100644
index 5abe35ce3..000000000
--- a/csharp/protos/tutorial/addressbook.proto
+++ /dev/null
@@ -1,31 +0,0 @@
-package tutorial;
- 
-import ""google/protobuf/csharp_options.proto"";
-option (google.protobuf.csharp_file_options).namespace = ""Google.ProtocolBuffers.Examples.AddressBook"";
-option (google.protobuf.csharp_file_options).umbrella_classname = ""AddressBookProtos"";
-
-option optimize_for = SPEED;
-
-message Person {
-  required string name = 1;
-  required int32 id = 2;        // Unique ID number for this person.
-  optional string email = 3;
- 
-  enum PhoneType {
-    MOBILE = 0;
-    HOME = 1;
-    WORK = 2;
-  }
- 
-  message PhoneNumber {
-    required string number = 1;
-    optional PhoneType type = 2 [default = HOME];
-  }
- 
-  repeated PhoneNumber phone = 4;
-}
- 
-// Our address book file is just one of these.
-message AddressBook {
-  repeated Person person = 1;
-}
diff --git a/csharp/src/ProtoGen.Test/DependencyResolutionTest.cs b/csharp/src/ProtoGen.Test/DependencyResolutionTest.cs
deleted file mode 100644
index 47c6f1a1e..000000000
--- a/csharp/src/ProtoGen.Test/DependencyResolutionTest.cs
+++ /dev/null
@@ -1,150 +0,0 @@
-#region Copyright notice and license
-
-// Protocol Buffers - Google's data interchange format
-// Copyright 2008 Google Inc.  All rights reserved.
-// http://github.com/jskeet/dotnet-protobufs/
-// Original C++/Java/Python code:
-// http://code.google.com/p/protobuf/
-//
-// Redistribution and use in source and binary forms, with or without
-// modification, are permitted provided that the following conditions are
-// met:
-//
-//     * Redistributions of source code must retain the above copyright
-// notice, this list of conditions and the following disclaimer.
-//     * Redistributions in binary form must reproduce the above
-// copyright notice, this list of conditions and the following disclaimer
-// in the documentation and/or other materials provided with the
-// distribution.
-//     * Neither the name of Google Inc. nor the names of its
-// contributors may be used to endorse or promote products derived from
-// this software without specific prior written permission.
-//
-// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-// ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
-#endregion
-
-using System.Collections.Generic;
-using Google.ProtocolBuffers.DescriptorProtos;
-using Google.ProtocolBuffers.Descriptors;
-using NUnit.Framework;
-
-namespace Google.ProtocolBuffers.ProtoGen
-{
-    /// <summary>
-    /// Tests for the dependency resolution in Generator.
-    /// </summary>
-    [TestFixture]
-    public class DependencyResolutionTest
-    {
-        [Test]
-        public void TwoDistinctFiles()
-        {
-            FileDescriptorProto first = new FileDescriptorProto.Builder {Name = ""First""}.Build();
-            FileDescriptorProto second = new FileDescriptorProto.Builder {Name = ""Second""}.Build();
-            var set = new List<FileDescriptorProto> { first, second };
-
-            IList<FileDescriptor> converted = Generator.ConvertDescriptors(CSharpFileOptions.DefaultInstance, set);
-            Assert.AreEqual(2, converted.Count);
-            Assert.AreEqual(""First"", converted[0].Name);
-            Assert.AreEqual(0, converted[0].Dependencies.Count);
-            Assert.AreEqual(""Second"", converted[1].Name);
-            Assert.AreEqual(0, converted[1].Dependencies.Count);
-        }
-
-        [Test]
-        public void FirstDependsOnSecond()
-        {
-            FileDescriptorProto first =
-                new FileDescriptorProto.Builder {Name = ""First"", DependencyList = {""Second""}}.Build();
-            FileDescriptorProto second = new FileDescriptorProto.Builder {Name = ""Second""}.Build();
-            var set = new List<FileDescriptorProto> { first, second };
-            IList<FileDescriptor> converted = Generator.ConvertDescriptors(CSharpFileOptions.DefaultInstance, set);
-            Assert.AreEqual(2, converted.Count);
-            Assert.AreEqual(""First"", converted[0].Name);
-            Assert.AreEqual(1, converted[0].Dependencies.Count);
-            Assert.AreEqual(converted[1], converted[0].Dependencies[0]);
-            Assert.AreEqual(""Second"", converted[1].Name);
-            Assert.AreEqual(0, converted[1].Dependencies.Count);
-        }
-
-        [Test]
-        public void SecondDependsOnFirst()
-        {
-            FileDescriptorProto first = new FileDescriptorProto.Builder {Name = ""First""}.Build();
-            FileDescriptorProto second =
-                new FileDescriptorProto.Builder {Name = ""Second"", DependencyList = {""First""}}.Build();
-            var set = new List<FileDescriptorProto> { first, second };
-            IList<FileDescriptor> converted = Generator.ConvertDescriptors(CSharpFileOptions.DefaultInstance, set);
-            Assert.AreEqual(2, converted.Count);
-            Assert.AreEqual(""First"", converted[0].Name);
-            Assert.AreEqual(0, converted[0].Dependencies.Count);
-            Assert.AreEqual(""Second"", converted[1].Name);
-            Assert.AreEqual(1, converted[1].Dependencies.Count);
-            Assert.AreEqual(converted[0], converted[1].Dependencies[0]);
-        }
-
-        [Test]
-        public void CircularDependency()
-        {
-            FileDescriptorProto first =
-                new FileDescriptorProto.Builder {Name = ""First"", DependencyList = {""Second""}}.Build();
-            FileDescriptorProto second =
-                new FileDescriptorProto.Builder {Name = ""Second"", DependencyList = {""First""}}.Build();
-            var set = new List<FileDescriptorProto> { first, second };
-            try
-            {
-                Generator.ConvertDescriptors(CSharpFileOptions.DefaultInstance, set);
-                Assert.Fail(""Expected exception"");
-            }
-            catch (DependencyResolutionException)
-            {
-                // Expected
-            }
-        }
-
-        [Test]
-        public void MissingDependency()
-        {
-            FileDescriptorProto first =
-                new FileDescriptorProto.Builder {Name = ""First"", DependencyList = {""Second""}}.Build();
-            var set = new List<FileDescriptorProto> { first };
-            try
-            {
-                Generator.ConvertDescriptors(CSharpFileOptions.DefaultInstance, set);
-                Assert.Fail(""Expected exception"");
-            }
-            catch (DependencyResolutionException)
-            {
-                // Expected
-            }
-        }
-
-        [Test]
-        public void SelfDependency()
-        {
-            FileDescriptorProto first =
-                new FileDescriptorProto.Builder {Name = ""First"", DependencyList = {""First""}}.Build();
-            var set = new List<FileDescriptorProto> { first };
-            try
-            {
-                Generator.ConvertDescriptors(CSharpFileOptions.DefaultInstance, set);
-                Assert.Fail(""Expected exception"");
-            }
-            catch (DependencyResolutionException)
-            {
-                // Expected
-            }
-        }
-    }
-}
\ No newline at end of file
diff --git a/csharp/src/ProtoGen.Test/Properties/AssemblyInfo.cs b/csharp/src/ProtoGen.Test/Properties/AssemblyInfo.cs
deleted file mode 100644
index 0b632bce6..000000000
--- a/csharp/src/ProtoGen.Test/Properties/AssemblyInfo.cs
+++ /dev/null
@@ -1,30 +0,0 @@
-using System.Reflection;
-using System.Runtime.CompilerServices;
-using System.Runtime.InteropServices;
-
-// General Information about an assembly is controlled through the following 
-// set of attributes. Change these attribute values to modify the information
-// associated with an assembly.
-
-[assembly: AssemblyTitle(""ProtoGen.Test"")]
-[assembly: AssemblyDescription("""")]
-[assembly: AssemblyConfiguration("""")]
-[assembly: AssemblyCompany("""")]
-[assembly: AssemblyProduct(""ProtoGen.Test"")]
-[assembly: AssemblyCopyright(""Copyright   2008"")]
-[assembly: AssemblyTrademark("""")]
-[assembly: AssemblyCulture("""")]
-
-// Version information for an assembly consists of the following four values:
-//
-//      Major Version
-//      Minor Version 
-//      Build Number
-//      Revision
-//
-// You can specify all the values or you can default the Build and Revision Numbers 
-// by using the '*' as shown below:
-// [assembly: AssemblyVersion(""2.4.1.555"")]
-
-[assembly: AssemblyVersion(""2.4.1.555"")]
-[assembly: AssemblyFileVersion(""2.4.1.555"")]
\ No newline at end of file
diff --git a/csharp/src/ProtoGen.Test/ProtoGen.Test.csproj b/csharp/src/ProtoGen.Test/ProtoGen.Test.csproj
deleted file mode 100644
index 81f84796a..000000000
--- a/csharp/src/ProtoGen.Test/ProtoGen.Test.csproj
+++ /dev/null
@@ -1,99 +0,0 @@
-<?xml version=""1.0"" encoding=""utf-8""?>
-<Project ToolsVersion=""4.0"" DefaultTargets=""Build"" xmlns=""http://schemas.microsoft.com/developer/msbuild/2003"">
-  <PropertyGroup>
-    <EnvironmentFlavor>CLIENTPROFILE</EnvironmentFlavor>
-    <EnvironmentTemplate>NET35</EnvironmentTemplate>
-    <Configuration Condition="" '$(Configuration)' == '' "">Debug</Configuration>
-    <Platform Condition="" '$(Platform)' == '' "">AnyCPU</Platform>
-    <ProductVersion>9.0.30729</ProductVersion>
-    <SchemaVersion>2.0</SchemaVersion>
-    <ProjectGuid>{C268DA4C-4004-47DA-AF23-44C983281A68}</ProjectGuid>
-    <OutputType>Library</OutputType>
-    <AppDesignerFolder>Properties</AppDesignerFolder>
-    <RootNamespace>Google.ProtocolBuffers.ProtoGen</RootNamespace>
-    <AssemblyName>Google.ProtocolBuffers.ProtoGen.Test</AssemblyName>
-    <TargetFrameworkVersion>v3.5</TargetFrameworkVersion>
-    <FileAlignment>512</FileAlignment>
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Debug|AnyCPU' "">
-    <DebugSymbols>true</DebugSymbols>
-    <DebugType>full</DebugType>
-    <Optimize>false</Optimize>
-    <OutputPath>bin\NET35\Debug</OutputPath>
-    <IntermediateOutputPath>obj\NET35\Debug\</IntermediateOutputPath>
-    <DefineConstants>DEBUG;TRACE;$(EnvironmentFlavor);$(EnvironmentTemplate)</DefineConstants>
-    <ErrorReport>prompt</ErrorReport>
-    <WarningLevel>4</WarningLevel>
-    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
-    <NoStdLib>true</NoStdLib>
-    <GenerateSerializationAssemblies>Off</GenerateSerializationAssemblies>
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Release|AnyCPU' "">
-    <DebugType>pdbonly</DebugType>
-    <Optimize>true</Optimize>
-    <OutputPath>bin\NET35\Release</OutputPath>
-    <IntermediateOutputPath>obj\NET35\Release\</IntermediateOutputPath>
-    <DefineConstants>TRACE;$(EnvironmentFlavor);$(EnvironmentTemplate)</DefineConstants>
-    <ErrorReport>prompt</ErrorReport>
-    <WarningLevel>4</WarningLevel>
-    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
-    <NoStdLib>true</NoStdLib>
-    <GenerateSerializationAssemblies>Off</GenerateSerializationAssemblies>
-  </PropertyGroup>
-  <ItemGroup>
-    <Reference Include=""nunit.framework"">
-      <SpecificVersion>False</SpecificVersion>
-      <HintPath>..\..\lib\NUnit\lib\nunit.framework.dll</HintPath>
-    </Reference>
-    <Reference Include=""mscorlib"" />
-    <Reference Include=""System"" />
-    <Reference Include=""System.Data"" />
-    <Reference Include=""System.Xml"" />
-  </ItemGroup>
-  <ItemGroup>
-    <Compile Include=""DependencyResolutionTest.cs"" />
-    <Compile Include=""Properties\AssemblyInfo.cs"" />
-    <Compile Include=""TempFile.cs"" />
-    <Compile Include=""TestPreprocessing.cs"" />
-  </ItemGroup>
-  <ItemGroup>
-    <ProjectReference Include=""..\ProtocolBuffers\ProtocolBuffers.csproj"">
-      <Project>{6908BDCE-D925-43F3-94AC-A531E6DF2591}</Project>
-      <Name>ProtocolBuffers</Name>
-    </ProjectReference>
-    <ProjectReference Include=""..\ProtoGen\ProtoGen.csproj"">
-      <Project>{250ADE34-82FD-4BAE-86D5-985FBE589C4A}</Project>
-      <Name>ProtoGen</Name>
-    </ProjectReference>
-  </ItemGroup>
-  <ItemGroup>
-    <Content Include=""..\..\lib\protoc.exe"">
-      <Link>protoc.exe</Link>
-      <CopyToOutputDirectory>PreserveNewest</CopyToOutputDirectory>
-    </Content>
-  </ItemGroup>
-  <ItemGroup>
-    <None Include=""..\..\protos\google\protobuf\csharp_options.proto"">
-      <Link>google\protobuf\csharp_options.proto</Link>
-      <CopyToOutputDirectory>PreserveNewest</CopyToOutputDirectory>
-    </None>
-    <None Include=""..\..\protos\google\protobuf\descriptor.proto"">
-      <Link>google\protobuf\descriptor.proto</Link>
-      <CopyToOutputDirectory>PreserveNewest</CopyToOutputDirectory>
-    </None>
-  </ItemGroup>
-  <Import Project=""$(MSBuildToolsPath)\Microsoft.CSharp.targets"" />
-  <!-- To modify your build process, add your task inside one of the targets below and uncomment it. 
-       Other similar extension points exist, see Microsoft.Common.targets.
-  <Target Name=""BeforeBuild"">
-  </Target>
-  <Target Name=""AfterBuild"">
-  </Target>
-  -->
-  <PropertyGroup>
-    <StartAction>Program</StartAction>
-    <StartProgram>$(ProjectDir)..\..\lib\NUnit\tools\nunit-console.exe</StartProgram>
-    <StartArguments>/nologo /noshadow /labels /wait $(AssemblyName).dll</StartArguments>
-    <StartWorkingDirectory>$(ProjectDir)$(OutputPath)</StartWorkingDirectory>
-  </PropertyGroup>
-</Project>
\ No newline at end of file
diff --git a/csharp/src/ProtoGen.Test/ProtocGenCsUnittests.cs b/csharp/src/ProtoGen.Test/ProtocGenCsUnittests.cs
deleted file mode 100644
index 8ee56de5f..000000000
--- a/csharp/src/ProtoGen.Test/ProtocGenCsUnittests.cs
+++ /dev/null
@@ -1,683 +0,0 @@
-#region Copyright notice and license
-
-// Protocol Buffers - Google's data interchange format
-// Copyright 2008 Google Inc.  All rights reserved.
-// http://github.com/jskeet/dotnet-protobufs/
-// Original C++/Java/Python code:
-// http://code.google.com/p/protobuf/
-//
-// Redistribution and use in source and binary forms, with or without
-// modification, are permitted provided that the following conditions are
-// met:
-//
-//     * Redistributions of source code must retain the above copyright
-// notice, this list of conditions and the following disclaimer.
-//     * Redistributions in binary form must reproduce the above
-// copyright notice, this list of conditions and the following disclaimer
-// in the documentation and/or other materials provided with the
-// distribution.
-//     * Neither the name of Google Inc. nor the names of its
-// contributors may be used to endorse or promote products derived from
-// this software without specific prior written permission.
-//
-// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-// ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
-#endregion
-
-using NUnit.Framework;
-using System;
-using System.Collections.Generic;
-using System.Diagnostics;
-using System.IO;
-using System.Reflection;
-using System.Text;
-
-namespace Google.ProtocolBuffers.ProtoGen
-{
-    /// <summary>
-    /// Tests protoc-gen-cs plugin.
-    /// </summary>
-    [TestFixture]
-    [Category(""Preprocessor"")]
-    public partial class ProtocGenCsUnittests
-    {
-        private static readonly string TempPath = Path.Combine(Path.GetTempPath(), ""protoc-gen-cs.Test"");
-
-        private const string DefaultProto =
-            @""
-package nunit.simple;
-// Test a very simple message.
-message MyMessage {
-  optional string name = 1;
-}"";
-
-        #region TestFixture SetUp/TearDown
-
-        private static readonly string OriginalWorkingDirectory = Environment.CurrentDirectory;
-
-        private StringBuilder buffer = new StringBuilder();
-
-        [TestFixtureSetUp]
-        public virtual void Setup()
-        {
-            Teardown();
-            Directory.CreateDirectory(TempPath);
-            Environment.CurrentDirectory = TempPath;
-            this.buffer.Length = 0;
-        }
-
-        [TestFixtureTearDown]
-        public virtual void Teardown()
-        {
-            Environment.CurrentDirectory = OriginalWorkingDirectory;
-            if (Directory.Exists(TempPath))
-            {
-                Directory.Delete(TempPath, true);
-            }
-        }
-
-        #endregion
-
-        #region Helper Methods RunProtoGen / RunCsc
-
-        private void RunProtoc(int expect, string protoFile, params string[] args)
-        {
-            string protoPath = string.Format(""-I. -I\""{0}\"""", OriginalWorkingDirectory);
-            string plugin = string.Format(""--plugin=\""{0}\"""", Path.Combine(OriginalWorkingDirectory, ""protoc-gen-cs.exe""));
-            string csOut = args.Length == 0 ? ""--cs_out=."" : string.Format(""--cs_out=\""{0}:.\"""", string.Join("" "", args));
-            // Start the child process.
-            Process p = new Process();
-            // Redirect the output stream of the child process.
-            p.StartInfo.CreateNoWindow = true;
-            p.StartInfo.UseShellExecute = false;
-            p.StartInfo.RedirectStandardError = true;
-            p.StartInfo.RedirectStandardOutput = true;
-            p.StartInfo.WorkingDirectory = TempPath;
-            p.StartInfo.FileName = Path.Combine(OriginalWorkingDirectory, ""protoc.exe"");
-            p.StartInfo.Arguments = string.Join("" "", new string[] { plugin, csOut, protoPath, protoFile });
-            p.Start();
-            // Read the output stream first and then wait.
-            buffer.AppendLine(string.Format(""{0}> \""{1}\"" {2}"", p.StartInfo.WorkingDirectory, p.StartInfo.FileName, p.StartInfo.Arguments));
-            buffer.AppendLine(p.StandardError.ReadToEnd());
-            buffer.AppendLine(p.StandardOutput.ReadToEnd());
-            p.WaitForExit();
-            Assert.AreEqual(expect, p.ExitCode, this.buffer.ToString());
-        }
-
-        private Assembly RunCsc(int expect, params string[] sources)
-        {
-            using (TempFile tempDll = new TempFile(String.Empty))
-            {
-                tempDll.ChangeExtension("".dll"");
-                List<string> args = new List<string>();
-                args.Add(""/nologo"");
-                args.Add(""/target:library"");
-                args.Add(""/debug-"");
-                args.Add(String.Format(@""""""/out:{0}"""""", tempDll.TempPath));
-                args.Add(""/r:System.dll"");
-                args.Add(String.Format(@""""""/r:{0}"""""",
-                                       typeof(Google.ProtocolBuffers.DescriptorProtos.DescriptorProto).Assembly.
-                                           Location));
-                args.AddRange(sources);
-
-                string exe = Path.Combine(System.Runtime.InteropServices.RuntimeEnvironment.GetRuntimeDirectory(),
-                                          ""csc.exe"");
-                ProcessStartInfo psi = new ProcessStartInfo(exe);
-                psi.WorkingDirectory = TempPath;
-                psi.CreateNoWindow = true;
-                psi.UseShellExecute = false;
-                psi.RedirectStandardOutput = true;
-                psi.RedirectStandardError = true;
-                psi.Arguments = string.Join("" "", args.ToArray());
-                Process p = Process.Start(psi);
-                buffer.AppendLine(string.Format(""{0}> \""{1}\"" {2}"", p.StartInfo.WorkingDirectory, p.StartInfo.FileName, p.StartInfo.Arguments));
-                buffer.AppendLine(p.StandardError.ReadToEnd());
-                buffer.AppendLine(p.StandardOutput.ReadToEnd());
-                p.WaitForExit();
-                Assert.AreEqual(expect, p.ExitCode, this.buffer.ToString());
-
-                Assembly asm = null;
-                if (p.ExitCode == 0)
-                {
-                    byte[] allbytes = File.ReadAllBytes(tempDll.TempPath);
-                    asm = Assembly.Load(allbytes);
-
-                    foreach (Type t in asm.GetTypes())
-                    {
-                        Debug.WriteLine(t.FullName, asm.FullName);
-                    }
-                }
-                return asm;
-            }
-        }
-
-        #endregion
-
-        // *******************************************************************
-        // The following tests excercise options for protogen.exe
-        // *******************************************************************
-
-        [Test]
-        public void TestProtoFile()
-        {
-            string test = new StackFrame(false).GetMethod().Name;
-            Setup();
-            using (TempFile source = TempFile.Attach(test + "".cs""))
-            using (ProtoFile proto = new ProtoFile(test + "".proto"", DefaultProto))
-            {
-                RunProtoc(0, proto.TempPath);
-                Assembly a = RunCsc(0, source.TempPath);
-                //assert that the message type is in the expected namespace
-                Type t = a.GetType(""nunit.simple.MyMessage"", true, true);
-                Assert.IsTrue(typeof(IMessage).IsAssignableFrom(t), ""Expect an IMessage"");
-                //assert that we can find the static descriptor type
-                a.GetType(""nunit.simple."" + test, true, true);
-            }
-        }
-
-        [Test]
-        public void TestProtoFileWithConflictingType()
-        {
-            string test = new StackFrame(false).GetMethod().Name;
-            Setup();
-            using (TempFile source = TempFile.Attach(test + "".cs""))
-            using (
-                ProtoFile proto = new ProtoFile(test + "".proto"",
-                                                @""
-package nunit.simple;
-// Test a very simple message.
-message "" +
-                                                test + @"" {
-  optional string name = 1;
-} ""))
-            {
-                RunProtoc(0, proto.TempPath);
-                Assembly a = RunCsc(0, source.TempPath);
-                //assert that the message type is in the expected namespace
-                Type t = a.GetType(""nunit.simple."" + test, true, true);
-                Assert.IsTrue(typeof(IMessage).IsAssignableFrom(t), ""Expect an IMessage"");
-                //assert that we can find the static descriptor type
-                a.GetType(""nunit.simple.Proto."" + test, true, true);
-            }
-        }
-
-        [Test]
-        public void TestProtoFileWithNamespace()
-        {
-            string test = new StackFrame(false).GetMethod().Name;
-            Setup();
-            using (TempFile source = TempFile.Attach(test + "".cs""))
-            using (ProtoFile proto = new ProtoFile(test + "".proto"", DefaultProto))
-            {
-                RunProtoc(0, proto.TempPath, ""-namespace=MyNewNamespace"");
-                Assembly a = RunCsc(0, source.TempPath);
-                //assert that the message type is in the expected namespace
-                Type t = a.GetType(""MyNewNamespace.MyMessage"", true, true);
-                Assert.IsTrue(typeof(IMessage).IsAssignableFrom(t), ""Expect an IMessage"");
-                //assert that we can find the static descriptor type
-                a.GetType(""MyNewNamespace."" + test, true, true);
-            }
-        }
-
-        [Test]
-        public void TestProtoFileWithUmbrellaClassName()
-        {
-            string test = new StackFrame(false).GetMethod().Name;
-            Setup();
-            using (TempFile source = TempFile.Attach(""MyUmbrellaClassname.cs""))
-            using (ProtoFile proto = new ProtoFile(test + "".proto"", DefaultProto))
-            {
-                RunProtoc(0, proto.TempPath, ""/umbrella_classname=MyUmbrellaClassname"");
-                Assembly a = RunCsc(0, source.TempPath);
-                //assert that the message type is in the expected namespace
-                Type t = a.GetType(""nunit.simple.MyMessage"", true, true);
-                Assert.IsTrue(typeof(IMessage).IsAssignableFrom(t), ""Expect an IMessage"");
-                //assert that we can find the static descriptor type
-                a.GetType(""nunit.simple.MyUmbrellaClassname"", true, true);
-            }
-        }
-
-        [Test]
-        public void TestProtoFileWithNestedClass()
-        {
-            string test = new StackFrame(false).GetMethod().Name;
-            Setup();
-            using (TempFile source = TempFile.Attach(test + "".cs""))
-            using (ProtoFile proto = new ProtoFile(test + "".proto"", DefaultProto))
-            {
-                RunProtoc(0, proto.TempPath, ""-nest_classes=true"");
-                Assembly a = RunCsc(0, source.TempPath);
-                //assert that the message type is in the expected namespace
-                Type t = a.GetType(""nunit.simple."" + test + ""+MyMessage"", true, true);
-                Assert.IsTrue(typeof(IMessage).IsAssignableFrom(t), ""Expect an IMessage"");
-                //assert that we can find the static descriptor type
-                a.GetType(""nunit.simple."" + test, true, true);
-            }
-        }
-
-        [Test]
-        public void TestProtoFileWithExpandedNsDirectories()
-        {
-            string test = new StackFrame(false).GetMethod().Name;
-            Setup();
-            using (TempFile source = TempFile.Attach(@""nunit\simple\"" + test + "".cs""))
-            using (ProtoFile proto = new ProtoFile(test + "".proto"", DefaultProto))
-            {
-                RunProtoc(0, proto.TempPath, ""-expand_namespace_directories=true"");
-                Assembly a = RunCsc(0, source.TempPath);
-                //assert that the message type is in the expected namespace
-                Type t = a.GetType(""nunit.simple.MyMessage"", true, true);
-                Assert.IsTrue(typeof(IMessage).IsAssignableFrom(t), ""Expect an IMessage"");
-                //assert that we can find the static descriptor type
-                a.GetType(""nunit.simple."" + test, true, true);
-            }
-        }
-
-        [Test]
-        public void TestProtoFileWithNewExtension()
-        {
-            string test = new StackFrame(false).GetMethod().Name;
-            Setup();
-            using (TempFile source = TempFile.Attach(test + "".Generated.cs""))
-            using (ProtoFile proto = new ProtoFile(test + "".proto"", DefaultProto))
-            {
-                RunProtoc(0, proto.TempPath, ""-file_extension=.Generated.cs"");
-                Assembly a = RunCsc(0, source.TempPath);
-                //assert that the message type is in the expected namespace
-                Type t = a.GetType(""nunit.simple.MyMessage"", true, true);
-                Assert.IsTrue(typeof(IMessage).IsAssignableFrom(t), ""Expect an IMessage"");
-                //assert that we can find the static descriptor type
-                a.GetType(""nunit.simple."" + test, true, true);
-            }
-        }
-
-        [Test]
-        public void TestProtoFileWithUmbrellaNamespace()
-        {
-            string test = new StackFrame(false).GetMethod().Name;
-            Setup();
-            using (TempFile source = TempFile.Attach(test + "".cs""))
-            using (ProtoFile proto = new ProtoFile(test + "".proto"", DefaultProto))
-            {
-                RunProtoc(0, proto.TempPath, ""-umbrella_namespace=MyUmbrella.Namespace"");
-                Assembly a = RunCsc(0, source.TempPath);
-                //assert that the message type is in the expected namespace
-                Type t = a.GetType(""nunit.simple.MyMessage"", true, true);
-                Assert.IsTrue(typeof(IMessage).IsAssignableFrom(t), ""Expect an IMessage"");
-                //assert that we can find the static descriptor type
-                a.GetType(""nunit.simple.MyUmbrella.Namespace."" + test, true, true);
-            }
-        }
-
-        [Test]
-        public void TestProtoFileWithIgnoredUmbrellaNamespaceDueToNesting()
-        {
-            string test = new StackFrame(false).GetMethod().Name;
-            Setup();
-            using (TempFile source = TempFile.Attach(test + "".cs""))
-            using (ProtoFile proto = new ProtoFile(test + "".proto"", DefaultProto))
-            {
-                RunProtoc(0, proto.TempPath, ""-nest_classes=true"", ""-umbrella_namespace=MyUmbrella.Namespace"");
-                Assembly a = RunCsc(0, source.TempPath);
-                //assert that the message type is in the expected namespace
-                Type t = a.GetType(""nunit.simple."" + test + ""+MyMessage"", true, true);
-                Assert.IsTrue(typeof(IMessage).IsAssignableFrom(t), ""Expect an IMessage"");
-                //assert that we can find the static descriptor type
-                a.GetType(""nunit.simple."" + test, true, true);
-            }
-        }
-
-        [Test]
-        public void TestProtoFileWithExplicitEmptyUmbrellaNamespace()
-        {
-            string test = new StackFrame(false).GetMethod().Name;
-            Setup();
-            using (TempFile source = TempFile.Attach(test + "".cs""))
-            using (
-                ProtoFile proto = new ProtoFile(test + "".proto"",
-                                                @""
-package nunit.simple;
-// Test a very simple message.
-message "" +
-                                                test + @"" {
-  optional string name = 1;
-} ""))
-            {
-                //Forces the umbrella class to not use a namespace even if a collision with a type is detected.
-                RunProtoc(0, proto.TempPath, ""-umbrella_namespace="");
-                //error CS0441: 'nunit.simple.TestProtoFileWithExplicitEmptyUmbrellaNamespace': a class cannot be both static and sealed
-                RunCsc(1, source.TempPath);
-            }
-        }
-
-        [Test]
-        public void TestProtoFileWithNewOutputFolder()
-        {
-            string test = new StackFrame(false).GetMethod().Name;
-            Setup();
-            using (TempFile source = TempFile.Attach(@""generated-code\"" + test + "".cs""))
-            using (ProtoFile proto = new ProtoFile(test + "".proto"", DefaultProto))
-            {
-                RunProtoc(1, proto.TempPath, ""-output_directory=generated-code"");
-                Directory.CreateDirectory(""generated-code"");
-                RunProtoc(0, proto.TempPath, ""-output_directory=generated-code"");
-                Assembly a = RunCsc(0, source.TempPath);
-                //assert that the message type is in the expected namespace
-                Type t = a.GetType(""nunit.simple.MyMessage"", true, true);
-                Assert.IsTrue(typeof(IMessage).IsAssignableFrom(t), ""Expect an IMessage"");
-                //assert that we can find the static descriptor type
-                a.GetType(""nunit.simple."" + test, true, true);
-            }
-        }
-
-        [Test]
-        public void TestProtoFileAndIgnoreGoogleProtobuf()
-        {
-            string test = new StackFrame(false).GetMethod().Name;
-            Setup();
-            using (TempFile source = TempFile.Attach(test + "".cs""))
-            using (
-                ProtoFile proto = new ProtoFile(test + "".proto"",
-                                                @""
-import """"google/protobuf/csharp_options.proto"""";
-option (google.protobuf.csharp_file_options).namespace = """"MyNewNamespace"""";
-"" +
-                                                DefaultProto))
-            {
-                string google = Path.Combine(TempPath, ""google\\protobuf"");
-                Directory.CreateDirectory(google);
-                foreach (string file in Directory.GetFiles(Path.Combine(OriginalWorkingDirectory, ""google\\protobuf"")))
-                {
-                    File.Copy(file, Path.Combine(google, Path.GetFileName(file)));
-                }
-
-                Assert.AreEqual(0, Directory.GetFiles(TempPath, ""*.cs"").Length);
-                RunProtoc(0, proto.TempPath);
-                Assert.AreEqual(1, Directory.GetFiles(TempPath, ""*.cs"").Length);
-
-                Assembly a = RunCsc(0, source.TempPath);
-                //assert that the message type is in the expected namespace
-                Type t = a.GetType(""MyNewNamespace.MyMessage"", true, true);
-                Assert.IsTrue(typeof(IMessage).IsAssignableFrom(t), ""Expect an IMessage"");
-                //assert that we can find the static descriptor type
-                a.GetType(""MyNewNamespace."" + test, true, true);
-            }
-        }
-
-        [Test]
-        public void TestProtoFileWithoutIgnoreGoogleProtobuf()
-        {
-            string test = new StackFrame(false).GetMethod().Name;
-            Setup();
-            using (TempFile source = TempFile.Attach(test + "".cs""))
-            using (
-                ProtoFile proto = new ProtoFile(test + "".proto"",
-                                                @""
-import """"google/protobuf/csharp_options.proto"""";
-option (google.protobuf.csharp_file_options).namespace = """"MyNewNamespace"""";
-"" +
-                                                DefaultProto))
-            {
-                string google = Path.Combine(TempPath, ""google\\protobuf"");
-                Directory.CreateDirectory(google);
-                foreach (string file in Directory.GetFiles(Path.Combine(OriginalWorkingDirectory, ""google\\protobuf"")))
-                {
-                    File.Copy(file, Path.Combine(google, Path.GetFileName(file)));
-                }
-
-                Assert.AreEqual(0, Directory.GetFiles(TempPath, ""*.cs"").Length);
-                //Without the option this fails due to being unable to resolve google/protobuf descriptors
-                RunProtoc(0, proto.TempPath);
-            }
-        }
-
-        // *******************************************************************
-        // The following tests excercise options for protoc.exe
-        // *******************************************************************
-
-        [Test]
-        public void TestProtoFileWithIncludeImports()
-        {
-            string test = new StackFrame(false).GetMethod().Name;
-            Setup();
-            using (TempFile source = TempFile.Attach(test + "".cs""))
-            using (
-                ProtoFile proto = new ProtoFile(test + "".proto"",
-                                                @""
-import """"google/protobuf/csharp_options.proto"""";
-option (google.protobuf.csharp_file_options).namespace = """"MyNewNamespace"""";
-
-package nunit.simple;
-// Test a very simple message.
-message MyMessage {
-  optional string name = 1;
-} "")
-                )
-            {
-                string google = Path.Combine(TempPath, ""google\\protobuf"");
-                Directory.CreateDirectory(google);
-                foreach (string file in Directory.GetFiles(Path.Combine(OriginalWorkingDirectory, ""google\\protobuf"")))
-                {
-                    File.Copy(file, Path.Combine(google, Path.GetFileName(file)));
-                }
-
-                Assert.AreEqual(0, Directory.GetFiles(TempPath, ""*.cs"").Length);
-                //if you specify the protoc option --include_imports this should build three source files
-                RunProtoc(0, proto.TempPath);
-                Assert.AreEqual(1, Directory.GetFiles(TempPath, ""*.cs"").Length);
-
-                //you can (and should) simply omit the inclusion of the extra source files in your project
-                Assembly a = RunCsc(0, source.TempPath);
-                //assert that the message type is in the expected namespace
-                Type t = a.GetType(""MyNewNamespace.MyMessage"", true, true);
-                Assert.IsTrue(typeof(IMessage).IsAssignableFrom(t), ""Expect an IMessage"");
-                //assert that we can find the static descriptor type
-                a.GetType(""MyNewNamespace."" + test, true, true);
-            }
-        }
-
-        //Seems the --proto_path or -I option is non-functional for me.  Maybe others have luck?
-        [Test]
-        public void TestProtoFileInDifferentDirectory()
-        {
-            string test = new StackFrame(false).GetMethod().Name;
-            Setup();
-            using (TempFile source = TempFile.Attach(test + "".cs""))
-            using (ProtoFile proto = new ProtoFile(test + "".proto"", DefaultProto))
-            {
-                Environment.CurrentDirectory = OriginalWorkingDirectory;
-                RunProtoc(0, proto.TempPath);
-                Assembly a = RunCsc(0, source.TempPath);
-                //assert that the message type is in the expected namespace
-                Type t = a.GetType(""nunit.simple.MyMessage"", true, true);
-                Assert.IsTrue(typeof(IMessage).IsAssignableFrom(t), ""Expect an IMessage"");
-                //assert that we can find the static descriptor type
-                a.GetType(""nunit.simple."" + test, true, true);
-            }
-        }
-
-        // *******************************************************************
-        // Handling of mutliple input files
-        // *******************************************************************
-
-        [Test]
-        public void TestMultipleProtoFiles()
-        {
-            Setup();
-            using (TempFile source1 = TempFile.Attach(""MyMessage.cs""))
-            using (
-                ProtoFile proto1 = new ProtoFile(""MyMessage.proto"",
-                                                 @""
-package nunit.simple;
-// Test a very simple message.
-message MyMessage {
-  optional string name = 1;
-}"")
-                )
-            using (TempFile source2 = TempFile.Attach(""MyMessageList.cs""))
-            using (
-                ProtoFile proto2 = new ProtoFile(""MyMessageList.proto"",
-                                                 @""
-package nunit.simple;
-import """"MyMessage.proto"""";
-// Test a very simple message.
-message MyMessageList {
-  repeated MyMessage messages = 1;
-}"")
-                )
-            {
-                RunProtoc(0, proto1.TempPath);
-                RunProtoc(0, proto2.TempPath);
-                Assembly a = RunCsc(0, source1.TempPath, source2.TempPath);
-                //assert that the message type is in the expected namespace
-                Type t1 = a.GetType(""nunit.simple.MyMessage"", true, true);
-                Assert.IsTrue(typeof(IMessage).IsAssignableFrom(t1), ""Expect an IMessage"");
-                //assert that the message type is in the expected namespace
-                Type t2 = a.GetType(""nunit.simple.MyMessageList"", true, true);
-                Assert.IsTrue(typeof(IMessage).IsAssignableFrom(t2), ""Expect an IMessage"");
-                //assert that we can find the static descriptor type
-                a.GetType(""nunit.simple.Proto.MyMessage"", true, true);
-                a.GetType(""nunit.simple.Proto.MyMessageList"", true, true);
-            }
-        }
-
-        [Test]
-        public void TestOneProtoFileWithBufferFile()
-        {
-            Setup();
-            using (TempFile source1 = TempFile.Attach(""MyMessage.cs""))
-            using (
-                ProtoFile proto1 = new ProtoFile(""MyMessage.proto"",
-                                                 @""
-package nunit.simple;
-// Test a very simple message.
-message MyMessage {
-  optional string name = 1;
-}"")
-                )
-            using (TempFile source2 = TempFile.Attach(""MyMessageList.cs""))
-            using (
-                ProtoFile proto2 = new ProtoFile(""MyMessageList.proto"",
-                                                 @""
-package nunit.simple;
-import """"MyMessage.proto"""";
-// Test a very simple message.
-message MyMessageList {
-  repeated MyMessage messages = 1;
-}"")
-                )
-            {
-                //build the proto buffer for MyMessage
-                RunProtoc(0, proto1.TempPath);
-                //build the MyMessageList proto-buffer and generate code by including MyMessage.pb
-                RunProtoc(0, proto2.TempPath);
-                Assembly a = RunCsc(0, source1.TempPath, source2.TempPath);
-                //assert that the message type is in the expected namespace
-                Type t1 = a.GetType(""nunit.simple.MyMessage"", true, true);
-                Assert.IsTrue(typeof(IMessage).IsAssignableFrom(t1), ""Expect an IMessage"");
-                //assert that the message type is in the expected namespace
-                Type t2 = a.GetType(""nunit.simple.MyMessageList"", true, true);
-                Assert.IsTrue(typeof(IMessage).IsAssignableFrom(t2), ""Expect an IMessage"");
-                //assert that we can find the static descriptor type
-                a.GetType(""nunit.simple.Proto.MyMessage"", true, true);
-                a.GetType(""nunit.simple.Proto.MyMessageList"", true, true);
-            }
-        }
-
-        [Test]
-        public void TestProtoFileWithService()
-        {
-            string test = new StackFrame(false).GetMethod().Name;
-            Setup();
-            using (TempFile source = TempFile.Attach(test + "".cs""))
-            using (ProtoFile proto = new ProtoFile(test + "".proto"",
-@""
-import """"google/protobuf/csharp_options.proto"""";
-option (google.protobuf.csharp_file_options).service_generator_type = GENERIC;
-
-package nunit.simple;
-// Test a very simple message.
-message MyMessage {
-  optional string name = 1;
-}
-// test a very simple service.
-service TestService {
-  rpc Execute (MyMessage) returns (MyMessage);
-}""))
-            {
-                CopyInGoogleProtoFiles();
-
-                RunProtoc(0, proto.TempPath, ""-nest_classes=false"");
-                Assert.AreEqual(1, Directory.GetFiles(TempPath, ""*.cs"").Length);
-
-                Assembly a = RunCsc(0, source.TempPath);
-                //assert that the service type is in the expected namespace
-                Type t1 = a.GetType(""nunit.simple.TestService"", true, true);
-                Assert.IsTrue(typeof(IService).IsAssignableFrom(t1), ""Expect an IService"");
-                Assert.IsTrue(t1.IsAbstract, ""Expect abstract class"");
-                //assert that the Stub subclass type is in the expected namespace
-                Type t2 = a.GetType(""nunit.simple.TestService+Stub"", true, true);
-                Assert.IsTrue(t1.IsAssignableFrom(t2), ""Expect a sub of TestService"");
-                Assert.IsFalse(t2.IsAbstract, ""Expect concrete class"");
-            }
-        }
-
-        [Test]
-        public void TestProtoFileWithServiceInternal()
-        {
-            string test = new StackFrame(false).GetMethod().Name;
-            Setup();
-            using (TempFile source = TempFile.Attach(test + "".cs""))
-            using (ProtoFile proto = new ProtoFile(test + "".proto"",
-@""
-import """"google/protobuf/csharp_options.proto"""";
-option (google.protobuf.csharp_file_options).service_generator_type = GENERIC;
-
-package nunit.simple;
-// Test a very simple message.
-message MyMessage {
-  optional string name = 1;
-}
-// test a very simple service.
-service TestService {
-  rpc Execute (MyMessage) returns (MyMessage);
-}""))
-            {
-                CopyInGoogleProtoFiles();
-
-                RunProtoc(0, proto.TempPath, ""-nest_classes=false"", ""-public_classes=false"");
-                Assert.AreEqual(1, Directory.GetFiles(TempPath, ""*.cs"").Length);
-
-                Assembly a = RunCsc(0, source.TempPath);
-                //assert that the service type is in the expected namespace
-                Type t1 = a.GetType(""nunit.simple.TestService"", true, true);
-                Assert.IsTrue(typeof(IService).IsAssignableFrom(t1), ""Expect an IService"");
-                Assert.IsTrue(t1.IsAbstract, ""Expect abstract class"");
-                //assert that the Stub subclass type is in the expected namespace
-                Type t2 = a.GetType(""nunit.simple.TestService+Stub"", true, true);
-                Assert.IsTrue(t1.IsAssignableFrom(t2), ""Expect a sub of TestService"");
-                Assert.IsFalse(t2.IsAbstract, ""Expect concrete class"");
-            }
-        }
-
-        private static void CopyInGoogleProtoFiles()
-        {
-            string google = Path.Combine(TempPath, ""google\\protobuf"");
-            Directory.CreateDirectory(google);
-            foreach (string file in Directory.GetFiles(Path.Combine(OriginalWorkingDirectory, ""google\\protobuf"")))
-            {
-                File.Copy(file, Path.Combine(google, Path.GetFileName(file)));
-            }
-        }
-    }
-}
\ No newline at end of file
diff --git a/csharp/src/ProtoGen.Test/TempFile.cs b/csharp/src/ProtoGen.Test/TempFile.cs
deleted file mode 100644
index 74a183f5a..000000000
--- a/csharp/src/ProtoGen.Test/TempFile.cs
+++ /dev/null
@@ -1,59 +0,0 @@
-using System;
-using System.Collections.Generic;
-using System.IO;
-using System.Text;
-
-namespace Google.ProtocolBuffers.ProtoGen
-{
-    internal class ProtoFile : TempFile
-    {
-        public ProtoFile(string filename, string contents)
-            : base(filename, contents)
-        {
-        }
-    }
-
-    internal class TempFile : IDisposable
-    {
-        private string tempFile;
-
-        public static TempFile Attach(string path)
-        {
-            return new TempFile(path, null);
-        }
-
-        protected TempFile(string filename, string contents)
-        {
-            tempFile = filename;
-            if (contents != null)
-            {
-                File.WriteAllText(tempFile, contents, new UTF8Encoding(false));
-            }
-        }
-
-        public TempFile(string contents)
-            : this(Path.GetTempFileName(), contents)
-        {
-        }
-
-        public string TempPath
-        {
-            get { return tempFile; }
-        }
-
-        public void ChangeExtension(string ext)
-        {
-            string newFile = Path.ChangeExtension(tempFile, ext);
-            File.Move(tempFile, newFile);
-            tempFile = newFile;
-        }
-
-        public void Dispose()
-        {
-            if (File.Exists(tempFile))
-            {
-                File.Delete(tempFile);
-            }
-        }
-    }
-}
\ No newline at end of file
diff --git a/csharp/src/ProtoGen.Test/TestPreprocessing.cs b/csharp/src/ProtoGen.Test/TestPreprocessing.cs
deleted file mode 100644
index 8b3b06630..000000000
--- a/csharp/src/ProtoGen.Test/TestPreprocessing.cs
+++ /dev/null
@@ -1,733 +0,0 @@
-#region Copyright notice and license
-
-// Protocol Buffers - Google's data interchange format
-// Copyright 2008 Google Inc.  All rights reserved.
-// http://github.com/jskeet/dotnet-protobufs/
-// Original C++/Java/Python code:
-// http://code.google.com/p/protobuf/
-//
-// Redistribution and use in source and binary forms, with or without
-// modification, are permitted provided that the following conditions are
-// met:
-//
-//     * Redistributions of source code must retain the above copyright
-// notice, this list of conditions and the following disclaimer.
-//     * Redistributions in binary form must reproduce the above
-// copyright notice, this list of conditions and the following disclaimer
-// in the documentation and/or other materials provided with the
-// distribution.
-//     * Neither the name of Google Inc. nor the names of its
-// contributors may be used to endorse or promote products derived from
-// this software without specific prior written permission.
-//
-// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-// ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
-#endregion
-
-using System;
-using System.Collections.Generic;
-using System.Diagnostics;
-using System.IO;
-using System.Reflection;
-using NUnit.Framework;
-
-namespace Google.ProtocolBuffers.ProtoGen
-{
-    [TestFixture]
-    [Category(""Preprocessor"")]
-    public partial class TestPreprocessing
-    {
-        private static readonly string TempPath = Path.Combine(Path.GetTempPath(), ""proto-gen-test"");
-
-        private const string DefaultProto =
-            @""
-package nunit.simple;
-// Test a very simple message.
-message MyMessage {
-  optional string name = 1;
-}"";
-
-        #region TestFixture SetUp/TearDown
-
-        private static readonly string OriginalWorkingDirectory = Environment.CurrentDirectory;
-
-        [TestFixtureSetUp]
-        public virtual void Setup()
-        {
-            Teardown();
-            Directory.CreateDirectory(TempPath);
-            Environment.CurrentDirectory = TempPath;
-        }
-
-        [TestFixtureTearDown]
-        public virtual void Teardown()
-        {
-            Environment.CurrentDirectory = OriginalWorkingDirectory;
-            if (Directory.Exists(TempPath))
-            {
-                Directory.Delete(TempPath, true);
-            }
-        }
-
-        #endregion
-
-        #region Helper Methods RunProtoGen / RunCsc
-
-        private void RunProtoGen(int expect, params string[] args)
-        {
-            TextWriter tout = Console.Out, terr = Console.Error;
-            StringWriter temp = new StringWriter();
-            Console.SetOut(temp);
-            Console.SetError(temp);
-            try
-            {
-                Assert.AreEqual(expect, ProgramPreprocess.Run(args), ""ProtoGen Failed: {0}"", temp);
-            }
-            finally
-            {
-                Console.SetOut(tout);
-                Console.SetError(terr);
-            }
-        }
-
-        private Assembly RunCsc(int expect, params string[] sources)
-        {
-            using (TempFile tempDll = new TempFile(String.Empty))
-            {
-                tempDll.ChangeExtension("".dll"");
-                List<string> args = new List<string>();
-                args.Add(""/nologo"");
-                args.Add(""/target:library"");
-                args.Add(""/debug-"");
-                args.Add(String.Format(@""""""/out:{0}"""""", tempDll.TempPath));
-                args.Add(""/r:System.dll"");
-                args.Add(String.Format(@""""""/r:{0}"""""",
-                                       typeof(Google.ProtocolBuffers.DescriptorProtos.DescriptorProto).Assembly.
-                                           Location));
-                args.AddRange(sources);
-
-                string exe = Path.Combine(System.Runtime.InteropServices.RuntimeEnvironment.GetRuntimeDirectory(),
-                                          ""csc.exe"");
-                ProcessStartInfo psi = new ProcessStartInfo(exe);
-                psi.CreateNoWindow = true;
-                psi.UseShellExecute = false;
-                psi.RedirectStandardOutput = true;
-                psi.RedirectStandardError = true;
-                psi.Arguments = string.Join("" "", args.ToArray());
-                Process p = Process.Start(psi);
-                p.WaitForExit();
-                string errorText = p.StandardOutput.ReadToEnd() + p.StandardError.ReadToEnd();
-                Assert.AreEqual(expect, p.ExitCode, ""CSC.exe Failed: {0}"", errorText);
-
-                Assembly asm = null;
-                if (p.ExitCode == 0)
-                {
-                    byte[] allbytes = File.ReadAllBytes(tempDll.TempPath);
-                    asm = Assembly.Load(allbytes);
-
-                    foreach (Type t in asm.GetTypes())
-                    {
-                        Debug.WriteLine(t.FullName, asm.FullName);
-                    }
-                }
-                return asm;
-            }
-        }
-
-        #endregion
-
-        // *******************************************************************
-        // The following tests excercise options for protogen.exe
-        // *******************************************************************
-
-        [Test]
-        public void TestProtoFile()
-        {
-            string test = new StackFrame(false).GetMethod().Name;
-            Setup();
-            using (TempFile source = TempFile.Attach(test + "".cs""))
-            using (ProtoFile proto = new ProtoFile(test + "".proto"", DefaultProto))
-            {
-                RunProtoGen(0, proto.TempPath);
-                Assembly a = RunCsc(0, source.TempPath);
-                //assert that the message type is in the expected namespace
-                Type t = a.GetType(""nunit.simple.MyMessage"", true, true);
-                Assert.IsTrue(typeof(IMessage).IsAssignableFrom(t), ""Expect an IMessage"");
-                //assert that we can find the static descriptor type
-                a.GetType(""nunit.simple."" + test, true, true);
-            }
-        }
-
-        [Test]
-        public void TestProtoFileWithConflictingType()
-        {
-            string test = new StackFrame(false).GetMethod().Name;
-            Setup();
-            using (TempFile source = TempFile.Attach(test + "".cs""))
-            using (
-                ProtoFile proto = new ProtoFile(test + "".proto"",
-                                                @""
-package nunit.simple;
-// Test a very simple message.
-message "" +
-                                                test + @"" {
-  optional string name = 1;
-} ""))
-            {
-                RunProtoGen(0, proto.TempPath);
-                Assembly a = RunCsc(0, source.TempPath);
-                //assert that the message type is in the expected namespace
-                Type t = a.GetType(""nunit.simple."" + test, true, true);
-                Assert.IsTrue(typeof(IMessage).IsAssignableFrom(t), ""Expect an IMessage"");
-                //assert that we can find the static descriptor type
-                a.GetType(""nunit.simple.Proto."" + test, true, true);
-            }
-        }
-
-        [Test]
-        public void TestProtoFileWithNamespace()
-        {
-            string test = new StackFrame(false).GetMethod().Name;
-            Setup();
-            using (TempFile source = TempFile.Attach(test + "".cs""))
-            using (ProtoFile proto = new ProtoFile(test + "".proto"", DefaultProto))
-            {
-                RunProtoGen(0, proto.TempPath, ""-namespace:MyNewNamespace"");
-                Assembly a = RunCsc(0, source.TempPath);
-                //assert that the message type is in the expected namespace
-                Type t = a.GetType(""MyNewNamespace.MyMessage"", true, true);
-                Assert.IsTrue(typeof(IMessage).IsAssignableFrom(t), ""Expect an IMessage"");
-                //assert that we can find the static descriptor type
-                a.GetType(""MyNewNamespace."" + test, true, true);
-            }
-        }
-
-        [Test]
-        public void TestProtoFileWithUmbrellaClassName()
-        {
-            string test = new StackFrame(false).GetMethod().Name;
-            Setup();
-            using (TempFile source = TempFile.Attach(""MyUmbrellaClassname.cs""))
-            using (ProtoFile proto = new ProtoFile(test + "".proto"", DefaultProto))
-            {
-                RunProtoGen(0, proto.TempPath, ""/umbrella_classname=MyUmbrellaClassname"");
-                Assembly a = RunCsc(0, source.TempPath);
-                //assert that the message type is in the expected namespace
-                Type t = a.GetType(""nunit.simple.MyMessage"", true, true);
-                Assert.IsTrue(typeof(IMessage).IsAssignableFrom(t), ""Expect an IMessage"");
-                //assert that we can find the static descriptor type
-                a.GetType(""nunit.simple.MyUmbrellaClassname"", true, true);
-            }
-        }
-
-        [Test]
-        public void TestProtoFileWithNestedClass()
-        {
-            string test = new StackFrame(false).GetMethod().Name;
-            Setup();
-            using (TempFile source = TempFile.Attach(test + "".cs""))
-            using (ProtoFile proto = new ProtoFile(test + "".proto"", DefaultProto))
-            {
-                RunProtoGen(0, proto.TempPath, ""-nest_classes:true"");
-                Assembly a = RunCsc(0, source.TempPath);
-                //assert that the message type is in the expected namespace
-                Type t = a.GetType(""nunit.simple."" + test + ""+MyMessage"", true, true);
-                Assert.IsTrue(typeof(IMessage).IsAssignableFrom(t), ""Expect an IMessage"");
-                //assert that we can find the static descriptor type
-                a.GetType(""nunit.simple."" + test, true, true);
-            }
-        }
-
-        [Test]
-        public void TestProtoFileWithExpandedNsDirectories()
-        {
-            string test = new StackFrame(false).GetMethod().Name;
-            Setup();
-            using (TempFile source = TempFile.Attach(@""nunit\simple\"" + test + "".cs""))
-            using (ProtoFile proto = new ProtoFile(test + "".proto"", DefaultProto))
-            {
-                RunProtoGen(0, proto.TempPath, ""-expand_namespace_directories:true"");
-                Assembly a = RunCsc(0, source.TempPath);
-                //assert that the message type is in the expected namespace
-                Type t = a.GetType(""nunit.simple.MyMessage"", true, true);
-                Assert.IsTrue(typeof(IMessage).IsAssignableFrom(t), ""Expect an IMessage"");
-                //assert that we can find the static descriptor type
-                a.GetType(""nunit.simple."" + test, true, true);
-            }
-        }
-
-        [Test]
-        public void TestProtoFileWithNewExtension()
-        {
-            string test = new StackFrame(false).GetMethod().Name;
-            Setup();
-            using (TempFile source = TempFile.Attach(test + "".Generated.cs""))
-            using (ProtoFile proto = new ProtoFile(test + "".proto"", DefaultProto))
-            {
-                RunProtoGen(0, proto.TempPath, ""-file_extension:.Generated.cs"");
-                Assembly a = RunCsc(0, source.TempPath);
-                //assert that the message type is in the expected namespace
-                Type t = a.GetType(""nunit.simple.MyMessage"", true, true);
-                Assert.IsTrue(typeof(IMessage).IsAssignableFrom(t), ""Expect an IMessage"");
-                //assert that we can find the static descriptor type
-                a.GetType(""nunit.simple."" + test, true, true);
-            }
-        }
-
-        [Test]
-        public void TestProtoFileWithUmbrellaNamespace()
-        {
-            string test = new StackFrame(false).GetMethod().Name;
-            Setup();
-            using (TempFile source = TempFile.Attach(test + "".cs""))
-            using (ProtoFile proto = new ProtoFile(test + "".proto"", DefaultProto))
-            {
-                RunProtoGen(0, proto.TempPath, ""-umbrella_namespace:MyUmbrella.Namespace"");
-                Assembly a = RunCsc(0, source.TempPath);
-                //assert that the message type is in the expected namespace
-                Type t = a.GetType(""nunit.simple.MyMessage"", true, true);
-                Assert.IsTrue(typeof(IMessage).IsAssignableFrom(t), ""Expect an IMessage"");
-                //assert that we can find the static descriptor type
-                a.GetType(""nunit.simple.MyUmbrella.Namespace."" + test, true, true);
-            }
-        }
-
-        [Test]
-        public void TestProtoFileWithIgnoredUmbrellaNamespaceDueToNesting()
-        {
-            string test = new StackFrame(false).GetMethod().Name;
-            Setup();
-            using (TempFile source = TempFile.Attach(test + "".cs""))
-            using (ProtoFile proto = new ProtoFile(test + "".proto"", DefaultProto))
-            {
-                RunProtoGen(0, proto.TempPath, ""-nest_classes:true"", ""-umbrella_namespace:MyUmbrella.Namespace"");
-                Assembly a = RunCsc(0, source.TempPath);
-                //assert that the message type is in the expected namespace
-                Type t = a.GetType(""nunit.simple."" + test + ""+MyMessage"", true, true);
-                Assert.IsTrue(typeof(IMessage).IsAssignableFrom(t), ""Expect an IMessage"");
-                //assert that we can find the static descriptor type
-                a.GetType(""nunit.simple."" + test, true, true);
-            }
-        }
-
-        [Test]
-        public void TestProtoFileWithExplicitEmptyUmbrellaNamespace()
-        {
-            string test = new StackFrame(false).GetMethod().Name;
-            Setup();
-            using (TempFile source = TempFile.Attach(test + "".cs""))
-            using (
-                ProtoFile proto = new ProtoFile(test + "".proto"",
-                                                @""
-package nunit.simple;
-// Test a very simple message.
-message "" +
-                                                test + @"" {
-  optional string name = 1;
-} ""))
-            {
-                //Forces the umbrella class to not use a namespace even if a collision with a type is detected.
-                RunProtoGen(0, proto.TempPath, ""-umbrella_namespace:"");
-                //error CS0441: 'nunit.simple.TestProtoFileWithExplicitEmptyUmbrellaNamespace': a class cannot be both static and sealed
-                RunCsc(1, source.TempPath);
-            }
-        }
-
-        [Test]
-        public void TestProtoFileWithNewOutputFolder()
-        {
-            string test = new StackFrame(false).GetMethod().Name;
-            Setup();
-            using (TempFile source = TempFile.Attach(@""generated-code\"" + test + "".cs""))
-            using (ProtoFile proto = new ProtoFile(test + "".proto"", DefaultProto))
-            {
-                RunProtoGen(1, proto.TempPath, ""-output_directory:generated-code"");
-                Directory.CreateDirectory(""generated-code"");
-                RunProtoGen(0, proto.TempPath, ""-output_directory:generated-code"");
-                Assembly a = RunCsc(0, source.TempPath);
-                //assert that the message type is in the expected namespace
-                Type t = a.GetType(""nunit.simple.MyMessage"", true, true);
-                Assert.IsTrue(typeof(IMessage).IsAssignableFrom(t), ""Expect an IMessage"");
-                //assert that we can find the static descriptor type
-                a.GetType(""nunit.simple."" + test, true, true);
-            }
-        }
-
-        [Test]
-        public void TestProtoFileAndIgnoreGoogleProtobuf()
-        {
-            string test = new StackFrame(false).GetMethod().Name;
-            Setup();
-            using (TempFile source = TempFile.Attach(test + "".cs""))
-            using (
-                ProtoFile proto = new ProtoFile(test + "".proto"",
-                                                @""
-import """"google/protobuf/csharp_options.proto"""";
-option (google.protobuf.csharp_file_options).namespace = """"MyNewNamespace"""";
-"" +
-                                                DefaultProto))
-            {
-                string google = Path.Combine(TempPath, ""google\\protobuf"");
-                Directory.CreateDirectory(google);
-                foreach (string file in Directory.GetFiles(Path.Combine(OriginalWorkingDirectory, ""google\\protobuf"")))
-                {
-                    File.Copy(file, Path.Combine(google, Path.GetFileName(file)));
-                }
-
-                Assert.AreEqual(0, Directory.GetFiles(TempPath, ""*.cs"").Length);
-                RunProtoGen(0, proto.TempPath, ""-ignore_google_protobuf:true"");
-                Assert.AreEqual(1, Directory.GetFiles(TempPath, ""*.cs"").Length);
-
-                Assembly a = RunCsc(0, source.TempPath);
-                //assert that the message type is in the expected namespace
-                Type t = a.GetType(""MyNewNamespace.MyMessage"", true, true);
-                Assert.IsTrue(typeof(IMessage).IsAssignableFrom(t), ""Expect an IMessage"");
-                //assert that we can find the static descriptor type
-                a.GetType(""MyNewNamespace."" + test, true, true);
-            }
-        }
-
-        [Test]
-        public void TestProtoFileWithoutIgnoreGoogleProtobuf()
-        {
-            string test = new StackFrame(false).GetMethod().Name;
-            Setup();
-            using (TempFile source = TempFile.Attach(test + "".cs""))
-            using (
-                ProtoFile proto = new ProtoFile(test + "".proto"",
-                                                @""
-import """"google/protobuf/csharp_options.proto"""";
-option (google.protobuf.csharp_file_options).namespace = """"MyNewNamespace"""";
-"" +
-                                                DefaultProto))
-            {
-                string google = Path.Combine(TempPath, ""google\\protobuf"");
-                Directory.CreateDirectory(google);
-                foreach (string file in Directory.GetFiles(Path.Combine(OriginalWorkingDirectory, ""google\\protobuf"")))
-                {
-                    File.Copy(file, Path.Combine(google, Path.GetFileName(file)));
-                }
-
-                Assert.AreEqual(0, Directory.GetFiles(TempPath, ""*.cs"").Length);
-                //Without the option this fails due to being unable to resolve google/protobuf descriptors
-                RunProtoGen(1, proto.TempPath, ""-ignore_google_protobuf:false"");
-            }
-        }
-
-        // *******************************************************************
-        // The following tests excercise options for protoc.exe
-        // *******************************************************************
-
-        [Test]
-        public void TestProtoFileWithIncludeImports()
-        {
-            string test = new StackFrame(false).GetMethod().Name;
-            Setup();
-            using (TempFile source = TempFile.Attach(test + "".cs""))
-            using (
-                ProtoFile proto = new ProtoFile(test + "".proto"",
-                                                @""
-import """"google/protobuf/csharp_options.proto"""";
-option (google.protobuf.csharp_file_options).namespace = """"MyNewNamespace"""";
-
-package nunit.simple;
-// Test a very simple message.
-message MyMessage {
-  optional string name = 1;
-} "")
-                )
-            {
-                string google = Path.Combine(TempPath, ""google\\protobuf"");
-                Directory.CreateDirectory(google);
-                foreach (string file in Directory.GetFiles(Path.Combine(OriginalWorkingDirectory, ""google\\protobuf"")))
-                {
-                    File.Copy(file, Path.Combine(google, Path.GetFileName(file)));
-                }
-
-                Assert.AreEqual(0, Directory.GetFiles(TempPath, ""*.cs"").Length);
-                //if you specify the protoc option --include_imports this should build three source files
-                RunProtoGen(0, proto.TempPath, ""--include_imports"");
-                Assert.AreEqual(3, Directory.GetFiles(TempPath, ""*.cs"").Length);
-
-                //you can (and should) simply omit the inclusion of the extra source files in your project
-                Assembly a = RunCsc(0, source.TempPath);
-                //assert that the message type is in the expected namespace
-                Type t = a.GetType(""MyNewNamespace.MyMessage"", true, true);
-                Assert.IsTrue(typeof(IMessage).IsAssignableFrom(t), ""Expect an IMessage"");
-                //assert that we can find the static descriptor type
-                a.GetType(""MyNewNamespace."" + test, true, true);
-            }
-        }
-
-        [Test]
-        public void TestProtoFileWithIncludeImportsAndIgnoreGoogleProtobuf()
-        {
-            string test = new StackFrame(false).GetMethod().Name;
-            Setup();
-            using (TempFile source = TempFile.Attach(test + "".cs""))
-            using (
-                ProtoFile proto = new ProtoFile(test + "".proto"",
-                                                @""
-import """"google/protobuf/csharp_options.proto"""";
-option (google.protobuf.csharp_file_options).namespace = """"MyNewNamespace"""";
-
-package nunit.simple;
-// Test a very simple message.
-message MyMessage {
-  optional string name = 1;
-} "")
-                )
-            {
-                string google = Path.Combine(TempPath, ""google\\protobuf"");
-                Directory.CreateDirectory(google);
-                foreach (string file in Directory.GetFiles(Path.Combine(OriginalWorkingDirectory, ""google\\protobuf"")))
-                    File.Copy(file, Path.Combine(google, Path.GetFileName(file)));
-
-                Assert.AreEqual(0, Directory.GetFiles(TempPath, ""*.cs"").Length);
-                //Even with --include_imports, if you provide -ignore_google_protobuf:true you only get the one source file
-                RunProtoGen(0, proto.TempPath, ""-ignore_google_protobuf:true"", ""--include_imports"");
-                Assert.AreEqual(1, Directory.GetFiles(TempPath, ""*.cs"").Length);
-
-                //you can (and should) simply omit the inclusion of the extra source files in your project
-                Assembly a = RunCsc(0, source.TempPath);
-                //assert that the message type is in the expected namespace
-                Type t = a.GetType(""MyNewNamespace.MyMessage"", true, true);
-                Assert.IsTrue(typeof(IMessage).IsAssignableFrom(t), ""Expect an IMessage"");
-                //assert that we can find the static descriptor type
-                a.GetType(""MyNewNamespace."" + test, true, true);
-            }
-        }
-
-        [Test]
-        public void TestProtoFileKeepingTheProtoBuffer()
-        {
-            string test = new StackFrame(false).GetMethod().Name;
-            Setup();
-            using (TempFile protobuf = TempFile.Attach(test + "".pb""))
-            using (TempFile source = TempFile.Attach(test + "".cs""))
-            using (
-                ProtoFile proto = new ProtoFile(test + "".proto"",
-                                                @""
-package nunit.simple;
-// Test a very simple message.
-message MyMessage {
-  optional string name = 1;
-} "")
-                )
-            {
-                RunProtoGen(0, proto.TempPath, ""--descriptor_set_out="" + protobuf.TempPath);
-                Assert.IsTrue(File.Exists(protobuf.TempPath), ""Missing: "" + protobuf.TempPath);
-                Assembly a = RunCsc(0, source.TempPath);
-                //assert that the message type is in the expected namespace
-                Type t = a.GetType(""nunit.simple.MyMessage"", true, true);
-                Assert.IsTrue(typeof(IMessage).IsAssignableFrom(t), ""Expect an IMessage"");
-                //assert that we can find the static descriptor type
-                a.GetType(""nunit.simple."" + test, true, true);
-            }
-        }
-
-        //Seems the --proto_path or -I option is non-functional for me.  Maybe others have luck?
-        [Test]
-        public void TestProtoFileInDifferentDirectory()
-        {
-            string test = new StackFrame(false).GetMethod().Name;
-            Setup();
-            using (TempFile source = TempFile.Attach(test + "".cs""))
-            using (ProtoFile proto = new ProtoFile(test + "".proto"", DefaultProto))
-            {
-                Environment.CurrentDirectory = OriginalWorkingDirectory;
-                RunProtoGen(0, proto.TempPath, ""--proto_path="" + TempPath);
-                Assembly a = RunCsc(0, source.TempPath);
-                //assert that the message type is in the expected namespace
-                Type t = a.GetType(""nunit.simple.MyMessage"", true, true);
-                Assert.IsTrue(typeof(IMessage).IsAssignableFrom(t), ""Expect an IMessage"");
-                //assert that we can find the static descriptor type
-                a.GetType(""nunit.simple."" + test, true, true);
-            }
-        }
-
-        // *******************************************************************
-        // Handling of mutliple input files
-        // *******************************************************************
-
-        [Test]
-        public void TestMultipleProtoFiles()
-        {
-            Setup();
-            using (TempFile source1 = TempFile.Attach(""MyMessage.cs""))
-            using (
-                ProtoFile proto1 = new ProtoFile(""MyMessage.proto"",
-                                                 @""
-package nunit.simple;
-// Test a very simple message.
-message MyMessage {
-  optional string name = 1;
-}"")
-                )
-            using (TempFile source2 = TempFile.Attach(""MyMessageList.cs""))
-            using (
-                ProtoFile proto2 = new ProtoFile(""MyMessageList.proto"",
-                                                 @""
-package nunit.simple;
-import """"MyMessage.proto"""";
-// Test a very simple message.
-message MyMessageList {
-  repeated MyMessage messages = 1;
-}"")
-                )
-            {
-                RunProtoGen(0, proto1.TempPath, proto2.TempPath);
-                Assembly a = RunCsc(0, source1.TempPath, source2.TempPath);
-                //assert that the message type is in the expected namespace
-                Type t1 = a.GetType(""nunit.simple.MyMessage"", true, true);
-                Assert.IsTrue(typeof(IMessage).IsAssignableFrom(t1), ""Expect an IMessage"");
-                //assert that the message type is in the expected namespace
-                Type t2 = a.GetType(""nunit.simple.MyMessageList"", true, true);
-                Assert.IsTrue(typeof(IMessage).IsAssignableFrom(t2), ""Expect an IMessage"");
-                //assert that we can find the static descriptor type
-                a.GetType(""nunit.simple.Proto.MyMessage"", true, true);
-                a.GetType(""nunit.simple.Proto.MyMessageList"", true, true);
-            }
-        }
-
-        [Test]
-        public void TestOneProtoFileWithBufferFile()
-        {
-            Setup();
-            using (TempFile source1 = TempFile.Attach(""MyMessage.cs""))
-            using (TempFile protobuf = TempFile.Attach(""MyMessage.pb""))
-            using (
-                ProtoFile proto1 = new ProtoFile(""MyMessage.proto"",
-                                                 @""
-package nunit.simple;
-// Test a very simple message.
-message MyMessage {
-  optional string name = 1;
-}"")
-                )
-            using (TempFile source2 = TempFile.Attach(""MyMessageList.cs""))
-            using (
-                ProtoFile proto2 = new ProtoFile(""MyMessageList.proto"",
-                                                 @""
-package nunit.simple;
-import """"MyMessage.proto"""";
-// Test a very simple message.
-message MyMessageList {
-  repeated MyMessage messages = 1;
-}"")
-                )
-            {
-                //build the proto buffer for MyMessage
-                RunProtoGen(0, proto1.TempPath, ""--descriptor_set_out="" + protobuf.TempPath);
-                //build the MyMessageList proto-buffer and generate code by including MyMessage.pb
-                RunProtoGen(0, proto2.TempPath, protobuf.TempPath);
-                Assembly a = RunCsc(0, source1.TempPath, source2.TempPath);
-                //assert that the message type is in the expected namespace
-                Type t1 = a.GetType(""nunit.simple.MyMessage"", true, true);
-                Assert.IsTrue(typeof(IMessage).IsAssignableFrom(t1), ""Expect an IMessage"");
-                //assert that the message type is in the expected namespace
-                Type t2 = a.GetType(""nunit.simple.MyMessageList"", true, true);
-                Assert.IsTrue(typeof(IMessage).IsAssignableFrom(t2), ""Expect an IMessage"");
-                //assert that we can find the static descriptor type
-                a.GetType(""nunit.simple.Proto.MyMessage"", true, true);
-                a.GetType(""nunit.simple.Proto.MyMessageList"", true, true);
-            }
-        }
-
-        [Test]
-        public void TestProtoFileWithService()
-        {
-            string test = new StackFrame(false).GetMethod().Name;
-            Setup();
-            using (TempFile source = TempFile.Attach(test + "".cs""))
-            using (ProtoFile proto = new ProtoFile(test + "".proto"",
-@""
-import """"google/protobuf/csharp_options.proto"""";
-option (google.protobuf.csharp_file_options).service_generator_type = GENERIC;
-
-package nunit.simple;
-// Test a very simple message.
-message MyMessage {
-  optional string name = 1;
-}
-// test a very simple service.
-service TestService {
-  rpc Execute (MyMessage) returns (MyMessage);
-}""))
-            {
-                CopyInGoogleProtoFiles();
-
-                RunProtoGen(0, proto.TempPath, ""-ignore_google_protobuf:true"", ""-nest_classes=false"");
-                Assert.AreEqual(1, Directory.GetFiles(TempPath, ""*.cs"").Length);
-
-                Assembly a = RunCsc(0, source.TempPath);
-                //assert that the service type is in the expected namespace
-                Type t1 = a.GetType(""nunit.simple.TestService"", true, true);
-                Assert.IsTrue(typeof(IService).IsAssignableFrom(t1), ""Expect an IService"");
-                Assert.IsTrue(t1.IsAbstract, ""Expect abstract class"");
-                //assert that the Stub subclass type is in the expected namespace
-                Type t2 = a.GetType(""nunit.simple.TestService+Stub"", true, true);
-                Assert.IsTrue(t1.IsAssignableFrom(t2), ""Expect a sub of TestService"");
-                Assert.IsFalse(t2.IsAbstract, ""Expect concrete class"");
-            }
-        }
-
-        [Test]
-        public void TestProtoFileWithServiceInternal()
-        {
-            string test = new StackFrame(false).GetMethod().Name;
-            Setup();
-            using (TempFile source = TempFile.Attach(test + "".cs""))
-            using (ProtoFile proto = new ProtoFile(test + "".proto"",
-@""
-import """"google/protobuf/csharp_options.proto"""";
-option (google.protobuf.csharp_file_options).service_generator_type = GENERIC;
-
-package nunit.simple;
-// Test a very simple message.
-message MyMessage {
-  optional string name = 1;
-}
-// test a very simple service.
-service TestService {
-  rpc Execute (MyMessage) returns (MyMessage);
-}""))
-            {
-                CopyInGoogleProtoFiles();
-
-                RunProtoGen(0, proto.TempPath, ""-ignore_google_protobuf:true"", ""-nest_classes=false"", ""-public_classes=false"");
-                Assert.AreEqual(1, Directory.GetFiles(TempPath, ""*.cs"").Length);
-
-                Assembly a = RunCsc(0, source.TempPath);
-                //assert that the service type is in the expected namespace
-                Type t1 = a.GetType(""nunit.simple.TestService"", true, true);
-                Assert.IsTrue(typeof(IService).IsAssignableFrom(t1), ""Expect an IService"");
-                Assert.IsTrue(t1.IsAbstract, ""Expect abstract class"");
-                //assert that the Stub subclass type is in the expected namespace
-                Type t2 = a.GetType(""nunit.simple.TestService+Stub"", true, true);
-                Assert.IsTrue(t1.IsAssignableFrom(t2), ""Expect a sub of TestService"");
-                Assert.IsFalse(t2.IsAbstract, ""Expect concrete class"");
-            }
-        }
-
-        private static void CopyInGoogleProtoFiles()
-        {
-            string google = Path.Combine(TempPath, ""google\\protobuf"");
-            Directory.CreateDirectory(google);
-            foreach (string file in Directory.GetFiles(Path.Combine(OriginalWorkingDirectory, ""google\\protobuf"")))
-            {
-                File.Copy(file, Path.Combine(google, Path.GetFileName(file)));
-            }
-        }
-    }
-}
\ No newline at end of file
diff --git a/csharp/src/ProtoGen.Test/protoc-gen-cs.Test.csproj b/csharp/src/ProtoGen.Test/protoc-gen-cs.Test.csproj
deleted file mode 100644
index 2e816115f..000000000
--- a/csharp/src/ProtoGen.Test/protoc-gen-cs.Test.csproj
+++ /dev/null
@@ -1,101 +0,0 @@
-<?xml version=""1.0"" encoding=""utf-8""?>
-<Project ToolsVersion=""4.0"" DefaultTargets=""Build"" xmlns=""http://schemas.microsoft.com/developer/msbuild/2003"">
-  <PropertyGroup>
-    <EnvironmentFlavor>CLIENTPROFILE</EnvironmentFlavor>
-    <EnvironmentTemplate>NET35</EnvironmentTemplate>
-    <Configuration Condition="" '$(Configuration)' == '' "">Debug</Configuration>
-    <Platform Condition="" '$(Platform)' == '' "">AnyCPU</Platform>
-    <ProductVersion>9.0.30729</ProductVersion>
-    <SchemaVersion>2.0</SchemaVersion>
-    <ProjectGuid>{C1024C9C-8176-48C3-B547-B9F6DF6B80A6}</ProjectGuid>
-    <OutputType>Library</OutputType>
-    <AppDesignerFolder>Properties</AppDesignerFolder>
-    <RootNamespace>Google.ProtocolBuffers.ProtoGen</RootNamespace>
-    <AssemblyName>protoc-gen-cs.Test</AssemblyName>
-    <TargetFrameworkVersion>v3.5</TargetFrameworkVersion>
-    <FileAlignment>512</FileAlignment>
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Debug|AnyCPU' "">
-    <DebugSymbols>true</DebugSymbols>
-    <DebugType>full</DebugType>
-    <Optimize>false</Optimize>
-    <OutputPath>bin\NET35\Debug</OutputPath>
-    <IntermediateOutputPath>obj\NET35\Debug\</IntermediateOutputPath>
-    <DefineConstants>DEBUG;TRACE;$(EnvironmentFlavor);$(EnvironmentTemplate)</DefineConstants>
-    <ErrorReport>prompt</ErrorReport>
-    <WarningLevel>4</WarningLevel>
-    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
-    <NoStdLib>true</NoStdLib>
-    <GenerateSerializationAssemblies>Off</GenerateSerializationAssemblies>
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Release|AnyCPU' "">
-    <DebugType>pdbonly</DebugType>
-    <Optimize>true</Optimize>
-    <OutputPath>bin\NET35\Release</OutputPath>
-    <IntermediateOutputPath>obj\NET35\Release\</IntermediateOutputPath>
-    <DefineConstants>TRACE;$(EnvironmentFlavor);$(EnvironmentTemplate)</DefineConstants>
-    <ErrorReport>prompt</ErrorReport>
-    <WarningLevel>4</WarningLevel>
-    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
-    <NoStdLib>true</NoStdLib>
-    <GenerateSerializationAssemblies>Off</GenerateSerializationAssemblies>
-  </PropertyGroup>
-  <ItemGroup>
-    <Reference Include=""nunit.framework"">
-      <SpecificVersion>False</SpecificVersion>
-      <HintPath>..\..\lib\NUnit\lib\nunit.framework.dll</HintPath>
-    </Reference>
-    <Reference Include=""mscorlib"" />
-    <Reference Include=""System"" />
-    <Reference Include=""System.Data"" />
-    <Reference Include=""System.Xml"" />
-  </ItemGroup>
-  <ItemGroup>
-    <Compile Include=""ProtocGenCsUnittests.cs"" />
-    <Compile Include=""Properties\AssemblyInfo.cs"" />
-    <Compile Include=""TempFile.cs"" />
-  </ItemGroup>
-  <ItemGroup>
-    <ProjectReference Include=""..\ProtocolBuffers\ProtocolBuffers.csproj"">
-      <Project>{6908bdce-d925-43f3-94ac-a531e6df2591}</Project>
-      <Name>ProtocolBuffers</Name>
-    </ProjectReference>
-    <ProjectReference Include=""..\ProtoGen\protoc-gen-cs.csproj"">
-      <Project>{250ade34-82fd-4bae-86d5-985fbe589c4b}</Project>
-      <Name>protoc-gen-cs</Name>
-    </ProjectReference>
-  </ItemGroup>
-  <ItemGroup>
-    <Content Include=""..\..\lib\protoc.exe"">
-      <Link>protoc.exe</Link>
-      <CopyToOutputDirectory>PreserveNewest</CopyToOutputDirectory>
-    </Content>
-  </ItemGroup>
-  <ItemGroup>
-    <None Include=""..\..\protos\google\protobuf\csharp_options.proto"">
-      <Link>google\protobuf\csharp_options.proto</Link>
-      <CopyToOutputDirectory>PreserveNewest</CopyToOutputDirectory>
-    </None>
-    <None Include=""..\..\protos\google\protobuf\descriptor.proto"">
-      <Link>google\protobuf\descriptor.proto</Link>
-      <CopyToOutputDirectory>PreserveNewest</CopyToOutputDirectory>
-    </None>
-  </ItemGroup>
-  <ItemGroup>
-    <Service Include=""{82A7F48D-3B50-4B1E-B82E-3ADA8210C358}"" />
-  </ItemGroup>
-  <Import Project=""$(MSBuildToolsPath)\Microsoft.CSharp.targets"" />
-  <!-- To modify your build process, add your task inside one of the targets below and uncomment it. 
-       Other similar extension points exist, see Microsoft.Common.targets.
-  <Target Name=""BeforeBuild"">
-  </Target>
-  <Target Name=""AfterBuild"">
-  </Target>
-  -->
-  <PropertyGroup>
-    <StartAction>Program</StartAction>
-    <StartProgram>$(ProjectDir)..\..\lib\NUnit\tools\nunit-console.exe</StartProgram>
-    <StartArguments>/nologo /noshadow /labels /wait $(AssemblyName).dll</StartArguments>
-    <StartWorkingDirectory>$(ProjectDir)$(OutputPath)</StartWorkingDirectory>
-  </PropertyGroup>
-</Project>
\ No newline at end of file
diff --git a/csharp/src/ProtoGen/DependencyResolutionException.cs b/csharp/src/ProtoGen/DependencyResolutionException.cs
deleted file mode 100644
index aef192e05..000000000
--- a/csharp/src/ProtoGen/DependencyResolutionException.cs
+++ /dev/null
@@ -1,55 +0,0 @@
-#region Copyright notice and license
-
-// Protocol Buffers - Google's data interchange format
-// Copyright 2008 Google Inc.  All rights reserved.
-// http://github.com/jskeet/dotnet-protobufs/
-// Original C++/Java/Python code:
-// http://code.google.com/p/protobuf/
-//
-// Redistribution and use in source and binary forms, with or without
-// modification, are permitted provided that the following conditions are
-// met:
-//
-//     * Redistributions of source code must retain the above copyright
-// notice, this list of conditions and the following disclaimer.
-//     * Redistributions in binary form must reproduce the above
-// copyright notice, this list of conditions and the following disclaimer
-// in the documentation and/or other materials provided with the
-// distribution.
-//     * Neither the name of Google Inc. nor the names of its
-// contributors may be used to endorse or promote products derived from
-// this software without specific prior written permission.
-//
-// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-// ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
-#endregion
-
-using System;
-
-namespace Google.ProtocolBuffers.ProtoGen
-{
-    /// <summary>
-    /// Exception thrown when dependencies within a descriptor set can't be resolved.
-    /// </summary>
-    public sealed class DependencyResolutionException : Exception
-    {
-        public DependencyResolutionException(string message) : base(message)
-        {
-        }
-
-        public DependencyResolutionException(string format, params object[] args)
-            : base(string.Format(format, args))
-        {
-        }
-    }
-}
\ No newline at end of file
diff --git a/csharp/src/ProtoGen/DescriptorUtil.cs b/csharp/src/ProtoGen/DescriptorUtil.cs
deleted file mode 100644
index 0666bb933..000000000
--- a/csharp/src/ProtoGen/DescriptorUtil.cs
+++ /dev/null
@@ -1,106 +0,0 @@
-#region Copyright notice and license
-
-// Protocol Buffers - Google's data interchange format
-// Copyright 2008 Google Inc.  All rights reserved.
-// http://github.com/jskeet/dotnet-protobufs/
-// Original C++/Java/Python code:
-// http://code.google.com/p/protobuf/
-//
-// Redistribution and use in source and binary forms, with or without
-// modification, are permitted provided that the following conditions are
-// met:
-//
-//     * Redistributions of source code must retain the above copyright
-// notice, this list of conditions and the following disclaimer.
-//     * Redistributions in binary form must reproduce the above
-// copyright notice, this list of conditions and the following disclaimer
-// in the documentation and/or other materials provided with the
-// distribution.
-//     * Neither the name of Google Inc. nor the names of its
-// contributors may be used to endorse or promote products derived from
-// this software without specific prior written permission.
-//
-// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-// ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
-#endregion
-
-using System;
-using Google.ProtocolBuffers.DescriptorProtos;
-using Google.ProtocolBuffers.Descriptors;
-
-namespace Google.ProtocolBuffers.ProtoGen
-{
-    /// <summary>
-    /// Utility class for determining namespaces etc.
-    /// </summary>
-    internal static class DescriptorUtil
-    {
-        internal static string GetFullUmbrellaClassName(IDescriptor descriptor)
-        {
-            CSharpFileOptions options = descriptor.File.CSharpOptions;
-            string result = options.Namespace;
-            if (result != """")
-            {
-                result += '.';
-            }
-            result += GetQualifiedUmbrellaClassName(options);
-            return ""global::"" + result;
-        }
-
-        /// <summary>
-        /// Evaluates the options and returns the qualified name of the umbrella class
-        /// relative to the descriptor type's namespace.  Basically concatenates the
-        /// UmbrellaNamespace + UmbrellaClassname fields.
-        /// </summary>
-        internal static string GetQualifiedUmbrellaClassName(CSharpFileOptions options)
-        {
-            string fullName = options.UmbrellaClassname;
-            if (!options.NestClasses && options.UmbrellaNamespace != """")
-            {
-                fullName = String.Format(""{0}.{1}"", options.UmbrellaNamespace, options.UmbrellaClassname);
-            }
-            return fullName;
-        }
-
-        internal static string GetMappedTypeName(MappedType type)
-        {
-            switch (type)
-            {
-                case MappedType.Int32:
-                    return ""int"";
-                case MappedType.Int64:
-                    return ""long"";
-                case MappedType.UInt32:
-                    return ""uint"";
-                case MappedType.UInt64:
-                    return ""ulong"";
-                case MappedType.Single:
-                    return ""float"";
-                case MappedType.Double:
-                    return ""double"";
-                case MappedType.Boolean:
-                    return ""bool"";
-                case MappedType.String:
-                    return ""string"";
-                case MappedType.ByteString:
-                    return ""pb::ByteString"";
-                case MappedType.Enum:
-                    return null;
-                case MappedType.Message:
-                    return null;
-                default:
-                    throw new ArgumentOutOfRangeException(""Unknown mapped type "" + type);
-            }
-        }
-    }
-}
\ No newline at end of file
diff --git a/csharp/src/ProtoGen/EnumFieldGenerator.cs b/csharp/src/ProtoGen/EnumFieldGenerator.cs
deleted file mode 100644
index 8d70bc676..000000000
--- a/csharp/src/ProtoGen/EnumFieldGenerator.cs
+++ /dev/null
@@ -1,148 +0,0 @@
-#region Copyright notice and license
-
-// Protocol Buffers - Google's data interchange format
-// Copyright 2008 Google Inc.  All rights reserved.
-// http://github.com/jskeet/dotnet-protobufs/
-// Original C++/Java/Python code:
-// http://code.google.com/p/protobuf/
-//
-// Redistribution and use in source and binary forms, with or without
-// modification, are permitted provided that the following conditions are
-// met:
-//
-//     * Redistributions of source code must retain the above copyright
-// notice, this list of conditions and the following disclaimer.
-//     * Redistributions in binary form must reproduce the above
-// copyright notice, this list of conditions and the following disclaimer
-// in the documentation and/or other materials provided with the
-// distribution.
-//     * Neither the name of Google Inc. nor the names of its
-// contributors may be used to endorse or promote products derived from
-// this software without specific prior written permission.
-//
-// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-// ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
-#endregion
-
-using Google.ProtocolBuffers.Descriptors;
-
-namespace Google.ProtocolBuffers.ProtoGen
-{
-    internal class EnumFieldGenerator : FieldGeneratorBase, IFieldSourceGenerator
-    {
-        internal EnumFieldGenerator(FieldDescriptor descriptor, int fieldOrdinal)
-            : base(descriptor, fieldOrdinal)
-        {
-        }
-
-        public void GenerateMembers(TextGenerator writer)
-        {
-            writer.WriteLine(""private bool has{0};"", PropertyName);
-            writer.WriteLine(""private {0} {1}_ = {2};"", TypeName, Name, DefaultValue);
-            AddDeprecatedFlag(writer);
-            writer.WriteLine(""public bool Has{0} {{"", PropertyName);
-            writer.WriteLine(""  get {{ return has{0}; }}"", PropertyName);
-            writer.WriteLine(""}"");
-            AddPublicMemberAttributes(writer);
-            writer.WriteLine(""public {0} {1} {{"", TypeName, PropertyName);
-            writer.WriteLine(""  get {{ return {0}_; }}"", Name);
-            writer.WriteLine(""}"");
-        }
-
-        public void GenerateBuilderMembers(TextGenerator writer)
-        {
-            AddDeprecatedFlag(writer);
-            writer.WriteLine(""public bool Has{0} {{"", PropertyName);
-            writer.WriteLine("" get {{ return result.has{0}; }}"", PropertyName);
-            writer.WriteLine(""}"");
-            AddPublicMemberAttributes(writer);
-            writer.WriteLine(""public {0} {1} {{"", TypeName, PropertyName);
-            writer.WriteLine(""  get {{ return result.{0}; }}"", PropertyName);
-            writer.WriteLine(""  set {{ Set{0}(value); }}"", PropertyName);
-            writer.WriteLine(""}"");
-            AddPublicMemberAttributes(writer);
-            writer.WriteLine(""public Builder Set{0}({1} value) {{"", PropertyName, TypeName);
-            writer.WriteLine(""  PrepareBuilder();"");
-            writer.WriteLine(""  result.has{0} = true;"", PropertyName);
-            writer.WriteLine(""  result.{0}_ = value;"", Name);
-            writer.WriteLine(""  return this;"");
-            writer.WriteLine(""}"");
-            AddDeprecatedFlag(writer);
-            writer.WriteLine(""public Builder Clear{0}() {{"", PropertyName);
-            writer.WriteLine(""  PrepareBuilder();"");
-            writer.WriteLine(""  result.has{0} = false;"", PropertyName);
-            writer.WriteLine(""  result.{0}_ = {1};"", Name, DefaultValue);
-            writer.WriteLine(""  return this;"");
-            writer.WriteLine(""}"");
-        }
-
-        public void GenerateMergingCode(TextGenerator writer)
-        {
-            writer.WriteLine(""if (other.Has{0}) {{"", PropertyName);
-            writer.WriteLine(""  {0} = other.{0};"", PropertyName);
-            writer.WriteLine(""}"");
-        }
-
-        public void GenerateBuildingCode(TextGenerator writer)
-        {
-            // Nothing to do here for enum types
-        }
-
-        public void GenerateParsingCode(TextGenerator writer)
-        {
-            writer.WriteLine(""object unknown;"");
-            writer.WriteLine(""if(input.ReadEnum(ref result.{0}_, out unknown)) {{"", Name);
-            writer.WriteLine(""  result.has{0} = true;"", PropertyName);
-            writer.WriteLine(""} else if(unknown is int) {"");
-            if (!UseLiteRuntime)
-            {
-                writer.WriteLine(""  if (unknownFields == null) {""); // First unknown field - create builder now
-                writer.WriteLine(""    unknownFields = pb::UnknownFieldSet.CreateBuilder(this.UnknownFields);"");
-                writer.WriteLine(""  }"");
-                writer.WriteLine(""  unknownFields.MergeVarintField({0}, (ulong)(int)unknown);"", Number);
-            }
-            writer.WriteLine(""}"");
-        }
-
-        public void GenerateSerializationCode(TextGenerator writer)
-        {
-            writer.WriteLine(""if (has{0}) {{"", PropertyName);
-            writer.WriteLine(""  output.WriteEnum({0}, field_names[{2}], (int) {1}, {1});"", Number, PropertyName,
-                             FieldOrdinal);
-            writer.WriteLine(""}"");
-        }
-
-        public void GenerateSerializedSizeCode(TextGenerator writer)
-        {
-            writer.WriteLine(""if (has{0}) {{"", PropertyName);
-            writer.WriteLine(""  size += pb::CodedOutputStream.ComputeEnumSize({0}, (int) {1});"", Number, PropertyName);
-            writer.WriteLine(""}"");
-        }
-
-        public override void WriteHash(TextGenerator writer)
-        {
-            writer.WriteLine(""if (has{0}) hash ^= {1}_.GetHashCode();"", PropertyName, Name);
-        }
-
-        public override void WriteEquals(TextGenerator writer)
-        {
-            writer.WriteLine(""if (has{0} != other.has{0} || (has{0} && !{1}_.Equals(other.{1}_))) return false;"",
-                             PropertyName, Name);
-        }
-
-        public override void WriteToString(TextGenerator writer)
-        {
-            writer.WriteLine(""PrintField(\""{0}\"", has{1}, {2}_, writer);"", Descriptor.Name, PropertyName, Name);
-        }
-    }
-}
\ No newline at end of file
diff --git a/csharp/src/ProtoGen/EnumGenerator.cs b/csharp/src/ProtoGen/EnumGenerator.cs
deleted file mode 100644
index a6ed45d1c..000000000
--- a/csharp/src/ProtoGen/EnumGenerator.cs
+++ /dev/null
@@ -1,62 +0,0 @@
-#region Copyright notice and license
-
-// Protocol Buffers - Google's data interchange format
-// Copyright 2008 Google Inc.  All rights reserved.
-// http://github.com/jskeet/dotnet-protobufs/
-// Original C++/Java/Python code:
-// http://code.google.com/p/protobuf/
-//
-// Redistribution and use in source and binary forms, with or without
-// modification, are permitted provided that the following conditions are
-// met:
-//
-//     * Redistributions of source code must retain the above copyright
-// notice, this list of conditions and the following disclaimer.
-//     * Redistributions in binary form must reproduce the above
-// copyright notice, this list of conditions and the following disclaimer
-// in the documentation and/or other materials provided with the
-// distribution.
-//     * Neither the name of Google Inc. nor the names of its
-// contributors may be used to endorse or promote products derived from
-// this software without specific prior written permission.
-//
-// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-// ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
-#endregion
-
-using Google.ProtocolBuffers.Descriptors;
-
-namespace Google.ProtocolBuffers.ProtoGen
-{
-    internal class EnumGenerator : SourceGeneratorBase<EnumDescriptor>, ISourceGenerator
-    {
-        internal EnumGenerator(EnumDescriptor descriptor) : base(descriptor)
-        {
-        }
-
-        // TODO(jonskeet): Write out enum descriptors? Can be retrieved from file...
-        public void Generate(TextGenerator writer)
-        {
-            WriteGeneratedCodeAttributes(writer);
-            writer.WriteLine(""{0} enum {1} {{"", ClassAccessLevel, Descriptor.Name);
-            writer.Indent();
-            foreach (EnumValueDescriptor value in Descriptor.Values)
-            {
-                writer.WriteLine(""{0} = {1},"", value.Name, value.Number);
-            }
-            writer.Outdent();
-            writer.WriteLine(""}"");
-            writer.WriteLine();
-        }
-    }
-}
\ No newline at end of file
diff --git a/csharp/src/ProtoGen/ExtensionGenerator.cs b/csharp/src/ProtoGen/ExtensionGenerator.cs
deleted file mode 100644
index a862a7a0a..000000000
--- a/csharp/src/ProtoGen/ExtensionGenerator.cs
+++ /dev/null
@@ -1,183 +0,0 @@
-#region Copyright notice and license
-
-// Protocol Buffers - Google's data interchange format
-// Copyright 2008 Google Inc.  All rights reserved.
-// http://github.com/jskeet/dotnet-protobufs/
-// Original C++/Java/Python code:
-// http://code.google.com/p/protobuf/
-//
-// Redistribution and use in source and binary forms, with or without
-// modification, are permitted provided that the following conditions are
-// met:
-//
-//     * Redistributions of source code must retain the above copyright
-// notice, this list of conditions and the following disclaimer.
-//     * Redistributions in binary form must reproduce the above
-// copyright notice, this list of conditions and the following disclaimer
-// in the documentation and/or other materials provided with the
-// distribution.
-//     * Neither the name of Google Inc. nor the names of its
-// contributors may be used to endorse or promote products derived from
-// this software without specific prior written permission.
-//
-// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-// ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
-#endregion
-
-using System;
-using Google.ProtocolBuffers.Descriptors;
-
-namespace Google.ProtocolBuffers.ProtoGen
-{
-    internal class ExtensionGenerator : FieldGeneratorBase, ISourceGenerator
-    {
-        private readonly string extends;
-        private readonly string scope;
-        private readonly string type;
-        private readonly string name;
-
-        internal ExtensionGenerator(FieldDescriptor descriptor)
-            : base(descriptor, 0)
-        {
-            if (Descriptor.ExtensionScope != null)
-            {
-                scope = GetClassName(Descriptor.ExtensionScope);
-            }
-            else
-            {
-                scope = DescriptorUtil.GetFullUmbrellaClassName(Descriptor.File);
-            }
-            switch (Descriptor.MappedType)
-            {
-                case MappedType.Message:
-                    type = GetClassName(Descriptor.MessageType);
-                    break;
-                case MappedType.Enum:
-                    type = GetClassName(Descriptor.EnumType);
-                    break;
-                default:
-                    type = DescriptorUtil.GetMappedTypeName(Descriptor.MappedType);
-                    break;
-            }
-            extends = GetClassName(Descriptor.ContainingType);
-            name = Descriptor.CSharpOptions.PropertyName;
-        }
-
-        public void Generate(TextGenerator writer)
-        {
-            if (Descriptor.File.CSharpOptions.ClsCompliance && GetFieldConstantName(Descriptor).StartsWith(""_""))
-            {
-                writer.WriteLine(""[global::System.CLSCompliant(false)]"");
-            }
-
-            writer.WriteLine(""public const int {0} = {1};"", GetFieldConstantName(Descriptor), Descriptor.FieldNumber);
-
-            if (UseLiteRuntime)
-            {
-                if (Descriptor.MappedType == MappedType.Message && Descriptor.MessageType.Options.MessageSetWireFormat)
-                {
-                    throw new ArgumentException(
-                        ""option message_set_wire_format = true; is not supported in Lite runtime extensions."");
-                }
-                if (!Descriptor.IsCLSCompliant && Descriptor.File.CSharpOptions.ClsCompliance)
-                {
-                    writer.WriteLine(""[global::System.CLSCompliant(false)]"");
-                }
-                writer.WriteLine(""{0} static pb::{4}<{1}, {2}> {3};"", ClassAccessLevel, extends, type, name,
-                                 Descriptor.IsRepeated ? ""GeneratedRepeatExtensionLite"" : ""GeneratedExtensionLite"");
-            }
-            else if (Descriptor.IsRepeated)
-            {
-                if (!Descriptor.IsCLSCompliant && Descriptor.File.CSharpOptions.ClsCompliance)
-                {
-                    writer.WriteLine(""[global::System.CLSCompliant(false)]"");
-                }
-                writer.WriteLine(""{0} static pb::GeneratedExtensionBase<scg::IList<{1}>> {2};"", ClassAccessLevel, type,
-                                 name);
-            }
-            else
-            {
-                if (!Descriptor.IsCLSCompliant && Descriptor.File.CSharpOptions.ClsCompliance)
-                {
-                    writer.WriteLine(""[global::System.CLSCompliant(false)]"");
-                }
-                writer.WriteLine(""{0} static pb::GeneratedExtensionBase<{1}> {2};"", ClassAccessLevel, type, name);
-            }
-        }
-
-        internal void GenerateStaticVariableInitializers(TextGenerator writer)
-        {
-            if (UseLiteRuntime)
-            {
-                writer.WriteLine(""{0}.{1} = "", scope, name);
-                writer.Indent();
-                writer.WriteLine(""new pb::{0}<{1}, {2}>("",
-                                 Descriptor.IsRepeated ? ""GeneratedRepeatExtensionLite"" : ""GeneratedExtensionLite"",
-                                 extends, type);
-                writer.Indent();
-                writer.WriteLine(""\""{0}\"","", Descriptor.FullName);
-                writer.WriteLine(""{0}.DefaultInstance,"", extends);
-                if (!Descriptor.IsRepeated)
-                {
-                    writer.WriteLine(""{0},"",
-                                     Descriptor.HasDefaultValue
-                                         ? DefaultValue
-                                         : IsNullableType ? ""null"" : ""default("" + type + "")"");
-                }
-                writer.WriteLine(""{0},"",
-                                 (Descriptor.MappedType == MappedType.Message) ? type + "".DefaultInstance"" : ""null"");
-                writer.WriteLine(""{0},"",
-                                 (Descriptor.MappedType == MappedType.Enum) ? ""new EnumLiteMap<"" + type + "">()"" : ""null"");
-                writer.WriteLine(""{0}.{1}FieldNumber,"", scope, name);
-                writer.Write(""pbd::FieldType.{0}"", Descriptor.FieldType);
-                if (Descriptor.IsRepeated)
-                {
-                    writer.WriteLine("","");
-                    writer.Write(Descriptor.IsPacked ? ""true"" : ""false"");
-                }
-                writer.Outdent();
-                writer.WriteLine("");"");
-                writer.Outdent();
-            }
-            else if (Descriptor.IsRepeated)
-            {
-                writer.WriteLine(
-                    ""{0}.{1} = pb::GeneratedRepeatExtension<{2}>.CreateInstance({0}.Descriptor.Extensions[{3}]);"", scope,
-                    name, type, Descriptor.Index);
-            }
-            else
-            {
-                writer.WriteLine(
-                    ""{0}.{1} = pb::GeneratedSingleExtension<{2}>.CreateInstance({0}.Descriptor.Extensions[{3}]);"", scope,
-                    name, type, Descriptor.Index);
-            }
-        }
-
-        internal void GenerateExtensionRegistrationCode(TextGenerator writer)
-        {
-            writer.WriteLine(""registry.Add({0}.{1});"", scope, name);
-        }
-
-        public override void WriteHash(TextGenerator writer)
-        {
-        }
-
-        public override void WriteEquals(TextGenerator writer)
-        {
-        }
-
-        public override void WriteToString(TextGenerator writer)
-        {
-        }
-    }
-}
\ No newline at end of file
diff --git a/csharp/src/ProtoGen/FieldGeneratorBase.cs b/csharp/src/ProtoGen/FieldGeneratorBase.cs
deleted file mode 100644
index 93aee6cad..000000000
--- a/csharp/src/ProtoGen/FieldGeneratorBase.cs
+++ /dev/null
@@ -1,389 +0,0 @@
-#region Copyright notice and license
-
-// Protocol Buffers - Google's data interchange format
-// Copyright 2008 Google Inc.  All rights reserved.
-// http://github.com/jskeet/dotnet-protobufs/
-// Original C++/Java/Python code:
-// http://code.google.com/p/protobuf/
-//
-// Redistribution and use in source and binary forms, with or without
-// modification, are permitted provided that the following conditions are
-// met:
-//
-//     * Redistributions of source code must retain the above copyright
-// notice, this list of conditions and the following disclaimer.
-//     * Redistributions in binary form must reproduce the above
-// copyright notice, this list of conditions and the following disclaimer
-// in the documentation and/or other materials provided with the
-// distribution.
-//     * Neither the name of Google Inc. nor the names of its
-// contributors may be used to endorse or promote products derived from
-// this software without specific prior written permission.
-//
-// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-// ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
-#endregion
-
-using System;
-using System.Globalization;
-using System.Text;
-using Google.ProtocolBuffers.Descriptors;
-
-namespace Google.ProtocolBuffers.ProtoGen
-{
-    internal abstract class FieldGeneratorBase : SourceGeneratorBase<FieldDescriptor>
-    {
-        private readonly int _fieldOrdinal;
-
-        protected FieldGeneratorBase(FieldDescriptor descriptor, int fieldOrdinal)
-            : base(descriptor)
-        {
-            _fieldOrdinal = fieldOrdinal;
-        }
-
-        public abstract void WriteHash(TextGenerator writer);
-        public abstract void WriteEquals(TextGenerator writer);
-        public abstract void WriteToString(TextGenerator writer);
-
-        public int FieldOrdinal
-        {
-            get { return _fieldOrdinal; }
-        }
-
-        private static bool AllPrintableAscii(string text)
-        {
-            foreach (char c in text)
-            {
-                if (c < 0x20 || c > 0x7e)
-                {
-                    return false;
-                }
-            }
-            return true;
-        }
-
-        /// <summary>
-        /// This returns true if the field has a non-default default value.  For instance this returns 
-        /// false for numerics with a default of zero '0', or booleans with a default of false.
-        /// </summary>
-        protected bool HasDefaultValue
-        {
-            get
-            {
-                switch (Descriptor.FieldType)
-                {
-                    case FieldType.Float:
-                    case FieldType.Double:
-                    case FieldType.Int32:
-                    case FieldType.Int64:
-                    case FieldType.SInt32:
-                    case FieldType.SInt64:
-                    case FieldType.SFixed32:
-                    case FieldType.SFixed64:
-                    case FieldType.UInt32:
-                    case FieldType.UInt64:
-                    case FieldType.Fixed32:
-                    case FieldType.Fixed64:
-                        {
-                            IConvertible value = (IConvertible) Descriptor.DefaultValue;
-                            return value.ToString(CultureInfo.InvariantCulture) != ""0"";
-                        }
-                    case FieldType.Bool:
-                        return ((bool) Descriptor.DefaultValue) == true;
-                    default:
-                        return true;
-                }
-            }
-        }
-
-        /// <remarks>Copy exists in ExtensionGenerator.cs</remarks>
-        protected string DefaultValue
-        {
-            get
-            {
-                string suffix = """";
-                switch (Descriptor.FieldType)
-                {
-                    case FieldType.Float:
-                        suffix = ""F"";
-                        break;
-                    case FieldType.Double:
-                        suffix = ""D"";
-                        break;
-                    case FieldType.Int64:
-                        suffix = ""L"";
-                        break;
-                    case FieldType.UInt64:
-                        suffix = ""UL"";
-                        break;
-                }
-                switch (Descriptor.FieldType)
-                {
-                    case FieldType.Float:
-                    case FieldType.Double:
-                    case FieldType.Int32:
-                    case FieldType.Int64:
-                    case FieldType.SInt32:
-                    case FieldType.SInt64:
-                    case FieldType.SFixed32:
-                    case FieldType.SFixed64:
-                    case FieldType.UInt32:
-                    case FieldType.UInt64:
-                    case FieldType.Fixed32:
-                    case FieldType.Fixed64:
-                        {
-                            // The simple Object.ToString converts using the current culture.
-                            // We want to always use the invariant culture so it's predictable.
-                            IConvertible value = (IConvertible) Descriptor.DefaultValue;
-                            //a few things that must be handled explicitly
-                            if (Descriptor.FieldType == FieldType.Double && value is double)
-                            {
-                                if (double.IsNaN((double) value))
-                                {
-                                    return ""double.NaN"";
-                                }
-                                if (double.IsPositiveInfinity((double) value))
-                                {
-                                    return ""double.PositiveInfinity"";
-                                }
-                                if (double.IsNegativeInfinity((double) value))
-                                {
-                                    return ""double.NegativeInfinity"";
-                                }
-                            }
-                            else if (Descriptor.FieldType == FieldType.Float && value is float)
-                            {
-                                if (float.IsNaN((float) value))
-                                {
-                                    return ""float.NaN"";
-                                }
-                                if (float.IsPositiveInfinity((float) value))
-                                {
-                                    return ""float.PositiveInfinity"";
-                                }
-                                if (float.IsNegativeInfinity((float) value))
-                                {
-                                    return ""float.NegativeInfinity"";
-                                }
-                            }
-                            return value.ToString(CultureInfo.InvariantCulture) + suffix;
-                        }
-                    case FieldType.Bool:
-                        return (bool) Descriptor.DefaultValue ? ""true"" : ""false"";
-
-                    case FieldType.Bytes:
-                        if (!Descriptor.HasDefaultValue)
-                        {
-                            return ""pb::ByteString.Empty"";
-                        }
-                        if (UseLiteRuntime && Descriptor.DefaultValue is ByteString)
-                        {
-                            string temp = (((ByteString) Descriptor.DefaultValue).ToBase64());
-                            return String.Format(""pb::ByteString.FromBase64(\""{0}\"")"", temp);
-                        }
-                        return string.Format(""(pb::ByteString) {0}.Descriptor.Fields[{1}].DefaultValue"",
-                                             GetClassName(Descriptor.ContainingType), Descriptor.Index);
-                    case FieldType.String:
-                        if (AllPrintableAscii(Descriptor.Proto.DefaultValue))
-                        {
-                            // All chars are ASCII and printable.  In this case we only
-                            // need to escape quotes and backslashes.
-                            return ""\"""" + Descriptor.Proto.DefaultValue
-                                              .Replace(""\\"", ""\\\\"")
-                                              .Replace(""'"", ""\\'"")
-                                              .Replace(""\"""", ""\\\"""")
-                                   + ""\"""";
-                        }
-                        if (UseLiteRuntime && Descriptor.DefaultValue is String)
-                        {
-                            string temp = Convert.ToBase64String(
-                                    Encoding.UTF8.GetBytes((String) Descriptor.DefaultValue));
-                            return String.Format(""pb::ByteString.FromBase64(\""{0}\"").ToStringUtf8()"", temp);
-                        }
-                        return string.Format(""(string) {0}.Descriptor.Fields[{1}].DefaultValue"",
-                                             GetClassName(Descriptor.ContainingType), Descriptor.Index);
-                    case FieldType.Enum:
-                        return TypeName + ""."" + ((EnumValueDescriptor) Descriptor.DefaultValue).Name;
-                    case FieldType.Message:
-                    case FieldType.Group:
-                        return TypeName + "".DefaultInstance"";
-                    default:
-                        throw new InvalidOperationException(""Invalid field descriptor type"");
-                }
-            }
-        }
-
-        protected string PropertyName
-        {
-            get { return Descriptor.CSharpOptions.PropertyName; }
-        }
-
-        protected string Name
-        {
-            get { return NameHelpers.UnderscoresToCamelCase(GetFieldName(Descriptor)); }
-        }
-
-        protected int Number
-        {
-            get { return Descriptor.FieldNumber; }
-        }
-
-        protected void AddNullCheck(TextGenerator writer)
-        {
-            AddNullCheck(writer, ""value"");
-        }
-
-        protected void AddNullCheck(TextGenerator writer, string name)
-        {
-            if (IsNullableType)
-            {
-                writer.WriteLine(""  pb::ThrowHelper.ThrowIfNull({0}, \""{0}\"");"", name);
-            }
-        }
-
-        protected void AddPublicMemberAttributes(TextGenerator writer)
-        {
-            AddDeprecatedFlag(writer);
-            AddClsComplianceCheck(writer);
-        }
-
-        protected void AddClsComplianceCheck(TextGenerator writer)
-        {
-            if (!Descriptor.IsCLSCompliant && Descriptor.File.CSharpOptions.ClsCompliance)
-            {
-                writer.WriteLine(""[global::System.CLSCompliant(false)]"");
-            }
-        }
-
-        protected bool IsObsolete { get { return Descriptor.Options.Deprecated; } }
-
-        /// <summary>
-        /// Writes [global::System.ObsoleteAttribute()] if the member is obsolete
-        /// </summary>
-        protected void AddDeprecatedFlag(TextGenerator writer)
-        {
-            if (IsObsolete)
-            {
-                writer.WriteLine(""[global::System.ObsoleteAttribute()]"");
-            }
-        }
-
-        /// <summary>
-        /// For encodings with fixed sizes, returns that size in bytes.  Otherwise
-        /// returns -1. TODO(jonskeet): Make this less ugly.
-        /// </summary>
-        protected int FixedSize
-        {
-            get
-            {
-                switch (Descriptor.FieldType)
-                {
-                    case FieldType.UInt32:
-                    case FieldType.UInt64:
-                    case FieldType.Int32:
-                    case FieldType.Int64:
-                    case FieldType.SInt32:
-                    case FieldType.SInt64:
-                    case FieldType.Enum:
-                    case FieldType.Bytes:
-                    case FieldType.String:
-                    case FieldType.Message:
-                    case FieldType.Group:
-                        return -1;
-                    case FieldType.Float:
-                        return WireFormat.FloatSize;
-                    case FieldType.SFixed32:
-                        return WireFormat.SFixed32Size;
-                    case FieldType.Fixed32:
-                        return WireFormat.Fixed32Size;
-                    case FieldType.Double:
-                        return WireFormat.DoubleSize;
-                    case FieldType.SFixed64:
-                        return WireFormat.SFixed64Size;
-                    case FieldType.Fixed64:
-                        return WireFormat.Fixed64Size;
-                    case FieldType.Bool:
-                        return WireFormat.BoolSize;
-                    default:
-                        throw new InvalidOperationException(""Invalid field descriptor type"");
-                }
-            }
-        }
-
-        protected bool IsNullableType
-        {
-            get
-            {
-                switch (Descriptor.FieldType)
-                {
-                    case FieldType.Float:
-                    case FieldType.Double:
-                    case FieldType.Int32:
-                    case FieldType.Int64:
-                    case FieldType.SInt32:
-                    case FieldType.SInt64:
-                    case FieldType.SFixed32:
-                    case FieldType.SFixed64:
-                    case FieldType.UInt32:
-                    case FieldType.UInt64:
-                    case FieldType.Fixed32:
-                    case FieldType.Fixed64:
-                    case FieldType.Bool:
-                    case FieldType.Enum:
-                        return false;
-                    case FieldType.Bytes:
-                    case FieldType.String:
-                    case FieldType.Message:
-                    case FieldType.Group:
-                        return true;
-                    default:
-                        throw new InvalidOperationException(""Invalid field descriptor type"");
-                }
-            }
-        }
-
-        protected string TypeName
-        {
-            get
-            {
-                switch (Descriptor.FieldType)
-                {
-                    case FieldType.Enum:
-                        return GetClassName(Descriptor.EnumType);
-                    case FieldType.Message:
-                    case FieldType.Group:
-                        return GetClassName(Descriptor.MessageType);
-                    default:
-                        return DescriptorUtil.GetMappedTypeName(Descriptor.MappedType);
-                }
-            }
-        }
-
-        protected string MessageOrGroup
-        {
-            get { return Descriptor.FieldType == FieldType.Group ? ""Group"" : ""Message""; }
-        }
-
-        /// <summary>
-        /// Returns the type name as used in CodedInputStream method names: SFixed32, UInt32 etc.
-        /// </summary>
-        protected string CapitalizedTypeName
-        {
-            get
-            {
-                // Our enum names match perfectly. How serendipitous.
-                return Descriptor.FieldType.ToString();
-            }
-        }
-    }
-}
\ No newline at end of file
diff --git a/csharp/src/ProtoGen/Generator.cs b/csharp/src/ProtoGen/Generator.cs
deleted file mode 100644
index bc481ec09..000000000
--- a/csharp/src/ProtoGen/Generator.cs
+++ /dev/null
@@ -1,267 +0,0 @@
-#region Copyright notice and license
-
-// Protocol Buffers - Google's data interchange format
-// Copyright 2008 Google Inc.  All rights reserved.
-// http://github.com/jskeet/dotnet-protobufs/
-// Original C++/Java/Python code:
-// http://code.google.com/p/protobuf/
-//
-// Redistribution and use in source and binary forms, with or without
-// modification, are permitted provided that the following conditions are
-// met:
-//
-//     * Redistributions of source code must retain the above copyright
-// notice, this list of conditions and the following disclaimer.
-//     * Redistributions in binary form must reproduce the above
-// copyright notice, this list of conditions and the following disclaimer
-// in the documentation and/or other materials provided with the
-// distribution.
-//     * Neither the name of Google Inc. nor the names of its
-// contributors may be used to endorse or promote products derived from
-// this software without specific prior written permission.
-//
-// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-// ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
-#endregion
-
-using System;
-using System.Collections.Generic;
-using System.IO;
-using System.Text;
-using Google.ProtocolBuffers.Collections;
-using Google.ProtocolBuffers.Compiler.PluginProto;
-using Google.ProtocolBuffers.DescriptorProtos;
-using Google.ProtocolBuffers.Descriptors;
-
-namespace Google.ProtocolBuffers.ProtoGen
-{
-    /// <summary>
-    /// Code generator for protocol buffers. Only C# is supported at the moment.
-    /// </summary>
-    public sealed class Generator
-    {
-        private readonly GeneratorOptions options;
-
-        private Generator(GeneratorOptions options)
-        {
-            options.Validate();
-            this.options = options;
-        }
-
-        /// <summary>
-        /// Returns a generator configured with the specified options.
-        /// </summary>
-        public static Generator CreateGenerator(GeneratorOptions options)
-        {
-            return new Generator(options);
-        }
-
-        public void Generate(CodeGeneratorRequest request, CodeGeneratorResponse.Builder response)
-        {
-            IList<FileDescriptor> descriptors = ConvertDescriptors(options.FileOptions, request.ProtoFileList);
-
-            // Combine with options from command line
-            foreach (FileDescriptor descriptor in descriptors)
-            {
-                descriptor.ConfigureWithDefaultOptions(options.FileOptions);
-            }
-
-            bool duplicates = false;
-            Dictionary<string, bool> names = new Dictionary<string, bool>(StringComparer.OrdinalIgnoreCase);
-            foreach (FileDescriptor descriptor in descriptors)
-            {
-                string file = GetOutputFile(descriptor, false);
-                if (names.ContainsKey(file))
-                {
-                    duplicates = true;
-                    break;
-                }
-                names.Add(file, true);
-            }
-
-            //ROK - Changed to dictionary from HashSet to allow 2.0 compile
-            var filesToGenerate = new Dictionary<string, string>(StringComparer.OrdinalIgnoreCase);
-            foreach (var item in request.FileToGenerateList)
-            {
-                filesToGenerate[item] = null;
-            }
-            foreach (FileDescriptor descriptor in descriptors)
-            {
-                // Optionally exclude descriptors in google.protobuf
-                if (descriptor.CSharpOptions.IgnoreGoogleProtobuf && descriptor.Package == ""google.protobuf"")
-                {
-                    continue;
-                }
-                if (filesToGenerate.ContainsKey(descriptor.Name))
-                {
-                    Generate(descriptor, duplicates, response);
-                }
-            }
-        }
-
-        /// <summary>
-        /// Generates code for a particular file. All dependencies must
-        /// already have been resolved.
-        /// </summary>
-        private void Generate(FileDescriptor descriptor, bool duplicates, CodeGeneratorResponse.Builder response)
-        {
-            var code = new StringBuilder();
-            var ucg = new UmbrellaClassGenerator(descriptor);
-            using (StringWriter textWriter = new StringWriter(code))
-            {
-                TextGenerator writer = new TextGenerator(textWriter, options.LineBreak);
-                ucg.Generate(writer);
-            }
-            response.AddFile(new CodeGeneratorResponse.Types.File.Builder
-            {
-                Name = GetOutputFile(descriptor, duplicates),
-                Content = code.ToString(),
-            }.Build());
-        }
-
-        private string GetOutputFile(FileDescriptor descriptor, bool duplicates)
-        {
-            CSharpFileOptions fileOptions = descriptor.CSharpOptions;
-
-            string filename = descriptor.CSharpOptions.UmbrellaClassname + descriptor.CSharpOptions.FileExtension;
-            if (duplicates)
-            {
-                string namepart;
-                if (String.IsNullOrEmpty(descriptor.Name) || String.IsNullOrEmpty(namepart = Path.GetFileNameWithoutExtension(descriptor.Name)))
-                    throw new ApplicationException(""Duplicate UmbrellaClassname options created a file name collision."");
-
-                filename = namepart + descriptor.CSharpOptions.FileExtension;
-            }
-
-            string outputDirectory = descriptor.CSharpOptions.OutputDirectory;
-            if (fileOptions.ExpandNamespaceDirectories)
-            {
-                string package = fileOptions.Namespace;
-                if (!string.IsNullOrEmpty(package))
-                {
-                    string[] bits = package.Split('.');
-                    foreach (string bit in bits)
-                    {
-                        outputDirectory = Path.Combine(outputDirectory, bit);
-                    }
-                }
-            }
-
-            // As the directory can be explicitly specified in options, we need to make sure it exists
-            Directory.CreateDirectory(outputDirectory);
-            return Path.Combine(outputDirectory, filename);
-        }
-
-        /// <summary>
-        /// Resolves any dependencies and converts FileDescriptorProtos into FileDescriptors.
-        /// The list returned is in the same order as the protos are listed in the descriptor set.
-        /// Note: this method is internal rather than private to allow testing.
-        /// </summary>
-        /// <exception cref=""DependencyResolutionException"">Not all dependencies could be resolved.</exception>
-        public static IList<FileDescriptor> ConvertDescriptors(CSharpFileOptions options,
-                                                               IList<FileDescriptorProto> fileList)
-        {
-            FileDescriptor[] converted = new FileDescriptor[fileList.Count];
-
-            Dictionary<string, FileDescriptor> convertedMap = new Dictionary<string, FileDescriptor>();
-
-            int totalConverted = 0;
-
-            bool madeProgress = true;
-            while (madeProgress && totalConverted < converted.Length)
-            {
-                madeProgress = false;
-                for (int i = 0; i < converted.Length; i++)
-                {
-                    if (converted[i] != null)
-                    {
-                        // Already done this one
-                        continue;
-                    }
-                    FileDescriptorProto candidate = fileList[i];
-                    FileDescriptor[] dependencies = new FileDescriptor[candidate.DependencyList.Count];
-
-
-                    CSharpFileOptions.Builder builder = options.ToBuilder();
-                    if (candidate.Options.HasExtension(CSharpOptions.CSharpFileOptions))
-                    {
-                        builder.MergeFrom(
-                            candidate.Options.GetExtension(CSharpOptions.CSharpFileOptions));
-                    }
-                    CSharpFileOptions localOptions = builder.Build();
-
-                    bool foundAllDependencies = true;
-                    for (int j = 0; j < dependencies.Length; j++)
-                    {
-                        if (!convertedMap.TryGetValue(candidate.DependencyList[j], out dependencies[j]))
-                        {
-                            // We can auto-magically resolve these since we already have their description
-                            // This way if the file is only referencing options it does not need to be built with the
-                            // --include_imports definition.
-                            if (localOptions.IgnoreGoogleProtobuf &&
-                                (candidate.DependencyList[j] == ""google/protobuf/csharp_options.proto""))
-                            {
-                                dependencies[j] = CSharpOptions.Descriptor;
-                                continue;
-                            }
-                            if (localOptions.IgnoreGoogleProtobuf &&
-                                (candidate.DependencyList[j] == ""google/protobuf/descriptor.proto""))
-                            {
-                                dependencies[j] = DescriptorProtoFile.Descriptor;
-                                continue;
-                            }
-                            foundAllDependencies = false;
-                            break;
-                        }
-                    }
-                    if (!foundAllDependencies)
-                    {
-                        continue;
-                    }
-                    madeProgress = true;
-                    totalConverted++;
-                    converted[i] = FileDescriptor.BuildFrom(candidate, dependencies);
-                    convertedMap[candidate.Name] = converted[i];
-                }
-            }
-            if (!madeProgress)
-            {
-                StringBuilder remaining = new StringBuilder();
-                for (int i = 0; i < converted.Length; i++)
-                {
-                    if (converted[i] == null)
-                    {
-                        if (remaining.Length != 0)
-                        {
-                            remaining.Append("", "");
-                        }
-                        FileDescriptorProto failure = fileList[i];
-                        remaining.Append(failure.Name);
-                        remaining.Append("":"");
-                        foreach (string dependency in failure.DependencyList)
-                        {
-                            if (!convertedMap.ContainsKey(dependency))
-                            {
-                                remaining.Append("" "");
-                                remaining.Append(dependency);
-                            }
-                        }
-                        remaining.Append("";"");
-                    }
-                }
-                throw new DependencyResolutionException(""Unable to resolve all dependencies: "" + remaining);
-            }
-            return Lists.AsReadOnly(converted);
-        }
-    }
-}
\ No newline at end of file
diff --git a/csharp/src/ProtoGen/GeneratorOptions.cs b/csharp/src/ProtoGen/GeneratorOptions.cs
deleted file mode 100644
index ec500d82e..000000000
--- a/csharp/src/ProtoGen/GeneratorOptions.cs
+++ /dev/null
@@ -1,330 +0,0 @@
-#region Copyright notice and license
-
-// Protocol Buffers - Google's data interchange format
-// Copyright 2008 Google Inc.  All rights reserved.
-// http://github.com/jskeet/dotnet-protobufs/
-// Original C++/Java/Python code:
-// http://code.google.com/p/protobuf/
-//
-// Redistribution and use in source and binary forms, with or without
-// modification, are permitted provided that the following conditions are
-// met:
-//
-//     * Redistributions of source code must retain the above copyright
-// notice, this list of conditions and the following disclaimer.
-//     * Redistributions in binary form must reproduce the above
-// copyright notice, this list of conditions and the following disclaimer
-// in the documentation and/or other materials provided with the
-// distribution.
-//     * Neither the name of Google Inc. nor the names of its
-// contributors may be used to endorse or promote products derived from
-// this software without specific prior written permission.
-//
-// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-// ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
-#endregion
-
-using System;
-using System.Collections.Generic;
-using System.IO;
-using System.Text.RegularExpressions;
-using Google.ProtocolBuffers.DescriptorProtos;
-using Google.ProtocolBuffers.Descriptors;
-
-namespace Google.ProtocolBuffers.ProtoGen
-{
-    /// <summary>
-    /// All the configuration required for the generator - where to generate
-    /// output files, the location of input files etc. While this isn't immutable
-    /// in practice, the contents shouldn't be changed after being passed to
-    /// the generator.
-    /// </summary>
-    public sealed class GeneratorOptions
-    {
-        private static Dictionary<string, string> LineBreaks =
-            new Dictionary<string, string>(StringComparer.InvariantCultureIgnoreCase)
-                {
-                    {""Windows"", ""\r\n""},
-                    {""Unix"", ""\n""},
-                    {""Default"", Environment.NewLine}
-                };
-
-        public IList<string> InputFiles { get; set; }
-
-        public GeneratorOptions()
-        {
-            LineBreak = Environment.NewLine;
-        }
-
-        /// <summary>
-        /// Attempts to validate the options, but doesn't throw an exception if they're invalid.
-        /// Instead, when this method returns false, the output variable will contain a collection
-        /// of reasons for the validation failure.
-        /// </summary>
-        /// <param name=""reasons"">Variable to receive a list of reasons in case of validation failure.</param>
-        /// <returns>true if the options are valid; false otherwise</returns>
-        public bool TryValidate(out IList<string> reasons)
-        {
-            List<string> tmpReasons = new List<string>();
-
-            ParseArguments(tmpReasons);
-
-            // Output directory validation
-            if (string.IsNullOrEmpty(FileOptions.OutputDirectory))
-            {
-                tmpReasons.Add(""No output directory specified"");
-            }
-            else
-            {
-                if (!Directory.Exists(FileOptions.OutputDirectory))
-                {
-                    tmpReasons.Add(""Specified output directory ("" + FileOptions.OutputDirectory + "" doesn't exist."");
-                }
-            }
-
-            // Input file validation (just in terms of presence)
-            if (InputFiles == null || InputFiles.Count == 0)
-            {
-                tmpReasons.Add(""No input files specified"");
-            }
-            else
-            {
-                foreach (string input in InputFiles)
-                {
-                    FileInfo fi = new FileInfo(input);
-                    if (!fi.Exists)
-                    {
-                        tmpReasons.Add(""Input file "" + input + "" doesn't exist."");
-                    }
-                }
-            }
-
-            if (tmpReasons.Count != 0)
-            {
-                reasons = tmpReasons;
-                return false;
-            }
-
-            reasons = null;
-            return true;
-        }
-
-        /// <summary>
-        /// Validates that all the options have been set and are valid,
-        /// throwing an exception if they haven't.
-        /// </summary>
-        /// <exception cref=""InvalidOptionsException"">The options are invalid.</exception>
-        public void Validate()
-        {
-            IList<string> reasons;
-            if (!TryValidate(out reasons))
-            {
-                throw new InvalidOptionsException(reasons);
-            }
-        }
-
-        // Raw arguments, used to provide defaults for proto file options
-        public IList<string> Arguments { get; set; }
-
-        [Obsolete(""Please use GeneratorOptions.FileOptions.OutputDirectory instead"")]
-        public string OutputDirectory
-        {
-            get { return FileOptions.OutputDirectory; }
-            set
-            {
-                CSharpFileOptions.Builder bld = FileOptions.ToBuilder();
-                bld.OutputDirectory = value;
-                FileOptions = bld.Build();
-            }
-        }
-
-        private static readonly Regex ArgMatch = new Regex(@""^[-/](?<name>[\w_]+?)[:=](?<value>.*)$"");
-        private CSharpFileOptions fileOptions;
-
-        public CSharpFileOptions FileOptions
-        {
-            get { return fileOptions ?? (fileOptions = CSharpFileOptions.DefaultInstance); }
-            set { fileOptions = value; }
-        }
-
-        public string LineBreak { get; set; }
-
-        private void ParseArguments(IList<string> tmpReasons)
-        {
-            bool doHelp = Arguments.Count == 0;
-
-            InputFiles = new List<string>();
-            CSharpFileOptions.Builder builder = FileOptions.ToBuilder();
-            Dictionary<string, FieldDescriptor> fields =
-                new Dictionary<string, FieldDescriptor>(StringComparer.OrdinalIgnoreCase);
-            foreach (FieldDescriptor fld in builder.DescriptorForType.Fields)
-            {
-                fields.Add(fld.Name, fld);
-            }
-
-            foreach (string argument in Arguments)
-            {
-                if (StringComparer.OrdinalIgnoreCase.Equals(""-help"", argument) ||
-                    StringComparer.OrdinalIgnoreCase.Equals(""/help"", argument) ||
-                    StringComparer.OrdinalIgnoreCase.Equals(""-?"", argument) ||
-                    StringComparer.OrdinalIgnoreCase.Equals(""/?"", argument))
-                {
-                    doHelp = true;
-                    break;
-                }
-
-                Match m = ArgMatch.Match(argument);
-                if (m.Success)
-                {
-                    FieldDescriptor fld;
-                    string name = m.Groups[""name""].Value;
-                    string value = m.Groups[""value""].Value;
-
-                    if (fields.TryGetValue(name, out fld))
-                    {
-                        object obj;
-                        if (TryCoerceType(value, fld, out obj, tmpReasons))
-                        {
-                            builder[fld] = obj;
-                        }
-                    }
-                    else if (name == ""line_break"")
-                    {
-                        string tmp;
-                        if (LineBreaks.TryGetValue(value, out tmp))
-                        {
-                            LineBreak = tmp;
-                        }
-                        else
-                        {
-                            tmpReasons.Add(""Invalid value for 'line_break': "" + value + ""."");
-                        }
-                    }
-                    else if (!File.Exists(argument))
-                    {
-                        doHelp = true;
-                        tmpReasons.Add(""Unknown argument '"" + name + ""'."");
-                    }
-                    else
-                    {
-                        InputFiles.Add(argument);
-                    }
-                }
-                else
-                {
-                    InputFiles.Add(argument);
-                }
-            }
-
-            if (doHelp || InputFiles.Count == 0)
-            {
-                tmpReasons.Add(""Arguments:"");
-                foreach (KeyValuePair<string, FieldDescriptor> field in fields)
-                {
-                    tmpReasons.Add(String.Format(""-{0}=[{1}]"", field.Key, field.Value.FieldType));
-                }
-                tmpReasons.Add(""-line_break=["" + string.Join(""|"", new List<string>(LineBreaks.Keys).ToArray()) + ""]"");
-                tmpReasons.Add(""followed by one or more file paths."");
-            }
-            else
-            {
-                FileOptions = builder.Build();
-            }
-        }
-
-        private static bool TryCoerceType(string text, FieldDescriptor field, out object value, IList<string> tmpReasons)
-        {
-            value = null;
-
-            switch (field.FieldType)
-            {
-                case FieldType.Int32:
-                case FieldType.SInt32:
-                case FieldType.SFixed32:
-                    value = Int32.Parse(text);
-                    break;
-
-                case FieldType.Int64:
-                case FieldType.SInt64:
-                case FieldType.SFixed64:
-                    value = Int64.Parse(text);
-                    break;
-
-                case FieldType.UInt32:
-                case FieldType.Fixed32:
-                    value = UInt32.Parse(text);
-                    break;
-
-                case FieldType.UInt64:
-                case FieldType.Fixed64:
-                    value = UInt64.Parse(text);
-                    break;
-
-                case FieldType.Float:
-                    value = float.Parse(text);
-                    break;
-
-                case FieldType.Double:
-                    value = Double.Parse(text);
-                    break;
-
-                case FieldType.Bool:
-                    value = Boolean.Parse(text);
-                    break;
-
-                case FieldType.String:
-                    value = text;
-                    break;
-
-                case FieldType.Enum:
-                    {
-                        EnumDescriptor enumType = field.EnumType;
-
-                        int number;
-                        if (int.TryParse(text, out number))
-                        {
-                            value = enumType.FindValueByNumber(number);
-                            if (value == null)
-                            {
-                                tmpReasons.Add(
-                                    ""Enum type \"""" + enumType.FullName +
-                                    ""\"" has no value with number "" + number + ""."");
-                                return false;
-                            }
-                        }
-                        else
-                        {
-                            value = enumType.FindValueByName(text);
-                            if (value == null)
-                            {
-                                tmpReasons.Add(
-                                    ""Enum type \"""" + enumType.FullName +
-                                    ""\"" has no value named \"""" + text + ""\""."");
-                                return false;
-                            }
-                        }
-
-                        break;
-                    }
-
-                case FieldType.Bytes:
-                case FieldType.Message:
-                case FieldType.Group:
-                    tmpReasons.Add(""Unhandled field type "" + field.FieldType.ToString() + ""."");
-                    return false;
-            }
-
-            return true;
-        }
-    }
-}
\ No newline at end of file
diff --git a/csharp/src/ProtoGen/Helpers.cs b/csharp/src/ProtoGen/Helpers.cs
deleted file mode 100644
index 3c0011504..000000000
--- a/csharp/src/ProtoGen/Helpers.cs
+++ /dev/null
@@ -1,45 +0,0 @@
-#region Copyright notice and license
-
-// Protocol Buffers - Google's data interchange format
-// Copyright 2008 Google Inc.  All rights reserved.
-// http://github.com/jskeet/dotnet-protobufs/
-// Original C++/Java/Python code:
-// http://code.google.com/p/protobuf/
-//
-// Redistribution and use in source and binary forms, with or without
-// modification, are permitted provided that the following conditions are
-// met:
-//
-//     * Redistributions of source code must retain the above copyright
-// notice, this list of conditions and the following disclaimer.
-//     * Redistributions in binary form must reproduce the above
-// copyright notice, this list of conditions and the following disclaimer
-// in the documentation and/or other materials provided with the
-// distribution.
-//     * Neither the name of Google Inc. nor the names of its
-// contributors may be used to endorse or promote products derived from
-// this software without specific prior written permission.
-//
-// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-// ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
-#endregion
-
-namespace Google.ProtocolBuffers.ProtoGen
-{
-    /// <summary>
-    /// Helpers to resolve class names etc.
-    /// </summary>
-    internal static class Helpers
-    {
-    }
-}
\ No newline at end of file
diff --git a/csharp/src/ProtoGen/IFieldSourceGenerator.cs b/csharp/src/ProtoGen/IFieldSourceGenerator.cs
deleted file mode 100644
index f53ae5e4d..000000000
--- a/csharp/src/ProtoGen/IFieldSourceGenerator.cs
+++ /dev/null
@@ -1,53 +0,0 @@
-#region Copyright notice and license
-
-// Protocol Buffers - Google's data interchange format
-// Copyright 2008 Google Inc.  All rights reserved.
-// http://github.com/jskeet/dotnet-protobufs/
-// Original C++/Java/Python code:
-// http://code.google.com/p/protobuf/
-//
-// Redistribution and use in source and binary forms, with or without
-// modification, are permitted provided that the following conditions are
-// met:
-//
-//     * Redistributions of source code must retain the above copyright
-// notice, this list of conditions and the following disclaimer.
-//     * Redistributions in binary form must reproduce the above
-// copyright notice, this list of conditions and the following disclaimer
-// in the documentation and/or other materials provided with the
-// distribution.
-//     * Neither the name of Google Inc. nor the names of its
-// contributors may be used to endorse or promote products derived from
-// this software without specific prior written permission.
-//
-// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-// ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
-#endregion
-
-namespace Google.ProtocolBuffers.ProtoGen
-{
-    internal interface IFieldSourceGenerator
-    {
-        void GenerateMembers(TextGenerator writer);
-        void GenerateBuilderMembers(TextGenerator writer);
-        void GenerateMergingCode(TextGenerator writer);
-        void GenerateBuildingCode(TextGenerator writer);
-        void GenerateParsingCode(TextGenerator writer);
-        void GenerateSerializationCode(TextGenerator writer);
-        void GenerateSerializedSizeCode(TextGenerator writer);
-
-        void WriteHash(TextGenerator writer);
-        void WriteEquals(TextGenerator writer);
-        void WriteToString(TextGenerator writer);
-    }
-}
\ No newline at end of file
diff --git a/csharp/src/ProtoGen/ISourceGenerator.cs b/csharp/src/ProtoGen/ISourceGenerator.cs
deleted file mode 100644
index 452d854a1..000000000
--- a/csharp/src/ProtoGen/ISourceGenerator.cs
+++ /dev/null
@@ -1,43 +0,0 @@
-#region Copyright notice and license
-
-// Protocol Buffers - Google's data interchange format
-// Copyright 2008 Google Inc.  All rights reserved.
-// http://github.com/jskeet/dotnet-protobufs/
-// Original C++/Java/Python code:
-// http://code.google.com/p/protobuf/
-//
-// Redistribution and use in source and binary forms, with or without
-// modification, are permitted provided that the following conditions are
-// met:
-//
-//     * Redistributions of source code must retain the above copyright
-// notice, this list of conditions and the following disclaimer.
-//     * Redistributions in binary form must reproduce the above
-// copyright notice, this list of conditions and the following disclaimer
-// in the documentation and/or other materials provided with the
-// distribution.
-//     * Neither the name of Google Inc. nor the names of its
-// contributors may be used to endorse or promote products derived from
-// this software without specific prior written permission.
-//
-// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-// ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
-#endregion
-
-namespace Google.ProtocolBuffers.ProtoGen
-{
-    internal interface ISourceGenerator
-    {
-        void Generate(TextGenerator writer);
-    }
-}
\ No newline at end of file
diff --git a/csharp/src/ProtoGen/InvalidOptionsException.cs b/csharp/src/ProtoGen/InvalidOptionsException.cs
deleted file mode 100644
index fb698495e..000000000
--- a/csharp/src/ProtoGen/InvalidOptionsException.cs
+++ /dev/null
@@ -1,77 +0,0 @@
-#region Copyright notice and license
-
-// Protocol Buffers - Google's data interchange format
-// Copyright 2008 Google Inc.  All rights reserved.
-// http://github.com/jskeet/dotnet-protobufs/
-// Original C++/Java/Python code:
-// http://code.google.com/p/protobuf/
-//
-// Redistribution and use in source and binary forms, with or without
-// modification, are permitted provided that the following conditions are
-// met:
-//
-//     * Redistributions of source code must retain the above copyright
-// notice, this list of conditions and the following disclaimer.
-//     * Redistributions in binary form must reproduce the above
-// copyright notice, this list of conditions and the following disclaimer
-// in the documentation and/or other materials provided with the
-// distribution.
-//     * Neither the name of Google Inc. nor the names of its
-// contributors may be used to endorse or promote products derived from
-// this software without specific prior written permission.
-//
-// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-// ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
-#endregion
-
-using System;
-using System.Collections.Generic;
-using System.Text;
-using Google.ProtocolBuffers.Collections;
-
-namespace Google.ProtocolBuffers.ProtoGen
-{
-    /// <summary>
-    /// Exception thrown to indicate that the options passed were invalid.
-    /// </summary>
-    public sealed class InvalidOptionsException : Exception
-    {
-        private readonly IList<string> reasons;
-
-        /// <summary>
-        /// An immutable list of reasons why the options were invalid.
-        /// </summary>
-        public IList<string> Reasons
-        {
-            get { return reasons; }
-        }
-
-        public InvalidOptionsException(IList<string> reasons)
-            : base(BuildMessage(reasons))
-        {
-            this.reasons = Lists.AsReadOnly(reasons);
-        }
-
-        private static string BuildMessage(IEnumerable<string> reasons)
-        {
-            StringBuilder builder = new StringBuilder(""Invalid options:"");
-            builder.AppendLine();
-            foreach (string reason in reasons)
-            {
-                builder.Append(""  "");
-                builder.AppendLine(reason);
-            }
-            return builder.ToString();
-        }
-    }
-}
\ No newline at end of file
diff --git a/csharp/src/ProtoGen/MessageFieldGenerator.cs b/csharp/src/ProtoGen/MessageFieldGenerator.cs
deleted file mode 100644
index 25b58a605..000000000
--- a/csharp/src/ProtoGen/MessageFieldGenerator.cs
+++ /dev/null
@@ -1,174 +0,0 @@
-#region Copyright notice and license
-
-// Protocol Buffers - Google's data interchange format
-// Copyright 2008 Google Inc.  All rights reserved.
-// http://github.com/jskeet/dotnet-protobufs/
-// Original C++/Java/Python code:
-// http://code.google.com/p/protobuf/
-//
-// Redistribution and use in source and binary forms, with or without
-// modification, are permitted provided that the following conditions are
-// met:
-//
-//     * Redistributions of source code must retain the above copyright
-// notice, this list of conditions and the following disclaimer.
-//     * Redistributions in binary form must reproduce the above
-// copyright notice, this list of conditions and the following disclaimer
-// in the documentation and/or other materials provided with the
-// distribution.
-//     * Neither the name of Google Inc. nor the names of its
-// contributors may be used to endorse or promote products derived from
-// this software without specific prior written permission.
-//
-// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-// ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
-#endregion
-
-using Google.ProtocolBuffers.Descriptors;
-
-namespace Google.ProtocolBuffers.ProtoGen
-{
-    internal class MessageFieldGenerator : FieldGeneratorBase, IFieldSourceGenerator
-    {
-        internal MessageFieldGenerator(FieldDescriptor descriptor, int fieldOrdinal)
-            : base(descriptor, fieldOrdinal)
-        {
-        }
-
-        public void GenerateMembers(TextGenerator writer)
-        {
-            writer.WriteLine(""private bool has{0};"", PropertyName);
-            writer.WriteLine(""private {0} {1}_;"", TypeName, Name);
-            AddDeprecatedFlag(writer);
-            writer.WriteLine(""public bool Has{0} {{"", PropertyName);
-            writer.WriteLine(""  get {{ return has{0}; }}"", PropertyName);
-            writer.WriteLine(""}"");
-            AddDeprecatedFlag(writer);
-            writer.WriteLine(""public {0} {1} {{"", TypeName, PropertyName);
-            writer.WriteLine(""  get {{ return {0}_ ?? {1}; }}"", Name, DefaultValue);
-            writer.WriteLine(""}"");
-        }
-
-        public void GenerateBuilderMembers(TextGenerator writer)
-        {
-            AddDeprecatedFlag(writer);
-            writer.WriteLine(""public bool Has{0} {{"", PropertyName);
-            writer.WriteLine("" get {{ return result.has{0}; }}"", PropertyName);
-            writer.WriteLine(""}"");
-            AddDeprecatedFlag(writer);
-            writer.WriteLine(""public {0} {1} {{"", TypeName, PropertyName);
-            writer.WriteLine(""  get {{ return result.{0}; }}"", PropertyName);
-            writer.WriteLine(""  set {{ Set{0}(value); }}"", PropertyName);
-            writer.WriteLine(""}"");
-            AddDeprecatedFlag(writer);
-            writer.WriteLine(""public Builder Set{0}({1} value) {{"", PropertyName, TypeName);
-            AddNullCheck(writer);
-            writer.WriteLine(""  PrepareBuilder();"");
-            writer.WriteLine(""  result.has{0} = true;"", PropertyName);
-            writer.WriteLine(""  result.{0}_ = value;"", Name);
-            writer.WriteLine(""  return this;"");
-            writer.WriteLine(""}"");
-            AddDeprecatedFlag(writer);
-            writer.WriteLine(""public Builder Set{0}({1}.Builder builderForValue) {{"", PropertyName, TypeName);
-            AddNullCheck(writer, ""builderForValue"");
-            writer.WriteLine(""  PrepareBuilder();"");
-            writer.WriteLine(""  result.has{0} = true;"", PropertyName);
-            writer.WriteLine(""  result.{0}_ = builderForValue.Build();"", Name);
-            writer.WriteLine(""  return this;"");
-            writer.WriteLine(""}"");
-            AddDeprecatedFlag(writer);
-            writer.WriteLine(""public Builder Merge{0}({1} value) {{"", PropertyName, TypeName);
-            AddNullCheck(writer);
-            writer.WriteLine(""  PrepareBuilder();"");
-            writer.WriteLine(""  if (result.has{0} &&"", PropertyName);
-            writer.WriteLine(""      result.{0}_ != {1}) {{"", Name, DefaultValue);
-            writer.WriteLine(""      result.{0}_ = {1}.CreateBuilder(result.{0}_).MergeFrom(value).BuildPartial();"", Name,
-                             TypeName);
-            writer.WriteLine(""  } else {"");
-            writer.WriteLine(""    result.{0}_ = value;"", Name);
-            writer.WriteLine(""  }"");
-            writer.WriteLine(""  result.has{0} = true;"", PropertyName);
-            writer.WriteLine(""  return this;"");
-            writer.WriteLine(""}"");
-            AddDeprecatedFlag(writer);
-            writer.WriteLine(""public Builder Clear{0}() {{"", PropertyName);
-            writer.WriteLine(""  PrepareBuilder();"");
-            writer.WriteLine(""  result.has{0} = false;"", PropertyName);
-            writer.WriteLine(""  result.{0}_ = null;"", Name);
-            writer.WriteLine(""  return this;"");
-            writer.WriteLine(""}"");
-        }
-
-        public void GenerateMergingCode(TextGenerator writer)
-        {
-            writer.WriteLine(""if (other.Has{0}) {{"", PropertyName);
-            writer.WriteLine(""  Merge{0}(other.{0});"", PropertyName);
-            writer.WriteLine(""}"");
-        }
-
-        public void GenerateBuildingCode(TextGenerator writer)
-        {
-            // Nothing to do for singular fields
-        }
-
-        public void GenerateParsingCode(TextGenerator writer)
-        {
-            writer.WriteLine(""{0}.Builder subBuilder = {0}.CreateBuilder();"", TypeName);
-            writer.WriteLine(""if (result.has{0}) {{"", PropertyName);
-            writer.WriteLine(""  subBuilder.MergeFrom({0});"", PropertyName);
-            writer.WriteLine(""}"");
-            if (Descriptor.FieldType == FieldType.Group)
-            {
-                writer.WriteLine(""input.ReadGroup({0}, subBuilder, extensionRegistry);"", Number);
-            }
-            else
-            {
-                writer.WriteLine(""input.ReadMessage(subBuilder, extensionRegistry);"");
-            }
-            writer.WriteLine(""{0} = subBuilder.BuildPartial();"", PropertyName);
-        }
-
-        public void GenerateSerializationCode(TextGenerator writer)
-        {
-            writer.WriteLine(""if (has{0}) {{"", PropertyName);
-            writer.WriteLine(""  output.Write{0}({1}, field_names[{3}], {2});"", MessageOrGroup, Number, PropertyName,
-                             FieldOrdinal);
-            writer.WriteLine(""}"");
-        }
-
-        public void GenerateSerializedSizeCode(TextGenerator writer)
-        {
-            writer.WriteLine(""if (has{0}) {{"", PropertyName);
-            writer.WriteLine(""  size += pb::CodedOutputStream.Compute{0}Size({1}, {2});"",
-                             MessageOrGroup, Number, PropertyName);
-            writer.WriteLine(""}"");
-        }
-
-        public override void WriteHash(TextGenerator writer)
-        {
-            writer.WriteLine(""if (has{0}) hash ^= {1}_.GetHashCode();"", PropertyName, Name);
-        }
-
-        public override void WriteEquals(TextGenerator writer)
-        {
-            writer.WriteLine(""if (has{0} != other.has{0} || (has{0} && !{1}_.Equals(other.{1}_))) return false;"",
-                             PropertyName, Name);
-        }
-
-        public override void WriteToString(TextGenerator writer)
-        {
-            writer.WriteLine(""PrintField(\""{2}\"", has{0}, {1}_, writer);"", PropertyName, Name,
-                             Descriptor.FieldType == FieldType.Group ? Descriptor.MessageType.Name : Descriptor.Name);
-        }
-    }
-}
\ No newline at end of file
diff --git a/csharp/src/ProtoGen/MessageGenerator.cs b/csharp/src/ProtoGen/MessageGenerator.cs
deleted file mode 100644
index e7ed1e86b..000000000
--- a/csharp/src/ProtoGen/MessageGenerator.cs
+++ /dev/null
@@ -1,893 +0,0 @@
-#region Copyright notice and license
-
-// Protocol Buffers - Google's data interchange format
-// Copyright 2008 Google Inc.  All rights reserved.
-// http://github.com/jskeet/dotnet-protobufs/
-// Original C++/Java/Python code:
-// http://code.google.com/p/protobuf/
-//
-// Redistribution and use in source and binary forms, with or without
-// modification, are permitted provided that the following conditions are
-// met:
-//
-//     * Redistributions of source code must retain the above copyright
-// notice, this list of conditions and the following disclaimer.
-//     * Redistributions in binary form must reproduce the above
-// copyright notice, this list of conditions and the following disclaimer
-// in the documentation and/or other materials provided with the
-// distribution.
-//     * Neither the name of Google Inc. nor the names of its
-// contributors may be used to endorse or promote products derived from
-// this software without specific prior written permission.
-//
-// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-// ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
-#endregion
-
-using System;
-using System.Collections.Generic;
-using Google.ProtocolBuffers.DescriptorProtos;
-using Google.ProtocolBuffers.Descriptors;
-
-namespace Google.ProtocolBuffers.ProtoGen
-{
-    internal class MessageGenerator : SourceGeneratorBase<MessageDescriptor>, ISourceGenerator
-    {
-        private string[] _fieldNames;
-
-        internal MessageGenerator(MessageDescriptor descriptor) : base(descriptor)
-        {
-        }
-
-        private string ClassName
-        {
-            get { return Descriptor.Name; }
-        }
-
-        private string FullClassName
-        {
-            get { return GetClassName(Descriptor); }
-        }
-
-        /// <summary>
-        /// Get an identifier that uniquely identifies this type within the file.
-        /// This is used to declare static variables related to this type at the
-        /// outermost file scope.
-        /// </summary>
-        private static string GetUniqueFileScopeIdentifier(IDescriptor descriptor)
-        {
-            return ""static_"" + descriptor.FullName.Replace(""."", ""_"");
-        }
-
-        internal void GenerateStaticVariables(TextGenerator writer)
-        {
-            // Because descriptor.proto (Google.ProtocolBuffers.DescriptorProtos) is
-            // used in the construction of descriptors, we have a tricky bootstrapping
-            // problem.  To help control static initialization order, we make sure all
-            // descriptors and other static data that depends on them are members of
-            // the proto-descriptor class.  This way, they will be initialized in
-            // a deterministic order.
-
-            string identifier = GetUniqueFileScopeIdentifier(Descriptor);
-
-            if (!UseLiteRuntime)
-            {
-                // The descriptor for this type.
-                string access = Descriptor.File.CSharpOptions.NestClasses ? ""private"" : ""internal"";
-                writer.WriteLine(""{0} static pbd::MessageDescriptor internal__{1}__Descriptor;"", access, identifier);
-                writer.WriteLine(
-                    ""{0} static pb::FieldAccess.FieldAccessorTable<{1}, {1}.Builder> internal__{2}__FieldAccessorTable;"",
-                    access, FullClassName, identifier);
-            }
-            // Generate static members for all nested types.
-            foreach (MessageDescriptor nestedMessage in Descriptor.NestedTypes)
-            {
-                new MessageGenerator(nestedMessage).GenerateStaticVariables(writer);
-            }
-        }
-
-        internal void GenerateStaticVariableInitializers(TextGenerator writer)
-        {
-            string identifier = GetUniqueFileScopeIdentifier(Descriptor);
-
-            if (!UseLiteRuntime)
-            {
-                writer.Write(""internal__{0}__Descriptor = "", identifier);
-                if (Descriptor.ContainingType == null)
-                {
-                    writer.WriteLine(""Descriptor.MessageTypes[{0}];"", Descriptor.Index);
-                }
-                else
-                {
-                    writer.WriteLine(""internal__{0}__Descriptor.NestedTypes[{1}];"",
-                                     GetUniqueFileScopeIdentifier(Descriptor.ContainingType), Descriptor.Index);
-                }
-
-                writer.WriteLine(""internal__{0}__FieldAccessorTable = "", identifier);
-                writer.WriteLine(
-                    ""    new pb::FieldAccess.FieldAccessorTable<{1}, {1}.Builder>(internal__{0}__Descriptor,"",
-                    identifier, FullClassName);
-                writer.Print(""        new string[] { "");
-                foreach (FieldDescriptor field in Descriptor.Fields)
-                {
-                    writer.Write(""\""{0}\"", "", field.CSharpOptions.PropertyName);
-                }
-                writer.WriteLine(""});"");
-            }
-
-            // Generate static member initializers for all nested types.
-            foreach (MessageDescriptor nestedMessage in Descriptor.NestedTypes)
-            {
-                new MessageGenerator(nestedMessage).GenerateStaticVariableInitializers(writer);
-            }
-
-            foreach (FieldDescriptor extension in Descriptor.Extensions)
-            {
-                new ExtensionGenerator(extension).GenerateStaticVariableInitializers(writer);
-            }
-        }
-
-        public string[] FieldNames
-        {
-            get
-            {
-                if (_fieldNames == null)
-                {
-                    List<string> names = new List<string>();
-                    foreach (FieldDescriptor fieldDescriptor in Descriptor.Fields)
-                    {
-                        names.Add(fieldDescriptor.Name);
-                    }
-                    //if you change this, the search must also change in GenerateBuilderParsingMethods
-                    names.Sort(StringComparer.Ordinal);
-                    _fieldNames = names.ToArray();
-                }
-                return _fieldNames;
-            }
-        }
-
-        internal int FieldOrdinal(FieldDescriptor field)
-        {
-            return Array.BinarySearch(FieldNames, field.Name, StringComparer.Ordinal);
-        }
-
-        private IFieldSourceGenerator CreateFieldGenerator(FieldDescriptor fieldDescriptor)
-        {
-            return SourceGenerators.CreateFieldGenerator(fieldDescriptor, FieldOrdinal(fieldDescriptor));
-        }
-        
-        public void Generate(TextGenerator writer)
-        {
-            if (Descriptor.File.CSharpOptions.AddSerializable)
-            {
-                writer.WriteLine(""[global::System.SerializableAttribute()]"");
-            }
-            writer.WriteLine(""[global::System.Diagnostics.DebuggerNonUserCodeAttribute()]"");
-            WriteGeneratedCodeAttributes(writer);
-            writer.WriteLine(""{0} sealed partial class {1} : pb::{2}Message{3}<{1}, {1}.Builder> {{"",
-                             ClassAccessLevel, ClassName,
-                             Descriptor.Proto.ExtensionRangeCount > 0 ? ""Extendable"" : ""Generated"",
-                             RuntimeSuffix);
-            writer.Indent();
-            if (Descriptor.File.CSharpOptions.GeneratePrivateCtor)
-            {
-                writer.WriteLine(""private {0}() {{ }}"", ClassName);
-            }
-            // Must call MakeReadOnly() to make sure all lists are made read-only
-            writer.WriteLine(""private static readonly {0} defaultInstance = new {0}().MakeReadOnly();"", ClassName);
-
-            if (OptimizeSpeed)
-            {
-                writer.WriteLine(""private static readonly string[] _{0}FieldNames = new string[] {{ {2}{1}{2} }};"",
-                                 NameHelpers.UnderscoresToCamelCase(ClassName), String.Join(""\"", \"""", FieldNames),
-                                 FieldNames.Length > 0 ? ""\"""" : """");
-                List<string> tags = new List<string>();
-                foreach (string name in FieldNames)
-                {
-                    tags.Add(WireFormat.MakeTag(Descriptor.FindFieldByName(name)).ToString());
-                }
-
-                writer.WriteLine(""private static readonly uint[] _{0}FieldTags = new uint[] {{ {1} }};"",
-                                 NameHelpers.UnderscoresToCamelCase(ClassName), String.Join("", "", tags.ToArray()));
-            }
-            writer.WriteLine(""public static {0} DefaultInstance {{"", ClassName);
-            writer.WriteLine(""  get { return defaultInstance; }"");
-            writer.WriteLine(""}"");
-            writer.WriteLine();
-            writer.WriteLine(""public override {0} DefaultInstanceForType {{"", ClassName);
-            writer.WriteLine(""  get { return DefaultInstance; }"");
-            writer.WriteLine(""}"");
-            writer.WriteLine();
-            writer.WriteLine(""protected override {0} ThisMessage {{"", ClassName);
-            writer.WriteLine(""  get { return this; }"");
-            writer.WriteLine(""}"");
-            writer.WriteLine();
-            if (!UseLiteRuntime)
-            {
-                writer.WriteLine(""public static pbd::MessageDescriptor Descriptor {"");
-                writer.WriteLine(""  get {{ return {0}.internal__{1}__Descriptor; }}"",
-                                 DescriptorUtil.GetFullUmbrellaClassName(Descriptor),
-                                 GetUniqueFileScopeIdentifier(Descriptor));
-                writer.WriteLine(""}"");
-                writer.WriteLine();
-                writer.WriteLine(
-                    ""protected override pb::FieldAccess.FieldAccessorTable<{0}, {0}.Builder> InternalFieldAccessors {{"",
-                    ClassName);
-                writer.WriteLine(""  get {{ return {0}.internal__{1}__FieldAccessorTable; }}"",
-                                 DescriptorUtil.GetFullUmbrellaClassName(Descriptor),
-                                 GetUniqueFileScopeIdentifier(Descriptor));
-                writer.WriteLine(""}"");
-                writer.WriteLine();
-            }
-
-            // Extensions don't need to go in an extra nested type 
-            WriteChildren(writer, null, Descriptor.Extensions);
-
-            if (Descriptor.EnumTypes.Count + Descriptor.NestedTypes.Count > 0)
-            {
-                writer.WriteLine(""#region Nested types"");
-                writer.WriteLine(""[global::System.Diagnostics.DebuggerNonUserCodeAttribute()]"");
-                WriteGeneratedCodeAttributes(writer);
-                writer.WriteLine(""public static partial class Types {"");
-                writer.Indent();
-                WriteChildren(writer, null, Descriptor.EnumTypes);
-                WriteChildren(writer, null, Descriptor.NestedTypes);
-                writer.Outdent();
-                writer.WriteLine(""}"");
-                writer.WriteLine(""#endregion"");
-                writer.WriteLine();
-            }
-
-            foreach (FieldDescriptor fieldDescriptor in Descriptor.Fields)
-            {
-                if (Descriptor.File.CSharpOptions.ClsCompliance && GetFieldConstantName(fieldDescriptor).StartsWith(""_""))
-                {
-                    writer.WriteLine(""[global::System.CLSCompliant(false)]"");
-                }
-
-                // Rats: we lose the debug comment here :(
-                writer.WriteLine(""public const int {0} = {1};"", GetFieldConstantName(fieldDescriptor),
-                                 fieldDescriptor.FieldNumber);
-                CreateFieldGenerator(fieldDescriptor).GenerateMembers(writer);
-                writer.WriteLine();
-            }
-
-            if (OptimizeSpeed)
-            {
-                GenerateIsInitialized(writer);
-                GenerateMessageSerializationMethods(writer);
-            }
-            if (UseLiteRuntime)
-            {
-                GenerateLiteRuntimeMethods(writer);
-            }
-
-            GenerateParseFromMethods(writer);
-            GenerateBuilder(writer);
-
-            // Force the static initialization code for the file to run, since it may
-            // initialize static variables declared in this class.
-            writer.WriteLine(""static {0}() {{"", ClassName);
-            // We call object.ReferenceEquals() just to make it a valid statement on its own.
-            // Another option would be GetType(), but that causes problems in DescriptorProtoFile,
-            // where the bootstrapping is somewhat recursive - type initializers call
-            // each other, effectively. We temporarily see Descriptor as null.
-            writer.WriteLine(""  object.ReferenceEquals({0}.Descriptor, null);"",
-                             DescriptorUtil.GetFullUmbrellaClassName(Descriptor));
-            writer.WriteLine(""}"");
-
-            writer.Outdent();
-            writer.WriteLine(""}"");
-            writer.WriteLine();
-        }
-
-        private void GenerateLiteRuntimeMethods(TextGenerator writer)
-        {
-            bool callbase = Descriptor.Proto.ExtensionRangeCount > 0;
-            writer.WriteLine(""#region Lite runtime methods"");
-            writer.WriteLine(""public override int GetHashCode() {"");
-            writer.Indent();
-            writer.WriteLine(""int hash = GetType().GetHashCode();"");
-            foreach (FieldDescriptor fieldDescriptor in Descriptor.Fields)
-            {
-                CreateFieldGenerator(fieldDescriptor).WriteHash(writer);
-            }
-            if (callbase)
-            {
-                writer.WriteLine(""hash ^= base.GetHashCode();"");
-            }
-            writer.WriteLine(""return hash;"");
-            writer.Outdent();
-            writer.WriteLine(""}"");
-            writer.WriteLine();
-
-            writer.WriteLine(""public override bool Equals(object obj) {"");
-            writer.Indent();
-            writer.WriteLine(""{0} other = obj as {0};"", ClassName);
-            writer.WriteLine(""if (other == null) return false;"");
-            foreach (FieldDescriptor fieldDescriptor in Descriptor.Fields)
-            {
-                CreateFieldGenerator(fieldDescriptor).WriteEquals(writer);
-            }
-            if (callbase)
-            {
-                writer.WriteLine(""if (!base.Equals(other)) return false;"");
-            }
-            writer.WriteLine(""return true;"");
-            writer.Outdent();
-            writer.WriteLine(""}"");
-            writer.WriteLine();
-
-            writer.WriteLine(""public override void PrintTo(global::System.IO.TextWriter writer) {"");
-            writer.Indent();
-            List<FieldDescriptor> sorted = new List<FieldDescriptor>(Descriptor.Fields);
-            sorted.Sort(
-                new Comparison<FieldDescriptor>(
-                    delegate(FieldDescriptor a, FieldDescriptor b) { return a.FieldNumber.CompareTo(b.FieldNumber); }));
-            foreach (FieldDescriptor fieldDescriptor in sorted)
-            {
-                CreateFieldGenerator(fieldDescriptor).WriteToString(writer);
-            }
-            if (callbase)
-            {
-                writer.WriteLine(""base.PrintTo(writer);"");
-            }
-            writer.Outdent();
-            writer.WriteLine(""}"");
-            writer.WriteLine(""#endregion"");
-            writer.WriteLine();
-        }
-
-        private void GenerateMessageSerializationMethods(TextGenerator writer)
-        {
-            List<FieldDescriptor> sortedFields = new List<FieldDescriptor>(Descriptor.Fields);
-            sortedFields.Sort((f1, f2) => f1.FieldNumber.CompareTo(f2.FieldNumber));
-
-            List<DescriptorProto.Types.ExtensionRange> sortedExtensions =
-                new List<DescriptorProto.Types.ExtensionRange>(Descriptor.Proto.ExtensionRangeList);
-            sortedExtensions.Sort((r1, r2) => (r1.Start.CompareTo(r2.Start)));
-
-            writer.WriteLine(""public override void WriteTo(pb::ICodedOutputStream output) {"");
-            writer.Indent();
-            // Make sure we've computed the serialized length, so that packed fields are generated correctly.
-            writer.WriteLine(""CalcSerializedSize();"");
-            writer.WriteLine(""string[] field_names = _{0}FieldNames;"", NameHelpers.UnderscoresToCamelCase(ClassName));
-            if (Descriptor.Proto.ExtensionRangeList.Count > 0)
-            {
-                writer.WriteLine(
-                    ""pb::ExtendableMessage{1}<{0}, {0}.Builder>.ExtensionWriter extensionWriter = CreateExtensionWriter(this);"",
-                    ClassName, RuntimeSuffix);
-            }
-
-            // Merge the fields and the extension ranges, both sorted by field number.
-            for (int i = 0, j = 0; i < Descriptor.Fields.Count || j < sortedExtensions.Count;)
-            {
-                if (i == Descriptor.Fields.Count)
-                {
-                    GenerateSerializeOneExtensionRange(writer, sortedExtensions[j++]);
-                }
-                else if (j == sortedExtensions.Count)
-                {
-                    GenerateSerializeOneField(writer, sortedFields[i++]);
-                }
-                else if (sortedFields[i].FieldNumber < sortedExtensions[j].Start)
-                {
-                    GenerateSerializeOneField(writer, sortedFields[i++]);
-                }
-                else
-                {
-                    GenerateSerializeOneExtensionRange(writer, sortedExtensions[j++]);
-                }
-            }
-
-            if (!UseLiteRuntime)
-            {
-                if (Descriptor.Proto.Options.MessageSetWireFormat)
-                {
-                    writer.WriteLine(""UnknownFields.WriteAsMessageSetTo(output);"");
-                }
-                else
-                {
-                    writer.WriteLine(""UnknownFields.WriteTo(output);"");
-                }
-            }
-
-            writer.Outdent();
-            writer.WriteLine(""}"");
-            writer.WriteLine();
-            writer.WriteLine(""private int memoizedSerializedSize = -1;"");
-            writer.WriteLine(""public override int SerializedSize {"");
-            writer.Indent();
-            writer.WriteLine(""get {"");
-            writer.Indent();
-            writer.WriteLine(""int size = memoizedSerializedSize;"");
-            writer.WriteLine(""if (size != -1) return size;"");
-            writer.WriteLine(""return CalcSerializedSize();"");
-            writer.Outdent();
-            writer.WriteLine(""}"");
-            writer.Outdent();
-            writer.WriteLine(""}"");
-            writer.WriteLine();
-
-            writer.WriteLine(""private int CalcSerializedSize() {"");
-            writer.Indent();
-            writer.WriteLine(""int size = memoizedSerializedSize;"");
-            writer.WriteLine(""if (size != -1) return size;"");
-            writer.WriteLine();
-            writer.WriteLine(""size = 0;"");
-            foreach (FieldDescriptor field in Descriptor.Fields)
-            {
-                CreateFieldGenerator(field).GenerateSerializedSizeCode(writer);
-            }
-            if (Descriptor.Proto.ExtensionRangeCount > 0)
-            {
-                writer.WriteLine(""size += ExtensionsSerializedSize;"");
-            }
-
-            if (!UseLiteRuntime)
-            {
-                if (Descriptor.Options.MessageSetWireFormat)
-                {
-                    writer.WriteLine(""size += UnknownFields.SerializedSizeAsMessageSet;"");
-                }
-                else
-                {
-                    writer.WriteLine(""size += UnknownFields.SerializedSize;"");
-                }
-            }
-            writer.WriteLine(""memoizedSerializedSize = size;"");
-            writer.WriteLine(""return size;"");
-            writer.Outdent();
-            writer.WriteLine(""}"");
-        }
-
-        private void GenerateSerializeOneField(TextGenerator writer, FieldDescriptor fieldDescriptor)
-        {
-            CreateFieldGenerator(fieldDescriptor).GenerateSerializationCode(writer);
-        }
-
-        private static void GenerateSerializeOneExtensionRange(TextGenerator writer,
-                                                               DescriptorProto.Types.ExtensionRange extensionRange)
-        {
-            writer.WriteLine(""extensionWriter.WriteUntil({0}, output);"", extensionRange.End);
-        }
-
-        private void GenerateParseFromMethods(TextGenerator writer)
-        {
-            // Note:  These are separate from GenerateMessageSerializationMethods()
-            //   because they need to be generated even for messages that are optimized
-            //   for code size.
-
-            writer.WriteLine(""public static {0} ParseFrom(pb::ByteString data) {{"", ClassName);
-            writer.WriteLine(""  return ((Builder) CreateBuilder().MergeFrom(data)).BuildParsed();"");
-            writer.WriteLine(""}"");
-            writer.WriteLine(
-                ""public static {0} ParseFrom(pb::ByteString data, pb::ExtensionRegistry extensionRegistry) {{"",
-                ClassName);
-            writer.WriteLine(""  return ((Builder) CreateBuilder().MergeFrom(data, extensionRegistry)).BuildParsed();"");
-            writer.WriteLine(""}"");
-            writer.WriteLine(""public static {0} ParseFrom(byte[] data) {{"", ClassName);
-            writer.WriteLine(""  return ((Builder) CreateBuilder().MergeFrom(data)).BuildParsed();"");
-            writer.WriteLine(""}"");
-            writer.WriteLine(""public static {0} ParseFrom(byte[] data, pb::ExtensionRegistry extensionRegistry) {{"",
-                             ClassName);
-            writer.WriteLine(""  return ((Builder) CreateBuilder().MergeFrom(data, extensionRegistry)).BuildParsed();"");
-            writer.WriteLine(""}"");
-            writer.WriteLine(""public static {0} ParseFrom(global::System.IO.Stream input) {{"", ClassName);
-            writer.WriteLine(""  return ((Builder) CreateBuilder().MergeFrom(input)).BuildParsed();"");
-            writer.WriteLine(""}"");
-            writer.WriteLine(
-                ""public static {0} ParseFrom(global::System.IO.Stream input, pb::ExtensionRegistry extensionRegistry) {{"",
-                ClassName);
-            writer.WriteLine(""  return ((Builder) CreateBuilder().MergeFrom(input, extensionRegistry)).BuildParsed();"");
-            writer.WriteLine(""}"");
-            writer.WriteLine(""public static {0} ParseDelimitedFrom(global::System.IO.Stream input) {{"", ClassName);
-            writer.WriteLine(""  return CreateBuilder().MergeDelimitedFrom(input).BuildParsed();"");
-            writer.WriteLine(""}"");
-            writer.WriteLine(
-                ""public static {0} ParseDelimitedFrom(global::System.IO.Stream input, pb::ExtensionRegistry extensionRegistry) {{"",
-                ClassName);
-            writer.WriteLine(""  return CreateBuilder().MergeDelimitedFrom(input, extensionRegistry).BuildParsed();"");
-            writer.WriteLine(""}"");
-            writer.WriteLine(""public static {0} ParseFrom(pb::ICodedInputStream input) {{"", ClassName);
-            writer.WriteLine(""  return ((Builder) CreateBuilder().MergeFrom(input)).BuildParsed();"");
-            writer.WriteLine(""}"");
-            writer.WriteLine(
-                ""public static {0} ParseFrom(pb::ICodedInputStream input, pb::ExtensionRegistry extensionRegistry) {{"",
-                ClassName);
-            writer.WriteLine(""  return ((Builder) CreateBuilder().MergeFrom(input, extensionRegistry)).BuildParsed();"");
-            writer.WriteLine(""}"");
-        }
-
-        /// <summary>
-        /// Returns whether or not the specified message type has any required fields.
-        /// If it doesn't, calls to check for initialization can be optimised.
-        /// TODO(jonskeet): Move this into MessageDescriptor?
-        /// </summary>
-        private static bool HasRequiredFields(MessageDescriptor descriptor,
-                                              Dictionary<MessageDescriptor, object> alreadySeen)
-        {
-            if (alreadySeen.ContainsKey(descriptor))
-            {
-                // The type is already in cache.  This means that either:
-                // a. The type has no required fields.
-                // b. We are in the midst of checking if the type has required fields,
-                //    somewhere up the stack.  In this case, we know that if the type
-                //    has any required fields, they'll be found when we return to it,
-                //    and the whole call to HasRequiredFields() will return true.
-                //    Therefore, we don't have to check if this type has required fields
-                //    here.
-                return false;
-            }
-            alreadySeen[descriptor] = descriptor; // Value is irrelevant
-
-            // If the type has extensions, an extension with message type could contain
-            // required fields, so we have to be conservative and assume such an
-            // extension exists.
-            if (descriptor.Extensions.Count > 0)
-            {
-                return true;
-            }
-
-            foreach (FieldDescriptor field in descriptor.Fields)
-            {
-                if (field.IsRequired)
-                {
-                    return true;
-                }
-                // Message or group
-                if (field.MappedType == MappedType.Message)
-                {
-                    if (HasRequiredFields(field.MessageType, alreadySeen))
-                    {
-                        return true;
-                    }
-                }
-            }
-            return false;
-        }
-
-        private void GenerateBuilder(TextGenerator writer)
-        {
-            writer.WriteLine(""private {0} MakeReadOnly() {{"", ClassName);
-            writer.Indent();
-            foreach (FieldDescriptor field in Descriptor.Fields)
-            {
-                CreateFieldGenerator(field).GenerateBuildingCode(writer);
-            }
-            writer.WriteLine(""return this;"");
-            writer.Outdent();
-            writer.WriteLine(""}"");
-            writer.WriteLine();
-
-            writer.WriteLine(""public static Builder CreateBuilder() { return new Builder(); }"");
-            writer.WriteLine(""public override Builder ToBuilder() { return CreateBuilder(this); }"");
-            writer.WriteLine(""public override Builder CreateBuilderForType() { return new Builder(); }"");
-            writer.WriteLine(""public static Builder CreateBuilder({0} prototype) {{"", ClassName);
-            writer.WriteLine(""  return new Builder(prototype);"");
-            writer.WriteLine(""}"");
-            writer.WriteLine();
-            if (Descriptor.File.CSharpOptions.AddSerializable)
-            {
-                writer.WriteLine(""[global::System.SerializableAttribute()]"");
-            }
-            writer.WriteLine(""[global::System.Diagnostics.DebuggerNonUserCodeAttribute()]"");
-            WriteGeneratedCodeAttributes(writer);
-            writer.WriteLine(""{0} sealed partial class Builder : pb::{2}Builder{3}<{1}, Builder> {{"",
-                             ClassAccessLevel, ClassName,
-                             Descriptor.Proto.ExtensionRangeCount > 0 ? ""Extendable"" : ""Generated"", RuntimeSuffix);
-            writer.Indent();
-            writer.WriteLine(""protected override Builder ThisBuilder {"");
-            writer.WriteLine(""  get { return this; }"");
-            writer.WriteLine(""}"");
-            GenerateCommonBuilderMethods(writer);
-            if (OptimizeSpeed)
-            {
-                GenerateBuilderParsingMethods(writer);
-            }
-            foreach (FieldDescriptor field in Descriptor.Fields)
-            {
-                writer.WriteLine();
-                // No field comment :(
-                CreateFieldGenerator(field).GenerateBuilderMembers(writer);
-            }
-            writer.Outdent();
-            writer.WriteLine(""}"");
-        }
-
-        private void GenerateCommonBuilderMethods(TextGenerator writer)
-        {
-            //default constructor
-            writer.WriteLine(""public Builder() {"");
-            //Durring static initialization of message, DefaultInstance is expected to return null.
-            writer.WriteLine(""  result = DefaultInstance;"");
-            writer.WriteLine(""  resultIsReadOnly = true;"");
-            writer.WriteLine(""}"");
-            //clone constructor
-            writer.WriteLine(""internal Builder({0} cloneFrom) {{"", ClassName);
-            writer.WriteLine(""  result = cloneFrom;"");
-            writer.WriteLine(""  resultIsReadOnly = true;"");
-            writer.WriteLine(""}"");
-            writer.WriteLine();
-            writer.WriteLine(""private bool resultIsReadOnly;"");
-            writer.WriteLine(""private {0} result;"", ClassName);
-            writer.WriteLine();
-            writer.WriteLine(""private {0} PrepareBuilder() {{"", ClassName);
-            writer.WriteLine(""  if (resultIsReadOnly) {"");
-            writer.WriteLine(""    {0} original = result;"", ClassName);
-            writer.WriteLine(""    result = new {0}();"", ClassName);
-            writer.WriteLine(""    resultIsReadOnly = false;"");
-            writer.WriteLine(""    MergeFrom(original);"");
-            writer.WriteLine(""  }"");
-            writer.WriteLine(""  return result;"");
-            writer.WriteLine(""}"");
-            writer.WriteLine();
-            writer.WriteLine(""public override bool IsInitialized {"");
-            writer.WriteLine(""  get { return result.IsInitialized; }"");
-            writer.WriteLine(""}"");
-            writer.WriteLine();
-            writer.WriteLine(""protected override {0} MessageBeingBuilt {{"", ClassName);
-            writer.WriteLine(""  get { return PrepareBuilder(); }"");
-            writer.WriteLine(""}"");
-            writer.WriteLine();
-            //Not actually expecting that DefaultInstance would ever be null here; however, we will ensure it does not break
-            writer.WriteLine(""public override Builder Clear() {"");
-            writer.WriteLine(""  result = DefaultInstance;"", ClassName);
-            writer.WriteLine(""  resultIsReadOnly = true;"");
-            writer.WriteLine(""  return this;"");
-            writer.WriteLine(""}"");
-            writer.WriteLine();
-            writer.WriteLine(""public override Builder Clone() {"");
-            writer.WriteLine(""  if (resultIsReadOnly) {"");
-            writer.WriteLine(""    return new Builder(result);"");
-            writer.WriteLine(""  } else {"");
-            writer.WriteLine(""    return new Builder().MergeFrom(result);"");
-            writer.WriteLine(""  }"");
-            writer.WriteLine(""}"");
-            writer.WriteLine();
-            if (!UseLiteRuntime)
-            {
-                writer.WriteLine(""public override pbd::MessageDescriptor DescriptorForType {"");
-                writer.WriteLine(""  get {{ return {0}.Descriptor; }}"", FullClassName);
-                writer.WriteLine(""}"");
-                writer.WriteLine();
-            }
-            writer.WriteLine(""public override {0} DefaultInstanceForType {{"", ClassName);
-            writer.WriteLine(""  get {{ return {0}.DefaultInstance; }}"", FullClassName);
-            writer.WriteLine(""}"");
-            writer.WriteLine();
-
-            writer.WriteLine(""public override {0} BuildPartial() {{"", ClassName);
-            writer.Indent();
-            writer.WriteLine(""if (resultIsReadOnly) {"");
-            writer.WriteLine(""  return result;"");
-            writer.WriteLine(""}"");
-            writer.WriteLine(""resultIsReadOnly = true;"");
-            writer.WriteLine(""return result.MakeReadOnly();"");
-            writer.Outdent();
-            writer.WriteLine(""}"");
-            writer.WriteLine();
-
-            if (OptimizeSpeed)
-            {
-                writer.WriteLine(""public override Builder MergeFrom(pb::IMessage{0} other) {{"", RuntimeSuffix);
-                writer.WriteLine(""  if (other is {0}) {{"", ClassName);
-                writer.WriteLine(""    return MergeFrom(({0}) other);"", ClassName);
-                writer.WriteLine(""  } else {"");
-                writer.WriteLine(""    base.MergeFrom(other);"");
-                writer.WriteLine(""    return this;"");
-                writer.WriteLine(""  }"");
-                writer.WriteLine(""}"");
-                writer.WriteLine();
-                writer.WriteLine(""public override Builder MergeFrom({0} other) {{"", ClassName);
-                // Optimization:  If other is the default instance, we know none of its
-                // fields are set so we can skip the merge.
-                writer.Indent();
-                writer.WriteLine(""if (other == {0}.DefaultInstance) return this;"", FullClassName);
-                writer.WriteLine(""PrepareBuilder();"");
-                foreach (FieldDescriptor field in Descriptor.Fields)
-                {
-                    CreateFieldGenerator(field).GenerateMergingCode(writer);
-                }
-                // if message type has extensions
-                if (Descriptor.Proto.ExtensionRangeCount > 0)
-                {
-                    writer.WriteLine(""  this.MergeExtensionFields(other);"");
-                }
-                if (!UseLiteRuntime)
-                {
-                    writer.WriteLine(""this.MergeUnknownFields(other.UnknownFields);"");
-                }
-                writer.WriteLine(""return this;"");
-                writer.Outdent();
-                writer.WriteLine(""}"");
-                writer.WriteLine();
-            }
-        }
-
-        private void GenerateBuilderParsingMethods(TextGenerator writer)
-        {
-            List<FieldDescriptor> sortedFields = new List<FieldDescriptor>(Descriptor.Fields);
-            sortedFields.Sort((f1, f2) => f1.FieldNumber.CompareTo(f2.FieldNumber));
-
-            writer.WriteLine(""public override Builder MergeFrom(pb::ICodedInputStream input) {"");
-            writer.WriteLine(""  return MergeFrom(input, pb::ExtensionRegistry.Empty);"");
-            writer.WriteLine(""}"");
-            writer.WriteLine();
-            writer.WriteLine(
-                ""public override Builder MergeFrom(pb::ICodedInputStream input, pb::ExtensionRegistry extensionRegistry) {"");
-            writer.Indent();
-            writer.WriteLine(""PrepareBuilder();"");
-            if (!UseLiteRuntime)
-            {
-                writer.WriteLine(""pb::UnknownFieldSet.Builder unknownFields = null;"");
-            }
-            writer.WriteLine(""uint tag;"");
-            writer.WriteLine(""string field_name;"");
-            writer.WriteLine(""while (input.ReadTag(out tag, out field_name)) {"");
-            writer.Indent();
-            writer.WriteLine(""if(tag == 0 && field_name != null) {"");
-            writer.Indent();
-            //if you change from StringComparer.Ordinal, the array sort in FieldNames { get; } must also change
-            writer.WriteLine(
-                ""int field_ordinal = global::System.Array.BinarySearch(_{0}FieldNames, field_name, global::System.StringComparer.Ordinal);"",
-                NameHelpers.UnderscoresToCamelCase(ClassName));
-            writer.WriteLine(""if(field_ordinal >= 0)"");
-            writer.WriteLine(""  tag = _{0}FieldTags[field_ordinal];"", NameHelpers.UnderscoresToCamelCase(ClassName));
-            writer.WriteLine(""else {"");
-            if (!UseLiteRuntime)
-            {
-                writer.WriteLine(""  if (unknownFields == null) {""); // First unknown field - create builder now
-                writer.WriteLine(""    unknownFields = pb::UnknownFieldSet.CreateBuilder(this.UnknownFields);"");
-                writer.WriteLine(""  }"");
-            }
-            writer.WriteLine(""  ParseUnknownField(input, {0}extensionRegistry, tag, field_name);"",
-                             UseLiteRuntime ? """" : ""unknownFields, "");
-            writer.WriteLine(""  continue;"");
-            writer.WriteLine(""}"");
-            writer.Outdent();
-            writer.WriteLine(""}"");
-
-            writer.WriteLine(""switch (tag) {"");
-            writer.Indent();
-            writer.WriteLine(""case 0: {""); // 0 signals EOF / limit reached
-            writer.WriteLine(""  throw pb::InvalidProtocolBufferException.InvalidTag();"");
-            writer.WriteLine(""}"");
-            writer.WriteLine(""default: {"");
-            writer.WriteLine(""  if (pb::WireFormat.IsEndGroupTag(tag)) {"");
-            if (!UseLiteRuntime)
-            {
-                writer.WriteLine(""    if (unknownFields != null) {"");
-                writer.WriteLine(""      this.UnknownFields = unknownFields.Build();"");
-                writer.WriteLine(""    }"");
-            }
-            writer.WriteLine(""    return this;""); // it's an endgroup tag
-            writer.WriteLine(""  }"");
-            if (!UseLiteRuntime)
-            {
-                writer.WriteLine(""  if (unknownFields == null) {""); // First unknown field - create builder now
-                writer.WriteLine(""    unknownFields = pb::UnknownFieldSet.CreateBuilder(this.UnknownFields);"");
-                writer.WriteLine(""  }"");
-            }
-            writer.WriteLine(""  ParseUnknownField(input, {0}extensionRegistry, tag, field_name);"",
-                             UseLiteRuntime ? """" : ""unknownFields, "");
-            writer.WriteLine(""  break;"");
-            writer.WriteLine(""}"");
-            foreach (FieldDescriptor field in sortedFields)
-            {
-                WireFormat.WireType wt = WireFormat.GetWireType(field.FieldType);
-                uint tag = WireFormat.MakeTag(field.FieldNumber, wt);
-
-                if (field.IsRepeated &&
-                    (wt == WireFormat.WireType.Varint || wt == WireFormat.WireType.Fixed32 ||
-                     wt == WireFormat.WireType.Fixed64))
-                {
-                    writer.WriteLine(""case {0}:"",
-                                     WireFormat.MakeTag(field.FieldNumber, WireFormat.WireType.LengthDelimited));
-                }
-
-                writer.WriteLine(""case {0}: {{"", tag);
-                writer.Indent();
-                CreateFieldGenerator(field).GenerateParsingCode(writer);
-                writer.WriteLine(""break;"");
-                writer.Outdent();
-                writer.WriteLine(""}"");
-            }
-            writer.Outdent();
-            writer.WriteLine(""}"");
-            writer.Outdent();
-            writer.WriteLine(""}"");
-            writer.WriteLine();
-            if (!UseLiteRuntime)
-            {
-                writer.WriteLine(""if (unknownFields != null) {"");
-                writer.WriteLine(""  this.UnknownFields = unknownFields.Build();"");
-                writer.WriteLine(""}"");
-            }
-            writer.WriteLine(""return this;"");
-            writer.Outdent();
-            writer.WriteLine(""}"");
-            writer.WriteLine();
-        }
-
-        private void GenerateIsInitialized(TextGenerator writer)
-        {
-            writer.WriteLine(""public override bool IsInitialized {"");
-            writer.Indent();
-            writer.WriteLine(""get {"");
-            writer.Indent();
-
-            // Check that all required fields in this message are set.
-            // TODO(kenton):  We can optimize this when we switch to putting all the
-            // ""has"" fields into a single bitfield.
-            foreach (FieldDescriptor field in Descriptor.Fields)
-            {
-                if (field.IsRequired)
-                {
-                    writer.WriteLine(""if (!has{0}) return false;"", field.CSharpOptions.PropertyName);
-                }
-            }
-
-            // Now check that all embedded messages are initialized.
-            foreach (FieldDescriptor field in Descriptor.Fields)
-            {
-                if (field.FieldType != FieldType.Message ||
-                    !HasRequiredFields(field.MessageType, new Dictionary<MessageDescriptor, object>()))
-                {
-                    continue;
-                }
-                string propertyName = NameHelpers.UnderscoresToPascalCase(GetFieldName(field));
-                if (field.IsRepeated)
-                {
-                    writer.WriteLine(""foreach ({0} element in {1}List) {{"", GetClassName(field.MessageType),
-                                     propertyName);
-                    writer.WriteLine(""  if (!element.IsInitialized) return false;"");
-                    writer.WriteLine(""}"");
-                }
-                else if (field.IsOptional)
-                {
-                    writer.WriteLine(""if (Has{0}) {{"", propertyName);
-                    writer.WriteLine(""  if (!{0}.IsInitialized) return false;"", propertyName);
-                    writer.WriteLine(""}"");
-                }
-                else
-                {
-                    writer.WriteLine(""if (!{0}.IsInitialized) return false;"", propertyName);
-                }
-            }
-
-            if (Descriptor.Proto.ExtensionRangeCount > 0)
-            {
-                writer.WriteLine(""if (!ExtensionsAreInitialized) return false;"");
-            }
-            writer.WriteLine(""return true;"");
-            writer.Outdent();
-            writer.WriteLine(""}"");
-            writer.Outdent();
-            writer.WriteLine(""}"");
-            writer.WriteLine();
-        }
-
-        internal void GenerateExtensionRegistrationCode(TextGenerator writer)
-        {
-            foreach (FieldDescriptor extension in Descriptor.Extensions)
-            {
-                new ExtensionGenerator(extension).GenerateExtensionRegistrationCode(writer);
-            }
-            foreach (MessageDescriptor nestedMessage in Descriptor.NestedTypes)
-            {
-                new MessageGenerator(nestedMessage).GenerateExtensionRegistrationCode(writer);
-            }
-        }
-    }
-}
\ No newline at end of file
diff --git a/csharp/src/ProtoGen/PluginProtoFile.cs b/csharp/src/ProtoGen/PluginProtoFile.cs
deleted file mode 100644
index e0fed5c34..000000000
--- a/csharp/src/ProtoGen/PluginProtoFile.cs
+++ /dev/null
@@ -1,1187 +0,0 @@
-// Generated by protoc-gen-cs, Version=2.4.1.521, Culture=neutral, PublicKeyToken=17b3b1f090c3ea48.  DO NOT EDIT!
-#pragma warning disable 1591, 0612, 3021
-#region Designer generated code
-
-using pb = global::Google.ProtocolBuffers;
-using pbc = global::Google.ProtocolBuffers.Collections;
-using pbd = global::Google.ProtocolBuffers.Descriptors;
-using scg = global::System.Collections.Generic;
-namespace Google.ProtocolBuffers.Compiler.PluginProto {
-
-  [global::System.Diagnostics.DebuggerNonUserCodeAttribute()]
-  public static partial class Plugin {
-
-    #region Extension registration
-    public static void RegisterAllExtensions(pb::ExtensionRegistry registry) {
-    }
-    #endregion
-    #region Static variables
-    internal static pbd::MessageDescriptor internal__static_google_protobuf_compiler_CodeGeneratorRequest__Descriptor;
-    internal static pb::FieldAccess.FieldAccessorTable<global::Google.ProtocolBuffers.Compiler.PluginProto.CodeGeneratorRequest, global::Google.ProtocolBuffers.Compiler.PluginProto.CodeGeneratorRequest.Builder> internal__static_google_protobuf_compiler_CodeGeneratorRequest__FieldAccessorTable;
-    internal static pbd::MessageDescriptor internal__static_google_protobuf_compiler_CodeGeneratorResponse__Descriptor;
-    internal static pb::FieldAccess.FieldAccessorTable<global::Google.ProtocolBuffers.Compiler.PluginProto.CodeGeneratorResponse, global::Google.ProtocolBuffers.Compiler.PluginProto.CodeGeneratorResponse.Builder> internal__static_google_protobuf_compiler_CodeGeneratorResponse__FieldAccessorTable;
-    internal static pbd::MessageDescriptor internal__static_google_protobuf_compiler_CodeGeneratorResponse_File__Descriptor;
-    internal static pb::FieldAccess.FieldAccessorTable<global::Google.ProtocolBuffers.Compiler.PluginProto.CodeGeneratorResponse.Types.File, global::Google.ProtocolBuffers.Compiler.PluginProto.CodeGeneratorResponse.Types.File.Builder> internal__static_google_protobuf_compiler_CodeGeneratorResponse_File__FieldAccessorTable;
-    #endregion
-    #region Descriptor
-    public static pbd::FileDescriptor Descriptor {
-      get { return descriptor; }
-    }
-    private static pbd::FileDescriptor descriptor;
-
-    static Plugin() {
-      byte[] descriptorData = global::System.Convert.FromBase64String(
-          string.Concat(
-            ""CiVnb29nbGUvcHJvdG9idWYvY29tcGlsZXIvcGx1Z2luLnByb3RvEhhnb29n"",
-            ""bGUucHJvdG9idWYuY29tcGlsZXIaIGdvb2dsZS9wcm90b2J1Zi9kZXNjcmlw"",
-            ""dG9yLnByb3RvIn0KFENvZGVHZW5lcmF0b3JSZXF1ZXN0EhgKEGZpbGVfdG9f"",
-            ""Z2VuZXJhdGUYASADKAkSEQoJcGFyYW1ldGVyGAIgASgJEjgKCnByb3RvX2Zp"",
-            ""bGUYDyADKAsyJC5nb29nbGUucHJvdG9idWYuRmlsZURlc2NyaXB0b3JQcm90"",
-            ""byKqAQoVQ29kZUdlbmVyYXRvclJlc3BvbnNlEg0KBWVycm9yGAEgASgJEkIK"",
-            ""BGZpbGUYDyADKAsyNC5nb29nbGUucHJvdG9idWYuY29tcGlsZXIuQ29kZUdl"",
-            ""bmVyYXRvclJlc3BvbnNlLkZpbGUaPgoERmlsZRIMCgRuYW1lGAEgASgJEhcK"",
-            ""D2luc2VydGlvbl9wb2ludBgCIAEoCRIPCgdjb250ZW50GA8gASgJQiwKHGNv"",
-          ""bS5nb29nbGUucHJvdG9idWYuY29tcGlsZXJCDFBsdWdpblByb3Rvcw==""));
-      pbd::FileDescriptor.InternalDescriptorAssigner assigner = delegate(pbd::FileDescriptor root) {
-        descriptor = root;
-        internal__static_google_protobuf_compiler_CodeGeneratorRequest__Descriptor = Descriptor.MessageTypes[0];
-        internal__static_google_protobuf_compiler_CodeGeneratorRequest__FieldAccessorTable =
-            new pb::FieldAccess.FieldAccessorTable<global::Google.ProtocolBuffers.Compiler.PluginProto.CodeGeneratorRequest, global::Google.ProtocolBuffers.Compiler.PluginProto.CodeGeneratorRequest.Builder>(internal__static_google_protobuf_compiler_CodeGeneratorRequest__Descriptor,
-                new string[] { ""FileToGenerate"", ""Parameter"", ""ProtoFile"", });
-        internal__static_google_protobuf_compiler_CodeGeneratorResponse__Descriptor = Descriptor.MessageTypes[1];
-        internal__static_google_protobuf_compiler_CodeGeneratorResponse__FieldAccessorTable =
-            new pb::FieldAccess.FieldAccessorTable<global::Google.ProtocolBuffers.Compiler.PluginProto.CodeGeneratorResponse, global::Google.ProtocolBuffers.Compiler.PluginProto.CodeGeneratorResponse.Builder>(internal__static_google_protobuf_compiler_CodeGeneratorResponse__Descriptor,
-                new string[] { ""Error"", ""File"", });
-        internal__static_google_protobuf_compiler_CodeGeneratorResponse_File__Descriptor = internal__static_google_protobuf_compiler_CodeGeneratorResponse__Descriptor.NestedTypes[0];
-        internal__static_google_protobuf_compiler_CodeGeneratorResponse_File__FieldAccessorTable =
-            new pb::FieldAccess.FieldAccessorTable<global::Google.ProtocolBuffers.Compiler.PluginProto.CodeGeneratorResponse.Types.File, global::Google.ProtocolBuffers.Compiler.PluginProto.CodeGeneratorResponse.Types.File.Builder>(internal__static_google_protobuf_compiler_CodeGeneratorResponse_File__Descriptor,
-                new string[] { ""Name"", ""InsertionPoint"", ""Content"", });
-        return null;
-      };
-      pbd::FileDescriptor.InternalBuildGeneratedFileFrom(descriptorData,
-          new pbd::FileDescriptor[] {
-          global::Google.ProtocolBuffers.DescriptorProtos.DescriptorProtoFile.Descriptor,
-          }, assigner);
-    }
-    #endregion
-
-  }
-  #region Messages
-  [global::System.Diagnostics.DebuggerNonUserCodeAttribute()]
-  public sealed partial class CodeGeneratorRequest : pb::GeneratedMessage<CodeGeneratorRequest, CodeGeneratorRequest.Builder> {
-    private CodeGeneratorRequest() { }
-    private static readonly CodeGeneratorRequest defaultInstance = new CodeGeneratorRequest().MakeReadOnly();
-    private static readonly string[] _codeGeneratorRequestFieldNames = new string[] { ""file_to_generate"", ""parameter"", ""proto_file"" };
-    private static readonly uint[] _codeGeneratorRequestFieldTags = new uint[] { 10, 18, 122 };
-    public static CodeGeneratorRequest DefaultInstance {
-      get { return defaultInstance; }
-    }
-
-    public override CodeGeneratorRequest DefaultInstanceForType {
-      get { return DefaultInstance; }
-    }
-
-    protected override CodeGeneratorRequest ThisMessage {
-      get { return this; }
-    }
-
-    public static pbd::MessageDescriptor Descriptor {
-      get { return global::Google.ProtocolBuffers.Compiler.PluginProto.Plugin.internal__static_google_protobuf_compiler_CodeGeneratorRequest__Descriptor; }
-    }
-
-    protected override pb::FieldAccess.FieldAccessorTable<CodeGeneratorRequest, CodeGeneratorRequest.Builder> InternalFieldAccessors {
-      get { return global::Google.ProtocolBuffers.Compiler.PluginProto.Plugin.internal__static_google_protobuf_compiler_CodeGeneratorRequest__FieldAccessorTable; }
-    }
-
-    public const int FileToGenerateFieldNumber = 1;
-    private pbc::PopsicleList<string> fileToGenerate_ = new pbc::PopsicleList<string>();
-    public scg::IList<string> FileToGenerateList {
-      get { return pbc::Lists.AsReadOnly(fileToGenerate_); }
-    }
-    public int FileToGenerateCount {
-      get { return fileToGenerate_.Count; }
-    }
-    public string GetFileToGenerate(int index) {
-      return fileToGenerate_[index];
-    }
-
-    public const int ParameterFieldNumber = 2;
-    private bool hasParameter;
-    private string parameter_ = """";
-    public bool HasParameter {
-      get { return hasParameter; }
-    }
-    public string Parameter {
-      get { return parameter_; }
-    }
-
-    public const int ProtoFileFieldNumber = 15;
-    private pbc::PopsicleList<global::Google.ProtocolBuffers.DescriptorProtos.FileDescriptorProto> protoFile_ = new pbc::PopsicleList<global::Google.ProtocolBuffers.DescriptorProtos.FileDescriptorProto>();
-    public scg::IList<global::Google.ProtocolBuffers.DescriptorProtos.FileDescriptorProto> ProtoFileList {
-      get { return protoFile_; }
-    }
-    public int ProtoFileCount {
-      get { return protoFile_.Count; }
-    }
-    public global::Google.ProtocolBuffers.DescriptorProtos.FileDescriptorProto GetProtoFile(int index) {
-      return protoFile_[index];
-    }
-
-    public override bool IsInitialized {
-      get {
-        foreach (global::Google.ProtocolBuffers.DescriptorProtos.FileDescriptorProto element in ProtoFileList) {
-          if (!element.IsInitialized) return false;
-        }
-        return true;
-      }
-    }
-
-    public override void WriteTo(pb::ICodedOutputStream output) {
-      int size = SerializedSize;
-      string[] field_names = _codeGeneratorRequestFieldNames;
-      if (fileToGenerate_.Count > 0) {
-        output.WriteStringArray(1, field_names[0], fileToGenerate_);
-      }
-      if (hasParameter) {
-        output.WriteString(2, field_names[1], Parameter);
-      }
-      if (protoFile_.Count > 0) {
-        output.WriteMessageArray(15, field_names[2], protoFile_);
-      }
-      UnknownFields.WriteTo(output);
-    }
-
-    private int memoizedSerializedSize = -1;
-    public override int SerializedSize {
-      get {
-        int size = memoizedSerializedSize;
-        if (size != -1) return size;
-
-        size = 0;
-        {
-          int dataSize = 0;
-          foreach (string element in FileToGenerateList) {
-            dataSize += pb::CodedOutputStream.ComputeStringSizeNoTag(element);
-          }
-          size += dataSize;
-          size += 1 * fileToGenerate_.Count;
-        }
-        if (hasParameter) {
-          size += pb::CodedOutputStream.ComputeStringSize(2, Parameter);
-        }
-        foreach (global::Google.ProtocolBuffers.DescriptorProtos.FileDescriptorProto element in ProtoFileList) {
-          size += pb::CodedOutputStream.ComputeMessageSize(15, element);
-        }
-        size += UnknownFields.SerializedSize;
-        memoizedSerializedSize = size;
-        return size;
-      }
-    }
-
-    public static CodeGeneratorRequest ParseFrom(pb::ByteString data) {
-      return ((Builder) CreateBuilder().MergeFrom(data)).BuildParsed();
-    }
-    public static CodeGeneratorRequest ParseFrom(pb::ByteString data, pb::ExtensionRegistry extensionRegistry) {
-      return ((Builder) CreateBuilder().MergeFrom(data, extensionRegistry)).BuildParsed();
-    }
-    public static CodeGeneratorRequest ParseFrom(byte[] data) {
-      return ((Builder) CreateBuilder().MergeFrom(data)).BuildParsed();
-    }
-    public static CodeGeneratorRequest ParseFrom(byte[] data, pb::ExtensionRegistry extensionRegistry) {
-      return ((Builder) CreateBuilder().MergeFrom(data, extensionRegistry)).BuildParsed();
-    }
-    public static CodeGeneratorRequest ParseFrom(global::System.IO.Stream input) {
-      return ((Builder) CreateBuilder().MergeFrom(input)).BuildParsed();
-    }
-    public static CodeGeneratorRequest ParseFrom(global::System.IO.Stream input, pb::ExtensionRegistry extensionRegistry) {
-      return ((Builder) CreateBuilder().MergeFrom(input, extensionRegistry)).BuildParsed();
-    }
-    public static CodeGeneratorRequest ParseDelimitedFrom(global::System.IO.Stream input) {
-      return CreateBuilder().MergeDelimitedFrom(input).BuildParsed();
-    }
-    public static CodeGeneratorRequest ParseDelimitedFrom(global::System.IO.Stream input, pb::ExtensionRegistry extensionRegistry) {
-      return CreateBuilder().MergeDelimitedFrom(input, extensionRegistry).BuildParsed();
-    }
-    public static CodeGeneratorRequest ParseFrom(pb::ICodedInputStream input) {
-      return ((Builder) CreateBuilder().MergeFrom(input)).BuildParsed();
-    }
-    public static CodeGeneratorRequest ParseFrom(pb::ICodedInputStream input, pb::ExtensionRegistry extensionRegistry) {
-      return ((Builder) CreateBuilder().MergeFrom(input, extensionRegistry)).BuildParsed();
-    }
-    private CodeGeneratorRequest MakeReadOnly() {
-      fileToGenerate_.MakeReadOnly();
-      protoFile_.MakeReadOnly();
-      return this;
-    }
-
-    public static Builder CreateBuilder() { return new Builder(); }
-    public override Builder ToBuilder() { return CreateBuilder(this); }
-    public override Builder CreateBuilderForType() { return new Builder(); }
-    public static Builder CreateBuilder(CodeGeneratorRequest prototype) {
-      return new Builder(prototype);
-    }
-
-    [global::System.Diagnostics.DebuggerNonUserCodeAttribute()]
-    public sealed partial class Builder : pb::GeneratedBuilder<CodeGeneratorRequest, Builder> {
-      protected override Builder ThisBuilder {
-        get { return this; }
-      }
-      public Builder() {
-        result = DefaultInstance;
-        resultIsReadOnly = true;
-      }
-      internal Builder(CodeGeneratorRequest cloneFrom) {
-        result = cloneFrom;
-        resultIsReadOnly = true;
-      }
-
-      private bool resultIsReadOnly;
-      private CodeGeneratorRequest result;
-
-      private CodeGeneratorRequest PrepareBuilder() {
-        if (resultIsReadOnly) {
-          CodeGeneratorRequest original = result;
-          result = new CodeGeneratorRequest();
-          resultIsReadOnly = false;
-          MergeFrom(original);
-        }
-        return result;
-      }
-
-      public override bool IsInitialized {
-        get { return result.IsInitialized; }
-      }
-
-      protected override CodeGeneratorRequest MessageBeingBuilt {
-        get { return PrepareBuilder(); }
-      }
-
-      public override Builder Clear() {
-        result = DefaultInstance;
-        resultIsReadOnly = true;
-        return this;
-      }
-
-      public override Builder Clone() {
-        if (resultIsReadOnly) {
-          return new Builder(result);
-        } else {
-          return new Builder().MergeFrom(result);
-        }
-      }
-
-      public override pbd::MessageDescriptor DescriptorForType {
-        get { return global::Google.ProtocolBuffers.Compiler.PluginProto.CodeGeneratorRequest.Descriptor; }
-      }
-
-      public override CodeGeneratorRequest DefaultInstanceForType {
-        get { return global::Google.ProtocolBuffers.Compiler.PluginProto.CodeGeneratorRequest.DefaultInstance; }
-      }
-
-      public override CodeGeneratorRequest BuildPartial() {
-        if (resultIsReadOnly) {
-          return result;
-        }
-        resultIsReadOnly = true;
-        return result.MakeReadOnly();
-      }
-
-      public override Builder MergeFrom(pb::IMessage other) {
-        if (other is CodeGeneratorRequest) {
-          return MergeFrom((CodeGeneratorRequest) other);
-        } else {
-          base.MergeFrom(other);
-          return this;
-        }
-      }
-
-      public override Builder MergeFrom(CodeGeneratorRequest other) {
-        if (other == global::Google.ProtocolBuffers.Compiler.PluginProto.CodeGeneratorRequest.DefaultInstance) return this;
-        PrepareBuilder();
-        if (other.fileToGenerate_.Count != 0) {
-          result.fileToGenerate_.Add(other.fileToGenerate_);
-        }
-        if (other.HasParameter) {
-          Parameter = other.Parameter;
-        }
-        if (other.protoFile_.Count != 0) {
-          result.protoFile_.Add(other.protoFile_);
-        }
-        this.MergeUnknownFields(other.UnknownFields);
-        return this;
-      }
-
-      public override Builder MergeFrom(pb::ICodedInputStream input) {
-        return MergeFrom(input, pb::ExtensionRegistry.Empty);
-      }
-
-      public override Builder MergeFrom(pb::ICodedInputStream input, pb::ExtensionRegistry extensionRegistry) {
-        PrepareBuilder();
-        pb::UnknownFieldSet.Builder unknownFields = null;
-        uint tag;
-        string field_name;
-        while (input.ReadTag(out tag, out field_name)) {
-          if(tag == 0 && field_name != null) {
-            int field_ordinal = global::System.Array.BinarySearch(_codeGeneratorRequestFieldNames, field_name, global::System.StringComparer.Ordinal);
-            if(field_ordinal >= 0)
-              tag = _codeGeneratorRequestFieldTags[field_ordinal];
-            else {
-              if (unknownFields == null) {
-                unknownFields = pb::UnknownFieldSet.CreateBuilder(this.UnknownFields);
-              }
-              ParseUnknownField(input, unknownFields, extensionRegistry, tag, field_name);
-              continue;
-            }
-          }
-          switch (tag) {
-            case 0: {
-              throw pb::InvalidProtocolBufferException.InvalidTag();
-            }
-            default: {
-              if (pb::WireFormat.IsEndGroupTag(tag)) {
-                if (unknownFields != null) {
-                  this.UnknownFields = unknownFields.Build();
-                }
-                return this;
-              }
-              if (unknownFields == null) {
-                unknownFields = pb::UnknownFieldSet.CreateBuilder(this.UnknownFields);
-              }
-              ParseUnknownField(input, unknownFields, extensionRegistry, tag, field_name);
-              break;
-            }
-            case 10: {
-              input.ReadStringArray(tag, field_name, result.fileToGenerate_);
-              break;
-            }
-            case 18: {
-              result.hasParameter = input.ReadString(ref result.parameter_);
-              break;
-            }
-            case 122: {
-              input.ReadMessageArray(tag, field_name, result.protoFile_, global::Google.ProtocolBuffers.DescriptorProtos.FileDescriptorProto.DefaultInstance, extensionRegistry);
-              break;
-            }
-          }
-        }
-
-        if (unknownFields != null) {
-          this.UnknownFields = unknownFields.Build();
-        }
-        return this;
-      }
-
-
-      public pbc::IPopsicleList<string> FileToGenerateList {
-        get { return PrepareBuilder().fileToGenerate_; }
-      }
-      public int FileToGenerateCount {
-        get { return result.FileToGenerateCount; }
-      }
-      public string GetFileToGenerate(int index) {
-        return result.GetFileToGenerate(index);
-      }
-      public Builder SetFileToGenerate(int index, string value) {
-        pb::ThrowHelper.ThrowIfNull(value, ""value"");
-        PrepareBuilder();
-        result.fileToGenerate_[index] = value;
-        return this;
-      }
-      public Builder AddFileToGenerate(string value) {
-        pb::ThrowHelper.ThrowIfNull(value, ""value"");
-        PrepareBuilder();
-        result.fileToGenerate_.Add(value);
-        return this;
-      }
-      public Builder AddRangeFileToGenerate(scg::IEnumerable<string> values) {
-        PrepareBuilder();
-        result.fileToGenerate_.Add(values);
-        return this;
-      }
-      public Builder ClearFileToGenerate() {
-        PrepareBuilder();
-        result.fileToGenerate_.Clear();
-        return this;
-      }
-
-      public bool HasParameter {
-        get { return result.hasParameter; }
-      }
-      public string Parameter {
-        get { return result.Parameter; }
-        set { SetParameter(value); }
-      }
-      public Builder SetParameter(string value) {
-        pb::ThrowHelper.ThrowIfNull(value, ""value"");
-        PrepareBuilder();
-        result.hasParameter = true;
-        result.parameter_ = value;
-        return this;
-      }
-      public Builder ClearParameter() {
-        PrepareBuilder();
-        result.hasParameter = false;
-        result.parameter_ = """";
-        return this;
-      }
-
-      public pbc::IPopsicleList<global::Google.ProtocolBuffers.DescriptorProtos.FileDescriptorProto> ProtoFileList {
-        get { return PrepareBuilder().protoFile_; }
-      }
-      public int ProtoFileCount {
-        get { return result.ProtoFileCount; }
-      }
-      public global::Google.ProtocolBuffers.DescriptorProtos.FileDescriptorProto GetProtoFile(int index) {
-        return result.GetProtoFile(index);
-      }
-      public Builder SetProtoFile(int index, global::Google.ProtocolBuffers.DescriptorProtos.FileDescriptorProto value) {
-        pb::ThrowHelper.ThrowIfNull(value, ""value"");
-        PrepareBuilder();
-        result.protoFile_[index] = value;
-        return this;
-      }
-      public Builder SetProtoFile(int index, global::Google.ProtocolBuffers.DescriptorProtos.FileDescriptorProto.Builder builderForValue) {
-        pb::ThrowHelper.ThrowIfNull(builderForValue, ""builderForValue"");
-        PrepareBuilder();
-        result.protoFile_[index] = builderForValue.Build();
-        return this;
-      }
-      public Builder AddProtoFile(global::Google.ProtocolBuffers.DescriptorProtos.FileDescriptorProto value) {
-        pb::ThrowHelper.ThrowIfNull(value, ""value"");
-        PrepareBuilder();
-        result.protoFile_.Add(value);
-        return this;
-      }
-      public Builder AddProtoFile(global::Google.ProtocolBuffers.DescriptorProtos.FileDescriptorProto.Builder builderForValue) {
-        pb::ThrowHelper.ThrowIfNull(builderForValue, ""builderForValue"");
-        PrepareBuilder();
-        result.protoFile_.Add(builderForValue.Build());
-        return this;
-      }
-      public Builder AddRangeProtoFile(scg::IEnumerable<global::Google.ProtocolBuffers.DescriptorProtos.FileDescriptorProto> values) {
-        PrepareBuilder();
-        result.protoFile_.Add(values);
-        return this;
-      }
-      public Builder ClearProtoFile() {
-        PrepareBuilder();
-        result.protoFile_.Clear();
-        return this;
-      }
-    }
-    static CodeGeneratorRequest() {
-      object.ReferenceEquals(global::Google.ProtocolBuffers.Compiler.PluginProto.Plugin.Descriptor, null);
-    }
-  }
-
-  [global::System.Diagnostics.DebuggerNonUserCodeAttribute()]
-  public sealed partial class CodeGeneratorResponse : pb::GeneratedMessage<CodeGeneratorResponse, CodeGeneratorResponse.Builder> {
-    private CodeGeneratorResponse() { }
-    private static readonly CodeGeneratorResponse defaultInstance = new CodeGeneratorResponse().MakeReadOnly();
-    private static readonly string[] _codeGeneratorResponseFieldNames = new string[] { ""error"", ""file"" };
-    private static readonly uint[] _codeGeneratorResponseFieldTags = new uint[] { 10, 122 };
-    public static CodeGeneratorResponse DefaultInstance {
-      get { return defaultInstance; }
-    }
-
-    public override CodeGeneratorResponse DefaultInstanceForType {
-      get { return DefaultInstance; }
-    }
-
-    protected override CodeGeneratorResponse ThisMessage {
-      get { return this; }
-    }
-
-    public static pbd::MessageDescriptor Descriptor {
-      get { return global::Google.ProtocolBuffers.Compiler.PluginProto.Plugin.internal__static_google_protobuf_compiler_CodeGeneratorResponse__Descriptor; }
-    }
-
-    protected override pb::FieldAccess.FieldAccessorTable<CodeGeneratorResponse, CodeGeneratorResponse.Builder> InternalFieldAccessors {
-      get { return global::Google.ProtocolBuffers.Compiler.PluginProto.Plugin.internal__static_google_protobuf_compiler_CodeGeneratorResponse__FieldAccessorTable; }
-    }
-
-    #region Nested types
-    [global::System.Diagnostics.DebuggerNonUserCodeAttribute()]
-    public static partial class Types {
-      [global::System.Diagnostics.DebuggerNonUserCodeAttribute()]
-      public sealed partial class File : pb::GeneratedMessage<File, File.Builder> {
-        private File() { }
-        private static readonly File defaultInstance = new File().MakeReadOnly();
-        private static readonly string[] _fileFieldNames = new string[] { ""content"", ""insertion_point"", ""name"" };
-        private static readonly uint[] _fileFieldTags = new uint[] { 122, 18, 10 };
-        public static File DefaultInstance {
-          get { return defaultInstance; }
-        }
-
-        public override File DefaultInstanceForType {
-          get { return DefaultInstance; }
-        }
-
-        protected override File ThisMessage {
-          get { return this; }
-        }
-
-        public static pbd::MessageDescriptor Descriptor {
-          get { return global::Google.ProtocolBuffers.Compiler.PluginProto.Plugin.internal__static_google_protobuf_compiler_CodeGeneratorResponse_File__Descriptor; }
-        }
-
-        protected override pb::FieldAccess.FieldAccessorTable<File, File.Builder> InternalFieldAccessors {
-          get { return global::Google.ProtocolBuffers.Compiler.PluginProto.Plugin.internal__static_google_protobuf_compiler_CodeGeneratorResponse_File__FieldAccessorTable; }
-        }
-
-        public const int NameFieldNumber = 1;
-        private bool hasName;
-        private string name_ = """";
-        public bool HasName {
-          get { return hasName; }
-        }
-        public string Name {
-          get { return name_; }
-        }
-
-        public const int InsertionPointFieldNumber = 2;
-        private bool hasInsertionPoint;
-        private string insertionPoint_ = """";
-        public bool HasInsertionPoint {
-          get { return hasInsertionPoint; }
-        }
-        public string InsertionPoint {
-          get { return insertionPoint_; }
-        }
-
-        public const int ContentFieldNumber = 15;
-        private bool hasContent;
-        private string content_ = """";
-        public bool HasContent {
-          get { return hasContent; }
-        }
-        public string Content {
-          get { return content_; }
-        }
-
-        public override bool IsInitialized {
-          get {
-            return true;
-          }
-        }
-
-        public override void WriteTo(pb::ICodedOutputStream output) {
-          int size = SerializedSize;
-          string[] field_names = _fileFieldNames;
-          if (hasName) {
-            output.WriteString(1, field_names[2], Name);
-          }
-          if (hasInsertionPoint) {
-            output.WriteString(2, field_names[1], InsertionPoint);
-          }
-          if (hasContent) {
-            output.WriteString(15, field_names[0], Content);
-          }
-          UnknownFields.WriteTo(output);
-        }
-
-        private int memoizedSerializedSize = -1;
-        public override int SerializedSize {
-          get {
-            int size = memoizedSerializedSize;
-            if (size != -1) return size;
-
-            size = 0;
-            if (hasName) {
-              size += pb::CodedOutputStream.ComputeStringSize(1, Name);
-            }
-            if (hasInsertionPoint) {
-              size += pb::CodedOutputStream.ComputeStringSize(2, InsertionPoint);
-            }
-            if (hasContent) {
-              size += pb::CodedOutputStream.ComputeStringSize(15, Content);
-            }
-            size += UnknownFields.SerializedSize;
-            memoizedSerializedSize = size;
-            return size;
-          }
-        }
-
-        public static File ParseFrom(pb::ByteString data) {
-          return ((Builder) CreateBuilder().MergeFrom(data)).BuildParsed();
-        }
-        public static File ParseFrom(pb::ByteString data, pb::ExtensionRegistry extensionRegistry) {
-          return ((Builder) CreateBuilder().MergeFrom(data, extensionRegistry)).BuildParsed();
-        }
-        public static File ParseFrom(byte[] data) {
-          return ((Builder) CreateBuilder().MergeFrom(data)).BuildParsed();
-        }
-        public static File ParseFrom(byte[] data, pb::ExtensionRegistry extensionRegistry) {
-          return ((Builder) CreateBuilder().MergeFrom(data, extensionRegistry)).BuildParsed();
-        }
-        public static File ParseFrom(global::System.IO.Stream input) {
-          return ((Builder) CreateBuilder().MergeFrom(input)).BuildParsed();
-        }
-        public static File ParseFrom(global::System.IO.Stream input, pb::ExtensionRegistry extensionRegistry) {
-          return ((Builder) CreateBuilder().MergeFrom(input, extensionRegistry)).BuildParsed();
-        }
-        public static File ParseDelimitedFrom(global::System.IO.Stream input) {
-          return CreateBuilder().MergeDelimitedFrom(input).BuildParsed();
-        }
-        public static File ParseDelimitedFrom(global::System.IO.Stream input, pb::ExtensionRegistry extensionRegistry) {
-          return CreateBuilder().MergeDelimitedFrom(input, extensionRegistry).BuildParsed();
-        }
-        public static File ParseFrom(pb::ICodedInputStream input) {
-          return ((Builder) CreateBuilder().MergeFrom(input)).BuildParsed();
-        }
-        public static File ParseFrom(pb::ICodedInputStream input, pb::ExtensionRegistry extensionRegistry) {
-          return ((Builder) CreateBuilder().MergeFrom(input, extensionRegistry)).BuildParsed();
-        }
-        private File MakeReadOnly() {
-          return this;
-        }
-
-        public static Builder CreateBuilder() { return new Builder(); }
-        public override Builder ToBuilder() { return CreateBuilder(this); }
-        public override Builder CreateBuilderForType() { return new Builder(); }
-        public static Builder CreateBuilder(File prototype) {
-          return new Builder(prototype);
-        }
-
-        [global::System.Diagnostics.DebuggerNonUserCodeAttribute()]
-        public sealed partial class Builder : pb::GeneratedBuilder<File, Builder> {
-          protected override Builder ThisBuilder {
-            get { return this; }
-          }
-          public Builder() {
-            result = DefaultInstance;
-            resultIsReadOnly = true;
-          }
-          internal Builder(File cloneFrom) {
-            result = cloneFrom;
-            resultIsReadOnly = true;
-          }
-
-          private bool resultIsReadOnly;
-          private File result;
-
-          private File PrepareBuilder() {
-            if (resultIsReadOnly) {
-              File original = result;
-              result = new File();
-              resultIsReadOnly = false;
-              MergeFrom(original);
-            }
-            return result;
-          }
-
-          public override bool IsInitialized {
-            get { return result.IsInitialized; }
-          }
-
-          protected override File MessageBeingBuilt {
-            get { return PrepareBuilder(); }
-          }
-
-          public override Builder Clear() {
-            result = DefaultInstance;
-            resultIsReadOnly = true;
-            return this;
-          }
-
-          public override Builder Clone() {
-            if (resultIsReadOnly) {
-              return new Builder(result);
-            } else {
-              return new Builder().MergeFrom(result);
-            }
-          }
-
-          public override pbd::MessageDescriptor DescriptorForType {
-            get { return global::Google.ProtocolBuffers.Compiler.PluginProto.CodeGeneratorResponse.Types.File.Descriptor; }
-          }
-
-          public override File DefaultInstanceForType {
-            get { return global::Google.ProtocolBuffers.Compiler.PluginProto.CodeGeneratorResponse.Types.File.DefaultInstance; }
-          }
-
-          public override File BuildPartial() {
-            if (resultIsReadOnly) {
-              return result;
-            }
-            resultIsReadOnly = true;
-            return result.MakeReadOnly();
-          }
-
-          public override Builder MergeFrom(pb::IMessage other) {
-            if (other is File) {
-              return MergeFrom((File) other);
-            } else {
-              base.MergeFrom(other);
-              return this;
-            }
-          }
-
-          public override Builder MergeFrom(File other) {
-            if (other == global::Google.ProtocolBuffers.Compiler.PluginProto.CodeGeneratorResponse.Types.File.DefaultInstance) return this;
-            PrepareBuilder();
-            if (other.HasName) {
-              Name = other.Name;
-            }
-            if (other.HasInsertionPoint) {
-              InsertionPoint = other.InsertionPoint;
-            }
-            if (other.HasContent) {
-              Content = other.Content;
-            }
-            this.MergeUnknownFields(other.UnknownFields);
-            return this;
-          }
-
-          public override Builder MergeFrom(pb::ICodedInputStream input) {
-            return MergeFrom(input, pb::ExtensionRegistry.Empty);
-          }
-
-          public override Builder MergeFrom(pb::ICodedInputStream input, pb::ExtensionRegistry extensionRegistry) {
-            PrepareBuilder();
-            pb::UnknownFieldSet.Builder unknownFields = null;
-            uint tag;
-            string field_name;
-            while (input.ReadTag(out tag, out field_name)) {
-              if(tag == 0 && field_name != null) {
-                int field_ordinal = global::System.Array.BinarySearch(_fileFieldNames, field_name, global::System.StringComparer.Ordinal);
-                if(field_ordinal >= 0)
-                  tag = _fileFieldTags[field_ordinal];
-                else {
-                  if (unknownFields == null) {
-                    unknownFields = pb::UnknownFieldSet.CreateBuilder(this.UnknownFields);
-                  }
-                  ParseUnknownField(input, unknownFields, extensionRegistry, tag, field_name);
-                  continue;
-                }
-              }
-              switch (tag) {
-                case 0: {
-                  throw pb::InvalidProtocolBufferException.InvalidTag();
-                }
-                default: {
-                  if (pb::WireFormat.IsEndGroupTag(tag)) {
-                    if (unknownFields != null) {
-                      this.UnknownFields = unknownFields.Build();
-                    }
-                    return this;
-                  }
-                  if (unknownFields == null) {
-                    unknownFields = pb::UnknownFieldSet.CreateBuilder(this.UnknownFields);
-                  }
-                  ParseUnknownField(input, unknownFields, extensionRegistry, tag, field_name);
-                  break;
-                }
-                case 10: {
-                  result.hasName = input.ReadString(ref result.name_);
-                  break;
-                }
-                case 18: {
-                  result.hasInsertionPoint = input.ReadString(ref result.insertionPoint_);
-                  break;
-                }
-                case 122: {
-                  result.hasContent = input.ReadString(ref result.content_);
-                  break;
-                }
-              }
-            }
-
-            if (unknownFields != null) {
-              this.UnknownFields = unknownFields.Build();
-            }
-            return this;
-          }
-
-
-          public bool HasName {
-            get { return result.hasName; }
-          }
-          public string Name {
-            get { return result.Name; }
-            set { SetName(value); }
-          }
-          public Builder SetName(string value) {
-            pb::ThrowHelper.ThrowIfNull(value, ""value"");
-            PrepareBuilder();
-            result.hasName = true;
-            result.name_ = value;
-            return this;
-          }
-          public Builder ClearName() {
-            PrepareBuilder();
-            result.hasName = false;
-            result.name_ = """";
-            return this;
-          }
-
-          public bool HasInsertionPoint {
-            get { return result.hasInsertionPoint; }
-          }
-          public string InsertionPoint {
-            get { return result.InsertionPoint; }
-            set { SetInsertionPoint(value); }
-          }
-          public Builder SetInsertionPoint(string value) {
-            pb::ThrowHelper.ThrowIfNull(value, ""value"");
-            PrepareBuilder();
-            result.hasInsertionPoint = true;
-            result.insertionPoint_ = value;
-            return this;
-          }
-          public Builder ClearInsertionPoint() {
-            PrepareBuilder();
-            result.hasInsertionPoint = false;
-            result.insertionPoint_ = """";
-            return this;
-          }
-
-          public bool HasContent {
-            get { return result.hasContent; }
-          }
-          public string Content {
-            get { return result.Content; }
-            set { SetContent(value); }
-          }
-          public Builder SetContent(string value) {
-            pb::ThrowHelper.ThrowIfNull(value, ""value"");
-            PrepareBuilder();
-            result.hasContent = true;
-            result.content_ = value;
-            return this;
-          }
-          public Builder ClearContent() {
-            PrepareBuilder();
-            result.hasContent = false;
-            result.content_ = """";
-            return this;
-          }
-        }
-        static File() {
-          object.ReferenceEquals(global::Google.ProtocolBuffers.Compiler.PluginProto.Plugin.Descriptor, null);
-        }
-      }
-
-    }
-    #endregion
-
-    public const int ErrorFieldNumber = 1;
-    private bool hasError;
-    private string error_ = """";
-    public bool HasError {
-      get { return hasError; }
-    }
-    public string Error {
-      get { return error_; }
-    }
-
-    public const int FileFieldNumber = 15;
-    private pbc::PopsicleList<global::Google.ProtocolBuffers.Compiler.PluginProto.CodeGeneratorResponse.Types.File> file_ = new pbc::PopsicleList<global::Google.ProtocolBuffers.Compiler.PluginProto.CodeGeneratorResponse.Types.File>();
-    public scg::IList<global::Google.ProtocolBuffers.Compiler.PluginProto.CodeGeneratorResponse.Types.File> FileList {
-      get { return file_; }
-    }
-    public int FileCount {
-      get { return file_.Count; }
-    }
-    public global::Google.ProtocolBuffers.Compiler.PluginProto.CodeGeneratorResponse.Types.File GetFile(int index) {
-      return file_[index];
-    }
-
-    public override bool IsInitialized {
-      get {
-        return true;
-      }
-    }
-
-    public override void WriteTo(pb::ICodedOutputStream output) {
-      int size = SerializedSize;
-      string[] field_names = _codeGeneratorResponseFieldNames;
-      if (hasError) {
-        output.WriteString(1, field_names[0], Error);
-      }
-      if (file_.Count > 0) {
-        output.WriteMessageArray(15, field_names[1], file_);
-      }
-      UnknownFields.WriteTo(output);
-    }
-
-    private int memoizedSerializedSize = -1;
-    public override int SerializedSize {
-      get {
-        int size = memoizedSerializedSize;
-        if (size != -1) return size;
-
-        size = 0;
-        if (hasError) {
-          size += pb::CodedOutputStream.ComputeStringSize(1, Error);
-        }
-        foreach (global::Google.ProtocolBuffers.Compiler.PluginProto.CodeGeneratorResponse.Types.File element in FileList) {
-          size += pb::CodedOutputStream.ComputeMessageSize(15, element);
-        }
-        size += UnknownFields.SerializedSize;
-        memoizedSerializedSize = size;
-        return size;
-      }
-    }
-
-    public static CodeGeneratorResponse ParseFrom(pb::ByteString data) {
-      return ((Builder) CreateBuilder().MergeFrom(data)).BuildParsed();
-    }
-    public static CodeGeneratorResponse ParseFrom(pb::ByteString data, pb::ExtensionRegistry extensionRegistry) {
-      return ((Builder) CreateBuilder().MergeFrom(data, extensionRegistry)).BuildParsed();
-    }
-    public static CodeGeneratorResponse ParseFrom(byte[] data) {
-      return ((Builder) CreateBuilder().MergeFrom(data)).BuildParsed();
-    }
-    public static CodeGeneratorResponse ParseFrom(byte[] data, pb::ExtensionRegistry extensionRegistry) {
-      return ((Builder) CreateBuilder().MergeFrom(data, extensionRegistry)).BuildParsed();
-    }
-    public static CodeGeneratorResponse ParseFrom(global::System.IO.Stream input) {
-      return ((Builder) CreateBuilder().MergeFrom(input)).BuildParsed();
-    }
-    public static CodeGeneratorResponse ParseFrom(global::System.IO.Stream input, pb::ExtensionRegistry extensionRegistry) {
-      return ((Builder) CreateBuilder().MergeFrom(input, extensionRegistry)).BuildParsed();
-    }
-    public static CodeGeneratorResponse ParseDelimitedFrom(global::System.IO.Stream input) {
-      return CreateBuilder().MergeDelimitedFrom(input).BuildParsed();
-    }
-    public static CodeGeneratorResponse ParseDelimitedFrom(global::System.IO.Stream input, pb::ExtensionRegistry extensionRegistry) {
-      return CreateBuilder().MergeDelimitedFrom(input, extensionRegistry).BuildParsed();
-    }
-    public static CodeGeneratorResponse ParseFrom(pb::ICodedInputStream input) {
-      return ((Builder) CreateBuilder().MergeFrom(input)).BuildParsed();
-    }
-    public static CodeGeneratorResponse ParseFrom(pb::ICodedInputStream input, pb::ExtensionRegistry extensionRegistry) {
-      return ((Builder) CreateBuilder().MergeFrom(input, extensionRegistry)).BuildParsed();
-    }
-    private CodeGeneratorResponse MakeReadOnly() {
-      file_.MakeReadOnly();
-      return this;
-    }
-
-    public static Builder CreateBuilder() { return new Builder(); }
-    public override Builder ToBuilder() { return CreateBuilder(this); }
-    public override Builder CreateBuilderForType() { return new Builder(); }
-    public static Builder CreateBuilder(CodeGeneratorResponse prototype) {
-      return new Builder(prototype);
-    }
-
-    [global::System.Diagnostics.DebuggerNonUserCodeAttribute()]
-    public sealed partial class Builder : pb::GeneratedBuilder<CodeGeneratorResponse, Builder> {
-      protected override Builder ThisBuilder {
-        get { return this; }
-      }
-      public Builder() {
-        result = DefaultInstance;
-        resultIsReadOnly = true;
-      }
-      internal Builder(CodeGeneratorResponse cloneFrom) {
-        result = cloneFrom;
-        resultIsReadOnly = true;
-      }
-
-      private bool resultIsReadOnly;
-      private CodeGeneratorResponse result;
-
-      private CodeGeneratorResponse PrepareBuilder() {
-        if (resultIsReadOnly) {
-          CodeGeneratorResponse original = result;
-          result = new CodeGeneratorResponse();
-          resultIsReadOnly = false;
-          MergeFrom(original);
-        }
-        return result;
-      }
-
-      public override bool IsInitialized {
-        get { return result.IsInitialized; }
-      }
-
-      protected override CodeGeneratorResponse MessageBeingBuilt {
-        get { return PrepareBuilder(); }
-      }
-
-      public override Builder Clear() {
-        result = DefaultInstance;
-        resultIsReadOnly = true;
-        return this;
-      }
-
-      public override Builder Clone() {
-        if (resultIsReadOnly) {
-          return new Builder(result);
-        } else {
-          return new Builder().MergeFrom(result);
-        }
-      }
-
-      public override pbd::MessageDescriptor DescriptorForType {
-        get { return global::Google.ProtocolBuffers.Compiler.PluginProto.CodeGeneratorResponse.Descriptor; }
-      }
-
-      public override CodeGeneratorResponse DefaultInstanceForType {
-        get { return global::Google.ProtocolBuffers.Compiler.PluginProto.CodeGeneratorResponse.DefaultInstance; }
-      }
-
-      public override CodeGeneratorResponse BuildPartial() {
-        if (resultIsReadOnly) {
-          return result;
-        }
-        resultIsReadOnly = true;
-        return result.MakeReadOnly();
-      }
-
-      public override Builder MergeFrom(pb::IMessage other) {
-        if (other is CodeGeneratorResponse) {
-          return MergeFrom((CodeGeneratorResponse) other);
-        } else {
-          base.MergeFrom(other);
-          return this;
-        }
-      }
-
-      public override Builder MergeFrom(CodeGeneratorResponse other) {
-        if (other == global::Google.ProtocolBuffers.Compiler.PluginProto.CodeGeneratorResponse.DefaultInstance) return this;
-        PrepareBuilder();
-        if (other.HasError) {
-          Error = other.Error;
-        }
-        if (other.file_.Count != 0) {
-          result.file_.Add(other.file_);
-        }
-        this.MergeUnknownFields(other.UnknownFields);
-        return this;
-      }
-
-      public override Builder MergeFrom(pb::ICodedInputStream input) {
-        return MergeFrom(input, pb::ExtensionRegistry.Empty);
-      }
-
-      public override Builder MergeFrom(pb::ICodedInputStream input, pb::ExtensionRegistry extensionRegistry) {
-        PrepareBuilder();
-        pb::UnknownFieldSet.Builder unknownFields = null;
-        uint tag;
-        string field_name;
-        while (input.ReadTag(out tag, out field_name)) {
-          if(tag == 0 && field_name != null) {
-            int field_ordinal = global::System.Array.BinarySearch(_codeGeneratorResponseFieldNames, field_name, global::System.StringComparer.Ordinal);
-            if(field_ordinal >= 0)
-              tag = _codeGeneratorResponseFieldTags[field_ordinal];
-            else {
-              if (unknownFields == null) {
-                unknownFields = pb::UnknownFieldSet.CreateBuilder(this.UnknownFields);
-              }
-              ParseUnknownField(input, unknownFields, extensionRegistry, tag, field_name);
-              continue;
-            }
-          }
-          switch (tag) {
-            case 0: {
-              throw pb::InvalidProtocolBufferException.InvalidTag();
-            }
-            default: {
-              if (pb::WireFormat.IsEndGroupTag(tag)) {
-                if (unknownFields != null) {
-                  this.UnknownFields = unknownFields.Build();
-                }
-                return this;
-              }
-              if (unknownFields == null) {
-                unknownFields = pb::UnknownFieldSet.CreateBuilder(this.UnknownFields);
-              }
-              ParseUnknownField(input, unknownFields, extensionRegistry, tag, field_name);
-              break;
-            }
-            case 10: {
-              result.hasError = input.ReadString(ref result.error_);
-              break;
-            }
-            case 122: {
-              input.ReadMessageArray(tag, field_name, result.file_, global::Google.ProtocolBuffers.Compiler.PluginProto.CodeGeneratorResponse.Types.File.DefaultInstance, extensionRegistry);
-              break;
-            }
-          }
-        }
-
-        if (unknownFields != null) {
-          this.UnknownFields = unknownFields.Build();
-        }
-        return this;
-      }
-
-
-      public bool HasError {
-        get { return result.hasError; }
-      }
-      public string Error {
-        get { return result.Error; }
-        set { SetError(value); }
-      }
-      public Builder SetError(string value) {
-        pb::ThrowHelper.ThrowIfNull(value, ""value"");
-        PrepareBuilder();
-        result.hasError = true;
-        result.error_ = value;
-        return this;
-      }
-      public Builder ClearError() {
-        PrepareBuilder();
-        result.hasError = false;
-        result.error_ = """";
-        return this;
-      }
-
-      public pbc::IPopsicleList<global::Google.ProtocolBuffers.Compiler.PluginProto.CodeGeneratorResponse.Types.File> FileList {
-        get { return PrepareBuilder().file_; }
-      }
-      public int FileCount {
-        get { return result.FileCount; }
-      }
-      public global::Google.ProtocolBuffers.Compiler.PluginProto.CodeGeneratorResponse.Types.File GetFile(int index) {
-        return result.GetFile(index);
-      }
-      public Builder SetFile(int index, global::Google.ProtocolBuffers.Compiler.PluginProto.CodeGeneratorResponse.Types.File value) {
-        pb::ThrowHelper.ThrowIfNull(value, ""value"");
-        PrepareBuilder();
-        result.file_[index] = value;
-        return this;
-      }
-      public Builder SetFile(int index, global::Google.ProtocolBuffers.Compiler.PluginProto.CodeGeneratorResponse.Types.File.Builder builderForValue) {
-        pb::ThrowHelper.ThrowIfNull(builderForValue, ""builderForValue"");
-        PrepareBuilder();
-        result.file_[index] = builderForValue.Build();
-        return this;
-      }
-      public Builder AddFile(global::Google.ProtocolBuffers.Compiler.PluginProto.CodeGeneratorResponse.Types.File value) {
-        pb::ThrowHelper.ThrowIfNull(value, ""value"");
-        PrepareBuilder();
-        result.file_.Add(value);
-        return this;
-      }
-      public Builder AddFile(global::Google.ProtocolBuffers.Compiler.PluginProto.CodeGeneratorResponse.Types.File.Builder builderForValue) {
-        pb::ThrowHelper.ThrowIfNull(builderForValue, ""builderForValue"");
-        PrepareBuilder();
-        result.file_.Add(builderForValue.Build());
-        return this;
-      }
-      public Builder AddRangeFile(scg::IEnumerable<global::Google.ProtocolBuffers.Compiler.PluginProto.CodeGeneratorResponse.Types.File> values) {
-        PrepareBuilder();
-        result.file_.Add(values);
-        return this;
-      }
-      public Builder ClearFile() {
-        PrepareBuilder();
-        result.file_.Clear();
-        return this;
-      }
-    }
-    static CodeGeneratorResponse() {
-      object.ReferenceEquals(global::Google.ProtocolBuffers.Compiler.PluginProto.Plugin.Descriptor, null);
-    }
-  }
-
-  #endregion
-
-}
-
-#endregion Designer generated code
diff --git a/csharp/src/ProtoGen/PrimitiveFieldGenerator.cs b/csharp/src/ProtoGen/PrimitiveFieldGenerator.cs
deleted file mode 100644
index 69e0d4d93..000000000
--- a/csharp/src/ProtoGen/PrimitiveFieldGenerator.cs
+++ /dev/null
@@ -1,140 +0,0 @@
-#region Copyright notice and license
-
-// Protocol Buffers - Google's data interchange format
-// Copyright 2008 Google Inc.  All rights reserved.
-// http://github.com/jskeet/dotnet-protobufs/
-// Original C++/Java/Python code:
-// http://code.google.com/p/protobuf/
-//
-// Redistribution and use in source and binary forms, with or without
-// modification, are permitted provided that the following conditions are
-// met:
-//
-//     * Redistributions of source code must retain the above copyright
-// notice, this list of conditions and the following disclaimer.
-//     * Redistributions in binary form must reproduce the above
-// copyright notice, this list of conditions and the following disclaimer
-// in the documentation and/or other materials provided with the
-// distribution.
-//     * Neither the name of Google Inc. nor the names of its
-// contributors may be used to endorse or promote products derived from
-// this software without specific prior written permission.
-//
-// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-// ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
-#endregion
-
-using Google.ProtocolBuffers.Descriptors;
-
-namespace Google.ProtocolBuffers.ProtoGen
-{
-    // TODO(jonskeet): Refactor this. There's loads of common code here.
-    internal class PrimitiveFieldGenerator : FieldGeneratorBase, IFieldSourceGenerator
-    {
-        internal PrimitiveFieldGenerator(FieldDescriptor descriptor, int fieldOrdinal)
-            : base(descriptor, fieldOrdinal)
-        {
-        }
-
-        public void GenerateMembers(TextGenerator writer)
-        {
-            writer.WriteLine(""private bool has{0};"", PropertyName);
-            writer.WriteLine(""private {0} {1}_{2};"", TypeName, Name, HasDefaultValue ? "" = "" + DefaultValue : """");
-            AddDeprecatedFlag(writer);
-            writer.WriteLine(""public bool Has{0} {{"", PropertyName);
-            writer.WriteLine(""  get {{ return has{0}; }}"", PropertyName);
-            writer.WriteLine(""}"");
-            AddPublicMemberAttributes(writer);
-            writer.WriteLine(""public {0} {1} {{"", TypeName, PropertyName);
-            writer.WriteLine(""  get {{ return {0}_; }}"", Name);
-            writer.WriteLine(""}"");
-        }
-
-        public void GenerateBuilderMembers(TextGenerator writer)
-        {
-            AddDeprecatedFlag(writer);
-            writer.WriteLine(""public bool Has{0} {{"", PropertyName);
-            writer.WriteLine(""  get {{ return result.has{0}; }}"", PropertyName);
-            writer.WriteLine(""}"");
-            AddPublicMemberAttributes(writer);
-            writer.WriteLine(""public {0} {1} {{"", TypeName, PropertyName);
-            writer.WriteLine(""  get {{ return result.{0}; }}"", PropertyName);
-            writer.WriteLine(""  set {{ Set{0}(value); }}"", PropertyName);
-            writer.WriteLine(""}"");
-            AddPublicMemberAttributes(writer);
-            writer.WriteLine(""public Builder Set{0}({1} value) {{"", PropertyName, TypeName);
-            AddNullCheck(writer);
-            writer.WriteLine(""  PrepareBuilder();"");
-            writer.WriteLine(""  result.has{0} = true;"", PropertyName);
-            writer.WriteLine(""  result.{0}_ = value;"", Name);
-            writer.WriteLine(""  return this;"");
-            writer.WriteLine(""}"");
-            AddDeprecatedFlag(writer);
-            writer.WriteLine(""public Builder Clear{0}() {{"", PropertyName);
-            writer.WriteLine(""  PrepareBuilder();"");
-            writer.WriteLine(""  result.has{0} = false;"", PropertyName);
-            writer.WriteLine(""  result.{0}_ = {1};"", Name, DefaultValue);
-            writer.WriteLine(""  return this;"");
-            writer.WriteLine(""}"");
-        }
-
-        public void GenerateMergingCode(TextGenerator writer)
-        {
-            writer.WriteLine(""if (other.Has{0}) {{"", PropertyName);
-            writer.WriteLine(""  {0} = other.{0};"", PropertyName);
-            writer.WriteLine(""}"");
-        }
-
-        public void GenerateBuildingCode(TextGenerator writer)
-        {
-            // Nothing to do here for primitive types
-        }
-
-        public void GenerateParsingCode(TextGenerator writer)
-        {
-            writer.WriteLine(""result.has{0} = input.Read{1}(ref result.{2}_);"", PropertyName, CapitalizedTypeName, Name);
-        }
-
-        public void GenerateSerializationCode(TextGenerator writer)
-        {
-            writer.WriteLine(""if (has{0}) {{"", PropertyName);
-            writer.WriteLine(""  output.Write{0}({1}, field_names[{3}], {2});"", CapitalizedTypeName, Number, PropertyName,
-                             FieldOrdinal);
-            writer.WriteLine(""}"");
-        }
-
-        public void GenerateSerializedSizeCode(TextGenerator writer)
-        {
-            writer.WriteLine(""if (has{0}) {{"", PropertyName);
-            writer.WriteLine(""  size += pb::CodedOutputStream.Compute{0}Size({1}, {2});"",
-                             CapitalizedTypeName, Number, PropertyName);
-            writer.WriteLine(""}"");
-        }
-
-        public override void WriteHash(TextGenerator writer)
-        {
-            writer.WriteLine(""if (has{0}) hash ^= {1}_.GetHashCode();"", PropertyName, Name);
-        }
-
-        public override void WriteEquals(TextGenerator writer)
-        {
-            writer.WriteLine(""if (has{0} != other.has{0} || (has{0} && !{1}_.Equals(other.{1}_))) return false;"",
-                             PropertyName, Name);
-        }
-
-        public override void WriteToString(TextGenerator writer)
-        {
-            writer.WriteLine(""PrintField(\""{0}\"", has{1}, {2}_, writer);"", Descriptor.Name, PropertyName, Name);
-        }
-    }
-}
\ No newline at end of file
diff --git a/csharp/src/ProtoGen/Program.cs b/csharp/src/ProtoGen/Program.cs
deleted file mode 100644
index b11d32e06..000000000
--- a/csharp/src/ProtoGen/Program.cs
+++ /dev/null
@@ -1,105 +0,0 @@
-#region Copyright notice and license
-
-// Protocol Buffers - Google's data interchange format
-// Copyright 2008 Google Inc.  All rights reserved.
-// http://github.com/jskeet/dotnet-protobufs/
-// Original C++/Java/Python code:
-// http://code.google.com/p/protobuf/
-//
-// Redistribution and use in source and binary forms, with or without
-// modification, are permitted provided that the following conditions are
-// met:
-//
-//     * Redistributions of source code must retain the above copyright
-// notice, this list of conditions and the following disclaimer.
-//     * Redistributions in binary form must reproduce the above
-// copyright notice, this list of conditions and the following disclaimer
-// in the documentation and/or other materials provided with the
-// distribution.
-//     * Neither the name of Google Inc. nor the names of its
-// contributors may be used to endorse or promote products derived from
-// this software without specific prior written permission.
-//
-// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-// ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
-#endregion
-
-using System;
-using System.IO;
-using System.Collections.Generic;
-using Google.ProtocolBuffers.Compiler.PluginProto;
-using Google.ProtocolBuffers.DescriptorProtos;
-
-namespace Google.ProtocolBuffers.ProtoGen
-{
-    /// <summary>
-    /// Entry point for the Protocol Buffers generator.
-    /// </summary>
-    internal class Program
-    {
-        internal static int Main(string[] args)
-        {
-            try
-            {
-                // Hack to make sure everything's initialized
-                DescriptorProtoFile.Descriptor.ToString();
-                GeneratorOptions options = new GeneratorOptions {Arguments = args};
-
-                IList<string> validationFailures;
-                if (!options.TryValidate(out validationFailures))
-                {
-                    // We've already got the message-building logic in the exception...
-                    InvalidOptionsException exception = new InvalidOptionsException(validationFailures);
-                    Console.WriteLine(exception.Message);
-                    return 1;
-                }
-
-                var request = new CodeGeneratorRequest.Builder();
-                foreach (string inputFile in options.InputFiles)
-                {
-                    ExtensionRegistry extensionRegistry = ExtensionRegistry.CreateInstance();
-                    CSharpOptions.RegisterAllExtensions(extensionRegistry);
-                    using (Stream inputStream = File.OpenRead(inputFile))
-                    {
-                        var fileSet = FileDescriptorSet.ParseFrom(inputStream, extensionRegistry);
-                        foreach (var fileProto in fileSet.FileList)
-                        {
-                            request.AddFileToGenerate(fileProto.Name);
-                            request.AddProtoFile(fileProto);
-                        }
-                    }
-                }
-
-                Generator generator = Generator.CreateGenerator(options);
-                var response = new CodeGeneratorResponse.Builder();
-                generator.Generate(request.Build(), response);
-                if (response.HasError)
-                {
-                    throw new Exception(response.Error);
-                }
-                foreach (var file in response.FileList)
-                {
-                    File.WriteAllText(file.Name, file.Content);
-                }
-                return 0;
-            }
-            catch (Exception e)
-            {
-                Console.Error.WriteLine(""Error: {0}"", e.Message);
-                Console.Error.WriteLine();
-                Console.Error.WriteLine(""Detailed exception information: {0}"", e);
-                return 1;
-            }
-        }
-    }
-}
\ No newline at end of file
diff --git a/csharp/src/ProtoGen/ProgramPreprocess.cs b/csharp/src/ProtoGen/ProgramPreprocess.cs
deleted file mode 100644
index 343e1f2a2..000000000
--- a/csharp/src/ProtoGen/ProgramPreprocess.cs
+++ /dev/null
@@ -1,276 +0,0 @@
-using System;
-using System.Collections.Generic;
-using System.Diagnostics;
-using System.IO;
-using System.Text;
-using System.Text.RegularExpressions;
-
-namespace Google.ProtocolBuffers.ProtoGen
-{
-    /// <summary>
-    /// Preprocesses any input files with an extension of '.proto' by running protoc.exe.  If arguments
-    /// are supplied with '--' prefix they are provided to protoc.exe, otherwise they are assumed to
-    /// be used for ProtoGen.exe which is run on the resulting output proto buffer.  If the option
-    /// --descriptor_set_out= is specified the proto buffer file is kept, otherwise it will be removed
-    /// after code generation.
-    /// </summary>
-    public class ProgramPreprocess
-    {
-        private const string ProtocExecutable = ""protoc.exe"";
-        private const string ProtocDirectoryArg = ""--protoc_dir="";
-
-        private static int Main(string[] args)
-        {
-            try
-            {
-                return Environment.ExitCode = Run(args);
-            }
-            catch (Exception ex)
-            {
-                Console.Error.WriteLine(ex);
-                return Environment.ExitCode = 2;
-            }
-        }
-
-        public static int Run(params string[] args)
-        {
-            bool deleteFile = false;
-            string tempFile = null;
-            int result;
-            bool doHelp = args.Length == 0;
-            try
-            {
-                List<string> protocArgs = new List<string>();
-                List<string> protoGenArgs = new List<string>();
-
-                string protocFile = GuessProtocFile(args);
-
-                foreach (string arg in args)
-                {
-                    doHelp |= StringComparer.OrdinalIgnoreCase.Equals(arg, ""/?"");
-                    doHelp |= StringComparer.OrdinalIgnoreCase.Equals(arg, ""/help"");
-                    doHelp |= StringComparer.OrdinalIgnoreCase.Equals(arg, ""-?"");
-                    doHelp |= StringComparer.OrdinalIgnoreCase.Equals(arg, ""-help"");
-
-                    if (arg.StartsWith(""--descriptor_set_out=""))
-                    {
-                        tempFile = arg.Substring(""--descriptor_set_out="".Length);
-                        protoGenArgs.Add(tempFile);
-                    }
-                }
-
-                if (doHelp)
-                {
-                    Console.WriteLine();
-                    Console.WriteLine(""PROTOC.exe: Use any of the following options that begin with '--':"");
-                    Console.WriteLine();
-                    try
-                    {
-                        RunProtoc(protocFile, ""--help"");
-                    }
-                    catch (Exception ex)
-                    {
-                        Console.Error.WriteLine(ex.Message);
-                    }
-                    Console.WriteLine();
-                    Console.WriteLine();
-                    Console.WriteLine(
-                        ""PROTOGEN.exe: The following options are used to specify defaults for code generation."");
-                    Console.WriteLine();
-                    Program.Main(new string[0]);
-                    Console.WriteLine();
-                    Console.WriteLine(""The following option enables PROTOGEN.exe to find PROTOC.exe"");
-                    Console.WriteLine(""{0}<directory containing protoc.exe>"", ProtocDirectoryArg);
-                    return 0;
-                }
-
-                string pathRoot = Environment.CurrentDirectory;
-                foreach(string arg in args)
-                {
-                    if (arg.StartsWith(""--proto_path="", StringComparison.InvariantCultureIgnoreCase))
-                    {
-                        pathRoot = arg.Substring(13);
-                    }
-                }
-
-                foreach (string arg in args)
-                {
-                    if (arg.StartsWith(ProtocDirectoryArg))
-                    {
-                        // Handled earlier
-                        continue;
-                    }
-                    if (arg.StartsWith(""--""))
-                    {
-                        protocArgs.Add(arg);
-                    }
-                    else if ((File.Exists(arg) || File.Exists(Path.Combine(pathRoot, arg))) &&
-                             StringComparer.OrdinalIgnoreCase.Equals("".proto"", Path.GetExtension(arg)))
-                    {
-                        if (tempFile == null)
-                        {
-                            deleteFile = true;
-                            tempFile = Path.GetTempFileName();
-                            protocArgs.Add(String.Format(""--descriptor_set_out={0}"", tempFile));
-                            protoGenArgs.Add(tempFile);
-                        }
-                        string patharg = arg;
-                        if (!File.Exists(patharg))
-                        {
-                            patharg = Path.Combine(pathRoot, arg);
-                        }
-
-                        protocArgs.Add(patharg);
-                    }
-                    else
-                    {
-                        protoGenArgs.Add(arg);
-                    }
-                }
-
-                if (tempFile != null)
-                {
-                    result = RunProtoc(protocFile, protocArgs.ToArray());
-                    if (result != 0)
-                    {
-                        return result;
-                    }
-                }
-
-                result = Program.Main(protoGenArgs.ToArray());
-            }
-            finally
-            {
-                if (deleteFile && tempFile != null && File.Exists(tempFile))
-                {
-                    File.Delete(tempFile);
-                }
-            }
-            return result;
-        }
-
-        /// <summary>
-        /// Tries to work out where protoc is based on command line arguments, the current
-        /// directory, the directory containing protogen, and the path.
-        /// </summary>
-        /// <returns>The path to protoc.exe, or null if it can't be found.</returns>
-        private static string GuessProtocFile(params string[] args)
-        {
-            // Why oh why is this not in System.IO.Path or Environment...?
-            List<string> searchPath = new List<string>();
-            foreach (string arg in args)
-            {
-                if (arg.StartsWith(""--protoc_dir=""))
-                {
-                    searchPath.Add(arg.Substring(ProtocDirectoryArg.Length));
-                }
-            }
-            searchPath.Add(Environment.CurrentDirectory);
-            searchPath.Add(AppDomain.CurrentDomain.BaseDirectory);
-            searchPath.AddRange((Environment.GetEnvironmentVariable(""PATH"") ?? String.Empty).Split(Path.PathSeparator));
-
-            foreach (string path in searchPath)
-            {
-                string exeFile = Path.Combine(path, ProtocExecutable);
-                if (File.Exists(exeFile))
-                {
-                    return exeFile;
-                }
-            }
-            return null;
-        }
-
-        private static int RunProtoc(string exeFile, params string[] args)
-        {
-            if (exeFile == null)
-            {
-                throw new FileNotFoundException(
-                    ""Unable to locate "" + ProtocExecutable +
-                    "" make sure it is in the PATH, cwd, or exe dir, or use --protoc_dir=..."");
-            }
-
-            ProcessStartInfo psi = new ProcessStartInfo(exeFile);
-            psi.Arguments = EscapeArguments(args);
-            psi.RedirectStandardError = true;
-            psi.RedirectStandardInput = false;
-            psi.RedirectStandardOutput = true;
-            psi.ErrorDialog = false;
-            psi.CreateNoWindow = true;
-            psi.UseShellExecute = false;
-            psi.WorkingDirectory = Environment.CurrentDirectory;
-
-            Process process = Process.Start(psi);
-            if (process == null)
-            {
-                return 1;
-            }
-
-            process.WaitForExit();
-
-            string tmp = process.StandardOutput.ReadToEnd();
-            if (tmp.Trim().Length > 0)
-            {
-                Console.Out.WriteLine(tmp);
-            }
-            tmp = process.StandardError.ReadToEnd();
-            if (tmp.Trim().Length > 0)
-            {
-                // Replace protoc output with something more amenable to Visual Studio.
-                var regexMsvs = new Regex(@""(.*)\((\d+)\).* column=(\d+)\s*:\s*(.*)"");
-                tmp = regexMsvs.Replace(tmp, ""$1($2,$3): error CS9999: $4"");
-                var regexGcc = new Regex(@""(.*):(\d+):(\d+):\s*(.*)"");
-                tmp = regexGcc.Replace(tmp, ""$1($2,$3): error CS9999: $4"");
-                Console.Error.WriteLine(tmp);
-            }
-            return process.ExitCode;
-        }
-
-        /// <summary>
-        /// Quotes all arguments that contain whitespace, or begin with a quote and returns a single
-        /// argument string for use with Process.Start().
-        /// </summary>
-        /// <remarks>http://csharptest.net/?p=529</remarks>
-        /// <param name=""args"">A list of strings for arguments, may not contain null, '\0', '\r', or '\n'</param>
-        /// <returns>The combined list of escaped/quoted strings</returns>
-        /// <exception cref=""System.ArgumentNullException"">Raised when one of the arguments is null</exception>
-        /// <exception cref=""System.ArgumentOutOfRangeException"">Raised if an argument contains '\0', '\r', or '\n'</exception>
-        public static string EscapeArguments(params string[] args)
-        {
-            StringBuilder arguments = new StringBuilder();
-            Regex invalidChar = new Regex(""[\x00\x0a\x0d]"");//  these can not be escaped
-            Regex needsQuotes = new Regex(@""\s|"""""");//          contains whitespace or two quote characters
-            Regex escapeQuote = new Regex(@""(\\*)(""""|$)"");//    one or more '\' followed with a quote or end of string
-            for (int carg = 0; args != null && carg < args.Length; carg++)
-            {
-                if (args[carg] == null)
-                {
-                    throw new ArgumentNullException(""args["" + carg + ""]"");
-                }
-                if (invalidChar.IsMatch(args[carg]))
-                {
-                    throw new ArgumentOutOfRangeException(""args["" + carg + ""]"");
-                }
-                if (args[carg] == String.Empty)
-                {
-                    arguments.Append(""\""\"""");
-                }
-                else if (!needsQuotes.IsMatch(args[carg])) { arguments.Append(args[carg]); }
-                else
-                {
-                    arguments.Append('""');
-                    arguments.Append(escapeQuote.Replace(args[carg],
-                                                         m =>
-                                                         m.Groups[1].Value + m.Groups[1].Value +
-                                                         (m.Groups[2].Value == ""\"""" ? ""\\\"""" : """")
-                                         ));
-                    arguments.Append('""');
-                }
-                if (carg + 1 < args.Length)
-                {
-                    arguments.Append(' ');
-                }
-            }
-            return arguments.ToString();
-        }
-    }
-}
\ No newline at end of file
diff --git a/csharp/src/ProtoGen/Properties/AssemblyInfo.cs b/csharp/src/ProtoGen/Properties/AssemblyInfo.cs
deleted file mode 100644
index 565894f23..000000000
--- a/csharp/src/ProtoGen/Properties/AssemblyInfo.cs
+++ /dev/null
@@ -1,29 +0,0 @@
-using System.Reflection;
-using System.Runtime.InteropServices;
-
-// General Information about an assembly is controlled through the following 
-// set of attributes. Change these attribute values to modify the information
-// associated with an assembly.
-
-[assembly: AssemblyTitle(""ProtoGen"")]
-[assembly: AssemblyDescription("""")]
-[assembly: AssemblyConfiguration("""")]
-[assembly: AssemblyCompany("""")]
-[assembly: AssemblyProduct(""ProtoGen"")]
-[assembly: AssemblyCopyright(""Copyright   2008"")]
-[assembly: AssemblyTrademark("""")]
-[assembly: AssemblyCulture("""")]
-
-// Version information for an assembly consists of the following four values:
-//
-//      Major Version
-//      Minor Version 
-//      Build Number
-//      Revision
-//
-// You can specify all the values or you can default the Build and Revision Numbers 
-// by using the '*' as shown below:
-// [assembly: AssemblyVersion(""2.4.1.555"")]
-
-[assembly: AssemblyVersion(""2.4.1.555"")]
-[assembly: AssemblyFileVersion(""2.4.1.555"")]
\ No newline at end of file
diff --git a/csharp/src/ProtoGen/ProtoGen.csproj b/csharp/src/ProtoGen/ProtoGen.csproj
deleted file mode 100644
index 2de44aeca..000000000
--- a/csharp/src/ProtoGen/ProtoGen.csproj
+++ /dev/null
@@ -1,98 +0,0 @@
-<?xml version=""1.0"" encoding=""utf-8""?>
-<Project ToolsVersion=""4.0"" DefaultTargets=""Build"" xmlns=""http://schemas.microsoft.com/developer/msbuild/2003"">
-  <PropertyGroup>
-    <EnvironmentFlavor>CLIENTPROFILE</EnvironmentFlavor>
-    <EnvironmentTemplate>NET35</EnvironmentTemplate>
-    <Configuration Condition="" '$(Configuration)' == '' "">Debug</Configuration>
-    <Platform Condition="" '$(Platform)' == '' "">AnyCPU</Platform>
-    <ProductVersion>9.0.30729</ProductVersion>
-    <SchemaVersion>2.0</SchemaVersion>
-    <ProjectGuid>{250ADE34-82FD-4BAE-86D5-985FBE589C4A}</ProjectGuid>
-    <OutputType>Exe</OutputType>
-    <AppDesignerFolder>Properties</AppDesignerFolder>
-    <RootNamespace>Google.ProtocolBuffers.ProtoGen</RootNamespace>
-    <AssemblyName>ProtoGen</AssemblyName>
-    <TargetFrameworkVersion>v3.5</TargetFrameworkVersion>
-    <FileAlignment>512</FileAlignment>
-    <SignAssembly>true</SignAssembly>
-    <AssemblyOriginatorKeyFile>..\..\keys\Google.ProtocolBuffers.snk</AssemblyOriginatorKeyFile>
-    <StartupObject>Google.ProtocolBuffers.ProtoGen.ProgramPreprocess</StartupObject>
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Debug|AnyCPU' "">
-    <DebugSymbols>true</DebugSymbols>
-    <DebugType>full</DebugType>
-    <Optimize>false</Optimize>
-    <OutputPath>bin\NET35\Debug</OutputPath>
-    <IntermediateOutputPath>obj\NET35\Debug\</IntermediateOutputPath>
-    <DefineConstants>DEBUG;TRACE</DefineConstants>
-    <ErrorReport>prompt</ErrorReport>
-    <WarningLevel>4</WarningLevel>
-    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
-    <NoStdLib>true</NoStdLib>
-    <GenerateSerializationAssemblies>Off</GenerateSerializationAssemblies>
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Release|AnyCPU' "">
-    <DebugType>pdbonly</DebugType>
-    <Optimize>true</Optimize>
-    <OutputPath>bin\NET35\Release</OutputPath>
-    <IntermediateOutputPath>obj\NET35\Release\</IntermediateOutputPath>
-    <DefineConstants>TRACE</DefineConstants>
-    <ErrorReport>prompt</ErrorReport>
-    <WarningLevel>4</WarningLevel>
-    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
-    <NoStdLib>true</NoStdLib>
-    <GenerateSerializationAssemblies>Off</GenerateSerializationAssemblies>
-  </PropertyGroup>
-  <ItemGroup>
-    <Reference Include=""mscorlib"" />
-    <Reference Include=""System"" />
-    <Reference Include=""System.Data"" />
-    <Reference Include=""System.Xml"" />
-  </ItemGroup>
-  <ItemGroup>
-    <Compile Include=""DescriptorUtil.cs"" />
-    <Compile Include=""EnumFieldGenerator.cs"" />
-    <Compile Include=""EnumGenerator.cs"" />
-    <Compile Include=""ExtensionGenerator.cs"" />
-    <Compile Include=""FieldGeneratorBase.cs"" />
-    <Compile Include=""IFieldSourceGenerator.cs"" />
-    <Compile Include=""ISourceGenerator.cs"" />
-    <Compile Include=""MessageFieldGenerator.cs"" />
-    <Compile Include=""MessageGenerator.cs"" />
-    <Compile Include=""PluginProtoFile.cs"" />
-    <Compile Include=""PrimitiveFieldGenerator.cs"" />
-    <Compile Include=""ProgramPreprocess.cs"" />
-    <Compile Include=""RepeatedEnumFieldGenerator.cs"" />
-    <Compile Include=""RepeatedMessageFieldGenerator.cs"" />
-    <Compile Include=""RepeatedPrimitiveFieldGenerator.cs"" />
-    <Compile Include=""ServiceGenerator.cs"" />
-    <Compile Include=""DependencyResolutionException.cs"" />
-    <Compile Include=""Generator.cs"" />
-    <Compile Include=""GeneratorOptions.cs"" />
-    <Compile Include=""Helpers.cs"" />
-    <Compile Include=""InvalidOptionsException.cs"" />
-    <Compile Include=""Program.cs"" />
-    <Compile Include=""Properties\AssemblyInfo.cs"" />
-    <Compile Include=""ServiceInterfaceGenerator.cs"" />
-    <Compile Include=""SourceGeneratorBase.cs"" />
-    <Compile Include=""SourceGenerators.cs"" />
-    <Compile Include=""UmbrellaClassGenerator.cs"" />
-  </ItemGroup>
-  <ItemGroup>
-    <ProjectReference Include=""..\ProtocolBuffers\ProtocolBuffers.csproj"">
-      <Project>{6908BDCE-D925-43F3-94AC-A531E6DF2591}</Project>
-      <Name>ProtocolBuffers</Name>
-    </ProjectReference>
-  </ItemGroup>
-  <ItemGroup>
-    <None Include=""app.config"" />
-  </ItemGroup>
-  <Import Project=""$(MSBuildToolsPath)\Microsoft.CSharp.targets"" />
-  <!-- To modify your build process, add your task inside one of the targets below and uncomment it. 
-       Other similar extension points exist, see Microsoft.Common.targets.
-  <Target Name=""BeforeBuild"">
-  </Target>
-  <Target Name=""AfterBuild"">
-  </Target>
-  -->
-</Project>
\ No newline at end of file
diff --git a/csharp/src/ProtoGen/ProtocGenCs.cs b/csharp/src/ProtoGen/ProtocGenCs.cs
deleted file mode 100644
index 292642000..000000000
--- a/csharp/src/ProtoGen/ProtocGenCs.cs
+++ /dev/null
@@ -1,76 +0,0 @@
-using Google.ProtocolBuffers.Compiler.PluginProto;
-using Google.ProtocolBuffers.DescriptorProtos;
-using System;
-using System.Collections.Generic;
-
-// Usage example:
-//   protoc.exe
-//     --plugin=path\to\protoc-gen-cs.exe
-//     --cs_out=""-generated_code_attributes=true umbrella_namespace=TutorialProto :.""
-//     --proto_path=.\protos\
-//     protos\tutorial\addressbook.proto
-
-namespace Google.ProtocolBuffers.ProtoGen
-{
-    public static class ProtocGenCs
-    {
-        internal static void Run(CodeGeneratorRequest request, CodeGeneratorResponse.Builder response)
-        {
-            var arguments = new List<string>();
-            foreach (var arg in request.Parameter.Split(' '))
-            {
-                var timmedArg = (arg ?? """").Trim();
-                if (!string.IsNullOrEmpty(timmedArg))
-                {
-                    arguments.Add(timmedArg);
-                }
-            }
-            // Adding fake input file to make TryValidate happy.
-            arguments.Add(System.Reflection.Assembly.GetExecutingAssembly().Location);
-
-            GeneratorOptions options = new GeneratorOptions
-            {
-                Arguments = arguments
-            };
-            IList<string> validationFailures;
-            if (!options.TryValidate(out validationFailures))
-            {
-                response.Error += new InvalidOptionsException(validationFailures).Message;
-                return;
-            }
-
-            Generator generator = Generator.CreateGenerator(options);
-            generator.Generate(request, response);
-        }
-
-        public static int Main(string[] args)
-        {
-            // Hack to make sure everything's initialized
-            DescriptorProtoFile.Descriptor.ToString();
-            ExtensionRegistry extensionRegistry = ExtensionRegistry.CreateInstance();
-            CSharpOptions.RegisterAllExtensions(extensionRegistry);
-
-            CodeGeneratorRequest request;
-            var response = new CodeGeneratorResponse.Builder();
-            try
-            {
-                using (var input = Console.OpenStandardInput())
-                {
-                    request = CodeGeneratorRequest.ParseFrom(input, extensionRegistry);
-                }
-                Run(request, response);
-            }
-            catch (Exception e)
-            {
-                response.Error += e.ToString();
-            }
-
-            using (var output = Console.OpenStandardOutput())
-            {
-                response.Build().WriteTo(output);
-                output.Flush();
-            }
-            return 0;
-        }
-    }
-}
diff --git a/csharp/src/ProtoGen/RepeatedEnumFieldGenerator.cs b/csharp/src/ProtoGen/RepeatedEnumFieldGenerator.cs
deleted file mode 100644
index 8c9f17b8d..000000000
--- a/csharp/src/ProtoGen/RepeatedEnumFieldGenerator.cs
+++ /dev/null
@@ -1,212 +0,0 @@
-#region Copyright notice and license
-
-// Protocol Buffers - Google's data interchange format
-// Copyright 2008 Google Inc.  All rights reserved.
-// http://github.com/jskeet/dotnet-protobufs/
-// Original C++/Java/Python code:
-// http://code.google.com/p/protobuf/
-//
-// Redistribution and use in source and binary forms, with or without
-// modification, are permitted provided that the following conditions are
-// met:
-//
-//     * Redistributions of source code must retain the above copyright
-// notice, this list of conditions and the following disclaimer.
-//     * Redistributions in binary form must reproduce the above
-// copyright notice, this list of conditions and the following disclaimer
-// in the documentation and/or other materials provided with the
-// distribution.
-//     * Neither the name of Google Inc. nor the names of its
-// contributors may be used to endorse or promote products derived from
-// this software without specific prior written permission.
-//
-// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-// ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
-#endregion
-
-using Google.ProtocolBuffers.Descriptors;
-
-namespace Google.ProtocolBuffers.ProtoGen
-{
-    internal class RepeatedEnumFieldGenerator : FieldGeneratorBase, IFieldSourceGenerator
-    {
-        internal RepeatedEnumFieldGenerator(FieldDescriptor descriptor, int fieldOrdinal)
-            : base(descriptor, fieldOrdinal)
-        {
-        }
-
-        public void GenerateMembers(TextGenerator writer)
-        {
-            if (Descriptor.IsPacked && OptimizeSpeed)
-            {
-                writer.WriteLine(""private int {0}MemoizedSerializedSize;"", Name);
-            }
-            writer.WriteLine(""private pbc::PopsicleList<{0}> {1}_ = new pbc::PopsicleList<{0}>();"", TypeName, Name);
-            AddDeprecatedFlag(writer);
-            writer.WriteLine(""public scg::IList<{0}> {1}List {{"", TypeName, PropertyName);
-            writer.WriteLine(""  get {{ return pbc::Lists.AsReadOnly({0}_); }}"", Name);
-            writer.WriteLine(""}"");
-
-            // TODO(jonskeet): Redundant API calls? Possibly - include for portability though. Maybe create an option.
-            AddDeprecatedFlag(writer);
-            writer.WriteLine(""public int {0}Count {{"", PropertyName);
-            writer.WriteLine(""  get {{ return {0}_.Count; }}"", Name);
-            writer.WriteLine(""}"");
-
-            AddDeprecatedFlag(writer);
-            writer.WriteLine(""public {0} Get{1}(int index) {{"", TypeName, PropertyName);
-            writer.WriteLine(""  return {0}_[index];"", Name);
-            writer.WriteLine(""}"");
-        }
-
-        public void GenerateBuilderMembers(TextGenerator writer)
-        {
-            // Note:  We can return the original list here, because we make it unmodifiable when we build
-            // We return it via IPopsicleList so that collection initializers work more pleasantly.
-            AddDeprecatedFlag(writer);
-            writer.WriteLine(""public pbc::IPopsicleList<{0}> {1}List {{"", TypeName, PropertyName);
-            writer.WriteLine(""  get {{ return PrepareBuilder().{0}_; }}"", Name);
-            writer.WriteLine(""}"");
-            AddDeprecatedFlag(writer);
-            writer.WriteLine(""public int {0}Count {{"", PropertyName);
-            writer.WriteLine(""  get {{ return result.{0}Count; }}"", PropertyName);
-            writer.WriteLine(""}"");
-            AddDeprecatedFlag(writer);
-            writer.WriteLine(""public {0} Get{1}(int index) {{"", TypeName, PropertyName);
-            writer.WriteLine(""  return result.Get{0}(index);"", PropertyName);
-            writer.WriteLine(""}"");
-            AddDeprecatedFlag(writer);
-            writer.WriteLine(""public Builder Set{0}(int index, {1} value) {{"", PropertyName, TypeName);
-            writer.WriteLine(""  PrepareBuilder();"");
-            writer.WriteLine(""  result.{0}_[index] = value;"", Name);
-            writer.WriteLine(""  return this;"");
-            writer.WriteLine(""}"");
-            AddDeprecatedFlag(writer);
-            writer.WriteLine(""public Builder Add{0}({1} value) {{"", PropertyName, TypeName);
-            writer.WriteLine(""  PrepareBuilder();"");
-            writer.WriteLine(""  result.{0}_.Add(value);"", Name, TypeName);
-            writer.WriteLine(""  return this;"");
-            writer.WriteLine(""}"");
-            AddDeprecatedFlag(writer);
-            writer.WriteLine(""public Builder AddRange{0}(scg::IEnumerable<{1}> values) {{"", PropertyName, TypeName);
-            writer.WriteLine(""  PrepareBuilder();"");
-            writer.WriteLine(""  result.{0}_.Add(values);"", Name);
-            writer.WriteLine(""  return this;"");
-            writer.WriteLine(""}"");
-            AddDeprecatedFlag(writer);
-            writer.WriteLine(""public Builder Clear{0}() {{"", PropertyName);
-            writer.WriteLine(""  PrepareBuilder();"");
-            writer.WriteLine(""  result.{0}_.Clear();"", Name);
-            writer.WriteLine(""  return this;"");
-            writer.WriteLine(""}"");
-        }
-
-        public void GenerateMergingCode(TextGenerator writer)
-        {
-            writer.WriteLine(""if (other.{0}_.Count != 0) {{"", Name);
-            writer.WriteLine(""  result.{0}_.Add(other.{0}_);"", Name);
-            writer.WriteLine(""}"");
-        }
-
-        public void GenerateBuildingCode(TextGenerator writer)
-        {
-            writer.WriteLine(""{0}_.MakeReadOnly();"", Name);
-        }
-
-        public void GenerateParsingCode(TextGenerator writer)
-        {
-            writer.WriteLine(""scg::ICollection<object> unknownItems;"");
-            writer.WriteLine(""input.ReadEnumArray<{0}>(tag, field_name, result.{1}_, out unknownItems);"", TypeName, Name);
-            if (!UseLiteRuntime)
-            {
-                writer.WriteLine(""if (unknownItems != null) {"");
-                writer.WriteLine(""  if (unknownFields == null) {"");
-                writer.WriteLine(""    unknownFields = pb::UnknownFieldSet.CreateBuilder(this.UnknownFields);"");
-                writer.WriteLine(""  }"");
-                writer.WriteLine(""  foreach (object rawValue in unknownItems)"");
-                writer.WriteLine(""    if (rawValue is int)"");
-                writer.WriteLine(""      unknownFields.MergeVarintField({0}, (ulong)(int)rawValue);"", Number);
-                writer.WriteLine(""}"");
-            }
-        }
-
-        public void GenerateSerializationCode(TextGenerator writer)
-        {
-            writer.WriteLine(""if ({0}_.Count > 0) {{"", Name);
-            writer.Indent();
-            if (Descriptor.IsPacked)
-            {
-                writer.WriteLine(
-                    ""output.WritePackedEnumArray({0}, field_names[{2}], {1}MemoizedSerializedSize, {1}_);"", Number, Name,
-                    FieldOrdinal, Descriptor.FieldType);
-            }
-            else
-            {
-                writer.WriteLine(""output.WriteEnumArray({0}, field_names[{2}], {1}_);"", Number, Name, FieldOrdinal,
-                                 Descriptor.FieldType);
-            }
-            writer.Outdent();
-            writer.WriteLine(""}"");
-        }
-
-        public void GenerateSerializedSizeCode(TextGenerator writer)
-        {
-            writer.WriteLine(""{"");
-            writer.Indent();
-            writer.WriteLine(""int dataSize = 0;"");
-            writer.WriteLine(""if ({0}_.Count > 0) {{"", Name);
-            writer.Indent();
-            writer.WriteLine(""foreach ({0} element in {1}_) {{"", TypeName, Name);
-            writer.WriteLine(""  dataSize += pb::CodedOutputStream.ComputeEnumSizeNoTag((int) element);"");
-            writer.WriteLine(""}"");
-            writer.WriteLine(""size += dataSize;"");
-            int tagSize = CodedOutputStream.ComputeTagSize(Descriptor.FieldNumber);
-            if (Descriptor.IsPacked)
-            {
-                writer.WriteLine(""size += {0};"", tagSize);
-                writer.WriteLine(""size += pb::CodedOutputStream.ComputeRawVarint32Size((uint) dataSize);"");
-            }
-            else
-            {
-                writer.WriteLine(""size += {0} * {1}_.Count;"", tagSize, Name);
-            }
-            writer.Outdent();
-            writer.WriteLine(""}"");
-            // cache the data size for packed fields.
-            if (Descriptor.IsPacked)
-            {
-                writer.WriteLine(""{0}MemoizedSerializedSize = dataSize;"", Name);
-            }
-            writer.Outdent();
-            writer.WriteLine(""}"");
-        }
-
-        public override void WriteHash(TextGenerator writer)
-        {
-            writer.WriteLine(""foreach({0} i in {1}_)"", TypeName, Name);
-            writer.WriteLine(""  hash ^= i.GetHashCode();"");
-        }
-
-        public override void WriteEquals(TextGenerator writer)
-        {
-            writer.WriteLine(""if({0}_.Count != other.{0}_.Count) return false;"", Name);
-            writer.WriteLine(""for(int ix=0; ix < {0}_.Count; ix++)"", Name);
-            writer.WriteLine(""  if(!{0}_[ix].Equals(other.{0}_[ix])) return false;"", Name);
-        }
-
-        public override void WriteToString(TextGenerator writer)
-        {
-            writer.WriteLine(""PrintField(\""{0}\"", {1}_, writer);"", Descriptor.Name, Name);
-        }
-    }
-}
\ No newline at end of file
diff --git a/csharp/src/ProtoGen/RepeatedMessageFieldGenerator.cs b/csharp/src/ProtoGen/RepeatedMessageFieldGenerator.cs
deleted file mode 100644
index a9a0143ca..000000000
--- a/csharp/src/ProtoGen/RepeatedMessageFieldGenerator.cs
+++ /dev/null
@@ -1,184 +0,0 @@
-#region Copyright notice and license
-
-// Protocol Buffers - Google's data interchange format
-// Copyright 2008 Google Inc.  All rights reserved.
-// http://github.com/jskeet/dotnet-protobufs/
-// Original C++/Java/Python code:
-// http://code.google.com/p/protobuf/
-//
-// Redistribution and use in source and binary forms, with or without
-// modification, are permitted provided that the following conditions are
-// met:
-//
-//     * Redistributions of source code must retain the above copyright
-// notice, this list of conditions and the following disclaimer.
-//     * Redistributions in binary form must reproduce the above
-// copyright notice, this list of conditions and the following disclaimer
-// in the documentation and/or other materials provided with the
-// distribution.
-//     * Neither the name of Google Inc. nor the names of its
-// contributors may be used to endorse or promote products derived from
-// this software without specific prior written permission.
-//
-// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-// ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
-#endregion
-
-using Google.ProtocolBuffers.Descriptors;
-
-namespace Google.ProtocolBuffers.ProtoGen
-{
-    internal class RepeatedMessageFieldGenerator : FieldGeneratorBase, IFieldSourceGenerator
-    {
-        internal RepeatedMessageFieldGenerator(FieldDescriptor descriptor, int fieldOrdinal)
-            : base(descriptor, fieldOrdinal)
-        {
-        }
-
-        public void GenerateMembers(TextGenerator writer)
-        {
-            writer.WriteLine(""private pbc::PopsicleList<{0}> {1}_ = new pbc::PopsicleList<{0}>();"", TypeName, Name);
-            AddDeprecatedFlag(writer);
-            writer.WriteLine(""public scg::IList<{0}> {1}List {{"", TypeName, PropertyName);
-            writer.WriteLine(""  get {{ return {0}_; }}"", Name);
-            writer.WriteLine(""}"");
-
-            // TODO(jonskeet): Redundant API calls? Possibly - include for portability though. Maybe create an option.
-            AddDeprecatedFlag(writer);
-            writer.WriteLine(""public int {0}Count {{"", PropertyName);
-            writer.WriteLine(""  get {{ return {0}_.Count; }}"", Name);
-            writer.WriteLine(""}"");
-
-            AddDeprecatedFlag(writer);
-            writer.WriteLine(""public {0} Get{1}(int index) {{"", TypeName, PropertyName);
-            writer.WriteLine(""  return {0}_[index];"", Name);
-            writer.WriteLine(""}"");
-        }
-
-        public void GenerateBuilderMembers(TextGenerator writer)
-        {
-            // Note:  We can return the original list here, because we make it unmodifiable when we build
-            // We return it via IPopsicleList so that collection initializers work more pleasantly.
-            AddDeprecatedFlag(writer);
-            writer.WriteLine(""public pbc::IPopsicleList<{0}> {1}List {{"", TypeName, PropertyName);
-            writer.WriteLine(""  get {{ return PrepareBuilder().{0}_; }}"", Name);
-            writer.WriteLine(""}"");
-            AddDeprecatedFlag(writer);
-            writer.WriteLine(""public int {0}Count {{"", PropertyName);
-            writer.WriteLine(""  get {{ return result.{0}Count; }}"", PropertyName);
-            writer.WriteLine(""}"");
-            AddDeprecatedFlag(writer);
-            writer.WriteLine(""public {0} Get{1}(int index) {{"", TypeName, PropertyName);
-            writer.WriteLine(""  return result.Get{0}(index);"", PropertyName);
-            writer.WriteLine(""}"");
-            AddDeprecatedFlag(writer);
-            writer.WriteLine(""public Builder Set{0}(int index, {1} value) {{"", PropertyName, TypeName);
-            AddNullCheck(writer);
-            writer.WriteLine(""  PrepareBuilder();"");
-            writer.WriteLine(""  result.{0}_[index] = value;"", Name);
-            writer.WriteLine(""  return this;"");
-            writer.WriteLine(""}"");
-            // Extra overload for builder (just on messages)
-            AddDeprecatedFlag(writer);
-            writer.WriteLine(""public Builder Set{0}(int index, {1}.Builder builderForValue) {{"", PropertyName, TypeName);
-            AddNullCheck(writer, ""builderForValue"");
-            writer.WriteLine(""  PrepareBuilder();"");
-            writer.WriteLine(""  result.{0}_[index] = builderForValue.Build();"", Name);
-            writer.WriteLine(""  return this;"");
-            writer.WriteLine(""}"");
-            AddDeprecatedFlag(writer);
-            writer.WriteLine(""public Builder Add{0}({1} value) {{"", PropertyName, TypeName);
-            AddNullCheck(writer);
-            writer.WriteLine(""  PrepareBuilder();"");
-            writer.WriteLine(""  result.{0}_.Add(value);"", Name, TypeName);
-            writer.WriteLine(""  return this;"");
-            writer.WriteLine(""}"");
-            // Extra overload for builder (just on messages)
-            AddDeprecatedFlag(writer);
-            writer.WriteLine(""public Builder Add{0}({1}.Builder builderForValue) {{"", PropertyName, TypeName);
-            AddNullCheck(writer, ""builderForValue"");
-            writer.WriteLine(""  PrepareBuilder();"");
-            writer.WriteLine(""  result.{0}_.Add(builderForValue.Build());"", Name);
-            writer.WriteLine(""  return this;"");
-            writer.WriteLine(""}"");
-            AddDeprecatedFlag(writer);
-            writer.WriteLine(""public Builder AddRange{0}(scg::IEnumerable<{1}> values) {{"", PropertyName, TypeName);
-            writer.WriteLine(""  PrepareBuilder();"");
-            writer.WriteLine(""  result.{0}_.Add(values);"", Name);
-            writer.WriteLine(""  return this;"");
-            writer.WriteLine(""}"");
-            AddDeprecatedFlag(writer);
-            writer.WriteLine(""public Builder Clear{0}() {{"", PropertyName);
-            writer.WriteLine(""  PrepareBuilder();"");
-            writer.WriteLine(""  result.{0}_.Clear();"", Name);
-            writer.WriteLine(""  return this;"");
-            writer.WriteLine(""}"");
-        }
-
-        public void GenerateMergingCode(TextGenerator writer)
-        {
-            writer.WriteLine(""if (other.{0}_.Count != 0) {{"", Name);
-            writer.WriteLine(""  result.{0}_.Add(other.{0}_);"", Name);
-            writer.WriteLine(""}"");
-        }
-
-        public void GenerateBuildingCode(TextGenerator writer)
-        {
-            writer.WriteLine(""{0}_.MakeReadOnly();"", Name);
-        }
-
-        public void GenerateParsingCode(TextGenerator writer)
-        {
-            writer.WriteLine(
-                ""input.Read{0}Array(tag, field_name, result.{1}_, {2}.DefaultInstance, extensionRegistry);"",
-                MessageOrGroup, Name, TypeName);
-        }
-
-        public void GenerateSerializationCode(TextGenerator writer)
-        {
-            writer.WriteLine(""if ({0}_.Count > 0) {{"", Name);
-            writer.Indent();
-            writer.WriteLine(""output.Write{0}Array({1}, field_names[{3}], {2}_);"", MessageOrGroup, Number, Name,
-                             FieldOrdinal, Descriptor.FieldType);
-            writer.Outdent();
-            writer.WriteLine(""}"");
-        }
-
-        public void GenerateSerializedSizeCode(TextGenerator writer)
-        {
-            writer.WriteLine(""foreach ({0} element in {1}List) {{"", TypeName, PropertyName);
-            writer.WriteLine(""  size += pb::CodedOutputStream.Compute{0}Size({1}, element);"", MessageOrGroup, Number);
-            writer.WriteLine(""}"");
-        }
-
-        public override void WriteHash(TextGenerator writer)
-        {
-            writer.WriteLine(""foreach({0} i in {1}_)"", TypeName, Name);
-            writer.WriteLine(""  hash ^= i.GetHashCode();"");
-        }
-
-        public override void WriteEquals(TextGenerator writer)
-        {
-            writer.WriteLine(""if({0}_.Count != other.{0}_.Count) return false;"", Name);
-            writer.WriteLine(""for(int ix=0; ix < {0}_.Count; ix++)"", Name);
-            writer.WriteLine(""  if(!{0}_[ix].Equals(other.{0}_[ix])) return false;"", Name);
-        }
-
-        public override void WriteToString(TextGenerator writer)
-        {
-            writer.WriteLine(""PrintField(\""{0}\"", {1}_, writer);"",
-                             Descriptor.FieldType == FieldType.Group ? Descriptor.MessageType.Name : Descriptor.Name,
-                             Name);
-        }
-    }
-}
\ No newline at end of file
diff --git a/csharp/src/ProtoGen/RepeatedPrimitiveFieldGenerator.cs b/csharp/src/ProtoGen/RepeatedPrimitiveFieldGenerator.cs
deleted file mode 100644
index b795f3b64..000000000
--- a/csharp/src/ProtoGen/RepeatedPrimitiveFieldGenerator.cs
+++ /dev/null
@@ -1,207 +0,0 @@
-#region Copyright notice and license
-
-// Protocol Buffers - Google's data interchange format
-// Copyright 2008 Google Inc.  All rights reserved.
-// http://github.com/jskeet/dotnet-protobufs/
-// Original C++/Java/Python code:
-// http://code.google.com/p/protobuf/
-//
-// Redistribution and use in source and binary forms, with or without
-// modification, are permitted provided that the following conditions are
-// met:
-//
-//     * Redistributions of source code must retain the above copyright
-// notice, this list of conditions and the following disclaimer.
-//     * Redistributions in binary form must reproduce the above
-// copyright notice, this list of conditions and the following disclaimer
-// in the documentation and/or other materials provided with the
-// distribution.
-//     * Neither the name of Google Inc. nor the names of its
-// contributors may be used to endorse or promote products derived from
-// this software without specific prior written permission.
-//
-// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-// ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
-#endregion
-
-using Google.ProtocolBuffers.Descriptors;
-
-namespace Google.ProtocolBuffers.ProtoGen
-{
-    internal class RepeatedPrimitiveFieldGenerator : FieldGeneratorBase, IFieldSourceGenerator
-    {
-        internal RepeatedPrimitiveFieldGenerator(FieldDescriptor descriptor, int fieldOrdinal)
-            : base(descriptor, fieldOrdinal)
-        {
-        }
-
-        public void GenerateMembers(TextGenerator writer)
-        {
-            if (Descriptor.IsPacked && OptimizeSpeed)
-            {
-                writer.WriteLine(""private int {0}MemoizedSerializedSize;"", Name);
-            }
-            writer.WriteLine(""private pbc::PopsicleList<{0}> {1}_ = new pbc::PopsicleList<{0}>();"", TypeName, Name);
-            AddPublicMemberAttributes(writer);
-            writer.WriteLine(""public scg::IList<{0}> {1}List {{"", TypeName, PropertyName);
-            writer.WriteLine(""  get {{ return pbc::Lists.AsReadOnly({0}_); }}"", Name);
-            writer.WriteLine(""}"");
-
-            // TODO(jonskeet): Redundant API calls? Possibly - include for portability though. Maybe create an option.
-            AddDeprecatedFlag(writer);
-            writer.WriteLine(""public int {0}Count {{"", PropertyName);
-            writer.WriteLine(""  get {{ return {0}_.Count; }}"", Name);
-            writer.WriteLine(""}"");
-
-            AddPublicMemberAttributes(writer);
-            writer.WriteLine(""public {0} Get{1}(int index) {{"", TypeName, PropertyName);
-            writer.WriteLine(""  return {0}_[index];"", Name);
-            writer.WriteLine(""}"");
-        }
-
-        public void GenerateBuilderMembers(TextGenerator writer)
-        {
-            // Note:  We can return the original list here, because we make it unmodifiable when we build
-            // We return it via IPopsicleList so that collection initializers work more pleasantly.
-            AddPublicMemberAttributes(writer);
-            writer.WriteLine(""public pbc::IPopsicleList<{0}> {1}List {{"", TypeName, PropertyName);
-            writer.WriteLine(""  get {{ return PrepareBuilder().{0}_; }}"", Name);
-            writer.WriteLine(""}"");
-            AddDeprecatedFlag(writer);
-            writer.WriteLine(""public int {0}Count {{"", PropertyName);
-            writer.WriteLine(""  get {{ return result.{0}Count; }}"", PropertyName);
-            writer.WriteLine(""}"");
-            AddPublicMemberAttributes(writer);
-            writer.WriteLine(""public {0} Get{1}(int index) {{"", TypeName, PropertyName);
-            writer.WriteLine(""  return result.Get{0}(index);"", PropertyName);
-            writer.WriteLine(""}"");
-            AddPublicMemberAttributes(writer);
-            writer.WriteLine(""public Builder Set{0}(int index, {1} value) {{"", PropertyName, TypeName);
-            AddNullCheck(writer);
-            writer.WriteLine(""  PrepareBuilder();"");
-            writer.WriteLine(""  result.{0}_[index] = value;"", Name);
-            writer.WriteLine(""  return this;"");
-            writer.WriteLine(""}"");
-            AddPublicMemberAttributes(writer);
-            writer.WriteLine(""public Builder Add{0}({1} value) {{"", PropertyName, TypeName);
-            AddNullCheck(writer);
-            writer.WriteLine(""  PrepareBuilder();"");
-            writer.WriteLine(""  result.{0}_.Add(value);"", Name, TypeName);
-            writer.WriteLine(""  return this;"");
-            writer.WriteLine(""}"");
-            AddPublicMemberAttributes(writer);
-            writer.WriteLine(""public Builder AddRange{0}(scg::IEnumerable<{1}> values) {{"", PropertyName, TypeName);
-            writer.WriteLine(""  PrepareBuilder();"");
-            writer.WriteLine(""  result.{0}_.Add(values);"", Name);
-            writer.WriteLine(""  return this;"");
-            writer.WriteLine(""}"");
-            AddDeprecatedFlag(writer);
-            writer.WriteLine(""public Builder Clear{0}() {{"", PropertyName);
-            writer.WriteLine(""  PrepareBuilder();"");
-            writer.WriteLine(""  result.{0}_.Clear();"", Name);
-            writer.WriteLine(""  return this;"");
-            writer.WriteLine(""}"");
-        }
-
-        public void GenerateMergingCode(TextGenerator writer)
-        {
-            writer.WriteLine(""if (other.{0}_.Count != 0) {{"", Name);
-            writer.WriteLine(""  result.{0}_.Add(other.{0}_);"", Name);
-            writer.WriteLine(""}"");
-        }
-
-        public void GenerateBuildingCode(TextGenerator writer)
-        {
-            writer.WriteLine(""{0}_.MakeReadOnly();"", Name);
-        }
-
-        public void GenerateParsingCode(TextGenerator writer)
-        {
-            writer.WriteLine(""input.Read{0}Array(tag, field_name, result.{1}_);"", CapitalizedTypeName, Name,
-                             Descriptor.FieldType);
-        }
-
-        public void GenerateSerializationCode(TextGenerator writer)
-        {
-            writer.WriteLine(""if ({0}_.Count > 0) {{"", Name);
-            writer.Indent();
-            if (Descriptor.IsPacked)
-            {
-                writer.WriteLine(""output.WritePacked{0}Array({1}, field_names[{3}], {2}MemoizedSerializedSize, {2}_);"",
-                                 CapitalizedTypeName, Number, Name, FieldOrdinal, Descriptor.FieldType);
-            }
-            else
-            {
-                writer.WriteLine(""output.Write{0}Array({1}, field_names[{3}], {2}_);"", CapitalizedTypeName, Number, Name,
-                                 FieldOrdinal, Descriptor.FieldType);
-            }
-            writer.Outdent();
-            writer.WriteLine(""}"");
-        }
-
-        public void GenerateSerializedSizeCode(TextGenerator writer)
-        {
-            writer.WriteLine(""{"");
-            writer.Indent();
-            writer.WriteLine(""int dataSize = 0;"");
-            if (FixedSize == -1)
-            {
-                writer.WriteLine(""foreach ({0} element in {1}List) {{"", TypeName, PropertyName);
-                writer.WriteLine(""  dataSize += pb::CodedOutputStream.Compute{0}SizeNoTag(element);"",
-                                 CapitalizedTypeName, Number);
-                writer.WriteLine(""}"");
-            }
-            else
-            {
-                writer.WriteLine(""dataSize = {0} * {1}_.Count;"", FixedSize, Name);
-            }
-            writer.WriteLine(""size += dataSize;"");
-            int tagSize = CodedOutputStream.ComputeTagSize(Descriptor.FieldNumber);
-            if (Descriptor.IsPacked)
-            {
-                writer.WriteLine(""if ({0}_.Count != 0) {{"", Name);
-                writer.WriteLine(""  size += {0} + pb::CodedOutputStream.ComputeInt32SizeNoTag(dataSize);"", tagSize);
-                writer.WriteLine(""}"");
-            }
-            else
-            {
-                writer.WriteLine(""size += {0} * {1}_.Count;"", tagSize, Name);
-            }
-            // cache the data size for packed fields.
-            if (Descriptor.IsPacked)
-            {
-                writer.WriteLine(""{0}MemoizedSerializedSize = dataSize;"", Name);
-            }
-            writer.Outdent();
-            writer.WriteLine(""}"");
-        }
-
-        public override void WriteHash(TextGenerator writer)
-        {
-            writer.WriteLine(""foreach({0} i in {1}_)"", TypeName, Name);
-            writer.WriteLine(""  hash ^= i.GetHashCode();"");
-        }
-
-        public override void WriteEquals(TextGenerator writer)
-        {
-            writer.WriteLine(""if({0}_.Count != other.{0}_.Count) return false;"", Name);
-            writer.WriteLine(""for(int ix=0; ix < {0}_.Count; ix++)"", Name);
-            writer.WriteLine(""  if(!{0}_[ix].Equals(other.{0}_[ix])) return false;"", Name);
-        }
-
-        public override void WriteToString(TextGenerator writer)
-        {
-            writer.WriteLine(""PrintField(\""{0}\"", {1}_, writer);"", Descriptor.Name, Name);
-        }
-    }
-}
\ No newline at end of file
diff --git a/csharp/src/ProtoGen/ServiceGenerator.cs b/csharp/src/ProtoGen/ServiceGenerator.cs
deleted file mode 100644
index a6b9eb28b..000000000
--- a/csharp/src/ProtoGen/ServiceGenerator.cs
+++ /dev/null
@@ -1,190 +0,0 @@
-#region Copyright notice and license
-
-// Protocol Buffers - Google's data interchange format
-// Copyright 2008 Google Inc.  All rights reserved.
-// http://github.com/jskeet/dotnet-protobufs/
-// Original C++/Java/Python code:
-// http://code.google.com/p/protobuf/
-//
-// Redistribution and use in source and binary forms, with or without
-// modification, are permitted provided that the following conditions are
-// met:
-//
-//     * Redistributions of source code must retain the above copyright
-// notice, this list of conditions and the following disclaimer.
-//     * Redistributions in binary form must reproduce the above
-// copyright notice, this list of conditions and the following disclaimer
-// in the documentation and/or other materials provided with the
-// distribution.
-//     * Neither the name of Google Inc. nor the names of its
-// contributors may be used to endorse or promote products derived from
-// this software without specific prior written permission.
-//
-// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-// ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
-#endregion
-
-using Google.ProtocolBuffers.Descriptors;
-
-namespace Google.ProtocolBuffers.ProtoGen
-{
-    internal class GenericServiceGenerator : SourceGeneratorBase<ServiceDescriptor>, ISourceGenerator
-    {
-        private enum RequestOrResponse
-        {
-            Request,
-            Response
-        }
-
-        internal GenericServiceGenerator(ServiceDescriptor descriptor)
-            : base(descriptor)
-        {
-        }
-
-        public void Generate(TextGenerator writer)
-        {
-            writer.WriteLine(""[global::System.Diagnostics.DebuggerNonUserCodeAttribute()]"");
-            WriteGeneratedCodeAttributes(writer);
-            writer.WriteLine(""{0} abstract class {1} : pb::IService {{"", ClassAccessLevel, Descriptor.Name);
-            writer.Indent();
-
-            foreach (MethodDescriptor method in Descriptor.Methods)
-            {
-                writer.WriteLine(""{0} abstract void {1}("", ClassAccessLevel,
-                                 NameHelpers.UnderscoresToPascalCase(method.Name));
-                writer.WriteLine(""    pb::IRpcController controller,"");
-                writer.WriteLine(""    {0} request,"", GetClassName(method.InputType));
-                writer.WriteLine(""    global::System.Action<{0}> done);"", GetClassName(method.OutputType));
-            }
-
-            // Generate Descriptor and DescriptorForType.
-            writer.WriteLine();
-            writer.WriteLine(""{0} static pbd::ServiceDescriptor Descriptor {{"", ClassAccessLevel);
-            writer.WriteLine(""  get {{ return {0}.Descriptor.Services[{1}]; }}"",
-                             DescriptorUtil.GetQualifiedUmbrellaClassName(Descriptor.File.CSharpOptions),
-                             Descriptor.Index);
-            writer.WriteLine(""}"");
-            writer.WriteLine(""public pbd::ServiceDescriptor DescriptorForType {"");
-            writer.WriteLine(""  get { return Descriptor; }"");
-            writer.WriteLine(""}"");
-
-            GenerateCallMethod(writer);
-            GenerateGetPrototype(RequestOrResponse.Request, writer);
-            GenerateGetPrototype(RequestOrResponse.Response, writer);
-            GenerateStub(writer);
-
-            writer.Outdent();
-            writer.WriteLine(""}"");
-        }
-
-        private void GenerateCallMethod(TextGenerator writer)
-        {
-            writer.WriteLine();
-            writer.WriteLine(""public void CallMethod("");
-            writer.WriteLine(""    pbd::MethodDescriptor method,"");
-            writer.WriteLine(""    pb::IRpcController controller,"");
-            writer.WriteLine(""    pb::IMessage request,"");
-            writer.WriteLine(""    global::System.Action<pb::IMessage> done) {"");
-            writer.Indent();
-            writer.WriteLine(""if (method.Service != Descriptor) {"");
-            writer.WriteLine(""  throw new global::System.ArgumentException("");
-            writer.WriteLine(""      \""Service.CallMethod() given method descriptor for wrong service type.\"");"");
-            writer.WriteLine(""}"");
-            writer.WriteLine(""switch(method.Index) {"");
-            writer.Indent();
-            foreach (MethodDescriptor method in Descriptor.Methods)
-            {
-                writer.WriteLine(""case {0}:"", method.Index);
-                writer.WriteLine(""  this.{0}(controller, ({1}) request,"",
-                                 NameHelpers.UnderscoresToPascalCase(method.Name), GetClassName(method.InputType));
-                writer.WriteLine(""      pb::RpcUtil.SpecializeCallback<{0}>("", GetClassName(method.OutputType));
-                writer.WriteLine(""      done));"");
-                writer.WriteLine(""  return;"");
-            }
-            writer.WriteLine(""default:"");
-            writer.WriteLine(""  throw new global::System.InvalidOperationException(\""Can't get here.\"");"");
-            writer.Outdent();
-            writer.WriteLine(""}"");
-            writer.Outdent();
-            writer.WriteLine(""}"");
-            writer.WriteLine();
-        }
-
-        private void GenerateGetPrototype(RequestOrResponse which, TextGenerator writer)
-        {
-            writer.WriteLine(""public pb::IMessage Get{0}Prototype(pbd::MethodDescriptor method) {{"", which);
-            writer.Indent();
-            writer.WriteLine(""if (method.Service != Descriptor) {"");
-            writer.WriteLine(""  throw new global::System.ArgumentException("");
-            writer.WriteLine(""      \""Service.Get{0}Prototype() given method descriptor for wrong service type.\"");"",
-                             which);
-            writer.WriteLine(""}"");
-            writer.WriteLine(""switch(method.Index) {"");
-            writer.Indent();
-
-            foreach (MethodDescriptor method in Descriptor.Methods)
-            {
-                writer.WriteLine(""case {0}:"", method.Index);
-                writer.WriteLine(""  return {0}.DefaultInstance;"",
-                                 GetClassName(which == RequestOrResponse.Request ? method.InputType : method.OutputType));
-            }
-            writer.WriteLine(""default:"");
-            writer.WriteLine(""  throw new global::System.InvalidOperationException(\""Can't get here.\"");"");
-            writer.Outdent();
-            writer.WriteLine(""}"");
-            writer.Outdent();
-            writer.WriteLine(""}"");
-            writer.WriteLine();
-        }
-
-        private void GenerateStub(TextGenerator writer)
-        {
-            writer.WriteLine(""public static Stub CreateStub(pb::IRpcChannel channel) {"");
-            writer.WriteLine(""  return new Stub(channel);"");
-            writer.WriteLine(""}"");
-            writer.WriteLine();
-            writer.WriteLine(""[global::System.Diagnostics.DebuggerNonUserCodeAttribute()]"");
-            WriteGeneratedCodeAttributes(writer);
-            writer.WriteLine(""{0} class Stub : {1} {{"", ClassAccessLevel, GetClassName(Descriptor));
-            writer.Indent();
-            writer.WriteLine(""internal Stub(pb::IRpcChannel channel) {"");
-            writer.WriteLine(""  this.channel = channel;"");
-            writer.WriteLine(""}"");
-            writer.WriteLine();
-            writer.WriteLine(""private readonly pb::IRpcChannel channel;"");
-            writer.WriteLine();
-            writer.WriteLine(""public pb::IRpcChannel Channel {"");
-            writer.WriteLine(""  get { return channel; }"");
-            writer.WriteLine(""}"");
-
-            foreach (MethodDescriptor method in Descriptor.Methods)
-            {
-                writer.WriteLine();
-                writer.WriteLine(""{0} override void {1}("", ClassAccessLevel, 
-                                 NameHelpers.UnderscoresToPascalCase(method.Name));
-                writer.WriteLine(""    pb::IRpcController controller,"");
-                writer.WriteLine(""    {0} request,"", GetClassName(method.InputType));
-                writer.WriteLine(""    global::System.Action<{0}> done) {{"", GetClassName(method.OutputType));
-                writer.Indent();
-                writer.WriteLine(""channel.CallMethod(Descriptor.Methods[{0}],"", method.Index);
-                writer.WriteLine(""    controller, request, {0}.DefaultInstance,"", GetClassName(method.OutputType));
-                writer.WriteLine(""    pb::RpcUtil.GeneralizeCallback<{0}, {0}.Builder>(done, {0}.DefaultInstance));"",
-                                 GetClassName(method.OutputType));
-                writer.Outdent();
-                writer.WriteLine(""}"");
-            }
-            writer.Outdent();
-            writer.WriteLine(""}"");
-        }
-    }
-}
\ No newline at end of file
diff --git a/csharp/src/ProtoGen/ServiceInterfaceGenerator.cs b/csharp/src/ProtoGen/ServiceInterfaceGenerator.cs
deleted file mode 100644
index 11e3d3d0e..000000000
--- a/csharp/src/ProtoGen/ServiceInterfaceGenerator.cs
+++ /dev/null
@@ -1,300 +0,0 @@
-#region Copyright notice and license
-
-// Protocol Buffers - Google's data interchange format
-// Copyright 2008 Google Inc.  All rights reserved.
-// http://github.com/jskeet/dotnet-protobufs/
-// Original C++/Java/Python code:
-// http://code.google.com/p/protobuf/
-//
-// Redistribution and use in source and binary forms, with or without
-// modification, are permitted provided that the following conditions are
-// met:
-//
-//     * Redistributions of source code must retain the above copyright
-// notice, this list of conditions and the following disclaimer.
-//     * Redistributions in binary form must reproduce the above
-// copyright notice, this list of conditions and the following disclaimer
-// in the documentation and/or other materials provided with the
-// distribution.
-//     * Neither the name of Google Inc. nor the names of its
-// contributors may be used to endorse or promote products derived from
-// this software without specific prior written permission.
-//
-// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-// ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
-#endregion
-
-using System;
-using Google.ProtocolBuffers.DescriptorProtos;
-using Google.ProtocolBuffers.Descriptors;
-
-namespace Google.ProtocolBuffers.ProtoGen
-{
-    internal class ServiceGenerator : SourceGeneratorBase<ServiceDescriptor>, ISourceGenerator
-    {
-        private readonly CSharpServiceType svcType;
-        private ISourceGenerator _generator;
-
-        internal ServiceGenerator(ServiceDescriptor descriptor)
-            : base(descriptor)
-        {
-            svcType = descriptor.File.CSharpOptions.ServiceGeneratorType;
-            switch (svcType)
-            {
-                case CSharpServiceType.NONE:
-                    _generator = new NoServicesGenerator(descriptor);
-                    break;
-                case CSharpServiceType.GENERIC:
-                    _generator = new GenericServiceGenerator(descriptor);
-                    break;
-                case CSharpServiceType.INTERFACE:
-                    _generator = new ServiceInterfaceGenerator(descriptor);
-                    break;
-                case CSharpServiceType.IRPCDISPATCH:
-                    _generator = new RpcServiceGenerator(descriptor);
-                    break;
-                default:
-                    throw new ApplicationException(""Unknown ServiceGeneratorType = "" + svcType.ToString());
-            }
-        }
-
-        public void Generate(TextGenerator writer)
-        {
-            _generator.Generate(writer);
-        }
-
-        private class NoServicesGenerator : SourceGeneratorBase<ServiceDescriptor>, ISourceGenerator
-        {
-            public NoServicesGenerator(ServiceDescriptor descriptor)
-                : base(descriptor)
-            {
-            }
-
-            public virtual void Generate(TextGenerator writer)
-            {
-                writer.WriteLine(""/*"");
-                writer.WriteLine(""* Service generation is now disabled by default, use the following option to enable:"");
-                writer.WriteLine(""* option (google.protobuf.csharp_file_options).service_generator_type = GENERIC;"");
-                writer.WriteLine(""*/"");
-            }
-        }
-
-        private class ServiceInterfaceGenerator : SourceGeneratorBase<ServiceDescriptor>, ISourceGenerator
-        {
-            public ServiceInterfaceGenerator(ServiceDescriptor descriptor)
-                : base(descriptor)
-            {
-            }
-
-            public virtual void Generate(TextGenerator writer)
-            {
-                CSharpServiceOptions options = Descriptor.Options.GetExtension(CSharpOptions.CsharpServiceOptions);
-                if (options != null && options.HasInterfaceId)
-                {
-                    writer.WriteLine(""[global::System.Runtime.InteropServices.GuidAttribute(\""{0}\"")]"",
-                                     new Guid(options.InterfaceId));
-                }
-                WriteGeneratedCodeAttributes(writer);
-                writer.WriteLine(""{0} partial interface I{1} {{"", ClassAccessLevel, Descriptor.Name);
-                writer.Indent();
-
-                foreach (MethodDescriptor method in Descriptor.Methods)
-                {
-                    CSharpMethodOptions mth = method.Options.GetExtension(CSharpOptions.CsharpMethodOptions);
-                    if (mth.HasDispatchId)
-                    {
-                        writer.WriteLine(""[global::System.Runtime.InteropServices.DispId({0})]"", mth.DispatchId);
-                    }
-                    writer.WriteLine(""{0} {1}({2} {3});"", GetClassName(method.OutputType),
-                                     NameHelpers.UnderscoresToPascalCase(method.Name), GetClassName(method.InputType),
-                                     NameHelpers.UnderscoresToCamelCase(method.InputType.Name));
-                }
-
-                writer.Outdent();
-                writer.WriteLine(""}"");
-            }
-        }
-
-        private class RpcServiceGenerator : ServiceInterfaceGenerator
-        {
-            public RpcServiceGenerator(ServiceDescriptor descriptor)
-                : base(descriptor)
-            {
-            }
-
-            public override void Generate(TextGenerator writer)
-            {
-                base.Generate(writer);
-
-                writer.WriteLine();
-
-                // CLIENT Proxy
-                {
-                    if (Descriptor.File.CSharpOptions.ClsCompliance)
-                    {
-                        writer.WriteLine(""[global::System.CLSCompliant(false)]"");
-                    }
-                    writer.WriteLine(""[global::System.Diagnostics.DebuggerNonUserCodeAttribute()]"");
-                    WriteGeneratedCodeAttributes(writer);
-                    writer.WriteLine(""{0} partial class {1} : I{1}, pb::IRpcDispatch, global::System.IDisposable {{"",
-                                     ClassAccessLevel, Descriptor.Name);
-                    writer.Indent();
-                    writer.WriteLine(""private readonly bool dispose;"");
-                    writer.WriteLine(""private readonly pb::IRpcDispatch dispatch;"");
-
-                    writer.WriteLine(""public {0}(pb::IRpcDispatch dispatch) : this(dispatch, true) {{"", Descriptor.Name);
-                    writer.WriteLine(""}"");
-                    writer.WriteLine(""public {0}(pb::IRpcDispatch dispatch, bool dispose) {{"", Descriptor.Name);
-                    writer.WriteLine(""  pb::ThrowHelper.ThrowIfNull(this.dispatch = dispatch, \""dispatch\"");"");
-                    writer.WriteLine(""  this.dispose = dispose && dispatch is global::System.IDisposable;"");
-                    writer.WriteLine(""}"");
-                    writer.WriteLine();
-
-                    writer.WriteLine(""public void Dispose() {"");
-                    writer.WriteLine(""  if (dispose) ((global::System.IDisposable)dispatch).Dispose();"");
-                    writer.WriteLine(""}"");
-                    writer.WriteLine();
-                    writer.WriteLine(
-                        ""TMessage pb::IRpcDispatch.CallMethod<TMessage, TBuilder>(string method, pb::IMessageLite request, pb::IBuilderLite<TMessage, TBuilder> response) {"");
-                    writer.WriteLine(""  return dispatch.CallMethod(method, request, response);"");
-                    writer.WriteLine(""}"");
-                    writer.WriteLine();
-
-                    foreach (MethodDescriptor method in Descriptor.Methods)
-                    {
-                        writer.WriteLine(""public {0} {1}({2} {3}) {{"", GetClassName(method.OutputType),
-                                         NameHelpers.UnderscoresToPascalCase(method.Name),
-                                         GetClassName(method.InputType),
-                                         NameHelpers.UnderscoresToCamelCase(method.InputType.Name));
-                        writer.WriteLine(""   return dispatch.CallMethod(\""{0}\"", {1}, {2}.CreateBuilder());"",
-                                         method.Name,
-                                         NameHelpers.UnderscoresToCamelCase(method.InputType.Name),
-                                         GetClassName(method.OutputType)
-                            );
-                        writer.WriteLine(""}"");
-                        writer.WriteLine();
-                    }
-                }
-                // SERVER - DISPATCH
-                {
-                    if (Descriptor.File.CSharpOptions.ClsCompliance)
-                    {
-                        writer.WriteLine(""[global::System.CLSCompliant(false)]"");
-                    }
-                    writer.WriteLine(""[global::System.Diagnostics.DebuggerNonUserCodeAttribute()]"");
-                    WriteGeneratedCodeAttributes(writer);
-                    writer.WriteLine(""public partial class Dispatch : pb::IRpcDispatch, global::System.IDisposable {"");
-                    writer.Indent();
-                    writer.WriteLine(""private readonly bool dispose;"");
-                    writer.WriteLine(""private readonly I{0} implementation;"", Descriptor.Name);
-
-                    writer.WriteLine(""public Dispatch(I{0} implementation) : this(implementation, true) {{"",
-                                     Descriptor.Name);
-                    writer.WriteLine(""}"");
-                    writer.WriteLine(""public Dispatch(I{0} implementation, bool dispose) {{"", Descriptor.Name);
-                    writer.WriteLine(""  pb::ThrowHelper.ThrowIfNull(this.implementation = implementation, \""implementation\"");"");
-                    writer.WriteLine(""  this.dispose = dispose && implementation is global::System.IDisposable;"");
-                    writer.WriteLine(""}"");
-                    writer.WriteLine();
-
-                    writer.WriteLine(""public void Dispose() {"");
-                    writer.WriteLine(""  if (dispose) ((global::System.IDisposable)implementation).Dispose();"");
-                    writer.WriteLine(""}"");
-                    writer.WriteLine();
-
-                    writer.WriteLine(
-                        ""public TMessage CallMethod<TMessage, TBuilder>(string methodName, pb::IMessageLite request, pb::IBuilderLite<TMessage, TBuilder> response)"");
-                    writer.WriteLine(""  where TMessage : pb::IMessageLite<TMessage, TBuilder>"");
-                    writer.WriteLine(""  where TBuilder : pb::IBuilderLite<TMessage, TBuilder> {"");
-                    writer.Indent();
-                    writer.WriteLine(""switch(methodName) {"");
-                    writer.Indent();
-
-                    foreach (MethodDescriptor method in Descriptor.Methods)
-                    {
-                        writer.WriteLine(
-                            ""case \""{0}\"": return response.MergeFrom(implementation.{1}(({2})request)).Build();"",
-                            method.Name, NameHelpers.UnderscoresToPascalCase(method.Name),
-                            GetClassName(method.InputType));
-                    }
-                    writer.WriteLine(""default: throw pb::ThrowHelper.CreateMissingMethod(typeof(I{0}), methodName);"", Descriptor.Name);
-                    writer.Outdent();
-                    writer.WriteLine(""}""); //end switch
-                    writer.Outdent();
-                    writer.WriteLine(""}""); //end invoke
-                    writer.Outdent();
-                    writer.WriteLine(""}""); //end server
-                }
-                // SERVER - STUB
-                {
-                    if (Descriptor.File.CSharpOptions.ClsCompliance)
-                    {
-                        writer.WriteLine(""[global::System.CLSCompliant(false)]"");
-                    }
-                    writer.WriteLine(""[global::System.Diagnostics.DebuggerNonUserCodeAttribute()]"");
-                    WriteGeneratedCodeAttributes(writer);
-                    writer.WriteLine(
-                        ""public partial class ServerStub : pb::IRpcServerStub, global::System.IDisposable {"");
-                    writer.Indent();
-                    writer.WriteLine(""private readonly bool dispose;"");
-                    writer.WriteLine(""private readonly pb::IRpcDispatch implementation;"", Descriptor.Name);
-
-                    writer.WriteLine(""public ServerStub(I{0} implementation) : this(implementation, true) {{"",
-                                     Descriptor.Name);
-                    writer.WriteLine(""}"");
-                    writer.WriteLine(
-                        ""public ServerStub(I{0} implementation, bool dispose) : this(new Dispatch(implementation, dispose), dispose) {{"",
-                        Descriptor.Name);
-                    writer.WriteLine(""}"");
-
-                    writer.WriteLine(""public ServerStub(pb::IRpcDispatch implementation) : this(implementation, true) {"");
-                    writer.WriteLine(""}"");
-                    writer.WriteLine(""public ServerStub(pb::IRpcDispatch implementation, bool dispose) {"");
-                    writer.WriteLine(""  pb::ThrowHelper.ThrowIfNull(this.implementation = implementation, \""implementation\"");"");
-                    writer.WriteLine(""  this.dispose = dispose && implementation is global::System.IDisposable;"");
-                    writer.WriteLine(""}"");
-                    writer.WriteLine();
-
-                    writer.WriteLine(""public void Dispose() {"");
-                    writer.WriteLine(""  if (dispose) ((global::System.IDisposable)implementation).Dispose();"");
-                    writer.WriteLine(""}"");
-                    writer.WriteLine();
-
-                    writer.WriteLine(
-                        ""public pb::IMessageLite CallMethod(string methodName, pb::ICodedInputStream input, pb::ExtensionRegistry registry) {{"",
-                        Descriptor.Name);
-                    writer.Indent();
-                    writer.WriteLine(""switch(methodName) {"");
-                    writer.Indent();
-
-                    foreach (MethodDescriptor method in Descriptor.Methods)
-                    {
-                        writer.WriteLine(
-                            ""case \""{0}\"": return implementation.CallMethod(methodName, {1}.ParseFrom(input, registry), {2}.CreateBuilder());"",
-                            method.Name, GetClassName(method.InputType), GetClassName(method.OutputType));
-                    }
-                    writer.WriteLine(""default: throw pb::ThrowHelper.CreateMissingMethod(typeof(I{0}), methodName);"", Descriptor.Name);
-                    writer.Outdent();
-                    writer.WriteLine(""}""); //end switch
-                    writer.Outdent();
-                    writer.WriteLine(""}""); //end invoke
-                    writer.Outdent();
-                    writer.WriteLine(""}""); //end server
-                }
-
-                writer.Outdent();
-                writer.WriteLine(""}"");
-            }
-        }
-    }
-}
\ No newline at end of file
diff --git a/csharp/src/ProtoGen/SourceGeneratorBase.cs b/csharp/src/ProtoGen/SourceGeneratorBase.cs
deleted file mode 100644
index 535c6f73c..000000000
--- a/csharp/src/ProtoGen/SourceGeneratorBase.cs
+++ /dev/null
@@ -1,167 +0,0 @@
-#region Copyright notice and license
-
-// Protocol Buffers - Google's data interchange format
-// Copyright 2008 Google Inc.  All rights reserved.
-// http://github.com/jskeet/dotnet-protobufs/
-// Original C++/Java/Python code:
-// http://code.google.com/p/protobuf/
-//
-// Redistribution and use in source and binary forms, with or without
-// modification, are permitted provided that the following conditions are
-// met:
-//
-//     * Redistributions of source code must retain the above copyright
-// notice, this list of conditions and the following disclaimer.
-//     * Redistributions in binary form must reproduce the above
-// copyright notice, this list of conditions and the following disclaimer
-// in the documentation and/or other materials provided with the
-// distribution.
-//     * Neither the name of Google Inc. nor the names of its
-// contributors may be used to endorse or promote products derived from
-// this software without specific prior written permission.
-//
-// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-// ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
-#endregion
-
-using System.Collections.Generic;
-using Google.ProtocolBuffers.DescriptorProtos;
-using Google.ProtocolBuffers.Descriptors;
-
-namespace Google.ProtocolBuffers.ProtoGen
-{
-    internal abstract class SourceGeneratorBase<T> where T : IDescriptor
-    {
-        private readonly T descriptor;
-
-        protected readonly bool OptimizeSpeed;
-        protected readonly bool OptimizeSize;
-        protected readonly bool UseLiteRuntime;
-        protected readonly string RuntimeSuffix;
-
-        protected SourceGeneratorBase(T descriptor)
-        {
-            this.descriptor = descriptor;
-
-            OptimizeSize = descriptor.File.Options.OptimizeFor ==
-                           FileOptions.Types.OptimizeMode.CODE_SIZE;
-            OptimizeSpeed = descriptor.File.Options.OptimizeFor ==
-                            FileOptions.Types.OptimizeMode.SPEED;
-            UseLiteRuntime = descriptor.File.Options.OptimizeFor ==
-                             FileOptions.Types.OptimizeMode.LITE_RUNTIME;
-            //Lite runtime uses OptimizeSpeed code branches
-            OptimizeSpeed |= UseLiteRuntime;
-            RuntimeSuffix = UseLiteRuntime ? ""Lite"" : """";
-        }
-
-        protected T Descriptor
-        {
-            get { return descriptor; }
-        }
-
-        internal static string GetClassName(IDescriptor descriptor)
-        {
-            return ToCSharpName(descriptor.FullName, descriptor.File);
-        }
-
-        // Groups are hacky:  The name of the field is just the lower-cased name
-        // of the group type.  In C#, though, we would like to retain the original
-        // capitalization of the type name.
-        internal static string GetFieldName(FieldDescriptor descriptor)
-        {
-            if (descriptor.FieldType == FieldType.Group)
-            {
-                return descriptor.MessageType.Name;
-            }
-            else
-            {
-                return descriptor.Name;
-            }
-        }
-
-        internal static string GetFieldConstantName(FieldDescriptor field)
-        {
-            return field.CSharpOptions.PropertyName + ""FieldNumber"";
-        }
-
-        private static string ToCSharpName(string name, FileDescriptor file)
-        {
-            string result = file.CSharpOptions.Namespace;
-            if (file.CSharpOptions.NestClasses)
-            {
-                if (result != """")
-                {
-                    result += ""."";
-                }
-                result += file.CSharpOptions.UmbrellaClassname;
-            }
-            if (result != """")
-            {
-                result += '.';
-            }
-            string classname;
-            if (file.Package == """")
-            {
-                classname = name;
-            }
-            else
-            {
-                // Strip the proto package from full_name since we've replaced it with
-                // the C# namespace.
-                classname = name.Substring(file.Package.Length + 1);
-            }
-            result += classname.Replace(""."", "".Types."");
-            return ""global::"" + result;
-        }
-
-        protected string ClassAccessLevel
-        {
-            get { return descriptor.File.CSharpOptions.PublicClasses ? ""public"" : ""internal""; }
-        }
-
-        protected void WriteGeneratedCodeAttributes(TextGenerator writer)
-        {
-            if (descriptor.File.CSharpOptions.GeneratedCodeAttributes)
-            {
-                writer.WriteLine(""[global::System.Runtime.CompilerServices.CompilerGeneratedAttribute()]"");
-                writer.WriteLine(""[global::System.CodeDom.Compiler.GeneratedCodeAttribute(\""{0}\"", \""{1}\"")]"",
-                                 GetType().Assembly.GetName().Name, GetType().Assembly.GetName().Version);
-            }
-        }
-
-        protected void WriteChildren<TChild>(TextGenerator writer, string region, IEnumerable<TChild> children)
-            where TChild : IDescriptor
-        {
-            // Copy the set of children; makes access easier
-            List<TChild> copy = new List<TChild>(children);
-            if (copy.Count == 0)
-            {
-                return;
-            }
-
-            if (region != null)
-            {
-                writer.WriteLine(""#region {0}"", region);
-            }
-            foreach (TChild child in children)
-            {
-                SourceGenerators.CreateGenerator(child).Generate(writer);
-            }
-            if (region != null)
-            {
-                writer.WriteLine(""#endregion"");
-                writer.WriteLine();
-            }
-        }
-    }
-}
\ No newline at end of file
diff --git a/csharp/src/ProtoGen/SourceGenerators.cs b/csharp/src/ProtoGen/SourceGenerators.cs
deleted file mode 100644
index 38458f05b..000000000
--- a/csharp/src/ProtoGen/SourceGenerators.cs
+++ /dev/null
@@ -1,87 +0,0 @@
-#region Copyright notice and license
-
-// Protocol Buffers - Google's data interchange format
-// Copyright 2008 Google Inc.  All rights reserved.
-// http://github.com/jskeet/dotnet-protobufs/
-// Original C++/Java/Python code:
-// http://code.google.com/p/protobuf/
-//
-// Redistribution and use in source and binary forms, with or without
-// modification, are permitted provided that the following conditions are
-// met:
-//
-//     * Redistributions of source code must retain the above copyright
-// notice, this list of conditions and the following disclaimer.
-//     * Redistributions in binary form must reproduce the above
-// copyright notice, this list of conditions and the following disclaimer
-// in the documentation and/or other materials provided with the
-// distribution.
-//     * Neither the name of Google Inc. nor the names of its
-// contributors may be used to endorse or promote products derived from
-// this software without specific prior written permission.
-//
-// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-// ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
-#endregion
-
-using System;
-using System.Collections.Generic;
-using Google.ProtocolBuffers.Descriptors;
-
-namespace Google.ProtocolBuffers.ProtoGen
-{
-    public delegate TResult Func<T, TResult>(T arg);
-
-    internal static class SourceGenerators
-    {
-        private static readonly Dictionary<Type, Func<IDescriptor, ISourceGenerator>> GeneratorFactories =
-            new Dictionary<Type, Func<IDescriptor, ISourceGenerator>>
-                {
-                    {typeof(FileDescriptor), descriptor => new UmbrellaClassGenerator((FileDescriptor) descriptor)},
-                    {typeof(EnumDescriptor), descriptor => new EnumGenerator((EnumDescriptor) descriptor)},
-                    {typeof(ServiceDescriptor), descriptor => new ServiceGenerator((ServiceDescriptor) descriptor)},
-                    {typeof(MessageDescriptor), descriptor => new MessageGenerator((MessageDescriptor) descriptor)},
-                    // For other fields, we have IFieldSourceGenerators.
-                    {typeof(FieldDescriptor), descriptor => new ExtensionGenerator((FieldDescriptor) descriptor)}
-                };
-
-        public static IFieldSourceGenerator CreateFieldGenerator(FieldDescriptor field, int fieldOrdinal)
-        {
-            switch (field.MappedType)
-            {
-                case MappedType.Message:
-                    return field.IsRepeated
-                               ? (IFieldSourceGenerator) new RepeatedMessageFieldGenerator(field, fieldOrdinal)
-                               : new MessageFieldGenerator(field, fieldOrdinal);
-                case MappedType.Enum:
-                    return field.IsRepeated
-                               ? (IFieldSourceGenerator) new RepeatedEnumFieldGenerator(field, fieldOrdinal)
-                               : new EnumFieldGenerator(field, fieldOrdinal);
-                default:
-                    return field.IsRepeated
-                               ? (IFieldSourceGenerator) new RepeatedPrimitiveFieldGenerator(field, fieldOrdinal)
-                               : new PrimitiveFieldGenerator(field, fieldOrdinal);
-            }
-        }
-
-        public static ISourceGenerator CreateGenerator<T>(T descriptor) where T : IDescriptor
-        {
-            Func<IDescriptor, ISourceGenerator> factory;
-            if (!GeneratorFactories.TryGetValue(typeof(T), out factory))
-            {
-                throw new ArgumentException(""No generator registered for "" + typeof(T).Name);
-            }
-            return factory(descriptor);
-        }
-    }
-}
\ No newline at end of file
diff --git a/csharp/src/ProtoGen/UmbrellaClassGenerator.cs b/csharp/src/ProtoGen/UmbrellaClassGenerator.cs
deleted file mode 100644
index d83b2dbd7..000000000
--- a/csharp/src/ProtoGen/UmbrellaClassGenerator.cs
+++ /dev/null
@@ -1,294 +0,0 @@
-// Protocol Buffers - Google's data interchange format
-// Copyright 2008 Google Inc.  All rights reserved.
-// http://github.com/jskeet/dotnet-protobufs/
-// Original C++/Java/Python code:
-// http://code.google.com/p/protobuf/
-//
-// Redistribution and use in source and binary forms, with or without
-// modification, are permitted provided that the following conditions are
-// met:
-//
-//     * Redistributions of source code must retain the above copyright
-// notice, this list of conditions and the following disclaimer.
-//     * Redistributions in binary form must reproduce the above
-// copyright notice, this list of conditions and the following disclaimer
-// in the documentation and/or other materials provided with the
-// distribution.
-//     * Neither the name of Google Inc. nor the names of its
-// contributors may be used to endorse or promote products derived from
-// this software without specific prior written permission.
-//
-// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-// ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-using System;
-using System.Collections;
-using System.Collections.Generic;
-using Google.ProtocolBuffers.Descriptors;
-
-namespace Google.ProtocolBuffers.ProtoGen
-{
-    /// <summary>
-    /// Generator for the class describing the .proto file in general,
-    /// containing things like the message descriptor.
-    /// </summary>
-    internal sealed class UmbrellaClassGenerator : SourceGeneratorBase<FileDescriptor>, ISourceGenerator
-    {
-        internal UmbrellaClassGenerator(FileDescriptor descriptor)
-            : base(descriptor)
-        {
-        }
-
-        // Recursively searches the given message to see if it contains any extensions.
-        private static bool UsesExtensions(IMessage message)
-        {
-            // We conservatively assume that unknown fields are extensions.
-            if (message.UnknownFields.FieldDictionary.Count > 0)
-            {
-                return true;
-            }
-
-            foreach (KeyValuePair<FieldDescriptor, object> keyValue in message.AllFields)
-            {
-                FieldDescriptor field = keyValue.Key;
-                if (field.IsExtension)
-                {
-                    return true;
-                }
-                if (field.MappedType == MappedType.Message)
-                {
-                    if (field.IsRepeated)
-                    {
-                        foreach (IMessage subMessage in (IEnumerable) keyValue.Value)
-                        {
-                            if (UsesExtensions(subMessage))
-                            {
-                                return true;
-                            }
-                        }
-                    }
-                    else
-                    {
-                        if (UsesExtensions((IMessage) keyValue.Value))
-                        {
-                            return true;
-                        }
-                    }
-                }
-            }
-            return false;
-        }
-
-        public void Generate(TextGenerator writer)
-        {
-            WriteIntroduction(writer);
-            WriteExtensionRegistration(writer);
-            WriteChildren(writer, ""Extensions"", Descriptor.Extensions);
-            writer.WriteLine(""#region Static variables"");
-            foreach (MessageDescriptor message in Descriptor.MessageTypes)
-            {
-                new MessageGenerator(message).GenerateStaticVariables(writer);
-            }
-            writer.WriteLine(""#endregion"");
-            if (!UseLiteRuntime)
-            {
-                WriteDescriptor(writer);
-            }
-            else
-            {
-                WriteLiteExtensions(writer);
-            }
-            // The class declaration either gets closed before or after the children are written.
-            if (!Descriptor.CSharpOptions.NestClasses)
-            {
-                writer.Outdent();
-                writer.WriteLine(""}"");
-
-                // Close the namespace around the umbrella class if defined
-                if (!Descriptor.CSharpOptions.NestClasses && Descriptor.CSharpOptions.UmbrellaNamespace != """")
-                {
-                    writer.Outdent();
-                    writer.WriteLine(""}"");
-                }
-            }
-            WriteChildren(writer, ""Enums"", Descriptor.EnumTypes);
-            WriteChildren(writer, ""Messages"", Descriptor.MessageTypes);
-            WriteChildren(writer, ""Services"", Descriptor.Services);
-            if (Descriptor.CSharpOptions.NestClasses)
-            {
-                writer.Outdent();
-                writer.WriteLine(""}"");
-            }
-            if (Descriptor.CSharpOptions.Namespace != """")
-            {
-                writer.Outdent();
-                writer.WriteLine(""}"");
-            }
-            writer.WriteLine();
-            writer.WriteLine(""#endregion Designer generated code"");
-        }
-
-        private void WriteIntroduction(TextGenerator writer)
-        {
-            writer.WriteLine(""// Generated by {0}.  DO NOT EDIT!"", this.GetType().Assembly.FullName);
-            writer.WriteLine(""#pragma warning disable 1591, 0612, 3021"");
-            writer.WriteLine(""#region Designer generated code"");
-
-            writer.WriteLine();
-            writer.WriteLine(""using pb = global::Google.ProtocolBuffers;"");
-            writer.WriteLine(""using pbc = global::Google.ProtocolBuffers.Collections;"");
-            writer.WriteLine(""using pbd = global::Google.ProtocolBuffers.Descriptors;"");
-            writer.WriteLine(""using scg = global::System.Collections.Generic;"");
-
-            if (Descriptor.CSharpOptions.Namespace != """")
-            {
-                writer.WriteLine(""namespace {0} {{"", Descriptor.CSharpOptions.Namespace);
-                writer.Indent();
-                writer.WriteLine();
-            }
-            // Add the namespace around the umbrella class if defined
-            if (!Descriptor.CSharpOptions.NestClasses && Descriptor.CSharpOptions.UmbrellaNamespace != """")
-            {
-                writer.WriteLine(""namespace {0} {{"", Descriptor.CSharpOptions.UmbrellaNamespace);
-                writer.Indent();
-                writer.WriteLine();
-            }
-
-            if (Descriptor.CSharpOptions.CodeContracts)
-            {
-                writer.WriteLine(""[global::System.Diagnostics.Contracts.ContractVerificationAttribute(false)]"");
-            }
-            writer.WriteLine(""[global::System.Diagnostics.DebuggerNonUserCodeAttribute()]"");
-            WriteGeneratedCodeAttributes(writer);
-            writer.WriteLine(""{0} static partial class {1} {{"", ClassAccessLevel,
-                             Descriptor.CSharpOptions.UmbrellaClassname);
-            writer.WriteLine();
-            writer.Indent();
-        }
-
-        private void WriteExtensionRegistration(TextGenerator writer)
-        {
-            writer.WriteLine(""#region Extension registration"");
-            writer.WriteLine(""public static void RegisterAllExtensions(pb::ExtensionRegistry registry) {"");
-            writer.Indent();
-            foreach (FieldDescriptor extension in Descriptor.Extensions)
-            {
-                new ExtensionGenerator(extension).GenerateExtensionRegistrationCode(writer);
-            }
-            foreach (MessageDescriptor message in Descriptor.MessageTypes)
-            {
-                new MessageGenerator(message).GenerateExtensionRegistrationCode(writer);
-            }
-            writer.Outdent();
-            writer.WriteLine(""}"");
-            writer.WriteLine(""#endregion"");
-        }
-
-        private void WriteDescriptor(TextGenerator writer)
-        {
-            writer.WriteLine(""#region Descriptor"");
-
-            writer.WriteLine(""public static pbd::FileDescriptor Descriptor {"");
-            writer.WriteLine(""  get { return descriptor; }"");
-            writer.WriteLine(""}"");
-            writer.WriteLine(""private static pbd::FileDescriptor descriptor;"");
-            writer.WriteLine();
-            writer.WriteLine(""static {0}() {{"", Descriptor.CSharpOptions.UmbrellaClassname);
-            writer.Indent();
-            writer.WriteLine(""byte[] descriptorData = global::System.Convert.FromBase64String("");
-            writer.Indent();
-            writer.Indent();
-            writer.WriteLine(""string.Concat("");
-            writer.Indent();
-            // TODO(jonskeet): Consider a C#-escaping format here instead of just Base64.
-            byte[] bytes = Descriptor.Proto.ToByteArray();
-            string base64 = Convert.ToBase64String(bytes);
-
-            while (base64.Length > 60)
-            {
-                writer.WriteLine(""\""{0}\"", "", base64.Substring(0, 60));
-                base64 = base64.Substring(60);
-            }
-            writer.Outdent();
-            writer.WriteLine(""\""{0}\""));"", base64);
-            writer.Outdent();
-            writer.Outdent();
-            writer.WriteLine(
-                ""pbd::FileDescriptor.InternalDescriptorAssigner assigner = delegate(pbd::FileDescriptor root) {"");
-            writer.Indent();
-            writer.WriteLine(""descriptor = root;"");
-            foreach (MessageDescriptor message in Descriptor.MessageTypes)
-            {
-                new MessageGenerator(message).GenerateStaticVariableInitializers(writer);
-            }
-            foreach (FieldDescriptor extension in Descriptor.Extensions)
-            {
-                new ExtensionGenerator(extension).GenerateStaticVariableInitializers(writer);
-            }
-
-            if (UsesExtensions(Descriptor.Proto))
-            {
-                // Must construct an ExtensionRegistry containing all possible extensions
-                // and return it.
-                writer.WriteLine(""pb::ExtensionRegistry registry = pb::ExtensionRegistry.CreateInstance();"");
-                writer.WriteLine(""RegisterAllExtensions(registry);"");
-                foreach (FileDescriptor dependency in Descriptor.Dependencies)
-                {
-                    writer.WriteLine(""{0}.RegisterAllExtensions(registry);"",
-                                     DescriptorUtil.GetFullUmbrellaClassName(dependency));
-                }
-                writer.WriteLine(""return registry;"");
-            }
-            else
-            {
-                writer.WriteLine(""return null;"");
-            }
-            writer.Outdent();
-            writer.WriteLine(""};"");
-
-            // -----------------------------------------------------------------
-            // Invoke internalBuildGeneratedFileFrom() to build the file.
-            writer.WriteLine(""pbd::FileDescriptor.InternalBuildGeneratedFileFrom(descriptorData,"");
-            writer.WriteLine(""    new pbd::FileDescriptor[] {"");
-            foreach (FileDescriptor dependency in Descriptor.Dependencies)
-            {
-                writer.WriteLine(""    {0}.Descriptor, "", DescriptorUtil.GetFullUmbrellaClassName(dependency));
-            }
-            writer.WriteLine(""    }, assigner);"");
-            writer.Outdent();
-            writer.WriteLine(""}"");
-            writer.WriteLine(""#endregion"");
-            writer.WriteLine();
-        }
-
-        private void WriteLiteExtensions(TextGenerator writer)
-        {
-            writer.WriteLine(""#region Extensions"");
-            writer.WriteLine(""internal static readonly object Descriptor;"");
-            writer.WriteLine(""static {0}() {{"", Descriptor.CSharpOptions.UmbrellaClassname);
-            writer.Indent();
-            writer.WriteLine(""Descriptor = null;"");
-
-            foreach (MessageDescriptor message in Descriptor.MessageTypes)
-            {
-                new MessageGenerator(message).GenerateStaticVariableInitializers(writer);
-            }
-            foreach (FieldDescriptor extension in Descriptor.Extensions)
-            {
-                new ExtensionGenerator(extension).GenerateStaticVariableInitializers(writer);
-            }
-            writer.Outdent();
-            writer.WriteLine(""}"");
-            writer.WriteLine(""#endregion"");
-            writer.WriteLine();
-        }
-    }
-}
\ No newline at end of file
diff --git a/csharp/src/ProtoGen/app.config b/csharp/src/ProtoGen/app.config
deleted file mode 100644
index 89b324bfe..000000000
--- a/csharp/src/ProtoGen/app.config
+++ /dev/null
@@ -1,7 +0,0 @@
-<?xml version=""1.0"" encoding=""utf-8"" ?>
-<configuration>
-  <startup useLegacyV2RuntimeActivationPolicy=""true"">
-    <supportedRuntime version=""v2.0.50727"" />
-    <supportedRuntime version=""v4.0"" sku="".NETFramework,Version=v4.0,Profile=Client"" />
-  </startup>
-</configuration>
\ No newline at end of file
diff --git a/csharp/src/ProtoGen/protoc-gen-cs.csproj b/csharp/src/ProtoGen/protoc-gen-cs.csproj
deleted file mode 100644
index fdc88cc2a..000000000
--- a/csharp/src/ProtoGen/protoc-gen-cs.csproj
+++ /dev/null
@@ -1,101 +0,0 @@
-<?xml version=""1.0"" encoding=""utf-8""?>
-<Project ToolsVersion=""4.0"" DefaultTargets=""Build"" xmlns=""http://schemas.microsoft.com/developer/msbuild/2003"">
-  <PropertyGroup>
-    <EnvironmentFlavor>CLIENTPROFILE</EnvironmentFlavor>
-    <EnvironmentTemplate>NET35</EnvironmentTemplate>
-    <Configuration Condition="" '$(Configuration)' == '' "">Debug</Configuration>
-    <Platform Condition="" '$(Platform)' == '' "">AnyCPU</Platform>
-    <ProductVersion>9.0.30729</ProductVersion>
-    <SchemaVersion>2.0</SchemaVersion>
-    <ProjectGuid>{250ADE34-82FD-4BAE-86D5-985FBE589C4B}</ProjectGuid>
-    <OutputType>Exe</OutputType>
-    <AppDesignerFolder>Properties</AppDesignerFolder>
-    <RootNamespace>Google.ProtocolBuffers.ProtoGen</RootNamespace>
-    <AssemblyName>protoc-gen-cs</AssemblyName>
-    <TargetFrameworkVersion>v3.5</TargetFrameworkVersion>
-    <FileAlignment>512</FileAlignment>
-    <SignAssembly>true</SignAssembly>
-    <AssemblyOriginatorKeyFile>..\..\keys\Google.ProtocolBuffers.snk</AssemblyOriginatorKeyFile>
-    <StartupObject>Google.ProtocolBuffers.ProtoGen.ProtocGenCs</StartupObject>
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Debug|AnyCPU' "">
-    <DebugSymbols>true</DebugSymbols>
-    <DebugType>full</DebugType>
-    <Optimize>false</Optimize>
-    <OutputPath>bin\NET35\Debug</OutputPath>
-    <IntermediateOutputPath>obj\NET35\Debug\</IntermediateOutputPath>
-    <DefineConstants>DEBUG;TRACE</DefineConstants>
-    <ErrorReport>prompt</ErrorReport>
-    <WarningLevel>4</WarningLevel>
-    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
-    <NoStdLib>true</NoStdLib>
-    <GenerateSerializationAssemblies>Off</GenerateSerializationAssemblies>
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Release|AnyCPU' "">
-    <DebugType>pdbonly</DebugType>
-    <Optimize>true</Optimize>
-    <OutputPath>bin\NET35\Release</OutputPath>
-    <IntermediateOutputPath>obj\NET35\Release\</IntermediateOutputPath>
-    <DefineConstants>TRACE</DefineConstants>
-    <ErrorReport>prompt</ErrorReport>
-    <WarningLevel>4</WarningLevel>
-    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
-    <NoStdLib>true</NoStdLib>
-    <GenerateSerializationAssemblies>Off</GenerateSerializationAssemblies>
-  </PropertyGroup>
-  <ItemGroup>
-    <Reference Include=""mscorlib"" />
-    <Reference Include=""System"" />
-    <Reference Include=""System.Data"" />
-    <Reference Include=""System.Xml"" />
-  </ItemGroup>
-  <ItemGroup>
-    <Compile Include=""DescriptorUtil.cs"" />
-    <Compile Include=""EnumFieldGenerator.cs"" />
-    <Compile Include=""EnumGenerator.cs"" />
-    <Compile Include=""ExtensionGenerator.cs"" />
-    <Compile Include=""FieldGeneratorBase.cs"" />
-    <Compile Include=""IFieldSourceGenerator.cs"" />
-    <Compile Include=""ISourceGenerator.cs"" />
-    <Compile Include=""MessageFieldGenerator.cs"" />
-    <Compile Include=""MessageGenerator.cs"" />
-    <Compile Include=""PluginProtoFile.cs"" />
-    <Compile Include=""PrimitiveFieldGenerator.cs"" />
-    <Compile Include=""ProtocGenCs.cs"" />
-    <Compile Include=""RepeatedEnumFieldGenerator.cs"" />
-    <Compile Include=""RepeatedMessageFieldGenerator.cs"" />
-    <Compile Include=""RepeatedPrimitiveFieldGenerator.cs"" />
-    <Compile Include=""ServiceGenerator.cs"" />
-    <Compile Include=""DependencyResolutionException.cs"" />
-    <Compile Include=""Generator.cs"" />
-    <Compile Include=""GeneratorOptions.cs"" />
-    <Compile Include=""Helpers.cs"" />
-    <Compile Include=""InvalidOptionsException.cs"" />
-    <Compile Include=""Properties\AssemblyInfo.cs"" />
-    <Compile Include=""ServiceInterfaceGenerator.cs"" />
-    <Compile Include=""SourceGeneratorBase.cs"" />
-    <Compile Include=""SourceGenerators.cs"" />
-    <Compile Include=""UmbrellaClassGenerator.cs"" />
-  </ItemGroup>
-  <ItemGroup>
-    <ProjectReference Include=""..\ProtocolBuffers.Serialization\ProtocolBuffers.Serialization.csproj"">
-      <Project>{231391af-449c-4a39-986c-ad7f270f4750}</Project>
-      <Name>ProtocolBuffers.Serialization</Name>
-    </ProjectReference>
-    <ProjectReference Include=""..\ProtocolBuffers\ProtocolBuffers.csproj"">
-      <Project>{6908BDCE-D925-43F3-94AC-A531E6DF2591}</Project>
-      <Name>ProtocolBuffers</Name>
-    </ProjectReference>
-  </ItemGroup>
-  <ItemGroup>
-    <None Include=""app.config"" />
-  </ItemGroup>
-  <Import Project=""$(MSBuildToolsPath)\Microsoft.CSharp.targets"" />
-  <!-- To modify your build process, add your task inside one of the targets below and uncomment it. 
-       Other similar extension points exist, see Microsoft.Common.targets.
-  <Target Name=""BeforeBuild"">
-  </Target>
-  <Target Name=""AfterBuild"">
-  </Target>
-  -->
-</Project>
\ No newline at end of file
diff --git a/csharp/src/ProtocolBuffers/ProtocolBuffers.CF20.csproj b/csharp/src/ProtocolBuffers/ProtocolBuffers.CF20.csproj
deleted file mode 100644
index bfadf1665..000000000
--- a/csharp/src/ProtocolBuffers/ProtocolBuffers.CF20.csproj
+++ /dev/null
@@ -1,166 +0,0 @@
-<Project ToolsVersion=""3.5"" DefaultTargets=""Build"" xmlns=""http://schemas.microsoft.com/developer/msbuild/2003"">
-  <PropertyGroup>
-    <EnvironmentFlavor>COMPACT_FRAMEWORK</EnvironmentFlavor>
-    <EnvironmentTemplate>CF20</EnvironmentTemplate>
-    <Configuration Condition="" '$(Configuration)' == '' "">Debug</Configuration>
-    <Platform Condition="" '$(Platform)' == '' "">AnyCPU</Platform>
-    <ProductVersion>9.0.30729</ProductVersion>
-    <SchemaVersion>2.0</SchemaVersion>
-    <ProjectGuid>{6908BDCE-D925-43F3-94AC-A531E6DF2591}</ProjectGuid>
-    <OutputType>Library</OutputType>
-    <AppDesignerFolder>Properties</AppDesignerFolder>
-    <RootNamespace>Google.ProtocolBuffers</RootNamespace>
-    <AssemblyName>Google.ProtocolBuffers</AssemblyName>
-    <TargetFrameworkVersion>v2.0</TargetFrameworkVersion>
-    <FileAlignment>512</FileAlignment>
-    <SignAssembly>true</SignAssembly>
-    <AssemblyOriginatorKeyFile>..\..\keys\Google.ProtocolBuffers.snk</AssemblyOriginatorKeyFile>
-    <OldToolsVersion>3.5</OldToolsVersion>
-    <ProjectTypeGuids>{4D628B5B-2FBC-4AA6-8C16-197242AEB884};{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}</ProjectTypeGuids>
-    <PlatformFamilyName>Smartphone</PlatformFamilyName>
-    <PlatformID>f27da329-3269-4191-98e0-c87d3d7f1db9</PlatformID>
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Debug|AnyCPU' "">
-    <DebugSymbols>true</DebugSymbols>
-    <DebugType>full</DebugType>
-    <Optimize>false</Optimize>
-    <OutputPath>bin\CF20\Debug</OutputPath>
-    <IntermediateOutputPath>obj\CF20\Debug\</IntermediateOutputPath>
-    <DocumentationFile>$(OutputPath)\$(AssemblyName).xml</DocumentationFile>
-    <NoWarn>1591, 1570, 1571, 1572, 1573, 1574</NoWarn>
-    <DefineConstants>DEBUG;TRACE;$(EnvironmentFlavor);$(EnvironmentTemplate);NOSERIALIZABLE;NOFILEVERSION;NOEXTENSIONS</DefineConstants>
-    <ErrorReport>prompt</ErrorReport>
-    <WarningLevel>4</WarningLevel>
-    <NoStdLib>true</NoStdLib>
-    <GenerateSerializationAssemblies>Off</GenerateSerializationAssemblies>
-    <NoConfig>true</NoConfig>
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Release|AnyCPU' "">
-    <DebugType>pdbonly</DebugType>
-    <Optimize>true</Optimize>
-    <OutputPath>bin\CF20\Release</OutputPath>
-    <IntermediateOutputPath>obj\CF20\Release\</IntermediateOutputPath>
-    <DocumentationFile>$(OutputPath)\$(AssemblyName).xml</DocumentationFile>
-    <NoWarn>1591, 1570, 1571, 1572, 1573, 1574</NoWarn>
-    <DefineConstants>TRACE;$(EnvironmentFlavor);$(EnvironmentTemplate);NOSERIALIZABLE;NOFILEVERSION;NOEXTENSIONS</DefineConstants>
-    <ErrorReport>prompt</ErrorReport>
-    <WarningLevel>4</WarningLevel>
-    <NoStdLib>true</NoStdLib>
-    <GenerateSerializationAssemblies>Off</GenerateSerializationAssemblies>
-    <NoConfig>true</NoConfig>
-  </PropertyGroup>
-  <ItemGroup>
-    <Reference Include=""mscorlib"" />
-    <Reference Include=""System"" />
-    <Reference Include=""System.Xml"" />
-  </ItemGroup>
-  <ItemGroup>
-    <Compile Include=""AbstractBuilder.cs"" />
-    <Compile Include=""AbstractBuilderLite.cs"" />
-    <Compile Include=""AbstractMessage.cs"" />
-    <Compile Include=""AbstractMessageLite.cs"" />
-    <Compile Include=""ByteArray.cs"" />
-    <Compile Include=""ByteString.cs"" />
-    <Compile Include=""Collections\Enumerables.cs"" />
-    <Compile Include=""Collections\IPopsicleList.cs"" />
-    <Compile Include=""Collections\PopsicleList.cs"" />
-    <Compile Include=""CodedOutputStream.ComputeSize.cs"" />
-    <Compile Include=""CustomSerialization.cs"" />
-    <Compile Include=""Delegates.cs"" />
-    <Compile Include=""CodedInputStream.cs"" />
-    <Compile Include=""CodedOutputStream.cs"" />
-    <Compile Include=""Collections\Dictionaries.cs"" />
-    <Compile Include=""Collections\Lists.cs"" />
-    <Compile Include=""Collections\ReadOnlyDictionary.cs"" />
-    <Compile Include=""DescriptorProtos\CSharpOptions.cs"" />
-    <Compile Include=""DescriptorProtos\DescriptorProtoFile.cs"" />
-    <Compile Include=""DescriptorProtos\IDescriptorProto.cs"" />
-    <Compile Include=""DescriptorProtos\PartialClasses.cs"" />
-    <Compile Include=""Descriptors\DescriptorBase.cs"" />
-    <Compile Include=""Descriptors\DescriptorPool.cs"" />
-    <Compile Include=""Descriptors\DescriptorUtil.cs"" />
-    <Compile Include=""Descriptors\DescriptorValidationException.cs"" />
-    <Compile Include=""Descriptors\EnumDescriptor.cs"" />
-    <Compile Include=""Descriptors\EnumValueDescriptor.cs"" />
-    <Compile Include=""Descriptors\FieldDescriptor.cs"" />
-    <Compile Include=""Descriptors\FieldMappingAttribute.cs"" />
-    <Compile Include=""Descriptors\FieldType.cs"" />
-    <Compile Include=""Descriptors\FileDescriptor.cs"" />
-    <Compile Include=""Descriptors\IDescriptor.cs"" />
-    <Compile Include=""Descriptors\IndexedDescriptorBase.cs"" />
-    <Compile Include=""Descriptors\MappedType.cs"" />
-    <Compile Include=""Descriptors\MessageDescriptor.cs"" />
-    <Compile Include=""Descriptors\MethodDescriptor.cs"" />
-    <Compile Include=""Descriptors\PackageDescriptor.cs"" />
-    <Compile Include=""Descriptors\ServiceDescriptor.cs"" />
-    <Compile Include=""DynamicMessage.cs"" />
-    <Compile Include=""EnumLite.cs"" />
-    <Compile Include=""ExtendableBuilder.cs"" />
-    <Compile Include=""ExtendableBuilderLite.cs"" />
-    <Compile Include=""ExtendableMessage.cs"" />
-    <Compile Include=""ExtendableMessageLite.cs"" />
-    <Compile Include=""ExtensionInfo.cs"" />
-    <Compile Include=""ExtensionRegistry.cs"" />
-    <Compile Include=""ExtensionRegistryLite.cs"" />
-    <Compile Include=""FieldAccess\ReflectionUtil.cs"" />
-    <Compile Include=""FieldAccess\SingleEnumAccessor.cs"" />
-    <Compile Include=""FieldAccess\SingleMessageAccessor.cs"" />
-    <Compile Include=""FieldAccess\SinglePrimitiveAccessor.cs"" />
-    <Compile Include=""FieldAccess\RepeatedPrimitiveAccessor.cs"" />
-    <Compile Include=""FieldAccess\RepeatedEnumAccessor.cs"" />
-    <Compile Include=""FieldAccess\IFieldAccessor.cs"" />
-    <Compile Include=""FieldAccess\FieldAccessorTable.cs"" />
-    <Compile Include=""FieldAccess\RepeatedMessageAccessor.cs"" />
-    <Compile Include=""FieldSet.cs"" />
-    <Compile Include=""FrameworkPortability.cs"" />
-    <Compile Include=""GeneratedBuilder.cs"" />
-    <Compile Include=""GeneratedBuilderLite.cs"" />
-    <Compile Include=""GeneratedExtensionLite.cs"" />
-    <Compile Include=""GeneratedMessageLite.cs"" />
-    <Compile Include=""GeneratedRepeatExtension.cs"" />
-    <Compile Include=""GeneratedSingleExtension.cs"" />
-    <Compile Include=""GeneratedMessage.cs"" />
-    <Compile Include=""IBuilder.cs"" />
-    <Compile Include=""GeneratedExtensionBase.cs"" />
-    <Compile Include=""IBuilderLite.cs"" />
-    <Compile Include=""ICodedInputStream.cs"" />
-    <Compile Include=""ICodedOutputStream.cs"" />
-    <Compile Include=""IMessage.cs"" />
-    <Compile Include=""IMessageLite.cs"" />
-    <Compile Include=""InvalidProtocolBufferException.cs"" />
-    <Compile Include=""IRpcChannel.cs"" />
-    <Compile Include=""IRpcController.cs"" />
-    <Compile Include=""IRpcDispatch.cs"" />
-    <Compile Include=""IService.cs"" />
-    <Compile Include=""MessageStreamIterator.cs"" />
-    <Compile Include=""MessageStreamWriter.cs"" />
-    <Compile Include=""MessageUtil.cs"" />
-    <Compile Include=""NameHelpers.cs"" />
-    <Compile Include=""Properties\AssemblyInfo.cs"" />
-    <Compile Include=""RpcUtil.cs"" />
-    <Compile Include=""SortedList.cs"" />
-    <Compile Include=""TextFormat.cs"" />
-    <Compile Include=""TextGenerator.cs"" />
-    <Compile Include=""TextTokenizer.cs"" />
-    <Compile Include=""ThrowHelper.cs"" />
-    <Compile Include=""UninitializedMessageException.cs"" />
-    <Compile Include=""UnknownField.cs"" />
-    <Compile Include=""UnknownFieldSet.cs"" />
-    <Compile Include=""WireFormat.cs"" />
-  </ItemGroup>
-  <Import Project=""$(MSBuildBinPath)\Microsoft.CompactFramework.CSharp.targets"" />
-  <ProjectExtensions>
-    <VisualStudio>
-      <FlavorProperties GUID=""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"">
-        <HostingProcess disable=""1"" />
-      </FlavorProperties>
-    </VisualStudio>
-  </ProjectExtensions>
-  <!-- To modify your build process, add your task inside one of the targets below and uncomment it. 
-       Other similar extension points exist, see Microsoft.Common.targets.
-  <Target Name=""BeforeBuild"">
-  </Target>
-  <Target Name=""AfterBuild"">
-  </Target>
-  -->
-</Project>
\ No newline at end of file
diff --git a/csharp/src/ProtocolBuffers/ProtocolBuffers.CF35.csproj b/csharp/src/ProtocolBuffers/ProtocolBuffers.CF35.csproj
deleted file mode 100644
index 72e35c172..000000000
--- a/csharp/src/ProtocolBuffers/ProtocolBuffers.CF35.csproj
+++ /dev/null
@@ -1,167 +0,0 @@
-<Project ToolsVersion=""3.5"" DefaultTargets=""Build"" xmlns=""http://schemas.microsoft.com/developer/msbuild/2003"">
-  <PropertyGroup>
-    <EnvironmentFlavor>COMPACT_FRAMEWORK</EnvironmentFlavor>
-    <EnvironmentTemplate>CF35</EnvironmentTemplate>
-    <Configuration Condition="" '$(Configuration)' == '' "">Debug</Configuration>
-    <Platform Condition="" '$(Platform)' == '' "">AnyCPU</Platform>
-    <ProductVersion>9.0.30729</ProductVersion>
-    <SchemaVersion>2.0</SchemaVersion>
-    <ProjectGuid>{6908BDCE-D925-43F3-94AC-A531E6DF2591}</ProjectGuid>
-    <OutputType>Library</OutputType>
-    <AppDesignerFolder>Properties</AppDesignerFolder>
-    <RootNamespace>Google.ProtocolBuffers</RootNamespace>
-    <AssemblyName>Google.ProtocolBuffers</AssemblyName>
-    <TargetFrameworkVersion>v3.5</TargetFrameworkVersion>
-    <FileAlignment>512</FileAlignment>
-    <SignAssembly>true</SignAssembly>
-    <AssemblyOriginatorKeyFile>..\..\keys\Google.ProtocolBuffers.snk</AssemblyOriginatorKeyFile>
-    <OldToolsVersion>3.5</OldToolsVersion>
-    <ProjectTypeGuids>{4D628B5B-2FBC-4AA6-8C16-197242AEB884};{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}</ProjectTypeGuids>
-    <PlatformFamilyName>Smartphone</PlatformFamilyName>
-    <PlatformID>f27da329-3269-4191-98e0-c87d3d7f1db9</PlatformID>
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Debug|AnyCPU' "">
-    <DebugSymbols>true</DebugSymbols>
-    <DebugType>full</DebugType>
-    <Optimize>false</Optimize>
-    <OutputPath>bin\CF35\Debug</OutputPath>
-    <IntermediateOutputPath>obj\CF35\Debug\</IntermediateOutputPath>
-    <DocumentationFile>$(OutputPath)\$(AssemblyName).xml</DocumentationFile>
-    <NoWarn>1591, 1570, 1571, 1572, 1573, 1574</NoWarn>
-    <DefineConstants>DEBUG;TRACE;$(EnvironmentFlavor);$(EnvironmentTemplate);NOSERIALIZABLE;NOFILEVERSION</DefineConstants>
-    <ErrorReport>prompt</ErrorReport>
-    <WarningLevel>4</WarningLevel>
-    <NoStdLib>true</NoStdLib>
-    <GenerateSerializationAssemblies>Off</GenerateSerializationAssemblies>
-    <NoConfig>true</NoConfig>
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Release|AnyCPU' "">
-    <DebugType>pdbonly</DebugType>
-    <Optimize>true</Optimize>
-    <OutputPath>bin\CF35\Release</OutputPath>
-    <IntermediateOutputPath>obj\CF35\Release\</IntermediateOutputPath>
-    <DocumentationFile>$(OutputPath)\$(AssemblyName).xml</DocumentationFile>
-    <NoWarn>1591, 1570, 1571, 1572, 1573, 1574</NoWarn>
-    <DefineConstants>TRACE;$(EnvironmentFlavor);$(EnvironmentTemplate);NOSERIALIZABLE;NOFILEVERSION</DefineConstants>
-    <ErrorReport>prompt</ErrorReport>
-    <WarningLevel>4</WarningLevel>
-    <NoStdLib>true</NoStdLib>
-    <GenerateSerializationAssemblies>Off</GenerateSerializationAssemblies>
-    <NoConfig>true</NoConfig>
-  </PropertyGroup>
-  <ItemGroup>
-    <Reference Include=""mscorlib"" />
-    <Reference Include=""System"" />
-    <Reference Include=""System.Xml"" />
-    <Reference Include=""System.Core"" />
-  </ItemGroup>
-  <ItemGroup>
-    <Compile Include=""AbstractBuilder.cs"" />
-    <Compile Include=""AbstractBuilderLite.cs"" />
-    <Compile Include=""AbstractMessage.cs"" />
-    <Compile Include=""AbstractMessageLite.cs"" />
-    <Compile Include=""ByteArray.cs"" />
-    <Compile Include=""ByteString.cs"" />
-    <Compile Include=""Collections\Enumerables.cs"" />
-    <Compile Include=""Collections\IPopsicleList.cs"" />
-    <Compile Include=""Collections\PopsicleList.cs"" />
-    <Compile Include=""CodedOutputStream.ComputeSize.cs"" />
-    <Compile Include=""CustomSerialization.cs"" />
-    <Compile Include=""Delegates.cs"" />
-    <Compile Include=""CodedInputStream.cs"" />
-    <Compile Include=""CodedOutputStream.cs"" />
-    <Compile Include=""Collections\Dictionaries.cs"" />
-    <Compile Include=""Collections\Lists.cs"" />
-    <Compile Include=""Collections\ReadOnlyDictionary.cs"" />
-    <Compile Include=""DescriptorProtos\CSharpOptions.cs"" />
-    <Compile Include=""DescriptorProtos\DescriptorProtoFile.cs"" />
-    <Compile Include=""DescriptorProtos\IDescriptorProto.cs"" />
-    <Compile Include=""DescriptorProtos\PartialClasses.cs"" />
-    <Compile Include=""Descriptors\DescriptorBase.cs"" />
-    <Compile Include=""Descriptors\DescriptorPool.cs"" />
-    <Compile Include=""Descriptors\DescriptorUtil.cs"" />
-    <Compile Include=""Descriptors\DescriptorValidationException.cs"" />
-    <Compile Include=""Descriptors\EnumDescriptor.cs"" />
-    <Compile Include=""Descriptors\EnumValueDescriptor.cs"" />
-    <Compile Include=""Descriptors\FieldDescriptor.cs"" />
-    <Compile Include=""Descriptors\FieldMappingAttribute.cs"" />
-    <Compile Include=""Descriptors\FieldType.cs"" />
-    <Compile Include=""Descriptors\FileDescriptor.cs"" />
-    <Compile Include=""Descriptors\IDescriptor.cs"" />
-    <Compile Include=""Descriptors\IndexedDescriptorBase.cs"" />
-    <Compile Include=""Descriptors\MappedType.cs"" />
-    <Compile Include=""Descriptors\MessageDescriptor.cs"" />
-    <Compile Include=""Descriptors\MethodDescriptor.cs"" />
-    <Compile Include=""Descriptors\PackageDescriptor.cs"" />
-    <Compile Include=""Descriptors\ServiceDescriptor.cs"" />
-    <Compile Include=""DynamicMessage.cs"" />
-    <Compile Include=""EnumLite.cs"" />
-    <Compile Include=""ExtendableBuilder.cs"" />
-    <Compile Include=""ExtendableBuilderLite.cs"" />
-    <Compile Include=""ExtendableMessage.cs"" />
-    <Compile Include=""ExtendableMessageLite.cs"" />
-    <Compile Include=""ExtensionInfo.cs"" />
-    <Compile Include=""ExtensionRegistry.cs"" />
-    <Compile Include=""ExtensionRegistryLite.cs"" />
-    <Compile Include=""FieldAccess\ReflectionUtil.cs"" />
-    <Compile Include=""FieldAccess\SingleEnumAccessor.cs"" />
-    <Compile Include=""FieldAccess\SingleMessageAccessor.cs"" />
-    <Compile Include=""FieldAccess\SinglePrimitiveAccessor.cs"" />
-    <Compile Include=""FieldAccess\RepeatedPrimitiveAccessor.cs"" />
-    <Compile Include=""FieldAccess\RepeatedEnumAccessor.cs"" />
-    <Compile Include=""FieldAccess\IFieldAccessor.cs"" />
-    <Compile Include=""FieldAccess\FieldAccessorTable.cs"" />
-    <Compile Include=""FieldAccess\RepeatedMessageAccessor.cs"" />
-    <Compile Include=""FieldSet.cs"" />
-    <Compile Include=""FrameworkPortability.cs"" />
-    <Compile Include=""GeneratedBuilder.cs"" />
-    <Compile Include=""GeneratedBuilderLite.cs"" />
-    <Compile Include=""GeneratedExtensionLite.cs"" />
-    <Compile Include=""GeneratedMessageLite.cs"" />
-    <Compile Include=""GeneratedRepeatExtension.cs"" />
-    <Compile Include=""GeneratedSingleExtension.cs"" />
-    <Compile Include=""GeneratedMessage.cs"" />
-    <Compile Include=""IBuilder.cs"" />
-    <Compile Include=""GeneratedExtensionBase.cs"" />
-    <Compile Include=""IBuilderLite.cs"" />
-    <Compile Include=""ICodedInputStream.cs"" />
-    <Compile Include=""ICodedOutputStream.cs"" />
-    <Compile Include=""IMessage.cs"" />
-    <Compile Include=""IMessageLite.cs"" />
-    <Compile Include=""InvalidProtocolBufferException.cs"" />
-    <Compile Include=""IRpcChannel.cs"" />
-    <Compile Include=""IRpcController.cs"" />
-    <Compile Include=""IRpcDispatch.cs"" />
-    <Compile Include=""IService.cs"" />
-    <Compile Include=""MessageStreamIterator.cs"" />
-    <Compile Include=""MessageStreamWriter.cs"" />
-    <Compile Include=""MessageUtil.cs"" />
-    <Compile Include=""NameHelpers.cs"" />
-    <Compile Include=""Properties\AssemblyInfo.cs"" />
-    <Compile Include=""RpcUtil.cs"" />
-    <Compile Include=""SortedList.cs"" />
-    <Compile Include=""TextFormat.cs"" />
-    <Compile Include=""TextGenerator.cs"" />
-    <Compile Include=""TextTokenizer.cs"" />
-    <Compile Include=""ThrowHelper.cs"" />
-    <Compile Include=""UninitializedMessageException.cs"" />
-    <Compile Include=""UnknownField.cs"" />
-    <Compile Include=""UnknownFieldSet.cs"" />
-    <Compile Include=""WireFormat.cs"" />
-  </ItemGroup>
-  <Import Project=""$(MSBuildBinPath)\Microsoft.CompactFramework.CSharp.targets"" />
-  <ProjectExtensions>
-    <VisualStudio>
-      <FlavorProperties GUID=""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"">
-        <HostingProcess disable=""1"" />
-      </FlavorProperties>
-    </VisualStudio>
-  </ProjectExtensions>
-  <!-- To modify your build process, add your task inside one of the targets below and uncomment it. 
-       Other similar extension points exist, see Microsoft.Common.targets.
-  <Target Name=""BeforeBuild"">
-  </Target>
-  <Target Name=""AfterBuild"">
-  </Target>
-  -->
-</Project>
\ No newline at end of file
diff --git a/csharp/src/ProtocolBuffers/ProtocolBuffers.NET20.csproj b/csharp/src/ProtocolBuffers/ProtocolBuffers.NET20.csproj
deleted file mode 100644
index 9bba72853..000000000
--- a/csharp/src/ProtocolBuffers/ProtocolBuffers.NET20.csproj
+++ /dev/null
@@ -1,154 +0,0 @@
-<Project ToolsVersion=""3.5"" DefaultTargets=""Build"" xmlns=""http://schemas.microsoft.com/developer/msbuild/2003"">
-  <PropertyGroup>
-    <EnvironmentFlavor>CLIENTPROFILE</EnvironmentFlavor>
-    <EnvironmentTemplate>NET20</EnvironmentTemplate>
-    <Configuration Condition="" '$(Configuration)' == '' "">Debug</Configuration>
-    <Platform Condition="" '$(Platform)' == '' "">AnyCPU</Platform>
-    <ProductVersion>9.0.30729</ProductVersion>
-    <SchemaVersion>2.0</SchemaVersion>
-    <ProjectGuid>{6908BDCE-D925-43F3-94AC-A531E6DF2591}</ProjectGuid>
-    <OutputType>Library</OutputType>
-    <AppDesignerFolder>Properties</AppDesignerFolder>
-    <RootNamespace>Google.ProtocolBuffers</RootNamespace>
-    <AssemblyName>Google.ProtocolBuffers</AssemblyName>
-    <TargetFrameworkVersion>v2.0</TargetFrameworkVersion>
-    <FileAlignment>512</FileAlignment>
-    <SignAssembly>true</SignAssembly>
-    <AssemblyOriginatorKeyFile>..\..\keys\Google.ProtocolBuffers.snk</AssemblyOriginatorKeyFile>
-    <OldToolsVersion>3.5</OldToolsVersion>
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Debug|AnyCPU' "">
-    <DebugSymbols>true</DebugSymbols>
-    <DebugType>full</DebugType>
-    <Optimize>false</Optimize>
-    <OutputPath>bin\NET20\Debug</OutputPath>
-    <IntermediateOutputPath>obj\NET20\Debug\</IntermediateOutputPath>
-    <DocumentationFile>$(OutputPath)\$(AssemblyName).xml</DocumentationFile>
-    <NoWarn>1591, 1570, 1571, 1572, 1573, 1574</NoWarn>
-    <DefineConstants>DEBUG;TRACE;$(EnvironmentFlavor);$(EnvironmentTemplate);NOEXTENSIONS</DefineConstants>
-    <ErrorReport>prompt</ErrorReport>
-    <WarningLevel>4</WarningLevel>
-    <NoStdLib>true</NoStdLib>
-    <GenerateSerializationAssemblies>Off</GenerateSerializationAssemblies>
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Release|AnyCPU' "">
-    <DebugType>pdbonly</DebugType>
-    <Optimize>true</Optimize>
-    <OutputPath>bin\NET20\Release</OutputPath>
-    <IntermediateOutputPath>obj\NET20\Release\</IntermediateOutputPath>
-    <DocumentationFile>$(OutputPath)\$(AssemblyName).xml</DocumentationFile>
-    <NoWarn>1591, 1570, 1571, 1572, 1573, 1574</NoWarn>
-    <DefineConstants>TRACE;$(EnvironmentFlavor);$(EnvironmentTemplate);NOEXTENSIONS</DefineConstants>
-    <ErrorReport>prompt</ErrorReport>
-    <WarningLevel>4</WarningLevel>
-    <NoStdLib>true</NoStdLib>
-    <GenerateSerializationAssemblies>Off</GenerateSerializationAssemblies>
-  </PropertyGroup>
-  <ItemGroup>
-    <Reference Include=""mscorlib"" />
-    <Reference Include=""System"" />
-    <Reference Include=""System.Xml"" />
-  </ItemGroup>
-  <ItemGroup>
-    <Compile Include=""AbstractBuilder.cs"" />
-    <Compile Include=""AbstractBuilderLite.cs"" />
-    <Compile Include=""AbstractMessage.cs"" />
-    <Compile Include=""AbstractMessageLite.cs"" />
-    <Compile Include=""ByteArray.cs"" />
-    <Compile Include=""ByteString.cs"" />
-    <Compile Include=""Collections\Enumerables.cs"" />
-    <Compile Include=""Collections\IPopsicleList.cs"" />
-    <Compile Include=""Collections\PopsicleList.cs"" />
-    <Compile Include=""CodedOutputStream.ComputeSize.cs"" />
-    <Compile Include=""CustomSerialization.cs"" />
-    <Compile Include=""Delegates.cs"" />
-    <Compile Include=""CodedInputStream.cs"" />
-    <Compile Include=""CodedOutputStream.cs"" />
-    <Compile Include=""Collections\Dictionaries.cs"" />
-    <Compile Include=""Collections\Lists.cs"" />
-    <Compile Include=""Collections\ReadOnlyDictionary.cs"" />
-    <Compile Include=""DescriptorProtos\CSharpOptions.cs"" />
-    <Compile Include=""DescriptorProtos\DescriptorProtoFile.cs"" />
-    <Compile Include=""DescriptorProtos\IDescriptorProto.cs"" />
-    <Compile Include=""DescriptorProtos\PartialClasses.cs"" />
-    <Compile Include=""Descriptors\DescriptorBase.cs"" />
-    <Compile Include=""Descriptors\DescriptorPool.cs"" />
-    <Compile Include=""Descriptors\DescriptorUtil.cs"" />
-    <Compile Include=""Descriptors\DescriptorValidationException.cs"" />
-    <Compile Include=""Descriptors\EnumDescriptor.cs"" />
-    <Compile Include=""Descriptors\EnumValueDescriptor.cs"" />
-    <Compile Include=""Descriptors\FieldDescriptor.cs"" />
-    <Compile Include=""Descriptors\FieldMappingAttribute.cs"" />
-    <Compile Include=""Descriptors\FieldType.cs"" />
-    <Compile Include=""Descriptors\FileDescriptor.cs"" />
-    <Compile Include=""Descriptors\IDescriptor.cs"" />
-    <Compile Include=""Descriptors\IndexedDescriptorBase.cs"" />
-    <Compile Include=""Descriptors\MappedType.cs"" />
-    <Compile Include=""Descriptors\MessageDescriptor.cs"" />
-    <Compile Include=""Descriptors\MethodDescriptor.cs"" />
-    <Compile Include=""Descriptors\PackageDescriptor.cs"" />
-    <Compile Include=""Descriptors\ServiceDescriptor.cs"" />
-    <Compile Include=""DynamicMessage.cs"" />
-    <Compile Include=""EnumLite.cs"" />
-    <Compile Include=""ExtendableBuilder.cs"" />
-    <Compile Include=""ExtendableBuilderLite.cs"" />
-    <Compile Include=""ExtendableMessage.cs"" />
-    <Compile Include=""ExtendableMessageLite.cs"" />
-    <Compile Include=""ExtensionInfo.cs"" />
-    <Compile Include=""ExtensionRegistry.cs"" />
-    <Compile Include=""ExtensionRegistryLite.cs"" />
-    <Compile Include=""FieldAccess\ReflectionUtil.cs"" />
-    <Compile Include=""FieldAccess\SingleEnumAccessor.cs"" />
-    <Compile Include=""FieldAccess\SingleMessageAccessor.cs"" />
-    <Compile Include=""FieldAccess\SinglePrimitiveAccessor.cs"" />
-    <Compile Include=""FieldAccess\RepeatedPrimitiveAccessor.cs"" />
-    <Compile Include=""FieldAccess\RepeatedEnumAccessor.cs"" />
-    <Compile Include=""FieldAccess\IFieldAccessor.cs"" />
-    <Compile Include=""FieldAccess\FieldAccessorTable.cs"" />
-    <Compile Include=""FieldAccess\RepeatedMessageAccessor.cs"" />
-    <Compile Include=""FieldSet.cs"" />
-    <Compile Include=""FrameworkPortability.cs"" />
-    <Compile Include=""GeneratedBuilder.cs"" />
-    <Compile Include=""GeneratedBuilderLite.cs"" />
-    <Compile Include=""GeneratedExtensionLite.cs"" />
-    <Compile Include=""GeneratedMessageLite.cs"" />
-    <Compile Include=""GeneratedRepeatExtension.cs"" />
-    <Compile Include=""GeneratedSingleExtension.cs"" />
-    <Compile Include=""GeneratedMessage.cs"" />
-    <Compile Include=""IBuilder.cs"" />
-    <Compile Include=""GeneratedExtensionBase.cs"" />
-    <Compile Include=""IBuilderLite.cs"" />
-    <Compile Include=""ICodedInputStream.cs"" />
-    <Compile Include=""ICodedOutputStream.cs"" />
-    <Compile Include=""IMessage.cs"" />
-    <Compile Include=""IMessageLite.cs"" />
-    <Compile Include=""InvalidProtocolBufferException.cs"" />
-    <Compile Include=""IRpcChannel.cs"" />
-    <Compile Include=""IRpcController.cs"" />
-    <Compile Include=""IRpcDispatch.cs"" />
-    <Compile Include=""IService.cs"" />
-    <Compile Include=""MessageStreamIterator.cs"" />
-    <Compile Include=""MessageStreamWriter.cs"" />
-    <Compile Include=""MessageUtil.cs"" />
-    <Compile Include=""NameHelpers.cs"" />
-    <Compile Include=""Properties\AssemblyInfo.cs"" />
-    <Compile Include=""RpcUtil.cs"" />
-    <Compile Include=""SortedList.cs"" />
-    <Compile Include=""TextFormat.cs"" />
-    <Compile Include=""TextGenerator.cs"" />
-    <Compile Include=""TextTokenizer.cs"" />
-    <Compile Include=""ThrowHelper.cs"" />
-    <Compile Include=""UninitializedMessageException.cs"" />
-    <Compile Include=""UnknownField.cs"" />
-    <Compile Include=""UnknownFieldSet.cs"" />
-    <Compile Include=""WireFormat.cs"" />
-  </ItemGroup>
-  <Import Project=""$(MSBuildToolsPath)\Microsoft.CSharp.targets"" />
-  <!-- To modify your build process, add your task inside one of the targets below and uncomment it. 
-       Other similar extension points exist, see Microsoft.Common.targets.
-  <Target Name=""BeforeBuild"">
-  </Target>
-  <Target Name=""AfterBuild"">
-  </Target>
-  -->
-</Project>
\ No newline at end of file
diff --git a/csharp/src/ProtocolBuffers/ProtocolBuffers.NET35.csproj b/csharp/src/ProtocolBuffers/ProtocolBuffers.NET35.csproj
deleted file mode 100644
index 6a79d9213..000000000
--- a/csharp/src/ProtocolBuffers/ProtocolBuffers.NET35.csproj
+++ /dev/null
@@ -1,155 +0,0 @@
-<Project ToolsVersion=""3.5"" DefaultTargets=""Build"" xmlns=""http://schemas.microsoft.com/developer/msbuild/2003"">
-  <PropertyGroup>
-    <EnvironmentFlavor>CLIENTPROFILE</EnvironmentFlavor>
-    <EnvironmentTemplate>NET35</EnvironmentTemplate>
-    <Configuration Condition="" '$(Configuration)' == '' "">Debug</Configuration>
-    <Platform Condition="" '$(Platform)' == '' "">AnyCPU</Platform>
-    <ProductVersion>9.0.30729</ProductVersion>
-    <SchemaVersion>2.0</SchemaVersion>
-    <ProjectGuid>{6908BDCE-D925-43F3-94AC-A531E6DF2591}</ProjectGuid>
-    <OutputType>Library</OutputType>
-    <AppDesignerFolder>Properties</AppDesignerFolder>
-    <RootNamespace>Google.ProtocolBuffers</RootNamespace>
-    <AssemblyName>Google.ProtocolBuffers</AssemblyName>
-    <TargetFrameworkVersion>v3.5</TargetFrameworkVersion>
-    <FileAlignment>512</FileAlignment>
-    <SignAssembly>true</SignAssembly>
-    <AssemblyOriginatorKeyFile>..\..\keys\Google.ProtocolBuffers.snk</AssemblyOriginatorKeyFile>
-    <OldToolsVersion>3.5</OldToolsVersion>
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Debug|AnyCPU' "">
-    <DebugSymbols>true</DebugSymbols>
-    <DebugType>full</DebugType>
-    <Optimize>false</Optimize>
-    <OutputPath>bin\NET35\Debug</OutputPath>
-    <IntermediateOutputPath>obj\NET35\Debug\</IntermediateOutputPath>
-    <DocumentationFile>$(OutputPath)\$(AssemblyName).xml</DocumentationFile>
-    <NoWarn>1591, 1570, 1571, 1572, 1573, 1574</NoWarn>
-    <DefineConstants>DEBUG;TRACE;$(EnvironmentFlavor);$(EnvironmentTemplate)</DefineConstants>
-    <ErrorReport>prompt</ErrorReport>
-    <WarningLevel>4</WarningLevel>
-    <NoStdLib>true</NoStdLib>
-    <GenerateSerializationAssemblies>Off</GenerateSerializationAssemblies>
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Release|AnyCPU' "">
-    <DebugType>pdbonly</DebugType>
-    <Optimize>true</Optimize>
-    <OutputPath>bin\NET35\Release</OutputPath>
-    <IntermediateOutputPath>obj\NET35\Release\</IntermediateOutputPath>
-    <DocumentationFile>$(OutputPath)\$(AssemblyName).xml</DocumentationFile>
-    <NoWarn>1591, 1570, 1571, 1572, 1573, 1574</NoWarn>
-    <DefineConstants>TRACE;$(EnvironmentFlavor);$(EnvironmentTemplate)</DefineConstants>
-    <ErrorReport>prompt</ErrorReport>
-    <WarningLevel>4</WarningLevel>
-    <NoStdLib>true</NoStdLib>
-    <GenerateSerializationAssemblies>Off</GenerateSerializationAssemblies>
-  </PropertyGroup>
-  <ItemGroup>
-    <Reference Include=""mscorlib"" />
-    <Reference Include=""System"" />
-    <Reference Include=""System.Xml"" />
-    <Reference Include=""System.Core"" />
-  </ItemGroup>
-  <ItemGroup>
-    <Compile Include=""AbstractBuilder.cs"" />
-    <Compile Include=""AbstractBuilderLite.cs"" />
-    <Compile Include=""AbstractMessage.cs"" />
-    <Compile Include=""AbstractMessageLite.cs"" />
-    <Compile Include=""ByteArray.cs"" />
-    <Compile Include=""ByteString.cs"" />
-    <Compile Include=""Collections\Enumerables.cs"" />
-    <Compile Include=""Collections\IPopsicleList.cs"" />
-    <Compile Include=""Collections\PopsicleList.cs"" />
-    <Compile Include=""CodedOutputStream.ComputeSize.cs"" />
-    <Compile Include=""CustomSerialization.cs"" />
-    <Compile Include=""Delegates.cs"" />
-    <Compile Include=""CodedInputStream.cs"" />
-    <Compile Include=""CodedOutputStream.cs"" />
-    <Compile Include=""Collections\Dictionaries.cs"" />
-    <Compile Include=""Collections\Lists.cs"" />
-    <Compile Include=""Collections\ReadOnlyDictionary.cs"" />
-    <Compile Include=""DescriptorProtos\CSharpOptions.cs"" />
-    <Compile Include=""DescriptorProtos\DescriptorProtoFile.cs"" />
-    <Compile Include=""DescriptorProtos\IDescriptorProto.cs"" />
-    <Compile Include=""DescriptorProtos\PartialClasses.cs"" />
-    <Compile Include=""Descriptors\DescriptorBase.cs"" />
-    <Compile Include=""Descriptors\DescriptorPool.cs"" />
-    <Compile Include=""Descriptors\DescriptorUtil.cs"" />
-    <Compile Include=""Descriptors\DescriptorValidationException.cs"" />
-    <Compile Include=""Descriptors\EnumDescriptor.cs"" />
-    <Compile Include=""Descriptors\EnumValueDescriptor.cs"" />
-    <Compile Include=""Descriptors\FieldDescriptor.cs"" />
-    <Compile Include=""Descriptors\FieldMappingAttribute.cs"" />
-    <Compile Include=""Descriptors\FieldType.cs"" />
-    <Compile Include=""Descriptors\FileDescriptor.cs"" />
-    <Compile Include=""Descriptors\IDescriptor.cs"" />
-    <Compile Include=""Descriptors\IndexedDescriptorBase.cs"" />
-    <Compile Include=""Descriptors\MappedType.cs"" />
-    <Compile Include=""Descriptors\MessageDescriptor.cs"" />
-    <Compile Include=""Descriptors\MethodDescriptor.cs"" />
-    <Compile Include=""Descriptors\PackageDescriptor.cs"" />
-    <Compile Include=""Descriptors\ServiceDescriptor.cs"" />
-    <Compile Include=""DynamicMessage.cs"" />
-    <Compile Include=""EnumLite.cs"" />
-    <Compile Include=""ExtendableBuilder.cs"" />
-    <Compile Include=""ExtendableBuilderLite.cs"" />
-    <Compile Include=""ExtendableMessage.cs"" />
-    <Compile Include=""ExtendableMessageLite.cs"" />
-    <Compile Include=""ExtensionInfo.cs"" />
-    <Compile Include=""ExtensionRegistry.cs"" />
-    <Compile Include=""ExtensionRegistryLite.cs"" />
-    <Compile Include=""FieldAccess\ReflectionUtil.cs"" />
-    <Compile Include=""FieldAccess\SingleEnumAccessor.cs"" />
-    <Compile Include=""FieldAccess\SingleMessageAccessor.cs"" />
-    <Compile Include=""FieldAccess\SinglePrimitiveAccessor.cs"" />
-    <Compile Include=""FieldAccess\RepeatedPrimitiveAccessor.cs"" />
-    <Compile Include=""FieldAccess\RepeatedEnumAccessor.cs"" />
-    <Compile Include=""FieldAccess\IFieldAccessor.cs"" />
-    <Compile Include=""FieldAccess\FieldAccessorTable.cs"" />
-    <Compile Include=""FieldAccess\RepeatedMessageAccessor.cs"" />
-    <Compile Include=""FieldSet.cs"" />
-    <Compile Include=""FrameworkPortability.cs"" />
-    <Compile Include=""GeneratedBuilder.cs"" />
-    <Compile Include=""GeneratedBuilderLite.cs"" />
-    <Compile Include=""GeneratedExtensionLite.cs"" />
-    <Compile Include=""GeneratedMessageLite.cs"" />
-    <Compile Include=""GeneratedRepeatExtension.cs"" />
-    <Compile Include=""GeneratedSingleExtension.cs"" />
-    <Compile Include=""GeneratedMessage.cs"" />
-    <Compile Include=""IBuilder.cs"" />
-    <Compile Include=""GeneratedExtensionBase.cs"" />
-    <Compile Include=""IBuilderLite.cs"" />
-    <Compile Include=""ICodedInputStream.cs"" />
-    <Compile Include=""ICodedOutputStream.cs"" />
-    <Compile Include=""IMessage.cs"" />
-    <Compile Include=""IMessageLite.cs"" />
-    <Compile Include=""InvalidProtocolBufferException.cs"" />
-    <Compile Include=""IRpcChannel.cs"" />
-    <Compile Include=""IRpcController.cs"" />
-    <Compile Include=""IRpcDispatch.cs"" />
-    <Compile Include=""IService.cs"" />
-    <Compile Include=""MessageStreamIterator.cs"" />
-    <Compile Include=""MessageStreamWriter.cs"" />
-    <Compile Include=""MessageUtil.cs"" />
-    <Compile Include=""NameHelpers.cs"" />
-    <Compile Include=""Properties\AssemblyInfo.cs"" />
-    <Compile Include=""RpcUtil.cs"" />
-    <Compile Include=""SortedList.cs"" />
-    <Compile Include=""TextFormat.cs"" />
-    <Compile Include=""TextGenerator.cs"" />
-    <Compile Include=""TextTokenizer.cs"" />
-    <Compile Include=""ThrowHelper.cs"" />
-    <Compile Include=""UninitializedMessageException.cs"" />
-    <Compile Include=""UnknownField.cs"" />
-    <Compile Include=""UnknownFieldSet.cs"" />
-    <Compile Include=""WireFormat.cs"" />
-  </ItemGroup>
-  <Import Project=""$(MSBuildToolsPath)\Microsoft.CSharp.targets"" />
-  <!-- To modify your build process, add your task inside one of the targets below and uncomment it. 
-       Other similar extension points exist, see Microsoft.Common.targets.
-  <Target Name=""BeforeBuild"">
-  </Target>
-  <Target Name=""AfterBuild"">
-  </Target>
-  -->
-</Project>
\ No newline at end of file
diff --git a/csharp/src/ProtocolBuffers/ProtocolBuffers.NET40.csproj b/csharp/src/ProtocolBuffers/ProtocolBuffers.NET40.csproj
deleted file mode 100644
index 7495778ee..000000000
--- a/csharp/src/ProtocolBuffers/ProtocolBuffers.NET40.csproj
+++ /dev/null
@@ -1,155 +0,0 @@
-<Project ToolsVersion=""4.0"" DefaultTargets=""Build"" xmlns=""http://schemas.microsoft.com/developer/msbuild/2003"">
-  <PropertyGroup>
-    <EnvironmentFlavor>CLIENTPROFILE</EnvironmentFlavor>
-    <EnvironmentTemplate>NET40</EnvironmentTemplate>
-    <Configuration Condition="" '$(Configuration)' == '' "">Debug</Configuration>
-    <Platform Condition="" '$(Platform)' == '' "">AnyCPU</Platform>
-    <ProductVersion>9.0.30729</ProductVersion>
-    <SchemaVersion>2.0</SchemaVersion>
-    <ProjectGuid>{6908BDCE-D925-43F3-94AC-A531E6DF2591}</ProjectGuid>
-    <OutputType>Library</OutputType>
-    <AppDesignerFolder>Properties</AppDesignerFolder>
-    <RootNamespace>Google.ProtocolBuffers</RootNamespace>
-    <AssemblyName>Google.ProtocolBuffers</AssemblyName>
-    <TargetFrameworkVersion>v4.0</TargetFrameworkVersion>
-    <FileAlignment>512</FileAlignment>
-    <SignAssembly>true</SignAssembly>
-    <AssemblyOriginatorKeyFile>..\..\keys\Google.ProtocolBuffers.snk</AssemblyOriginatorKeyFile>
-    <OldToolsVersion>3.5</OldToolsVersion>
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Debug|AnyCPU' "">
-    <DebugSymbols>true</DebugSymbols>
-    <DebugType>full</DebugType>
-    <Optimize>false</Optimize>
-    <OutputPath>bin\NET40\Debug</OutputPath>
-    <IntermediateOutputPath>obj\NET40\Debug\</IntermediateOutputPath>
-    <DocumentationFile>$(OutputPath)\$(AssemblyName).xml</DocumentationFile>
-    <NoWarn>1591, 1570, 1571, 1572, 1573, 1574</NoWarn>
-    <DefineConstants>DEBUG;TRACE;$(EnvironmentFlavor);$(EnvironmentTemplate)</DefineConstants>
-    <ErrorReport>prompt</ErrorReport>
-    <WarningLevel>4</WarningLevel>
-    <NoStdLib>true</NoStdLib>
-    <GenerateSerializationAssemblies>Off</GenerateSerializationAssemblies>
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Release|AnyCPU' "">
-    <DebugType>pdbonly</DebugType>
-    <Optimize>true</Optimize>
-    <OutputPath>bin\NET40\Release</OutputPath>
-    <IntermediateOutputPath>obj\NET40\Release\</IntermediateOutputPath>
-    <DocumentationFile>$(OutputPath)\$(AssemblyName).xml</DocumentationFile>
-    <NoWarn>1591, 1570, 1571, 1572, 1573, 1574</NoWarn>
-    <DefineConstants>TRACE;$(EnvironmentFlavor);$(EnvironmentTemplate)</DefineConstants>
-    <ErrorReport>prompt</ErrorReport>
-    <WarningLevel>4</WarningLevel>
-    <NoStdLib>true</NoStdLib>
-    <GenerateSerializationAssemblies>Off</GenerateSerializationAssemblies>
-  </PropertyGroup>
-  <ItemGroup>
-    <Reference Include=""mscorlib"" />
-    <Reference Include=""System"" />
-    <Reference Include=""System.Xml"" />
-    <Reference Include=""System.Core"" />
-  </ItemGroup>
-  <ItemGroup>
-    <Compile Include=""AbstractBuilder.cs"" />
-    <Compile Include=""AbstractBuilderLite.cs"" />
-    <Compile Include=""AbstractMessage.cs"" />
-    <Compile Include=""AbstractMessageLite.cs"" />
-    <Compile Include=""ByteArray.cs"" />
-    <Compile Include=""ByteString.cs"" />
-    <Compile Include=""Collections\Enumerables.cs"" />
-    <Compile Include=""Collections\IPopsicleList.cs"" />
-    <Compile Include=""Collections\PopsicleList.cs"" />
-    <Compile Include=""CodedOutputStream.ComputeSize.cs"" />
-    <Compile Include=""CustomSerialization.cs"" />
-    <Compile Include=""Delegates.cs"" />
-    <Compile Include=""CodedInputStream.cs"" />
-    <Compile Include=""CodedOutputStream.cs"" />
-    <Compile Include=""Collections\Dictionaries.cs"" />
-    <Compile Include=""Collections\Lists.cs"" />
-    <Compile Include=""Collections\ReadOnlyDictionary.cs"" />
-    <Compile Include=""DescriptorProtos\CSharpOptions.cs"" />
-    <Compile Include=""DescriptorProtos\DescriptorProtoFile.cs"" />
-    <Compile Include=""DescriptorProtos\IDescriptorProto.cs"" />
-    <Compile Include=""DescriptorProtos\PartialClasses.cs"" />
-    <Compile Include=""Descriptors\DescriptorBase.cs"" />
-    <Compile Include=""Descriptors\DescriptorPool.cs"" />
-    <Compile Include=""Descriptors\DescriptorUtil.cs"" />
-    <Compile Include=""Descriptors\DescriptorValidationException.cs"" />
-    <Compile Include=""Descriptors\EnumDescriptor.cs"" />
-    <Compile Include=""Descriptors\EnumValueDescriptor.cs"" />
-    <Compile Include=""Descriptors\FieldDescriptor.cs"" />
-    <Compile Include=""Descriptors\FieldMappingAttribute.cs"" />
-    <Compile Include=""Descriptors\FieldType.cs"" />
-    <Compile Include=""Descriptors\FileDescriptor.cs"" />
-    <Compile Include=""Descriptors\IDescriptor.cs"" />
-    <Compile Include=""Descriptors\IndexedDescriptorBase.cs"" />
-    <Compile Include=""Descriptors\MappedType.cs"" />
-    <Compile Include=""Descriptors\MessageDescriptor.cs"" />
-    <Compile Include=""Descriptors\MethodDescriptor.cs"" />
-    <Compile Include=""Descriptors\PackageDescriptor.cs"" />
-    <Compile Include=""Descriptors\ServiceDescriptor.cs"" />
-    <Compile Include=""DynamicMessage.cs"" />
-    <Compile Include=""EnumLite.cs"" />
-    <Compile Include=""ExtendableBuilder.cs"" />
-    <Compile Include=""ExtendableBuilderLite.cs"" />
-    <Compile Include=""ExtendableMessage.cs"" />
-    <Compile Include=""ExtendableMessageLite.cs"" />
-    <Compile Include=""ExtensionInfo.cs"" />
-    <Compile Include=""ExtensionRegistry.cs"" />
-    <Compile Include=""ExtensionRegistryLite.cs"" />
-    <Compile Include=""FieldAccess\ReflectionUtil.cs"" />
-    <Compile Include=""FieldAccess\SingleEnumAccessor.cs"" />
-    <Compile Include=""FieldAccess\SingleMessageAccessor.cs"" />
-    <Compile Include=""FieldAccess\SinglePrimitiveAccessor.cs"" />
-    <Compile Include=""FieldAccess\RepeatedPrimitiveAccessor.cs"" />
-    <Compile Include=""FieldAccess\RepeatedEnumAccessor.cs"" />
-    <Compile Include=""FieldAccess\IFieldAccessor.cs"" />
-    <Compile Include=""FieldAccess\FieldAccessorTable.cs"" />
-    <Compile Include=""FieldAccess\RepeatedMessageAccessor.cs"" />
-    <Compile Include=""FieldSet.cs"" />
-    <Compile Include=""FrameworkPortability.cs"" />
-    <Compile Include=""GeneratedBuilder.cs"" />
-    <Compile Include=""GeneratedBuilderLite.cs"" />
-    <Compile Include=""GeneratedExtensionLite.cs"" />
-    <Compile Include=""GeneratedMessageLite.cs"" />
-    <Compile Include=""GeneratedRepeatExtension.cs"" />
-    <Compile Include=""GeneratedSingleExtension.cs"" />
-    <Compile Include=""GeneratedMessage.cs"" />
-    <Compile Include=""IBuilder.cs"" />
-    <Compile Include=""GeneratedExtensionBase.cs"" />
-    <Compile Include=""IBuilderLite.cs"" />
-    <Compile Include=""ICodedInputStream.cs"" />
-    <Compile Include=""ICodedOutputStream.cs"" />
-    <Compile Include=""IMessage.cs"" />
-    <Compile Include=""IMessageLite.cs"" />
-    <Compile Include=""InvalidProtocolBufferException.cs"" />
-    <Compile Include=""IRpcChannel.cs"" />
-    <Compile Include=""IRpcController.cs"" />
-    <Compile Include=""IRpcDispatch.cs"" />
-    <Compile Include=""IService.cs"" />
-    <Compile Include=""MessageStreamIterator.cs"" />
-    <Compile Include=""MessageStreamWriter.cs"" />
-    <Compile Include=""MessageUtil.cs"" />
-    <Compile Include=""NameHelpers.cs"" />
-    <Compile Include=""Properties\AssemblyInfo.cs"" />
-    <Compile Include=""RpcUtil.cs"" />
-    <Compile Include=""SortedList.cs"" />
-    <Compile Include=""TextFormat.cs"" />
-    <Compile Include=""TextGenerator.cs"" />
-    <Compile Include=""TextTokenizer.cs"" />
-    <Compile Include=""ThrowHelper.cs"" />
-    <Compile Include=""UninitializedMessageException.cs"" />
-    <Compile Include=""UnknownField.cs"" />
-    <Compile Include=""UnknownFieldSet.cs"" />
-    <Compile Include=""WireFormat.cs"" />
-  </ItemGroup>
-  <Import Project=""$(MSBuildToolsPath)\Microsoft.CSharp.targets"" />
-  <!-- To modify your build process, add your task inside one of the targets below and uncomment it. 
-       Other similar extension points exist, see Microsoft.Common.targets.
-  <Target Name=""BeforeBuild"">
-  </Target>
-  <Target Name=""AfterBuild"">
-  </Target>
-  -->
-</Project>
\ No newline at end of file
diff --git a/csharp/src/ProtocolBuffers/ProtocolBuffers.PL40.csproj b/csharp/src/ProtocolBuffers/ProtocolBuffers.PL40.csproj
deleted file mode 100644
index 00ffddb86..000000000
--- a/csharp/src/ProtocolBuffers/ProtocolBuffers.PL40.csproj
+++ /dev/null
@@ -1,158 +0,0 @@
-<Project ToolsVersion=""4.0"" DefaultTargets=""Build"" xmlns=""http://schemas.microsoft.com/developer/msbuild/2003"" xmlns:cs=""urn:schemas-csharp-project:template"">
-  <PropertyGroup>
-    <EnvironmentFlavor>PORTABLE_LIBRARY</EnvironmentFlavor>
-    <EnvironmentTemplate>PL40</EnvironmentTemplate>
-    <Configuration Condition="" '$(Configuration)' == '' "">Debug</Configuration>
-    <Platform Condition="" '$(Platform)' == '' "">AnyCPU</Platform>
-    <ProductVersion>9.0.30729</ProductVersion>
-    <SchemaVersion>2.0</SchemaVersion>
-    <ProjectGuid>{6908BDCE-D925-43F3-94AC-A531E6DF2591}</ProjectGuid>
-    <OutputType>Library</OutputType>
-    <AppDesignerFolder>Properties</AppDesignerFolder>
-    <RootNamespace>Google.ProtocolBuffers</RootNamespace>
-    <AssemblyName>Google.ProtocolBuffers</AssemblyName>
-    <TargetFrameworkVersion>v4.0</TargetFrameworkVersion>
-    <FileAlignment>512</FileAlignment>
-    <SignAssembly>true</SignAssembly>
-    <AssemblyOriginatorKeyFile>..\..\keys\Google.ProtocolBuffers.snk</AssemblyOriginatorKeyFile>
-    <OldToolsVersion>3.5</OldToolsVersion>
-    <MinimumVisualStudioVersion>10.0</MinimumVisualStudioVersion>
-    <ProjectTypeGuids>{786C830F-07A1-408B-BD7F-6EE04809D6DB};{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}</ProjectTypeGuids>
-    <TargetFrameworkProfile>Profile1</TargetFrameworkProfile>
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Debug|AnyCPU' "">
-    <DebugSymbols>true</DebugSymbols>
-    <DebugType>full</DebugType>
-    <Optimize>false</Optimize>
-    <OutputPath>bin\PL40\Debug</OutputPath>
-    <IntermediateOutputPath>obj\PL40\Debug\</IntermediateOutputPath>
-    <DocumentationFile>$(OutputPath)\$(AssemblyName).xml</DocumentationFile>
-    <NoWarn>1591, 1570, 1571, 1572, 1573, 1574</NoWarn>
-    <DefineConstants>DEBUG;TRACE;$(EnvironmentFlavor);$(EnvironmentTemplate);NOSERIALIZABLE;NOSORTEDLIST</DefineConstants>
-    <ErrorReport>prompt</ErrorReport>
-    <WarningLevel>4</WarningLevel>
-    <NoStdLib>true</NoStdLib>
-    <GenerateSerializationAssemblies>Off</GenerateSerializationAssemblies>
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Release|AnyCPU' "">
-    <DebugType>pdbonly</DebugType>
-    <Optimize>true</Optimize>
-    <OutputPath>bin\PL40\Release</OutputPath>
-    <IntermediateOutputPath>obj\PL40\Release\</IntermediateOutputPath>
-    <DocumentationFile>$(OutputPath)\$(AssemblyName).xml</DocumentationFile>
-    <NoWarn>1591, 1570, 1571, 1572, 1573, 1574</NoWarn>
-    <DefineConstants>TRACE;$(EnvironmentFlavor);$(EnvironmentTemplate);NOSERIALIZABLE;NOSORTEDLIST</DefineConstants>
-    <ErrorReport>prompt</ErrorReport>
-    <WarningLevel>4</WarningLevel>
-    <NoStdLib>true</NoStdLib>
-    <GenerateSerializationAssemblies>Off</GenerateSerializationAssemblies>
-  </PropertyGroup>
-  <ItemGroup>
-    <Reference Include=""mscorlib"" />
-    <Reference Include=""System"" />
-    <Reference Include=""System.Xml"" />
-    <Reference Include=""System.Core"" />
-  </ItemGroup>
-  <ItemGroup>
-    <Compile Include=""AbstractBuilder.cs"" />
-    <Compile Include=""AbstractBuilderLite.cs"" />
-    <Compile Include=""AbstractMessage.cs"" />
-    <Compile Include=""AbstractMessageLite.cs"" />
-    <Compile Include=""ByteArray.cs"" />
-    <Compile Include=""ByteString.cs"" />
-    <Compile Include=""Collections\Enumerables.cs"" />
-    <Compile Include=""Collections\IPopsicleList.cs"" />
-    <Compile Include=""Collections\PopsicleList.cs"" />
-    <Compile Include=""CodedOutputStream.ComputeSize.cs"" />
-    <Compile Include=""CustomSerialization.cs"" />
-    <Compile Include=""Delegates.cs"" />
-    <Compile Include=""CodedInputStream.cs"" />
-    <Compile Include=""CodedOutputStream.cs"" />
-    <Compile Include=""Collections\Dictionaries.cs"" />
-    <Compile Include=""Collections\Lists.cs"" />
-    <Compile Include=""Collections\ReadOnlyDictionary.cs"" />
-    <Compile Include=""DescriptorProtos\CSharpOptions.cs"" />
-    <Compile Include=""DescriptorProtos\DescriptorProtoFile.cs"" />
-    <Compile Include=""DescriptorProtos\IDescriptorProto.cs"" />
-    <Compile Include=""DescriptorProtos\PartialClasses.cs"" />
-    <Compile Include=""Descriptors\DescriptorBase.cs"" />
-    <Compile Include=""Descriptors\DescriptorPool.cs"" />
-    <Compile Include=""Descriptors\DescriptorUtil.cs"" />
-    <Compile Include=""Descriptors\DescriptorValidationException.cs"" />
-    <Compile Include=""Descriptors\EnumDescriptor.cs"" />
-    <Compile Include=""Descriptors\EnumValueDescriptor.cs"" />
-    <Compile Include=""Descriptors\FieldDescriptor.cs"" />
-    <Compile Include=""Descriptors\FieldMappingAttribute.cs"" />
-    <Compile Include=""Descriptors\FieldType.cs"" />
-    <Compile Include=""Descriptors\FileDescriptor.cs"" />
-    <Compile Include=""Descriptors\IDescriptor.cs"" />
-    <Compile Include=""Descriptors\IndexedDescriptorBase.cs"" />
-    <Compile Include=""Descriptors\MappedType.cs"" />
-    <Compile Include=""Descriptors\MessageDescriptor.cs"" />
-    <Compile Include=""Descriptors\MethodDescriptor.cs"" />
-    <Compile Include=""Descriptors\PackageDescriptor.cs"" />
-    <Compile Include=""Descriptors\ServiceDescriptor.cs"" />
-    <Compile Include=""DynamicMessage.cs"" />
-    <Compile Include=""EnumLite.cs"" />
-    <Compile Include=""ExtendableBuilder.cs"" />
-    <Compile Include=""ExtendableBuilderLite.cs"" />
-    <Compile Include=""ExtendableMessage.cs"" />
-    <Compile Include=""ExtendableMessageLite.cs"" />
-    <Compile Include=""ExtensionInfo.cs"" />
-    <Compile Include=""ExtensionRegistry.cs"" />
-    <Compile Include=""ExtensionRegistryLite.cs"" />
-    <Compile Include=""FieldAccess\ReflectionUtil.cs"" />
-    <Compile Include=""FieldAccess\SingleEnumAccessor.cs"" />
-    <Compile Include=""FieldAccess\SingleMessageAccessor.cs"" />
-    <Compile Include=""FieldAccess\SinglePrimitiveAccessor.cs"" />
-    <Compile Include=""FieldAccess\RepeatedPrimitiveAccessor.cs"" />
-    <Compile Include=""FieldAccess\RepeatedEnumAccessor.cs"" />
-    <Compile Include=""FieldAccess\IFieldAccessor.cs"" />
-    <Compile Include=""FieldAccess\FieldAccessorTable.cs"" />
-    <Compile Include=""FieldAccess\RepeatedMessageAccessor.cs"" />
-    <Compile Include=""FieldSet.cs"" />
-    <Compile Include=""FrameworkPortability.cs"" />
-    <Compile Include=""GeneratedBuilder.cs"" />
-    <Compile Include=""GeneratedBuilderLite.cs"" />
-    <Compile Include=""GeneratedExtensionLite.cs"" />
-    <Compile Include=""GeneratedMessageLite.cs"" />
-    <Compile Include=""GeneratedRepeatExtension.cs"" />
-    <Compile Include=""GeneratedSingleExtension.cs"" />
-    <Compile Include=""GeneratedMessage.cs"" />
-    <Compile Include=""IBuilder.cs"" />
-    <Compile Include=""GeneratedExtensionBase.cs"" />
-    <Compile Include=""IBuilderLite.cs"" />
-    <Compile Include=""ICodedInputStream.cs"" />
-    <Compile Include=""ICodedOutputStream.cs"" />
-    <Compile Include=""IMessage.cs"" />
-    <Compile Include=""IMessageLite.cs"" />
-    <Compile Include=""InvalidProtocolBufferException.cs"" />
-    <Compile Include=""IRpcChannel.cs"" />
-    <Compile Include=""IRpcController.cs"" />
-    <Compile Include=""IRpcDispatch.cs"" />
-    <Compile Include=""IService.cs"" />
-    <Compile Include=""MessageStreamIterator.cs"" />
-    <Compile Include=""MessageStreamWriter.cs"" />
-    <Compile Include=""MessageUtil.cs"" />
-    <Compile Include=""NameHelpers.cs"" />
-    <Compile Include=""Properties\AssemblyInfo.cs"" />
-    <Compile Include=""RpcUtil.cs"" />
-    <Compile Include=""SortedList.cs"" />
-    <Compile Include=""TextFormat.cs"" />
-    <Compile Include=""TextGenerator.cs"" />
-    <Compile Include=""TextTokenizer.cs"" />
-    <Compile Include=""ThrowHelper.cs"" />
-    <Compile Include=""UninitializedMessageException.cs"" />
-    <Compile Include=""UnknownField.cs"" />
-    <Compile Include=""UnknownFieldSet.cs"" />
-    <Compile Include=""WireFormat.cs"" />
-  </ItemGroup>
-  <Import Project=""$(MSBuildExtensionsPath32)\Microsoft\Portable\$(TargetFrameworkVersion)\Microsoft.Portable.CSharp.targets"" />
-  <!-- To modify your build process, add your task inside one of the targets below and uncomment it. 
-       Other similar extension points exist, see Microsoft.Common.targets.
-  <Target Name=""BeforeBuild"">
-  </Target>
-  <Target Name=""AfterBuild"">
-  </Target>
-  -->
-</Project>
\ No newline at end of file
diff --git a/csharp/src/ProtocolBuffers/ProtocolBuffers.SL20.csproj b/csharp/src/ProtocolBuffers/ProtocolBuffers.SL20.csproj
deleted file mode 100644
index 10fc8283d..000000000
--- a/csharp/src/ProtocolBuffers/ProtocolBuffers.SL20.csproj
+++ /dev/null
@@ -1,169 +0,0 @@
-<Project ToolsVersion=""3.5"" DefaultTargets=""Build"" xmlns=""http://schemas.microsoft.com/developer/msbuild/2003"" xmlns:cs=""urn:schemas-csharp-project:template"">
-  <PropertyGroup>
-    <EnvironmentFlavor>SILVERLIGHT</EnvironmentFlavor>
-    <EnvironmentTemplate>SL20</EnvironmentTemplate>
-    <Configuration Condition="" '$(Configuration)' == '' "">Debug</Configuration>
-    <Platform Condition="" '$(Platform)' == '' "">AnyCPU</Platform>
-    <ProductVersion>9.0.30729</ProductVersion>
-    <SchemaVersion>2.0</SchemaVersion>
-    <ProjectGuid>{6908BDCE-D925-43F3-94AC-A531E6DF2591}</ProjectGuid>
-    <OutputType>Library</OutputType>
-    <AppDesignerFolder>Properties</AppDesignerFolder>
-    <RootNamespace>Google.ProtocolBuffers</RootNamespace>
-    <AssemblyName>Google.ProtocolBuffers</AssemblyName>
-    <TargetFrameworkVersion>v2.0</TargetFrameworkVersion>
-    <FileAlignment>512</FileAlignment>
-    <SignAssembly>true</SignAssembly>
-    <AssemblyOriginatorKeyFile>..\..\keys\Google.ProtocolBuffers.snk</AssemblyOriginatorKeyFile>
-    <OldToolsVersion>3.5</OldToolsVersion>
-    <ProjectTypeGuids>{A1591282-1198-4647-A2B1-27E5FF5F6F3B};{fae04ec0-301f-11d3-bf4b-00c04f79efbc}</ProjectTypeGuids>
-    <SilverlightApplication>false</SilverlightApplication>
-    <ValidateXaml>false</ValidateXaml>
-    <ThrowErrorsInValidation>false</ThrowErrorsInValidation>
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Debug|AnyCPU' "">
-    <DebugSymbols>true</DebugSymbols>
-    <DebugType>full</DebugType>
-    <Optimize>false</Optimize>
-    <OutputPath>bin\SL20\Debug</OutputPath>
-    <IntermediateOutputPath>obj\SL20\Debug\</IntermediateOutputPath>
-    <DocumentationFile>$(OutputPath)\$(AssemblyName).xml</DocumentationFile>
-    <NoWarn>1591, 1570, 1571, 1572, 1573, 1574</NoWarn>
-    <DefineConstants>DEBUG;TRACE;$(EnvironmentFlavor);$(EnvironmentTemplate);NOSERIALIZABLE;NOSORTEDLIST;NOEXTENSIONS</DefineConstants>
-    <ErrorReport>prompt</ErrorReport>
-    <WarningLevel>4</WarningLevel>
-    <NoStdLib>true</NoStdLib>
-    <GenerateSerializationAssemblies>Off</GenerateSerializationAssemblies>
-    <NoConfig>true</NoConfig>
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Release|AnyCPU' "">
-    <DebugType>pdbonly</DebugType>
-    <Optimize>true</Optimize>
-    <OutputPath>bin\SL20\Release</OutputPath>
-    <IntermediateOutputPath>obj\SL20\Release\</IntermediateOutputPath>
-    <DocumentationFile>$(OutputPath)\$(AssemblyName).xml</DocumentationFile>
-    <NoWarn>1591, 1570, 1571, 1572, 1573, 1574</NoWarn>
-    <DefineConstants>TRACE;$(EnvironmentFlavor);$(EnvironmentTemplate);NOSERIALIZABLE;NOSORTEDLIST;NOEXTENSIONS</DefineConstants>
-    <ErrorReport>prompt</ErrorReport>
-    <WarningLevel>4</WarningLevel>
-    <NoStdLib>true</NoStdLib>
-    <GenerateSerializationAssemblies>Off</GenerateSerializationAssemblies>
-    <NoConfig>true</NoConfig>
-  </PropertyGroup>
-  <ItemGroup>
-    <Reference Include=""mscorlib"" />
-    <Reference Include=""System"" />
-    <Reference Include=""System.Xml"" />
-  </ItemGroup>
-  <ItemGroup>
-    <Compile Include=""AbstractBuilder.cs"" />
-    <Compile Include=""AbstractBuilderLite.cs"" />
-    <Compile Include=""AbstractMessage.cs"" />
-    <Compile Include=""AbstractMessageLite.cs"" />
-    <Compile Include=""ByteArray.cs"" />
-    <Compile Include=""ByteString.cs"" />
-    <Compile Include=""Collections\Enumerables.cs"" />
-    <Compile Include=""Collections\IPopsicleList.cs"" />
-    <Compile Include=""Collections\PopsicleList.cs"" />
-    <Compile Include=""CodedOutputStream.ComputeSize.cs"" />
-    <Compile Include=""CustomSerialization.cs"" />
-    <Compile Include=""Delegates.cs"" />
-    <Compile Include=""CodedInputStream.cs"" />
-    <Compile Include=""CodedOutputStream.cs"" />
-    <Compile Include=""Collections\Dictionaries.cs"" />
-    <Compile Include=""Collections\Lists.cs"" />
-    <Compile Include=""Collections\ReadOnlyDictionary.cs"" />
-    <Compile Include=""DescriptorProtos\CSharpOptions.cs"" />
-    <Compile Include=""DescriptorProtos\DescriptorProtoFile.cs"" />
-    <Compile Include=""DescriptorProtos\IDescriptorProto.cs"" />
-    <Compile Include=""DescriptorProtos\PartialClasses.cs"" />
-    <Compile Include=""Descriptors\DescriptorBase.cs"" />
-    <Compile Include=""Descriptors\DescriptorPool.cs"" />
-    <Compile Include=""Descriptors\DescriptorUtil.cs"" />
-    <Compile Include=""Descriptors\DescriptorValidationException.cs"" />
-    <Compile Include=""Descriptors\EnumDescriptor.cs"" />
-    <Compile Include=""Descriptors\EnumValueDescriptor.cs"" />
-    <Compile Include=""Descriptors\FieldDescriptor.cs"" />
-    <Compile Include=""Descriptors\FieldMappingAttribute.cs"" />
-    <Compile Include=""Descriptors\FieldType.cs"" />
-    <Compile Include=""Descriptors\FileDescriptor.cs"" />
-    <Compile Include=""Descriptors\IDescriptor.cs"" />
-    <Compile Include=""Descriptors\IndexedDescriptorBase.cs"" />
-    <Compile Include=""Descriptors\MappedType.cs"" />
-    <Compile Include=""Descriptors\MessageDescriptor.cs"" />
-    <Compile Include=""Descriptors\MethodDescriptor.cs"" />
-    <Compile Include=""Descriptors\PackageDescriptor.cs"" />
-    <Compile Include=""Descriptors\ServiceDescriptor.cs"" />
-    <Compile Include=""DynamicMessage.cs"" />
-    <Compile Include=""EnumLite.cs"" />
-    <Compile Include=""ExtendableBuilder.cs"" />
-    <Compile Include=""ExtendableBuilderLite.cs"" />
-    <Compile Include=""ExtendableMessage.cs"" />
-    <Compile Include=""ExtendableMessageLite.cs"" />
-    <Compile Include=""ExtensionInfo.cs"" />
-    <Compile Include=""ExtensionRegistry.cs"" />
-    <Compile Include=""ExtensionRegistryLite.cs"" />
-    <Compile Include=""FieldAccess\ReflectionUtil.cs"" />
-    <Compile Include=""FieldAccess\SingleEnumAccessor.cs"" />
-    <Compile Include=""FieldAccess\SingleMessageAccessor.cs"" />
-    <Compile Include=""FieldAccess\SinglePrimitiveAccessor.cs"" />
-    <Compile Include=""FieldAccess\RepeatedPrimitiveAccessor.cs"" />
-    <Compile Include=""FieldAccess\RepeatedEnumAccessor.cs"" />
-    <Compile Include=""FieldAccess\IFieldAccessor.cs"" />
-    <Compile Include=""FieldAccess\FieldAccessorTable.cs"" />
-    <Compile Include=""FieldAccess\RepeatedMessageAccessor.cs"" />
-    <Compile Include=""FieldSet.cs"" />
-    <Compile Include=""FrameworkPortability.cs"" />
-    <Compile Include=""GeneratedBuilder.cs"" />
-    <Compile Include=""GeneratedBuilderLite.cs"" />
-    <Compile Include=""GeneratedExtensionLite.cs"" />
-    <Compile Include=""GeneratedMessageLite.cs"" />
-    <Compile Include=""GeneratedRepeatExtension.cs"" />
-    <Compile Include=""GeneratedSingleExtension.cs"" />
-    <Compile Include=""GeneratedMessage.cs"" />
-    <Compile Include=""IBuilder.cs"" />
-    <Compile Include=""GeneratedExtensionBase.cs"" />
-    <Compile Include=""IBuilderLite.cs"" />
-    <Compile Include=""ICodedInputStream.cs"" />
-    <Compile Include=""ICodedOutputStream.cs"" />
-    <Compile Include=""IMessage.cs"" />
-    <Compile Include=""IMessageLite.cs"" />
-    <Compile Include=""InvalidProtocolBufferException.cs"" />
-    <Compile Include=""IRpcChannel.cs"" />
-    <Compile Include=""IRpcController.cs"" />
-    <Compile Include=""IRpcDispatch.cs"" />
-    <Compile Include=""IService.cs"" />
-    <Compile Include=""MessageStreamIterator.cs"" />
-    <Compile Include=""MessageStreamWriter.cs"" />
-    <Compile Include=""MessageUtil.cs"" />
-    <Compile Include=""NameHelpers.cs"" />
-    <Compile Include=""Properties\AssemblyInfo.cs"" />
-    <Compile Include=""RpcUtil.cs"" />
-    <Compile Include=""SortedList.cs"" />
-    <Compile Include=""TextFormat.cs"" />
-    <Compile Include=""TextGenerator.cs"" />
-    <Compile Include=""TextTokenizer.cs"" />
-    <Compile Include=""ThrowHelper.cs"" />
-    <Compile Include=""UninitializedMessageException.cs"" />
-    <Compile Include=""UnknownField.cs"" />
-    <Compile Include=""UnknownFieldSet.cs"" />
-    <Compile Include=""WireFormat.cs"" />
-  </ItemGroup>
-  <Import Project=""$(MSBuildExtensionsPath32)\Microsoft\Silverlight\v2.0\Microsoft.Silverlight.CSharp.targets"" />
-  <ProjectExtensions>
-    <VisualStudio>
-      <FlavorProperties GUID=""{A1591282-1198-4647-A2B1-27E5FF5F6F3B}"">
-        <SilverlightProjectProperties>
-          <StartAction>OfflineApplication</StartAction>
-        </SilverlightProjectProperties>
-      </FlavorProperties>
-    </VisualStudio>
-  </ProjectExtensions>
-  <!-- To modify your build process, add your task inside one of the targets below and uncomment it. 
-       Other similar extension points exist, see Microsoft.Common.targets.
-  <Target Name=""BeforeBuild"">
-  </Target>
-  <Target Name=""AfterBuild"">
-  </Target>
-  -->
-</Project>
\ No newline at end of file
diff --git a/csharp/src/ProtocolBuffers/ProtocolBuffers.SL30.csproj b/csharp/src/ProtocolBuffers/ProtocolBuffers.SL30.csproj
deleted file mode 100644
index 4fe571ca4..000000000
--- a/csharp/src/ProtocolBuffers/ProtocolBuffers.SL30.csproj
+++ /dev/null
@@ -1,170 +0,0 @@
-<Project ToolsVersion=""3.5"" DefaultTargets=""Build"" xmlns=""http://schemas.microsoft.com/developer/msbuild/2003"" xmlns:cs=""urn:schemas-csharp-project:template"">
-  <PropertyGroup>
-    <EnvironmentFlavor>SILVERLIGHT</EnvironmentFlavor>
-    <EnvironmentTemplate>SL30</EnvironmentTemplate>
-    <Configuration Condition="" '$(Configuration)' == '' "">Debug</Configuration>
-    <Platform Condition="" '$(Platform)' == '' "">AnyCPU</Platform>
-    <ProductVersion>9.0.30729</ProductVersion>
-    <SchemaVersion>2.0</SchemaVersion>
-    <ProjectGuid>{6908BDCE-D925-43F3-94AC-A531E6DF2591}</ProjectGuid>
-    <OutputType>Library</OutputType>
-    <AppDesignerFolder>Properties</AppDesignerFolder>
-    <RootNamespace>Google.ProtocolBuffers</RootNamespace>
-    <AssemblyName>Google.ProtocolBuffers</AssemblyName>
-    <TargetFrameworkVersion>v3.5</TargetFrameworkVersion>
-    <FileAlignment>512</FileAlignment>
-    <SignAssembly>true</SignAssembly>
-    <AssemblyOriginatorKeyFile>..\..\keys\Google.ProtocolBuffers.snk</AssemblyOriginatorKeyFile>
-    <OldToolsVersion>3.5</OldToolsVersion>
-    <ProjectTypeGuids>{A1591282-1198-4647-A2B1-27E5FF5F6F3B};{fae04ec0-301f-11d3-bf4b-00c04f79efbc}</ProjectTypeGuids>
-    <SilverlightApplication>false</SilverlightApplication>
-    <ValidateXaml>false</ValidateXaml>
-    <ThrowErrorsInValidation>false</ThrowErrorsInValidation>
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Debug|AnyCPU' "">
-    <DebugSymbols>true</DebugSymbols>
-    <DebugType>full</DebugType>
-    <Optimize>false</Optimize>
-    <OutputPath>bin\SL30\Debug</OutputPath>
-    <IntermediateOutputPath>obj\SL30\Debug\</IntermediateOutputPath>
-    <DocumentationFile>$(OutputPath)\$(AssemblyName).xml</DocumentationFile>
-    <NoWarn>1591, 1570, 1571, 1572, 1573, 1574</NoWarn>
-    <DefineConstants>DEBUG;TRACE;$(EnvironmentFlavor);$(EnvironmentTemplate);NOSERIALIZABLE;NOSORTEDLIST</DefineConstants>
-    <ErrorReport>prompt</ErrorReport>
-    <WarningLevel>4</WarningLevel>
-    <NoStdLib>true</NoStdLib>
-    <GenerateSerializationAssemblies>Off</GenerateSerializationAssemblies>
-    <NoConfig>true</NoConfig>
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Release|AnyCPU' "">
-    <DebugType>pdbonly</DebugType>
-    <Optimize>true</Optimize>
-    <OutputPath>bin\SL30\Release</OutputPath>
-    <IntermediateOutputPath>obj\SL30\Release\</IntermediateOutputPath>
-    <DocumentationFile>$(OutputPath)\$(AssemblyName).xml</DocumentationFile>
-    <NoWarn>1591, 1570, 1571, 1572, 1573, 1574</NoWarn>
-    <DefineConstants>TRACE;$(EnvironmentFlavor);$(EnvironmentTemplate);NOSERIALIZABLE;NOSORTEDLIST</DefineConstants>
-    <ErrorReport>prompt</ErrorReport>
-    <WarningLevel>4</WarningLevel>
-    <NoStdLib>true</NoStdLib>
-    <GenerateSerializationAssemblies>Off</GenerateSerializationAssemblies>
-    <NoConfig>true</NoConfig>
-  </PropertyGroup>
-  <ItemGroup>
-    <Reference Include=""mscorlib"" />
-    <Reference Include=""System"" />
-    <Reference Include=""System.Xml"" />
-    <Reference Include=""System.Core"" />
-  </ItemGroup>
-  <ItemGroup>
-    <Compile Include=""AbstractBuilder.cs"" />
-    <Compile Include=""AbstractBuilderLite.cs"" />
-    <Compile Include=""AbstractMessage.cs"" />
-    <Compile Include=""AbstractMessageLite.cs"" />
-    <Compile Include=""ByteArray.cs"" />
-    <Compile Include=""ByteString.cs"" />
-    <Compile Include=""Collections\Enumerables.cs"" />
-    <Compile Include=""Collections\IPopsicleList.cs"" />
-    <Compile Include=""Collections\PopsicleList.cs"" />
-    <Compile Include=""CodedOutputStream.ComputeSize.cs"" />
-    <Compile Include=""CustomSerialization.cs"" />
-    <Compile Include=""Delegates.cs"" />
-    <Compile Include=""CodedInputStream.cs"" />
-    <Compile Include=""CodedOutputStream.cs"" />
-    <Compile Include=""Collections\Dictionaries.cs"" />
-    <Compile Include=""Collections\Lists.cs"" />
-    <Compile Include=""Collections\ReadOnlyDictionary.cs"" />
-    <Compile Include=""DescriptorProtos\CSharpOptions.cs"" />
-    <Compile Include=""DescriptorProtos\DescriptorProtoFile.cs"" />
-    <Compile Include=""DescriptorProtos\IDescriptorProto.cs"" />
-    <Compile Include=""DescriptorProtos\PartialClasses.cs"" />
-    <Compile Include=""Descriptors\DescriptorBase.cs"" />
-    <Compile Include=""Descriptors\DescriptorPool.cs"" />
-    <Compile Include=""Descriptors\DescriptorUtil.cs"" />
-    <Compile Include=""Descriptors\DescriptorValidationException.cs"" />
-    <Compile Include=""Descriptors\EnumDescriptor.cs"" />
-    <Compile Include=""Descriptors\EnumValueDescriptor.cs"" />
-    <Compile Include=""Descriptors\FieldDescriptor.cs"" />
-    <Compile Include=""Descriptors\FieldMappingAttribute.cs"" />
-    <Compile Include=""Descriptors\FieldType.cs"" />
-    <Compile Include=""Descriptors\FileDescriptor.cs"" />
-    <Compile Include=""Descriptors\IDescriptor.cs"" />
-    <Compile Include=""Descriptors\IndexedDescriptorBase.cs"" />
-    <Compile Include=""Descriptors\MappedType.cs"" />
-    <Compile Include=""Descriptors\MessageDescriptor.cs"" />
-    <Compile Include=""Descriptors\MethodDescriptor.cs"" />
-    <Compile Include=""Descriptors\PackageDescriptor.cs"" />
-    <Compile Include=""Descriptors\ServiceDescriptor.cs"" />
-    <Compile Include=""DynamicMessage.cs"" />
-    <Compile Include=""EnumLite.cs"" />
-    <Compile Include=""ExtendableBuilder.cs"" />
-    <Compile Include=""ExtendableBuilderLite.cs"" />
-    <Compile Include=""ExtendableMessage.cs"" />
-    <Compile Include=""ExtendableMessageLite.cs"" />
-    <Compile Include=""ExtensionInfo.cs"" />
-    <Compile Include=""ExtensionRegistry.cs"" />
-    <Compile Include=""ExtensionRegistryLite.cs"" />
-    <Compile Include=""FieldAccess\ReflectionUtil.cs"" />
-    <Compile Include=""FieldAccess\SingleEnumAccessor.cs"" />
-    <Compile Include=""FieldAccess\SingleMessageAccessor.cs"" />
-    <Compile Include=""FieldAccess\SinglePrimitiveAccessor.cs"" />
-    <Compile Include=""FieldAccess\RepeatedPrimitiveAccessor.cs"" />
-    <Compile Include=""FieldAccess\RepeatedEnumAccessor.cs"" />
-    <Compile Include=""FieldAccess\IFieldAccessor.cs"" />
-    <Compile Include=""FieldAccess\FieldAccessorTable.cs"" />
-    <Compile Include=""FieldAccess\RepeatedMessageAccessor.cs"" />
-    <Compile Include=""FieldSet.cs"" />
-    <Compile Include=""FrameworkPortability.cs"" />
-    <Compile Include=""GeneratedBuilder.cs"" />
-    <Compile Include=""GeneratedBuilderLite.cs"" />
-    <Compile Include=""GeneratedExtensionLite.cs"" />
-    <Compile Include=""GeneratedMessageLite.cs"" />
-    <Compile Include=""GeneratedRepeatExtension.cs"" />
-    <Compile Include=""GeneratedSingleExtension.cs"" />
-    <Compile Include=""GeneratedMessage.cs"" />
-    <Compile Include=""IBuilder.cs"" />
-    <Compile Include=""GeneratedExtensionBase.cs"" />
-    <Compile Include=""IBuilderLite.cs"" />
-    <Compile Include=""ICodedInputStream.cs"" />
-    <Compile Include=""ICodedOutputStream.cs"" />
-    <Compile Include=""IMessage.cs"" />
-    <Compile Include=""IMessageLite.cs"" />
-    <Compile Include=""InvalidProtocolBufferException.cs"" />
-    <Compile Include=""IRpcChannel.cs"" />
-    <Compile Include=""IRpcController.cs"" />
-    <Compile Include=""IRpcDispatch.cs"" />
-    <Compile Include=""IService.cs"" />
-    <Compile Include=""MessageStreamIterator.cs"" />
-    <Compile Include=""MessageStreamWriter.cs"" />
-    <Compile Include=""MessageUtil.cs"" />
-    <Compile Include=""NameHelpers.cs"" />
-    <Compile Include=""Properties\AssemblyInfo.cs"" />
-    <Compile Include=""RpcUtil.cs"" />
-    <Compile Include=""SortedList.cs"" />
-    <Compile Include=""TextFormat.cs"" />
-    <Compile Include=""TextGenerator.cs"" />
-    <Compile Include=""TextTokenizer.cs"" />
-    <Compile Include=""ThrowHelper.cs"" />
-    <Compile Include=""UninitializedMessageException.cs"" />
-    <Compile Include=""UnknownField.cs"" />
-    <Compile Include=""UnknownFieldSet.cs"" />
-    <Compile Include=""WireFormat.cs"" />
-  </ItemGroup>
-  <Import Project=""$(MSBuildExtensionsPath32)\Microsoft\Silverlight\v3.0\Microsoft.Silverlight.CSharp.targets"" />
-  <ProjectExtensions>
-    <VisualStudio>
-      <FlavorProperties GUID=""{A1591282-1198-4647-A2B1-27E5FF5F6F3B}"">
-        <SilverlightProjectProperties>
-          <StartAction>OfflineApplication</StartAction>
-        </SilverlightProjectProperties>
-      </FlavorProperties>
-    </VisualStudio>
-  </ProjectExtensions>
-  <!-- To modify your build process, add your task inside one of the targets below and uncomment it. 
-       Other similar extension points exist, see Microsoft.Common.targets.
-  <Target Name=""BeforeBuild"">
-  </Target>
-  <Target Name=""AfterBuild"">
-  </Target>
-  -->
-</Project>
\ No newline at end of file
diff --git a/csharp/src/ProtocolBuffers/ProtocolBuffers.SL40.csproj b/csharp/src/ProtocolBuffers/ProtocolBuffers.SL40.csproj
deleted file mode 100644
index 3664e4734..000000000
--- a/csharp/src/ProtocolBuffers/ProtocolBuffers.SL40.csproj
+++ /dev/null
@@ -1,171 +0,0 @@
-<Project ToolsVersion=""4.0"" DefaultTargets=""Build"" xmlns=""http://schemas.microsoft.com/developer/msbuild/2003"" xmlns:cs=""urn:schemas-csharp-project:template"">
-  <PropertyGroup>
-    <EnvironmentFlavor>SILVERLIGHT</EnvironmentFlavor>
-    <EnvironmentTemplate>SL40</EnvironmentTemplate>
-    <Configuration Condition="" '$(Configuration)' == '' "">Debug</Configuration>
-    <Platform Condition="" '$(Platform)' == '' "">AnyCPU</Platform>
-    <ProductVersion>9.0.30729</ProductVersion>
-    <SchemaVersion>2.0</SchemaVersion>
-    <ProjectGuid>{6908BDCE-D925-43F3-94AC-A531E6DF2591}</ProjectGuid>
-    <OutputType>Library</OutputType>
-    <AppDesignerFolder>Properties</AppDesignerFolder>
-    <RootNamespace>Google.ProtocolBuffers</RootNamespace>
-    <AssemblyName>Google.ProtocolBuffers</AssemblyName>
-    <TargetFrameworkVersion>v4.0</TargetFrameworkVersion>
-    <FileAlignment>512</FileAlignment>
-    <SignAssembly>true</SignAssembly>
-    <AssemblyOriginatorKeyFile>..\..\keys\Google.ProtocolBuffers.snk</AssemblyOriginatorKeyFile>
-    <OldToolsVersion>3.5</OldToolsVersion>
-    <ProjectTypeGuids>{A1591282-1198-4647-A2B1-27E5FF5F6F3B};{fae04ec0-301f-11d3-bf4b-00c04f79efbc}</ProjectTypeGuids>
-    <SilverlightApplication>false</SilverlightApplication>
-    <ValidateXaml>false</ValidateXaml>
-    <ThrowErrorsInValidation>false</ThrowErrorsInValidation>
-    <SilverlightVersion>v4.0</SilverlightVersion>
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Debug|AnyCPU' "">
-    <DebugSymbols>true</DebugSymbols>
-    <DebugType>full</DebugType>
-    <Optimize>false</Optimize>
-    <OutputPath>bin\SL40\Debug</OutputPath>
-    <IntermediateOutputPath>obj\SL40\Debug\</IntermediateOutputPath>
-    <DocumentationFile>$(OutputPath)\$(AssemblyName).xml</DocumentationFile>
-    <NoWarn>1591, 1570, 1571, 1572, 1573, 1574</NoWarn>
-    <DefineConstants>DEBUG;TRACE;$(EnvironmentFlavor);$(EnvironmentTemplate);NOSERIALIZABLE;NOSORTEDLIST</DefineConstants>
-    <ErrorReport>prompt</ErrorReport>
-    <WarningLevel>4</WarningLevel>
-    <NoStdLib>true</NoStdLib>
-    <GenerateSerializationAssemblies>Off</GenerateSerializationAssemblies>
-    <NoConfig>true</NoConfig>
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Release|AnyCPU' "">
-    <DebugType>pdbonly</DebugType>
-    <Optimize>true</Optimize>
-    <OutputPath>bin\SL40\Release</OutputPath>
-    <IntermediateOutputPath>obj\SL40\Release\</IntermediateOutputPath>
-    <DocumentationFile>$(OutputPath)\$(AssemblyName).xml</DocumentationFile>
-    <NoWarn>1591, 1570, 1571, 1572, 1573, 1574</NoWarn>
-    <DefineConstants>TRACE;$(EnvironmentFlavor);$(EnvironmentTemplate);NOSERIALIZABLE;NOSORTEDLIST</DefineConstants>
-    <ErrorReport>prompt</ErrorReport>
-    <WarningLevel>4</WarningLevel>
-    <NoStdLib>true</NoStdLib>
-    <GenerateSerializationAssemblies>Off</GenerateSerializationAssemblies>
-    <NoConfig>true</NoConfig>
-  </PropertyGroup>
-  <ItemGroup>
-    <Reference Include=""mscorlib"" />
-    <Reference Include=""System"" />
-    <Reference Include=""System.Xml"" />
-    <Reference Include=""System.Core"" />
-  </ItemGroup>
-  <ItemGroup>
-    <Compile Include=""AbstractBuilder.cs"" />
-    <Compile Include=""AbstractBuilderLite.cs"" />
-    <Compile Include=""AbstractMessage.cs"" />
-    <Compile Include=""AbstractMessageLite.cs"" />
-    <Compile Include=""ByteArray.cs"" />
-    <Compile Include=""ByteString.cs"" />
-    <Compile Include=""Collections\Enumerables.cs"" />
-    <Compile Include=""Collections\IPopsicleList.cs"" />
-    <Compile Include=""Collections\PopsicleList.cs"" />
-    <Compile Include=""CodedOutputStream.ComputeSize.cs"" />
-    <Compile Include=""CustomSerialization.cs"" />
-    <Compile Include=""Delegates.cs"" />
-    <Compile Include=""CodedInputStream.cs"" />
-    <Compile Include=""CodedOutputStream.cs"" />
-    <Compile Include=""Collections\Dictionaries.cs"" />
-    <Compile Include=""Collections\Lists.cs"" />
-    <Compile Include=""Collections\ReadOnlyDictionary.cs"" />
-    <Compile Include=""DescriptorProtos\CSharpOptions.cs"" />
-    <Compile Include=""DescriptorProtos\DescriptorProtoFile.cs"" />
-    <Compile Include=""DescriptorProtos\IDescriptorProto.cs"" />
-    <Compile Include=""DescriptorProtos\PartialClasses.cs"" />
-    <Compile Include=""Descriptors\DescriptorBase.cs"" />
-    <Compile Include=""Descriptors\DescriptorPool.cs"" />
-    <Compile Include=""Descriptors\DescriptorUtil.cs"" />
-    <Compile Include=""Descriptors\DescriptorValidationException.cs"" />
-    <Compile Include=""Descriptors\EnumDescriptor.cs"" />
-    <Compile Include=""Descriptors\EnumValueDescriptor.cs"" />
-    <Compile Include=""Descriptors\FieldDescriptor.cs"" />
-    <Compile Include=""Descriptors\FieldMappingAttribute.cs"" />
-    <Compile Include=""Descriptors\FieldType.cs"" />
-    <Compile Include=""Descriptors\FileDescriptor.cs"" />
-    <Compile Include=""Descriptors\IDescriptor.cs"" />
-    <Compile Include=""Descriptors\IndexedDescriptorBase.cs"" />
-    <Compile Include=""Descriptors\MappedType.cs"" />
-    <Compile Include=""Descriptors\MessageDescriptor.cs"" />
-    <Compile Include=""Descriptors\MethodDescriptor.cs"" />
-    <Compile Include=""Descriptors\PackageDescriptor.cs"" />
-    <Compile Include=""Descriptors\ServiceDescriptor.cs"" />
-    <Compile Include=""DynamicMessage.cs"" />
-    <Compile Include=""EnumLite.cs"" />
-    <Compile Include=""ExtendableBuilder.cs"" />
-    <Compile Include=""ExtendableBuilderLite.cs"" />
-    <Compile Include=""ExtendableMessage.cs"" />
-    <Compile Include=""ExtendableMessageLite.cs"" />
-    <Compile Include=""ExtensionInfo.cs"" />
-    <Compile Include=""ExtensionRegistry.cs"" />
-    <Compile Include=""ExtensionRegistryLite.cs"" />
-    <Compile Include=""FieldAccess\ReflectionUtil.cs"" />
-    <Compile Include=""FieldAccess\SingleEnumAccessor.cs"" />
-    <Compile Include=""FieldAccess\SingleMessageAccessor.cs"" />
-    <Compile Include=""FieldAccess\SinglePrimitiveAccessor.cs"" />
-    <Compile Include=""FieldAccess\RepeatedPrimitiveAccessor.cs"" />
-    <Compile Include=""FieldAccess\RepeatedEnumAccessor.cs"" />
-    <Compile Include=""FieldAccess\IFieldAccessor.cs"" />
-    <Compile Include=""FieldAccess\FieldAccessorTable.cs"" />
-    <Compile Include=""FieldAccess\RepeatedMessageAccessor.cs"" />
-    <Compile Include=""FieldSet.cs"" />
-    <Compile Include=""FrameworkPortability.cs"" />
-    <Compile Include=""GeneratedBuilder.cs"" />
-    <Compile Include=""GeneratedBuilderLite.cs"" />
-    <Compile Include=""GeneratedExtensionLite.cs"" />
-    <Compile Include=""GeneratedMessageLite.cs"" />
-    <Compile Include=""GeneratedRepeatExtension.cs"" />
-    <Compile Include=""GeneratedSingleExtension.cs"" />
-    <Compile Include=""GeneratedMessage.cs"" />
-    <Compile Include=""IBuilder.cs"" />
-    <Compile Include=""GeneratedExtensionBase.cs"" />
-    <Compile Include=""IBuilderLite.cs"" />
-    <Compile Include=""ICodedInputStream.cs"" />
-    <Compile Include=""ICodedOutputStream.cs"" />
-    <Compile Include=""IMessage.cs"" />
-    <Compile Include=""IMessageLite.cs"" />
-    <Compile Include=""InvalidProtocolBufferException.cs"" />
-    <Compile Include=""IRpcChannel.cs"" />
-    <Compile Include=""IRpcController.cs"" />
-    <Compile Include=""IRpcDispatch.cs"" />
-    <Compile Include=""IService.cs"" />
-    <Compile Include=""MessageStreamIterator.cs"" />
-    <Compile Include=""MessageStreamWriter.cs"" />
-    <Compile Include=""MessageUtil.cs"" />
-    <Compile Include=""NameHelpers.cs"" />
-    <Compile Include=""Properties\AssemblyInfo.cs"" />
-    <Compile Include=""RpcUtil.cs"" />
-    <Compile Include=""SortedList.cs"" />
-    <Compile Include=""TextFormat.cs"" />
-    <Compile Include=""TextGenerator.cs"" />
-    <Compile Include=""TextTokenizer.cs"" />
-    <Compile Include=""ThrowHelper.cs"" />
-    <Compile Include=""UninitializedMessageException.cs"" />
-    <Compile Include=""UnknownField.cs"" />
-    <Compile Include=""UnknownFieldSet.cs"" />
-    <Compile Include=""WireFormat.cs"" />
-  </ItemGroup>
-  <Import Project=""$(MSBuildExtensionsPath32)\Microsoft\Silverlight\$(SilverlightVersion)\Microsoft.Silverlight.CSharp.targets"" />
-  <ProjectExtensions>
-    <VisualStudio>
-      <FlavorProperties GUID=""{A1591282-1198-4647-A2B1-27E5FF5F6F3B}"">
-        <SilverlightProjectProperties>
-          <StartAction>OfflineApplication</StartAction>
-        </SilverlightProjectProperties>
-      </FlavorProperties>
-    </VisualStudio>
-  </ProjectExtensions>
-  <!-- To modify your build process, add your task inside one of the targets below and uncomment it. 
-       Other similar extension points exist, see Microsoft.Common.targets.
-  <Target Name=""BeforeBuild"">
-  </Target>
-  <Target Name=""AfterBuild"">
-  </Target>
-  -->
-</Project>
\ No newline at end of file
diff --git a/csharp/src/ProtocolBuffers/ProtocolBuffersLite.CF20.csproj b/csharp/src/ProtocolBuffers/ProtocolBuffersLite.CF20.csproj
deleted file mode 100644
index 6cf373f26..000000000
--- a/csharp/src/ProtocolBuffers/ProtocolBuffersLite.CF20.csproj
+++ /dev/null
@@ -1,111 +0,0 @@
-<Project ToolsVersion=""3.5"" DefaultTargets=""Build"" xmlns=""http://schemas.microsoft.com/developer/msbuild/2003"">
-  <PropertyGroup>
-    <EnvironmentFlavor>COMPACT_FRAMEWORK</EnvironmentFlavor>
-    <EnvironmentTemplate>CF20</EnvironmentTemplate>
-    <Configuration Condition="" '$(Configuration)' == '' "">Debug</Configuration>
-    <Platform Condition="" '$(Platform)' == '' "">AnyCPU</Platform>
-    <ProductVersion>9.0.30729</ProductVersion>
-    <SchemaVersion>2.0</SchemaVersion>
-    <ProjectGuid>{6969BDCE-D925-43F3-94AC-A531E6DF2591}</ProjectGuid>
-    <OutputType>Library</OutputType>
-    <AppDesignerFolder>Properties</AppDesignerFolder>
-    <RootNamespace>Google.ProtocolBuffers</RootNamespace>
-    <AssemblyName>Google.ProtocolBuffersLite</AssemblyName>
-    <TargetFrameworkVersion>v2.0</TargetFrameworkVersion>
-    <FileAlignment>512</FileAlignment>
-    <SignAssembly>true</SignAssembly>
-    <AssemblyOriginatorKeyFile>..\..\keys\Google.ProtocolBuffers.snk</AssemblyOriginatorKeyFile>
-    <OldToolsVersion>3.5</OldToolsVersion>
-    <ProjectTypeGuids>{4D628B5B-2FBC-4AA6-8C16-197242AEB884};{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}</ProjectTypeGuids>
-    <PlatformFamilyName>Smartphone</PlatformFamilyName>
-    <PlatformID>f27da329-3269-4191-98e0-c87d3d7f1db9</PlatformID>
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Debug|AnyCPU' "">
-    <DebugSymbols>true</DebugSymbols>
-    <DebugType>full</DebugType>
-    <Optimize>false</Optimize>
-    <OutputPath>bin\CF20\Debug</OutputPath>
-    <IntermediateOutputPath>obj\CF20\Debug\</IntermediateOutputPath>
-    <DocumentationFile>$(OutputPath)\$(AssemblyName).xml</DocumentationFile>
-    <NoWarn>1591, 1570, 1571, 1572, 1573, 1574</NoWarn>
-    <DefineConstants>DEBUG;TRACE;LITE;$(EnvironmentFlavor);$(EnvironmentTemplate);NOSERIALIZABLE;NOFILEVERSION;NOEXTENSIONS</DefineConstants>
-    <ErrorReport>prompt</ErrorReport>
-    <WarningLevel>4</WarningLevel>
-    <NoStdLib>true</NoStdLib>
-    <GenerateSerializationAssemblies>Off</GenerateSerializationAssemblies>
-    <NoConfig>true</NoConfig>
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Release|AnyCPU' "">
-    <DebugType>pdbonly</DebugType>
-    <Optimize>true</Optimize>
-    <OutputPath>bin\CF20\Release</OutputPath>
-    <IntermediateOutputPath>obj\CF20\Release\</IntermediateOutputPath>
-    <DocumentationFile>$(OutputPath)\$(AssemblyName).xml</DocumentationFile>
-    <NoWarn>1591, 1570, 1571, 1572, 1573, 1574</NoWarn>
-    <DefineConstants>TRACE;LITE;$(EnvironmentFlavor);$(EnvironmentTemplate);NOSERIALIZABLE;NOFILEVERSION;NOEXTENSIONS</DefineConstants>
-    <ErrorReport>prompt</ErrorReport>
-    <WarningLevel>4</WarningLevel>
-    <NoStdLib>true</NoStdLib>
-    <GenerateSerializationAssemblies>Off</GenerateSerializationAssemblies>
-    <NoConfig>true</NoConfig>
-  </PropertyGroup>
-  <ItemGroup>
-    <Reference Include=""mscorlib"" />
-    <Reference Include=""System"" />
-    <Reference Include=""System.Xml"" />
-  </ItemGroup>
-  <ItemGroup>
-    <Compile Include=""AbstractBuilderLite.cs"" />
-    <Compile Include=""AbstractMessageLite.cs"" />
-    <Compile Include=""ByteArray.cs"" />
-    <Compile Include=""CodedOutputStream.ComputeSize.cs"" />
-    <Compile Include=""Collections\Dictionaries.cs"" />
-    <Compile Include=""Collections\Enumerables.cs"" />
-    <Compile Include=""Collections\IPopsicleList.cs"" />
-    <Compile Include=""Collections\Lists.cs"" />
-    <Compile Include=""Collections\PopsicleList.cs"" />
-    <Compile Include=""Collections\ReadOnlyDictionary.cs"" />
-    <Compile Include=""CustomSerialization.cs"" />
-    <Compile Include=""Descriptors\FieldMappingAttribute.cs"" />
-    <Compile Include=""Descriptors\FieldType.cs"" />
-    <Compile Include=""Descriptors\MappedType.cs"" />
-    <Compile Include=""EnumLite.cs"" />
-    <Compile Include=""ExtendableBuilderLite.cs"" />
-    <Compile Include=""ExtendableMessageLite.cs"" />
-    <Compile Include=""FieldSet.cs"" />
-    <Compile Include=""FrameworkPortability.cs"" />
-    <Compile Include=""GeneratedBuilderLite.cs"" />
-    <Compile Include=""GeneratedExtensionLite.cs"" />
-    <Compile Include=""GeneratedMessageLite.cs"" />
-    <Compile Include=""ICodedInputStream.cs"" />
-    <Compile Include=""ICodedOutputStream.cs"" />
-    <Compile Include=""IRpcDispatch.cs"" />
-    <Compile Include=""Properties\AssemblyInfo.cs"" />
-    <Compile Include=""ByteString.cs"" />
-    <Compile Include=""CodedInputStream.cs"" />
-    <Compile Include=""CodedOutputStream.cs"" />
-    <Compile Include=""ExtensionRegistryLite.cs"" />
-    <Compile Include=""IBuilderLite.cs"" />
-    <Compile Include=""IMessageLite.cs"" />
-    <Compile Include=""InvalidProtocolBufferException.cs"" />
-    <Compile Include=""SortedList.cs"" />
-    <Compile Include=""ThrowHelper.cs"" />
-    <Compile Include=""UninitializedMessageException.cs"" />
-    <Compile Include=""WireFormat.cs"" />
-  </ItemGroup>
-  <Import Project=""$(MSBuildBinPath)\Microsoft.CompactFramework.CSharp.targets"" />
-  <ProjectExtensions>
-    <VisualStudio>
-      <FlavorProperties GUID=""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"">
-        <HostingProcess disable=""1"" />
-      </FlavorProperties>
-    </VisualStudio>
-  </ProjectExtensions>
-  <!-- To modify your build process, add your task inside one of the targets below and uncomment it. 
-       Other similar extension points exist, see Microsoft.Common.targets.
-  <Target Name=""BeforeBuild"">
-  </Target>
-  <Target Name=""AfterBuild"">
-  </Target>
-  -->
-</Project>
\ No newline at end of file
diff --git a/csharp/src/ProtocolBuffers/ProtocolBuffersLite.CF35.csproj b/csharp/src/ProtocolBuffers/ProtocolBuffersLite.CF35.csproj
deleted file mode 100644
index dad00719d..000000000
--- a/csharp/src/ProtocolBuffers/ProtocolBuffersLite.CF35.csproj
+++ /dev/null
@@ -1,112 +0,0 @@
-<Project ToolsVersion=""3.5"" DefaultTargets=""Build"" xmlns=""http://schemas.microsoft.com/developer/msbuild/2003"">
-  <PropertyGroup>
-    <EnvironmentFlavor>COMPACT_FRAMEWORK</EnvironmentFlavor>
-    <EnvironmentTemplate>CF35</EnvironmentTemplate>
-    <Configuration Condition="" '$(Configuration)' == '' "">Debug</Configuration>
-    <Platform Condition="" '$(Platform)' == '' "">AnyCPU</Platform>
-    <ProductVersion>9.0.30729</ProductVersion>
-    <SchemaVersion>2.0</SchemaVersion>
-    <ProjectGuid>{6969BDCE-D925-43F3-94AC-A531E6DF2591}</ProjectGuid>
-    <OutputType>Library</OutputType>
-    <AppDesignerFolder>Properties</AppDesignerFolder>
-    <RootNamespace>Google.ProtocolBuffers</RootNamespace>
-    <AssemblyName>Google.ProtocolBuffersLite</AssemblyName>
-    <TargetFrameworkVersion>v3.5</TargetFrameworkVersion>
-    <FileAlignment>512</FileAlignment>
-    <SignAssembly>true</SignAssembly>
-    <AssemblyOriginatorKeyFile>..\..\keys\Google.ProtocolBuffers.snk</AssemblyOriginatorKeyFile>
-    <OldToolsVersion>3.5</OldToolsVersion>
-    <ProjectTypeGuids>{4D628B5B-2FBC-4AA6-8C16-197242AEB884};{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}</ProjectTypeGuids>
-    <PlatformFamilyName>Smartphone</PlatformFamilyName>
-    <PlatformID>f27da329-3269-4191-98e0-c87d3d7f1db9</PlatformID>
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Debug|AnyCPU' "">
-    <DebugSymbols>true</DebugSymbols>
-    <DebugType>full</DebugType>
-    <Optimize>false</Optimize>
-    <OutputPath>bin\CF35\Debug</OutputPath>
-    <IntermediateOutputPath>obj\CF35\Debug\</IntermediateOutputPath>
-    <DocumentationFile>$(OutputPath)\$(AssemblyName).xml</DocumentationFile>
-    <NoWarn>1591, 1570, 1571, 1572, 1573, 1574</NoWarn>
-    <DefineConstants>DEBUG;TRACE;LITE;$(EnvironmentFlavor);$(EnvironmentTemplate);NOSERIALIZABLE;NOFILEVERSION</DefineConstants>
-    <ErrorReport>prompt</ErrorReport>
-    <WarningLevel>4</WarningLevel>
-    <NoStdLib>true</NoStdLib>
-    <GenerateSerializationAssemblies>Off</GenerateSerializationAssemblies>
-    <NoConfig>true</NoConfig>
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Release|AnyCPU' "">
-    <DebugType>pdbonly</DebugType>
-    <Optimize>true</Optimize>
-    <OutputPath>bin\CF35\Release</OutputPath>
-    <IntermediateOutputPath>obj\CF35\Release\</IntermediateOutputPath>
-    <DocumentationFile>$(OutputPath)\$(AssemblyName).xml</DocumentationFile>
-    <NoWarn>1591, 1570, 1571, 1572, 1573, 1574</NoWarn>
-    <DefineConstants>TRACE;LITE;$(EnvironmentFlavor);$(EnvironmentTemplate);NOSERIALIZABLE;NOFILEVERSION</DefineConstants>
-    <ErrorReport>prompt</ErrorReport>
-    <WarningLevel>4</WarningLevel>
-    <NoStdLib>true</NoStdLib>
-    <GenerateSerializationAssemblies>Off</GenerateSerializationAssemblies>
-    <NoConfig>true</NoConfig>
-  </PropertyGroup>
-  <ItemGroup>
-    <Reference Include=""mscorlib"" />
-    <Reference Include=""System"" />
-    <Reference Include=""System.Xml"" />
-    <Reference Include=""System.Core"" />
-  </ItemGroup>
-  <ItemGroup>
-    <Compile Include=""AbstractBuilderLite.cs"" />
-    <Compile Include=""AbstractMessageLite.cs"" />
-    <Compile Include=""ByteArray.cs"" />
-    <Compile Include=""CodedOutputStream.ComputeSize.cs"" />
-    <Compile Include=""Collections\Dictionaries.cs"" />
-    <Compile Include=""Collections\Enumerables.cs"" />
-    <Compile Include=""Collections\IPopsicleList.cs"" />
-    <Compile Include=""Collections\Lists.cs"" />
-    <Compile Include=""Collections\PopsicleList.cs"" />
-    <Compile Include=""Collections\ReadOnlyDictionary.cs"" />
-    <Compile Include=""CustomSerialization.cs"" />
-    <Compile Include=""Descriptors\FieldMappingAttribute.cs"" />
-    <Compile Include=""Descriptors\FieldType.cs"" />
-    <Compile Include=""Descriptors\MappedType.cs"" />
-    <Compile Include=""EnumLite.cs"" />
-    <Compile Include=""ExtendableBuilderLite.cs"" />
-    <Compile Include=""ExtendableMessageLite.cs"" />
-    <Compile Include=""FieldSet.cs"" />
-    <Compile Include=""FrameworkPortability.cs"" />
-    <Compile Include=""GeneratedBuilderLite.cs"" />
-    <Compile Include=""GeneratedExtensionLite.cs"" />
-    <Compile Include=""GeneratedMessageLite.cs"" />
-    <Compile Include=""ICodedInputStream.cs"" />
-    <Compile Include=""ICodedOutputStream.cs"" />
-    <Compile Include=""IRpcDispatch.cs"" />
-    <Compile Include=""Properties\AssemblyInfo.cs"" />
-    <Compile Include=""ByteString.cs"" />
-    <Compile Include=""CodedInputStream.cs"" />
-    <Compile Include=""CodedOutputStream.cs"" />
-    <Compile Include=""ExtensionRegistryLite.cs"" />
-    <Compile Include=""IBuilderLite.cs"" />
-    <Compile Include=""IMessageLite.cs"" />
-    <Compile Include=""InvalidProtocolBufferException.cs"" />
-    <Compile Include=""SortedList.cs"" />
-    <Compile Include=""ThrowHelper.cs"" />
-    <Compile Include=""UninitializedMessageException.cs"" />
-    <Compile Include=""WireFormat.cs"" />
-  </ItemGroup>
-  <Import Project=""$(MSBuildBinPath)\Microsoft.CompactFramework.CSharp.targets"" />
-  <ProjectExtensions>
-    <VisualStudio>
-      <FlavorProperties GUID=""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"">
-        <HostingProcess disable=""1"" />
-      </FlavorProperties>
-    </VisualStudio>
-  </ProjectExtensions>
-  <!-- To modify your build process, add your task inside one of the targets below and uncomment it. 
-       Other similar extension points exist, see Microsoft.Common.targets.
-  <Target Name=""BeforeBuild"">
-  </Target>
-  <Target Name=""AfterBuild"">
-  </Target>
-  -->
-</Project>
\ No newline at end of file
diff --git a/csharp/src/ProtocolBuffers/ProtocolBuffersLite.NET20.csproj b/csharp/src/ProtocolBuffers/ProtocolBuffersLite.NET20.csproj
deleted file mode 100644
index d51677688..000000000
--- a/csharp/src/ProtocolBuffers/ProtocolBuffersLite.NET20.csproj
+++ /dev/null
@@ -1,99 +0,0 @@
-<Project ToolsVersion=""3.5"" DefaultTargets=""Build"" xmlns=""http://schemas.microsoft.com/developer/msbuild/2003"">
-  <PropertyGroup>
-    <EnvironmentFlavor>CLIENTPROFILE</EnvironmentFlavor>
-    <EnvironmentTemplate>NET20</EnvironmentTemplate>
-    <Configuration Condition="" '$(Configuration)' == '' "">Debug</Configuration>
-    <Platform Condition="" '$(Platform)' == '' "">AnyCPU</Platform>
-    <ProductVersion>9.0.30729</ProductVersion>
-    <SchemaVersion>2.0</SchemaVersion>
-    <ProjectGuid>{6969BDCE-D925-43F3-94AC-A531E6DF2591}</ProjectGuid>
-    <OutputType>Library</OutputType>
-    <AppDesignerFolder>Properties</AppDesignerFolder>
-    <RootNamespace>Google.ProtocolBuffers</RootNamespace>
-    <AssemblyName>Google.ProtocolBuffersLite</AssemblyName>
-    <TargetFrameworkVersion>v2.0</TargetFrameworkVersion>
-    <FileAlignment>512</FileAlignment>
-    <SignAssembly>true</SignAssembly>
-    <AssemblyOriginatorKeyFile>..\..\keys\Google.ProtocolBuffers.snk</AssemblyOriginatorKeyFile>
-    <OldToolsVersion>3.5</OldToolsVersion>
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Debug|AnyCPU' "">
-    <DebugSymbols>true</DebugSymbols>
-    <DebugType>full</DebugType>
-    <Optimize>false</Optimize>
-    <OutputPath>bin\NET20\Debug</OutputPath>
-    <IntermediateOutputPath>obj\NET20\Debug\</IntermediateOutputPath>
-    <DocumentationFile>$(OutputPath)\$(AssemblyName).xml</DocumentationFile>
-    <NoWarn>1591, 1570, 1571, 1572, 1573, 1574</NoWarn>
-    <DefineConstants>DEBUG;TRACE;LITE;$(EnvironmentFlavor);$(EnvironmentTemplate);NOEXTENSIONS</DefineConstants>
-    <ErrorReport>prompt</ErrorReport>
-    <WarningLevel>4</WarningLevel>
-    <NoStdLib>true</NoStdLib>
-    <GenerateSerializationAssemblies>Off</GenerateSerializationAssemblies>
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Release|AnyCPU' "">
-    <DebugType>pdbonly</DebugType>
-    <Optimize>true</Optimize>
-    <OutputPath>bin\NET20\Release</OutputPath>
-    <IntermediateOutputPath>obj\NET20\Release\</IntermediateOutputPath>
-    <DocumentationFile>$(OutputPath)\$(AssemblyName).xml</DocumentationFile>
-    <NoWarn>1591, 1570, 1571, 1572, 1573, 1574</NoWarn>
-    <DefineConstants>TRACE;LITE;$(EnvironmentFlavor);$(EnvironmentTemplate);NOEXTENSIONS</DefineConstants>
-    <ErrorReport>prompt</ErrorReport>
-    <WarningLevel>4</WarningLevel>
-    <NoStdLib>true</NoStdLib>
-    <GenerateSerializationAssemblies>Off</GenerateSerializationAssemblies>
-  </PropertyGroup>
-  <ItemGroup>
-    <Reference Include=""mscorlib"" />
-    <Reference Include=""System"" />
-    <Reference Include=""System.Xml"" />
-  </ItemGroup>
-  <ItemGroup>
-    <Compile Include=""AbstractBuilderLite.cs"" />
-    <Compile Include=""AbstractMessageLite.cs"" />
-    <Compile Include=""ByteArray.cs"" />
-    <Compile Include=""CodedOutputStream.ComputeSize.cs"" />
-    <Compile Include=""Collections\Dictionaries.cs"" />
-    <Compile Include=""Collections\Enumerables.cs"" />
-    <Compile Include=""Collections\IPopsicleList.cs"" />
-    <Compile Include=""Collections\Lists.cs"" />
-    <Compile Include=""Collections\PopsicleList.cs"" />
-    <Compile Include=""Collections\ReadOnlyDictionary.cs"" />
-    <Compile Include=""CustomSerialization.cs"" />
-    <Compile Include=""Descriptors\FieldMappingAttribute.cs"" />
-    <Compile Include=""Descriptors\FieldType.cs"" />
-    <Compile Include=""Descriptors\MappedType.cs"" />
-    <Compile Include=""EnumLite.cs"" />
-    <Compile Include=""ExtendableBuilderLite.cs"" />
-    <Compile Include=""ExtendableMessageLite.cs"" />
-    <Compile Include=""FieldSet.cs"" />
-    <Compile Include=""FrameworkPortability.cs"" />
-    <Compile Include=""GeneratedBuilderLite.cs"" />
-    <Compile Include=""GeneratedExtensionLite.cs"" />
-    <Compile Include=""GeneratedMessageLite.cs"" />
-    <Compile Include=""ICodedInputStream.cs"" />
-    <Compile Include=""ICodedOutputStream.cs"" />
-    <Compile Include=""IRpcDispatch.cs"" />
-    <Compile Include=""Properties\AssemblyInfo.cs"" />
-    <Compile Include=""ByteString.cs"" />
-    <Compile Include=""CodedInputStream.cs"" />
-    <Compile Include=""CodedOutputStream.cs"" />
-    <Compile Include=""ExtensionRegistryLite.cs"" />
-    <Compile Include=""IBuilderLite.cs"" />
-    <Compile Include=""IMessageLite.cs"" />
-    <Compile Include=""InvalidProtocolBufferException.cs"" />
-    <Compile Include=""SortedList.cs"" />
-    <Compile Include=""ThrowHelper.cs"" />
-    <Compile Include=""UninitializedMessageException.cs"" />
-    <Compile Include=""WireFormat.cs"" />
-  </ItemGroup>
-  <Import Project=""$(MSBuildToolsPath)\Microsoft.CSharp.targets"" />
-  <!-- To modify your build process, add your task inside one of the targets below and uncomment it. 
-       Other similar extension points exist, see Microsoft.Common.targets.
-  <Target Name=""BeforeBuild"">
-  </Target>
-  <Target Name=""AfterBuild"">
-  </Target>
-  -->
-</Project>
\ No newline at end of file
diff --git a/csharp/src/ProtocolBuffers/ProtocolBuffersLite.NET35.csproj b/csharp/src/ProtocolBuffers/ProtocolBuffersLite.NET35.csproj
deleted file mode 100644
index d811fb58d..000000000
--- a/csharp/src/ProtocolBuffers/ProtocolBuffersLite.NET35.csproj
+++ /dev/null
@@ -1,100 +0,0 @@
-<Project ToolsVersion=""3.5"" DefaultTargets=""Build"" xmlns=""http://schemas.microsoft.com/developer/msbuild/2003"">
-  <PropertyGroup>
-    <EnvironmentFlavor>CLIENTPROFILE</EnvironmentFlavor>
-    <EnvironmentTemplate>NET35</EnvironmentTemplate>
-    <Configuration Condition="" '$(Configuration)' == '' "">Debug</Configuration>
-    <Platform Condition="" '$(Platform)' == '' "">AnyCPU</Platform>
-    <ProductVersion>9.0.30729</ProductVersion>
-    <SchemaVersion>2.0</SchemaVersion>
-    <ProjectGuid>{6969BDCE-D925-43F3-94AC-A531E6DF2591}</ProjectGuid>
-    <OutputType>Library</OutputType>
-    <AppDesignerFolder>Properties</AppDesignerFolder>
-    <RootNamespace>Google.ProtocolBuffers</RootNamespace>
-    <AssemblyName>Google.ProtocolBuffersLite</AssemblyName>
-    <TargetFrameworkVersion>v3.5</TargetFrameworkVersion>
-    <FileAlignment>512</FileAlignment>
-    <SignAssembly>true</SignAssembly>
-    <AssemblyOriginatorKeyFile>..\..\keys\Google.ProtocolBuffers.snk</AssemblyOriginatorKeyFile>
-    <OldToolsVersion>3.5</OldToolsVersion>
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Debug|AnyCPU' "">
-    <DebugSymbols>true</DebugSymbols>
-    <DebugType>full</DebugType>
-    <Optimize>false</Optimize>
-    <OutputPath>bin\NET35\Debug</OutputPath>
-    <IntermediateOutputPath>obj\NET35\Debug\</IntermediateOutputPath>
-    <DocumentationFile>$(OutputPath)\$(AssemblyName).xml</DocumentationFile>
-    <NoWarn>1591, 1570, 1571, 1572, 1573, 1574</NoWarn>
-    <DefineConstants>DEBUG;TRACE;LITE;$(EnvironmentFlavor);$(EnvironmentTemplate)</DefineConstants>
-    <ErrorReport>prompt</ErrorReport>
-    <WarningLevel>4</WarningLevel>
-    <NoStdLib>true</NoStdLib>
-    <GenerateSerializationAssemblies>Off</GenerateSerializationAssemblies>
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Release|AnyCPU' "">
-    <DebugType>pdbonly</DebugType>
-    <Optimize>true</Optimize>
-    <OutputPath>bin\NET35\Release</OutputPath>
-    <IntermediateOutputPath>obj\NET35\Release\</IntermediateOutputPath>
-    <DocumentationFile>$(OutputPath)\$(AssemblyName).xml</DocumentationFile>
-    <NoWarn>1591, 1570, 1571, 1572, 1573, 1574</NoWarn>
-    <DefineConstants>TRACE;LITE;$(EnvironmentFlavor);$(EnvironmentTemplate)</DefineConstants>
-    <ErrorReport>prompt</ErrorReport>
-    <WarningLevel>4</WarningLevel>
-    <NoStdLib>true</NoStdLib>
-    <GenerateSerializationAssemblies>Off</GenerateSerializationAssemblies>
-  </PropertyGroup>
-  <ItemGroup>
-    <Reference Include=""mscorlib"" />
-    <Reference Include=""System"" />
-    <Reference Include=""System.Xml"" />
-    <Reference Include=""System.Core"" />
-  </ItemGroup>
-  <ItemGroup>
-    <Compile Include=""AbstractBuilderLite.cs"" />
-    <Compile Include=""AbstractMessageLite.cs"" />
-    <Compile Include=""ByteArray.cs"" />
-    <Compile Include=""CodedOutputStream.ComputeSize.cs"" />
-    <Compile Include=""Collections\Dictionaries.cs"" />
-    <Compile Include=""Collections\Enumerables.cs"" />
-    <Compile Include=""Collections\IPopsicleList.cs"" />
-    <Compile Include=""Collections\Lists.cs"" />
-    <Compile Include=""Collections\PopsicleList.cs"" />
-    <Compile Include=""Collections\ReadOnlyDictionary.cs"" />
-    <Compile Include=""CustomSerialization.cs"" />
-    <Compile Include=""Descriptors\FieldMappingAttribute.cs"" />
-    <Compile Include=""Descriptors\FieldType.cs"" />
-    <Compile Include=""Descriptors\MappedType.cs"" />
-    <Compile Include=""EnumLite.cs"" />
-    <Compile Include=""ExtendableBuilderLite.cs"" />
-    <Compile Include=""ExtendableMessageLite.cs"" />
-    <Compile Include=""FieldSet.cs"" />
-    <Compile Include=""FrameworkPortability.cs"" />
-    <Compile Include=""GeneratedBuilderLite.cs"" />
-    <Compile Include=""GeneratedExtensionLite.cs"" />
-    <Compile Include=""GeneratedMessageLite.cs"" />
-    <Compile Include=""ICodedInputStream.cs"" />
-    <Compile Include=""ICodedOutputStream.cs"" />
-    <Compile Include=""IRpcDispatch.cs"" />
-    <Compile Include=""Properties\AssemblyInfo.cs"" />
-    <Compile Include=""ByteString.cs"" />
-    <Compile Include=""CodedInputStream.cs"" />
-    <Compile Include=""CodedOutputStream.cs"" />
-    <Compile Include=""ExtensionRegistryLite.cs"" />
-    <Compile Include=""IBuilderLite.cs"" />
-    <Compile Include=""IMessageLite.cs"" />
-    <Compile Include=""InvalidProtocolBufferException.cs"" />
-    <Compile Include=""SortedList.cs"" />
-    <Compile Include=""ThrowHelper.cs"" />
-    <Compile Include=""UninitializedMessageException.cs"" />
-    <Compile Include=""WireFormat.cs"" />
-  </ItemGroup>
-  <Import Project=""$(MSBuildToolsPath)\Microsoft.CSharp.targets"" />
-  <!-- To modify your build process, add your task inside one of the targets below and uncomment it. 
-       Other similar extension points exist, see Microsoft.Common.targets.
-  <Target Name=""BeforeBuild"">
-  </Target>
-  <Target Name=""AfterBuild"">
-  </Target>
-  -->
-</Project>
\ No newline at end of file
diff --git a/csharp/src/ProtocolBuffers/ProtocolBuffersLite.NET40.csproj b/csharp/src/ProtocolBuffers/ProtocolBuffersLite.NET40.csproj
deleted file mode 100644
index ad3abc6c2..000000000
--- a/csharp/src/ProtocolBuffers/ProtocolBuffersLite.NET40.csproj
+++ /dev/null
@@ -1,100 +0,0 @@
-<Project ToolsVersion=""4.0"" DefaultTargets=""Build"" xmlns=""http://schemas.microsoft.com/developer/msbuild/2003"">
-  <PropertyGroup>
-    <EnvironmentFlavor>CLIENTPROFILE</EnvironmentFlavor>
-    <EnvironmentTemplate>NET40</EnvironmentTemplate>
-    <Configuration Condition="" '$(Configuration)' == '' "">Debug</Configuration>
-    <Platform Condition="" '$(Platform)' == '' "">AnyCPU</Platform>
-    <ProductVersion>9.0.30729</ProductVersion>
-    <SchemaVersion>2.0</SchemaVersion>
-    <ProjectGuid>{6969BDCE-D925-43F3-94AC-A531E6DF2591}</ProjectGuid>
-    <OutputType>Library</OutputType>
-    <AppDesignerFolder>Properties</AppDesignerFolder>
-    <RootNamespace>Google.ProtocolBuffers</RootNamespace>
-    <AssemblyName>Google.ProtocolBuffersLite</AssemblyName>
-    <TargetFrameworkVersion>v4.0</TargetFrameworkVersion>
-    <FileAlignment>512</FileAlignment>
-    <SignAssembly>true</SignAssembly>
-    <AssemblyOriginatorKeyFile>..\..\keys\Google.ProtocolBuffers.snk</AssemblyOriginatorKeyFile>
-    <OldToolsVersion>3.5</OldToolsVersion>
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Debug|AnyCPU' "">
-    <DebugSymbols>true</DebugSymbols>
-    <DebugType>full</DebugType>
-    <Optimize>false</Optimize>
-    <OutputPath>bin\NET40\Debug</OutputPath>
-    <IntermediateOutputPath>obj\NET40\Debug\</IntermediateOutputPath>
-    <DocumentationFile>$(OutputPath)\$(AssemblyName).xml</DocumentationFile>
-    <NoWarn>1591, 1570, 1571, 1572, 1573, 1574</NoWarn>
-    <DefineConstants>DEBUG;TRACE;LITE;$(EnvironmentFlavor);$(EnvironmentTemplate)</DefineConstants>
-    <ErrorReport>prompt</ErrorReport>
-    <WarningLevel>4</WarningLevel>
-    <NoStdLib>true</NoStdLib>
-    <GenerateSerializationAssemblies>Off</GenerateSerializationAssemblies>
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Release|AnyCPU' "">
-    <DebugType>pdbonly</DebugType>
-    <Optimize>true</Optimize>
-    <OutputPath>bin\NET40\Release</OutputPath>
-    <IntermediateOutputPath>obj\NET40\Release\</IntermediateOutputPath>
-    <DocumentationFile>$(OutputPath)\$(AssemblyName).xml</DocumentationFile>
-    <NoWarn>1591, 1570, 1571, 1572, 1573, 1574</NoWarn>
-    <DefineConstants>TRACE;LITE;$(EnvironmentFlavor);$(EnvironmentTemplate)</DefineConstants>
-    <ErrorReport>prompt</ErrorReport>
-    <WarningLevel>4</WarningLevel>
-    <NoStdLib>true</NoStdLib>
-    <GenerateSerializationAssemblies>Off</GenerateSerializationAssemblies>
-  </PropertyGroup>
-  <ItemGroup>
-    <Reference Include=""mscorlib"" />
-    <Reference Include=""System"" />
-    <Reference Include=""System.Xml"" />
-    <Reference Include=""System.Core"" />
-  </ItemGroup>
-  <ItemGroup>
-    <Compile Include=""AbstractBuilderLite.cs"" />
-    <Compile Include=""AbstractMessageLite.cs"" />
-    <Compile Include=""ByteArray.cs"" />
-    <Compile Include=""CodedOutputStream.ComputeSize.cs"" />
-    <Compile Include=""Collections\Dictionaries.cs"" />
-    <Compile Include=""Collections\Enumerables.cs"" />
-    <Compile Include=""Collections\IPopsicleList.cs"" />
-    <Compile Include=""Collections\Lists.cs"" />
-    <Compile Include=""Collections\PopsicleList.cs"" />
-    <Compile Include=""Collections\ReadOnlyDictionary.cs"" />
-    <Compile Include=""CustomSerialization.cs"" />
-    <Compile Include=""Descriptors\FieldMappingAttribute.cs"" />
-    <Compile Include=""Descriptors\FieldType.cs"" />
-    <Compile Include=""Descriptors\MappedType.cs"" />
-    <Compile Include=""EnumLite.cs"" />
-    <Compile Include=""ExtendableBuilderLite.cs"" />
-    <Compile Include=""ExtendableMessageLite.cs"" />
-    <Compile Include=""FieldSet.cs"" />
-    <Compile Include=""FrameworkPortability.cs"" />
-    <Compile Include=""GeneratedBuilderLite.cs"" />
-    <Compile Include=""GeneratedExtensionLite.cs"" />
-    <Compile Include=""GeneratedMessageLite.cs"" />
-    <Compile Include=""ICodedInputStream.cs"" />
-    <Compile Include=""ICodedOutputStream.cs"" />
-    <Compile Include=""IRpcDispatch.cs"" />
-    <Compile Include=""Properties\AssemblyInfo.cs"" />
-    <Compile Include=""ByteString.cs"" />
-    <Compile Include=""CodedInputStream.cs"" />
-    <Compile Include=""CodedOutputStream.cs"" />
-    <Compile Include=""ExtensionRegistryLite.cs"" />
-    <Compile Include=""IBuilderLite.cs"" />
-    <Compile Include=""IMessageLite.cs"" />
-    <Compile Include=""InvalidProtocolBufferException.cs"" />
-    <Compile Include=""SortedList.cs"" />
-    <Compile Include=""ThrowHelper.cs"" />
-    <Compile Include=""UninitializedMessageException.cs"" />
-    <Compile Include=""WireFormat.cs"" />
-  </ItemGroup>
-  <Import Project=""$(MSBuildToolsPath)\Microsoft.CSharp.targets"" />
-  <!-- To modify your build process, add your task inside one of the targets below and uncomment it. 
-       Other similar extension points exist, see Microsoft.Common.targets.
-  <Target Name=""BeforeBuild"">
-  </Target>
-  <Target Name=""AfterBuild"">
-  </Target>
-  -->
-</Project>
\ No newline at end of file
diff --git a/csharp/src/ProtocolBuffers/ProtocolBuffersLite.PL40.csproj b/csharp/src/ProtocolBuffers/ProtocolBuffersLite.PL40.csproj
deleted file mode 100644
index 67f9093e3..000000000
--- a/csharp/src/ProtocolBuffers/ProtocolBuffersLite.PL40.csproj
+++ /dev/null
@@ -1,103 +0,0 @@
-<Project ToolsVersion=""4.0"" DefaultTargets=""Build"" xmlns=""http://schemas.microsoft.com/developer/msbuild/2003"" xmlns:cs=""urn:schemas-csharp-project:template"">
-  <PropertyGroup>
-    <EnvironmentFlavor>PORTABLE_LIBRARY</EnvironmentFlavor>
-    <EnvironmentTemplate>PL40</EnvironmentTemplate>
-    <Configuration Condition="" '$(Configuration)' == '' "">Debug</Configuration>
-    <Platform Condition="" '$(Platform)' == '' "">AnyCPU</Platform>
-    <ProductVersion>9.0.30729</ProductVersion>
-    <SchemaVersion>2.0</SchemaVersion>
-    <ProjectGuid>{6969BDCE-D925-43F3-94AC-A531E6DF2591}</ProjectGuid>
-    <OutputType>Library</OutputType>
-    <AppDesignerFolder>Properties</AppDesignerFolder>
-    <RootNamespace>Google.ProtocolBuffers</RootNamespace>
-    <AssemblyName>Google.ProtocolBuffersLite</AssemblyName>
-    <TargetFrameworkVersion>v4.0</TargetFrameworkVersion>
-    <FileAlignment>512</FileAlignment>
-    <SignAssembly>true</SignAssembly>
-    <AssemblyOriginatorKeyFile>..\..\keys\Google.ProtocolBuffers.snk</AssemblyOriginatorKeyFile>
-    <OldToolsVersion>3.5</OldToolsVersion>
-    <MinimumVisualStudioVersion>10.0</MinimumVisualStudioVersion>
-    <ProjectTypeGuids>{786C830F-07A1-408B-BD7F-6EE04809D6DB};{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}</ProjectTypeGuids>
-    <TargetFrameworkProfile>Profile1</TargetFrameworkProfile>
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Debug|AnyCPU' "">
-    <DebugSymbols>true</DebugSymbols>
-    <DebugType>full</DebugType>
-    <Optimize>false</Optimize>
-    <OutputPath>bin\PL40\Debug</OutputPath>
-    <IntermediateOutputPath>obj\PL40\Debug\</IntermediateOutputPath>
-    <DocumentationFile>$(OutputPath)\$(AssemblyName).xml</DocumentationFile>
-    <NoWarn>1591, 1570, 1571, 1572, 1573, 1574</NoWarn>
-    <DefineConstants>DEBUG;TRACE;LITE;$(EnvironmentFlavor);$(EnvironmentTemplate);NOSERIALIZABLE;NOSORTEDLIST</DefineConstants>
-    <ErrorReport>prompt</ErrorReport>
-    <WarningLevel>4</WarningLevel>
-    <NoStdLib>true</NoStdLib>
-    <GenerateSerializationAssemblies>Off</GenerateSerializationAssemblies>
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Release|AnyCPU' "">
-    <DebugType>pdbonly</DebugType>
-    <Optimize>true</Optimize>
-    <OutputPath>bin\PL40\Release</OutputPath>
-    <IntermediateOutputPath>obj\PL40\Release\</IntermediateOutputPath>
-    <DocumentationFile>$(OutputPath)\$(AssemblyName).xml</DocumentationFile>
-    <NoWarn>1591, 1570, 1571, 1572, 1573, 1574</NoWarn>
-    <DefineConstants>TRACE;LITE;$(EnvironmentFlavor);$(EnvironmentTemplate);NOSERIALIZABLE;NOSORTEDLIST</DefineConstants>
-    <ErrorReport>prompt</ErrorReport>
-    <WarningLevel>4</WarningLevel>
-    <NoStdLib>true</NoStdLib>
-    <GenerateSerializationAssemblies>Off</GenerateSerializationAssemblies>
-  </PropertyGroup>
-  <ItemGroup>
-    <Reference Include=""mscorlib"" />
-    <Reference Include=""System"" />
-    <Reference Include=""System.Xml"" />
-    <Reference Include=""System.Core"" />
-  </ItemGroup>
-  <ItemGroup>
-    <Compile Include=""AbstractBuilderLite.cs"" />
-    <Compile Include=""AbstractMessageLite.cs"" />
-    <Compile Include=""ByteArray.cs"" />
-    <Compile Include=""CodedOutputStream.ComputeSize.cs"" />
-    <Compile Include=""Collections\Dictionaries.cs"" />
-    <Compile Include=""Collections\Enumerables.cs"" />
-    <Compile Include=""Collections\IPopsicleList.cs"" />
-    <Compile Include=""Collections\Lists.cs"" />
-    <Compile Include=""Collections\PopsicleList.cs"" />
-    <Compile Include=""Collections\ReadOnlyDictionary.cs"" />
-    <Compile Include=""CustomSerialization.cs"" />
-    <Compile Include=""Descriptors\FieldMappingAttribute.cs"" />
-    <Compile Include=""Descriptors\FieldType.cs"" />
-    <Compile Include=""Descriptors\MappedType.cs"" />
-    <Compile Include=""EnumLite.cs"" />
-    <Compile Include=""ExtendableBuilderLite.cs"" />
-    <Compile Include=""ExtendableMessageLite.cs"" />
-    <Compile Include=""FieldSet.cs"" />
-    <Compile Include=""FrameworkPortability.cs"" />
-    <Compile Include=""GeneratedBuilderLite.cs"" />
-    <Compile Include=""GeneratedExtensionLite.cs"" />
-    <Compile Include=""GeneratedMessageLite.cs"" />
-    <Compile Include=""ICodedInputStream.cs"" />
-    <Compile Include=""ICodedOutputStream.cs"" />
-    <Compile Include=""IRpcDispatch.cs"" />
-    <Compile Include=""Properties\AssemblyInfo.cs"" />
-    <Compile Include=""ByteString.cs"" />
-    <Compile Include=""CodedInputStream.cs"" />
-    <Compile Include=""CodedOutputStream.cs"" />
-    <Compile Include=""ExtensionRegistryLite.cs"" />
-    <Compile Include=""IBuilderLite.cs"" />
-    <Compile Include=""IMessageLite.cs"" />
-    <Compile Include=""InvalidProtocolBufferException.cs"" />
-    <Compile Include=""SortedList.cs"" />
-    <Compile Include=""ThrowHelper.cs"" />
-    <Compile Include=""UninitializedMessageException.cs"" />
-    <Compile Include=""WireFormat.cs"" />
-  </ItemGroup>
-  <Import Project=""$(MSBuildExtensionsPath32)\Microsoft\Portable\$(TargetFrameworkVersion)\Microsoft.Portable.CSharp.targets"" />
-  <!-- To modify your build process, add your task inside one of the targets below and uncomment it. 
-       Other similar extension points exist, see Microsoft.Common.targets.
-  <Target Name=""BeforeBuild"">
-  </Target>
-  <Target Name=""AfterBuild"">
-  </Target>
-  -->
-</Project>
\ No newline at end of file
diff --git a/csharp/src/ProtocolBuffers/ProtocolBuffersLite.SL20.csproj b/csharp/src/ProtocolBuffers/ProtocolBuffersLite.SL20.csproj
deleted file mode 100644
index 1bbad1806..000000000
--- a/csharp/src/ProtocolBuffers/ProtocolBuffersLite.SL20.csproj
+++ /dev/null
@@ -1,114 +0,0 @@
-<Project ToolsVersion=""3.5"" DefaultTargets=""Build"" xmlns=""http://schemas.microsoft.com/developer/msbuild/2003"" xmlns:cs=""urn:schemas-csharp-project:template"">
-  <PropertyGroup>
-    <EnvironmentFlavor>SILVERLIGHT</EnvironmentFlavor>
-    <EnvironmentTemplate>SL20</EnvironmentTemplate>
-    <Configuration Condition="" '$(Configuration)' == '' "">Debug</Configuration>
-    <Platform Condition="" '$(Platform)' == '' "">AnyCPU</Platform>
-    <ProductVersion>9.0.30729</ProductVersion>
-    <SchemaVersion>2.0</SchemaVersion>
-    <ProjectGuid>{6969BDCE-D925-43F3-94AC-A531E6DF2591}</ProjectGuid>
-    <OutputType>Library</OutputType>
-    <AppDesignerFolder>Properties</AppDesignerFolder>
-    <RootNamespace>Google.ProtocolBuffers</RootNamespace>
-    <AssemblyName>Google.ProtocolBuffersLite</AssemblyName>
-    <TargetFrameworkVersion>v2.0</TargetFrameworkVersion>
-    <FileAlignment>512</FileAlignment>
-    <SignAssembly>true</SignAssembly>
-    <AssemblyOriginatorKeyFile>..\..\keys\Google.ProtocolBuffers.snk</AssemblyOriginatorKeyFile>
-    <OldToolsVersion>3.5</OldToolsVersion>
-    <ProjectTypeGuids>{A1591282-1198-4647-A2B1-27E5FF5F6F3B};{fae04ec0-301f-11d3-bf4b-00c04f79efbc}</ProjectTypeGuids>
-    <SilverlightApplication>false</SilverlightApplication>
-    <ValidateXaml>false</ValidateXaml>
-    <ThrowErrorsInValidation>false</ThrowErrorsInValidation>
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Debug|AnyCPU' "">
-    <DebugSymbols>true</DebugSymbols>
-    <DebugType>full</DebugType>
-    <Optimize>false</Optimize>
-    <OutputPath>bin\SL20\Debug</OutputPath>
-    <IntermediateOutputPath>obj\SL20\Debug\</IntermediateOutputPath>
-    <DocumentationFile>$(OutputPath)\$(AssemblyName).xml</DocumentationFile>
-    <NoWarn>1591, 1570, 1571, 1572, 1573, 1574</NoWarn>
-    <DefineConstants>DEBUG;TRACE;LITE;$(EnvironmentFlavor);$(EnvironmentTemplate);NOSERIALIZABLE;NOSORTEDLIST;NOEXTENSIONS</DefineConstants>
-    <ErrorReport>prompt</ErrorReport>
-    <WarningLevel>4</WarningLevel>
-    <NoStdLib>true</NoStdLib>
-    <GenerateSerializationAssemblies>Off</GenerateSerializationAssemblies>
-    <NoConfig>true</NoConfig>
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Release|AnyCPU' "">
-    <DebugType>pdbonly</DebugType>
-    <Optimize>true</Optimize>
-    <OutputPath>bin\SL20\Release</OutputPath>
-    <IntermediateOutputPath>obj\SL20\Release\</IntermediateOutputPath>
-    <DocumentationFile>$(OutputPath)\$(AssemblyName).xml</DocumentationFile>
-    <NoWarn>1591, 1570, 1571, 1572, 1573, 1574</NoWarn>
-    <DefineConstants>TRACE;LITE;$(EnvironmentFlavor);$(EnvironmentTemplate);NOSERIALIZABLE;NOSORTEDLIST;NOEXTENSIONS</DefineConstants>
-    <ErrorReport>prompt</ErrorReport>
-    <WarningLevel>4</WarningLevel>
-    <NoStdLib>true</NoStdLib>
-    <GenerateSerializationAssemblies>Off</GenerateSerializationAssemblies>
-    <NoConfig>true</NoConfig>
-  </PropertyGroup>
-  <ItemGroup>
-    <Reference Include=""mscorlib"" />
-    <Reference Include=""System"" />
-    <Reference Include=""System.Xml"" />
-  </ItemGroup>
-  <ItemGroup>
-    <Compile Include=""AbstractBuilderLite.cs"" />
-    <Compile Include=""AbstractMessageLite.cs"" />
-    <Compile Include=""ByteArray.cs"" />
-    <Compile Include=""CodedOutputStream.ComputeSize.cs"" />
-    <Compile Include=""Collections\Dictionaries.cs"" />
-    <Compile Include=""Collections\Enumerables.cs"" />
-    <Compile Include=""Collections\IPopsicleList.cs"" />
-    <Compile Include=""Collections\Lists.cs"" />
-    <Compile Include=""Collections\PopsicleList.cs"" />
-    <Compile Include=""Collections\ReadOnlyDictionary.cs"" />
-    <Compile Include=""CustomSerialization.cs"" />
-    <Compile Include=""Descriptors\FieldMappingAttribute.cs"" />
-    <Compile Include=""Descriptors\FieldType.cs"" />
-    <Compile Include=""Descriptors\MappedType.cs"" />
-    <Compile Include=""EnumLite.cs"" />
-    <Compile Include=""ExtendableBuilderLite.cs"" />
-    <Compile Include=""ExtendableMessageLite.cs"" />
-    <Compile Include=""FieldSet.cs"" />
-    <Compile Include=""FrameworkPortability.cs"" />
-    <Compile Include=""GeneratedBuilderLite.cs"" />
-    <Compile Include=""GeneratedExtensionLite.cs"" />
-    <Compile Include=""GeneratedMessageLite.cs"" />
-    <Compile Include=""ICodedInputStream.cs"" />
-    <Compile Include=""ICodedOutputStream.cs"" />
-    <Compile Include=""IRpcDispatch.cs"" />
-    <Compile Include=""Properties\AssemblyInfo.cs"" />
-    <Compile Include=""ByteString.cs"" />
-    <Compile Include=""CodedInputStream.cs"" />
-    <Compile Include=""CodedOutputStream.cs"" />
-    <Compile Include=""ExtensionRegistryLite.cs"" />
-    <Compile Include=""IBuilderLite.cs"" />
-    <Compile Include=""IMessageLite.cs"" />
-    <Compile Include=""InvalidProtocolBufferException.cs"" />
-    <Compile Include=""SortedList.cs"" />
-    <Compile Include=""ThrowHelper.cs"" />
-    <Compile Include=""UninitializedMessageException.cs"" />
-    <Compile Include=""WireFormat.cs"" />
-  </ItemGroup>
-  <Import Project=""$(MSBuildExtensionsPath32)\Microsoft\Silverlight\v2.0\Microsoft.Silverlight.CSharp.targets"" />
-  <ProjectExtensions>
-    <VisualStudio>
-      <FlavorProperties GUID=""{A1591282-1198-4647-A2B1-27E5FF5F6F3B}"">
-        <SilverlightProjectProperties>
-          <StartAction>OfflineApplication</StartAction>
-        </SilverlightProjectProperties>
-      </FlavorProperties>
-    </VisualStudio>
-  </ProjectExtensions>
-  <!-- To modify your build process, add your task inside one of the targets below and uncomment it. 
-       Other similar extension points exist, see Microsoft.Common.targets.
-  <Target Name=""BeforeBuild"">
-  </Target>
-  <Target Name=""AfterBuild"">
-  </Target>
-  -->
-</Project>
\ No newline at end of file
diff --git a/csharp/src/ProtocolBuffers/ProtocolBuffersLite.SL30.csproj b/csharp/src/ProtocolBuffers/ProtocolBuffersLite.SL30.csproj
deleted file mode 100644
index ab0e809b7..000000000
--- a/csharp/src/ProtocolBuffers/ProtocolBuffersLite.SL30.csproj
+++ /dev/null
@@ -1,115 +0,0 @@
-<Project ToolsVersion=""3.5"" DefaultTargets=""Build"" xmlns=""http://schemas.microsoft.com/developer/msbuild/2003"" xmlns:cs=""urn:schemas-csharp-project:template"">
-  <PropertyGroup>
-    <EnvironmentFlavor>SILVERLIGHT</EnvironmentFlavor>
-    <EnvironmentTemplate>SL30</EnvironmentTemplate>
-    <Configuration Condition="" '$(Configuration)' == '' "">Debug</Configuration>
-    <Platform Condition="" '$(Platform)' == '' "">AnyCPU</Platform>
-    <ProductVersion>9.0.30729</ProductVersion>
-    <SchemaVersion>2.0</SchemaVersion>
-    <ProjectGuid>{6969BDCE-D925-43F3-94AC-A531E6DF2591}</ProjectGuid>
-    <OutputType>Library</OutputType>
-    <AppDesignerFolder>Properties</AppDesignerFolder>
-    <RootNamespace>Google.ProtocolBuffers</RootNamespace>
-    <AssemblyName>Google.ProtocolBuffersLite</AssemblyName>
-    <TargetFrameworkVersion>v3.5</TargetFrameworkVersion>
-    <FileAlignment>512</FileAlignment>
-    <SignAssembly>true</SignAssembly>
-    <AssemblyOriginatorKeyFile>..\..\keys\Google.ProtocolBuffers.snk</AssemblyOriginatorKeyFile>
-    <OldToolsVersion>3.5</OldToolsVersion>
-    <ProjectTypeGuids>{A1591282-1198-4647-A2B1-27E5FF5F6F3B};{fae04ec0-301f-11d3-bf4b-00c04f79efbc}</ProjectTypeGuids>
-    <SilverlightApplication>false</SilverlightApplication>
-    <ValidateXaml>false</ValidateXaml>
-    <ThrowErrorsInValidation>false</ThrowErrorsInValidation>
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Debug|AnyCPU' "">
-    <DebugSymbols>true</DebugSymbols>
-    <DebugType>full</DebugType>
-    <Optimize>false</Optimize>
-    <OutputPath>bin\SL30\Debug</OutputPath>
-    <IntermediateOutputPath>obj\SL30\Debug\</IntermediateOutputPath>
-    <DocumentationFile>$(OutputPath)\$(AssemblyName).xml</DocumentationFile>
-    <NoWarn>1591, 1570, 1571, 1572, 1573, 1574</NoWarn>
-    <DefineConstants>DEBUG;TRACE;LITE;$(EnvironmentFlavor);$(EnvironmentTemplate);NOSERIALIZABLE;NOSORTEDLIST</DefineConstants>
-    <ErrorReport>prompt</ErrorReport>
-    <WarningLevel>4</WarningLevel>
-    <NoStdLib>true</NoStdLib>
-    <GenerateSerializationAssemblies>Off</GenerateSerializationAssemblies>
-    <NoConfig>true</NoConfig>
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Release|AnyCPU' "">
-    <DebugType>pdbonly</DebugType>
-    <Optimize>true</Optimize>
-    <OutputPath>bin\SL30\Release</OutputPath>
-    <IntermediateOutputPath>obj\SL30\Release\</IntermediateOutputPath>
-    <DocumentationFile>$(OutputPath)\$(AssemblyName).xml</DocumentationFile>
-    <NoWarn>1591, 1570, 1571, 1572, 1573, 1574</NoWarn>
-    <DefineConstants>TRACE;LITE;$(EnvironmentFlavor);$(EnvironmentTemplate);NOSERIALIZABLE;NOSORTEDLIST</DefineConstants>
-    <ErrorReport>prompt</ErrorReport>
-    <WarningLevel>4</WarningLevel>
-    <NoStdLib>true</NoStdLib>
-    <GenerateSerializationAssemblies>Off</GenerateSerializationAssemblies>
-    <NoConfig>true</NoConfig>
-  </PropertyGroup>
-  <ItemGroup>
-    <Reference Include=""mscorlib"" />
-    <Reference Include=""System"" />
-    <Reference Include=""System.Xml"" />
-    <Reference Include=""System.Core"" />
-  </ItemGroup>
-  <ItemGroup>
-    <Compile Include=""AbstractBuilderLite.cs"" />
-    <Compile Include=""AbstractMessageLite.cs"" />
-    <Compile Include=""ByteArray.cs"" />
-    <Compile Include=""CodedOutputStream.ComputeSize.cs"" />
-    <Compile Include=""Collections\Dictionaries.cs"" />
-    <Compile Include=""Collections\Enumerables.cs"" />
-    <Compile Include=""Collections\IPopsicleList.cs"" />
-    <Compile Include=""Collections\Lists.cs"" />
-    <Compile Include=""Collections\PopsicleList.cs"" />
-    <Compile Include=""Collections\ReadOnlyDictionary.cs"" />
-    <Compile Include=""CustomSerialization.cs"" />
-    <Compile Include=""Descriptors\FieldMappingAttribute.cs"" />
-    <Compile Include=""Descriptors\FieldType.cs"" />
-    <Compile Include=""Descriptors\MappedType.cs"" />
-    <Compile Include=""EnumLite.cs"" />
-    <Compile Include=""ExtendableBuilderLite.cs"" />
-    <Compile Include=""ExtendableMessageLite.cs"" />
-    <Compile Include=""FieldSet.cs"" />
-    <Compile Include=""FrameworkPortability.cs"" />
-    <Compile Include=""GeneratedBuilderLite.cs"" />
-    <Compile Include=""GeneratedExtensionLite.cs"" />
-    <Compile Include=""GeneratedMessageLite.cs"" />
-    <Compile Include=""ICodedInputStream.cs"" />
-    <Compile Include=""ICodedOutputStream.cs"" />
-    <Compile Include=""IRpcDispatch.cs"" />
-    <Compile Include=""Properties\AssemblyInfo.cs"" />
-    <Compile Include=""ByteString.cs"" />
-    <Compile Include=""CodedInputStream.cs"" />
-    <Compile Include=""CodedOutputStream.cs"" />
-    <Compile Include=""ExtensionRegistryLite.cs"" />
-    <Compile Include=""IBuilderLite.cs"" />
-    <Compile Include=""IMessageLite.cs"" />
-    <Compile Include=""InvalidProtocolBufferException.cs"" />
-    <Compile Include=""SortedList.cs"" />
-    <Compile Include=""ThrowHelper.cs"" />
-    <Compile Include=""UninitializedMessageException.cs"" />
-    <Compile Include=""WireFormat.cs"" />
-  </ItemGroup>
-  <Import Project=""$(MSBuildExtensionsPath32)\Microsoft\Silverlight\v3.0\Microsoft.Silverlight.CSharp.targets"" />
-  <ProjectExtensions>
-    <VisualStudio>
-      <FlavorProperties GUID=""{A1591282-1198-4647-A2B1-27E5FF5F6F3B}"">
-        <SilverlightProjectProperties>
-          <StartAction>OfflineApplication</StartAction>
-        </SilverlightProjectProperties>
-      </FlavorProperties>
-    </VisualStudio>
-  </ProjectExtensions>
-  <!-- To modify your build process, add your task inside one of the targets below and uncomment it. 
-       Other similar extension points exist, see Microsoft.Common.targets.
-  <Target Name=""BeforeBuild"">
-  </Target>
-  <Target Name=""AfterBuild"">
-  </Target>
-  -->
-</Project>
\ No newline at end of file
diff --git a/csharp/src/ProtocolBuffers/ProtocolBuffersLite.SL40.csproj b/csharp/src/ProtocolBuffers/ProtocolBuffersLite.SL40.csproj
deleted file mode 100644
index 42e5be18f..000000000
--- a/csharp/src/ProtocolBuffers/ProtocolBuffersLite.SL40.csproj
+++ /dev/null
@@ -1,116 +0,0 @@
-<Project ToolsVersion=""4.0"" DefaultTargets=""Build"" xmlns=""http://schemas.microsoft.com/developer/msbuild/2003"" xmlns:cs=""urn:schemas-csharp-project:template"">
-  <PropertyGroup>
-    <EnvironmentFlavor>SILVERLIGHT</EnvironmentFlavor>
-    <EnvironmentTemplate>SL40</EnvironmentTemplate>
-    <Configuration Condition="" '$(Configuration)' == '' "">Debug</Configuration>
-    <Platform Condition="" '$(Platform)' == '' "">AnyCPU</Platform>
-    <ProductVersion>9.0.30729</ProductVersion>
-    <SchemaVersion>2.0</SchemaVersion>
-    <ProjectGuid>{6969BDCE-D925-43F3-94AC-A531E6DF2591}</ProjectGuid>
-    <OutputType>Library</OutputType>
-    <AppDesignerFolder>Properties</AppDesignerFolder>
-    <RootNamespace>Google.ProtocolBuffers</RootNamespace>
-    <AssemblyName>Google.ProtocolBuffersLite</AssemblyName>
-    <TargetFrameworkVersion>v4.0</TargetFrameworkVersion>
-    <FileAlignment>512</FileAlignment>
-    <SignAssembly>true</SignAssembly>
-    <AssemblyOriginatorKeyFile>..\..\keys\Google.ProtocolBuffers.snk</AssemblyOriginatorKeyFile>
-    <OldToolsVersion>3.5</OldToolsVersion>
-    <ProjectTypeGuids>{A1591282-1198-4647-A2B1-27E5FF5F6F3B};{fae04ec0-301f-11d3-bf4b-00c04f79efbc}</ProjectTypeGuids>
-    <SilverlightApplication>false</SilverlightApplication>
-    <ValidateXaml>false</ValidateXaml>
-    <ThrowErrorsInValidation>false</ThrowErrorsInValidation>
-    <SilverlightVersion>v4.0</SilverlightVersion>
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Debug|AnyCPU' "">
-    <DebugSymbols>true</DebugSymbols>
-    <DebugType>full</DebugType>
-    <Optimize>false</Optimize>
-    <OutputPath>bin\SL40\Debug</OutputPath>
-    <IntermediateOutputPath>obj\SL40\Debug\</IntermediateOutputPath>
-    <DocumentationFile>$(OutputPath)\$(AssemblyName).xml</DocumentationFile>
-    <NoWarn>1591, 1570, 1571, 1572, 1573, 1574</NoWarn>
-    <DefineConstants>DEBUG;TRACE;LITE;$(EnvironmentFlavor);$(EnvironmentTemplate);NOSERIALIZABLE;NOSORTEDLIST</DefineConstants>
-    <ErrorReport>prompt</ErrorReport>
-    <WarningLevel>4</WarningLevel>
-    <NoStdLib>true</NoStdLib>
-    <GenerateSerializationAssemblies>Off</GenerateSerializationAssemblies>
-    <NoConfig>true</NoConfig>
-  </PropertyGroup>
-  <PropertyGroup Condition="" '$(Configuration)|$(Platform)' == 'Release|AnyCPU' "">
-    <DebugType>pdbonly</DebugType>
-    <Optimize>true</Optimize>
-    <OutputPath>bin\SL40\Release</OutputPath>
-    <IntermediateOutputPath>obj\SL40\Release\</IntermediateOutputPath>
-    <DocumentationFile>$(OutputPath)\$(AssemblyName).xml</DocumentationFile>
-    <NoWarn>1591, 1570, 1571, 1572, 1573, 1574</NoWarn>
-    <DefineConstants>TRACE;LITE;$(EnvironmentFlavor);$(EnvironmentTemplate);NOSERIALIZABLE;NOSORTEDLIST</DefineConstants>
-    <ErrorReport>prompt</ErrorReport>
-    <WarningLevel>4</WarningLevel>
-    <NoStdLib>true</NoStdLib>
-    <GenerateSerializationAssemblies>Off</GenerateSerializationAssemblies>
-    <NoConfig>true</NoConfig>
-  </PropertyGroup>
-  <ItemGroup>
-    <Reference Include=""mscorlib"" />
-    <Reference Include=""System"" />
-    <Reference Include=""System.Xml"" />
-    <Reference Include=""System.Core"" />
-  </ItemGroup>
-  <ItemGroup>
-    <Compile Include=""AbstractBuilderLite.cs"" />
-    <Compile Include=""AbstractMessageLite.cs"" />
-    <Compile Include=""ByteArray.cs"" />
-    <Compile Include=""CodedOutputStream.ComputeSize.cs"" />
-    <Compile Include=""Collections\Dictionaries.cs"" />
-    <Compile Include=""Collections\Enumerables.cs"" />
-    <Compile Include=""Collections\IPopsicleList.cs"" />
-    <Compile Include=""Collections\Lists.cs"" />
-    <Compile Include=""Collections\PopsicleList.cs"" />
-    <Compile Include=""Collections\ReadOnlyDictionary.cs"" />
-    <Compile Include=""CustomSerialization.cs"" />
-    <Compile Include=""Descriptors\FieldMappingAttribute.cs"" />
-    <Compile Include=""Descriptors\FieldType.cs"" />
-    <Compile Include=""Descriptors\MappedType.cs"" />
-    <Compile Include=""EnumLite.cs"" />
-    <Compile Include=""ExtendableBuilderLite.cs"" />
-    <Compile Include=""ExtendableMessageLite.cs"" />
-    <Compile Include=""FieldSet.cs"" />
-    <Compile Include=""FrameworkPortability.cs"" />
-    <Compile Include=""GeneratedBuilderLite.cs"" />
-    <Compile Include=""GeneratedExtensionLite.cs"" />
-    <Compile Include=""GeneratedMessageLite.cs"" />
-    <Compile Include=""ICodedInputStream.cs"" />
-    <Compile Include=""ICodedOutputStream.cs"" />
-    <Compile Include=""IRpcDispatch.cs"" />
-    <Compile Include=""Properties\AssemblyInfo.cs"" />
-    <Compile Include=""ByteString.cs"" />
-    <Compile Include=""CodedInputStream.cs"" />
-    <Compile Include=""CodedOutputStream.cs"" />
-    <Compile Include=""ExtensionRegistryLite.cs"" />
-    <Compile Include=""IBuilderLite.cs"" />
-    <Compile Include=""IMessageLite.cs"" />
-    <Compile Include=""InvalidProtocolBufferException.cs"" />
-    <Compile Include=""SortedList.cs"" />
-    <Compile Include=""ThrowHelper.cs"" />
-    <Compile Include=""UninitializedMessageException.cs"" />
-    <Compile Include=""WireFormat.cs"" />
-  </ItemGroup>
-  <Import Project=""$(MSBuildExtensionsPath32)\Microsoft\Silverlight\$(SilverlightVersion)\Microsoft.Silverlight.CSharp.targets"" />
-  <ProjectExtensions>
-    <VisualStudio>
-      <FlavorProperties GUID=""{A1591282-1198-4647-A2B1-27E5FF5F6F3B}"">
-        <SilverlightProjectProperties>
-          <StartAction>OfflineApplication</StartAction>
-        </SilverlightProjectProperties>
-      </FlavorProperties>
-    </VisualStudio>
-  </ProjectExtensions>
-  <!-- To modify your build process, add your task inside one of the targets below and uncomment it. 
-       Other similar extension points exist, see Microsoft.Common.targets.
-  <Target Name=""BeforeBuild"">
-  </Target>
-  <Target Name=""AfterBuild"">
-  </Target>
-  -->
-</Project>
\ No newline at end of file
diff --git a/csharp/src/ProtocolBuffersLibrary.CF20.sln b/csharp/src/ProtocolBuffersLibrary.CF20.sln
deleted file mode 100644
index 7f1836feb..000000000
--- a/csharp/src/ProtocolBuffersLibrary.CF20.sln
+++ /dev/null
@@ -1,55 +0,0 @@
-Microsoft Visual Studio Solution File, Format Version 10.00
-# Visual Studio 2008
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffers"", ""ProtocolBuffers\ProtocolBuffers.CF20.csproj"", ""{6908BDCE-D925-43F3-94AC-A531E6DF2591}""
-EndProject
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffersLite"", ""ProtocolBuffers\ProtocolBuffersLite.CF20.csproj"", ""{6969BDCE-D925-43F3-94AC-A531E6DF2591}""
-EndProject
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffers.Serialization"", ""ProtocolBuffers.Serialization\ProtocolBuffers.Serialization.CF20.csproj"", ""{231391AF-449C-4A39-986C-AD7F270F4750}""
-EndProject
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffersLite.Serialization"", ""ProtocolBuffers.Serialization\ProtocolBuffersLite.Serialization.CF20.csproj"", ""{E067A59D-9D0A-4A1F-92B1-38E4457241D1}""
-EndProject
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffers.Test"", ""ProtocolBuffers.Test\ProtocolBuffers.Test.CF20.csproj"", ""{DD01ED24-3750-4567-9A23-1DB676A15610}""
-EndProject
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffersLite.Test"", ""ProtocolBuffersLite.Test\ProtocolBuffersLite.Test.CF20.csproj"", ""{EE01ED24-3750-4567-9A23-1DB676A15610}""
-EndProject
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffersLiteMixed.Test"", ""ProtocolBuffersLite.Test\ProtocolBuffersLiteMixed.Test.CF20.csproj"", ""{EEFFED24-3750-4567-9A23-1DB676A15610}""
-EndProject
-Global
-	GlobalSection(SolutionConfigurationPlatforms) = preSolution
-		Debug|Any CPU = Debug|Any CPU
-		Release|Any CPU = Release|Any CPU
-	EndGlobalSection
-	GlobalSection(ProjectConfigurationPlatforms) = postSolution
-		{6908BDCE-D925-43F3-94AC-A531E6DF2591}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{6908BDCE-D925-43F3-94AC-A531E6DF2591}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{6908BDCE-D925-43F3-94AC-A531E6DF2591}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{6908BDCE-D925-43F3-94AC-A531E6DF2591}.Release|Any CPU.Build.0 = Release|Any CPU
-		{6969BDCE-D925-43F3-94AC-A531E6DF2591}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{6969BDCE-D925-43F3-94AC-A531E6DF2591}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{6969BDCE-D925-43F3-94AC-A531E6DF2591}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{6969BDCE-D925-43F3-94AC-A531E6DF2591}.Release|Any CPU.Build.0 = Release|Any CPU
-		{231391AF-449C-4A39-986C-AD7F270F4750}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{231391AF-449C-4A39-986C-AD7F270F4750}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{231391AF-449C-4A39-986C-AD7F270F4750}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{231391AF-449C-4A39-986C-AD7F270F4750}.Release|Any CPU.Build.0 = Release|Any CPU
-		{E067A59D-9D0A-4A1F-92B1-38E4457241D1}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{E067A59D-9D0A-4A1F-92B1-38E4457241D1}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{E067A59D-9D0A-4A1F-92B1-38E4457241D1}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{E067A59D-9D0A-4A1F-92B1-38E4457241D1}.Release|Any CPU.Build.0 = Release|Any CPU
-		{DD01ED24-3750-4567-9A23-1DB676A15610}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{DD01ED24-3750-4567-9A23-1DB676A15610}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{DD01ED24-3750-4567-9A23-1DB676A15610}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{DD01ED24-3750-4567-9A23-1DB676A15610}.Release|Any CPU.Build.0 = Release|Any CPU
-		{EE01ED24-3750-4567-9A23-1DB676A15610}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{EE01ED24-3750-4567-9A23-1DB676A15610}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{EE01ED24-3750-4567-9A23-1DB676A15610}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{EE01ED24-3750-4567-9A23-1DB676A15610}.Release|Any CPU.Build.0 = Release|Any CPU
-		{EEFFED24-3750-4567-9A23-1DB676A15610}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{EEFFED24-3750-4567-9A23-1DB676A15610}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{EEFFED24-3750-4567-9A23-1DB676A15610}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{EEFFED24-3750-4567-9A23-1DB676A15610}.Release|Any CPU.Build.0 = Release|Any CPU
-	EndGlobalSection
-	GlobalSection(SolutionProperties) = preSolution
-		HideSolutionNode = FALSE
-	EndGlobalSection
-EndGlobal
diff --git a/csharp/src/ProtocolBuffersLibrary.CF35.sln b/csharp/src/ProtocolBuffersLibrary.CF35.sln
deleted file mode 100644
index d83e22c18..000000000
--- a/csharp/src/ProtocolBuffersLibrary.CF35.sln
+++ /dev/null
@@ -1,55 +0,0 @@
-Microsoft Visual Studio Solution File, Format Version 10.00
-# Visual Studio 2008
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffers"", ""ProtocolBuffers\ProtocolBuffers.CF35.csproj"", ""{6908BDCE-D925-43F3-94AC-A531E6DF2591}""
-EndProject
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffersLite"", ""ProtocolBuffers\ProtocolBuffersLite.CF35.csproj"", ""{6969BDCE-D925-43F3-94AC-A531E6DF2591}""
-EndProject
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffers.Serialization"", ""ProtocolBuffers.Serialization\ProtocolBuffers.Serialization.CF35.csproj"", ""{231391AF-449C-4A39-986C-AD7F270F4750}""
-EndProject
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffersLite.Serialization"", ""ProtocolBuffers.Serialization\ProtocolBuffersLite.Serialization.CF35.csproj"", ""{E067A59D-9D0A-4A1F-92B1-38E4457241D1}""
-EndProject
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffers.Test"", ""ProtocolBuffers.Test\ProtocolBuffers.Test.CF35.csproj"", ""{DD01ED24-3750-4567-9A23-1DB676A15610}""
-EndProject
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffersLite.Test"", ""ProtocolBuffersLite.Test\ProtocolBuffersLite.Test.CF35.csproj"", ""{EE01ED24-3750-4567-9A23-1DB676A15610}""
-EndProject
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffersLiteMixed.Test"", ""ProtocolBuffersLite.Test\ProtocolBuffersLiteMixed.Test.CF35.csproj"", ""{EEFFED24-3750-4567-9A23-1DB676A15610}""
-EndProject
-Global
-	GlobalSection(SolutionConfigurationPlatforms) = preSolution
-		Debug|Any CPU = Debug|Any CPU
-		Release|Any CPU = Release|Any CPU
-	EndGlobalSection
-	GlobalSection(ProjectConfigurationPlatforms) = postSolution
-		{6908BDCE-D925-43F3-94AC-A531E6DF2591}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{6908BDCE-D925-43F3-94AC-A531E6DF2591}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{6908BDCE-D925-43F3-94AC-A531E6DF2591}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{6908BDCE-D925-43F3-94AC-A531E6DF2591}.Release|Any CPU.Build.0 = Release|Any CPU
-		{6969BDCE-D925-43F3-94AC-A531E6DF2591}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{6969BDCE-D925-43F3-94AC-A531E6DF2591}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{6969BDCE-D925-43F3-94AC-A531E6DF2591}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{6969BDCE-D925-43F3-94AC-A531E6DF2591}.Release|Any CPU.Build.0 = Release|Any CPU
-		{231391AF-449C-4A39-986C-AD7F270F4750}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{231391AF-449C-4A39-986C-AD7F270F4750}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{231391AF-449C-4A39-986C-AD7F270F4750}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{231391AF-449C-4A39-986C-AD7F270F4750}.Release|Any CPU.Build.0 = Release|Any CPU
-		{E067A59D-9D0A-4A1F-92B1-38E4457241D1}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{E067A59D-9D0A-4A1F-92B1-38E4457241D1}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{E067A59D-9D0A-4A1F-92B1-38E4457241D1}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{E067A59D-9D0A-4A1F-92B1-38E4457241D1}.Release|Any CPU.Build.0 = Release|Any CPU
-		{DD01ED24-3750-4567-9A23-1DB676A15610}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{DD01ED24-3750-4567-9A23-1DB676A15610}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{DD01ED24-3750-4567-9A23-1DB676A15610}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{DD01ED24-3750-4567-9A23-1DB676A15610}.Release|Any CPU.Build.0 = Release|Any CPU
-		{EE01ED24-3750-4567-9A23-1DB676A15610}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{EE01ED24-3750-4567-9A23-1DB676A15610}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{EE01ED24-3750-4567-9A23-1DB676A15610}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{EE01ED24-3750-4567-9A23-1DB676A15610}.Release|Any CPU.Build.0 = Release|Any CPU
-		{EEFFED24-3750-4567-9A23-1DB676A15610}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{EEFFED24-3750-4567-9A23-1DB676A15610}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{EEFFED24-3750-4567-9A23-1DB676A15610}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{EEFFED24-3750-4567-9A23-1DB676A15610}.Release|Any CPU.Build.0 = Release|Any CPU
-	EndGlobalSection
-	GlobalSection(SolutionProperties) = preSolution
-		HideSolutionNode = FALSE
-	EndGlobalSection
-EndGlobal
diff --git a/csharp/src/ProtocolBuffersLibrary.NET20.sln b/csharp/src/ProtocolBuffersLibrary.NET20.sln
deleted file mode 100644
index 2de8ed21a..000000000
--- a/csharp/src/ProtocolBuffersLibrary.NET20.sln
+++ /dev/null
@@ -1,55 +0,0 @@
-Microsoft Visual Studio Solution File, Format Version 10.00
-# Visual Studio 2008
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffers"", ""ProtocolBuffers\ProtocolBuffers.NET20.csproj"", ""{6908BDCE-D925-43F3-94AC-A531E6DF2591}""
-EndProject
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffersLite"", ""ProtocolBuffers\ProtocolBuffersLite.NET20.csproj"", ""{6969BDCE-D925-43F3-94AC-A531E6DF2591}""
-EndProject
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffers.Serialization"", ""ProtocolBuffers.Serialization\ProtocolBuffers.Serialization.NET20.csproj"", ""{231391AF-449C-4A39-986C-AD7F270F4750}""
-EndProject
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffersLite.Serialization"", ""ProtocolBuffers.Serialization\ProtocolBuffersLite.Serialization.NET20.csproj"", ""{E067A59D-9D0A-4A1F-92B1-38E4457241D1}""
-EndProject
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffers.Test"", ""ProtocolBuffers.Test\ProtocolBuffers.Test.NET20.csproj"", ""{DD01ED24-3750-4567-9A23-1DB676A15610}""
-EndProject
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffersLite.Test"", ""ProtocolBuffersLite.Test\ProtocolBuffersLite.Test.NET20.csproj"", ""{EE01ED24-3750-4567-9A23-1DB676A15610}""
-EndProject
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffersLiteMixed.Test"", ""ProtocolBuffersLite.Test\ProtocolBuffersLiteMixed.Test.NET20.csproj"", ""{EEFFED24-3750-4567-9A23-1DB676A15610}""
-EndProject
-Global
-	GlobalSection(SolutionConfigurationPlatforms) = preSolution
-		Debug|Any CPU = Debug|Any CPU
-		Release|Any CPU = Release|Any CPU
-	EndGlobalSection
-	GlobalSection(ProjectConfigurationPlatforms) = postSolution
-		{6908BDCE-D925-43F3-94AC-A531E6DF2591}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{6908BDCE-D925-43F3-94AC-A531E6DF2591}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{6908BDCE-D925-43F3-94AC-A531E6DF2591}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{6908BDCE-D925-43F3-94AC-A531E6DF2591}.Release|Any CPU.Build.0 = Release|Any CPU
-		{6969BDCE-D925-43F3-94AC-A531E6DF2591}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{6969BDCE-D925-43F3-94AC-A531E6DF2591}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{6969BDCE-D925-43F3-94AC-A531E6DF2591}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{6969BDCE-D925-43F3-94AC-A531E6DF2591}.Release|Any CPU.Build.0 = Release|Any CPU
-		{231391AF-449C-4A39-986C-AD7F270F4750}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{231391AF-449C-4A39-986C-AD7F270F4750}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{231391AF-449C-4A39-986C-AD7F270F4750}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{231391AF-449C-4A39-986C-AD7F270F4750}.Release|Any CPU.Build.0 = Release|Any CPU
-		{E067A59D-9D0A-4A1F-92B1-38E4457241D1}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{E067A59D-9D0A-4A1F-92B1-38E4457241D1}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{E067A59D-9D0A-4A1F-92B1-38E4457241D1}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{E067A59D-9D0A-4A1F-92B1-38E4457241D1}.Release|Any CPU.Build.0 = Release|Any CPU
-		{DD01ED24-3750-4567-9A23-1DB676A15610}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{DD01ED24-3750-4567-9A23-1DB676A15610}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{DD01ED24-3750-4567-9A23-1DB676A15610}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{DD01ED24-3750-4567-9A23-1DB676A15610}.Release|Any CPU.Build.0 = Release|Any CPU
-		{EE01ED24-3750-4567-9A23-1DB676A15610}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{EE01ED24-3750-4567-9A23-1DB676A15610}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{EE01ED24-3750-4567-9A23-1DB676A15610}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{EE01ED24-3750-4567-9A23-1DB676A15610}.Release|Any CPU.Build.0 = Release|Any CPU
-		{EEFFED24-3750-4567-9A23-1DB676A15610}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{EEFFED24-3750-4567-9A23-1DB676A15610}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{EEFFED24-3750-4567-9A23-1DB676A15610}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{EEFFED24-3750-4567-9A23-1DB676A15610}.Release|Any CPU.Build.0 = Release|Any CPU
-	EndGlobalSection
-	GlobalSection(SolutionProperties) = preSolution
-		HideSolutionNode = FALSE
-	EndGlobalSection
-EndGlobal
diff --git a/csharp/src/ProtocolBuffersLibrary.NET35.sln b/csharp/src/ProtocolBuffersLibrary.NET35.sln
deleted file mode 100644
index 639ab170b..000000000
--- a/csharp/src/ProtocolBuffersLibrary.NET35.sln
+++ /dev/null
@@ -1,55 +0,0 @@
-Microsoft Visual Studio Solution File, Format Version 10.00
-# Visual Studio 2008
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffers"", ""ProtocolBuffers\ProtocolBuffers.NET35.csproj"", ""{6908BDCE-D925-43F3-94AC-A531E6DF2591}""
-EndProject
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffersLite"", ""ProtocolBuffers\ProtocolBuffersLite.NET35.csproj"", ""{6969BDCE-D925-43F3-94AC-A531E6DF2591}""
-EndProject
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffers.Serialization"", ""ProtocolBuffers.Serialization\ProtocolBuffers.Serialization.NET35.csproj"", ""{231391AF-449C-4A39-986C-AD7F270F4750}""
-EndProject
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffersLite.Serialization"", ""ProtocolBuffers.Serialization\ProtocolBuffersLite.Serialization.NET35.csproj"", ""{E067A59D-9D0A-4A1F-92B1-38E4457241D1}""
-EndProject
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffers.Test"", ""ProtocolBuffers.Test\ProtocolBuffers.Test.NET35.csproj"", ""{DD01ED24-3750-4567-9A23-1DB676A15610}""
-EndProject
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffersLite.Test"", ""ProtocolBuffersLite.Test\ProtocolBuffersLite.Test.NET35.csproj"", ""{EE01ED24-3750-4567-9A23-1DB676A15610}""
-EndProject
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffersLiteMixed.Test"", ""ProtocolBuffersLite.Test\ProtocolBuffersLiteMixed.Test.NET35.csproj"", ""{EEFFED24-3750-4567-9A23-1DB676A15610}""
-EndProject
-Global
-	GlobalSection(SolutionConfigurationPlatforms) = preSolution
-		Debug|Any CPU = Debug|Any CPU
-		Release|Any CPU = Release|Any CPU
-	EndGlobalSection
-	GlobalSection(ProjectConfigurationPlatforms) = postSolution
-		{6908BDCE-D925-43F3-94AC-A531E6DF2591}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{6908BDCE-D925-43F3-94AC-A531E6DF2591}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{6908BDCE-D925-43F3-94AC-A531E6DF2591}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{6908BDCE-D925-43F3-94AC-A531E6DF2591}.Release|Any CPU.Build.0 = Release|Any CPU
-		{6969BDCE-D925-43F3-94AC-A531E6DF2591}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{6969BDCE-D925-43F3-94AC-A531E6DF2591}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{6969BDCE-D925-43F3-94AC-A531E6DF2591}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{6969BDCE-D925-43F3-94AC-A531E6DF2591}.Release|Any CPU.Build.0 = Release|Any CPU
-		{231391AF-449C-4A39-986C-AD7F270F4750}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{231391AF-449C-4A39-986C-AD7F270F4750}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{231391AF-449C-4A39-986C-AD7F270F4750}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{231391AF-449C-4A39-986C-AD7F270F4750}.Release|Any CPU.Build.0 = Release|Any CPU
-		{E067A59D-9D0A-4A1F-92B1-38E4457241D1}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{E067A59D-9D0A-4A1F-92B1-38E4457241D1}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{E067A59D-9D0A-4A1F-92B1-38E4457241D1}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{E067A59D-9D0A-4A1F-92B1-38E4457241D1}.Release|Any CPU.Build.0 = Release|Any CPU
-		{DD01ED24-3750-4567-9A23-1DB676A15610}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{DD01ED24-3750-4567-9A23-1DB676A15610}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{DD01ED24-3750-4567-9A23-1DB676A15610}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{DD01ED24-3750-4567-9A23-1DB676A15610}.Release|Any CPU.Build.0 = Release|Any CPU
-		{EE01ED24-3750-4567-9A23-1DB676A15610}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{EE01ED24-3750-4567-9A23-1DB676A15610}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{EE01ED24-3750-4567-9A23-1DB676A15610}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{EE01ED24-3750-4567-9A23-1DB676A15610}.Release|Any CPU.Build.0 = Release|Any CPU
-		{EEFFED24-3750-4567-9A23-1DB676A15610}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{EEFFED24-3750-4567-9A23-1DB676A15610}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{EEFFED24-3750-4567-9A23-1DB676A15610}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{EEFFED24-3750-4567-9A23-1DB676A15610}.Release|Any CPU.Build.0 = Release|Any CPU
-	EndGlobalSection
-	GlobalSection(SolutionProperties) = preSolution
-		HideSolutionNode = FALSE
-	EndGlobalSection
-EndGlobal
diff --git a/csharp/src/ProtocolBuffersLibrary.NET40.sln b/csharp/src/ProtocolBuffersLibrary.NET40.sln
deleted file mode 100644
index 849264567..000000000
--- a/csharp/src/ProtocolBuffersLibrary.NET40.sln
+++ /dev/null
@@ -1,55 +0,0 @@
-Microsoft Visual Studio Solution File, Format Version 11.00
-# Visual Studio 2010
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffers"", ""ProtocolBuffers\ProtocolBuffers.NET40.csproj"", ""{6908BDCE-D925-43F3-94AC-A531E6DF2591}""
-EndProject
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffersLite"", ""ProtocolBuffers\ProtocolBuffersLite.NET40.csproj"", ""{6969BDCE-D925-43F3-94AC-A531E6DF2591}""
-EndProject
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffers.Serialization"", ""ProtocolBuffers.Serialization\ProtocolBuffers.Serialization.NET40.csproj"", ""{231391AF-449C-4A39-986C-AD7F270F4750}""
-EndProject
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffersLite.Serialization"", ""ProtocolBuffers.Serialization\ProtocolBuffersLite.Serialization.NET40.csproj"", ""{E067A59D-9D0A-4A1F-92B1-38E4457241D1}""
-EndProject
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffers.Test"", ""ProtocolBuffers.Test\ProtocolBuffers.Test.NET40.csproj"", ""{DD01ED24-3750-4567-9A23-1DB676A15610}""
-EndProject
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffersLite.Test"", ""ProtocolBuffersLite.Test\ProtocolBuffersLite.Test.NET40.csproj"", ""{EE01ED24-3750-4567-9A23-1DB676A15610}""
-EndProject
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffersLiteMixed.Test"", ""ProtocolBuffersLite.Test\ProtocolBuffersLiteMixed.Test.NET40.csproj"", ""{EEFFED24-3750-4567-9A23-1DB676A15610}""
-EndProject
-Global
-	GlobalSection(SolutionConfigurationPlatforms) = preSolution
-		Debug|Any CPU = Debug|Any CPU
-		Release|Any CPU = Release|Any CPU
-	EndGlobalSection
-	GlobalSection(ProjectConfigurationPlatforms) = postSolution
-		{6908BDCE-D925-43F3-94AC-A531E6DF2591}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{6908BDCE-D925-43F3-94AC-A531E6DF2591}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{6908BDCE-D925-43F3-94AC-A531E6DF2591}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{6908BDCE-D925-43F3-94AC-A531E6DF2591}.Release|Any CPU.Build.0 = Release|Any CPU
-		{6969BDCE-D925-43F3-94AC-A531E6DF2591}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{6969BDCE-D925-43F3-94AC-A531E6DF2591}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{6969BDCE-D925-43F3-94AC-A531E6DF2591}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{6969BDCE-D925-43F3-94AC-A531E6DF2591}.Release|Any CPU.Build.0 = Release|Any CPU
-		{231391AF-449C-4A39-986C-AD7F270F4750}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{231391AF-449C-4A39-986C-AD7F270F4750}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{231391AF-449C-4A39-986C-AD7F270F4750}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{231391AF-449C-4A39-986C-AD7F270F4750}.Release|Any CPU.Build.0 = Release|Any CPU
-		{E067A59D-9D0A-4A1F-92B1-38E4457241D1}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{E067A59D-9D0A-4A1F-92B1-38E4457241D1}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{E067A59D-9D0A-4A1F-92B1-38E4457241D1}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{E067A59D-9D0A-4A1F-92B1-38E4457241D1}.Release|Any CPU.Build.0 = Release|Any CPU
-		{DD01ED24-3750-4567-9A23-1DB676A15610}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{DD01ED24-3750-4567-9A23-1DB676A15610}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{DD01ED24-3750-4567-9A23-1DB676A15610}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{DD01ED24-3750-4567-9A23-1DB676A15610}.Release|Any CPU.Build.0 = Release|Any CPU
-		{EE01ED24-3750-4567-9A23-1DB676A15610}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{EE01ED24-3750-4567-9A23-1DB676A15610}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{EE01ED24-3750-4567-9A23-1DB676A15610}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{EE01ED24-3750-4567-9A23-1DB676A15610}.Release|Any CPU.Build.0 = Release|Any CPU
-		{EEFFED24-3750-4567-9A23-1DB676A15610}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{EEFFED24-3750-4567-9A23-1DB676A15610}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{EEFFED24-3750-4567-9A23-1DB676A15610}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{EEFFED24-3750-4567-9A23-1DB676A15610}.Release|Any CPU.Build.0 = Release|Any CPU
-	EndGlobalSection
-	GlobalSection(SolutionProperties) = preSolution
-		HideSolutionNode = FALSE
-	EndGlobalSection
-EndGlobal
diff --git a/csharp/src/ProtocolBuffersLibrary.PL40.sln b/csharp/src/ProtocolBuffersLibrary.PL40.sln
deleted file mode 100644
index aca83c2ed..000000000
--- a/csharp/src/ProtocolBuffersLibrary.PL40.sln
+++ /dev/null
@@ -1,55 +0,0 @@
-Microsoft Visual Studio Solution File, Format Version 11.00
-# Visual Studio 2010
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffers"", ""ProtocolBuffers\ProtocolBuffers.PL40.csproj"", ""{6908BDCE-D925-43F3-94AC-A531E6DF2591}""
-EndProject
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffersLite"", ""ProtocolBuffers\ProtocolBuffersLite.PL40.csproj"", ""{6969BDCE-D925-43F3-94AC-A531E6DF2591}""
-EndProject
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffers.Serialization"", ""ProtocolBuffers.Serialization\ProtocolBuffers.Serialization.PL40.csproj"", ""{231391AF-449C-4A39-986C-AD7F270F4750}""
-EndProject
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffersLite.Serialization"", ""ProtocolBuffers.Serialization\ProtocolBuffersLite.Serialization.PL40.csproj"", ""{E067A59D-9D0A-4A1F-92B1-38E4457241D1}""
-EndProject
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffers.Test"", ""ProtocolBuffers.Test\ProtocolBuffers.Test.PL40.csproj"", ""{DD01ED24-3750-4567-9A23-1DB676A15610}""
-EndProject
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffersLite.Test"", ""ProtocolBuffersLite.Test\ProtocolBuffersLite.Test.PL40.csproj"", ""{EE01ED24-3750-4567-9A23-1DB676A15610}""
-EndProject
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffersLiteMixed.Test"", ""ProtocolBuffersLite.Test\ProtocolBuffersLiteMixed.Test.PL40.csproj"", ""{EEFFED24-3750-4567-9A23-1DB676A15610}""
-EndProject
-Global
-	GlobalSection(SolutionConfigurationPlatforms) = preSolution
-		Debug|Any CPU = Debug|Any CPU
-		Release|Any CPU = Release|Any CPU
-	EndGlobalSection
-	GlobalSection(ProjectConfigurationPlatforms) = postSolution
-		{6908BDCE-D925-43F3-94AC-A531E6DF2591}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{6908BDCE-D925-43F3-94AC-A531E6DF2591}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{6908BDCE-D925-43F3-94AC-A531E6DF2591}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{6908BDCE-D925-43F3-94AC-A531E6DF2591}.Release|Any CPU.Build.0 = Release|Any CPU
-		{6969BDCE-D925-43F3-94AC-A531E6DF2591}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{6969BDCE-D925-43F3-94AC-A531E6DF2591}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{6969BDCE-D925-43F3-94AC-A531E6DF2591}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{6969BDCE-D925-43F3-94AC-A531E6DF2591}.Release|Any CPU.Build.0 = Release|Any CPU
-		{231391AF-449C-4A39-986C-AD7F270F4750}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{231391AF-449C-4A39-986C-AD7F270F4750}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{231391AF-449C-4A39-986C-AD7F270F4750}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{231391AF-449C-4A39-986C-AD7F270F4750}.Release|Any CPU.Build.0 = Release|Any CPU
-		{E067A59D-9D0A-4A1F-92B1-38E4457241D1}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{E067A59D-9D0A-4A1F-92B1-38E4457241D1}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{E067A59D-9D0A-4A1F-92B1-38E4457241D1}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{E067A59D-9D0A-4A1F-92B1-38E4457241D1}.Release|Any CPU.Build.0 = Release|Any CPU
-		{DD01ED24-3750-4567-9A23-1DB676A15610}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{DD01ED24-3750-4567-9A23-1DB676A15610}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{DD01ED24-3750-4567-9A23-1DB676A15610}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{DD01ED24-3750-4567-9A23-1DB676A15610}.Release|Any CPU.Build.0 = Release|Any CPU
-		{EE01ED24-3750-4567-9A23-1DB676A15610}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{EE01ED24-3750-4567-9A23-1DB676A15610}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{EE01ED24-3750-4567-9A23-1DB676A15610}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{EE01ED24-3750-4567-9A23-1DB676A15610}.Release|Any CPU.Build.0 = Release|Any CPU
-		{EEFFED24-3750-4567-9A23-1DB676A15610}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{EEFFED24-3750-4567-9A23-1DB676A15610}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{EEFFED24-3750-4567-9A23-1DB676A15610}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{EEFFED24-3750-4567-9A23-1DB676A15610}.Release|Any CPU.Build.0 = Release|Any CPU
-	EndGlobalSection
-	GlobalSection(SolutionProperties) = preSolution
-		HideSolutionNode = FALSE
-	EndGlobalSection
-EndGlobal
diff --git a/csharp/src/ProtocolBuffersLibrary.SL20.sln b/csharp/src/ProtocolBuffersLibrary.SL20.sln
deleted file mode 100644
index bba4adada..000000000
--- a/csharp/src/ProtocolBuffersLibrary.SL20.sln
+++ /dev/null
@@ -1,55 +0,0 @@
-Microsoft Visual Studio Solution File, Format Version 10.00
-# Visual Studio 2008
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffers"", ""ProtocolBuffers\ProtocolBuffers.SL20.csproj"", ""{6908BDCE-D925-43F3-94AC-A531E6DF2591}""
-EndProject
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffersLite"", ""ProtocolBuffers\ProtocolBuffersLite.SL20.csproj"", ""{6969BDCE-D925-43F3-94AC-A531E6DF2591}""
-EndProject
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffers.Serialization"", ""ProtocolBuffers.Serialization\ProtocolBuffers.Serialization.SL20.csproj"", ""{231391AF-449C-4A39-986C-AD7F270F4750}""
-EndProject
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffersLite.Serialization"", ""ProtocolBuffers.Serialization\ProtocolBuffersLite.Serialization.SL20.csproj"", ""{E067A59D-9D0A-4A1F-92B1-38E4457241D1}""
-EndProject
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffers.Test"", ""ProtocolBuffers.Test\ProtocolBuffers.Test.SL20.csproj"", ""{DD01ED24-3750-4567-9A23-1DB676A15610}""
-EndProject
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffersLite.Test"", ""ProtocolBuffersLite.Test\ProtocolBuffersLite.Test.SL20.csproj"", ""{EE01ED24-3750-4567-9A23-1DB676A15610}""
-EndProject
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffersLiteMixed.Test"", ""ProtocolBuffersLite.Test\ProtocolBuffersLiteMixed.Test.SL20.csproj"", ""{EEFFED24-3750-4567-9A23-1DB676A15610}""
-EndProject
-Global
-	GlobalSection(SolutionConfigurationPlatforms) = preSolution
-		Debug|Any CPU = Debug|Any CPU
-		Release|Any CPU = Release|Any CPU
-	EndGlobalSection
-	GlobalSection(ProjectConfigurationPlatforms) = postSolution
-		{6908BDCE-D925-43F3-94AC-A531E6DF2591}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{6908BDCE-D925-43F3-94AC-A531E6DF2591}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{6908BDCE-D925-43F3-94AC-A531E6DF2591}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{6908BDCE-D925-43F3-94AC-A531E6DF2591}.Release|Any CPU.Build.0 = Release|Any CPU
-		{6969BDCE-D925-43F3-94AC-A531E6DF2591}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{6969BDCE-D925-43F3-94AC-A531E6DF2591}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{6969BDCE-D925-43F3-94AC-A531E6DF2591}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{6969BDCE-D925-43F3-94AC-A531E6DF2591}.Release|Any CPU.Build.0 = Release|Any CPU
-		{231391AF-449C-4A39-986C-AD7F270F4750}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{231391AF-449C-4A39-986C-AD7F270F4750}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{231391AF-449C-4A39-986C-AD7F270F4750}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{231391AF-449C-4A39-986C-AD7F270F4750}.Release|Any CPU.Build.0 = Release|Any CPU
-		{E067A59D-9D0A-4A1F-92B1-38E4457241D1}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{E067A59D-9D0A-4A1F-92B1-38E4457241D1}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{E067A59D-9D0A-4A1F-92B1-38E4457241D1}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{E067A59D-9D0A-4A1F-92B1-38E4457241D1}.Release|Any CPU.Build.0 = Release|Any CPU
-		{DD01ED24-3750-4567-9A23-1DB676A15610}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{DD01ED24-3750-4567-9A23-1DB676A15610}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{DD01ED24-3750-4567-9A23-1DB676A15610}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{DD01ED24-3750-4567-9A23-1DB676A15610}.Release|Any CPU.Build.0 = Release|Any CPU
-		{EE01ED24-3750-4567-9A23-1DB676A15610}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{EE01ED24-3750-4567-9A23-1DB676A15610}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{EE01ED24-3750-4567-9A23-1DB676A15610}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{EE01ED24-3750-4567-9A23-1DB676A15610}.Release|Any CPU.Build.0 = Release|Any CPU
-		{EEFFED24-3750-4567-9A23-1DB676A15610}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{EEFFED24-3750-4567-9A23-1DB676A15610}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{EEFFED24-3750-4567-9A23-1DB676A15610}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{EEFFED24-3750-4567-9A23-1DB676A15610}.Release|Any CPU.Build.0 = Release|Any CPU
-	EndGlobalSection
-	GlobalSection(SolutionProperties) = preSolution
-		HideSolutionNode = FALSE
-	EndGlobalSection
-EndGlobal
diff --git a/csharp/src/ProtocolBuffersLibrary.SL30.sln b/csharp/src/ProtocolBuffersLibrary.SL30.sln
deleted file mode 100644
index 080c22ea7..000000000
--- a/csharp/src/ProtocolBuffersLibrary.SL30.sln
+++ /dev/null
@@ -1,55 +0,0 @@
-Microsoft Visual Studio Solution File, Format Version 10.00
-# Visual Studio 2008
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffers"", ""ProtocolBuffers\ProtocolBuffers.SL30.csproj"", ""{6908BDCE-D925-43F3-94AC-A531E6DF2591}""
-EndProject
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffersLite"", ""ProtocolBuffers\ProtocolBuffersLite.SL30.csproj"", ""{6969BDCE-D925-43F3-94AC-A531E6DF2591}""
-EndProject
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffers.Serialization"", ""ProtocolBuffers.Serialization\ProtocolBuffers.Serialization.SL30.csproj"", ""{231391AF-449C-4A39-986C-AD7F270F4750}""
-EndProject
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffersLite.Serialization"", ""ProtocolBuffers.Serialization\ProtocolBuffersLite.Serialization.SL30.csproj"", ""{E067A59D-9D0A-4A1F-92B1-38E4457241D1}""
-EndProject
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffers.Test"", ""ProtocolBuffers.Test\ProtocolBuffers.Test.SL30.csproj"", ""{DD01ED24-3750-4567-9A23-1DB676A15610}""
-EndProject
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffersLite.Test"", ""ProtocolBuffersLite.Test\ProtocolBuffersLite.Test.SL30.csproj"", ""{EE01ED24-3750-4567-9A23-1DB676A15610}""
-EndProject
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffersLiteMixed.Test"", ""ProtocolBuffersLite.Test\ProtocolBuffersLiteMixed.Test.SL30.csproj"", ""{EEFFED24-3750-4567-9A23-1DB676A15610}""
-EndProject
-Global
-	GlobalSection(SolutionConfigurationPlatforms) = preSolution
-		Debug|Any CPU = Debug|Any CPU
-		Release|Any CPU = Release|Any CPU
-	EndGlobalSection
-	GlobalSection(ProjectConfigurationPlatforms) = postSolution
-		{6908BDCE-D925-43F3-94AC-A531E6DF2591}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{6908BDCE-D925-43F3-94AC-A531E6DF2591}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{6908BDCE-D925-43F3-94AC-A531E6DF2591}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{6908BDCE-D925-43F3-94AC-A531E6DF2591}.Release|Any CPU.Build.0 = Release|Any CPU
-		{6969BDCE-D925-43F3-94AC-A531E6DF2591}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{6969BDCE-D925-43F3-94AC-A531E6DF2591}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{6969BDCE-D925-43F3-94AC-A531E6DF2591}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{6969BDCE-D925-43F3-94AC-A531E6DF2591}.Release|Any CPU.Build.0 = Release|Any CPU
-		{231391AF-449C-4A39-986C-AD7F270F4750}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{231391AF-449C-4A39-986C-AD7F270F4750}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{231391AF-449C-4A39-986C-AD7F270F4750}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{231391AF-449C-4A39-986C-AD7F270F4750}.Release|Any CPU.Build.0 = Release|Any CPU
-		{E067A59D-9D0A-4A1F-92B1-38E4457241D1}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{E067A59D-9D0A-4A1F-92B1-38E4457241D1}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{E067A59D-9D0A-4A1F-92B1-38E4457241D1}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{E067A59D-9D0A-4A1F-92B1-38E4457241D1}.Release|Any CPU.Build.0 = Release|Any CPU
-		{DD01ED24-3750-4567-9A23-1DB676A15610}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{DD01ED24-3750-4567-9A23-1DB676A15610}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{DD01ED24-3750-4567-9A23-1DB676A15610}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{DD01ED24-3750-4567-9A23-1DB676A15610}.Release|Any CPU.Build.0 = Release|Any CPU
-		{EE01ED24-3750-4567-9A23-1DB676A15610}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{EE01ED24-3750-4567-9A23-1DB676A15610}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{EE01ED24-3750-4567-9A23-1DB676A15610}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{EE01ED24-3750-4567-9A23-1DB676A15610}.Release|Any CPU.Build.0 = Release|Any CPU
-		{EEFFED24-3750-4567-9A23-1DB676A15610}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{EEFFED24-3750-4567-9A23-1DB676A15610}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{EEFFED24-3750-4567-9A23-1DB676A15610}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{EEFFED24-3750-4567-9A23-1DB676A15610}.Release|Any CPU.Build.0 = Release|Any CPU
-	EndGlobalSection
-	GlobalSection(SolutionProperties) = preSolution
-		HideSolutionNode = FALSE
-	EndGlobalSection
-EndGlobal
diff --git a/csharp/src/ProtocolBuffersLibrary.SL40.sln b/csharp/src/ProtocolBuffersLibrary.SL40.sln
deleted file mode 100644
index 01ea57484..000000000
--- a/csharp/src/ProtocolBuffersLibrary.SL40.sln
+++ /dev/null
@@ -1,55 +0,0 @@
-Microsoft Visual Studio Solution File, Format Version 11.00
-# Visual Studio 2010
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffers"", ""ProtocolBuffers\ProtocolBuffers.SL40.csproj"", ""{6908BDCE-D925-43F3-94AC-A531E6DF2591}""
-EndProject
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffersLite"", ""ProtocolBuffers\ProtocolBuffersLite.SL40.csproj"", ""{6969BDCE-D925-43F3-94AC-A531E6DF2591}""
-EndProject
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffers.Serialization"", ""ProtocolBuffers.Serialization\ProtocolBuffers.Serialization.SL40.csproj"", ""{231391AF-449C-4A39-986C-AD7F270F4750}""
-EndProject
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffersLite.Serialization"", ""ProtocolBuffers.Serialization\ProtocolBuffersLite.Serialization.SL40.csproj"", ""{E067A59D-9D0A-4A1F-92B1-38E4457241D1}""
-EndProject
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffers.Test"", ""ProtocolBuffers.Test\ProtocolBuffers.Test.SL40.csproj"", ""{DD01ED24-3750-4567-9A23-1DB676A15610}""
-EndProject
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffersLite.Test"", ""ProtocolBuffersLite.Test\ProtocolBuffersLite.Test.SL40.csproj"", ""{EE01ED24-3750-4567-9A23-1DB676A15610}""
-EndProject
-Project(""{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}"") = ""ProtocolBuffersLiteMixed.Test"", ""ProtocolBuffersLite.Test\ProtocolBuffersLiteMixed.Test.SL40.csproj"", ""{EEFFED24-3750-4567-9A23-1DB676A15610}""
-EndProject
-Global
-	GlobalSection(SolutionConfigurationPlatforms) = preSolution
-		Debug|Any CPU = Debug|Any CPU
-		Release|Any CPU = Release|Any CPU
-	EndGlobalSection
-	GlobalSection(ProjectConfigurationPlatforms) = postSolution
-		{6908BDCE-D925-43F3-94AC-A531E6DF2591}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{6908BDCE-D925-43F3-94AC-A531E6DF2591}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{6908BDCE-D925-43F3-94AC-A531E6DF2591}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{6908BDCE-D925-43F3-94AC-A531E6DF2591}.Release|Any CPU.Build.0 = Release|Any CPU
-		{6969BDCE-D925-43F3-94AC-A531E6DF2591}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{6969BDCE-D925-43F3-94AC-A531E6DF2591}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{6969BDCE-D925-43F3-94AC-A531E6DF2591}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{6969BDCE-D925-43F3-94AC-A531E6DF2591}.Release|Any CPU.Build.0 = Release|Any CPU
-		{231391AF-449C-4A39-986C-AD7F270F4750}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{231391AF-449C-4A39-986C-AD7F270F4750}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{231391AF-449C-4A39-986C-AD7F270F4750}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{231391AF-449C-4A39-986C-AD7F270F4750}.Release|Any CPU.Build.0 = Release|Any CPU
-		{E067A59D-9D0A-4A1F-92B1-38E4457241D1}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{E067A59D-9D0A-4A1F-92B1-38E4457241D1}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{E067A59D-9D0A-4A1F-92B1-38E4457241D1}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{E067A59D-9D0A-4A1F-92B1-38E4457241D1}.Release|Any CPU.Build.0 = Release|Any CPU
-		{DD01ED24-3750-4567-9A23-1DB676A15610}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{DD01ED24-3750-4567-9A23-1DB676A15610}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{DD01ED24-3750-4567-9A23-1DB676A15610}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{DD01ED24-3750-4567-9A23-1DB676A15610}.Release|Any CPU.Build.0 = Release|Any CPU
-		{EE01ED24-3750-4567-9A23-1DB676A15610}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{EE01ED24-3750-4567-9A23-1DB676A15610}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{EE01ED24-3750-4567-9A23-1DB676A15610}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{EE01ED24-3750-4567-9A23-1DB676A15610}.Release|Any CPU.Build.0 = Release|Any CPU
-		{EEFFED24-3750-4567-9A23-1DB676A15610}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{EEFFED24-3750-4567-9A23-1DB676A15610}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{EEFFED24-3750-4567-9A23-1DB676A15610}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{EEFFED24-3750-4567-9A23-1DB676A15610}.Release|Any CPU.Build.0 = Release|Any CPU
-	EndGlobalSection
-	GlobalSection(SolutionProperties) = preSolution
-		HideSolutionNode = FALSE
-	EndGlobalSection
-EndGlobal
diff --git a/csharp/src/UseVS2008.bat b/csharp/src/UseVS2008.bat
deleted file mode 100644
index 4cf973818..000000000
--- a/csharp/src/UseVS2008.bat
+++ /dev/null
@@ -1,8 +0,0 @@
-@ECHO OFF
-REM ---- Converts the solution to Visual Studio 2008 ----
-PUSHD %~dp0
-ECHO Microsoft Visual Studio Solution File, Format Version 10.00> Temp.sln
-ECHO # Visual Studio 2008>> Temp.sln
-type ProtocolBuffers.sln | FIND /V "" Visual Studio "" >> Temp.sln
-move /Y Temp.sln ProtocolBuffers.sln
-POPD
diff --git a/csharp/src/UseVS2010.bat b/csharp/src/UseVS2010.bat
deleted file mode 100644
index 376a08f72..000000000
--- a/csharp/src/UseVS2010.bat
+++ /dev/null
@@ -1,8 +0,0 @@
-@ECHO OFF
-REM ---- Converts the solution to Visual Studio 2010 ----
-PUSHD %~dp0
-ECHO Microsoft Visual Studio Solution File, Format Version 11.00> Temp.sln
-ECHO # Visual Studio 2010>> Temp.sln
-type ProtocolBuffers.sln | FIND /V "" Visual Studio "" >> Temp.sln
-move /Y Temp.sln ProtocolBuffers.sln
-POPD
","Remove a bunch of files which are no longer relevant:
1) Project files for different configurations - we're going to look at all this again, ideally to just have a single PCL-compatible build
2) ProtoGen - the C++ generator is now the only one we care about
3) Proto files - these are mostly duplicates (or older versions) of the ones in the common directories

"
112,C++,a9890afd12bd3bf41a092bf9d8e822408b4fe1c2,https://github.com/tesseract-ocr/tesseract/commit/a9890afd12bd3bf41a092bf9d8e822408b4fe1c2,C,tesseract-ocr,tesseract,"[1, 5, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/src/training/text2image.cpp b/src/training/text2image.cpp
index ab0b3f73..45b7b09a 100644
--- a/src/training/text2image.cpp
+++ b/src/training/text2image.cpp
@@ -32,4 +32,5 @@
 #include <iostream>
 #include <map>
+#include <random>
 #include <string>
 #include <utility>
@@ -574,6 +575,9 @@ static int Main() {
       offset += SpanUTF8Whitespace(str8 + offset);
     }
-    if (FLAGS_render_ngrams)
-      std::random_shuffle(offsets.begin(), offsets.end());
+    if (FLAGS_render_ngrams) {
+      std::seed_seq seed{kRandomSeed};
+      std::mt19937 random_gen(seed);
+      std::shuffle(offsets.begin(), offsets.end(), random_gen);
+    }
 
     for (size_t i = 0, line = 1; i < offsets.size(); ++i) {
","Fix text2image compilation on C++17 compilers

C++17 drops support for `std::random_shuffle`, breaking C++17 compilers
that run to compile text2image.cpp. std::shuffle is valid on C++11
through C++17, so use std::shuffle instead.

Due to the use `std::random_shuffle`, `text2image --render_ngrams`
would not give consistent results for different compilers or platforms.
With the current change, the same random number generator is used for
all platforms and initialized to the same seed, so training output
should be consistent.

"
113,C++,04a7650b51bc4950410a7c86ad56353fd21b72f3,https://github.com/tesseract-ocr/tesseract/commit/04a7650b51bc4950410a7c86ad56353fd21b72f3,P,tesseract-ocr,tesseract,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0]","diff --git a/README.md b/README.md
index 79c317ef..bc55525d 100644
--- a/README.md
+++ b/README.md
@@ -3,5 +3,5 @@
 [![Build Status](https://travis-ci.org/tesseract-ocr/tesseract.svg?branch=master)](https://travis-ci.org/tesseract-ocr/tesseract)
 [![Build status](https://ci.appveyor.com/api/projects/status/miah0ikfsf0j3819/branch/master?svg=true)](https://ci.appveyor.com/project/zdenop/tesseract/)
-![Build status](https://github.com/tesseract-ocr/tesseract/workflows/windows/badge.svg)<br>
+![Build status](https://github.com/tesseract-ocr/tesseract/workflows/sw/badge.svg)<br>
 [![Coverity Scan Build Status](https://scan.coverity.com/projects/tesseract-ocr/badge.svg)](https://scan.coverity.com/projects/tesseract-ocr)
 [![Code Quality: Cpp](https://img.shields.io/lgtm/grade/cpp/g/tesseract-ocr/tesseract.svg?logo=lgtm&logoWidth=18)](https://lgtm.com/projects/g/tesseract-ocr/tesseract/context:cpp)
","Update README.md
"
114,C++,25d0968d094a8f6d4ec52f1cc9b869f4a650e3b7,https://github.com/tesseract-ocr/tesseract/commit/25d0968d094a8f6d4ec52f1cc9b869f4a650e3b7,P,tesseract-ocr,tesseract,"[28, 399, 766, 211, 138, 486, 37, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/ccmain/applybox.cpp b/ccmain/applybox.cpp
index b9a28fa3..9c067e79 100644
--- a/ccmain/applybox.cpp
+++ b/ccmain/applybox.cpp
@@ -583,5 +583,5 @@ bool Tesseract::FindSegmentation(const GenericVector<UNICHAR_ID>& target_text,
     for (int s = 0; s < word_res->seam_array.size(); ++s) {
       SEAM* seam = word_res->seam_array[s];
-      if (seam->split1 == NULL) {
+      if (!seam->HasAnySplits()) {
         word_res->best_state.push_back(blob_count);
         blob_count = 1;
diff --git a/ccmain/tfacepp.cpp b/ccmain/tfacepp.cpp
index 45775fe4..e1dc778f 100644
--- a/ccmain/tfacepp.cpp
+++ b/ccmain/tfacepp.cpp
@@ -255,5 +255,5 @@ void Tesseract::join_words(WERD_RES *word,
   // Since the seam list is one element short, an empty seam marking the
   // end of the last blob in the first word is needed first.
-  word->seam_array.push_back(new SEAM(0.0f, split_pt, NULL, NULL, NULL));
+  word->seam_array.push_back(new SEAM(0.0f, split_pt));
   word->seam_array += word2->seam_array;
   word2->seam_array.truncate(0);
diff --git a/ccstruct/blobs.cpp b/ccstruct/blobs.cpp
index a0e6dc7b..97f95eba 100644
--- a/ccstruct/blobs.cpp
+++ b/ccstruct/blobs.cpp
@@ -65,4 +65,40 @@ const TPOINT kDivisibleVerticalItalic(1, 5);
 CLISTIZE(EDGEPT);
 
+// Returns true when the two line segments cross each other.
+// (Moved from outlines.cpp).
+// Finds where the projected lines would cross and then checks to see if the
+// point of intersection lies on both of the line segments. If it does
+// then these two segments cross.
+/* static */
+bool TPOINT::IsCrossed(const TPOINT& a0, const TPOINT& a1, const TPOINT& b0,
+                       const TPOINT& b1) {
+  int b0a1xb0b1, b0b1xb0a0;
+  int a1b1xa1a0, a1a0xa1b0;
+
+  TPOINT b0a1, b0a0, a1b1, b0b1, a1a0;
+
+  b0a1.x = a1.x - b0.x;
+  b0a0.x = a0.x - b0.x;
+  a1b1.x = b1.x - a1.x;
+  b0b1.x = b1.x - b0.x;
+  a1a0.x = a0.x - a1.x;
+  b0a1.y = a1.y - b0.y;
+  b0a0.y = a0.y - b0.y;
+  a1b1.y = b1.y - a1.y;
+  b0b1.y = b1.y - b0.y;
+  a1a0.y = a0.y - a1.y;
+
+  b0a1xb0b1 = CROSS(b0a1, b0b1);
+  b0b1xb0a0 = CROSS(b0b1, b0a0);
+  a1b1xa1a0 = CROSS(a1b1, a1a0);
+  // For clarity, we want CROSS(a1a0,a1b0) here but we have b0a1 instead of a1b0
+  // so use -CROSS(a1b0,b0a1) instead, which is the same.
+  a1a0xa1b0 = -CROSS(a1a0, b0a1);
+
+  return ((b0a1xb0b1 > 0 && b0b1xb0a0 > 0) ||
+          (b0a1xb0b1 < 0 && b0b1xb0a0 < 0)) &&
+         ((a1b1xa1a0 > 0 && a1a0xa1b0 > 0) || (a1b1xa1a0 < 0 && a1a0xa1b0 < 0));
+}
+
 // Consume the circular list of EDGEPTs to make a TESSLINE.
 TESSLINE* TESSLINE::BuildFromOutlineList(EDGEPT* outline) {
@@ -455,4 +491,34 @@ TBOX TBLOB::bounding_box() const {
 }
 
+// Finds and deletes any duplicate outlines in this blob, without deleting
+// their EDGEPTs.
+void TBLOB::EliminateDuplicateOutlines() {
+  for (TESSLINE* outline = outlines; outline != NULL; outline = outline->next) {
+    TESSLINE* last_outline = outline;
+    for (TESSLINE* other_outline = outline->next; other_outline != NULL;
+         last_outline = other_outline, other_outline = other_outline->next) {
+      if (outline->SameBox(*other_outline)) {
+        last_outline->next = other_outline->next;
+        // This doesn't leak - the outlines share the EDGEPTs.
+        other_outline->loop = NULL;
+        delete other_outline;
+        other_outline = last_outline;
+        // If it is part of a cut, then it can't be a hole any more.
+        outline->is_hole = false;
+      }
+    }
+  }
+}
+
+// Swaps the outlines of *this and next if needed to keep the centers in
+// increasing x.
+void TBLOB::CorrectBlobOrder(TBLOB* next) {
+  TBOX box = bounding_box();
+  TBOX next_box = next->bounding_box();
+  if (box.x_middle() > next_box.x_middle()) {
+    Swap(&outlines, &next->outlines);
+  }
+}
+
 #ifndef GRAPHICS_DISABLED
 void TBLOB::plot(ScrollView* window, ScrollView::Color color,
@@ -859,16 +925,4 @@ void TWERD::plot(ScrollView* window) {
 #endif  // GRAPHICS_DISABLED
 
-/**********************************************************************
- * blob_origin
- *
- * Compute the origin of a compound blob, define to be the centre
- * of the bounding box.
- **********************************************************************/
-void blob_origin(TBLOB *blob,       /*blob to compute on */
-                 TPOINT *origin) {  /*return value */
-  TBOX bbox = blob->bounding_box();
-  *origin = (bbox.topleft() + bbox.botright()) / 2;
-}
-
 /**********************************************************************
  * divisible_blob
diff --git a/ccstruct/blobs.h b/ccstruct/blobs.h
index e39761b1..1fd9683e 100644
--- a/ccstruct/blobs.h
+++ b/ccstruct/blobs.h
@@ -61,4 +61,11 @@ struct TPOINT {
     y /= divisor;
   }
+  bool operator==(const TPOINT& other) const {
+    return x == other.x && y == other.y;
+  }
+  // Returns true when the two line segments cross each other.
+  // (Moved from outlines.cpp).
+  static bool IsCrossed(const TPOINT& a0, const TPOINT& a1, const TPOINT& b0,
+                        const TPOINT& b1);
 
   inT16 x;                       // absolute x coord.
@@ -88,4 +95,53 @@ struct EDGEPT {
     step_count = src.step_count;
   }
+  // Returns the squared distance between the points, with the x-component
+  // weighted by x_factor.
+  int WeightedDistance(const EDGEPT& other, int x_factor) const {
+    int x_dist = pos.x - other.pos.x;
+    int y_dist = pos.y - other.pos.y;
+    return x_dist * x_dist * x_factor + y_dist * y_dist;
+  }
+  // Returns true if the positions are equal.
+  bool EqualPos(const EDGEPT& other) const { return pos == other.pos; }
+  // Returns the bounding box of the outline segment from *this to *end.
+  // Ignores hidden edge flags.
+  TBOX SegmentBox(const EDGEPT* end) const {
+    TBOX box(pos.x, pos.y, pos.x, pos.y);
+    const EDGEPT* pt = this;
+    do {
+      pt = pt->next;
+      if (pt->pos.x < box.left()) box.set_left(pt->pos.x);
+      if (pt->pos.x > box.right()) box.set_right(pt->pos.x);
+      if (pt->pos.y < box.bottom()) box.set_bottom(pt->pos.y);
+      if (pt->pos.y > box.top()) box.set_top(pt->pos.y);
+    } while (pt != end && pt != this);
+    return box;
+  }
+  // Returns the area of the outline segment from *this to *end.
+  // Ignores hidden edge flags.
+  int SegmentArea(const EDGEPT* end) const {
+    int area = 0;
+    const EDGEPT* pt = this->next;
+    do {
+      TPOINT origin_vec(pt->pos.x - pos.x, pt->pos.y - pos.y);
+      area += CROSS(origin_vec, pt->vec);
+      pt = pt->next;
+    } while (pt != end && pt != this);
+    return area;
+  }
+  // Returns true if the number of points in the outline segment from *this to
+  // *end is less that min_points and false if we get back to *this first.
+  // Ignores hidden edge flags.
+  bool ShortNonCircularSegment(int min_points, const EDGEPT* end) const {
+    int count = 0;
+    const EDGEPT* pt = this;
+    do {
+      if (pt == end) return true;
+      pt = pt->next;
+      ++count;
+    } while (pt != this && count <= min_points);
+    return false;
+  }
+
   // Accessors to hide or reveal a cut edge from feature extractors.
   void Hide() {
@@ -101,7 +157,4 @@ struct EDGEPT {
     flags[2] = true;
   }
-  void UnmarkChop() {
-    flags[2] = false;
-  }
   bool IsChopPt() const {
     return flags[2] != 0;
@@ -163,6 +216,21 @@ struct TESSLINE {
 
   TBOX bounding_box() const;
+  // Returns true if *this and other have equal bounding boxes.
+  bool SameBox(const TESSLINE& other) const {
+    return topleft == other.topleft && botright == other.botright;
+  }
+  // Returns true if the given line segment crosses any outline of this blob.
+  bool SegmentCrosses(const TPOINT& pt1, const TPOINT& pt2) const {
+    if (Contains(pt1) && Contains(pt2)) {
+      EDGEPT* pt = loop;
+      do {
+        if (TPOINT::IsCrossed(pt1, pt2, pt->pos, pt->next->pos)) return true;
+        pt = pt->next;
+      } while (pt != loop);
+    }
+    return false;
+  }
   // Returns true if the point is contained within the outline box.
-  bool Contains(const TPOINT& pt) {
+  bool Contains(const TPOINT& pt) const {
     return topleft.x <= pt.x && pt.x <= botright.x &&
            botright.y <= pt.y && pt.y <= topleft.y;
@@ -245,4 +313,29 @@ struct TBLOB {
   TBOX bounding_box() const;
 
+  // Returns true if the given line segment crosses any outline of this blob.
+  bool SegmentCrossesOutline(const TPOINT& pt1, const TPOINT& pt2) const {
+    for (const TESSLINE* outline = outlines; outline != NULL;
+         outline = outline->next) {
+      if (outline->SegmentCrosses(pt1, pt2)) return true;
+    }
+    return false;
+  }
+  // Returns true if the point is contained within any of the outline boxes.
+  bool Contains(const TPOINT& pt) const {
+    for (const TESSLINE* outline = outlines; outline != NULL;
+         outline = outline->next) {
+      if (outline->Contains(pt)) return true;
+    }
+    return false;
+  }
+
+  // Finds and deletes any duplicate outlines in this blob, without deleting
+  // their EDGEPTs.
+  void EliminateDuplicateOutlines();
+
+  // Swaps the outlines of *this and next if needed to keep the centers in
+  // increasing x.
+  void CorrectBlobOrder(TBLOB* next);
+
   const DENORM& denorm() const {
     return denorm_;
@@ -359,10 +452,5 @@ if (w) memfree (w)
               F u n c t i o n s
 ----------------------------------------------------------------------*/
-// TODO(rays) This will become a member of TBLOB when TBLOB's definition
-// moves to blobs.h
-
-// Returns the center of blob's bounding box in origin.
-void blob_origin(TBLOB *blob, TPOINT *origin);
-
+// TODO(rays) Make divisible_blob and divide_blobs members of TBLOB.
 bool divisible_blob(TBLOB *blob, bool italic_blob, TPOINT* location);
 
diff --git a/ccstruct/pageres.cpp b/ccstruct/pageres.cpp
index 6a7f7a02..58f7d8a8 100644
--- a/ccstruct/pageres.cpp
+++ b/ccstruct/pageres.cpp
@@ -405,5 +405,6 @@ void WERD_RES::SetupBlobWidthsAndGaps() {
 void WERD_RES::InsertSeam(int blob_number, SEAM* seam) {
   // Insert the seam into the SEAMS array.
-  insert_seam(chopped_word, blob_number, seam, &seam_array);
+  seam->PrepareToInsertSeam(seam_array, chopped_word->blobs, blob_number, true);
+  seam_array.insert(seam, blob_number);
   if (ratings != NULL) {
     // Expand the ratings matrix.
@@ -805,10 +806,14 @@ void WERD_RES::RebuildBestState() {
     int length = best_choice->state(i);
     best_state.push_back(length);
-    if (length > 1)
-      join_pieces(seam_array, start, start + length - 1, chopped_word);
+    if (length > 1) {
+      SEAM::JoinPieces(seam_array, chopped_word->blobs, start,
+                       start + length - 1);
+    }
     TBLOB* blob = chopped_word->blobs[start];
     rebuild_word->blobs.push_back(new TBLOB(*blob));
-    if (length > 1)
-      break_pieces(seam_array, start, start + length - 1, chopped_word);
+    if (length > 1) {
+      SEAM::BreakPieces(seam_array, chopped_word->blobs, start,
+                        start + length - 1);
+    }
     start += length;
   }
@@ -1066,6 +1071,5 @@ bool WERD_RES::PiecesAllNatural(int start, int count) const {
     if (index >= 0 && index < seam_array.size()) {
       SEAM* seam = seam_array[index];
-      if (seam != NULL && seam->split1 != NULL)
-        return false;
+      if (seam != NULL && seam->HasAnySplits()) return false;
     }
   }
diff --git a/ccstruct/seam.cpp b/ccstruct/seam.cpp
index e05fac9a..3d70eafc 100644
--- a/ccstruct/seam.cpp
+++ b/ccstruct/seam.cpp
@@ -28,320 +28,153 @@
 #include ""seam.h""
 #include ""blobs.h""
-#include ""freelist.h""
 #include ""tprintf.h""
 
-#ifdef __UNIX__
-#include <assert.h>
-#endif
-
-/*----------------------------------------------------------------------
-              V a r i a b l e s
-----------------------------------------------------------------------*/
-#define NUM_STARTING_SEAMS  20
-
 /*----------------------------------------------------------------------
         Public Function Code
 ----------------------------------------------------------------------*/
-/**
- * @name point_in_split
- *
- * Check to see if either of these points are present in the current
- * split.
- * @returns TRUE if one of them is split.
- */
-bool point_in_split(SPLIT *split, EDGEPT *point1, EDGEPT *point2) {
-  return ((split) ? ((exact_point (split->point1, point1) ||
-                      exact_point (split->point1, point2) ||
-                      exact_point (split->point2, point1) ||
-                      exact_point (split->point2, point2)) ? TRUE : FALSE)
-                  : FALSE);
-}
-
-
-/**
- * @name point_in_seam
- *
- * Check to see if either of these points are present in the current
- * seam.
- * @returns TRUE if one of them is.
- */
-bool point_in_seam(const SEAM *seam, SPLIT *split) {
-  return (point_in_split(seam->split1, split->point1, split->point2) ||
-          point_in_split(seam->split2, split->point1, split->point2) ||
-          point_in_split(seam->split3, split->point1, split->point2));
-}
-
-/**
- * @name point_used_by_split
- *
- * Return whether this particular EDGEPT * is used in a given split.
- * @returns TRUE if the edgept is used by the split.
- */
-bool point_used_by_split(SPLIT *split, EDGEPT *point) {
-  if (split == NULL) return false;
-  return point == split->point1 || point == split->point2;
-}
 
-/**
- * @name point_used_by_seam
- *
- * Return whether this particular EDGEPT * is used in a given seam.
- * @returns TRUE if the edgept is used by the seam.
- */
-bool point_used_by_seam(SEAM *seam, EDGEPT *point) {
-  if (seam == NULL) return false;
-  return point_used_by_split(seam->split1, point) ||
-      point_used_by_split(seam->split2, point) ||
-      point_used_by_split(seam->split3, point);
+// Returns the bounding box of all the points in the seam.
+TBOX SEAM::bounding_box() const {
+  TBOX box(location_.x, location_.y, location_.x, location_.y);
+  for (int s = 0; s < num_splits_; ++s) {
+    box += splits_[s].bounding_box();
+  }
+  return box;
 }
 
-/**
- * @name combine_seam
- *
- * Combine two seam records into a single seam.  Move the split
- * references from the second seam to the first one.  The argument
- * convention is patterned after strcpy.
- */
-void combine_seams(SEAM *dest_seam, SEAM *source_seam) {
-  dest_seam->priority += source_seam->priority;
-  dest_seam->location += source_seam->location;
-  dest_seam->location /= 2;
-
-  if (source_seam->split1) {
-    if (!dest_seam->split1)
-      dest_seam->split1 = source_seam->split1;
-    else if (!dest_seam->split2)
-      dest_seam->split2 = source_seam->split1;
-    else if (!dest_seam->split3)
-      dest_seam->split3 = source_seam->split1;
-    else
-      delete source_seam->split1;  // Wouldn't have fitted.
-    source_seam->split1 = NULL;
-  }
-  if (source_seam->split2) {
-    if (!dest_seam->split2)
-      dest_seam->split2 = source_seam->split2;
-    else if (!dest_seam->split3)
-      dest_seam->split3 = source_seam->split2;
-    else
-      delete source_seam->split2;  // Wouldn't have fitted.
-    source_seam->split2 = NULL;
-  }
-  if (source_seam->split3) {
-    if (!dest_seam->split3)
-      dest_seam->split3 = source_seam->split3;
-    else
-      delete source_seam->split3;  // Wouldn't have fitted.
-    source_seam->split3 = NULL;
+// Returns true if other can be combined into *this.
+bool SEAM::CombineableWith(const SEAM& other, int max_x_dist,
+                           float max_total_priority) const {
+  int dist = location_.x - other.location_.x;
+  if (-max_x_dist < dist && dist < max_x_dist &&
+      num_splits_ + other.num_splits_ <= kMaxNumSplits &&
+      priority_ + other.priority_ < max_total_priority &&
+      !OverlappingSplits(other) && !SharesPosition(other)) {
+    return true;
+  } else {
+    return false;
   }
-  delete source_seam;
 }
 
-/**
- * @name start_seam_list
- *
- * Initialize a list of seams that match the original number of blobs
- * present in the starting segmentation.  Each of the seams created
- * by this routine have location information only.
- */
-void start_seam_list(TWERD *word, GenericVector<SEAM*>* seam_array) {
-  seam_array->truncate(0);
-  TPOINT location;
+// Combines other into *this. Only works if CombinableWith returned true.
+void SEAM::CombineWith(const SEAM& other) {
+  priority_ += other.priority_;
+  location_ += other.location_;
+  location_ /= 2;
 
-  for (int b = 1; b < word->NumBlobs(); ++b) {
-    TBOX bbox = word->blobs[b - 1]->bounding_box();
-    TBOX nbox = word->blobs[b]->bounding_box();
-    location.x = (bbox.right() + nbox.left()) / 2;
-    location.y = (bbox.bottom() + bbox.top() + nbox.bottom() + nbox.top()) / 4;
-    seam_array->push_back(new SEAM(0.0f, location, NULL, NULL, NULL));
-  }
+  for (int s = 0; s < other.num_splits_ && num_splits_ < kMaxNumSplits; ++s)
+    splits_[num_splits_++] = other.splits_[s];
 }
 
+// Returns true if the splits in *this SEAM appear OK in the sense that they
+// do not cross any outlines and do not chop off any ridiculously small
+// pieces.
+bool SEAM::IsHealthy(const TBLOB& blob, int min_points, int min_area) const {
+  // TODO(rays) Try testing all the splits. Duplicating original code for now,
+  // which tested only the first.
+  return num_splits_ == 0 || splits_[0].IsHealthy(blob, min_points, min_area);
+}
 
-/**
- * @name test_insert_seam
- *
- * @returns true if insert_seam will succeed.
- */
-bool test_insert_seam(const GenericVector<SEAM*>& seam_array,
-                      TWERD *word, int index) {
-  SEAM *test_seam;
-  int list_length = seam_array.size();
-  for (int test_index = 0; test_index < index; ++test_index) {
-    test_seam = seam_array[test_index];
-    if (test_index + test_seam->widthp < index &&
-        test_seam->widthp + test_index == index - 1 &&
-        account_splits(test_seam, word, test_index + 1, 1) < 0)
-      return false;
+// Computes the widthp_/widthn_ range for all existing SEAMs and for *this
+// seam, which is about to be inserted at insert_index. Returns false if
+// any of the computations fails, as this indicates an invalid chop.
+// widthn_/widthp_ are only changed if modify is true.
+bool SEAM::PrepareToInsertSeam(const GenericVector<SEAM*>& seams,
+                               const GenericVector<TBLOB*>& blobs,
+                               int insert_index, bool modify) {
+  for (int s = 0; s < insert_index; ++s) {
+    if (!seams[s]->FindBlobWidth(blobs, s, modify)) return false;
   }
-  for (int test_index = index; test_index < list_length; test_index++) {
-    test_seam = seam_array[test_index];
-    if (test_index - test_seam->widthn >= index &&
-        test_index - test_seam->widthn == index &&
-        account_splits(test_seam, word, test_index + 1, -1) < 0)
-      return false;
+  if (!FindBlobWidth(blobs, insert_index, modify)) return false;
+  for (int s = insert_index; s < seams.size(); ++s) {
+    if (!seams[s]->FindBlobWidth(blobs, s + 1, modify)) return false;
   }
   return true;
 }
 
-/**
- * @name insert_seam
- *
- * Add another seam to a collection of seams at a particular location
- * in the seam array.
- */
-void insert_seam(const TWERD* word, int index, SEAM *seam,
-                 GenericVector<SEAM*>* seam_array) {
-  SEAM *test_seam;
-  int list_length = seam_array->size();
-  for (int test_index = 0; test_index < index; ++test_index) {
-    test_seam = seam_array->get(test_index);
-    if (test_index + test_seam->widthp >= index) {
-      test_seam->widthp++;       /*got in the way */
-    } else if (test_seam->widthp + test_index == index - 1) {
-      test_seam->widthp = account_splits(test_seam, word, test_index + 1, 1);
-      if (test_seam->widthp < 0) {
-        tprintf(""Failed to find any right blob for a split!\n"");
-        print_seam(""New dud seam"", seam);
-        print_seam(""Failed seam"", test_seam);
-      }
-    }
+// Computes the widthp_/widthn_ range. Returns false if not all the splits
+// are accounted for. widthn_/widthp_ are only changed if modify is true.
+bool SEAM::FindBlobWidth(const GenericVector<TBLOB*>& blobs, int index,
+                         bool modify) {
+  int num_found = 0;
+  if (modify) {
+    widthp_ = 0;
+    widthn_ = 0;
   }
-  for (int test_index = index; test_index < list_length; test_index++) {
-    test_seam = seam_array->get(test_index);
-    if (test_index - test_seam->widthn < index) {
-      test_seam->widthn++;       /*got in the way */
-    } else if (test_index - test_seam->widthn == index) {
-      test_seam->widthn = account_splits(test_seam, word, test_index + 1, -1);
-      if (test_seam->widthn < 0) {
-        tprintf(""Failed to find any left blob for a split!\n"");
-        print_seam(""New dud seam"", seam);
-        print_seam(""Failed seam"", test_seam);
-      }
+  for (int s = 0; s < num_splits_; ++s) {
+    const SPLIT& split = splits_[s];
+    bool found_split = split.ContainedByBlob(*blobs[index]);
+    // Look right.
+    for (int b = index + 1; !found_split && b < blobs.size(); ++b) {
+      found_split = split.ContainedByBlob(*blobs[b]);
+      if (found_split && b - index > widthp_ && modify) widthp_ = b - index;
     }
+    // Look left.
+    for (int b = index - 1; !found_split && b >= 0; --b) {
+      found_split = split.ContainedByBlob(*blobs[b]);
+      if (found_split && index - b > widthn_ && modify) widthn_ = index - b;
+    }
+    if (found_split) ++num_found;
   }
-  seam_array->insert(seam, index);
+  return num_found == num_splits_;
 }
 
+// Splits this blob into two blobs by applying the splits included in
+// *this SEAM
+void SEAM::ApplySeam(bool italic_blob, TBLOB* blob, TBLOB* other_blob) const {
+  for (int s = 0; s < num_splits_; ++s) {
+    splits_[s].SplitOutlineList(blob->outlines);
+  }
+  blob->ComputeBoundingBoxes();
 
-/**
- * @name account_splits
- *
- * Account for all the splits by looking to the right (blob_direction == 1),
- * or to the left (blob_direction == -1) in the word.
- */
-int account_splits(const SEAM *seam, const TWERD *word, int blob_index,
-                   int blob_direction) {
-  inT8 found_em[3];
-  inT8 width;
-
-  found_em[0] = seam->split1 == NULL;
-  found_em[1] = seam->split2 == NULL;
-  found_em[2] = seam->split3 == NULL;
-  if (found_em[0] && found_em[1] && found_em[2])
-    return 0;
-  width = 0;
-  do {
-    TBLOB* blob = word->blobs[blob_index];
-    if (!found_em[0])
-      found_em[0] = find_split_in_blob(seam->split1, blob);
-    if (!found_em[1])
-      found_em[1] = find_split_in_blob(seam->split2, blob);
-    if (!found_em[2])
-      found_em[2] = find_split_in_blob(seam->split3, blob);
-    if (found_em[0] && found_em[1] && found_em[2]) {
-      return width;
-    }
-    width++;
-    blob_index += blob_direction;
-  } while (0 <= blob_index && blob_index < word->NumBlobs());
-  return -1;
-}
-
+  divide_blobs(blob, other_blob, italic_blob, location_);
 
-/**
- * @name find_split_in_blob
- *
- * @returns TRUE if the split is somewhere in this blob.
- */
-bool find_split_in_blob(SPLIT *split, TBLOB *blob) {
-  TESSLINE *outline;
+  blob->EliminateDuplicateOutlines();
+  other_blob->EliminateDuplicateOutlines();
 
-  for (outline = blob->outlines; outline != NULL; outline = outline->next)
-    if (outline->Contains(split->point1->pos))
-      break;
-  if (outline == NULL)
-    return FALSE;
-  for (outline = blob->outlines; outline != NULL; outline = outline->next)
-    if (outline->Contains(split->point2->pos))
-      return TRUE;
-  return FALSE;
+  blob->CorrectBlobOrder(other_blob);
 }
 
+// Undoes ApplySeam by removing the seam between these two blobs.
+// Produces one blob as a result, and deletes other_blob.
+void SEAM::UndoSeam(TBLOB* blob, TBLOB* other_blob) const {
+  if (blob->outlines == NULL) {
+    blob->outlines = other_blob->outlines;
+    other_blob->outlines = NULL;
+  }
 
-/**
- * @name join_two_seams
- *
- * Merge these two seams into a new seam.  Duplicate the split records
- * in both of the input seams.  Return the resultant seam.
- */
-SEAM *join_two_seams(const SEAM *seam1, const SEAM *seam2) {
-  SEAM *result = NULL;
-  SEAM *temp;
-
-  assert(seam1 &&seam2);
+  TESSLINE* outline = blob->outlines;
+  while (outline->next) outline = outline->next;
+  outline->next = other_blob->outlines;
+  other_blob->outlines = NULL;
+  delete other_blob;
 
-  if (((seam1->split3 == NULL && seam2->split2 == NULL) ||
-       (seam1->split2 == NULL && seam2->split3 == NULL) ||
-        seam1->split1 == NULL || seam2->split1 == NULL) &&
-      (!shared_split_points(seam1, seam2))) {
-    result = new SEAM(*seam1);
-    temp = new SEAM(*seam2);
-    combine_seams(result, temp);
+  for (int s = 0; s < num_splits_; ++s) {
+    splits_[s].UnsplitOutlineList(blob);
   }
-  return (result);
+  blob->ComputeBoundingBoxes();
+  blob->EliminateDuplicateOutlines();
 }
 
-/**
- * @name print_seam
- *
- * Print a list of splits.  Show the coordinates of both points in
- * each split.
- */
-void print_seam(const char *label, SEAM *seam) {
-  if (seam) {
-    tprintf(label);
-    tprintf("" %6.2f @ (%d,%d), p=%d, n=%d "",
-            seam->priority, seam->location.x, seam->location.y,
-            seam->widthp, seam->widthn);
-    print_split(seam->split1);
-
-    if (seam->split2) {
-      tprintf("",   "");
-      print_split (seam->split2);
-      if (seam->split3) {
-        tprintf("",   "");
-        print_split (seam->split3);
-      }
-    }
-    tprintf(""\n"");
+// Prints everything in *this SEAM.
+void SEAM::Print(const char* label) const {
+  tprintf(label);
+  tprintf("" %6.2f @ (%d,%d), p=%d, n=%d "", priority_, location_.x, location_.y,
+          widthp_, widthn_);
+  for (int s = 0; s < num_splits_; ++s) {
+    splits_[s].Print();
+    if (s + 1 < num_splits_) tprintf("",   "");
   }
+  tprintf(""\n"");
 }
 
-
-/**
- * @name print_seams
- *
- * Print a list of splits.  Show the coordinates of both points in
- * each split.
- */
-void print_seams(const char *label, const GenericVector<SEAM*>& seams) {
-  char number[CHARS_PER_LINE];
-
+// Prints a collection of SEAMs.
+/* static */
+void SEAM::PrintSeams(const char* label, const GenericVector<SEAM*>& seams) {
   if (!seams.empty()) {
     tprintf(""%s\n"", label);
     for (int x = 0; x < seams.size(); ++x) {
-      sprintf(number, ""%2d:   "", x);
-      print_seam(number, seams[x]);
+      tprintf(""%2d:   "", x);
+      seams[x]->Print("""");
     }
     tprintf(""\n"");
@@ -349,52 +182,26 @@ void print_seams(const char *label, const GenericVector<SEAM*>& seams) {
 }
 
-
-/**
- * @name shared_split_points
- *
- * Check these two seams to make sure that neither of them have two
- * points in common. Return TRUE if any of the same points are present
- * in any of the splits of both seams.
- */
-int shared_split_points(const SEAM *seam1, const SEAM *seam2) {
-  if (seam1 == NULL || seam2 == NULL)
-    return (FALSE);
-
-  if (seam2->split1 == NULL)
-    return (FALSE);
-  if (point_in_seam(seam1, seam2->split1))
-    return (TRUE);
-
-  if (seam2->split2 == NULL)
-    return (FALSE);
-  if (point_in_seam(seam1, seam2->split2))
-    return (TRUE);
-
-  if (seam2->split3 == NULL)
-    return (FALSE);
-  if (point_in_seam(seam1, seam2->split3))
-    return (TRUE);
-
-  return (FALSE);
+#ifndef GRAPHICS_DISABLED
+// Draws the seam in the given window.
+void SEAM::Mark(ScrollView* window) const {
+  for (int s = 0; s < num_splits_; ++s) splits_[s].Mark(window);
 }
+#endif
 
-/**********************************************************************
- * break_pieces
- *
- * Break up the blobs in this chain so that they are all independent.
- * This operation should undo the affect of join_pieces.
- **********************************************************************/
-void break_pieces(const GenericVector<SEAM*>& seams, int first, int last,
-                  TWERD *word) {
-  for (int x = first; x < last; ++x)
-    reveal_seam(seams[x]);
+// Break up the blobs in this chain so that they are all independent.
+// This operation should undo the affect of join_pieces.
+/* static */
+void SEAM::BreakPieces(const GenericVector<SEAM*>& seams,
+                       const GenericVector<TBLOB*>& blobs, int first,
+                       int last) {
+  for (int x = first; x < last; ++x) seams[x]->Reveal();
 
-  TESSLINE *outline = word->blobs[first]->outlines;
+  TESSLINE* outline = blobs[first]->outlines;
   int next_blob = first + 1;
 
   while (outline != NULL && next_blob <= last) {
-    if (outline->next == word->blobs[next_blob]->outlines) {
+    if (outline->next == blobs[next_blob]->outlines) {
       outline->next = NULL;
-      outline = word->blobs[next_blob]->outlines;
+      outline = blobs[next_blob]->outlines;
       ++next_blob;
     } else {
@@ -404,14 +211,10 @@ void break_pieces(const GenericVector<SEAM*>& seams, int first, int last,
 }
 
-
-/**********************************************************************
- * join_pieces
- *
- * Join a group of base level pieces into a single blob that can then
- * be classified.
- **********************************************************************/
-void join_pieces(const GenericVector<SEAM*>& seams, int first, int last,
-                 TWERD *word) {
-  TESSLINE *outline = word->blobs[first]->outlines;
+// Join a group of base level pieces into a single blob that can then
+// be classified.
+/* static */
+void SEAM::JoinPieces(const GenericVector<SEAM*>& seams,
+                      const GenericVector<TBLOB*>& blobs, int first, int last) {
+  TESSLINE* outline = blobs[first]->outlines;
   if (!outline)
     return;
@@ -419,115 +222,59 @@ void join_pieces(const GenericVector<SEAM*>& seams, int first, int last,
   for (int x = first; x < last; ++x) {
     SEAM *seam = seams[x];
-    if (x - seam->widthn >= first && x + seam->widthp < last)
-      hide_seam(seam);
-    while (outline->next)
-      outline = outline->next;
-    outline->next = word->blobs[x + 1]->outlines;
+    if (x - seam->widthn_ >= first && x + seam->widthp_ < last) seam->Hide();
+    while (outline->next) outline = outline->next;
+    outline->next = blobs[x + 1]->outlines;
   }
 }
 
-
-/**********************************************************************
- * hide_seam
- *
- * Change the edge points that are referenced by this seam to make
- * them hidden edges.
- **********************************************************************/
-void hide_seam(SEAM *seam) {
-  if (seam == NULL || seam->split1 == NULL)
-    return;
-  hide_edge_pair (seam->split1->point1, seam->split1->point2);
-
-  if (seam->split2 == NULL)
-    return;
-  hide_edge_pair (seam->split2->point1, seam->split2->point2);
-
-  if (seam->split3 == NULL)
-    return;
-  hide_edge_pair (seam->split3->point1, seam->split3->point2);
+// Hides the seam so the outlines appear not to be cut by it.
+void SEAM::Hide() const {
+  for (int s = 0; s < num_splits_; ++s) {
+    splits_[s].Hide();
+  }
 }
 
-
-/**********************************************************************
- * hide_edge_pair
- *
- * Change the edge points that are referenced by this seam to make
- * them hidden edges.
- **********************************************************************/
-void hide_edge_pair(EDGEPT *pt1, EDGEPT *pt2) {
-  EDGEPT *edgept;
-
-  edgept = pt1;
-  do {
-    edgept->Hide();
-    edgept = edgept->next;
-  }
-  while (!exact_point (edgept, pt2) && edgept != pt1);
-  if (edgept == pt1) {
-    /*              tprintf(""Hid entire outline at (%d,%d)!!\n"",
-       edgept->pos.x,edgept->pos.y);                                */
-  }
-  edgept = pt2;
-  do {
-    edgept->Hide();
-    edgept = edgept->next;
-  }
-  while (!exact_point (edgept, pt1) && edgept != pt2);
-  if (edgept == pt2) {
-    /*              tprintf(""Hid entire outline at (%d,%d)!!\n"",
-       edgept->pos.x,edgept->pos.y);                                */
+// Undoes hide, so the outlines are cut by the seam.
+void SEAM::Reveal() const {
+  for (int s = 0; s < num_splits_; ++s) {
+    splits_[s].Reveal();
   }
 }
 
-
-/**********************************************************************
- * reveal_seam
- *
- * Change the edge points that are referenced by this seam to make
- * them hidden edges.
- **********************************************************************/
-void reveal_seam(SEAM *seam) {
-  if (seam == NULL || seam->split1 == NULL)
-    return;
-  reveal_edge_pair (seam->split1->point1, seam->split1->point2);
-
-  if (seam->split2 == NULL)
-    return;
-  reveal_edge_pair (seam->split2->point1, seam->split2->point2);
-
-  if (seam->split3 == NULL)
-    return;
-  reveal_edge_pair (seam->split3->point1, seam->split3->point2);
+// Computes and returns, but does not set, the full priority of *this SEAM.
+float SEAM::FullPriority(int xmin, int xmax, double overlap_knob,
+                         int centered_maxwidth, double center_knob,
+                         double width_change_knob) const {
+  if (num_splits_ == 0) return 0.0f;
+  for (int s = 1; s < num_splits_; ++s) {
+    splits_[s].SplitOutline();
+  }
+  float full_priority =
+      priority_ +
+      splits_[0].FullPriority(xmin, xmax, overlap_knob, centered_maxwidth,
+                              center_knob, width_change_knob);
+  for (int s = num_splits_ - 1; s >= 1; --s) {
+    splits_[s].UnsplitOutlines();
+  }
+  return full_priority;
 }
 
-
-/**********************************************************************
- * reveal_edge_pair
+/**
+ * @name start_seam_list
  *
- * Change the edge points that are referenced by this seam to make
- * them hidden edges.
- **********************************************************************/
-void reveal_edge_pair(EDGEPT *pt1, EDGEPT *pt2) {
-  EDGEPT *edgept;
+ * Initialize a list of seams that match the original number of blobs
+ * present in the starting segmentation.  Each of the seams created
+ * by this routine have location information only.
+ */
+void start_seam_list(TWERD* word, GenericVector<SEAM*>* seam_array) {
+  seam_array->truncate(0);
+  TPOINT location;
 
-  edgept = pt1;
-  do {
-    edgept->Reveal();
-    edgept = edgept->next;
-  }
-  while (!exact_point (edgept, pt2) && edgept != pt1);
-  if (edgept == pt1) {
-    /*              tprintf(""Hid entire outline at (%d,%d)!!\n"",
-       edgept->pos.x,edgept->pos.y);                                */
-  }
-  edgept = pt2;
-  do {
-    edgept->Reveal();
-    edgept = edgept->next;
-  }
-  while (!exact_point (edgept, pt1) && edgept != pt2);
-  if (edgept == pt2) {
-    /*              tprintf(""Hid entire outline at (%d,%d)!!\n"",
-       edgept->pos.x,edgept->pos.y);                                */
+  for (int b = 1; b < word->NumBlobs(); ++b) {
+    TBOX bbox = word->blobs[b - 1]->bounding_box();
+    TBOX nbox = word->blobs[b]->bounding_box();
+    location.x = (bbox.right() + nbox.left()) / 2;
+    location.y = (bbox.bottom() + bbox.top() + nbox.bottom() + nbox.top()) / 4;
+    seam_array->push_back(new SEAM(0.0f, location));
   }
 }
diff --git a/ccstruct/seam.h b/ccstruct/seam.h
index 23b7bc71..9ae63148 100644
--- a/ccstruct/seam.h
+++ b/ccstruct/seam.h
@@ -37,94 +37,162 @@
 typedef float PRIORITY;          /*  PRIORITY  */
 
-struct SEAM {
-  // Constructor that was formerly new_seam.
-  SEAM(PRIORITY priority0, const TPOINT& location0,
-       SPLIT *splita, SPLIT *splitb, SPLIT *splitc)
-  : priority(priority0), widthp(0), widthn(0), location(location0),
-    split1(splita), split2(splitb), split3(splitc) {}
-  // Copy constructor that was formerly clone_seam.
-  SEAM(const SEAM& src)
-  : priority(src.priority), widthp(src.widthp), widthn(src.widthn),
-    location(src.location) {
-    clone_split(split1, src.split1);
-    clone_split(split2, src.split2);
-    clone_split(split3, src.split3);
+class SEAM {
+ public:
+  // A seam with no splits
+  SEAM(float priority, const TPOINT& location)
+      : priority_(priority),
+        location_(location),
+        widthp_(0),
+        widthn_(0),
+        num_splits_(0) {}
+  // A seam with a single split point.
+  SEAM(float priority, const TPOINT& location, const SPLIT& split)
+      : priority_(priority),
+        location_(location),
+        widthp_(0),
+        widthn_(0),
+        num_splits_(1) {
+    splits_[0] = split;
   }
-  // Destructor was delete_seam.
-  ~SEAM() {
-    if (split1)
-      delete_split(split1);
-    if (split2)
-      delete_split(split2);
-    if (split3)
-      delete_split(split3);
+  // Default copy constructor, operator= and destructor are OK!
+
+  // Accessors.
+  float priority() const { return priority_; }
+  void set_priority(float priority) { priority_ = priority; }
+  bool HasAnySplits() const { return num_splits_ > 0; }
+
+  // Returns the bounding box of all the points in the seam.
+  TBOX bounding_box() const;
+
+  // Returns true if other can be combined into *this.
+  bool CombineableWith(const SEAM& other, int max_x_dist,
+                       float max_total_priority) const;
+  // Combines other into *this. Only works if CombinableWith returned true.
+  void CombineWith(const SEAM& other);
+
+  // Returns true if the given blob contains all splits of *this SEAM.
+  bool ContainedByBlob(const TBLOB& blob) const {
+    for (int s = 0; s < num_splits_; ++s) {
+      if (!splits_[s].ContainedByBlob(blob)) return false;
+    }
+    return true;
   }
 
-  PRIORITY priority;
-  inT8 widthp;
-  inT8 widthn;
-  TPOINT location;
-  SPLIT *split1;
-  SPLIT *split2;
-  SPLIT *split3;
-};
+  // Returns true if the given EDGEPT is used by this SEAM, checking only
+  // the EDGEPT pointer, not the coordinates.
+  bool UsesPoint(const EDGEPT* point) const {
+    for (int s = 0; s < num_splits_; ++s) {
+      if (splits_[s].UsesPoint(point)) return true;
+    }
+    return false;
+  }
+  // Returns true if *this and other share any common point, by coordinates.
+  bool SharesPosition(const SEAM& other) const {
+    for (int s = 0; s < num_splits_; ++s) {
+      for (int t = 0; t < other.num_splits_; ++t)
+        if (splits_[s].SharesPosition(other.splits_[t])) return true;
+    }
+    return false;
+  }
+  // Returns true if *this and other have any vertically overlapping splits.
+  bool OverlappingSplits(const SEAM& other) const {
+    for (int s = 0; s < num_splits_; ++s) {
+      TBOX split1_box = splits_[s].bounding_box();
+      for (int t = 0; t < other.num_splits_; ++t) {
+        TBOX split2_box = other.splits_[t].bounding_box();
+        if (split1_box.y_overlap(split2_box)) return true;
+      }
+    }
+    return false;
+  }
 
-/**
- * exact_point
- *
- * Return TRUE if the point positions are the exactly the same. The
- * parameters must be of type (EDGEPT*).
- */
+  // Marks the edgepts used by the seam so the segments made by the cut
+  // never get split further by another seam in the future.
+  void Finalize() {
+    for (int s = 0; s < num_splits_; ++s) {
+      splits_[s].point1->MarkChop();
+      splits_[s].point2->MarkChop();
+    }
+  }
+
+  // Returns true if the splits in *this SEAM appear OK in the sense that they
+  // do not cross any outlines and do not chop off any ridiculously small
+  // pieces.
+  bool IsHealthy(const TBLOB& blob, int min_points, int min_area) const;
+
+  // Computes the widthp_/widthn_ range for all existing SEAMs and for *this
+  // seam, which is about to be inserted at insert_index. Returns false if
+  // any of the computations fails, as this indicates an invalid chop.
+  // widthn_/widthp_ are only changed if modify is true.
+  bool PrepareToInsertSeam(const GenericVector<SEAM*>& seams,
+                           const GenericVector<TBLOB*>& blobs, int insert_index,
+                           bool modify);
+  // Computes the widthp_/widthn_ range. Returns false if not all the splits
+  // are accounted for. widthn_/widthp_ are only changed if modify is true.
+  bool FindBlobWidth(const GenericVector<TBLOB*>& blobs, int index,
+                     bool modify);
+
+  // Splits this blob into two blobs by applying the splits included in
+  // *this SEAM
+  void ApplySeam(bool italic_blob, TBLOB* blob, TBLOB* other_blob) const;
+  // Undoes ApplySeam by removing the seam between these two blobs.
+  // Produces one blob as a result, and deletes other_blob.
+  void UndoSeam(TBLOB* blob, TBLOB* other_blob) const;
+
+  // Prints everything in *this SEAM.
+  void Print(const char* label) const;
+  // Prints a collection of SEAMs.
+  static void PrintSeams(const char* label, const GenericVector<SEAM*>& seams);
+#ifndef GRAPHICS_DISABLED
+  // Draws the seam in the given window.
+  void Mark(ScrollView* window) const;
+#endif
 
-#define exact_point(p1,p2)                    \
-        (! ((p1->pos.x - p2->pos.x) || (p1->pos.y - p2->pos.y)))
+  // Break up the blobs in this chain so that they are all independent.
+  // This operation should undo the affect of join_pieces.
+  static void BreakPieces(const GenericVector<SEAM*>& seams,
+                          const GenericVector<TBLOB*>& blobs, int first,
+                          int last);
+  // Join a group of base level pieces into a single blob that can then
+  // be classified.
+  static void JoinPieces(const GenericVector<SEAM*>& seams,
+                         const GenericVector<TBLOB*>& blobs, int first,
+                         int last);
+
+  // Hides the seam so the outlines appear not to be cut by it.
+  void Hide() const;
+  // Undoes hide, so the outlines are cut by the seam.
+  void Reveal() const;
+
+  // Computes and returns, but does not set, the full priority of *this SEAM.
+  // The arguments here are config parameters defined in Wordrec. Add chop_
+  // to the beginning of the name.
+  float FullPriority(int xmin, int xmax, double overlap_knob,
+                     int centered_maxwidth, double center_knob,
+                     double width_change_knob) const;
+
+ private:
+  // Maximum number of splits that a SEAM can hold.
+  static const int kMaxNumSplits = 3;
+  // Priority of this split. Lower is better.
+  float priority_;
+  // Position of the middle of the seam.
+  TPOINT location_;
+  // A range such that all splits in *this SEAM are contained within blobs in
+  // the range [index - widthn_,index + widthp_] where index is the index of
+  // this SEAM in the seams vector.
+  inT8 widthp_;
+  inT8 widthn_;
+  // Number of splits_ that are used.
+  inT8 num_splits_;
+  // Set of pairs of points that are the ends of each split in the SEAM.
+  SPLIT splits_[kMaxNumSplits];
+};
 
 /*----------------------------------------------------------------------
               F u n c t i o n s
 ----------------------------------------------------------------------*/
-bool point_in_split(SPLIT *split, EDGEPT *point1, EDGEPT *point2);
-
-bool point_in_seam(const SEAM *seam, SPLIT *split);
-
-bool point_used_by_split(SPLIT *split, EDGEPT *point);
-
-bool point_used_by_seam(SEAM *seam, EDGEPT *point);
-
-void combine_seams(SEAM *dest_seam, SEAM *source_seam);
-
-void start_seam_list(TWERD *word, GenericVector<SEAM*>* seam_array);
-
-bool test_insert_seam(const GenericVector<SEAM*>& seam_array,
-                      TWERD *word, int index);
-
-void insert_seam(const TWERD *word, int index, SEAM *seam,
-                 GenericVector<SEAM*>* seam_array);
-
-int account_splits(const SEAM *seam, const TWERD *word, int blob_index,
-                   int blob_direction);
-
-bool find_split_in_blob(SPLIT *split, TBLOB *blob);
-
-SEAM *join_two_seams(const SEAM *seam1, const SEAM *seam2);
-
-void print_seam(const char *label, SEAM *seam);
-
-void print_seams(const char *label, const GenericVector<SEAM*>& seams);
-
-int shared_split_points(const SEAM *seam1, const SEAM *seam2);
-
-void break_pieces(const GenericVector<SEAM*>& seams,
-                  int first, int last, TWERD *word);
-
-void join_pieces(const GenericVector<SEAM*>& seams,
-                 int first, int last, TWERD *word);
-
-void hide_seam(SEAM *seam);
-
-void hide_edge_pair(EDGEPT *pt1, EDGEPT *pt2);
-
-void reveal_seam(SEAM *seam);
 
-void reveal_edge_pair(EDGEPT *pt1, EDGEPT *pt2);
+void start_seam_list(TWERD* word, GenericVector<SEAM*>* seam_array);
 
 #endif
diff --git a/ccstruct/split.cpp b/ccstruct/split.cpp
index a2e974ef..24650d4f 100644
--- a/ccstruct/split.cpp
+++ b/ccstruct/split.cpp
@@ -37,21 +37,101 @@
               V a r i a b l e s
 ----------------------------------------------------------------------*/
+// Limit on the amount of penalty for the chop being off-center.
+const int kCenterGradeCap = 25;
+// Ridiculously large priority for splits that are no use.
+const double kBadPriority = 999.0;
+
 BOOL_VAR(wordrec_display_splits, 0, ""Display splits"");
 
-/*----------------------------------------------------------------------
-              F u n c t i o n s
-----------------------------------------------------------------------*/
+// Returns the bounding box of all the points in the split.
+TBOX SPLIT::bounding_box() const {
+  return TBOX(
+      MIN(point1->pos.x, point2->pos.x), MIN(point1->pos.y, point2->pos.y),
+      MAX(point1->pos.x, point2->pos.x), MAX(point1->pos.y, point2->pos.y));
+}
 
-/**********************************************************************
- * delete_split
- *
- * Remove this split from existence.
- **********************************************************************/
-void delete_split(SPLIT *split) { 
-  if (split) {
-    delete split;
+// Hides the SPLIT so the outlines appear not to be cut by it.
+void SPLIT::Hide() const {
+  EDGEPT* edgept = point1;
+  do {
+    edgept->Hide();
+    edgept = edgept->next;
+  } while (!edgept->EqualPos(*point2) && edgept != point1);
+  edgept = point2;
+  do {
+    edgept->Hide();
+    edgept = edgept->next;
+  } while (!edgept->EqualPos(*point1) && edgept != point2);
+}
+
+// Undoes hide, so the outlines are cut by the SPLIT.
+void SPLIT::Reveal() const {
+  EDGEPT* edgept = point1;
+  do {
+    edgept->Reveal();
+    edgept = edgept->next;
+  } while (!edgept->EqualPos(*point2) && edgept != point1);
+  edgept = point2;
+  do {
+    edgept->Reveal();
+    edgept = edgept->next;
+  } while (!edgept->EqualPos(*point1) && edgept != point2);
+}
+
+// Compute a split priority based on the bounding boxes of the parts.
+// The arguments here are config parameters defined in Wordrec. Add chop_
+// to the beginning of the name.
+float SPLIT::FullPriority(int xmin, int xmax, double overlap_knob,
+                          int centered_maxwidth, double center_knob,
+                          double width_change_knob) const {
+  TBOX box1 = Box12();
+  TBOX box2 = Box21();
+  int min_left = MIN(box1.left(), box2.left());
+  int max_right = MAX(box1.right(), box2.right());
+  if (xmin < min_left && xmax > max_right) return kBadPriority;
+
+  float grade = 0.0f;
+  // grade_overlap.
+  int width1 = box1.width();
+  int width2 = box2.width();
+  int min_width = MIN(width1, width2);
+  int overlap = -box1.x_gap(box2);
+  if (overlap == min_width) {
+    grade += 100.0f;  // Total overlap.
+  } else {
+    if (2 * overlap > min_width) overlap += 2 * overlap - min_width;
+    if (overlap > 0) grade += overlap_knob * overlap;
+  }
+  // grade_center_of_blob.
+  if (width1 <= centered_maxwidth || width2 <= centered_maxwidth) {
+    grade += MIN(kCenterGradeCap, center_knob * abs(width1 - width2));
   }
+  // grade_width_change.
+  float width_change_grade = 20 - (max_right - min_left - MAX(width1, width2));
+  if (width_change_grade > 0.0f)
+    grade += width_change_grade * width_change_knob;
+  return grade;
+}
+
+// Returns true if *this SPLIT appears OK in the sense that it does not cross
+// any outlines and does not chop off any ridiculously small pieces.
+bool SPLIT::IsHealthy(const TBLOB& blob, int min_points, int min_area) const {
+  return !IsLittleChunk(min_points, min_area) &&
+         !blob.SegmentCrossesOutline(point1->pos, point2->pos);
 }
 
+// Returns true if the split generates a small chunk in terms of either area
+// or number of points.
+bool SPLIT::IsLittleChunk(int min_points, int min_area) const {
+  if (point1->ShortNonCircularSegment(min_points, point2) &&
+      point1->SegmentArea(point2) < min_area) {
+    return true;
+  }
+  if (point2->ShortNonCircularSegment(min_points, point1) &&
+      point2->SegmentArea(point1) < min_area) {
+    return true;
+  }
+  return false;
+}
 
 /**********************************************************************
@@ -136,101 +216,112 @@ void remove_edgept(EDGEPT *point) {
 
 /**********************************************************************
- * new_split
+ * Print
  *
- * Create a new split record and initialize it.  Put it on the display
- * list.
+ * Shows the coordinates of both points in a split.
  **********************************************************************/
-SPLIT *new_split(EDGEPT *point1, EDGEPT *point2) { 
-  SPLIT *s = new SPLIT;
-  s->point1 = point1;
-  s->point2 = point2;
-  return (s);
+void SPLIT::Print() const {
+  if (this != NULL) {
+    tprintf(""(%d,%d)--(%d,%d)"", point1->pos.x, point1->pos.y, point2->pos.x,
+            point2->pos.y);
+  }
 }
 
-
-/**********************************************************************
- * print_split
- *
- * Print a list of splits.  Show the coordinates of both points in
- * each split.
- **********************************************************************/
-void print_split(SPLIT *split) { 
-  if (split) {
-    tprintf(""(%d,%d)--(%d,%d)"",
-            split->point1->pos.x, split->point1->pos.y,
-            split->point2->pos.x, split->point2->pos.y);
-  }
+#ifndef GRAPHICS_DISABLED
+// Draws the split in the given window.
+void SPLIT::Mark(ScrollView* window) const {
+  window->Pen(ScrollView::GREEN);
+  window->Line(point1->pos.x, point1->pos.y, point2->pos.x, point2->pos.y);
+  window->UpdateWindow();
 }
+#endif
 
+// Creates two outlines out of one by splitting the original one in half.
+// Inserts the resulting outlines into the given list.
+void SPLIT::SplitOutlineList(TESSLINE* outlines) const {
+  SplitOutline();
+  while (outlines->next != NULL) outlines = outlines->next;
 
-/**********************************************************************
- * split_outline
- *
- * Split between these two edge points.
- **********************************************************************/
-void split_outline(EDGEPT *join_point1, EDGEPT *join_point2) { 
-  assert(join_point1 != join_point2);
+  outlines->next = new TESSLINE;
+  outlines->next->loop = point1;
+  outlines->next->ComputeBoundingBox();
+
+  outlines = outlines->next;
+
+  outlines->next = new TESSLINE;
+  outlines->next->loop = point2;
+  outlines->next->ComputeBoundingBox();
 
-  EDGEPT* temp2 = join_point2->next;
-  EDGEPT* temp1 = join_point1->next;
+  outlines->next->next = NULL;
+}
+
+// Makes a split between these two edge points, but does not affect the
+// outlines to which they belong.
+void SPLIT::SplitOutline() const {
+  EDGEPT* temp2 = point2->next;
+  EDGEPT* temp1 = point1->next;
   /* Create two new points */
-  EDGEPT* new_point1 = make_edgept(join_point1->pos.x, join_point1->pos.y,
-                                   temp1, join_point2);
-  EDGEPT* new_point2 = make_edgept(join_point2->pos.x, join_point2->pos.y,
-                                   temp2, join_point1);
-  // Join_point1 and 2 are now cross-over points, so they must have NULL
+  EDGEPT* new_point1 = make_edgept(point1->pos.x, point1->pos.y, temp1, point2);
+  EDGEPT* new_point2 = make_edgept(point2->pos.x, point2->pos.y, temp2, point1);
+  // point1 and 2 are now cross-over points, so they must have NULL
   // src_outlines and give their src_outline information their new
   // replacements.
-  new_point1->src_outline = join_point1->src_outline;
-  new_point1->start_step = join_point1->start_step;
-  new_point1->step_count = join_point1->step_count;
-  new_point2->src_outline = join_point2->src_outline;
-  new_point2->start_step = join_point2->start_step;
-  new_point2->step_count = join_point2->step_count;
-  join_point1->src_outline = NULL;
-  join_point1->start_step = 0;
-  join_point1->step_count = 0;
-  join_point2->src_outline = NULL;
-  join_point2->start_step = 0;
-  join_point2->step_count = 0;
-  join_point1->MarkChop();
-  join_point2->MarkChop();
+  new_point1->src_outline = point1->src_outline;
+  new_point1->start_step = point1->start_step;
+  new_point1->step_count = point1->step_count;
+  new_point2->src_outline = point2->src_outline;
+  new_point2->start_step = point2->start_step;
+  new_point2->step_count = point2->step_count;
+  point1->src_outline = NULL;
+  point1->start_step = 0;
+  point1->step_count = 0;
+  point2->src_outline = NULL;
+  point2->start_step = 0;
+  point2->step_count = 0;
 }
 
+// Undoes the effect of SplitOutlineList, correcting the outlines for undoing
+// the split, but possibly leaving some duplicate outlines.
+void SPLIT::UnsplitOutlineList(TBLOB* blob) const {
+  /* Modify edge points */
+  UnsplitOutlines();
 
-/**********************************************************************
- * unsplit_outlines
- *
- * Remove the split that was put between these two points.
- **********************************************************************/
-void unsplit_outlines(EDGEPT *p1, EDGEPT *p2) { 
-  EDGEPT *tmp1 = p1->next;
-  EDGEPT *tmp2 = p2->next;
-
-  assert (p1 != p2);
-
-  tmp1->next->prev = p2;
-  tmp2->next->prev = p1;
-
-  // tmp2 is coincident with p1. p1 takes tmp2's place as tmp2 is deleted.
-  p1->next = tmp2->next;
-  p1->src_outline = tmp2->src_outline;
-  p1->start_step = tmp2->start_step;
-  p1->step_count = tmp2->step_count;
-  // Likewise p2 takes tmp1's place.
-  p2->next = tmp1->next;
-  p2->src_outline = tmp1->src_outline;
-  p2->start_step = tmp1->start_step;
-  p2->step_count = tmp1->step_count;
-  p1->UnmarkChop();
-  p2->UnmarkChop();
+  TESSLINE* outline1 = new TESSLINE;
+  outline1->next = blob->outlines;
+  blob->outlines = outline1;
+  outline1->loop = point1;
+
+  TESSLINE* outline2 = new TESSLINE;
+  outline2->next = blob->outlines;
+  blob->outlines = outline2;
+  outline2->loop = point2;
+}
+
+// Removes the split that was put between these two points.
+void SPLIT::UnsplitOutlines() const {
+  EDGEPT* tmp1 = point1->next;
+  EDGEPT* tmp2 = point2->next;
+
+  tmp1->next->prev = point2;
+  tmp2->next->prev = point1;
+
+  // tmp2 is coincident with point1. point1 takes tmp2's place as tmp2 is
+  // deleted.
+  point1->next = tmp2->next;
+  point1->src_outline = tmp2->src_outline;
+  point1->start_step = tmp2->start_step;
+  point1->step_count = tmp2->step_count;
+  // Likewise point2 takes tmp1's place.
+  point2->next = tmp1->next;
+  point2->src_outline = tmp1->src_outline;
+  point2->start_step = tmp1->start_step;
+  point2->step_count = tmp1->step_count;
 
   delete tmp1;
   delete tmp2;
 
-  p1->vec.x = p1->next->pos.x - p1->pos.x;
-  p1->vec.y = p1->next->pos.y - p1->pos.y;
+  point1->vec.x = point1->next->pos.x - point1->pos.x;
+  point1->vec.y = point1->next->pos.y - point1->pos.y;
 
-  p2->vec.x = p2->next->pos.x - p2->pos.x;
-  p2->vec.y = p2->next->pos.y - p2->pos.y;
+  point2->vec.x = point2->next->pos.x - point2->pos.x;
+  point2->vec.y = point2->next->pos.y - point2->pos.y;
 }
diff --git a/ccstruct/split.h b/ccstruct/split.h
index 7291b4cf..26424748 100644
--- a/ccstruct/split.h
+++ b/ccstruct/split.h
@@ -30,16 +30,78 @@
 ----------------------------------------------------------------------*/
 #include ""blobs.h""
-#include ""oldlist.h""
+#include ""scrollview.h""
 
 /*----------------------------------------------------------------------
               T y p e s
 ----------------------------------------------------------------------*/
-typedef struct split_record
-{                                /*  SPLIT  */
+struct SPLIT {
+  SPLIT() : point1(NULL), point2(NULL) {}
+  SPLIT(EDGEPT* pt1, EDGEPT* pt2) : point1(pt1), point2(pt2) {}
+
+  // Returns the bounding box of all the points in the split.
+  TBOX bounding_box() const;
+  // Returns the bounding box of the outline from point1 to point2.
+  TBOX Box12() const { return point1->SegmentBox(point2); }
+  // Returns the bounding box of the outline from point1 to point1.
+  TBOX Box21() const { return point2->SegmentBox(point1); }
+  // Returns the bounding box of the out
+
+  // Hides the SPLIT so the outlines appear not to be cut by it.
+  void Hide() const;
+  // Undoes hide, so the outlines are cut by the SPLIT.
+  void Reveal() const;
+
+  // Returns true if the given EDGEPT is used by this SPLIT, checking only
+  // the EDGEPT pointer, not the coordinates.
+  bool UsesPoint(const EDGEPT* point) const {
+    return point1 == point || point2 == point;
+  }
+  // Returns true if the other SPLIT has any position shared with *this.
+  bool SharesPosition(const SPLIT& other) const {
+    return point1->EqualPos(*other.point1) || point1->EqualPos(*other.point2) ||
+           point2->EqualPos(*other.point1) || point2->EqualPos(*other.point2);
+  }
+  // Returns true if both points are contained within the blob.
+  bool ContainedByBlob(const TBLOB& blob) const {
+    return blob.Contains(point1->pos) && blob.Contains(point2->pos);
+  }
+  // Returns true if both points are contained within the outline.
+  bool ContainedByOutline(const TESSLINE& outline) const {
+    return outline.Contains(point1->pos) && outline.Contains(point2->pos);
+  }
+  // Compute a split priority based on the bounding boxes of the parts.
+  // The arguments here are config parameters defined in Wordrec. Add chop_
+  // to the beginning of the name.
+  float FullPriority(int xmin, int xmax, double overlap_knob,
+                     int centered_maxwidth, double center_knob,
+                     double width_change_knob) const;
+  // Returns true if *this SPLIT appears OK in the sense that it does not cross
+  // any outlines and does not chop off any ridiculously small pieces.
+  bool IsHealthy(const TBLOB& blob, int min_points, int min_area) const;
+  // Returns true if the split generates a small chunk in terms of either area
+  // or number of points.
+  bool IsLittleChunk(int min_points, int min_area) const;
+
+  void Print() const;
+#ifndef GRAPHICS_DISABLED
+  // Draws the split in the given window.
+  void Mark(ScrollView* window) const;
+#endif
+
+  // Creates two outlines out of one by splitting the original one in half.
+  // Inserts the resulting outlines into the given list.
+  void SplitOutlineList(TESSLINE* outlines) const;
+  // Makes a split between these two edge points, but does not affect the
+  // outlines to which they belong.
+  void SplitOutline() const;
+  // Undoes the effect of SplitOutlineList, correcting the outlines for undoing
+  // the split, but possibly leaving some duplicate outlines.
+  void UnsplitOutlineList(TBLOB* blob) const;
+  // Removes the split that was put between these two points.
+  void UnsplitOutlines() const;
+
   EDGEPT *point1;
   EDGEPT *point2;
-} SPLIT;
-
-typedef LIST SPLITS;             /*  SPLITS  */
+};
 
 /*----------------------------------------------------------------------
@@ -49,37 +111,10 @@ typedef LIST SPLITS;             /*  SPLITS  */
 extern BOOL_VAR_H(wordrec_display_splits, 0, ""Display splits"");
 
-/*----------------------------------------------------------------------
-              M a c r o s
-----------------------------------------------------------------------*/
-/**********************************************************************
- * clone_split
- *
- * Create a new split record and set the contents equal to the contents
- * of this record.
- **********************************************************************/
-
-#define clone_split(dest,source)                               \
-if (source)                                                  \
-	(dest) = new_split ((source)->point1, (source)->point2);  \
-else                                                         \
-	(dest) = (SPLIT*) NULL                                    \
-
-
 /*----------------------------------------------------------------------
               F u n c t i o n s
 ----------------------------------------------------------------------*/
-void delete_split(SPLIT *split);
-
 EDGEPT *make_edgept(int x, int y, EDGEPT *next, EDGEPT *prev);
 
 void remove_edgept(EDGEPT *point);
 
-SPLIT *new_split(EDGEPT *point1, EDGEPT *point2);
-
-void print_split(SPLIT *split);
-
-void split_outline(EDGEPT *join_point1, EDGEPT *join_point2);
-
-void unsplit_outlines(EDGEPT *p1, EDGEPT *p2);
-
 #endif
diff --git a/ccstruct/vecfuncs.cpp b/ccstruct/vecfuncs.cpp
index 3f825173..8357c9aa 100644
--- a/ccstruct/vecfuncs.cpp
+++ b/ccstruct/vecfuncs.cpp
@@ -31,4 +31,5 @@
 ----------------------------------------------------------------------*/
 #include ""vecfuncs.h""
+#include ""blobs.h""
 
 /*----------------------------------------------------------------------
diff --git a/ccstruct/vecfuncs.h b/ccstruct/vecfuncs.h
index 91bbb088..55cf3108 100644
--- a/ccstruct/vecfuncs.h
+++ b/ccstruct/vecfuncs.h
@@ -27,5 +27,4 @@
 
 #include <math.h>
-#include ""blobs.h""
 
 struct EDGEPT;
diff --git a/classify/adaptmatch.cpp b/classify/adaptmatch.cpp
index 0eaf1440..7bbc8471 100644
--- a/classify/adaptmatch.cpp
+++ b/classify/adaptmatch.cpp
@@ -360,6 +360,6 @@ void Classify::LearnPieces(const char* filename, int start, int length,
 
   if (length > 1) {
-    join_pieces(word->seam_array, start, start + length - 1,
-                word->chopped_word);
+    SEAM::JoinPieces(word->seam_array, word->chopped_word->blobs, start,
+                     start + length - 1);
   }
   TBLOB* blob = word->chopped_word->blobs[start];
@@ -414,5 +414,6 @@ void Classify::LearnPieces(const char* filename, int start, int length,
   }
 
-  break_pieces(word->seam_array, start, start + length - 1, word->chopped_word);
+  SEAM::BreakPieces(word->seam_array, word->chopped_word->blobs, start,
+                    start + length - 1);
 }  // LearnPieces.
 
diff --git a/wordrec/chop.cpp b/wordrec/chop.cpp
index 9ae61bb9..c7310052 100644
--- a/wordrec/chop.cpp
+++ b/wordrec/chop.cpp
@@ -30,5 +30,4 @@
 #include ""chop.h""
 #include ""outlines.h""
-#include ""olutil.h""
 #include ""callcpp.h""
 #include ""plotedges.h""
@@ -75,4 +74,9 @@ void Wordrec::add_point_to_list(PointHeap* point_heap, EDGEPT *point) {
 }
 
+// Returns true if the edgept supplied as input is an inside angle.  This
+// is determined by the angular change of the vectors from point to point.
+bool Wordrec::is_inside_angle(EDGEPT *pt) {
+  return angle_change(pt->prev, pt, pt->next) < chop_inside_angle;
+}
 
 /**
@@ -112,63 +116,4 @@ int Wordrec::angle_change(EDGEPT *point1, EDGEPT *point2, EDGEPT *point3) {
 }
 
-/**
- * @name is_little_chunk
- *
- * Return TRUE if one of the pieces resulting from this split would
- * less than some number of edge points.
- */
-int Wordrec::is_little_chunk(EDGEPT *point1, EDGEPT *point2) {
-  EDGEPT *p = point1;            /* Iterator */
-  int counter = 0;
-
-  do {
-                                 /* Go from P1 to P2 */
-    if (is_same_edgept (point2, p)) {
-      if (is_small_area (point1, point2))
-        return (TRUE);
-      else
-        break;
-    }
-    p = p->next;
-  }
-  while ((p != point1) && (counter++ < chop_min_outline_points));
-  /* Go from P2 to P1 */
-  p = point2;
-  counter = 0;
-  do {
-    if (is_same_edgept (point1, p)) {
-      return (is_small_area (point2, point1));
-    }
-    p = p->next;
-  }
-  while ((p != point2) && (counter++ < chop_min_outline_points));
-
-  return (FALSE);
-}
-
-
-/**
- * @name is_small_area
- *
- * Test the area defined by a split accross this outline.
- */
-int Wordrec::is_small_area(EDGEPT *point1, EDGEPT *point2) {
-  EDGEPT *p = point1->next;      /* Iterator */
-  int area = 0;
-  TPOINT origin;
-
-  do {
-                                 /* Go from P1 to P2 */
-    origin.x = p->pos.x - point1->pos.x;
-    origin.y = p->pos.y - point1->pos.y;
-    area += CROSS (origin, p->vec);
-    p = p->next;
-  }
-  while (!is_same_edgept (point2, p));
-
-  return (area < chop_min_outline_area);
-}
-
-
 /**
  * @name pick_close_point
diff --git a/wordrec/chopper.cpp b/wordrec/chopper.cpp
index cf39ceb6..c1a57fcd 100644
--- a/wordrec/chopper.cpp
+++ b/wordrec/chopper.cpp
@@ -40,5 +40,4 @@
 #include ""freelist.h""
 #include ""globals.h""
-#include ""makechop.h""
 #include ""render.h""
 #include ""pageres.h""
@@ -136,16 +135,12 @@ static SEAM* CheckSeam(int debug_level, inT32 blob_number, TWERD* word,
                        TBLOB* blob, TBLOB* other_blob,
                        const GenericVector<SEAM*>& seams, SEAM* seam) {
-  if (seam == NULL ||
-      blob->outlines == NULL ||
-      other_blob->outlines == NULL ||
-      total_containment(blob, other_blob) ||
-      check_blob(other_blob) ||
-      !(check_seam_order(blob, seam) &&
-          check_seam_order(other_blob, seam)) ||
+  if (seam == NULL || blob->outlines == NULL || other_blob->outlines == NULL ||
+      total_containment(blob, other_blob) || check_blob(other_blob) ||
+      !seam->ContainedByBlob(*blob) || !seam->ContainedByBlob(*other_blob) ||
       any_shared_split_points(seams, seam) ||
-      !test_insert_seam(seams, word, blob_number)) {
+      !seam->PrepareToInsertSeam(seams, word->blobs, blob_number, false)) {
     word->blobs.remove(blob_number + 1);
     if (seam) {
-      undo_seam(blob, other_blob, seam);
+      seam->UndoSeam(blob, other_blob);
       delete seam;
       seam = NULL;
@@ -186,5 +181,5 @@ SEAM *Wordrec::attempt_blob_chop(TWERD *word, TBLOB *blob, inT32 blob_number,
     TPOINT location;
     if (divisible_blob(blob, italic_blob, &location)) {
-      seam = new SEAM(0.0f, location, NULL, NULL, NULL);
+      seam = new SEAM(0.0f, location);
     }
   }
@@ -193,10 +188,10 @@ SEAM *Wordrec::attempt_blob_chop(TWERD *word, TBLOB *blob, inT32 blob_number,
   if (chop_debug) {
     if (seam != NULL)
-      print_seam(""Good seam picked="", seam);
+      seam->Print(""Good seam picked="");
     else
       tprintf(""\n** no seam picked *** \n"");
   }
   if (seam) {
-    apply_seam(blob, other_blob, italic_blob, seam);
+    seam->ApplySeam(italic_blob, blob, other_blob);
   }
 
@@ -212,6 +207,6 @@ SEAM *Wordrec::attempt_blob_chop(TWERD *word, TBLOB *blob, inT32 blob_number,
         other_blob = TBLOB::ShallowCopy(*blob);       /* Make new blob */
         word->blobs.insert(other_blob, blob_number + 1);
-        seam = new SEAM(0.0f, location, NULL, NULL, NULL);
-        apply_seam(blob, other_blob, italic_blob, seam);
+        seam = new SEAM(0.0f, location);
+        seam->ApplySeam(italic_blob, blob, other_blob);
         seam = CheckSeam(chop_debug, blob_number, word, blob, other_blob,
                          seams, seam);
@@ -219,4 +214,8 @@ SEAM *Wordrec::attempt_blob_chop(TWERD *word, TBLOB *blob, inT32 blob_number,
     }
   }
+  if (seam != NULL) {
+    // Make sure this seam doesn't get chopped again.
+    seam->Finalize();
+  }
   return seam;
 }
@@ -287,6 +286,5 @@ int any_shared_split_points(const GenericVector<SEAM*>& seams, SEAM *seam) {
   length = seams.size();
   for (index = 0; index < length; index++)
-    if (shared_split_points(seams[index], seam))
-      return TRUE;
+    if (seam->SharesPosition(*seams[index])) return TRUE;
   return FALSE;
 }
@@ -385,48 +383,4 @@ SEAM* Wordrec::chop_one_blob(const GenericVector<TBOX>& boxes,
   }
 }
-}  // namespace tesseract
-
-/**
- * @name check_seam_order
- *
- * Make sure that each of the splits in this seam match to outlines
- * in this blob.  If any of the splits could not correspond to this
- * blob then there is a problem (and FALSE should be returned to the
- * caller).
- */
-inT16 check_seam_order(TBLOB *blob, SEAM *seam) {
-  TESSLINE *outline;
-  inT8 found_em[3];
-
-  if (seam->split1 == NULL || blob == NULL)
-    return (TRUE);
-
-  found_em[0] = found_em[1] = found_em[2] = FALSE;
-
-  for (outline = blob->outlines; outline; outline = outline->next) {
-    if (!found_em[0] &&
-      ((seam->split1 == NULL) ||
-    is_split_outline (outline, seam->split1))) {
-      found_em[0] = TRUE;
-    }
-    if (!found_em[1] &&
-      ((seam->split2 == NULL) ||
-    is_split_outline (outline, seam->split2))) {
-      found_em[1] = TRUE;
-    }
-    if (!found_em[2] &&
-      ((seam->split3 == NULL) ||
-    is_split_outline (outline, seam->split3))) {
-      found_em[2] = TRUE;
-    }
-  }
-
-  if (!found_em[0] || !found_em[1] || !found_em[2])
-    return (FALSE);
-  else
-    return (TRUE);
-}
-
-namespace tesseract {
 
 /**
diff --git a/wordrec/chopper.h b/wordrec/chopper.h
index 7955a51f..4bfbf653 100644
--- a/wordrec/chopper.h
+++ b/wordrec/chopper.h
@@ -45,6 +45,4 @@ int any_shared_split_points(const GenericVector<SEAM*>& seams, SEAM *seam);
 int check_blob(TBLOB *blob);
 
-inT16 check_seam_order(TBLOB *blob, SEAM *seam);
-
 inT16 total_containment(TBLOB *blob1, TBLOB *blob2);
 #endif
diff --git a/wordrec/findseam.cpp b/wordrec/findseam.cpp
index 786393c5..dd2de6e6 100644
--- a/wordrec/findseam.cpp
+++ b/wordrec/findseam.cpp
@@ -28,5 +28,4 @@
 #include ""findseam.h""
 #include ""gradechop.h""
-#include ""olutil.h""
 #include ""plotedges.h""
 #include ""outlines.h""
@@ -68,5 +67,5 @@ void Wordrec::add_seam_to_queue(float new_priority, SEAM *new_seam,
   if (chop_debug) {
     tprintf(""Pushing new seam with priority %g :"", new_priority);
-    print_seam(""seam: "", new_seam);
+    new_seam->Print(""seam: "");
   }
   if (seams->size() >= MAX_NUM_SEAMS) {
@@ -102,10 +101,7 @@ void Wordrec::add_seam_to_queue(float new_priority, SEAM *new_seam,
  * caller.
  **********************************************************************/
-void Wordrec::choose_best_seam(SeamQueue* seam_queue,
-                               SPLIT *split,
-                               PRIORITY priority,
-                               SEAM **seam_result,
-                               TBLOB *blob,
-                               SeamPile* seam_pile) {
+void Wordrec::choose_best_seam(SeamQueue *seam_queue, const SPLIT *split,
+                               PRIORITY priority, SEAM **seam_result,
+                               TBLOB *blob, SeamPile *seam_pile) {
   SEAM *seam;
   char str[80];
@@ -117,7 +113,6 @@ void Wordrec::choose_best_seam(SeamQueue* seam_queue,
     split_point += split->point2->pos;
     split_point /= 2;
-    seam = new SEAM(my_priority, split_point, split, NULL, NULL);
-    if (chop_debug > 1)
-      print_seam (""Partial priority    "", seam);
+    seam = new SEAM(my_priority, split_point, *split);
+    if (chop_debug > 1) seam->Print(""Partial priority    "");
     add_seam_to_queue(my_priority, seam, seam_queue);
 
@@ -133,17 +128,20 @@ void Wordrec::choose_best_seam(SeamQueue* seam_queue,
     seam = seam_pair.extract_data();
     /* Set full priority */
-    my_priority = seam_priority(seam, bbox.left(), bbox.right());
+    my_priority = seam->FullPriority(bbox.left(), bbox.right(),
+                                     chop_overlap_knob, chop_centered_maxwidth,
+                                     chop_center_knob, chop_width_change_knob);
     if (chop_debug) {
       sprintf (str, ""Full my_priority %0.0f,  "", my_priority);
-      print_seam(str, seam);
+      seam->Print(str);
     }
 
-    if ((*seam_result == NULL || (*seam_result)->priority > my_priority) &&
+    if ((*seam_result == NULL || (*seam_result)->priority() > my_priority) &&
         my_priority < chop_ok_split) {
       /* No crossing */
-      if (constrained_split(seam->split1, blob)) {
+      if (seam->IsHealthy(*blob, chop_min_outline_points,
+                          chop_min_outline_area)) {
         delete *seam_result;
         *seam_result = new SEAM(*seam);
-        (*seam_result)->priority = my_priority;
+        (*seam_result)->set_priority(my_priority);
       } else {
         delete seam;
@@ -199,102 +197,15 @@ void Wordrec::choose_best_seam(SeamQueue* seam_queue,
 void Wordrec::combine_seam(const SeamPile& seam_pile,
                            const SEAM* seam, SeamQueue* seam_queue) {
-  register inT16 dist;
-  inT16 bottom1, top1;
-  inT16 bottom2, top2;
-
-  SEAM *new_one;
-  const SEAM *this_one;
-
-  bottom1 = seam->split1->point1->pos.y;
-  if (seam->split1->point2->pos.y >= bottom1)
-    top1 = seam->split1->point2->pos.y;
-  else {
-    top1 = bottom1;
-    bottom1 = seam->split1->point2->pos.y;
-  }
-  if (seam->split2 != NULL) {
-    bottom2 = seam->split2->point1->pos.y;
-    if (seam->split2->point2->pos.y >= bottom2)
-      top2 = seam->split2->point2->pos.y;
-    else {
-      top2 = bottom2;
-      bottom2 = seam->split2->point2->pos.y;
-    }
-  }
-  else {
-    bottom2 = bottom1;
-    top2 = top1;
-  }
   for (int x = 0; x < seam_pile.size(); ++x) {
-    this_one = seam_pile.get(x).data();
-    dist = seam->location.x - this_one->location.x;
-    if (-SPLIT_CLOSENESS < dist &&
-      dist < SPLIT_CLOSENESS &&
-    seam->priority + this_one->priority < chop_ok_split) {
-      inT16 split1_point1_y = this_one->split1->point1->pos.y;
-      inT16 split1_point2_y = this_one->split1->point2->pos.y;
-      inT16 split2_point1_y = 0;
-      inT16 split2_point2_y = 0;
-      if (this_one->split2) {
-        split2_point1_y = this_one->split2->point1->pos.y;
-        split2_point2_y = this_one->split2->point2->pos.y;
-      }
-      if (
-        /*!tessedit_fix_sideways_chops || */
-        (
-          /* this_one->split1 always exists */
-          (
-            ((split1_point1_y >= top1 && split1_point2_y >= top1) ||
-             (split1_point1_y <= bottom1 && split1_point2_y <= bottom1))
-            &&
-            ((split1_point1_y >= top2 && split1_point2_y >= top2) ||
-             (split1_point1_y <= bottom2 && split1_point2_y <= bottom2))
-          )
-        )
-        &&
-        (
-          this_one->split2 == NULL ||
-          (
-            ((split2_point1_y >= top1 && split2_point2_y >= top1) ||
-             (split2_point1_y <= bottom1 && split2_point2_y <= bottom1))
-            &&
-            ((split2_point1_y >= top2 && split2_point2_y >= top2) ||
-             (split2_point1_y <= bottom2 && split2_point2_y <= bottom2))
-          )
-        )
-      ) {
-        new_one = join_two_seams (seam, this_one);
-        if (new_one != NULL) {
-          if (chop_debug > 1)
-            print_seam (""Combo priority       "", new_one);
-          add_seam_to_queue(new_one->priority, new_one, seam_queue);
-        }
-      }
+    const SEAM *this_one = seam_pile.get(x).data();
+    if (seam->CombineableWith(*this_one, SPLIT_CLOSENESS, chop_ok_split)) {
+      SEAM *new_one = new SEAM(*seam);
+      new_one->CombineWith(*this_one);
+      if (chop_debug > 1) new_one->Print(""Combo priority       "");
+      add_seam_to_queue(new_one->priority(), new_one, seam_queue);
     }
   }
 }
 
-
-/**********************************************************************
- * constrained_split
- *
- * Constrain this split to obey certain rules.  It must not cross any
- * inner outline.  It must not cut off a small chunk of the outline.
- **********************************************************************/
-inT16 Wordrec::constrained_split(SPLIT *split, TBLOB *blob) {
-  TESSLINE *outline;
-
-  if (is_little_chunk (split->point1, split->point2))
-    return (FALSE);
-
-  for (outline = blob->outlines; outline; outline = outline->next) {
-    if (split_bounds_overlap (split, outline) &&
-    crosses_outline (split->point1, split->point2, outline->loop)) {
-      return (FALSE);
-    }
-  }
-  return (TRUE);
-}
-
 /**********************************************************************
  * pick_good_seam
@@ -336,8 +247,7 @@ SEAM *Wordrec::pick_good_seam(TBLOB *blob) {
   if (seam == NULL) {
     choose_best_seam(&seam_queue, NULL, BAD_PRIORITY, &seam, blob, &seam_pile);
-  }
-  else if (seam->priority > chop_good_split) {
-    choose_best_seam(&seam_queue, NULL, seam->priority,
-                     &seam, blob, &seam_pile);
+  } else if (seam->priority() > chop_good_split) {
+    choose_best_seam(&seam_queue, NULL, seam->priority(), &seam, blob,
+                     &seam_pile);
   }
 
@@ -345,5 +255,5 @@ SEAM *Wordrec::pick_good_seam(TBLOB *blob) {
   for (it.mark_cycle_pt(); !it.cycled_list(); it.forward()) {
     EDGEPT *inserted_point = it.data();
-    if (!point_used_by_seam(seam, inserted_point)) {
+    if (seam == NULL || !seam->UsesPoint(inserted_point)) {
       for (outline = blob->outlines; outline; outline = outline->next) {
         if (outline->loop == inserted_point) {
@@ -356,5 +266,5 @@ SEAM *Wordrec::pick_good_seam(TBLOB *blob) {
 
   if (seam) {
-    if (seam->priority > chop_ok_split) {
+    if (seam->priority() > chop_ok_split) {
       delete seam;
       seam = NULL;
@@ -362,10 +272,5 @@ SEAM *Wordrec::pick_good_seam(TBLOB *blob) {
 #ifndef GRAPHICS_DISABLED
     else if (wordrec_display_splits) {
-      if (seam->split1)
-        mark_split (seam->split1);
-      if (seam->split2)
-        mark_split (seam->split2);
-      if (seam->split3)
-        mark_split (seam->split3);
+      seam->Mark(edge_window);
       if (chop_debug > 2) {
         update_edge_window();
@@ -383,40 +288,4 @@ SEAM *Wordrec::pick_good_seam(TBLOB *blob) {
 
 
-/**********************************************************************
- * seam_priority
- *
- * Assign a full priority value to the seam.
- **********************************************************************/
-PRIORITY Wordrec::seam_priority(SEAM *seam, inT16 xmin, inT16 xmax) {
-  PRIORITY priority;
-
-  if (seam->split1 == NULL)
-    priority = 0;
-
-  else if (seam->split2 == NULL) {
-    priority = (seam->priority +
-      full_split_priority (seam->split1, xmin, xmax));
-  }
-
-  else if (seam->split3 == NULL) {
-    split_outline (seam->split2->point1, seam->split2->point2);
-    priority = (seam->priority +
-      full_split_priority (seam->split1, xmin, xmax));
-    unsplit_outlines (seam->split2->point1, seam->split2->point2);
-  }
-
-  else {
-    split_outline (seam->split2->point1, seam->split2->point2);
-    split_outline (seam->split3->point1, seam->split3->point2);
-    priority = (seam->priority +
-      full_split_priority (seam->split1, xmin, xmax));
-    unsplit_outlines (seam->split3->point1, seam->split3->point2);
-    unsplit_outlines (seam->split2->point1, seam->split2->point2);
-  }
-
-  return (priority);
-}
-
-
 /**********************************************************************
  * try_point_pairs
@@ -434,21 +303,18 @@ void Wordrec::try_point_pairs(EDGEPT * points[MAX_NUM_POINTS],
   inT16 x;
   inT16 y;
-  SPLIT *split;
   PRIORITY priority;
 
   for (x = 0; x < num_points; x++) {
     for (y = x + 1; y < num_points; y++) {
-
       if (points[y] &&
-          weighted_edgept_dist(points[x], points[y],
-                               chop_x_y_weight) < chop_split_length &&
-          points[x] != points[y]->next &&
-          points[y] != points[x]->next &&
+          points[x]->WeightedDistance(*points[y], chop_x_y_weight) <
+              chop_split_length &&
+          points[x] != points[y]->next && points[y] != points[x]->next &&
           !is_exterior_point(points[x], points[y]) &&
           !is_exterior_point(points[y], points[x])) {
-        split = new_split (points[x], points[y]);
-        priority = partial_split_priority (split);
+        SPLIT split(points[x], points[y]);
+        priority = partial_split_priority(&split);
 
-        choose_best_seam(seam_queue, split, priority, seam, blob, seam_pile);
+        choose_best_seam(seam_queue, &split, priority, seam, blob, seam_pile);
       }
     }
@@ -475,5 +341,4 @@ void Wordrec::try_vertical_splits(EDGEPT * points[MAX_NUM_POINTS],
                                   TBLOB * blob) {
   EDGEPT *vertical_point = NULL;
-  SPLIT *split;
   inT16 x;
   PRIORITY priority;
@@ -487,14 +352,11 @@ void Wordrec::try_vertical_splits(EDGEPT * points[MAX_NUM_POINTS],
     }
 
-    if (vertical_point &&
-      points[x] != vertical_point->next &&
-      vertical_point != points[x]->next &&
-      weighted_edgept_dist(points[x], vertical_point,
-                           chop_x_y_weight) < chop_split_length) {
-
-      split = new_split (points[x], vertical_point);
-      priority = partial_split_priority (split);
-
-      choose_best_seam(seam_queue, split, priority, seam, blob, seam_pile);
+    if (vertical_point && points[x] != vertical_point->next &&
+        vertical_point != points[x]->next &&
+        points[x]->WeightedDistance(*vertical_point, chop_x_y_weight) <
+            chop_split_length) {
+      SPLIT split(points[x], vertical_point);
+      priority = partial_split_priority(&split);
+      choose_best_seam(seam_queue, &split, priority, seam, blob, seam_pile);
     }
   }
diff --git a/wordrec/gradechop.cpp b/wordrec/gradechop.cpp
index dce35ba5..ace8dfc5 100644
--- a/wordrec/gradechop.cpp
+++ b/wordrec/gradechop.cpp
@@ -28,35 +28,11 @@
 #include ""gradechop.h""
 #include ""wordrec.h""
-#include ""olutil.h""
 #include ""chop.h""
 #include ""ndminx.h""
 #include <math.h>
 
-/*----------------------------------------------------------------------
-              T y p e s
-----------------------------------------------------------------------*/
-#define CENTER_GRADE_CAP 25.0
-
 /*----------------------------------------------------------------------
               M a c r o s
 ----------------------------------------------------------------------*/
-/**********************************************************************
- * find_bounds_loop
- *
- * This is a macro to be used by set_outline_bounds.
- **********************************************************************/
-
-#define find_bounds_loop(point1,point2,x_min,x_max)     \
-	x_min = point2->pos.x;                               \
-	x_max = point2->pos.x;                               \
-																		\
-	this_point = point1;                                 \
-	do {                                                 \
-		x_min = MIN (this_point->pos.x, x_min);           \
-		x_max = MAX (this_point->pos.x, x_max);           \
-		this_point = this_point->next;                    \
-	}                                                    \
-	while (this_point != point2 && this_point != point1) \
-
 
 namespace tesseract {
@@ -65,81 +41,4 @@ namespace tesseract {
               F u n c t i o n s
 ----------------------------------------------------------------------*/
-/**********************************************************************
- * full_split_priority
- *
- * Assign a priority to this split based on the features that it has.
- * Part of the priority has already been calculated so just return the
- * additional amount for the bounding box type information.
- **********************************************************************/
-PRIORITY Wordrec::full_split_priority(SPLIT *split, inT16 xmin, inT16 xmax) {
-  BOUNDS_RECT rect;
-
-  set_outline_bounds (split->point1, split->point2, rect);
-
-  if (xmin < MIN (rect[0], rect[2]) && xmax > MAX (rect[1], rect[3]))
-    return (999.0);
-
-  return (grade_overlap (rect) +
-    grade_center_of_blob (rect) + grade_width_change (rect));
-}
-
-
-/**********************************************************************
- * grade_center_of_blob
- *
- * Return a grade for the a split.  Rank it on closeness to the center
- * of the original blob
- *   0    =  ""perfect""
- *   100  =  ""no way jay""
- **********************************************************************/
-PRIORITY Wordrec::grade_center_of_blob(register BOUNDS_RECT rect) {
-  register PRIORITY grade;
-  int width1 = rect[1] - rect[0];
-  int width2 = rect[3] - rect[2];
-
-  if (width1 > chop_centered_maxwidth &&
-      width2 > chop_centered_maxwidth) {
-    return 0.0;
-  }
-
-  grade = width1 - width2;
-  if (grade < 0)
-    grade = -grade;
-
-  grade *= chop_center_knob;
-  grade = MIN (CENTER_GRADE_CAP, grade);
-  return (MAX (0.0, grade));
-}
-
-
-/**********************************************************************
- * grade_overlap
- *
- * Return a grade for this split for the overlap of the resultant blobs.
- *   0    =  ""perfect""
- *   100  =  ""no way jay""
- **********************************************************************/
-PRIORITY Wordrec::grade_overlap(register BOUNDS_RECT rect) {
-  register PRIORITY grade;
-  register inT16 width1;
-  register inT16 width2;
-  register inT16 overlap;
-
-  width1 = rect[3] - rect[2];
-  width2 = rect[1] - rect[0];
-
-  overlap = MIN (rect[1], rect[3]) - MAX (rect[0], rect[2]);
-  width1 = MIN (width1, width2);
-  if (overlap == width1)
-    return (100.0);              /* Total overlap */
-
-  width1 = 2 * overlap - width1; /* Extra penalty for too */
-  overlap += MAX (0, width1);    /* much overlap */
-
-  grade = overlap * chop_overlap_knob;
-
-  return (MAX (0.0, grade));
-}
-
 
 /**********************************************************************
@@ -154,6 +53,6 @@ PRIORITY Wordrec::grade_split_length(register SPLIT *split) {
   register float split_length;
 
-  split_length = weighted_edgept_dist (split->point1, split->point2,
-    chop_x_y_weight);
+  split_length =
+      split->point1->WeightedDistance(*split->point2, chop_x_y_weight);
 
   if (split_length <= 0)
@@ -189,50 +88,3 @@ PRIORITY Wordrec::grade_sharpness(register SPLIT *split) {
 
 
-/**********************************************************************
- * grade_width_change
- *
- * Return a grade for the change in width of the resultant blobs.
- *   0    =  ""perfect""
- *   100  =  ""no way jay""
- **********************************************************************/
-PRIORITY Wordrec::grade_width_change(register BOUNDS_RECT rect) {
-  register PRIORITY grade;
-  register inT32 width1;
-  register inT32 width2;
-
-  width1 = rect[3] - rect[2];
-  width2 = rect[1] - rect[0];
-
-  grade = 20 - (MAX (rect[1], rect[3])
-    - MIN (rect[0], rect[2]) - MAX (width1, width2));
-
-  grade *= chop_width_change_knob;
-
-  return (MAX (0.0, grade));
-}
-
-
-/**********************************************************************
- * set_outline_bounds
- *
- * Set up the limits for the x coordinate of the outline.
- **********************************************************************/
-void Wordrec::set_outline_bounds(register EDGEPT *point1,
-                                 register EDGEPT *point2,
-                                 BOUNDS_RECT rect) {
-  register EDGEPT *this_point;
-  register inT16 x_min;
-  register inT16 x_max;
-
-  find_bounds_loop(point1, point2, x_min, x_max);
-
-  rect[0] = x_min;
-  rect[1] = x_max;
-
-  find_bounds_loop(point2, point1, x_min, x_max);
-
-  rect[2] = x_min;
-  rect[3] = x_max;
-}
-
 }  // namespace tesseract
diff --git a/wordrec/gradechop.h b/wordrec/gradechop.h
index 469a140b..01e5bf26 100644
--- a/wordrec/gradechop.h
+++ b/wordrec/gradechop.h
@@ -33,9 +33,4 @@
 #include ""ndminx.h""
 
-/*----------------------------------------------------------------------
-              T y p e s
-----------------------------------------------------------------------*/
-typedef inT16 BOUNDS_RECT[4];
-
 /*----------------------------------------------------------------------
               M a c r o s
@@ -53,17 +48,3 @@ typedef inT16 BOUNDS_RECT[4];
 	grade_sharpness      (split))       \
 
-
-/**********************************************************************
- * split_bounds_overlap
- *
- * Check to see if this split might overlap with this outline.  Return
- * TRUE if there is a positive overlap in the bounding boxes of the two.
- **********************************************************************/
-
-#define split_bounds_overlap(split,outline)  \
-(outline->topleft.x  <= MAX (split->point1->pos.x,split->point2->pos.x) && \
-	outline->botright.x >= MIN (split->point1->pos.x,split->point2->pos.x) && \
-	outline->botright.y <= MAX (split->point1->pos.y,split->point2->pos.y) && \
-	outline->topleft.y  >= MIN (split->point1->pos.y,split->point2->pos.y))
-
 #endif
diff --git a/wordrec/makechop.cpp b/wordrec/makechop.cpp
deleted file mode 100644
index d6795bc3..00000000
--- a/wordrec/makechop.cpp
+++ /dev/null
@@ -1,226 +0,0 @@
-/* -*-C-*-
- ********************************************************************************
- *
- * File:        makechop.c  (Formerly makechop.c)
- * Description:
- * Author:   Mark Seaman, OCR Technology
- * Created:  Fri Oct 16 14:37:00 1987
- * Modified:     Mon Jul 29 15:50:42 1991 (Mark Seaman) marks@hpgrlt
- * Language: C
- * Package:  N/A
- * Status:   Reusable Software Component
- *
- * (c) Copyright 1987, Hewlett-Packard Company.
- ** Licensed under the Apache License, Version 2.0 (the ""License"");
- ** you may not use this file except in compliance with the License.
- ** You may obtain a copy of the License at
- ** http://www.apache.org/licenses/LICENSE-2.0
- ** Unless required by applicable law or agreed to in writing, software
- ** distributed under the License is distributed on an ""AS IS"" BASIS,
- ** WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- ** See the License for the specific language governing permissions and
- ** limitations under the License.
- *
- *********************************************************************************/
-/*----------------------------------------------------------------------
-      I n c l u d e s
-----------------------------------------------------------------------*/
-
-#include ""makechop.h""
-#include ""blobs.h""
-#include ""render.h""
-#include ""structures.h""
-#ifdef __UNIX__
-#include <assert.h>
-#include <unistd.h>
-#endif
-
-// Include automatically generated configuration file if running autoconf.
-#ifdef HAVE_CONFIG_H
-#include ""config_auto.h""
-#endif
-
-/*----------------------------------------------------------------------
-        Public Function Code
-----------------------------------------------------------------------*/
-/**********************************************************************
- * apply_seam
- *
- * Split this blob into two blobs by applying the splits included in
- * the seam description.
- **********************************************************************/
-void apply_seam(TBLOB *blob, TBLOB *other_blob, bool italic_blob, SEAM *seam) {
-  if (seam->split1 == NULL) {
-    divide_blobs(blob, other_blob, italic_blob, seam->location);
-  }
-  else if (seam->split2 == NULL) {
-    make_split_blobs(blob, other_blob, italic_blob, seam);
-  }
-  else if (seam->split3 == NULL) {
-    make_double_split(blob, other_blob, italic_blob, seam);
-  }
-  else {
-    make_triple_split(blob, other_blob, italic_blob, seam);
-  }
-}
-
-
-/**********************************************************************
- * form_two_blobs
- *
- * Group the outlines from the first blob into both of them. Do so
- * according to the information about the split.
- **********************************************************************/
-void form_two_blobs(TBLOB *blob, TBLOB *other_blob, bool italic_blob,
-                    const TPOINT& location) {
-  setup_blob_outlines(blob);
-
-  divide_blobs(blob, other_blob, italic_blob, location);
-
-  eliminate_duplicate_outlines(blob);
-  eliminate_duplicate_outlines(other_blob);
-
-  correct_blob_order(blob, other_blob);
-}
-
-
-/**********************************************************************
- * make_double_split
- *
- * Create two blobs out of one by splitting the original one in half.
- * Return the resultant blobs for classification.
- **********************************************************************/
-void make_double_split(TBLOB *blob, TBLOB *other_blob, bool italic_blob,
-                       SEAM *seam) {
-  make_single_split(blob->outlines, seam->split1);
-  make_single_split(blob->outlines, seam->split2);
-  form_two_blobs(blob, other_blob, italic_blob, seam->location);
-}
-
-
-/**********************************************************************
- * make_single_split
- *
- * Create two outlines out of one by splitting the original one in half.
- * Return the resultant outlines.
- **********************************************************************/
-void make_single_split(TESSLINE *outlines, SPLIT *split) {
-  assert (outlines != NULL);
-
-  split_outline (split->point1, split->point2);
-
-  while (outlines->next != NULL)
-    outlines = outlines->next;
-
-  outlines->next = new TESSLINE;
-  outlines->next->loop = split->point1;
-  outlines->next->ComputeBoundingBox();
-
-  outlines = outlines->next;
-
-  outlines->next = new TESSLINE;
-  outlines->next->loop = split->point2;
-  outlines->next->ComputeBoundingBox();
-
-  outlines->next->next = NULL;
-}
-
-
-/**********************************************************************
- * make_split_blobs
- *
- * Create two blobs out of one by splitting the original one in half.
- * Return the resultant blobs for classification.
- **********************************************************************/
-void make_split_blobs(TBLOB *blob, TBLOB *other_blob, bool italic_blob,
-                      SEAM *seam) {
-  make_single_split(blob->outlines, seam->split1);
-
-  form_two_blobs (blob, other_blob, italic_blob, seam->location);
-}
-
-
-/**********************************************************************
- * make_triple_split
- *
- * Create two blobs out of one by splitting the original one in half.
- * This splitting is accomplished by applying three separate splits on
- * the outlines. Three of the starting outlines will produce two ending
- * outlines. Return the resultant blobs for classification.
- **********************************************************************/
-void make_triple_split(TBLOB *blob, TBLOB *other_blob, bool italic_blob,
-                       SEAM *seam) {
-  make_single_split(blob->outlines, seam->split1);
-  make_single_split(blob->outlines, seam->split2);
-  make_single_split(blob->outlines, seam->split3);
-
-  form_two_blobs(blob, other_blob, italic_blob, seam->location);
-}
-
-
-/**********************************************************************
- * undo_seam
- *
- * Remove the seam between these two blobs.  Produce one blob as a
- * result.  The seam may consist of one, two, or three splits.  Each
- * of these split must be removed from the outlines.
- **********************************************************************/
-void undo_seam(TBLOB *blob, TBLOB *other_blob, SEAM *seam) {
-  TESSLINE *outline;
-
-  if (!seam)
-    return;                      /* Append other blob outlines */
-  if (blob->outlines == NULL) {
-    blob->outlines = other_blob->outlines;
-    other_blob->outlines = NULL;
-  }
-
-  outline = blob->outlines;
-  while (outline->next)
-    outline = outline->next;
-  outline->next = other_blob->outlines;
-  other_blob->outlines = NULL;
-  delete other_blob;
-
-  if (seam->split1 == NULL) {
-  }
-  else if (seam->split2 == NULL) {
-    undo_single_split (blob, seam->split1);
-  }
-  else if (seam->split3 == NULL) {
-    undo_single_split (blob, seam->split1);
-    undo_single_split (blob, seam->split2);
-  }
-  else {
-    undo_single_split (blob, seam->split3);
-    undo_single_split (blob, seam->split2);
-    undo_single_split (blob, seam->split1);
-  }
-
-  setup_blob_outlines(blob);
-  eliminate_duplicate_outlines(blob);
-}
-
-
-/**********************************************************************
- * undo_single_split
- *
- * Undo a seam that is made by a single split.  Perform the correct
- * magic to reconstruct the appropriate set of outline data structures.
- **********************************************************************/
-void undo_single_split(TBLOB *blob, SPLIT *split) {
-  TESSLINE *outline1;
-  TESSLINE *outline2;
-  /* Modify edge points */
-  unsplit_outlines (split->point1, split->point2);
-
-  outline1 = new TESSLINE;
-  outline1->next = blob->outlines;
-  blob->outlines = outline1;
-  outline1->loop = split->point1;
-
-  outline2 = new TESSLINE;
-  outline2->next = blob->outlines;
-  blob->outlines = outline2;
-  outline2->loop = split->point2;
-}
diff --git a/wordrec/makechop.h b/wordrec/makechop.h
deleted file mode 100644
index 1f2639cd..00000000
--- a/wordrec/makechop.h
+++ /dev/null
@@ -1,71 +0,0 @@
-/* -*-C-*-
- ********************************************************************************
- *
- * File:        makechop.h  (Formerly makechop.h)
- * Description:
- * Author:	Mark Seaman, SW Productivity
- * Created:	Fri Oct 16 14:37:00 1987
- * Modified:     Mon Jul 29 13:33:23 1991 (Mark Seaman) marks@hpgrlt
- * Language:	C
- * Package:	N/A
- * Status:	Reusable Software Component
- *
- * (c) Copyright 1987, Hewlett-Packard Company.
- ** Licensed under the Apache License, Version 2.0 (the ""License"");
- ** you may not use this file except in compliance with the License.
- ** You may obtain a copy of the License at
- ** http://www.apache.org/licenses/LICENSE-2.0
- ** Unless required by applicable law or agreed to in writing, software
- ** distributed under the License is distributed on an ""AS IS"" BASIS,
- ** WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- ** See the License for the specific language governing permissions and
- ** limitations under the License.
- *
- *********************************************************************************/
-#ifndef MAKECHOP_H
-#define MAKECHOP_H
-
-/*----------------------------------------------------------------------
-      I n c l u d e s
-----------------------------------------------------------------------*/
-#include ""chop.h""
-#include ""olutil.h""
-
-/*----------------------------------------------------------------------
-      M a c r o s
----------------------------------------------------------------------*/
-/**********************************************************************
- * is_split_outline
- *
- * Check to see if both sides of the split fall within the bounding
- * box of this outline.
- **********************************************************************/
-
-#define is_split_outline(outline,split)          \
-(outline->Contains(split->point1->pos) &&  \
-	outline->Contains(split->point2->pos))    \
-
-
-/*----------------------------------------------------------------------
-        Public Function Prototypes
-----------------------------------------------------------------------*/
-void apply_seam(TBLOB *blob, TBLOB *other_blob, bool italic_blob, SEAM *seam);
-
-void form_two_blobs(TBLOB *blob, TBLOB *other_blob, bool italic_blob,
-                    const TPOINT& location);
-
-void make_double_split(TBLOB *blob, TBLOB *other_blob, bool italic_blob,
-                       SEAM *seam);
-
-void make_single_split(TESSLINE *outlines, SPLIT *split);
-
-void make_split_blobs(TBLOB *blob, TBLOB *other_blob, bool italic_blob,
-                      SEAM *seam);
-
-void make_triple_split(TBLOB *blob, TBLOB *other_blob, bool italic_blob,
-                       SEAM *seam);
-
-void undo_seam(TBLOB *blob, TBLOB *other_blob, SEAM *seam);
-
-void undo_single_split(TBLOB *blob, SPLIT *split);
-#endif
diff --git a/wordrec/olutil.cpp b/wordrec/olutil.cpp
deleted file mode 100644
index dadf51af..00000000
--- a/wordrec/olutil.cpp
+++ /dev/null
@@ -1,102 +0,0 @@
-/* -*-C-*-
- ********************************************************************************
- *
- * File:        olutil.c  (Formerly olutil.c)
- * Description:
- * Author:       Mark Seaman, OCR Technology
- * Created:      Fri Oct 16 14:37:00 1987
- * Modified:     Fri May 17 13:11:24 1991 (Mark Seaman) marks@hpgrlt
- * Language:     C
- * Package:      N/A
- * Status:       Reusable Software Component
- *
- * (c) Copyright 1987, Hewlett-Packard Company.
- ** Licensed under the Apache License, Version 2.0 (the ""License"");
- ** you may not use this file except in compliance with the License.
- ** You may obtain a copy of the License at
- ** http://www.apache.org/licenses/LICENSE-2.0
- ** Unless required by applicable law or agreed to in writing, software
- ** distributed under the License is distributed on an ""AS IS"" BASIS,
- ** WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- ** See the License for the specific language governing permissions and
- ** limitations under the License.
- *
- *********************************************************************************/
-/*----------------------------------------------------------------------
-              I n c l u d e s
-----------------------------------------------------------------------*/
-#include ""olutil.h""
-#include ""structures.h""
-#include ""blobs.h""
-#include ""const.h""
-
-#ifdef __UNIX__
-#include <assert.h>
-#endif
-
-/*----------------------------------------------------------------------
-              F u n c t i o n s
-----------------------------------------------------------------------*/
-/**********************************************************************
- * correct_blob_order
- *
- * Check to see if the blobs are in the correct order.  If they are not
- * then swap which outlines are attached to which blobs.
- **********************************************************************/
-void correct_blob_order(TBLOB *blob1, TBLOB *blob2) { 
-  TPOINT origin1;
-  TPOINT origin2;
-  TESSLINE *temp;
-
-  blob_origin(blob1, &origin1); 
-  blob_origin(blob2, &origin2); 
-
-  if (origin1.x > origin2.x) {
-    temp = blob2->outlines;
-    blob2->outlines = blob1->outlines;
-    blob1->outlines = temp;
-  }
-}
-
-
-/**********************************************************************
- * eliminate_duplicate_outlines
- *
- * Find and delete any duplicate outline records in this blob.
- **********************************************************************/
-void eliminate_duplicate_outlines(TBLOB *blob) { 
-  TESSLINE *outline;
-  TESSLINE *other_outline;
-  TESSLINE *last_outline;
-
-  for (outline = blob->outlines; outline; outline = outline->next) {
-
-    for (last_outline = outline, other_outline = outline->next;
-      other_outline;
-    last_outline = other_outline, other_outline = other_outline->next) {
-
-      if (same_outline_bounds (outline, other_outline)) {
-        last_outline->next = other_outline->next;
-        // This doesn't leak - the outlines share the EDGEPTs.
-        other_outline->loop = NULL;
-        delete other_outline;
-        other_outline = last_outline;
-        // If it is part of a cut, then it can't be a hole any more.
-        outline->is_hole = false;
-      }
-    }
-  }
-}
-
-/**********************************************************************
- * setup_blob_outlines
- *
- * Set up each of the outlines in this blob.
- **********************************************************************/
-void setup_blob_outlines(TBLOB *blob) { 
-  TESSLINE *outline;
-
-  for (outline = blob->outlines; outline; outline = outline->next) {
-    outline->ComputeBoundingBox();
-  }
-}
diff --git a/wordrec/olutil.h b/wordrec/olutil.h
deleted file mode 100644
index c7eeecd2..00000000
--- a/wordrec/olutil.h
+++ /dev/null
@@ -1,82 +0,0 @@
-/* -*-C-*-
- ********************************************************************************
- *
- * File:        olutil.h  (Formerly olutil.h)
- * Description:
- * Author:       Mark Seaman, SW Productivity
- * Created:      Fri Oct 16 14:37:00 1987
- * Modified:     Wed Jul 10 14:21:55 1991 (Mark Seaman) marks@hpgrlt
- * Language:     C
- * Package:      N/A
- * Status:       Reusable Software Component
- *
- * (c) Copyright 1987, Hewlett-Packard Company.
- ** Licensed under the Apache License, Version 2.0 (the ""License"");
- ** you may not use this file except in compliance with the License.
- ** You may obtain a copy of the License at
- ** http://www.apache.org/licenses/LICENSE-2.0
- ** Unless required by applicable law or agreed to in writing, software
- ** distributed under the License is distributed on an ""AS IS"" BASIS,
- ** WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- ** See the License for the specific language governing permissions and
- ** limitations under the License.
- *
- *********************************************************************************/
-#ifndef OLUTIL_H
-#define OLUTIL_H
-
-/*----------------------------------------------------------------------
-              I n c l u d e s
-----------------------------------------------------------------------*/
-#include ""blobs.h""
-
-/*----------------------------------------------------------------------
-              M a c r o s
-----------------------------------------------------------------------*/
-/**********************************************************************
- * is_inside_angle
- *
- * Return true if the edgept supplied as input is an inside angle.  This
- * is determined by the angular change of the vectors from point to
- * point.
-
- **********************************************************************/
-
-#define is_inside_angle(pt)                                  \
-(angle_change ((pt)->prev, (pt), (pt)->next) < chop_inside_angle)
-
-/**********************************************************************
- * same_outline_bounds
- *
- * Return TRUE if these two outlines have the same bounds.
- **********************************************************************/
-
-#define same_outline_bounds(outline,other_outline)     \
-(outline->topleft.x  == other_outline->topleft.x  && \
-	outline->topleft.y  == other_outline->topleft.y  && \
-	outline->botright.x == other_outline->botright.x && \
-	outline->botright.y == other_outline->botright.y)   \
-
-
-/**********************************************************************
- * weighted_edgept_dist
- *
- * Return the distance (squared) between the two edge points.
- **********************************************************************/
-
-#define weighted_edgept_dist(p1,p2,chop_x_y_weight)  \
-(((p1)->pos.x - (p2)->pos.x) *                \
-	((p1)->pos.x - (p2)->pos.x) * chop_x_y_weight +  \
-	((p1)->pos.y - (p2)->pos.y) *               \
-	((p1)->pos.y - (p2)->pos.y))
-
-/*----------------------------------------------------------------------
-              F u n c t i o n s
-----------------------------------------------------------------------*/
-void correct_blob_order(TBLOB *blob1, TBLOB *blob2); 
-
-void eliminate_duplicate_outlines(TBLOB *blob); 
-
-void setup_blob_outlines(TBLOB *blob); 
-
-#endif
diff --git a/wordrec/outlines.cpp b/wordrec/outlines.cpp
index 3d31a67c..fdcedfc7 100644
--- a/wordrec/outlines.cpp
+++ b/wordrec/outlines.cpp
@@ -40,71 +40,4 @@ namespace tesseract {
               F u n c t i o n s
 ----------------------------------------------------------------------*/
-/**********************************************************************
- * crosses_outline
- *
- * Check to see if this line crosses over this outline.  If it does
- * return TRUE.
- **********************************************************************/
-int Wordrec::crosses_outline(EDGEPT *p0,         /* Start of line */
-                             EDGEPT *p1,         /* End of line */
-                             EDGEPT *outline) {  /* Outline to check */
-  EDGEPT *pt = outline;
-  do {
-    if (is_crossed (p0->pos, p1->pos, pt->pos, pt->next->pos))
-      return (TRUE);
-    pt = pt->next;
-  }
-  while (pt != outline);
-  return (FALSE);
-}
-
-
-/**********************************************************************
- * is_crossed
- *
- * Return TRUE when the two line segments cross each other.  Find out
- * where the projected lines would cross and then check to see if the
- * point of intersection lies on both of the line segments. If it does
- * then these two segments cross.
- **********************************************************************/
-int Wordrec::is_crossed(TPOINT a0, TPOINT a1, TPOINT b0, TPOINT b1) {
-  int b0a1xb0b1, b0b1xb0a0;
-  int a1b1xa1a0, a1a0xa1b0;
-
-  TPOINT b0a1, b0a0, a1b1, b0b1, a1a0;
-
-  b0a1.x = a1.x - b0.x;
-  b0a0.x = a0.x - b0.x;
-  a1b1.x = b1.x - a1.x;
-  b0b1.x = b1.x - b0.x;
-  a1a0.x = a0.x - a1.x;
-  b0a1.y = a1.y - b0.y;
-  b0a0.y = a0.y - b0.y;
-  a1b1.y = b1.y - a1.y;
-  b0b1.y = b1.y - b0.y;
-  a1a0.y = a0.y - a1.y;
-
-  b0a1xb0b1 = CROSS (b0a1, b0b1);
-  b0b1xb0a0 = CROSS (b0b1, b0a0);
-  a1b1xa1a0 = CROSS (a1b1, a1a0);
-                                 /*a1a0xa1b0=CROSS(a1a0,a1b0); */
-  a1a0xa1b0 = -CROSS (a1a0, b0a1);
-
-  return ((b0a1xb0b1 > 0 && b0b1xb0a0 > 0)
-    || (b0a1xb0b1 < 0 && b0b1xb0a0 < 0))
-    && ((a1b1xa1a0 > 0 && a1a0xa1b0 > 0) || (a1b1xa1a0 < 0 && a1a0xa1b0 < 0));
-}
-
-
-/**********************************************************************
- * is_same_edgept
- *
- * Return true if the points are identical.
- **********************************************************************/
-int Wordrec::is_same_edgept(EDGEPT *p1, EDGEPT *p2) {
-  return (p1 == p2);
-}
-
-
 /**********************************************************************
  * near_point
@@ -154,29 +87,3 @@ bool Wordrec::near_point(EDGEPT *point,
 }
 
-
-/**********************************************************************
- * reverse_outline
- *
- * Change the direction of the outline.  If it was clockwise make it
- * counter-clockwise and vice versa.  Do this by swapping each of the
- * next and prev fields of each edge point.
- **********************************************************************/
-void Wordrec::reverse_outline(EDGEPT *outline) {
-  EDGEPT *edgept = outline;
-  EDGEPT *temp;
-
-  do {
-                                 /* Swap next and prev */
-    temp = edgept->prev;
-    edgept->prev = edgept->next;
-    edgept->next = temp;
-    /* Set up vec field */
-    edgept->vec.x = edgept->next->pos.x - edgept->pos.x;
-    edgept->vec.y = edgept->next->pos.y - edgept->pos.y;
-
-    edgept = edgept->prev;       /* Go to next point */
-  }
-  while (edgept != outline);
-}
-
 }  // namespace tesseract
diff --git a/wordrec/pieces.cpp b/wordrec/pieces.cpp
index 35462ea2..f9205340 100644
--- a/wordrec/pieces.cpp
+++ b/wordrec/pieces.cpp
@@ -59,5 +59,5 @@ BLOB_CHOICE_LIST *Wordrec::classify_piece(const GenericVector<SEAM*>& seams,
                                           TWERD *word,
                                           BlamerBundle *blamer_bundle) {
-  if (end > start) join_pieces(seams, start, end, word);
+  if (end > start) SEAM::JoinPieces(seams, word->blobs, start, end);
   BLOB_CHOICE_LIST *choices = classify_blob(word->blobs[start], description,
                                             White, blamer_bundle);
@@ -68,5 +68,5 @@ BLOB_CHOICE_LIST *Wordrec::classify_piece(const GenericVector<SEAM*>& seams,
   }
 
-  if (end > start) break_pieces(seams, start, end, word);
+  if (end > start) SEAM::BreakPieces(seams, word->blobs, start, end);
 
   return (choices);
diff --git a/wordrec/plotedges.cpp b/wordrec/plotedges.cpp
index 0aa02c37..f7fbacee 100644
--- a/wordrec/plotedges.cpp
+++ b/wordrec/plotedges.cpp
@@ -120,20 +120,3 @@ void mark_outline(EDGEPT *edgept) {  /* Start of point list */
 }
 
-
-/**********************************************************************
- * mark_split
- *
- * Set up the marks list to be displayed in subsequent updates and draw
- * the marks in the current window.  The marks are stored in the second
- * sublist. The first sublist is left unmodified.
- **********************************************************************/
-void mark_split(SPLIT *split) {
-  void *window = edge_window;
-
-  c_line_color_index(window, Green);
-  c_move (window, (float) split->point1->pos.x, (float) split->point1->pos.y);
-  c_draw (window, (float) split->point2->pos.x, (float) split->point2->pos.y);
-  c_make_current(window);
-}
-
 #endif  // GRAPHICS_DISABLED
diff --git a/wordrec/plotedges.h b/wordrec/plotedges.h
index d0ca40be..91521de7 100644
--- a/wordrec/plotedges.h
+++ b/wordrec/plotedges.h
@@ -29,5 +29,4 @@
 #include ""oldlist.h""
 #include ""blobs.h""
-#include ""split.h""
 
 /*----------------------------------------------------------------------
@@ -68,4 +67,3 @@ void draw_blob_edges(TBLOB *blob);
 void mark_outline(EDGEPT *edgept);
 
-void mark_split(SPLIT *split);
 #endif
diff --git a/wordrec/segsearch.cpp b/wordrec/segsearch.cpp
index 29d03702..a6fe10ff 100644
--- a/wordrec/segsearch.cpp
+++ b/wordrec/segsearch.cpp
@@ -54,6 +54,5 @@ void Wordrec::SegSearch(WERD_RES* word_res,
                           blamer_bundle, &pain_points, &pending);
     }
-    if (chop_debug)
-      print_seams(""Final seam list:"", word_res->seam_array);
+    if (chop_debug) SEAM::PrintSeams(""Final seam list:"", word_res->seam_array);
 
     if (blamer_bundle != NULL &&
diff --git a/wordrec/wordrec.h b/wordrec/wordrec.h
index a69026b1..38f09f23 100644
--- a/wordrec/wordrec.h
+++ b/wordrec/wordrec.h
@@ -291,7 +291,8 @@ class Wordrec : public Classify {
   PRIORITY point_priority(EDGEPT *point);
   void add_point_to_list(PointHeap* point_heap, EDGEPT *point);
+  // Returns true if the edgept supplied as input is an inside angle.  This
+  // is determined by the angular change of the vectors from point to point.
+  bool is_inside_angle(EDGEPT *pt);
   int angle_change(EDGEPT *point1, EDGEPT *point2, EDGEPT *point3);
-  int is_little_chunk(EDGEPT *point1, EDGEPT *point2);
-  int is_small_area(EDGEPT *point1, EDGEPT *point2);
   EDGEPT *pick_close_point(EDGEPT *critical_point,
                            EDGEPT *vertical_point,
@@ -336,15 +337,10 @@ class Wordrec : public Classify {
   // findseam.cpp
   void add_seam_to_queue(float new_priority, SEAM *new_seam, SeamQueue* seams);
-  void choose_best_seam(SeamQueue* seam_queue,
-                        SPLIT *split,
-                        PRIORITY priority,
-                        SEAM **seam_result,
-                        TBLOB *blob,
-                        SeamPile* seam_pile);
+  void choose_best_seam(SeamQueue *seam_queue, const SPLIT *split,
+                        PRIORITY priority, SEAM **seam_result, TBLOB *blob,
+                        SeamPile *seam_pile);
   void combine_seam(const SeamPile& seam_pile,
                     const SEAM* seam, SeamQueue* seam_queue);
-  inT16 constrained_split(SPLIT *split, TBLOB *blob);
   SEAM *pick_good_seam(TBLOB *blob);
-  PRIORITY seam_priority(SEAM *seam, inT16 xmin, inT16 xmax);
   void try_point_pairs (EDGEPT * points[MAX_NUM_POINTS],
                         inT16 num_points,
@@ -360,21 +356,10 @@ class Wordrec : public Classify {
 
   // gradechop.cpp
-  PRIORITY full_split_priority(SPLIT *split, inT16 xmin, inT16 xmax);
-  PRIORITY grade_center_of_blob(register BOUNDS_RECT rect);
-  PRIORITY grade_overlap(register BOUNDS_RECT rect);
   PRIORITY grade_split_length(register SPLIT *split);
   PRIORITY grade_sharpness(register SPLIT *split);
-  PRIORITY grade_width_change(register BOUNDS_RECT rect);
-  void set_outline_bounds(register EDGEPT *point1,
-                          register EDGEPT *point2,
-                          BOUNDS_RECT rect);
 
   // outlines.cpp
-  int crosses_outline(EDGEPT *p0, EDGEPT *p1, EDGEPT *outline);
-  int is_crossed(TPOINT a0, TPOINT a1, TPOINT b0, TPOINT b1);
-  int is_same_edgept(EDGEPT *p1, EDGEPT *p2);
   bool near_point(EDGEPT *point, EDGEPT *line_pt_0, EDGEPT *line_pt_1,
                   EDGEPT **near_pt);
-  void reverse_outline(EDGEPT *outline);
 
   // pieces.cpp
","Major refactor to improve speed on difficut images, especially when running
a heap checker.
SEAM and SPLIT have been begging for a refactor for a *LONG* time.
This change does most of the work of turning them into proper classes:
  Moved relevant code into SEAM/SPLIT/TBLOB/EDGEPT etc from global helper functions.
  Made the splits full data members of SEAM in an array instead of 3 separate pointers.
    This greatly reduces the amount of new/delete happening in the chopper, which is the main goal.
  Deleted redundant files: olutil.*,  makechop.*
  Brought other code into SEAM in order to keep its data members private with only priority having accessors.

"
132,C++,cabba0f15882317a5bf891b92e596b32761a13ca,https://github.com/ocornut/imgui/commit/cabba0f15882317a5bf891b92e596b32761a13ca,P,ocornut,imgui,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 3, 0, 0, 0, 0]","diff --git a/README.md b/README.md
index 8a9eab15..ea0d4639 100644
--- a/README.md
+++ b/README.md
@@ -169,11 +169,12 @@ Ongoing ImGui development is financially supported on [**Patreon**](http://www.p
 
 Double-chocolate sponsors:
-- Media Molecule, Mobigame
+- Media Molecule
+- Mobigame
 
 Salty caramel supporters:
-- Jetha Chan, Wild Sheep Studio, Pastagames, Mrti Moeiko, Daniel Collin, Stefano Cristiano, Chris Genova, ikrima
+- Jetha Chan, Wild Sheep Studio, Pastagames, Mrti Moeiko, Daniel Collin, Stefano Cristiano, Chris Genova, ikrima, Glenn Fiedler, Geoffrey Evans, Dakko Dakko.
 
 Caramel supporters:
-- Michel Courtine, Csar Leblic, Dale Kim, Alex Evans, Rui Figueira, Paul Patrashcu, Jerome Lanquetot, Ctrl Alt Ninja, Paul Fleming, Neil Henning, Stephan Dilly, Neil Blakey-Milner, Aleksei, NeiloGD, Justin Paver, FiniteSol, Vincent Pancaldi, James Billot, Robin Hbner, furrtek, Eric, Simon Barratt, Game Atelier, Julian Bosch, Simon Lundmark, Vincent Hamm, Farhan Wali, Jeff Roberts, Matt Reyer, Colin Riley.
+- Michel Courtine, Csar Leblic, Dale Kim, Alex Evans, Rui Figueira, Paul Patrashcu, Jerome Lanquetot, Ctrl Alt Ninja, Paul Fleming, Neil Henning, Stephan Dilly, Neil Blakey-Milner, Aleksei, NeiloGD, Justin Paver, FiniteSol, Vincent Pancaldi, James Billot, Robin Hbner, furrtek, Eric, Simon Barratt, Game Atelier, Julian Bosch, Simon Lundmark, Vincent Hamm, Farhan Wali, Jeff Roberts, Matt Reyer, Colin Riley, Victor Martins, Josh Simmons, Garrett Hoofman, Sergio Gonzales, Andrew Berridge, Roy Eltham, Game Preservation Society.
 
 And other supporters; thanks!
","Update README.md
"
141,C++,f74363bb3adf89748f10b9f07634332b86087c43,https://github.com/nomic-ai/gpt4all/commit/f74363bb3adf89748f10b9f07634332b86087c43,C,nomic-ai,gpt4all,"[1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/gpt4all-chat/chatllm.cpp b/gpt4all-chat/chatllm.cpp
index a419f99..23312ce 100644
--- a/gpt4all-chat/chatllm.cpp
+++ b/gpt4all-chat/chatllm.cpp
@@ -217,5 +217,5 @@ bool ChatLLM::loadModel(const QString &modelName)
             if (m_modelInfo.model) {
                 m_modelInfo.model->loadModel(filePath.toStdString());
-                switch (m_modelInfo.model->getImplementation().modelType[0]) {
+                switch (m_modelInfo.model->implementation().modelType[0]) {
                 case 'L': m_modelType = LLModelType::LLAMA_; break;
                 case 'G': m_modelType = LLModelType::GPTJ_; break;
","Fix compile

"
146,C++,2daecd6066ac665dd664e87062632cddf702e1b9,https://github.com/nomic-ai/gpt4all/commit/2daecd6066ac665dd664e87062632cddf702e1b9,A,nomic-ai,gpt4all,"[1, 9, 1, 3, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/configs/train/finetune_lora.yaml b/configs/train/finetune_lora.yaml
index d5fdf92..51e8809 100644
--- a/configs/train/finetune_lora.yaml
+++ b/configs/train/finetune_lora.yaml
@@ -9,6 +9,6 @@ streaming: false
 num_proc: 64
 dataset_path: ""data""
-max_length: 512
-batch_size: 8
+max_length: 1024
+batch_size: 4
 
 # train dynamics
@@ -23,7 +23,6 @@ warmup_steps: 100
 
 # logging
-wandb: false
-wandb_entity: zanussbaum
-wandb_project: llama
-seed: 42
-
+wandb: true
+wandb_entity: vicuna
+wandb_project_name: vicuna
+seed: 42
\ No newline at end of file
diff --git a/train.py b/train.py
index 49f1d9f..d8ea616 100644
--- a/train.py
+++ b/train.py
@@ -48,9 +48,8 @@ def train(accelerator, config):
 
     tokenizer = AutoTokenizer.from_pretrained(config['tokenizer_name'])
-    # llama has no pad token, set it to eos
+    # llama has no pad token, set it to new token
     if tokenizer.pad_token is None:
         # these tokens are already in the vocab, just not mapped correctly
-        tokenizer.add_special_tokens({""bos_token"": ""<s>"", ""eos_token"": ""</s>""})
-        tokenizer.pad_token = tokenizer.eos_token
+        added_tokens = tokenizer.add_special_tokens({""bos_token"": ""<s>"", ""eos_token"": ""</s>"", ""pad_token"": ""<pad>""})
 
         
@@ -63,4 +62,7 @@ def train(accelerator, config):
                                                     use_cache=False if checkpoint else True,
                                                     trust_remote_code=True) 
+
+    if added_tokens > 0:
+        model.resize_token_embeddings(len(tokenizer))
     
     if checkpoint:
@@ -109,19 +111,26 @@ def train(accelerator, config):
     train_loss = MeanMetric().to(model.device)
 
+    if accelerator.state.deepspeed_plugin is not None:
+        gradient_accumulation_steps = accelerator.state.deepspeed_plugin.deepspeed_config[
+            ""gradient_accumulation_steps""
+        ]
+
     for step, batch in enumerate(tqdm(train_dataloader)):
         model.train()
         outputs = model(**batch)
         loss = outputs.loss
+        loss = loss / gradient_accumulation_steps
 
         accelerator.backward(loss)
-        optimizer.step()
 
         # log LR in case something weird happens 
-        if step % (config[""eval_every""] // 10) == 0:
+        if step > 0 and step % (config[""eval_every""] // 10) == 0:
             if config[""wandb""]:
                 accelerator.log({""lr"": scheduler.get_last_lr()[0]}, step=step)
 
-        scheduler.step()
-        optimizer.zero_grad()
+        if (step + 1) % gradient_accumulation_steps == 0 or step == len(train_dataloader) - 1:
+            optimizer.step()
+            scheduler.step()
+            optimizer.zero_grad()
 
         loss_values = accelerator.gather_for_metrics({""loss"": loss.detach()})
","feat: update embeddings

"
149,C++,23f3ba5b783f8d9c02f33103b3c6d7d0d0764412,https://github.com/nomic-ai/gpt4all/commit/23f3ba5b783f8d9c02f33103b3c6d7d0d0764412,C,nomic-ai,gpt4all,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2]","diff --git a/cmake/installerscript.qs b/cmake/installerscript.qs
index 1102704..841e1e5 100644
--- a/cmake/installerscript.qs
+++ b/cmake/installerscript.qs
@@ -58,5 +58,6 @@ Component.prototype.createOperationsForArchive = function(archive)
 
     if (systemInfo.productType === ""osx"") {
-        var symlinkPath = targetDirectory + ""/../GPT4All.app"";
+        var uninstallTargetDirectory = installer.value(""TargetDir"");
+        var symlinkPath = uninstallTargetDirectory + ""/../GPT4All.app"";
 
         // Remove the symlink during uninstallation
","Try to fix uninstall of symlink.

"
159,C++,f586be85324e29a378a1d3ffe3256ca1d266dca7,https://github.com/grpc/grpc/commit/f586be85324e29a378a1d3ffe3256ca1d266dca7,P,grpc,grpc,"[1, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/src/cpp/thread_manager/thread_manager.cc b/src/cpp/thread_manager/thread_manager.cc
index c5df8cf9e7..8d51a6f2af 100644
--- a/src/cpp/thread_manager/thread_manager.cc
+++ b/src/cpp/thread_manager/thread_manager.cc
@@ -35,11 +35,7 @@ ThreadManager::WorkerThread::WorkerThread(ThreadManager* thd_mgr)
       ""grpcpp_sync_server"",
       [](void* th) { static_cast<ThreadManager::WorkerThread*>(th)->Run(); },
-      this,
-      &created_
-      );
+      this, &created_);
   if (!created_) {
-    gpr_log(GPR_ERROR,
-            ""Could not create grpc_sync_server worker-thread""
-            );
+    gpr_log(GPR_ERROR, ""Could not create grpc_sync_server worker-thread"");
   } else {
     thd_.Start();
@@ -52,5 +48,4 @@ void ThreadManager::WorkerThread::Run() {
 }
 
-
 ThreadManager::WorkerThread::~WorkerThread() {
   // Don't join until the thread is fully constructed.
","Fix formatting

"
160,C++,9a244d61d4a0b2bbe775041b5ce63c1df6a97e37,https://github.com/grpc/grpc/commit/9a244d61d4a0b2bbe775041b5ce63c1df6a97e37,P,grpc,grpc,"[7, 49, 38, 17, 1, 2, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/src/csharp/Grpc.Core.Tests/PInvokeTest.cs b/src/csharp/Grpc.Core.Tests/PInvokeTest.cs
index 7529c44c4e..43f816bb1c 100644
--- a/src/csharp/Grpc.Core.Tests/PInvokeTest.cs
+++ b/src/csharp/Grpc.Core.Tests/PInvokeTest.cs
@@ -64,5 +64,5 @@ namespace Grpc.Core.Tests
         public void NativeCallbackBenchmark()
         {
-            OpCompletionDelegate handler = Handler;
+            NativeCallbackTestDelegate handler = Handler;
 
             counter = 0;
@@ -92,5 +92,5 @@ namespace Grpc.Core.Tests
                 () =>
                 {
-                    Native.grpcsharp_test_callback(new OpCompletionDelegate(Handler));
+                    Native.grpcsharp_test_callback(new NativeCallbackTestDelegate(Handler));
                 });
             Assert.AreNotEqual(0, counter);
diff --git a/src/csharp/Grpc.Core/Internal/BatchContextSafeHandle.cs b/src/csharp/Grpc.Core/Internal/BatchContextSafeHandle.cs
index cd5e3d8911..d839413a80 100644
--- a/src/csharp/Grpc.Core/Internal/BatchContextSafeHandle.cs
+++ b/src/csharp/Grpc.Core/Internal/BatchContextSafeHandle.cs
@@ -21,13 +21,20 @@ using System.Runtime.InteropServices;
 using System.Text;
 using Grpc.Core;
+using Grpc.Core.Logging;
 
 namespace Grpc.Core.Internal
 {
+    internal interface IOpCompletionCallback
+    {
+        void OnComplete(bool success);
+    }
+
     /// <summary>
     /// grpcsharp_batch_context
     /// </summary>
-    internal class BatchContextSafeHandle : SafeHandleZeroIsInvalid
+    internal class BatchContextSafeHandle : SafeHandleZeroIsInvalid, IOpCompletionCallback
     {
         static readonly NativeMethods Native = NativeMethods.Get();
+        static readonly ILogger Logger = GrpcEnvironment.Logger.ForType<BatchContextSafeHandle>();
 
         private BatchContextSafeHandle()
@@ -48,4 +55,6 @@ namespace Grpc.Core.Internal
         }
 
+        public BatchCompletionDelegate CompletionCallback { get; set; }
+
         // Gets data of recv_initial_metadata completion.
         public Metadata GetReceivedInitialMetadata()
@@ -93,4 +102,21 @@ namespace Grpc.Core.Internal
             return true;
         }
+
+        void IOpCompletionCallback.OnComplete(bool success)
+        {
+            try
+            {
+                CompletionCallback(success, this);
+            }
+            catch (Exception e)
+            {
+                Logger.Error(e, ""Exception occured while invoking batch completion delegate."");
+            }
+            finally
+            {
+                CompletionCallback = null;
+                Dispose();
+            }
+        }
     }
 }
diff --git a/src/csharp/Grpc.Core/Internal/CompletionRegistry.cs b/src/csharp/Grpc.Core/Internal/CompletionRegistry.cs
index 1102c8d14f..33734864bd 100644
--- a/src/csharp/Grpc.Core/Internal/CompletionRegistry.cs
+++ b/src/csharp/Grpc.Core/Internal/CompletionRegistry.cs
@@ -26,6 +26,4 @@ using Grpc.Core.Utils;
 namespace Grpc.Core.Internal
 {
-    internal delegate void OpCompletionDelegate(bool success);
-
     internal delegate void BatchCompletionDelegate(bool success, BatchContextSafeHandle ctx);
 
@@ -37,5 +35,5 @@ namespace Grpc.Core.Internal
 
         readonly GrpcEnvironment environment;
-        readonly Dictionary<IntPtr, OpCompletionDelegate> dict = new Dictionary<IntPtr, OpCompletionDelegate>(new IntPtrComparer());
+        readonly Dictionary<IntPtr, IOpCompletionCallback> dict = new Dictionary<IntPtr, IOpCompletionCallback>(new IntPtrComparer());
         readonly object myLock = new object();
         IntPtr lastRegisteredKey;  // only for testing
@@ -46,5 +44,5 @@ namespace Grpc.Core.Internal
         }
 
-        public void Register(IntPtr key, OpCompletionDelegate callback)
+        public void Register(IntPtr key, IOpCompletionCallback callback)
         {
             environment.DebugStats.PendingBatchCompletions.Increment();
@@ -58,19 +56,17 @@ namespace Grpc.Core.Internal
         public void RegisterBatchCompletion(BatchContextSafeHandle ctx, BatchCompletionDelegate callback)
         {
-            // TODO(jtattermusch): get rid of new delegate creation here
-            OpCompletionDelegate opCallback = ((success) => HandleBatchCompletion(success, ctx, callback));
-            Register(ctx.Handle, opCallback);
+            ctx.CompletionCallback = callback;
+            Register(ctx.Handle, ctx);
         }
 
         public void RegisterRequestCallCompletion(RequestCallContextSafeHandle ctx, RequestCallCompletionDelegate callback)
         {
-            // TODO(jtattermusch): get rid of new delegate creation here
-            OpCompletionDelegate opCallback = ((success) => HandleRequestCallCompletion(success, ctx, callback));
-            Register(ctx.Handle, opCallback);
+            ctx.CompletionCallback = callback;
+            Register(ctx.Handle, ctx);
         }
 
-        public OpCompletionDelegate Extract(IntPtr key)
+        public IOpCompletionCallback Extract(IntPtr key)
         {
-            OpCompletionDelegate value = null;
+            IOpCompletionCallback value = null;
             lock (myLock)
             {
@@ -90,42 +86,4 @@ namespace Grpc.Core.Internal
         }
 
-        private static void HandleBatchCompletion(bool success, BatchContextSafeHandle ctx, BatchCompletionDelegate callback)
-        {
-            try
-            {
-                callback(success, ctx);
-            }
-            catch (Exception e)
-            {
-                Logger.Error(e, ""Exception occured while invoking batch completion delegate."");
-            }
-            finally
-            {
-                if (ctx != null)
-                {
-                    ctx.Dispose();
-                }
-            }
-        }
-
-        private static void HandleRequestCallCompletion(bool success, RequestCallContextSafeHandle ctx, RequestCallCompletionDelegate callback)
-        {
-            try
-            {
-                callback(success, ctx);
-            }
-            catch (Exception e)
-            {
-                Logger.Error(e, ""Exception occured while invoking request call completion delegate."");
-            }
-            finally
-            {
-                if (ctx != null)
-                {
-                    ctx.Dispose();
-                }
-            }
-        }
-
         /// <summary>
         /// IntPtr doesn't implement <c>IEquatable{IntPtr}</c> so we need to use custom comparer to avoid boxing.
diff --git a/src/csharp/Grpc.Core/Internal/GrpcThreadPool.cs b/src/csharp/Grpc.Core/Internal/GrpcThreadPool.cs
index f7f723c00b..bd0229a9dd 100644
--- a/src/csharp/Grpc.Core/Internal/GrpcThreadPool.cs
+++ b/src/csharp/Grpc.Core/Internal/GrpcThreadPool.cs
@@ -69,6 +69,6 @@ namespace Grpc.Core.Internal
                 ""Thread pool size cannot be smaller than the number of completion queues used."");
 
-            this.runCompletionQueueEventCallbackSuccess = new WaitCallback((callback) => RunCompletionQueueEventCallback((OpCompletionDelegate) callback, true));
-            this.runCompletionQueueEventCallbackFailure = new WaitCallback((callback) => RunCompletionQueueEventCallback((OpCompletionDelegate) callback, false));
+            this.runCompletionQueueEventCallbackSuccess = new WaitCallback((callback) => RunCompletionQueueEventCallback((IOpCompletionCallback) callback, true));
+            this.runCompletionQueueEventCallbackFailure = new WaitCallback((callback) => RunCompletionQueueEventCallback((IOpCompletionCallback) callback, false));
         }
 
@@ -226,9 +226,9 @@ namespace Grpc.Core.Internal
         }
 
-        private void RunCompletionQueueEventCallback(OpCompletionDelegate callback, bool success)
+        private void RunCompletionQueueEventCallback(IOpCompletionCallback callback, bool success)
         {
             try
             {
-                callback(success);
+                callback.OnComplete(success);
             }
             catch (Exception e)
diff --git a/src/csharp/Grpc.Core/Internal/NativeMethods.cs b/src/csharp/Grpc.Core/Internal/NativeMethods.cs
index 22faa19d9b..d517252cfe 100644
--- a/src/csharp/Grpc.Core/Internal/NativeMethods.cs
+++ b/src/csharp/Grpc.Core/Internal/NativeMethods.cs
@@ -30,4 +30,6 @@ using Grpc.Core.Utils;
 namespace Grpc.Core.Internal
 {
+    internal delegate void NativeCallbackTestDelegate(bool success);
+
     /// <summary>
     /// Provides access to all native methods provided by <c>NativeExtension</c>.
@@ -421,5 +423,5 @@ namespace Grpc.Core.Internal
             public delegate int gprsharp_sizeof_timespec_delegate();
 
-            public delegate CallError grpcsharp_test_callback_delegate([MarshalAs(UnmanagedType.FunctionPtr)] OpCompletionDelegate callback);
+            public delegate CallError grpcsharp_test_callback_delegate([MarshalAs(UnmanagedType.FunctionPtr)] NativeCallbackTestDelegate callback);
             public delegate IntPtr grpcsharp_test_nop_delegate(IntPtr ptr);
             public delegate void grpcsharp_test_override_method_delegate(string methodName, string variant);
diff --git a/src/csharp/Grpc.Core/Internal/RequestCallContextSafeHandle.cs b/src/csharp/Grpc.Core/Internal/RequestCallContextSafeHandle.cs
index b7af0c102d..09f5c3e452 100644
--- a/src/csharp/Grpc.Core/Internal/RequestCallContextSafeHandle.cs
+++ b/src/csharp/Grpc.Core/Internal/RequestCallContextSafeHandle.cs
@@ -20,4 +20,5 @@ using System;
 using System.Runtime.InteropServices;
 using Grpc.Core;
+using Grpc.Core.Logging;
 
 namespace Grpc.Core.Internal
@@ -26,7 +27,8 @@ namespace Grpc.Core.Internal
     /// grpcsharp_request_call_context
     /// </summary>
-    internal class RequestCallContextSafeHandle : SafeHandleZeroIsInvalid
+    internal class RequestCallContextSafeHandle : SafeHandleZeroIsInvalid, IOpCompletionCallback
     {
         static readonly NativeMethods Native = NativeMethods.Get();
+        static readonly ILogger Logger = GrpcEnvironment.Logger.ForType<RequestCallContextSafeHandle>();
 
         private RequestCallContextSafeHandle()
@@ -47,4 +49,6 @@ namespace Grpc.Core.Internal
         }
 
+        public RequestCallCompletionDelegate CompletionCallback { get; set; }
+
         // Gets data of server_rpc_new completion.
         public ServerRpcNew GetServerRpcNew(Server server)
@@ -73,4 +77,21 @@ namespace Grpc.Core.Internal
             return true;
         }
+
+        void IOpCompletionCallback.OnComplete(bool success)
+        {
+            try
+            {
+                CompletionCallback(success, this);
+            }
+            catch (Exception e)
+            {
+                Logger.Error(e, ""Exception occured while invoking request call completion delegate."");
+            }
+            finally
+            {
+                CompletionCallback = null;
+                Dispose();
+            }
+        }
     }
 }
diff --git a/src/csharp/Grpc.Microbenchmarks/CompletionRegistryBenchmark.cs b/src/csharp/Grpc.Microbenchmarks/CompletionRegistryBenchmark.cs
index 810de119a8..0e2fb070f1 100644
--- a/src/csharp/Grpc.Microbenchmarks/CompletionRegistryBenchmark.cs
+++ b/src/csharp/Grpc.Microbenchmarks/CompletionRegistryBenchmark.cs
@@ -53,11 +53,11 @@ namespace Grpc.Microbenchmarks
             var completionRegistry = new CompletionRegistry(environment);
             var ctx = BatchContextSafeHandle.Create();
-            var completionDelegate = new OpCompletionDelegate((success) => {});
   
             var stopwatch = Stopwatch.StartNew();
             for (int i = 0; i < iterations; i++)
             {
-                completionRegistry.Register(ctx.DangerousGetHandle(), completionDelegate);
+                completionRegistry.Register(ctx.Handle, ctx);
                 var callback = completionRegistry.Extract(completionRegistry.LastRegisteredKey);
+                // NOTE: we are not calling the callback to avoid disposing ctx.
             }
             stopwatch.Stop();
@@ -66,4 +66,12 @@ namespace Grpc.Microbenchmarks
             ctx.Dispose();
         }
+
+        private class NopCompletionCallback : IOpCompletionCallback
+        {
+            public void OnComplete(bool success)
+            {
+
+            }
+        }
     }
 }
diff --git a/src/csharp/Grpc.Microbenchmarks/SendMessageBenchmark.cs b/src/csharp/Grpc.Microbenchmarks/SendMessageBenchmark.cs
index de67874580..6a8a29d770 100644
--- a/src/csharp/Grpc.Microbenchmarks/SendMessageBenchmark.cs
+++ b/src/csharp/Grpc.Microbenchmarks/SendMessageBenchmark.cs
@@ -69,5 +69,5 @@ namespace Grpc.Microbenchmarks
                 call.StartSendMessage(sendCompletionHandler, payload, writeFlags, false);
                 var callback = completionRegistry.Extract(completionRegistry.LastRegisteredKey);
-                callback(true);
+                callback.OnComplete(true);
             }
             stopwatch.Stop();
","avoid unnecessary allocation in completion registry

"
168,C++,833e6688f1330eaf2e58119acb6ac084963e5bd2,https://github.com/topjohnwu/Magisk/commit/833e6688f1330eaf2e58119acb6ac084963e5bd2,P,topjohnwu,Magisk,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 210, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/app/src/main/res/values-uk/strings.xml b/app/src/main/res/values-uk/strings.xml
new file mode 100644
index 000000000..2eca4a646
--- /dev/null
+++ b/app/src/main/res/values-uk/strings.xml
@@ -0,0 +1,227 @@
+<resources>
+
+    <!--Welcome Activity-->
+    <string name=""navigation_drawer_open"">  </string>
+    <string name=""navigation_drawer_close"">  </string>
+    <string name=""modules""></string>
+    <string name=""downloads""></string>
+    <string name=""superuser""></string>
+    <string name=""log""></string>
+    <string name=""settings""></string>
+    <string name=""status""></string>
+    <string name=""install""></string>
+
+    <!--Status Fragment-->
+    <string name=""magisk_version""> Magisk v%1$s</string>
+    <string name=""magisk_version_core_only""> Magisk v%1$s ( )</string>
+    <string name=""magisk_version_error"">Magisk  </string>
+
+    <string name=""checking_for_updates""> </string>
+    <string name=""magisk_update_available""> Magisk v%1$s!</string>
+    <string name=""cannot_check_updates"">   </string>
+    <string name=""up_to_date"">   %1$s</string>
+    <string name=""root_error"">Root ,   </string>
+    <string name=""not_rooted"">Root </string>
+    <string name=""proper_root""> root-</string>
+    <string name=""safetyNet_check_text"">  SafetyNet</string>
+    <string name=""checking_safetyNet_status"">  SafetyNet</string>
+    <string name=""safetyNet_check_success""> SafetyNet </string>
+    <string name=""safetyNet_connection_failed"">   Google API</string>
+    <string name=""safetyNet_connection_suspended"">  Google API  </string>
+    <string name=""safetyNet_no_response"">   SafetyNet</string>
+    <string name=""safetyNet_fail""> SafetyNet  :   CTS</string>
+    <string name=""safetyNet_pass""> SafetyNet </string>
+    <string name=""safetyNet_network_loss"">   </string>
+    <string name=""safetyNet_service_disconnected""> </string>
+    <string name=""safetyNet_res_invalid""> </string>
+    <string name=""root_info_warning"">  </string>
+
+    <!--Install Fragment-->
+    <string name=""auto_detect"">() %1$s</string>
+    <string name=""cannot_auto_detect"">( )</string>
+    <string name=""boot_image_title""> boot-</string>
+    <string name=""detect_button""></string>
+    <string name=""advanced_settings_title""> </string>
+    <string name=""keep_force_encryption"">  </string>
+    <string name=""keep_dm_verity""> dm-verity</string>
+    <string name=""current_magisk_title"">  Magisk: %1$s</string>
+    <string name=""install_magisk_title"">  Magisk: %1$s</string>
+    <string name=""uninstall""></string>
+    <string name=""reboot_countdown"">  %1$d</string>
+    <string name=""uninstall_magisk_title""> Magisk</string>
+    <string name=""uninstall_magisk_msg"">      , MagiskSU,    ,    .\n,   ?</string>
+    <string name=""version_none"">( )</string>
+    <string name=""reinstall""></string>
+    <string name=""update""></string>
+    
+    <!--Module Fragment-->
+    <string name=""no_info_provided"">(  )</string>
+    <string name=""no_modules_found"">  </string>
+    <string name=""update_file_created"">   </string>
+    <string name=""remove_file_created"">   </string>
+    <string name=""remove_file_deleted"">    </string>
+    <string name=""disable_file_created"">   </string>
+    <string name=""disable_file_removed"">   </string>
+    <string name=""author"">: %1$s</string>
+    <string name=""fab_flash_zip"">   </string>
+
+    <!--Repo Fragment-->
+    <string name=""update_available""> </string>
+    <string name=""installed""></string>
+    <string name=""not_installed""> </string>
+
+    <!--Log Fragment-->
+    <string name=""menuSaveToSd"">   \'</string>
+    <string name=""menuReload""></string>
+    <string name=""menuClearLog""> </string>
+    <string name=""logs_cleared""> </string>
+    <string name=""log_is_empty""> </string>
+    <string name=""logs_save_failed"">      \':</string>
+
+    <!--About Activity-->
+    <string name=""about""> </string>
+    <string name=""app_developers""> </string>
+    <string name=""app_developers_""><![CDATA[  <a href=""https://github.com/topjohnwu"">topjohnwu</a>,   <a href=""https://github.com/d8ahazard"">Digitalhigh</a>  <a href=""https://github.com/dvdandroid"">Dvdandroid</a>.]]></string>
+    <string name=""app_changelog""> </string>
+    <string name=""translators""></string>
+    <string name=""app_version""></string>
+    <string name=""app_source_code""> </string>
+    <string name=""donation""> </string>
+    <string name=""app_translators""></string>
+    <string name=""support_thread""> </string>
+
+    <!--Toasts, Dialogs-->
+    <string name=""permissionNotGranted"">          </string>
+    <string name=""no_thanks"">, </string>
+    <string name=""yes""></string>
+    <string name=""ok"">OK</string>
+    <string name=""close""></string>
+    <string name=""repo_install_title""> %1$s</string>
+    <string name=""repo_install_msg"">  %1$s ?</string>
+    <string name=""download_install"">  </string>
+    <string name=""download""></string>
+    <string name=""goto_install"">   \""\""</string>
+    <string name=""download_file_error"">  </string>
+    <string name=""install_error"">   </string>
+    <string name=""invalid_zip"">    Magisk!</string>
+    <string name=""reboot_title""> !</string>
+    <string name=""reboot_msg"">  ?</string>
+    <string name=""reboot""></string>
+    <string name=""copying_msg"">    </string>
+    <string name=""zip_install_progress_title""></string>
+    <string name=""zip_unzip_msg"">  </string>
+    <string name=""zip_process_msg"">  </string>
+    <string name=""zip_install_progress_msg""> %1$s </string>
+    <string name=""no_magisk_title"">Magisk  !</string>
+    <string name=""no_magisk_msg"">    Magisk?</string>
+    <string name=""downloading_toast""> %1$s</string>
+    <string name=""magisk_update_title"">  Magisk!</string>
+    <string name=""settings_reboot_toast"">    </string>
+    <string name=""release_notes""> </string>
+    <string name=""repo_cache_cleared"">  </string>
+    <string name=""safetyNet_hide_notice"">   SafetyNet.\n  MagiskHide  </string>
+    <string name=""start_magiskhide""> MagiskHide </string>
+    <string name=""no_magisksu_title"">  MagiskSU!</string>
+    <string name=""no_magisksu_msg"">  root-   MagiskSU.  MagiskHide      root,      (, suhide)     SafetyNet</string>
+    <string name=""understand""></string>
+    <string name=""process_error""> </string>
+    <string name=""internal_storage""> :\n[ ]%1$s</string>
+    <string name=""zip_process_title""></string>
+    <string name=""manual_boot_image""> ,  boot-!</string>
+    <string name=""manager_update_title"">  Magisk Manager!</string>
+    <string name=""manager_download_install"">,    </string>
+    <string name=""magisk_updates""> Magisk</string>
+    <string name=""flashing""></string>
+
+    <!--Settings Activity -->
+    <string name=""settings_general_category""></string>
+    <string name=""settings_dark_theme_title""> </string>
+    <string name=""settings_dark_theme_summary"">  </string>
+    <string name=""settings_notification_title"">  </string>
+    <string name=""settings_notification_summary"">      ,    </string>
+    <string name=""settings_clear_cache_title""> </string>
+    <string name=""settings_clear_cache_summary"">     ,      </string>
+    <string name=""language""></string>
+    <string name=""system_default""> ()</string>
+
+    <string name=""settings_core_only_title"">  Magisk</string>
+    <string name=""settings_core_only_summary"">   ,     . MagiskSU, MagiskHide     </string>
+    <string name=""settings_magiskhide_summary""> Magisk   </string>
+    <string name=""settings_busybox_title""> BusyBox</string>
+    <string name=""settings_busybox_summary"">   Magisk busybox  xbin</string>
+    <string name=""settings_hosts_title""> </string>
+    <string name=""settings_hosts_summary"">      </string>
+
+    <string name=""settings_su_app_adb"">  ADB</string>
+    <string name=""settings_su_app""></string>
+    <string name=""settings_su_adb"">ADB</string>
+    <string name=""settings_su_disable""></string>
+    <string name=""settings_su_request_10"">10 </string>
+    <string name=""settings_su_request_20"">20 </string>
+    <string name=""settings_su_request_30"">30 </string>
+    <string name=""settings_su_request_60"">60 </string>
+    <string name=""superuser_access""> </string>
+    <string name=""auto_response""> </string>
+    <string name=""request_timeout""> </string>
+    <string name=""superuser_notification""> </string>
+    <string name=""request_timeout_summary"">%1$s .</string>
+    <string name=""settings_su_reauth_title""> </string>
+    <string name=""settings_su_reauth_summary"">     </string>
+
+    <string name=""multiuser_mode""> </string>
+    <string name=""settings_owner_only""> </string>
+    <string name=""settings_owner_manage""> </string>
+    <string name=""settings_user_independent""> </string>
+    <string name=""owner_only_summary"">   root-</string>
+    <string name=""owner_manage_summary"">    root-      </string>
+    <string name=""user_indepenent_summary"">     root-</string>
+    <string name=""multiuser_hint_owner_request"">  .  ,       </string>
+
+    <string name=""mount_namespace_mode"">   </string>
+    <string name=""settings_ns_global"">  </string>
+    <string name=""settings_ns_requester"">  </string>
+    <string name=""settings_ns_isolate"">  </string>
+    <string name=""global_summary"">      </string>
+    <string name=""requester_summary"">     </string>
+    <string name=""isolate_summary"">       </string>
+
+    <string name=""settings_development_category""></string>
+    <string name=""settings_developer_logging_title""> </string>
+    <string name=""settings_developer_logging_summary"">    </string>
+    <string name=""settings_shell_logging_title"">  </string>
+    <string name=""settings_shell_logging_summary"">        </string>
+
+    <!--Superuser-->
+    <string name=""su_request_title"">  </string>
+    <string name=""deny_with_str""> %1$s</string>
+    <string name=""deny""></string>
+    <string name=""prompt""></string>
+    <string name=""grant""></string>
+    <string name=""su_warning"">    .\n  ,   ,   .</string>
+    <string name=""forever""></string>
+    <string name=""once""></string>
+    <string name=""tenmin"">10 .</string>
+    <string name=""twentymin"">20 .</string>
+    <string name=""thirtymin"">30 .</string>
+    <string name=""sixtymin"">60 .</string>
+    <string name=""su_allow_toast"">%1$s   </string>
+    <string name=""su_deny_toast"">%1$s    </string>
+    <string name=""no_apps_found"">  </string>
+    <string name=""su_snack_grant"">%1$s   </string>
+    <string name=""su_snack_deny"">%1$s    </string>
+    <string name=""su_snack_notif_on"">  %1$s </string>
+    <string name=""su_snack_notif_off"">  %1$s </string>
+    <string name=""su_snack_log_on"">   %1$s </string>
+    <string name=""su_snack_log_off"">   %1$s </string>
+    <string name=""su_snack_revoke"">  %1$s </string>
+    <string name=""su_revoke_title"">?</string>
+    <string name=""su_revoke_msg"">    %1$s?</string>
+    <string name=""toast""> </string>
+    <string name=""none""></string>
+
+    <!--Superuser logs-->
+    <string name=""pid"">PID:\u0020</string>
+    <string name=""target_uid""> UID:\u0020</string>
+    <string name=""command"">:\u0020</string>
+
+</resources>
","Added Ukrainian translation

"
170,C++,82fff615d6e4c3c39e71f9470d1885be18ca782c,https://github.com/topjohnwu/Magisk/commit/82fff615d6e4c3c39e71f9470d1885be18ca782c,P,topjohnwu,Magisk,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/app/src/main/res/values-sk/strings.xml b/app/src/main/res/values-sk/strings.xml
index b2cc8d901..5cd000ac2 100644
--- a/app/src/main/res/values-sk/strings.xml
+++ b/app/src/main/res/values-sk/strings.xml
@@ -103,4 +103,5 @@
     <!-- MagiskHide -->
     <string name=""show_system_app"">Zobrazi systmov aplikcie</string>
+    <string name=""show_os_app"">Zobrazi aplikcie OS</string>
     <string name=""hide_filter_hint"">Filtrova poda nzvu</string>
     <string name=""hide_scroll_up"">Posun nahor</string>
@@ -110,4 +111,5 @@
     <!--Module Fragment-->
     <string name=""no_info_provided"">(Nie s k dispozcii iadne informcie)</string>
+    <string name=""reboot_userspace"">Softvrov retart</string>
     <string name=""reboot_recovery"">Retartova do Recovery</string>
     <string name=""reboot_bootloader"">Retartova do Bootloader</string>
@@ -219,6 +221,7 @@
     <string name=""done"">Hotovo!</string>
     <string name=""failure"">Zlyhalo</string>
-    <string name=""hide_manager_title"">Skrytie Magisk Managera</string>
-    <string name=""hide_manager_fail_toast"">Skrytie Magisk Manager zlyhalo.</string>
+    <string name=""hide_manager_title"">Skrvanie Magisk Managera</string>
+    <string name=""hide_manager_fail_toast"">Skrytie Magisk Managera zlyhalo</string>
+    <string name=""restore_manager_fail_toast"">Obnovenie Magisk Managera zlyhalo</string>
     <string name=""open_link_failed_toast"">Nepodarilo sa njs vhodn aplikciu na otvorenie odkazu</string>
     <string name=""complete_uninstall"">plne odintalova</string>
","Update Slovak translation

"
174,C++,23a33b43513734888ca2391849751f8c6153b9d5,https://github.com/topjohnwu/Magisk/commit/23a33b43513734888ca2391849751f8c6153b9d5,P,topjohnwu,Magisk,"[9, 0, 43, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 23, 3, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/app/src/main/java/com/topjohnwu/magisk/core/Config.kt b/app/src/main/java/com/topjohnwu/magisk/core/Config.kt
index e8f425026..32378f3e6 100644
--- a/app/src/main/java/com/topjohnwu/magisk/core/Config.kt
+++ b/app/src/main/java/com/topjohnwu/magisk/core/Config.kt
@@ -61,5 +61,4 @@ object Config : PreferenceModel, DBConfig {
         // system state
         const val MAGISKHIDE = ""magiskhide""
-        const val COREONLY = ""disable""
     }
 
@@ -130,6 +129,4 @@ object Config : PreferenceModel, DBConfig {
     var checkUpdate by preference(Key.CHECK_UPDATES, true)
     var magiskHide by preference(Key.MAGISKHIDE, true)
-    @JvmStatic
-    var coreOnly by preference(Key.COREONLY, false)
     var showSystemApp by preference(Key.SHOW_SYSTEM_APP, false)
     @JvmStatic
@@ -167,7 +164,4 @@ object Config : PreferenceModel, DBConfig {
             }
 
-            // Get actual state
-            putBoolean(Key.COREONLY, Const.MAGISK_DISABLE_FILE.exists())
-
             // Write database configs
             putString(Key.ROOT_ACCESS, rootMode.toString())
diff --git a/app/src/main/java/com/topjohnwu/magisk/core/Const.kt b/app/src/main/java/com/topjohnwu/magisk/core/Const.kt
index bcd96628e..62d700969 100644
--- a/app/src/main/java/com/topjohnwu/magisk/core/Const.kt
+++ b/app/src/main/java/com/topjohnwu/magisk/core/Const.kt
@@ -2,5 +2,4 @@ package com.topjohnwu.magisk.core
 
 import android.os.Process
-import java.io.File
 
 object Const {
@@ -9,5 +8,4 @@ object Const {
     lateinit var MAGISKTMP: String
     val MAGISK_PATH get() = ""$MAGISKTMP/modules""
-    var MAGISK_DISABLE_FILE = File(""xxx"")
     const val TMP_FOLDER_PATH = ""/dev/tmp""
     const val MAGISK_LOG = ""/cache/magisk.log""
diff --git a/app/src/main/java/com/topjohnwu/magisk/core/utils/RootInit.kt b/app/src/main/java/com/topjohnwu/magisk/core/utils/RootInit.kt
index 21b30b218..dca3d8a45 100644
--- a/app/src/main/java/com/topjohnwu/magisk/core/utils/RootInit.kt
+++ b/app/src/main/java/com/topjohnwu/magisk/core/utils/RootInit.kt
@@ -9,5 +9,4 @@ import com.topjohnwu.magisk.extensions.rawResource
 import com.topjohnwu.superuser.Shell
 import com.topjohnwu.superuser.ShellUtils
-import com.topjohnwu.superuser.io.SuFile
 
 class RootInit : Shell.Initializer() {
@@ -30,5 +29,4 @@ class RootInit : Shell.Initializer() {
         if (shell.isRoot) {
             job.add(context.rawResource(R.raw.util_functions))
-            Const.MAGISK_DISABLE_FILE = SuFile(""/cache/.disable_magisk"")
         }
         job.add(""mm_init"").exec()
diff --git a/app/src/main/java/com/topjohnwu/magisk/core/view/Shortcuts.kt b/app/src/main/java/com/topjohnwu/magisk/core/view/Shortcuts.kt
index f4d0a3c78..a86e4d267 100644
--- a/app/src/main/java/com/topjohnwu/magisk/core/view/Shortcuts.kt
+++ b/app/src/main/java/com/topjohnwu/magisk/core/view/Shortcuts.kt
@@ -68,5 +68,5 @@ object Shortcuts {
             )
         }
-        if (!Config.coreOnly && Info.env.isActive) {
+        if (Info.env.isActive) {
             shortCuts.add(
                 ShortcutInfo.Builder(context, ""modules"")
diff --git a/app/src/main/java/com/topjohnwu/magisk/model/entity/recycler/ModuleRvItem.kt b/app/src/main/java/com/topjohnwu/magisk/model/entity/recycler/ModuleRvItem.kt
index 111154846..b9108f528 100644
--- a/app/src/main/java/com/topjohnwu/magisk/model/entity/recycler/ModuleRvItem.kt
+++ b/app/src/main/java/com/topjohnwu/magisk/model/entity/recycler/ModuleRvItem.kt
@@ -14,17 +14,4 @@ import com.topjohnwu.magisk.ui.module.ModuleViewModel
 import com.topjohnwu.magisk.utils.KObservableField
 
-object SafeModeNotice : ComparableRvItem<SafeModeNotice>() {
-    override val layoutRes = R.layout.item_safe_mode_notice
-
-    override fun onBindingBound(binding: ViewDataBinding) {
-        super.onBindingBound(binding)
-        val params = binding.root.layoutParams as? StaggeredGridLayoutManager.LayoutParams
-        params?.isFullSpan = true
-    }
-
-    override fun contentSameAs(other: SafeModeNotice) = this == other
-    override fun itemSameAs(other: SafeModeNotice) = this === other
-}
-
 object InstallModule : ComparableRvItem<InstallModule>() {
     override val layoutRes = R.layout.item_module_download
diff --git a/app/src/main/java/com/topjohnwu/magisk/ui/home/HomeViewModel.kt b/app/src/main/java/com/topjohnwu/magisk/ui/home/HomeViewModel.kt
index 7435116fa..fd49bfb29 100644
--- a/app/src/main/java/com/topjohnwu/magisk/ui/home/HomeViewModel.kt
+++ b/app/src/main/java/com/topjohnwu/magisk/ui/home/HomeViewModel.kt
@@ -46,5 +46,5 @@ class HomeViewModel(
     val stateMagiskInstalledVersion get() =
         ""${Info.env.magiskVersionString} (${Info.env.magiskVersionCode})""
-    val stateMagiskMode get() = (if (Config.coreOnly) R.string.home_status_safe else R.string.home_status_normal).res()
+    val stateMagiskMode get() = R.string.home_status_normal.res()
 
     val stateManagerRemoteVersion = KObservableField(R.string.loading.res())
diff --git a/app/src/main/java/com/topjohnwu/magisk/ui/module/ModuleViewModel.kt b/app/src/main/java/com/topjohnwu/magisk/ui/module/ModuleViewModel.kt
index 5a8f38edf..2b11492c0 100644
--- a/app/src/main/java/com/topjohnwu/magisk/ui/module/ModuleViewModel.kt
+++ b/app/src/main/java/com/topjohnwu/magisk/ui/module/ModuleViewModel.kt
@@ -81,5 +81,4 @@ class ModuleViewModel(
     private val itemsUpdatableHelpers = ObservableArrayList<TextItem>()
 
-    private val itemsCoreOnly = ObservableArrayList<SafeModeNotice>()
     private val itemsInstalled = diffListOf<ModuleItem>()
     private val itemsUpdatable = diffListOf<RepoItem.Update>()
@@ -95,5 +94,4 @@ class ModuleViewModel(
     val adapter = adapterOf<ComparableRvItem<*>>()
     val items = MergeObservableList<ComparableRvItem<*>>()
-        .insertList(itemsCoreOnly)
         .insertItem(InstallModule)
         .insertItem(sectionUpdate)
@@ -177,5 +175,4 @@ class ModuleViewModel(
 
     override fun refresh(): Disposable {
-        updateCoreOnlyWarning()
         if (itemsRemote.isEmpty())
             loadRemote()
@@ -304,13 +301,4 @@ class ModuleViewModel(
     }
 
-    private fun updateCoreOnlyWarning() {
-        if (Config.coreOnly) {
-            if (itemsCoreOnly.isNotEmpty()) return
-            itemsCoreOnly.add(SafeModeNotice)
-        } else {
-            itemsCoreOnly.clear()
-        }
-    }
-
     // ---
 
diff --git a/app/src/main/java/com/topjohnwu/magisk/ui/settings/SettingsItems.kt b/app/src/main/java/com/topjohnwu/magisk/ui/settings/SettingsItems.kt
index 6b44c5998..43536debe 100644
--- a/app/src/main/java/com/topjohnwu/magisk/ui/settings/SettingsItems.kt
+++ b/app/src/main/java/com/topjohnwu/magisk/ui/settings/SettingsItems.kt
@@ -5,5 +5,4 @@ import android.os.Build
 import android.os.Environment
 import android.view.LayoutInflater
-import android.widget.Toast
 import androidx.databinding.Bindable
 import com.topjohnwu.magisk.BR
@@ -211,19 +210,4 @@ object Magisk : SettingsItem.Section() {
 }
 
-object SafeMode : SettingsItem.Toggle() {
-    override val title = R.string.settings_safe_mode_title.asTransitive()
-    // Use old placeholder for now, will update text once native implementation is changed
-    override val description = R.string.settings_core_only_summary.asTransitive()
-    override var value by bindableValue(Config.coreOnly) {
-        if (Config.coreOnly == it) return@bindableValue
-        Config.coreOnly = it
-        when {
-            it -> runCatching { Const.MAGISK_DISABLE_FILE.createNewFile() }
-            else -> Const.MAGISK_DISABLE_FILE.delete()
-        }
-        Utils.toast(R.string.settings_reboot_toast, Toast.LENGTH_LONG)
-    }
-}
-
 object MagiskHide : SettingsItem.Toggle() {
     override val title = R.string.magiskhide.asTransitive()
diff --git a/app/src/main/java/com/topjohnwu/magisk/ui/settings/SettingsViewModel.kt b/app/src/main/java/com/topjohnwu/magisk/ui/settings/SettingsViewModel.kt
index 991c58866..6b2f0ec4f 100644
--- a/app/src/main/java/com/topjohnwu/magisk/ui/settings/SettingsViewModel.kt
+++ b/app/src/main/java/com/topjohnwu/magisk/ui/settings/SettingsViewModel.kt
@@ -64,5 +64,5 @@ class SettingsViewModel(
             list.addAll(listOf(
                 Magisk,
-                MagiskHide, SystemlessHosts, SafeMode
+                MagiskHide, SystemlessHosts
             ))
         }
diff --git a/app/src/main/res/layout/item_module_md2.xml b/app/src/main/res/layout/item_module_md2.xml
index bbc4a7792..13fda3ff6 100644
--- a/app/src/main/res/layout/item_module_md2.xml
+++ b/app/src/main/res/layout/item_module_md2.xml
@@ -22,8 +22,8 @@
     <com.google.android.material.card.MaterialCardView
         style=""@style/WidgetFoundation.Card.Variant""
-        isEnabled=""@{!Config.coreOnly &amp;&amp; !item.removed}""
+        isEnabled=""@{!item.removed}""
         android:layout_width=""match_parent""
         android:layout_height=""wrap_content""
-        android:alpha=""@{item.enabled &amp;&amp; !Config.coreOnly ? 1f : .5f}""
+        android:alpha=""@{item.enabled ? 1f : .5f}""
         android:onClick=""@{() -> item.toggle()}""
         tools:layout_gravity=""center""
@@ -83,5 +83,5 @@
                 android:id=""@+id/module_indicator""
                 style=""@style/WidgetFoundation.Switch""
-                isSelected=""@{item.enabled &amp;&amp; !Config.coreOnly}""
+                isSelected=""@{item.enabled}""
                 android:layout_marginEnd=""@dimen/l_50""
                 app:layout_constraintBottom_toBottomOf=""@+id/module_version_author""
diff --git a/app/src/main/res/layout/item_safe_mode_notice.xml b/app/src/main/res/layout/item_safe_mode_notice.xml
deleted file mode 100644
index f99e806f4..000000000
--- a/app/src/main/res/layout/item_safe_mode_notice.xml
+++ /dev/null
@@ -1,30 +0,0 @@
-<?xml version=""1.0"" encoding=""utf-8""?>
-<layout xmlns:android=""http://schemas.android.com/apk/res/android""
-    xmlns:app=""http://schemas.android.com/apk/res-auto"">
-
-    <data>
-
-        <variable
-            name=""item""
-            type=""com.topjohnwu.magisk.model.entity.recycler.SafeModeNotice"" />
-
-    </data>
-
-    <com.google.android.material.card.MaterialCardView
-        style=""@style/WidgetFoundation.Card""
-        android:layout_width=""match_parent""
-        android:layout_height=""wrap_content""
-        app:cardBackgroundColor=""?colorError"">
-
-        <androidx.appcompat.widget.AppCompatTextView
-            android:layout_width=""match_parent""
-            android:layout_height=""wrap_content""
-            android:gravity=""center""
-            android:padding=""@dimen/l1""
-            android:text=""@string/module_safe_mode_message""
-            android:textAppearance=""@style/AppearanceFoundation.Caption.OnPrimary""
-            android:textStyle=""bold"" />
-
-    </com.google.android.material.card.MaterialCardView>
-
-</layout>
\ No newline at end of file
","Remove core only mode

Replaced by native safe mode

"
178,C++,d1735172127c37bfee7a816d96d34647cfff6494,https://github.com/nlohmann/json/commit/d1735172127c37bfee7a816d96d34647cfff6494,P,nlohmann,json,"[1, 8, 0, 0, 0, 0, 0, 1, 4, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 8, 0, 0]","diff --git a/src/json.hpp b/src/json.hpp
index 5dc8e67c..afa35baa 100644
--- a/src/json.hpp
+++ b/src/json.hpp
@@ -874,6 +874,15 @@ class basic_json
                 }
 
+                case value_t::null:
+                {
+                    break;
+                }
+
                 default:
                 {
+                    if (t == value_t::null)
+                    {
+                        throw std::domain_error(""961c151d2e87f2686a955a9be24d316f1362bf21""); // LCOV_EXCL_LINE
+                    }
                     break;
                 }
diff --git a/src/json.hpp.re2c b/src/json.hpp.re2c
index 49bccb02..db0b4c88 100644
--- a/src/json.hpp.re2c
+++ b/src/json.hpp.re2c
@@ -874,6 +874,15 @@ class basic_json
                 }
 
+                case value_t::null:
+                {
+                    break;
+                }
+
                 default:
                 {
+                    if (t == value_t::null)
+                    {
+                        throw std::domain_error(""961c151d2e87f2686a955a9be24d316f1362bf21""); // LCOV_EXCL_LINE
+                    }
                     break;
                 }
diff --git a/test/src/unit-allocator.cpp b/test/src/unit-allocator.cpp
index c439c1c3..04f6ac9d 100644
--- a/test/src/unit-allocator.cpp
+++ b/test/src/unit-allocator.cpp
@@ -142,5 +142,8 @@ TEST_CASE(""controlled bad_alloc"")
                 next_construct_fails = false;
                 auto t = my_json::value_t::object;
-                auto clean_up = [](my_json::json_value& j){ my_allocator_clean_up(j.object); };
+                auto clean_up = [](my_json::json_value & j)
+                {
+                    my_allocator_clean_up(j.object);
+                };
                 CHECK_NOTHROW(my_json::json_value j(t); clean_up(j));
                 next_construct_fails = true;
@@ -152,5 +155,8 @@ TEST_CASE(""controlled bad_alloc"")
                 next_construct_fails = false;
                 auto t = my_json::value_t::array;
-                auto clean_up = [](my_json::json_value& j){ my_allocator_clean_up(j.array); };
+                auto clean_up = [](my_json::json_value & j)
+                {
+                    my_allocator_clean_up(j.array);
+                };
                 CHECK_NOTHROW(my_json::json_value j(t); clean_up(j));
                 next_construct_fails = true;
@@ -162,5 +168,8 @@ TEST_CASE(""controlled bad_alloc"")
                 next_construct_fails = false;
                 auto t = my_json::value_t::string;
-                auto clean_up = [](my_json::json_value& j){ my_allocator_clean_up(j.string); };
+                auto clean_up = [](my_json::json_value & j)
+                {
+                    my_allocator_clean_up(j.string);
+                };
                 CHECK_NOTHROW(my_json::json_value j(t); clean_up(j));
                 next_construct_fails = true;
@@ -174,5 +183,8 @@ TEST_CASE(""controlled bad_alloc"")
             next_construct_fails = false;
             my_json::string_t v(""foo"");
-            auto clean_up = [](my_json::json_value& j){ my_allocator_clean_up(j.string); };
+            auto clean_up = [](my_json::json_value & j)
+            {
+                my_allocator_clean_up(j.string);
+            };
             CHECK_NOTHROW(my_json::json_value j(v); clean_up(j));
             next_construct_fails = true;
",":lipstick: clean up

"
187,C++,aa10382629c291a50584d9aaf3a9f8f03824e4fd,https://github.com/nlohmann/json/commit/aa10382629c291a50584d9aaf3a9f8f03824e4fd,C,nlohmann,json,"[2, 8, 0, 4, 2, 0, 2, 1, 12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/include/nlohmann/detail/input/input_adapters.hpp b/include/nlohmann/detail/input/input_adapters.hpp
index 79a19c17..e11fb896 100644
--- a/include/nlohmann/detail/input/input_adapters.hpp
+++ b/include/nlohmann/detail/input/input_adapters.hpp
@@ -61,6 +61,6 @@ class input_stream_adapter : public input_adapter_protocol
     {
         // clear stream flags; we use underlying streambuf I/O, do not
-        // maintain ifstream flags
-        is.clear();
+        // maintain ifstream flags, except eof
+        is.clear(is.rdstate() & std::ios::eofbit);
     }
 
@@ -80,5 +80,9 @@ class input_stream_adapter : public input_adapter_protocol
     std::char_traits<char>::int_type get_character() override
     {
-        return sb.sbumpc();
+        auto res = sb.sbumpc();
+        // set eof manually, as we don't use the istream interface.
+        if (res == EOF)
+            is.clear(is.rdstate() | std::ios::eofbit);
+        return res;
     }
 
diff --git a/single_include/nlohmann/json.hpp b/single_include/nlohmann/json.hpp
index 931e7b36..873e75d5 100644
--- a/single_include/nlohmann/json.hpp
+++ b/single_include/nlohmann/json.hpp
@@ -2110,6 +2110,6 @@ class input_stream_adapter : public input_adapter_protocol
     {
         // clear stream flags; we use underlying streambuf I/O, do not
-        // maintain ifstream flags
-        is.clear();
+        // maintain ifstream flags, except eof
+        is.clear(is.rdstate() & std::ios::eofbit);
     }
 
@@ -2129,5 +2129,9 @@ class input_stream_adapter : public input_adapter_protocol
     std::char_traits<char>::int_type get_character() override
     {
-        return sb.sbumpc();
+        auto res = sb.sbumpc();
+        // set eof manually, as we don't use the istream interface.
+        if (res == EOF)
+            is.clear(is.rdstate() | std::ios::eofbit);
+        return res;
     }
 
diff --git a/test/src/unit-regression.cpp b/test/src/unit-regression.cpp
index 5f007980..058c71c0 100644
--- a/test/src/unit-regression.cpp
+++ b/test/src/unit-regression.cpp
@@ -1709,2 +1709,15 @@ TEST_CASE(""regression tests"")
     }
 }
+
+TEST_CASE(""regression tests, exceptions dependent"", ""[!throws]"")
+{
+    SECTION(""issue #1340 - eof not set on exhausted input stream"")
+    {
+        std::stringstream s(""{}{}"");
+        json j;
+        s >> j;
+        s >> j;
+        CHECK_THROWS_AS(s >> j, json::parse_error const&);
+        CHECK(s.eof());
+    }
+}
","Set eofbit on exhausted input stream.

	Fix issue #1340.

        The eofbit is set manually since we don't go through the
	stream interface. We could maybe use the stream interface
	instead, but there are some assumptions regarding which
	exception go through, so this seems to be the most prudent
	approach for now.

"
192,C++,f57e23351f416d15cb6dc2905f2abade5a632fc3,https://github.com/google/leveldb/commit/f57e23351f416d15cb6dc2905f2abade5a632fc3,A,google,leveldb,"[4, 206, 51, 30, 51, 1, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 73, 20, 8, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/Makefile b/Makefile
index 84f77ab..0537762 100644
--- a/Makefile
+++ b/Makefile
@@ -14,35 +14,30 @@ OPT = -O2 -DNDEBUG       # (A) Production use (optimized mode)
 #-----------------------------------------------
 
+# detect what platform we're building on
+$(shell sh ./build_detect_platform)
+# this file is generated by build_detect_platform to set build flags
+include build_config.mk
 
-UNAME := $(shell uname)
-
-ifeq ($(UNAME), Darwin)
-# To build for iOS, set PLATFORM=IOS.
-ifndef PLATFORM
-PLATFORM=OSX
-endif # PLATFORM
-PLATFORM_CFLAGS = -DLEVELDB_PLATFORM_OSX
-PORT_MODULE = port_osx.o
-else # UNAME
-PLATFORM_CFLAGS = -DLEVELDB_PLATFORM_POSIX -std=c++0x
-PORT_MODULE = port_posix.o
-endif # UNAME
-
-# Set 'SNAPPY' to 1 if you have the Snappy compression library
-# installed and want to enable its use in LevelDB
+# If Snappy is installed, add compilation and linker flags
 # (see http://code.google.com/p/snappy/)
-SNAPPY=0
-
-ifeq ($(SNAPPY), 0)
+ifeq ($(SNAPPY), 1)
+SNAPPY_CFLAGS=-DSNAPPY
+SNAPPY_LDFLAGS=-lsnappy
+else
 SNAPPY_CFLAGS=
 SNAPPY_LDFLAGS=
+endif
+
+# If Google Perf Tools are installed, add compilation and linker flags
+# (see http://code.google.com/p/google-perftools/)
+ifeq ($(GOOGLE_PERFTOOLS), 1)
+GOOGLE_PERFTOOLS_LDFLAGS=-ltcmalloc
 else
-SNAPPY_CFLAGS=-DSNAPPY
-SNAPPY_LDFLAGS=-lsnappy
+GOOGLE_PERFTOOLS_LDFLAGS=
 endif
 
-CFLAGS = -c -I. -I./include $(PLATFORM_CFLAGS) $(OPT) $(SNAPPY_CFLAGS)
+CFLAGS = -c -I. -I./include $(PORT_CFLAGS) $(PLATFORM_CCFLAGS) $(OPT) $(SNAPPY_CFLAGS)
 
-LDFLAGS=-lpthread $(SNAPPY_LDFLAGS)
+LDFLAGS=$(PLATFORM_LDFLAGS) $(SNAPPY_LDFLAGS) $(GOOGLE_PERFTOOLS_LDFLAGS)
 
 LIBOBJECTS = \
@@ -60,5 +55,5 @@ LIBOBJECTS = \
 	./db/version_set.o \
 	./db/write_batch.o \
-	./port/$(PORT_MODULE) \
+	./port/port_posix.o \
 	./table/block.o \
 	./table/block_builder.o \
@@ -106,17 +101,13 @@ PROGRAMS = db_bench $(TESTS)
 LIBRARY = libleveldb.a
 
-ifeq ($(PLATFORM), IOS)
-# Only XCode can build executable applications for iOS.
 all: $(LIBRARY)
-else
-all: $(PROGRAMS) $(LIBRARY)
-endif
 
-check: $(TESTS)
+check: $(PROGRAMS) $(TESTS)
 	for t in $(TESTS); do echo ""***** Running $$t""; ./$$t || exit 1; done
 
 clean:
 	-rm -f $(PROGRAMS) $(LIBRARY) */*.o ios-x86/*/*.o ios-arm/*/*.o
-	-rmdir -p ios-x86/* ios-arm/*
+	-rm -rf ios-x86/* ios-arm/*
+	-rm build_config.mk
 
 $(LIBRARY): $(LIBOBJECTS)
@@ -189,4 +180,2 @@ else
 endif
 
-# TODO(gabor): dependencies for .o files
-# TODO(gabor): Build library
diff --git a/build_detect_platform b/build_detect_platform
new file mode 100644
index 0000000..f23068a
--- /dev/null
+++ b/build_detect_platform
@@ -0,0 +1,69 @@
+#!/bin/sh
+
+# Detects OS we're compiling on and generates build_config.mk,
+# which in turn gets read while processing Makefile.
+
+# build_config.mk will set the following variables:
+# - PORT_CFLAGS will either set:
+#               -DLEVELDB_PLATFORM_POSIX if cstatomic is present
+#               -DLEVELDB_PLATFORM_NOATOMIC if it is not
+# - PLATFORM_CFLAGS with compiler flags for the platform
+# - PLATFORM_LDFLAGS with linker flags for the platform
+
+# Delete existing build_config.mk
+rm -f build_config.mk
+
+# Detect OS
+case `uname -s` in
+    Darwin)
+        PLATFORM=OS_MACOSX
+        echo ""PLATFORM_CFLAGS=-pthread -DOS_MACOSX"" >> build_config.mk
+        echo ""PLATFORM_LDFLAGS=-lpthread""  >> build_config.mk
+        ;;
+    Linux)
+        PLATFORM=OS_LINUX
+        echo ""PLATFORM_CFLAGS=-pthread -DOS_LINUX"" >> build_config.mk
+        echo ""PLATFORM_LDFLAGS=-lpthread""  >> build_config.mk
+        ;;
+    SunOS)
+        PLATFORM=OS_SOLARIS
+        echo ""PLATFORM_CFLAGS=-D_REENTRANT -DOS_SOLARIS""  >> build_config.mk
+        echo ""PLATFORM_LDFLAGS=-lpthread -lrt"" >> build_config.mk
+        ;;
+    *)
+        echo ""Unknown platform!""
+        exit 1
+esac
+
+echo ""PLATFORM=$PLATFORM"" >> build_config.mk
+
+# On GCC, use libc's memcmp, not GCC's memcmp
+PORT_CFLAGS=""-fno-builtin-memcmp""
+
+# Detect C++0x -- this determines whether we'll use port_noatomic.h
+# or port_posix.h by:
+# 1. Rrying to compile with -std=c++0x and including <cstdatomic>.
+# 2. If g++ returns error code, we know to use port_posix.h
+g++ $CFLAGS -std=c++0x -x c++ - -o /dev/null 2>/dev/null  <<EOF
+  #include <cstdatomic>
+  int main() {}
+EOF
+if [ ""$?"" = 0 ]; then
+    PORT_CFLAGS+="" -DLEVELDB_PLATFORM_POSIX -DLEVELDB_CSTDATOMIC_PRESENT -std=c++0x""
+else
+    PORT_CFLAGS+="" -DLEVELDB_PLATFORM_POSIX""
+fi
+
+# Test whether Snappy library is installed
+# http://code.google.com/p/snappy/
+g++ $CFLAGS -x c++ - -o /dev/null 2>/dev/null  <<EOF
+  #include <snappy.h>
+  int main() {}
+EOF
+if [ ""$?"" = 0 ]; then
+    echo ""SNAPPY=1"" >> build_config.mk
+else
+    echo ""SNAPPY=0"" >> build_config.mk
+fi
+
+echo ""PORT_CFLAGS=$PORT_CFLAGS"" >> build_config.mk
diff --git a/port/atomic_pointer.h b/port/atomic_pointer.h
new file mode 100644
index 0000000..3bae007
--- /dev/null
+++ b/port/atomic_pointer.h
@@ -0,0 +1,213 @@
+// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file. See the AUTHORS file for names of contributors.
+
+// AtomicPointer provides storage for a lock-free pointer.
+// Platform-dependent implementation of AtomicPointer:
+// - If cstdatomic is present (on newer versions of gcc, it is), we use
+//   a cstdatomic-based AtomicPointer
+// - If it is not, we define processor-dependent AtomicWord operations,
+//   and then use them to build AtomicPointer
+//
+// This code is based on atomicops-internals-* in Google's perftools:
+// http://code.google.com/p/google-perftools/source/browse/#svn%2Ftrunk%2Fsrc%2Fbase
+
+#ifndef PORT_ATOMIC_POINTER_H_
+#define PORT_ATOMIC_POINTER_H_
+
+#ifdef LEVELDB_CSTDATOMIC_PRESENT
+
+///////////////////////////////////////////////////////////////////////////////
+// WE HAVE <cstdatomic>
+// Use a <cstdatomic>-based AtomicPointer
+
+#include <cstdatomic>
+#include <stdint.h>
+
+namespace leveldb {
+namespace port {
+
+// Storage for a lock-free pointer
+class AtomicPointer {
+ private:
+  std::atomic<void*> rep_;
+ public:
+  AtomicPointer() { }
+  explicit AtomicPointer(void* v) : rep_(v) { }
+  inline void* Acquire_Load() const {
+    return rep_.load(std::memory_order_acquire);
+  }
+  inline void Release_Store(void* v) {
+    rep_.store(v, std::memory_order_release);
+  }
+  inline void* NoBarrier_Load() const {
+    return rep_.load(std::memory_order_relaxed);
+  }
+  inline void NoBarrier_Store(void* v) {
+    rep_.store(v, std::memory_order_relaxed);
+  }
+};
+
+} // namespace leveldb::port
+} // namespace leveldb
+
+#else
+///////////////////////////////////////////////////////////////////////////////
+// NO <cstdatomic>
+// The entire rest of this file covers that case
+
+#if defined(_M_X64) || defined(__x86_64__)
+#define ARCH_CPU_X86_FAMILY 1
+#elif defined(_M_IX86) || defined(__i386__) || defined(__i386)
+#define ARCH_CPU_X86_FAMILY 1
+#elif defined(__ARMEL__)
+#define ARCH_CPU_ARM_FAMILY 1
+#else
+#warning Please add support for your architecture in atomicpointer.h
+#endif
+
+namespace leveldb {
+namespace port {
+namespace internal {
+
+// AtomicWord is a machine-sized pointer.
+typedef intptr_t AtomicWord;
+
+} // namespace leveldb::port::internal
+} // namespace leveldb::port
+} // namespace leveldb
+
+// Include our platform specific implementation.
+///////////////////////////////////////////////////////////////////////////////
+// Windows on x86
+#if defined(OS_WIN) && defined(COMPILER_MSVC) && defined(ARCH_CPU_X86_FAMILY)
+
+// void MemoryBarrier(void) macro is defined in windows.h:
+// http://msdn.microsoft.com/en-us/library/ms684208(v=vs.85).aspx
+// Including windows.h here; MemoryBarrier() gets used below.
+#include <windows.h>
+
+///////////////////////////////////////////////////////////////////////////////
+// Mac OS on x86
+#elif defined(OS_MACOSX) && defined(ARCH_CPU_X86_FAMILY)
+
+#include <libkern/OSAtomic.h>
+
+namespace leveldb {
+namespace port {
+namespace internal {
+
+inline void MemoryBarrier() {
+#if defined(__GNUC__) && (defined(__i386__) || defined(__x86_64__))
+  // See http://gcc.gnu.org/ml/gcc/2003-04/msg01180.html for a discussion on
+  // this idiom. Also see http://en.wikipedia.org/wiki/Memory_ordering.
+  __asm__ __volatile__("""" : : : ""memory"");
+#else
+  OSMemoryBarrier();
+#endif
+}
+
+} // namespace leveldb::port::internal
+} // namespace leveldb::port
+} // namespace leveldb
+
+///////////////////////////////////////////////////////////////////////////////
+// Any x86 CPU
+#elif defined(ARCH_CPU_X86_FAMILY)
+
+namespace leveldb {
+namespace port {
+namespace internal {
+
+inline void MemoryBarrier() {
+  __asm__ __volatile__("""" : : : ""memory"");
+}
+
+} // namespace leveldb::port::internal
+} // namespace leveldb::port
+} // namespace leveldb
+
+#undef ATOMICOPS_COMPILER_BARRIER
+
+///////////////////////////////////////////////////////////////////////////////
+// ARM
+#elif defined(ARCH_CPU_ARM_FAMILY)
+
+namespace leveldb {
+namespace port {
+namespace internal {
+
+typedef void (*LinuxKernelMemoryBarrierFunc)(void);
+LinuxKernelMemoryBarrierFunc pLinuxKernelMemoryBarrier __attribute__((weak)) =
+    (LinuxKernelMemoryBarrierFunc) 0xffff0fa0;
+
+inline void MemoryBarrier() {
+  pLinuxKernelMemoryBarrier();
+}
+
+} // namespace leveldb::port::internal
+} // namespace leveldb::port
+} // namespace leveldb
+
+#else
+#error ""Atomic operations are not supported on your platform""
+#endif
+
+///////////////////////////////////////////////////////////////////////////////
+// Implementation of AtomicPointer based on MemoryBarriers above
+
+namespace leveldb {
+namespace port {
+namespace internal {
+
+// Atomic operations using per-system MemoryBarrier()s
+
+inline AtomicWord Acquire_Load(volatile const AtomicWord* ptr) {
+  AtomicWord value = *ptr;
+  MemoryBarrier();
+  return value;
+}
+
+inline void Release_Store(volatile AtomicWord* ptr, AtomicWord value) {
+  MemoryBarrier();
+  *ptr = value;
+}
+
+inline AtomicWord NoBarrier_Load(volatile const AtomicWord* ptr) {
+  return *ptr;
+}
+
+inline void NoBarrier_Store(volatile AtomicWord* ptr, AtomicWord value) {
+  *ptr = value;
+}
+
+} // namespace leveldb::port::internal
+
+// AtomicPointer definition for systems without <cstdatomic>.
+class AtomicPointer {
+ private:
+  typedef internal::AtomicWord Rep;
+  Rep rep_;
+ public:
+  AtomicPointer() { }
+  explicit AtomicPointer(void* p) : rep_(reinterpret_cast<Rep>(p)) {}
+  inline void* Acquire_Load() const {
+    return reinterpret_cast<void*>(internal::Acquire_Load(&rep_));
+  }
+  inline void Release_Store(void* v) {
+    internal::Release_Store(&rep_, reinterpret_cast<Rep>(v));
+  }
+  inline void* NoBarrier_Load() const {
+    return reinterpret_cast<void*>(internal::NoBarrier_Load(&rep_));
+  }
+  inline void NoBarrier_Store(void* v) {
+    internal::NoBarrier_Store(&rep_, reinterpret_cast<Rep>(v));
+  }
+};
+
+} // namespace leveldb::port
+} // namespace leveldb
+
+#endif // LEVELDB_CSTDATOMIC_PRESENT
+
+#endif  // PORT_ATOMIC_POINTER_H_
diff --git a/port/port.h b/port/port.h
index e35db23..816826b 100644
--- a/port/port.h
+++ b/port/port.h
@@ -17,6 +17,4 @@
 #elif defined(LEVELDB_PLATFORM_ANDROID)
 #  include ""port/port_android.h""
-#elif defined(LEVELDB_PLATFORM_OSX)
-#  include ""port/port_osx.h""
 #endif
 
diff --git a/port/port_posix.h b/port/port_posix.h
index d0b0615..3f329f0 100644
--- a/port/port_posix.h
+++ b/port/port_posix.h
@@ -8,5 +8,16 @@
 #define STORAGE_LEVELDB_PORT_PORT_POSIX_H_
 
-#include <endian.h>
+#if defined(OS_MACOSX)
+  #include <machine/endian.h>
+#elif defined(OS_SOLARIS)
+  #include <sys/isa_defs.h>
+  #ifdef _LITTLE_ENDIAN
+    #define LITTLE_ENDIAN
+  #else
+    #define BIG_ENDIAN
+  #endif
+#else
+  #include <endian.h>
+#endif
 #include <pthread.h>
 #ifdef SNAPPY
@@ -15,11 +26,26 @@
 #include <stdint.h>
 #include <string>
-#include <cstdatomic>
-#include <cstring>
+#include ""port/atomic_pointer.h""
+
+#ifdef LITTLE_ENDIAN
+#define IS_LITTLE_ENDIAN true
+#else
+#define IS_LITTLE_ENDIAN (__BYTE_ORDER == __LITTLE_ENDIAN)
+#endif
+
+#if defined(OS_MACOSX) || defined(OS_SOLARIS)
+#define fread_unlocked fread
+#define fwrite_unlocked fwrite
+#define fflush_unlocked fflush
+#endif
+
+#if defined(OS_MACOSX)
+#define fdatasync fsync
+#endif
 
 namespace leveldb {
 namespace port {
 
-static const bool kLittleEndian = (__BYTE_ORDER == __LITTLE_ENDIAN);
+static const bool kLittleEndian = IS_LITTLE_ENDIAN;
 
 class CondVar;
@@ -55,27 +81,6 @@ class CondVar {
 };
 
-// Storage for a lock-free pointer
-class AtomicPointer {
- private:
-  std::atomic<void*> rep_;
- public:
-  AtomicPointer() { }
-  explicit AtomicPointer(void* v) : rep_(v) { }
-  inline void* Acquire_Load() const {
-    return rep_.load(std::memory_order_acquire);
-  }
-  inline void Release_Store(void* v) {
-    rep_.store(v, std::memory_order_release);
-  }
-  inline void* NoBarrier_Load() const {
-    return rep_.load(std::memory_order_relaxed);
-  }
-  inline void NoBarrier_Store(void* v) {
-    rep_.store(v, std::memory_order_relaxed);
-  }
-};
-
 inline bool Snappy_Compress(const char* input, size_t input_length,
-                            std::string* output) {
+                            ::std::string* output) {
 #ifdef SNAPPY
   output->resize(snappy::MaxCompressedLength(input_length));
@@ -90,5 +95,5 @@ inline bool Snappy_Compress(const char* input, size_t input_length,
 
 inline bool Snappy_Uncompress(const char* input_data, size_t input_length,
-                              std::string* output) {
+                              ::std::string* output) {
 #ifdef SNAPPY
   size_t ulength;
@@ -107,6 +112,6 @@ inline bool GetHeapProfile(void (*func)(void*, const char*, int), void* arg) {
 }
 
-}
-}
+} // namespace port
+} // namespace leveldb
 
 #endif  // STORAGE_LEVELDB_PORT_PORT_POSIX_H_
diff --git a/util/cache.cc b/util/cache.cc
index 968e6a0..5829b79 100644
--- a/util/cache.cc
+++ b/util/cache.cc
@@ -3,15 +3,7 @@
 // found in the LICENSE file. See the AUTHORS file for names of contributors.
 
-#if defined(LEVELDB_PLATFORM_POSIX) || defined(LEVELDB_PLATFORM_ANDROID)
-#include <unordered_set>
-#elif defined(LEVELDB_PLATFORM_OSX)
-#include <ext/hash_set>
-#elif defined(LEVELDB_PLATFORM_CHROMIUM)
-#include ""base/hash_tables.h""
-#else
-#include <hash_set> // TODO(sanjay): Switch to unordered_set when possible.
-#endif
-
 #include <assert.h>
+#include <stdio.h>
+#include <stdlib.h>
 
 #include ""leveldb/cache.h""
@@ -34,4 +26,5 @@ struct LRUHandle {
   void* value;
   void (*deleter)(const Slice&, void* value);
+  LRUHandle* next_hash;
   LRUHandle* next;
   LRUHandle* prev;
@@ -52,41 +45,91 @@ struct LRUHandle {
 };
 
-// Pick a platform specific hash_set instantiation
-#if defined(LEVELDB_PLATFORM_CHROMIUM) && defined(OS_WIN)
-  // Microsoft's hash_set deviates from the standard. See
-  // http://msdn.microsoft.com/en-us/library/1t4xas78(v=vs.80).aspx
-  // for details. Basically the 2 param () operator is a less than and
-  // the 1 param () operator is a hash function.
-  struct HandleHashCompare : public stdext::hash_compare<LRUHandle*> {
-    size_t operator() (LRUHandle* h) const {
-      Slice k = h->key();
-      return Hash(k.data(), k.size(), 0);
+// We provide our own simple hash table since it removes a whole bunch
+// of porting hacks and is also faster than some of the built-in hash
+// table implementations in some of the compiler/runtime combinations
+// we have tested.  E.g., readrandom speeds up by ~5% over the g++
+// 4.4.3's builtin hashtable.
+class HandleTable {
+ public:
+  HandleTable() : length_(0), elems_(0), list_(NULL) { Resize(); }
+  ~HandleTable() { delete[] list_; }
+
+  LRUHandle* Lookup(LRUHandle* h) {
+    return *FindPointer(h);
+  }
+
+  LRUHandle* Insert(LRUHandle* h) {
+    LRUHandle** ptr = FindPointer(h);
+    LRUHandle* old = *ptr;
+    h->next_hash = (old == NULL ? NULL : old->next_hash);
+    *ptr = h;
+    if (old == NULL) {
+      ++elems_;
+      if (elems_ > length_) {
+        // Since each cache entry is fairly large, we aim for a small
+        // average linked list length (<= 1).
+        Resize();
+      }
     }
-    bool operator() (LRUHandle* a, LRUHandle* b) const {
-      return a->key().compare(b->key()) < 0;
+    return old;
+  }
+
+  LRUHandle* Remove(LRUHandle* h) {
+    LRUHandle** ptr = FindPointer(h);
+    LRUHandle* result = *ptr;
+    if (result != NULL) {
+      *ptr = result->next_hash;
+      --elems_;
     }
-  };
-  typedef base::hash_set<LRUHandle*, HandleHashCompare> HandleTable;
-#else
-  struct HandleHash {
-    inline size_t operator()(LRUHandle* h) const {
-      Slice k = h->key();
-      return Hash(k.data(), k.size(), 0);
+    return result;
+  }
+
+ private:
+  // The table consists of an array of buckets where each bucket is
+  // a linked list of cache entries that hash into the bucket.
+  uint32_t length_;
+  uint32_t elems_;
+  LRUHandle** list_;
+
+  // Return a pointer to slot that points to a cache entry that
+  // matches *h.  If there is no such cache entry, return a pointer to
+  // the trailing slot in the corresponding linked list.
+  LRUHandle** FindPointer(LRUHandle* h) {
+    Slice key = h->key();
+    uint32_t hash = Hash(key.data(), key.size(), 0);
+    LRUHandle** ptr = &list_[hash & (length_ - 1)];
+    while (*ptr != NULL && key != (*ptr)->key()) {
+      ptr = &(*ptr)->next_hash;
     }
-  };
+    return ptr;
+  }
 
-  struct HandleEq {
-    inline bool operator()(LRUHandle* a, LRUHandle* b) const {
-      return a->key() == b->key();
+  void Resize() {
+    uint32_t new_length = 4;
+    while (new_length < elems_) {
+      new_length *= 2;
+    }
+    LRUHandle** new_list = new LRUHandle*[new_length];
+    memset(new_list, 0, sizeof(new_list[0]) * new_length);
+    uint32_t count = 0;
+    for (int i = 0; i < length_; i++) {
+      LRUHandle* h = list_[i];
+      while (h != NULL) {
+        LRUHandle* next = h->next_hash;
+        Slice key = h->key();
+        uint32_t hash = Hash(key.data(), key.size(), 0);
+        LRUHandle** ptr = &new_list[hash & (new_length - 1)];
+        h->next_hash = *ptr;
+        *ptr = h;
+        h = next;
+        count++;
+      }
     }
-  };
-#  if defined(LEVELDB_PLATFORM_CHROMIUM)
-    typedef base::hash_set<LRUHandle*, HandleHash, HandleEq> HandleTable;
-#  elif defined(LEVELDB_PLATFORM_POSIX) || defined(LEVELDB_PLATFORM_ANDROID)
-    typedef std::unordered_set<LRUHandle*, HandleHash, HandleEq> HandleTable;
-#  else
-    typedef __gnu_cxx::hash_set<LRUHandle*, HandleHash, HandleEq> HandleTable;
-#  endif
-#endif
+    assert(elems_ == count);
+    delete[] list_;
+    list_ = new_list;
+    length_ = new_length;
+  }
+};
 
 class LRUCache : public Cache {
@@ -133,5 +176,4 @@ LRUCache::LRUCache(size_t capacity)
 
 LRUCache::~LRUCache() {
-  table_.clear();
   for (LRUHandle* e = lru_.next; e != &lru_; ) {
     LRUHandle* next = e->next;
@@ -171,14 +213,11 @@ Cache::Handle* LRUCache::Lookup(const Slice& key) {
   dummy.next = &dummy;
   dummy.value = const_cast<Slice*>(&key);
-  HandleTable::iterator iter = table_.find(&dummy);
-  if (iter == table_.end()) {
-    return NULL;
-  } else {
-    LRUHandle* e = const_cast<LRUHandle*>(*iter);
+  LRUHandle* e = table_.Lookup(&dummy);
+  if (e != NULL) {
     e->refs++;
     LRU_Remove(e);
     LRU_Append(e);
-    return reinterpret_cast<Handle*>(e);
   }
+  return reinterpret_cast<Handle*>(e);
 }
 
@@ -207,11 +246,7 @@ Cache::Handle* LRUCache::Insert(const Slice& key, void* value, size_t charge,
   usage_ += charge;
 
-  std::pair<HandleTable::iterator,bool> p = table_.insert(e);
-  if (!p.second) {
-    // Kill existing entry
-    LRUHandle* old = const_cast<LRUHandle*>(*(p.first));
+  LRUHandle* old = table_.Insert(e);
+  if (old != NULL) {
     LRU_Remove(old);
-    table_.erase(p.first);
-    table_.insert(e);
     Unref(old);
   }
@@ -220,5 +255,5 @@ Cache::Handle* LRUCache::Insert(const Slice& key, void* value, size_t charge,
     LRUHandle* old = lru_.next;
     LRU_Remove(old);
-    table_.erase(old);
+    table_.Remove(old);
     Unref(old);
   }
@@ -233,9 +268,7 @@ void LRUCache::Erase(const Slice& key) {
   dummy.next = &dummy;
   dummy.value = const_cast<Slice*>(&key);
-  HandleTable::iterator iter = table_.find(&dummy);
-  if (iter != table_.end()) {
-    LRUHandle* e = const_cast<LRUHandle*>(*iter);
+  LRUHandle* e = table_.Remove(&dummy);
+  if (e != NULL) {
     LRU_Remove(e);
-    table_.erase(iter);
     Unref(e);
   }
","Platform detection during build, plus compatibility patches for machines without <cstdatomic>.

This revision adds two major changes:
1. build_detect_platform which generates build_config.mk
   with platform-dependent flags for the build process
2. /port/atomic_pointer.h with anAtomicPointerimplementation
   for platforms without <cstdatomic>

Some of this code is loosely based on patches submitted to the 
LevelDB mailing list at https://groups.google.com/forum/#!forum/leveldb
Tip of the hat to Dave Smith and Edouard A, who both sent patches.

The presence of Snappy (http://code.google.com/p/snappy/) and
cstdatomic are now both detected in the build_detect_platform
script (1.) which gets executing during make.

For (2.), instead of broadly importing atomicops_* from Chromium or
the Google performance tools, we chose to just implement AtomicPointer 
and the limited atomic load and store operations it needs. 
This resulted in much less code and fewer files - everything is 
contained in atomic_pointer.h.



git-svn-id: https://leveldb.googlecode.com/svn/trunk@34 62dab493-f737-651d-591e-8d6aee1b9529

"
193,C++,ba369ddbaffcfe635dd620d1aa68473b56267065,https://github.com/google/leveldb/commit/ba369ddbaffcfe635dd620d1aa68473b56267065,P,google,leveldb,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/.travis.yml b/.travis.yml
index 42cbe64..766fdc9 100644
--- a/.travis.yml
+++ b/.travis.yml
@@ -21,9 +21,9 @@ addons:
   apt:
     sources:
-    - sourceline: 'deb http://apt.llvm.org/bionic/ llvm-toolchain-bionic-9 main'
+    - sourceline: 'deb http://apt.llvm.org/bionic/ llvm-toolchain-bionic-10 main'
       key_url: 'https://apt.llvm.org/llvm-snapshot.gpg.key'
     - sourceline: 'ppa:ubuntu-toolchain-r/test'
     packages:
-    - clang-9
+    - clang-10
     - cmake
     - gcc-9
@@ -41,5 +41,5 @@ addons:
     - gperftools
     - kyoto-cabinet
-    - llvm@9
+    - llvm@10
     - ninja
     - snappy
@@ -61,5 +61,5 @@ install:
 # default values (clang and clang++) resolve to the correct compiler on macOS.
 - if [ ""$TRAVIS_OS_NAME"" = ""linux"" ]; then
-    if [ ""$CXX"" = ""clang++"" ]; then export CXX=""clang++-9"" CC=""clang-9""; fi;
+    if [ ""$CXX"" = ""clang++"" ]; then export CXX=""clang++-10"" CC=""clang-10""; fi;
   fi
 - echo ${CC}
","Use LLVM 10 on Travis CI.

PiperOrigin-RevId: 306236199

"
201,C++,c61238dcf39bdcfb6ef27abbda35b4cbf42b9002,https://github.com/google/leveldb/commit/c61238dcf39bdcfb6ef27abbda35b4cbf42b9002,A,google,leveldb,"[5, 13, 0, 6, 3, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/benchmarks/db_bench.cc b/benchmarks/db_bench.cc
index db866f5..8e3f4e7 100644
--- a/benchmarks/db_bench.cc
+++ b/benchmarks/db_bench.cc
@@ -127,4 +127,7 @@ static bool FLAGS_compression = true;
 static const char* FLAGS_db = nullptr;
 
+// ZSTD compression level to try out
+static int FLAGS_zstd_compression_level = 1;
+
 namespace leveldb {
 
@@ -780,9 +783,19 @@ class Benchmark {
 
   void ZstdCompress(ThreadState* thread) {
-    Compress(thread, ""zstd"", &port::Zstd_Compress);
+    Compress(thread, ""zstd"",
+             [](const char* input, size_t length, std::string* output) {
+               return port::Zstd_Compress(FLAGS_zstd_compression_level, input,
+                                          length, output);
+             });
   }
 
   void ZstdUncompress(ThreadState* thread) {
-    Uncompress(thread, ""zstd"", &port::Zstd_Compress, &port::Zstd_Uncompress);
+    Uncompress(
+        thread, ""zstd"",
+        [](const char* input, size_t length, std::string* output) {
+          return port::Zstd_Compress(FLAGS_zstd_compression_level, input,
+                                     length, output);
+        },
+        &port::Zstd_Uncompress);
   }
 
diff --git a/include/leveldb/options.h b/include/leveldb/options.h
index 79bcdbb..d755f46 100644
--- a/include/leveldb/options.h
+++ b/include/leveldb/options.h
@@ -132,4 +132,8 @@ struct LEVELDB_EXPORT Options {
   CompressionType compression = kSnappyCompression;
 
+  // Compression level for zstd.
+  // Currently only the range [-5,22] is supported. Default is 1.
+  int zstd_compression_level = 1;
+
   // EXPERIMENTAL: If true, append to existing MANIFEST and log files
   // when a database is opened.  This can significantly speed up open.
diff --git a/port/port_example.h b/port/port_example.h
index b1a1c32..5d50ffa 100644
--- a/port/port_example.h
+++ b/port/port_example.h
@@ -84,5 +84,6 @@ bool Snappy_Uncompress(const char* input_data, size_t input_length,
 // Store the zstd compression of ""input[0,input_length-1]"" in *output.
 // Returns false if zstd is not supported by this port.
-bool Zstd_Compress(const char* input, size_t input_length, std::string* output);
+bool Zstd_Compress(int level, const char* input, size_t input_length,
+                   std::string* output);
 
 // If input[0,input_length-1] looks like a valid zstd compressed
diff --git a/port/port_stdcxx.h b/port/port_stdcxx.h
index ca961e6..6f503f6 100644
--- a/port/port_stdcxx.h
+++ b/port/port_stdcxx.h
@@ -30,4 +30,5 @@
 #endif  // HAVE_SNAPPY
 #if HAVE_ZSTD
+#define ZSTD_STATIC_LINKING_ONLY  // For ZSTD_compressionParameters.
 #include <zstd.h>
 #endif  // HAVE_ZSTD
@@ -130,5 +131,5 @@ inline bool Snappy_Uncompress(const char* input, size_t length, char* output) {
 }
 
-inline bool Zstd_Compress(const char* input, size_t length,
+inline bool Zstd_Compress(int level, const char* input, size_t length,
                           std::string* output) {
 #if HAVE_ZSTD
@@ -140,4 +141,7 @@ inline bool Zstd_Compress(const char* input, size_t length,
   output->resize(outlen);
   ZSTD_CCtx* ctx = ZSTD_createCCtx();
+  ZSTD_compressionParameters parameters =
+      ZSTD_getCParams(level, std::max(length, size_t{1}), /*dictSize=*/0);
+  ZSTD_CCtx_setCParams(ctx, parameters);
   outlen = ZSTD_compress2(ctx, &(*output)[0], output->size(), input, length);
   ZSTD_freeCCtx(ctx);
@@ -149,4 +153,5 @@ inline bool Zstd_Compress(const char* input, size_t length,
 #else
   // Silence compiler warnings about unused arguments.
+  (void)level;
   (void)input;
   (void)length;
diff --git a/table/table_builder.cc b/table/table_builder.cc
index ba3df9e..0932c94 100644
--- a/table/table_builder.cc
+++ b/table/table_builder.cc
@@ -172,5 +172,6 @@ void TableBuilder::WriteBlock(BlockBuilder* block, BlockHandle* handle) {
     case kZstdCompression: {
       std::string* compressed = &r->compressed_output;
-      if (port::Zstd_Compress(raw.data(), raw.size(), compressed) &&
+      if (port::Zstd_Compress(r->options.zstd_compression_level, raw.data(),
+                              raw.size(), compressed) &&
           compressed->size() < raw.size() - (raw.size() / 8u)) {
         block_contents = *compressed;
diff --git a/table/table_test.cc b/table/table_test.cc
index b3baf95..aea0697 100644
--- a/table/table_test.cc
+++ b/table/table_test.cc
@@ -792,5 +792,5 @@ static bool CompressionSupported(CompressionType type) {
     return port::Snappy_Compress(in.data(), in.size(), &out);
   } else if (type == kZstdCompression) {
-    return port::Zstd_Compress(in.data(), in.size(), &out);
+    return port::Zstd_Compress(/*level=*/1, in.data(), in.size(), &out);
   }
   return false;
","Support Zstd compression level in Leveldb

PiperOrigin-RevId: 520556840

"
213,C++,85cfb3b930e8c1cec2ae642bcb48d75c810b0a7a,https://github.com/carbon-language/carbon-lang/commit/85cfb3b930e8c1cec2ae642bcb48d75c810b0a7a,P,carbon-language,carbon-lang,"[4, 0, 0, 32, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/executable_semantics/ast/expression.cpp b/executable_semantics/ast/expression.cpp
index 9d791062..f643ee32 100644
--- a/executable_semantics/ast/expression.cpp
+++ b/executable_semantics/ast/expression.cpp
@@ -97,5 +97,5 @@ auto Expression::MakeVar(int line_num, std::string var) -> const Expression* {
   auto* v = new Expression();
   v->line_num = line_num;
-  v->value = Variable({.name = new std::string(std::move(var))});
+  v->value = Variable({.name = std::move(var)});
   return v;
 }
@@ -105,6 +105,5 @@ auto Expression::MakeVarPat(int line_num, std::string var,
   auto* v = new Expression();
   v->line_num = line_num;
-  v->value =
-      PatternVariable({.name = new std::string(std::move(var)), .type = type});
+  v->value = PatternVariable({.name = std::move(var), .type = type});
   return v;
 }
@@ -164,6 +163,5 @@ auto Expression::MakeGetField(int line_num, const Expression* exp,
   auto* e = new Expression();
   e->line_num = line_num;
-  e->value = FieldAccess(
-      {.aggregate = exp, .field = new std::string(std::move(field))});
+  e->value = FieldAccess({.aggregate = exp, .field = std::move(field)});
   return e;
 }
@@ -263,5 +261,5 @@ void PrintExp(const Expression* e) {
       PrintExp(e->GetFieldAccess().aggregate);
       std::cout << ""."";
-      std::cout << *e->GetFieldAccess().field;
+      std::cout << e->GetFieldAccess().field;
       break;
     case ExpressionKind::Tuple:
@@ -300,10 +298,10 @@ void PrintExp(const Expression* e) {
     }
     case ExpressionKind::Variable:
-      std::cout << *e->GetVariable().name;
+      std::cout << e->GetVariable().name;
       break;
     case ExpressionKind::PatternVariable:
       PrintExp(e->GetPatternVariable().type);
       std::cout << "": "";
-      std::cout << *e->GetPatternVariable().name;
+      std::cout << e->GetPatternVariable().name;
       break;
     case ExpressionKind::Call:
diff --git a/executable_semantics/ast/expression.h b/executable_semantics/ast/expression.h
index 3110148c..64835d88 100644
--- a/executable_semantics/ast/expression.h
+++ b/executable_semantics/ast/expression.h
@@ -58,5 +58,5 @@ struct Expression;
 struct Variable {
   static constexpr ExpressionKind Kind = ExpressionKind::Variable;
-  std::string* name;
+  std::string name;
 };
 
@@ -64,5 +64,5 @@ struct FieldAccess {
   static constexpr ExpressionKind Kind = ExpressionKind::GetField;
   const Expression* aggregate;
-  std::string* field;
+  std::string field;
 };
 
@@ -75,5 +75,5 @@ struct Index {
 struct PatternVariable {
   static constexpr ExpressionKind Kind = ExpressionKind::PatternVariable;
-  std::string* name;
+  std::string name;
   const Expression* type;
 };
diff --git a/executable_semantics/interpreter/interpreter.cpp b/executable_semantics/interpreter/interpreter.cpp
index 415cbea0..ed089716 100644
--- a/executable_semantics/interpreter/interpreter.cpp
+++ b/executable_semantics/interpreter/interpreter.cpp
@@ -625,8 +625,8 @@ void StepLvalue() {
       // -> { {E(x) :: C, E, F} :: S, H}
       std::optional<Address> pointer =
-          CurrentEnv(state).Get(*(exp->GetVariable().name));
+          CurrentEnv(state).Get(exp->GetVariable().name);
       if (!pointer) {
         std::cerr << exp->line_num << "": could not find `""
-                  << *(exp->GetVariable().name) << ""`"" << std::endl;
+                  << exp->GetVariable().name << ""`"" << std::endl;
         exit(-1);
       }
@@ -722,8 +722,8 @@ void StepExp() {
       // { {x :: C, E, F} :: S, H} -> { {H(E(x)) :: C, E, F} :: S, H}
       std::optional<Address> pointer =
-          CurrentEnv(state).Get(*(exp->GetVariable().name));
+          CurrentEnv(state).Get(exp->GetVariable().name);
       if (!pointer) {
         std::cerr << exp->line_num << "": could not find `""
-                  << *(exp->GetVariable().name) << ""`"" << std::endl;
+                  << exp->GetVariable().name << ""`"" << std::endl;
         exit(-1);
       }
@@ -1083,5 +1083,5 @@ void HandleValue() {
           const Value* str = act->results[0];
           Address a = GetMember(ValToPtr(str, exp->line_num),
-                                *exp->GetFieldAccess().field, exp->line_num);
+                                exp->GetFieldAccess().field, exp->line_num);
           frame->todo.Pop(2);
           frame->todo.Push(MakeValAct(Value::MakePtrVal(a)));
@@ -1136,5 +1136,5 @@ void HandleValue() {
       switch (exp->tag()) {
         case ExpressionKind::PatternVariable: {
-          auto v = Value::MakeVarPatVal(*exp->GetPatternVariable().name,
+          auto v = Value::MakeVarPatVal(exp->GetPatternVariable().name,
                                         act->results[0]);
           frame->todo.Pop(2);
@@ -1195,5 +1195,5 @@ void HandleValue() {
           // -> { { v_f :: C, E, F} : S, H}
           auto a = GetMember(ValToPtr(act->results[0], exp->line_num),
-                             *exp->GetFieldAccess().field, exp->line_num);
+                             exp->GetFieldAccess().field, exp->line_num);
           const Value* element = state->heap.Read(a, exp->line_num);
           frame->todo.Pop(2);
diff --git a/executable_semantics/interpreter/typecheck.cpp b/executable_semantics/interpreter/typecheck.cpp
index 02db00fd..57adb7d8 100644
--- a/executable_semantics/interpreter/typecheck.cpp
+++ b/executable_semantics/interpreter/typecheck.cpp
@@ -158,8 +158,7 @@ auto TypeCheckExp(const Expression* e, TypeEnv types, Env values,
         ExpectType(e->line_num, ""pattern variable"", t, expected);
       }
-      auto new_e =
-          Expression::MakeVarPat(e->line_num, *e->GetPatternVariable().name,
-                                 ReifyType(t, e->line_num));
-      types.Set(*e->GetPatternVariable().name, t);
+      auto new_e = Expression::MakeVarPat(
+          e->line_num, e->GetPatternVariable().name, ReifyType(t, e->line_num));
+      types.Set(e->GetPatternVariable().name, t);
       return TCResult(new_e, t, types);
     }
@@ -242,7 +241,7 @@ auto TypeCheckExp(const Expression* e, TypeEnv types, Env values,
           // Search for a field
           for (auto& field : *t->GetStructType().fields) {
-            if (*e->GetFieldAccess().field == field.first) {
+            if (e->GetFieldAccess().field == field.first) {
               const Expression* new_e = Expression::MakeGetField(
-                  e->line_num, res.exp, *e->GetFieldAccess().field);
+                  e->line_num, res.exp, e->GetFieldAccess().field);
               return TCResult(new_e, field.second, res.types);
             }
@@ -250,7 +249,7 @@ auto TypeCheckExp(const Expression* e, TypeEnv types, Env values,
           // Search for a method
           for (auto& method : *t->GetStructType().methods) {
-            if (*e->GetFieldAccess().field == method.first) {
+            if (e->GetFieldAccess().field == method.first) {
               const Expression* new_e = Expression::MakeGetField(
-                  e->line_num, res.exp, *e->GetFieldAccess().field);
+                  e->line_num, res.exp, e->GetFieldAccess().field);
               return TCResult(new_e, method.second, res.types);
             }
@@ -259,11 +258,11 @@ auto TypeCheckExp(const Expression* e, TypeEnv types, Env values,
                     << *t->GetStructType().name
                     << "" does not have a field named ""
-                    << *e->GetFieldAccess().field << std::endl;
+                    << e->GetFieldAccess().field << std::endl;
           exit(-1);
         case ValKind::TupleV:
           for (const TupleElement& field : *t->GetTuple().elements) {
-            if (*e->GetFieldAccess().field == field.name) {
+            if (e->GetFieldAccess().field == field.name) {
               auto new_e = Expression::MakeGetField(e->line_num, res.exp,
-                                                    *e->GetFieldAccess().field);
+                                                    e->GetFieldAccess().field);
               return TCResult(new_e,
                               state->heap.Read(field.address, e->line_num),
@@ -274,12 +273,12 @@ auto TypeCheckExp(const Expression* e, TypeEnv types, Env values,
                     << *t->GetStructType().name
                     << "" does not have a field named ""
-                    << *e->GetFieldAccess().field << std::endl;
+                    << e->GetFieldAccess().field << std::endl;
           exit(-1);
         case ValKind::ChoiceTV:
           for (auto vt = t->GetChoiceType().alternatives->begin();
                vt != t->GetChoiceType().alternatives->end(); ++vt) {
-            if (*e->GetFieldAccess().field == vt->first) {
+            if (e->GetFieldAccess().field == vt->first) {
               const Expression* new_e = Expression::MakeGetField(
-                  e->line_num, res.exp, *e->GetFieldAccess().field);
+                  e->line_num, res.exp, e->GetFieldAccess().field);
               auto fun_ty = Value::MakeFunTypeVal(vt->second, t);
               return TCResult(new_e, fun_ty, res.types);
@@ -289,5 +288,5 @@ auto TypeCheckExp(const Expression* e, TypeEnv types, Env values,
                     << *t->GetStructType().name
                     << "" does not have a field named ""
-                    << *e->GetFieldAccess().field << std::endl;
+                    << e->GetFieldAccess().field << std::endl;
           exit(-1);
 
@@ -302,10 +301,10 @@ auto TypeCheckExp(const Expression* e, TypeEnv types, Env values,
     }
     case ExpressionKind::Variable: {
-      std::optional<const Value*> type = types.Get(*(e->GetVariable().name));
+      std::optional<const Value*> type = types.Get(e->GetVariable().name);
       if (type) {
         return TCResult(e, *type, types);
       } else {
         std::cerr << e->line_num << "": could not find `""
-                  << *(e->GetVariable().name) << ""`"" << std::endl;
+                  << e->GetVariable().name << ""`"" << std::endl;
         exit(-1);
       }
","Use string values instead of string pointers in Expression. (#591)


"
215,C++,4e1adcf4c7ed9db1c504658b857661b0ffb8bc0e,https://github.com/carbon-language/carbon-lang/commit/4e1adcf4c7ed9db1c504658b857661b0ffb8bc0e,A,carbon-language,carbon-lang,"[4, 85, 7, 9, 22, 1, 7, 1, 0, 0, 0, 0, 0, 0, 26, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/explorer/ast/pattern.h b/explorer/ast/pattern.h
index 4d7ff728..ee39270c 100644
--- a/explorer/ast/pattern.h
+++ b/explorer/ast/pattern.h
@@ -107,6 +107,6 @@ class Pattern : public AstNode {
 
 // Call the given `visitor` on all patterns nested within the given pattern,
-// including `pattern` itself. Aborts and returns `false` if `visitor` returns
-// `false`, otherwise returns `true`.
+// including `pattern` itself, in a preorder traversal. Aborts and returns
+// `false` if `visitor` returns `false`, otherwise returns `true`.
 auto VisitNestedPatterns(const Pattern& pattern,
                          llvm::function_ref<bool(const Pattern&)> visitor)
diff --git a/explorer/ast/value.cpp b/explorer/ast/value.cpp
index f4bf04a1..599884af 100644
--- a/explorer/ast/value.cpp
+++ b/explorer/ast/value.cpp
@@ -14,4 +14,5 @@
 #include ""explorer/ast/element.h""
 #include ""explorer/ast/element_path.h""
+#include ""explorer/ast/value_transform.h""
 #include ""explorer/common/arena.h""
 #include ""explorer/common/error_builders.h""
@@ -28,4 +29,84 @@ using llvm::dyn_cast_or_null;
 using llvm::isa;
 
+namespace {
+// A visitor that walks the Value*s nested within a value.
+struct NestedValueVisitor {
+  template <typename T>
+  auto VisitParts(const T& decomposable) -> bool {
+    return decomposable.Decompose(
+        [&](const auto&... parts) { return (Visit(parts) && ...); });
+  }
+
+  auto Visit(Nonnull<const Value*> value) -> bool {
+    if (!callback(value)) {
+      return false;
+    }
+
+    return value->Visit<bool>(
+        [&](const auto* derived_value) { return VisitParts(*derived_value); });
+  }
+
+  auto Visit(Nonnull<const Bindings*> bindings) -> bool {
+    for (auto [binding, value] : bindings->args()) {
+      if (!Visit(value)) {
+        return false;
+      }
+    }
+    for (auto [binding, value] : bindings->witnesses()) {
+      if (!Visit(value)) {
+        return false;
+      }
+    }
+    return true;
+  }
+
+  template <typename T>
+  auto Visit(const std::vector<T>& vec) -> bool {
+    for (auto& v : vec) {
+      if (!Visit(v)) {
+        return false;
+      }
+    }
+    return true;
+  }
+
+  template <typename T>
+  auto Visit(const std::optional<T>& opt) -> bool {
+    return !opt || Visit(*opt);
+  }
+
+  template <typename T,
+            typename = std::enable_if_t<IsRecursivelyTransformable<T>>>
+  auto Visit(Nonnull<const T*> value) -> bool {
+    return VisitParts(*value);
+  }
+  template <typename T,
+            typename = std::enable_if_t<IsRecursivelyTransformable<T>>>
+  auto Visit(const T& value) -> bool {
+    return VisitParts(value);
+  }
+
+  // Other value components can't refer to a value.
+  auto Visit(Nonnull<const AstNode*>) -> bool { return true; }
+  auto Visit(ValueNodeView) -> bool { return true; }
+  auto Visit(int) -> bool { return true; }
+  auto Visit(Address) -> bool { return true; }
+  auto Visit(const std::string&) -> bool { return true; }
+  auto Visit(Nonnull<const NominalClassValue**>) -> bool {
+    // This is the pointer to the most-derived value within a class value,
+    // which is not ""within"" this value, so we shouldn't visit it.
+    return true;
+  }
+  auto Visit(const VTable&) -> bool { return true; }
+
+  llvm::function_ref<bool(const Value*)> callback;
+};
+}  // namespace
+
+auto VisitNestedValues(Nonnull<const Value*> value,
+                       llvm::function_ref<bool(const Value*)> visitor) -> bool {
+  return NestedValueVisitor{.callback = visitor}.Visit(value);
+}
+
 auto StructValue::FindField(std::string_view name) const
     -> std::optional<Nonnull<const Value*>> {
diff --git a/explorer/ast/value.h b/explorer/ast/value.h
index e8798b43..49c8c91d 100644
--- a/explorer/ast/value.h
+++ b/explorer/ast/value.h
@@ -123,4 +123,10 @@ auto ValueEqual(Nonnull<const Value*> v1, Nonnull<const Value*> v2,
     -> bool;
 
+// Call the given `visitor` on all values nested within the given value,
+// including `value` itself, in a preorder traversal. Aborts and returns
+// `false` if `visitor` returns `false`, otherwise returns `true`.
+auto VisitNestedValues(Nonnull<const Value*> value,
+                       llvm::function_ref<bool(const Value*)> visitor) -> bool;
+
 // An integer value.
 class IntValue : public Value {
diff --git a/explorer/interpreter/type_checker.cpp b/explorer/interpreter/type_checker.cpp
index 951938f9..85a82707 100644
--- a/explorer/interpreter/type_checker.cpp
+++ b/explorer/interpreter/type_checker.cpp
@@ -455,25 +455,15 @@ static auto ExpectResolvedBindingType(const BindingPattern& binding,
 
 // Returns whether the given value is template-dependent, that is, if it
-// depends on any template paramaeter.
-static auto IsTemplateDependent(Nonnull<const Value*> value) -> bool {
-  // A VariableType is template dependent if it names a template binding.
-  if (const auto* var_type = dyn_cast<VariableType>(value)) {
-    return var_type->binding().binding_kind() ==
-           GenericBinding::BindingKind::Template;
-  }
-
-  static constexpr auto is_dependent_value = [](auto&& x) -> bool {
-    if constexpr (std::is_convertible_v<decltype(x), const Value*>) {
-      return IsTemplateDependent(x);
-    }
-    return false;
-  };
-
-  // Any other value is template dependent if any part of it is.
-  return value->Visit<bool>([](auto* derived_value) {
-    return derived_value->Decompose([](auto&&... parts) {
-      return (is_dependent_value(decltype(parts)(parts)) || ...);
-    });
-  });
+// depends on any template parameter.
+static auto DependsOnTemplateParameter(Nonnull<const Value*> value) -> bool {
+  bool mentions_no_template_parameters =
+      VisitNestedValues(value, [](Nonnull<const Value*> nested) -> bool {
+        if (const auto* var_type = dyn_cast<VariableType>(nested)) {
+          return var_type->binding().binding_kind() !=
+                 GenericBinding::BindingKind::Template;
+        }
+        return true;
+      });
+  return !mentions_no_template_parameters;
 }
 
@@ -484,5 +474,5 @@ static auto IsTemplateSaturated(const Bindings& bindings) -> bool {
   for (auto [binding, value] : bindings.args()) {
     if (binding->binding_kind() == GenericBinding::BindingKind::Template &&
-        IsTemplateDependent(value)) {
+        DependsOnTemplateParameter(value)) {
       return false;
     }
@@ -6408,4 +6398,10 @@ auto TypeChecker::InstantiateImplDeclaration(
   }
 
+  // TODO: Make this method non-const and remove the const-cast here. The
+  // requirement to perform template instantiation unfortunately means that a
+  // lot of type-checking stops being free of side-effects, so this means
+  // removing `const` throughout most of the type-checker.
+  auto* type_checker = const_cast<TypeChecker*>(this);
+
   // TODO: It's probably not correct to use the top-level impl scope here. It's
   // not obvious what we should use, though -- which impls are in scope in
@@ -6415,9 +6411,32 @@ auto TypeChecker::InstantiateImplDeclaration(
   ImplScope scope(*top_level_impl_scope_);
 
-  // TODO: Remove the const-cast here. The requirement to perform template
-  // instantiation unfortunately means that a lot of type-checking stops being
-  // free of side-effects, so this means removing `const` throughout most of
-  // the type-checker.
-  auto* type_checker = const_cast<TypeChecker*>(this);
+  // Bring all impls from any checked generic bindings in the template
+  // arguments into scope.
+  //
+  // TODO: There shouldn't be any checked generic bindings in the template
+  // arguments by the time we come to perform an instantiation, but in order
+  // for that to work, we need to defer instantiating templates until we know
+  // the values of checked generic parameters, such as by performing
+  // monomorphization for checked generics (see #2153 for details). However,
+  // explorer doesn't yet support that.
+  //
+  // As a workaround for the lack of support for #2153, we can instantiate
+  // templates with the argument equal to a generic parameter. When we do so,
+  // the constraints on that generic parameter need to be in scope in the
+  // instantiation. This is imperfect: it misses constraints on the binding
+  // that come from anywhere other than its type.
+  for (auto [param, value] : bindings->args()) {
+    if (param->binding_kind() != GenericBinding::BindingKind::Template) {
+      continue;
+    }
+    VisitNestedValues(value, [&](Nonnull<const Value*> nested) -> bool {
+      if (auto* var_type = dyn_cast<VariableType>(nested)) {
+        if (auto impl_binding = var_type->binding().impl_binding()) {
+          type_checker->BringImplBindingIntoScope(*impl_binding, scope);
+        }
+      }
+      return true;
+    });
+  }
 
   // Type-check the new impl.
diff --git a/explorer/testdata/template/instantiate_from_generic.carbon b/explorer/testdata/template/instantiate_from_generic.carbon
new file mode 100644
index 00000000..785d6719
--- /dev/null
+++ b/explorer/testdata/template/instantiate_from_generic.carbon
@@ -0,0 +1,34 @@
+// Part of the Carbon Language project, under the Apache License v2.0 with LLVM
+// Exceptions. See /LICENSE for license information.
+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+//
+// AUTOUPDATE
+// CHECK:STDOUT: 1
+// CHECK:STDOUT: result: 0
+
+package ExplorerTest api;
+
+interface I { fn F[self: Self](); }
+
+fn CheckTimplsI[T:! I](x: T) { x.F(); }
+
+interface J { fn F[self: Self](); }
+
+impl forall [template T:! I] T as J {
+  fn F[self: Self]() { CheckTimplsI(self); }
+}
+
+// Ensure that the instantiated `impl T as J` is type-checked in an impl scope
+// where `T impls I` is available, so that its call to `CheckTimplsI` is valid.
+fn UseTemplatedImplFromGeneric[T:! I](x: T) { x.(J.F)(); }
+
+impl i32 as I {
+  fn F[self: i32]() {
+    Print(""{0}"", self);
+  }
+}
+
+fn Main() -> i32 {
+  UseTemplatedImplFromGeneric(1);
+  return 0;
+}
","Bring constraints into scope when a generic calls a template. (#2878)

When a template has an argument that involves a generic parameter, we're supposed to delay instantiation until we know the concrete value, but explorer is not set up to do that yet, so for now we instead instantiate the template with the symbolic argument. When that happens, bring the constraints on the generic parameter into scope so they can be used inside the template instantiation.

This requires adding a new search over a value for the generic parameters that appear within it; a `VisitNestedValues` visitor is added to visit all the `Value`s nested with a value, and also convert an existing place where we were doing the same thing in a way that was incorrect (but harmlessly incorrect for now) to use it.

This is needed by #2881, which needs implementations of `ImplicitAs` for nested types when instantiating a builtin impl of `ImplicitAs` for an aggregate type.

Co-authored-by: Geoff Romer <gromer@google.com>
"
216,C++,d76fe462f6fe40b374e992b86b9c12b0db861179,https://github.com/carbon-language/carbon-lang/commit/d76fe462f6fe40b374e992b86b9c12b0db861179,P,carbon-language,carbon-lang,"[0, 0, 0, 0, 0, 0, 0, 2, 6, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/executable_semantics/testdata/lit.cfg.py b/executable_semantics/testdata/lit.cfg.py
index ad4ba539..088dd25e 100644
--- a/executable_semantics/testdata/lit.cfg.py
+++ b/executable_semantics/testdata/lit.cfg.py
@@ -36,4 +36,7 @@ config.substitutions.append(
 config.substitutions.append((""%{not}"", fullpath(""llvm-project/llvm/not"")))
 config.substitutions.append(
-    (""%{FileCheck}"", fullpath(""llvm-project/llvm/FileCheck""))
+    (
+        ""%{FileCheck}"",
+        fullpath(""llvm-project/llvm/FileCheck --dump-input-filter=all""),
+    )
 )
diff --git a/toolchain/driver/testdata/lit.cfg.py b/toolchain/driver/testdata/lit.cfg.py
index 47c48bd4..e975c265 100644
--- a/toolchain/driver/testdata/lit.cfg.py
+++ b/toolchain/driver/testdata/lit.cfg.py
@@ -29,4 +29,7 @@ config.substitutions.append(
 config.substitutions.append((""%{not}"", fullpath(""llvm-project/llvm/not"")))
 config.substitutions.append(
-    (""%{FileCheck}"", fullpath(""llvm-project/llvm/FileCheck""))
+    (
+        ""%{FileCheck}"",
+        fullpath(""llvm-project/llvm/FileCheck --dump-input-filter=all""),
+    )
 )
","Have FileCheck dump all input on errors. (#1050)

I'm hoping this improves debugability.


"
229,C++,a184ceb9e2d129e5d20bfd7d3dc5f1ea49d27592,https://github.com/aria2/aria2/commit/a184ceb9e2d129e5d20bfd7d3dc5f1ea49d27592,C,aria2,aria2,"[1, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/src/AppleTLSSession.cc b/src/AppleTLSSession.cc
index 74253582..e9e16b64 100644
--- a/src/AppleTLSSession.cc
+++ b/src/AppleTLSSession.cc
@@ -56,5 +56,8 @@ namespace {
 static const SSLProtocol kTLSProtocol11 = 7;
 static const SSLProtocol kTLSProtocol12 = 8;
-static const SSLProtocol kTLSProtocol13 = 13;
+#endif
+
+#if !defined(__MAC_10_13)
+static const SSLProtocol kTLSProtocol13 = 10;
 #endif
 
","AppleTLS: correctly define kTLSProtocol13

"
232,C++,1fdc6e0a332e9952e271caa36f6fb19798cb9457,https://github.com/aria2/aria2/commit/1fdc6e0a332e9952e271caa36f6fb19798cb9457,P,aria2,aria2,"[4, 0, 1, 23, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/src/DownloadHandler.cc b/src/DownloadHandler.cc
index db2c02fe..bde2b746 100644
--- a/src/DownloadHandler.cc
+++ b/src/DownloadHandler.cc
@@ -49,5 +49,6 @@ bool DownloadHandler::canHandle(const RequestGroup* requestGroup) const
 }
 
-void DownloadHandler::setCriteria(const RequestGroupCriteriaHandle& criteria)
+void DownloadHandler::setCriteria
+(const SharedHandle<RequestGroupCriteria>& criteria)
 {
   criteria_ = criteria;
diff --git a/src/DownloadHandlerFactory.cc b/src/DownloadHandlerFactory.cc
index 0a9387c0..7ca0a904 100644
--- a/src/DownloadHandlerFactory.cc
+++ b/src/DownloadHandlerFactory.cc
@@ -45,8 +45,8 @@ namespace aria2 {
 #ifdef ENABLE_METALINK
 
-SharedHandle<MemoryBufferPreDownloadHandler>
+SharedHandle<PreDownloadHandler>
 DownloadHandlerFactory::metalinkPreDownloadHandler_;
 
-SharedHandle<MetalinkPostDownloadHandler>
+SharedHandle<PostDownloadHandler>
 DownloadHandlerFactory::metalinkPostDownloadHandler_;
 
@@ -55,11 +55,11 @@ DownloadHandlerFactory::metalinkPostDownloadHandler_;
 #ifdef ENABLE_BITTORRENT
 
-SharedHandle<bittorrent::MemoryBencodePreDownloadHandler>
+SharedHandle<PreDownloadHandler>
 DownloadHandlerFactory::btPreDownloadHandler_;
 
-SharedHandle<BtPostDownloadHandler>
+SharedHandle<PostDownloadHandler>
 DownloadHandlerFactory::btPostDownloadHandler_;
 
-SharedHandle<UTMetadataPostDownloadHandler>
+SharedHandle<PostDownloadHandler>
 DownloadHandlerFactory::btMetadataPostDownloadHandler_;
 #endif // ENABLE_BITTORRENT
@@ -67,5 +67,5 @@ DownloadHandlerFactory::btMetadataPostDownloadHandler_;
 #ifdef ENABLE_METALINK
 
-SharedHandle<MemoryBufferPreDownloadHandler>
+SharedHandle<PreDownloadHandler>
 DownloadHandlerFactory::getMetalinkPreDownloadHandler()
 {
@@ -73,5 +73,5 @@ DownloadHandlerFactory::getMetalinkPreDownloadHandler()
     metalinkPreDownloadHandler_.reset(new MemoryBufferPreDownloadHandler());
 
-    RequestGroupCriteriaHandle criteria
+    SharedHandle<RequestGroupCriteria> criteria
       (new ContentTypeRequestGroupCriteria
        (getMetalinkContentTypes(), getMetalinkExtensions()));
@@ -81,5 +81,5 @@ DownloadHandlerFactory::getMetalinkPreDownloadHandler()
 }
 
-SharedHandle<MetalinkPostDownloadHandler>
+SharedHandle<PostDownloadHandler>
 DownloadHandlerFactory::getMetalinkPostDownloadHandler()
 {
@@ -94,5 +94,5 @@ DownloadHandlerFactory::getMetalinkPostDownloadHandler()
 #ifdef ENABLE_BITTORRENT
 
-SharedHandle<bittorrent::MemoryBencodePreDownloadHandler>
+SharedHandle<PreDownloadHandler>
 DownloadHandlerFactory::getBtPreDownloadHandler()
 {
@@ -101,5 +101,5 @@ DownloadHandlerFactory::getBtPreDownloadHandler()
       (new bittorrent::MemoryBencodePreDownloadHandler());
 
-    RequestGroupCriteriaHandle criteria
+    SharedHandle<RequestGroupCriteria> criteria
       (new ContentTypeRequestGroupCriteria
        (getBtContentTypes(), getBtExtensions()));
@@ -109,5 +109,5 @@ DownloadHandlerFactory::getBtPreDownloadHandler()
 }
 
-SharedHandle<BtPostDownloadHandler>
+SharedHandle<PostDownloadHandler>
 DownloadHandlerFactory::getBtPostDownloadHandler()
 {
@@ -118,5 +118,5 @@ DownloadHandlerFactory::getBtPostDownloadHandler()
 }
 
-SharedHandle<UTMetadataPostDownloadHandler>
+SharedHandle<PostDownloadHandler>
 DownloadHandlerFactory::getUTMetadataPostDownloadHandler()
 {
diff --git a/src/DownloadHandlerFactory.h b/src/DownloadHandlerFactory.h
index 1ec81fd7..34c7cd23 100644
--- a/src/DownloadHandlerFactory.h
+++ b/src/DownloadHandlerFactory.h
@@ -57,38 +57,38 @@ class DownloadHandlerFactory
 private:
 #ifdef ENABLE_METALINK
-  static SharedHandle<MemoryBufferPreDownloadHandler>
+  static SharedHandle<PreDownloadHandler>
   metalinkPreDownloadHandler_;
 
-  static SharedHandle<MetalinkPostDownloadHandler>
+  static SharedHandle<PostDownloadHandler>
   metalinkPostDownloadHandler_;
 #endif // ENABLE_METALINK
 
 #ifdef ENABLE_BITTORRENT
-  static SharedHandle<bittorrent::MemoryBencodePreDownloadHandler>
+  static SharedHandle<PreDownloadHandler>
   btPreDownloadHandler_;
 
-  static SharedHandle<BtPostDownloadHandler>
+  static SharedHandle<PostDownloadHandler>
   btPostDownloadHandler_;
 
-  static SharedHandle<UTMetadataPostDownloadHandler>
+  static SharedHandle<PostDownloadHandler>
   btMetadataPostDownloadHandler_;
 #endif // ENABLE_BITTORRENT
 public:
 #ifdef ENABLE_METALINK
-  static SharedHandle<MemoryBufferPreDownloadHandler>
+  static SharedHandle<PreDownloadHandler>
   getMetalinkPreDownloadHandler();
 
-  static SharedHandle<MetalinkPostDownloadHandler>
+  static SharedHandle<PostDownloadHandler>
   getMetalinkPostDownloadHandler();
 #endif // ENABLE_METALINK
 
 #ifdef ENABLE_BITTORRENT
-  static SharedHandle<bittorrent::MemoryBencodePreDownloadHandler>
+  static SharedHandle<PreDownloadHandler>
   getBtPreDownloadHandler();
 
-  static SharedHandle<BtPostDownloadHandler>
+  static SharedHandle<PostDownloadHandler>
   getBtPostDownloadHandler();
 
-  static SharedHandle<UTMetadataPostDownloadHandler>
+  static SharedHandle<PostDownloadHandler>
   getUTMetadataPostDownloadHandler();
 #endif // ENABLE_BITTORRENT
diff --git a/src/RequestGroupCriteria.h b/src/RequestGroupCriteria.h
index 69e4ae69..7cbaa332 100644
--- a/src/RequestGroupCriteria.h
+++ b/src/RequestGroupCriteria.h
@@ -51,6 +51,4 @@ public:
 };
 
-typedef SharedHandle<RequestGroupCriteria> RequestGroupCriteriaHandle;
-
 } // namespace aria2
 
","Code cleanup

"
236,Go,45bd3b1bc4aa36ef313899fa372c23d850380b12,https://github.com/golang/go/commit/45bd3b1bc4aa36ef313899fa372c23d850380b12,A,golang,go,"[3, 96, 0, 4, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/src/cmd/link/internal/ld/data.go b/src/cmd/link/internal/ld/data.go
index 46fc6ec304..5cd7727cd0 100644
--- a/src/cmd/link/internal/ld/data.go
+++ b/src/cmd/link/internal/ld/data.go
@@ -1258,4 +1258,79 @@ func (p *GCProg) AddSym(s *sym.Symbol) {
 }
 
+type GCProg2 struct {
+	ctxt *Link
+	sym  *loader.SymbolBuilder
+	w    gcprog.Writer
+}
+
+func (p *GCProg2) Init(ctxt *Link, name string) {
+	p.ctxt = ctxt
+	symIdx := ctxt.loader.LookupOrCreateSym(name, 0)
+	p.sym = ctxt.loader.MakeSymbolUpdater(symIdx)
+	p.w.Init(p.writeByte())
+	if debugGCProg {
+		fmt.Fprintf(os.Stderr, ""ld: start GCProg %s\n"", name)
+		p.w.Debug(os.Stderr)
+	}
+}
+
+func (p *GCProg2) writeByte() func(x byte) {
+	return func(x byte) {
+		p.sym.AddUint8(x)
+	}
+}
+
+func (p *GCProg2) End(size int64) {
+	p.w.ZeroUntil(size / int64(p.ctxt.Arch.PtrSize))
+	p.w.End()
+	if debugGCProg {
+		fmt.Fprintf(os.Stderr, ""ld: end GCProg\n"")
+	}
+}
+
+func (p *GCProg2) AddSym(s loader.Sym) {
+	ldr := p.ctxt.loader
+	typ := ldr.SymGoType(s)
+
+	// Things without pointers should be in sym.SNOPTRDATA or sym.SNOPTRBSS;
+	// everything we see should have pointers and should therefore have a type.
+	if typ == 0 {
+		switch p.sym.Name() {
+		case ""runtime.data"", ""runtime.edata"", ""runtime.bss"", ""runtime.ebss"":
+			// Ignore special symbols that are sometimes laid out
+			// as real symbols. See comment about dyld on darwin in
+			// the address function.
+			return
+		}
+		p.ctxt.Errorf(p.sym.Sym(), ""missing Go type information for global symbol: size %d"", ldr.SymSize(s))
+		return
+	}
+
+	ptrsize := int64(p.ctxt.Arch.PtrSize)
+	typData := ldr.Data(typ)
+	nptr := decodetypePtrdata(p.ctxt.Arch, typData) / ptrsize
+
+	if debugGCProg {
+		fmt.Fprintf(os.Stderr, ""gcprog sym: %s at %d (ptr=%d+%d)\n"", ldr.SymName(s), ldr.SymValue(s), ldr.SymValue(s)/ptrsize, nptr)
+	}
+
+	sval := ldr.SymValue(s)
+	if decodetypeUsegcprog(p.ctxt.Arch, typData) == 0 {
+		// Copy pointers from mask into program.
+		mask := decodetypeGcmask2(p.ctxt, typ)
+		for i := int64(0); i < nptr; i++ {
+			if (mask[i/8]>>uint(i%8))&1 != 0 {
+				p.w.Ptr(sval/ptrsize + i)
+			}
+		}
+		return
+	}
+
+	// Copy program.
+	prog := decodetypeGcprog2(p.ctxt, typ)
+	p.w.ZeroUntil(sval / ptrsize)
+	p.w.Append(prog[4:], nptr)
+}
+
 // dataSortKey is used to sort a slice of data symbol *sym.Symbol pointers.
 // The sort keys are kept inline to improve cache behavior while sorting.
diff --git a/src/cmd/link/internal/ld/decodesym.go b/src/cmd/link/internal/ld/decodesym.go
index 50586081d3..8e248fc982 100644
--- a/src/cmd/link/internal/ld/decodesym.go
+++ b/src/cmd/link/internal/ld/decodesym.go
@@ -107,5 +107,5 @@ func findShlibSection(ctxt *Link, path string, addr uint64) *elf.Section {
 func decodetypeGcprog(ctxt *Link, s *sym.Symbol) []byte {
 	if s.Type == sym.SDYNIMPORT {
-		addr := decodetypeGcprogShlib(ctxt, s)
+		addr := decodetypeGcprogShlib(ctxt, s.P)
 		sect := findShlibSection(ctxt, s.File, addr)
 		if sect != nil {
@@ -124,14 +124,14 @@ func decodetypeGcprog(ctxt *Link, s *sym.Symbol) []byte {
 }
 
-func decodetypeGcprogShlib(ctxt *Link, s *sym.Symbol) uint64 {
+func decodetypeGcprogShlib(ctxt *Link, data []byte) uint64 {
 	if ctxt.Arch.Family == sys.ARM64 {
 		return 0
 	}
-	return decodeInuxi(ctxt.Arch, s.P[2*int32(ctxt.Arch.PtrSize)+8+1*int32(ctxt.Arch.PtrSize):], ctxt.Arch.PtrSize)
+	return decodeInuxi(ctxt.Arch, data[2*int32(ctxt.Arch.PtrSize)+8+1*int32(ctxt.Arch.PtrSize):], ctxt.Arch.PtrSize)
 }
 
 func decodetypeGcmask(ctxt *Link, s *sym.Symbol) []byte {
 	if s.Type == sym.SDYNIMPORT {
-		addr := decodetypeGcprogShlib(ctxt, s)
+		addr := decodetypeGcprogShlib(ctxt, s.P)
 		ptrdata := decodetypePtrdata(ctxt.Arch, s.P)
 		sect := findShlibSection(ctxt, s.File, addr)
diff --git a/src/cmd/link/internal/ld/decodesym2.go b/src/cmd/link/internal/ld/decodesym2.go
index 8b19afffa3..33b85f3dff 100644
--- a/src/cmd/link/internal/ld/decodesym2.go
+++ b/src/cmd/link/internal/ld/decodesym2.go
@@ -8,4 +8,5 @@ import (
 	""cmd/internal/sys""
 	""cmd/link/internal/loader""
+	""cmd/link/internal/sym""
 )
 
@@ -130,2 +131,44 @@ func decodetypeStr2(ldr *loader.Loader, arch *sys.Arch, symIdx loader.Sym) strin
 	return str
 }
+
+func decodetypeGcmask2(ctxt *Link, s loader.Sym) []byte {
+	if ctxt.loader.SymType(s) == sym.SDYNIMPORT {
+		symData := ctxt.loader.Data(s)
+		addr := decodetypeGcprogShlib(ctxt, symData)
+		ptrdata := decodetypePtrdata(ctxt.Arch, symData)
+		sect := findShlibSection(ctxt, ctxt.loader.SymPkg(s), addr)
+		if sect != nil {
+			r := make([]byte, ptrdata/int64(ctxt.Arch.PtrSize))
+			sect.ReadAt(r, int64(addr-sect.Addr))
+			return r
+		}
+		Exitf(""cannot find gcmask for %s"", ctxt.loader.SymName(s))
+		return nil
+	}
+	relocs := ctxt.loader.Relocs(s)
+	mask := decodeRelocSym2(ctxt.loader, s, &relocs, 2*int32(ctxt.Arch.PtrSize)+8+1*int32(ctxt.Arch.PtrSize))
+	return ctxt.loader.Data(mask)
+}
+
+// Type.commonType.gc
+func decodetypeGcprog2(ctxt *Link, s loader.Sym) []byte {
+	if ctxt.loader.SymType(s) == sym.SDYNIMPORT {
+		symData := ctxt.loader.Data(s)
+		addr := decodetypeGcprogShlib(ctxt, symData)
+		sect := findShlibSection(ctxt, ctxt.loader.SymPkg(s), addr)
+		if sect != nil {
+			// A gcprog is a 4-byte uint32 indicating length, followed by
+			// the actual program.
+			progsize := make([]byte, 4)
+			sect.ReadAt(progsize, int64(addr-sect.Addr))
+			progbytes := make([]byte, ctxt.Arch.ByteOrder.Uint32(progsize))
+			sect.ReadAt(progbytes, int64(addr-sect.Addr+4))
+			return append(progsize, progbytes...)
+		}
+		Exitf(""cannot find gcmask for %s"", ctxt.loader.SymName(s))
+		return nil
+	}
+	relocs := ctxt.loader.Relocs(s)
+	rs := decodeRelocSym2(ctxt.loader, s, &relocs, 2*int32(ctxt.Arch.PtrSize)+8+1*int32(ctxt.Arch.PtrSize))
+	return ctxt.loader.Data(rs)
+}
","[dev.link] cmd/link: create loader-specific version of GCProg

Create a new version of the GCProg type + methods that use loader APIs
instead of sym.Symbol.

This code isn't actually used just yet, but will be needed once the
wavefront reaches dodata() and we need to convert that phase.

Change-Id: I087521832015818204fe5c2ac99c7bd3f61b2bf0
Reviewed-on: https://go-review.googlesource.com/c/go/+/229037
Run-TryBot: Than McIntosh <thanm@google.com>
TryBot-Result: Gobot Gobot <gobot@golang.org>
Reviewed-by: Cherry Zhang <cherryyz@google.com>

"
260,Go,ecf1b37850461f680d48ba1cd1351e79b26f742a,https://github.com/gin-gonic/gin/commit/ecf1b37850461f680d48ba1cd1351e79b26f742a,P,gin-gonic,gin,"[1, 3, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/doc.go b/doc.go
new file mode 100644
index 0000000..01ac4a9
--- /dev/null
+++ b/doc.go
@@ -0,0 +1,6 @@
+/*
+Package gin implements a HTTP web framework called gin.
+
+See https://gin-gonic.github.io/gin/ for more information about gin.
+*/
+package gin // import ""github.com/gin-gonic/gin""
","add doc.go (#970)


"
269,Go,b512566acfe0b4ed3496f30a8801b951edb4ea9b,https://github.com/gin-gonic/gin/commit/b512566acfe0b4ed3496f30a8801b951edb4ea9b,P,gin-gonic,gin,"[0, 0, 0, 0, 0, 0, 0, 1, 34, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/gin_integration_test.go b/gin_integration_test.go
new file mode 100644
index 0000000..47d1e10
--- /dev/null
+++ b/gin_integration_test.go
@@ -0,0 +1,40 @@
+package gin
+
+import (
+	""bufio""
+	""bytes""
+	""fmt""
+	""net""
+	""net/http""
+	""testing""
+	""time""
+
+	""github.com/stretchr/testify/assert""
+)
+
+func TestUnixSocket(t *testing.T) {
+	buffer := new(bytes.Buffer)
+	router := New()
+	go func() {
+		router.Use(LoggerWithWriter(buffer))
+		router.GET(""/example"", func(c *Context) { c.String(http.StatusOK, ""it worked"") })
+		router.RunUnix(""/tmp/unix_unit_test"")
+	}()
+	// have to wait for the goroutine to start and run the server
+	// otherwise the main thread will complete
+	time.Sleep(5 * time.Millisecond)
+
+	c, err := net.Dial(""unix"", ""/tmp/unix_unit_test"")
+	if err != nil {
+		println(err)
+		t.FailNow()
+	}
+	fmt.Fprintf(c, ""GET /example HTTP/1.0\r\n\r\n"")
+	scanner := bufio.NewScanner(c)
+	var response string
+	for scanner.Scan() {
+		response += scanner.Text()
+	}
+	assert.Contains(t, response, ""HTTP/1.0 200"", ""should get a 200"")
+	assert.Contains(t, response, ""it worked"", ""resp body should match"")
+}
","unix socket integration test

"
271,Go,740fb05b210fbb872c05f073b9dcb0ebbe1aada9,https://github.com/fatedier/frp/commit/740fb05b210fbb872c05f073b9dcb0ebbe1aada9,P,fatedier,frp,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 3, 3, 0, 0, 0, 0, 1, 0, 0, 2]","diff --git a/Makefile b/Makefile
index b553eaa..2136238 100644
--- a/Makefile
+++ b/Makefile
@@ -1,15 +1,11 @@
 export PATH := $(GOPATH)/bin:$(PATH)
-export OLDGOPATH := $(GOPATH)
-export GOPATH := $(shell pwd):$(GOPATH)
+export GOPATH := $(shell pwd)/Godeps/_workspace:$(shell pwd):$(GOPATH)
 
 all: build
 
-build: godep fmt frps frpc build_test
+build: fmt frps frpc build_test
 
 build_test: echo_server http_server
 
-godep:
-	GOPATH=$(OLDGOPATH) go get github.com/tools/godep
-
 fmt:
 	go fmt ./src/...
@@ -19,24 +15,24 @@ fmt:
 
 frps:
-	godep go build -o bin/frps ./src/frp/cmd/frps
+	go build -o bin/frps ./src/frp/cmd/frps
 
 frpc:
-	godep go build -o bin/frpc ./src/frp/cmd/frpc
+	go build -o bin/frpc ./src/frp/cmd/frpc
 
 echo_server:
-	godep go build -o test/bin/echo_server ./test/echo_server.go
+	go build -o test/bin/echo_server ./test/echo_server.go
 
 http_server:
-	godep go build -o test/bin/http_server ./test/http_server.go
+	go build -o test/bin/http_server ./test/http_server.go
 
 test: gotest
 
 gotest:
-	godep go test -v ./src/...
+	go test -v ./src/...
 
 alltest:
 	cd ./test && ./run_test.sh && cd -
-	godep go test -v ./src/...
-	godep go test -v ./test/func_test.go
+	go test -v ./src/...
+	go test -v ./test/func_test.go
 	cd ./test && ./clean_test.sh && cd -
 
diff --git a/Makefile.cross-compiles b/Makefile.cross-compiles
index 76c287a..5f47bb8 100644
--- a/Makefile.cross-compiles
+++ b/Makefile.cross-compiles
@@ -5,7 +5,7 @@ export GOPATH := $(shell pwd)/Godeps/_workspace:$(shell pwd):$(GOPATH)
 all: build
 
-build: godep app 
+build: gox app 
 
-godep:
+gox:
 	GOPATH=$(OLDGOPATH) go get github.com/mitchellh/gox
 
","build: remove godep command(can not download packages in golang.org used in latest godep version)

"
279,Go,44eb513f059a4e8d24cf0680673b047cf55b5712,https://github.com/fatedier/frp/commit/44eb513f059a4e8d24cf0680673b047cf55b5712,P,fatedier,frp,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 27, 53, 8, 2, 14, 2, 8, 0, 0, 0, 0]","diff --git a/.github/workflows/build-and-push-image.yml b/.github/workflows/build-and-push-image.yml
index d929e58..f089027 100644
--- a/.github/workflows/build-and-push-image.yml
+++ b/.github/workflows/build-and-push-image.yml
@@ -11,41 +11,7 @@ on:
         default: 'test'
 jobs:
-  binary:
-    name: Build Golang project
-    runs-on: ubuntu-latest
-    steps:
-      - name: Set up Go 1.x
-        uses: actions/setup-go@v2
-        with:
-          go-version: 1.18
-
-      - run: |
-          # https://github.com/actions/setup-go/issues/107
-          cp -f `which go` /usr/bin/go
-
-      - run: go version
-
-      - name: Check out code into the Go module directory
-        uses: actions/checkout@v2
-
-      - name: Build
-        run: make build
-
-      - name: Archive artifacts for frpc
-        uses: actions/upload-artifact@v1
-        with:
-          name: frpc
-          path: bin/frpc
-
-      - name: Archive artifacts for frps
-        uses: actions/upload-artifact@v1
-        with:
-          name: frps
-          path: bin/frps
-
   image:
     name: Build Image from Dockerfile and binaries
     runs-on: ubuntu-latest
-    needs: binary
     steps:
       # environment
@@ -61,17 +27,4 @@ jobs:
         uses: docker/setup-buildx-action@v1
 
-      # download binaries of frpc and frps
-      - name: Download binary of frpc
-        uses: actions/download-artifact@v2
-        with:
-          name: frpc
-          path: bin/frpc
-
-      - name: Download binary of frps
-        uses: actions/download-artifact@v2
-        with:
-          name: frps
-          path: bin/frps
-
       # get image tag name
       - name: Get Image Tag Name
@@ -82,4 +35,16 @@ jobs:
             echo ""TAG_NAME=${{ github.event.inputs.tag }}"" >> $GITHUB_ENV
           fi
+      - name: Login to DockerHub
+        uses: docker/login-action@v1
+        with:
+          username: ${{ secrets.DOCKERHUB_USERNAME }}
+          password: ${{ secrets.DOCKERHUB_PASSWORD }}
+
+      - name: Login to the GPR
+        uses: docker/login-action@v1
+        with:
+          registry: ghcr.io
+          username: ${{ github.actor }}
+          password: ${{ secrets.GITHUB_TOKEN }}
 
       # prepare image tags
@@ -93,25 +58,27 @@ jobs:
           echo ""TAG_FRPS_GPR=ghcr.io/fatedier/frps:${{ env.TAG_NAME }}"" >> $GITHUB_ENV
 
-      # build images
-      - name: Build Images
-        run: |
-          # for Docker hub
-          docker build --file ${{ env.DOCKERFILE_FRPC_PATH }} --tag ${{ env.TAG_FRPC }} .
-          docker build --file ${{ env.DOCKERFILE_FRPS_PATH }} --tag ${{ env.TAG_FRPS }} .
-          # for GPR
-          docker build --file ${{ env.DOCKERFILE_FRPC_PATH }} --tag ${{ env.TAG_FRPC_GPR }} .
-          docker build --file ${{ env.DOCKERFILE_FRPS_PATH }} --tag ${{ env.TAG_FRPS_GPR }} .
-
-      # push to dockerhub
-      - name: Publish to Dockerhub
-        run: |
-          echo ${{ secrets.DOCKERHUB_PASSWORD }} | docker login --username ${{ secrets.DOCKERHUB_USERNAME }} --password-stdin
-          docker push ${{ env.TAG_FRPC }}
-          docker push ${{ env.TAG_FRPS }}
-
-      # push to gpr
-      - name: Publish to GPR
-        run: |
-          echo ${{ secrets.GPR_TOKEN }} | docker login ghcr.io --username ${{ github.repository_owner }} --password-stdin
-          docker push ${{ env.TAG_FRPC_GPR }}
-          docker push ${{ env.TAG_FRPS_GPR }}
+      - name: Build and push frpc
+        uses: docker/build-push-action@v2
+        with:
+          context: .
+          file: ./dockerfiles/Dockerfile-for-frpc
+          platforms: linux/386,linux/amd64,linux/arm/v6,linux/arm/v7,linux/arm64/v8,linux/ppc64le,linux/s390x
+          push: ${{ github.event_name != 'pull_request' }}
+          cache-from: type=local,src=/tmp/.buildx-cache
+          cache-to: type=local,dest=/tmp/.buildx-cache,mode=max
+          tags: |
+            ${{ env.TAG_FRPC }}
+            ${{ env.TAG_FRPC_GPR }}
+
+      - name: Build and push frps
+        uses: docker/build-push-action@v2
+        with:
+          context: .
+          file: ./dockerfiles/Dockerfile-for-frps
+          platforms: linux/386,linux/amd64,linux/arm/v6,linux/arm/v7,linux/arm64/v8,linux/ppc64le,linux/s390x
+          push: ${{ github.event_name != 'pull_request' }}
+          cache-from: type=local,src=/tmp/.buildx-cache
+          cache-to: type=local,dest=/tmp/.buildx-cache,mode=max
+          tags: |
+            ${{ env.TAG_FRPS }}
+            ${{ env.TAG_FRPS_GPR }}
diff --git a/dockerfiles/Dockerfile-for-frpc b/dockerfiles/Dockerfile-for-frpc
index fce3d57..b9eb18a 100644
--- a/dockerfiles/Dockerfile-for-frpc
+++ b/dockerfiles/Dockerfile-for-frpc
@@ -1,14 +1,17 @@
-FROM alpine:3 AS temp
+FROM golang:1.18-alpine3.15 AS building
 
-COPY bin/frpc /tmp
+COPY . /building
+WORKDIR /building
 
-RUN chmod -R 777 /tmp/frpc
+RUN apk --no-cache add \
+    git \
+ && export GO111MODULE=on \
+ && env CGO_ENABLED=0 go build -trimpath -ldflags ""-s -w"" -o ./bin/frpc ./cmd/frpc
 
+FROM alpine:3.15
+LABEL maintainer=""i@muir.fun""
 
-FROM alpine:3
-
-WORKDIR /app
-
-COPY --from=temp /tmp/frpc /usr/bin
+COPY --from=building /building/bin/frpc /usr/bin/frpc
 
 ENTRYPOINT [""/usr/bin/frpc""]
+CMD [""-h""]
\ No newline at end of file
diff --git a/dockerfiles/Dockerfile-for-frps b/dockerfiles/Dockerfile-for-frps
index 3d65a9e..d5809e9 100644
--- a/dockerfiles/Dockerfile-for-frps
+++ b/dockerfiles/Dockerfile-for-frps
@@ -1,14 +1,17 @@
-FROM alpine:3 AS temp
+FROM golang:1.18-alpine3.15 AS building
 
-COPY bin/frps /tmp
+COPY . /building
+WORKDIR /building
 
-RUN chmod -R 777 /tmp/frps
+RUN apk --no-cache add \
+    git \
+ && export GO111MODULE=on \
+ && env CGO_ENABLED=0 go build -trimpath -ldflags ""-s -w"" -o ./bin/frps ./cmd/frps
 
+FROM alpine:3.15
+LABEL maintainer=""i@muir.fun""
 
-FROM alpine:3
-
-WORKDIR /app
-
-COPY --from=temp /tmp/frps /usr/bin
+COPY --from=building /building/bin/frps /usr/bin/frps
 
 ENTRYPOINT [""/usr/bin/frps""]
+CMD [""-h""]
\ No newline at end of file
","Update docker image build file (#2892)

* update docker image building
"
292,Go,fc77b6303c8aeda6362d7e2fc5d0fe52067c1a8d,https://github.com/gohugoio/hugo/commit/fc77b6303c8aeda6362d7e2fc5d0fe52067c1a8d,P,gohugoio,hugo,"[3, 31, 6, 0, 12, 0, 0, 1, 0, 12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/tpl/inflect/init.go b/tpl/inflect/init.go
new file mode 100644
index 00000000..b42ae5af
--- /dev/null
+++ b/tpl/inflect/init.go
@@ -0,0 +1,50 @@
+// Copyright 2017 The Hugo Authors. All rights reserved.
+//
+// Licensed under the Apache License, Version 2.0 (the ""License"");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+// http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an ""AS IS"" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package inflect
+
+import (
+	""github.com/spf13/hugo/deps""
+	""github.com/spf13/hugo/tpl/internal""
+)
+
+const name = ""inflect""
+
+func init() {
+	f := func(d *deps.Deps) *internal.TemplateFuncsNamespace {
+		ctx := New()
+
+		examples := [][2]string{
+			{`{{ humanize ""my-first-post"" }}`, `My first post`},
+			{`{{ humanize ""myCamelPost"" }}`, `My camel post`},
+			{`{{ humanize ""52"" }}`, `52nd`},
+			{`{{ humanize 103 }}`, `103rd`},
+			{`{{ ""cat"" | pluralize }}`, `cats`},
+			{`{{ ""cats"" | singularize }}`, `cat`},
+		}
+
+		return &internal.TemplateFuncsNamespace{
+			Name:    name,
+			Context: func() interface{} { return ctx },
+			Aliases: map[string]interface{}{
+				""humanize"":    ctx.Humanize,
+				""pluralize"":   ctx.Pluralize,
+				""singularize"": ctx.Singularize,
+			},
+			Examples: examples,
+		}
+
+	}
+
+	internal.AddTemplateFuncsNamespace(f)
+}
diff --git a/tpl/tplimpl/templateFuncster.go b/tpl/tplimpl/templateFuncster.go
index 5b2594cd..a4001f56 100644
--- a/tpl/tplimpl/templateFuncster.go
+++ b/tpl/tplimpl/templateFuncster.go
@@ -22,5 +22,4 @@ import (
 	bp ""github.com/spf13/hugo/bufferpool""
 	""github.com/spf13/hugo/deps""
-	""github.com/spf13/hugo/tpl/inflect""
 	""github.com/spf13/hugo/tpl/os""
 	""github.com/spf13/hugo/tpl/safe""
@@ -36,5 +35,4 @@ type templateFuncster struct {
 
 	// Namespaces
-	inflect   *inflect.Namespace
 	os        *os.Namespace
 	safe      *safe.Namespace
@@ -52,5 +50,4 @@ func newTemplateFuncster(deps *deps.Deps) *templateFuncster {
 
 		// Namespaces
-		inflect:   inflect.New(),
 		os:        os.New(deps),
 		safe:      safe.New(),
diff --git a/tpl/tplimpl/template_funcs.go b/tpl/tplimpl/template_funcs.go
index cc9711fa..0bc8f459 100644
--- a/tpl/tplimpl/template_funcs.go
+++ b/tpl/tplimpl/template_funcs.go
@@ -31,4 +31,5 @@ import (
 	_ ""github.com/spf13/hugo/tpl/encoding""
 	_ ""github.com/spf13/hugo/tpl/images""
+	_ ""github.com/spf13/hugo/tpl/inflect""
 	_ ""github.com/spf13/hugo/tpl/lang""
 	_ ""github.com/spf13/hugo/tpl/math""
@@ -87,7 +88,6 @@ func (t *templateFuncster) initFuncMap() {
 	funcMap := template.FuncMap{
 		// Namespaces
-		""inflect"": t.inflect.Namespace,
-		""os"":      t.os.Namespace,
-		""safe"":    t.safe.Namespace,
+		""os"":   t.os.Namespace,
+		""safe"": t.safe.Namespace,
 		//""time"":        t.time.Namespace,
 		""transform"": t.transform.Namespace,
@@ -102,5 +102,4 @@ func (t *templateFuncster) initFuncMap() {
 		""htmlEscape"":    t.transform.HTMLEscape,
 		""htmlUnescape"":  t.transform.HTMLUnescape,
-		""humanize"":      t.inflect.Humanize,
 		""int"":           func(v interface{}) (int, error) { return cast.ToIntE(v) },
 		""markdownify"":   t.transform.Markdownify,
@@ -109,5 +108,4 @@ func (t *templateFuncster) initFuncMap() {
 		""partialCached"": t.partialCached,
 		""plainify"":      t.transform.Plainify,
-		""pluralize"":     t.inflect.Pluralize,
 		""print"":         fmt.Sprint,
 		""printf"":        fmt.Sprintf,
@@ -127,5 +125,4 @@ func (t *templateFuncster) initFuncMap() {
 		""sanitizeURL"":   t.safe.SanitizeURL,
 		""sanitizeurl"":   t.safe.SanitizeURL,
-		""singularize"":   t.inflect.Singularize,
 		""string"":        func(v interface{}) (string, error) { return cast.ToStringE(v) },
 		""time"":          t.time.AsTime,
diff --git a/tpl/tplimpl/template_funcs_test.go b/tpl/tplimpl/template_funcs_test.go
index 52bf499a..e894d328 100644
--- a/tpl/tplimpl/template_funcs_test.go
+++ b/tpl/tplimpl/template_funcs_test.go
@@ -135,8 +135,4 @@ htmlUnescape 3: {{""Cathal Garvey &amp;amp; The Sunshine Band &amp;lt;cathal@foo.
 htmlUnescape 4: {{ htmlEscape ""Cathal Garvey & The Sunshine Band <cathal@foo.bar>"" | htmlUnescape | safeHTML }}
 htmlUnescape 5: {{ htmlUnescape ""Cathal Garvey &amp; The Sunshine Band &lt;cathal@foo.bar&gt;"" | htmlEscape | safeHTML }}
-humanize 1: {{ humanize ""my-first-post"" }}
-humanize 2: {{ humanize ""myCamelPost"" }}
-humanize 3: {{ humanize ""52"" }}
-humanize 4: {{ humanize 103 }}
 markdownify: {{ .Title | markdownify}}
 print: {{ print ""works!"" }}
@@ -144,5 +140,4 @@ printf: {{ printf ""%s!"" ""works"" }}
 println: {{ println ""works!"" -}}
 plainify: {{ plainify  ""Hello <strong>world</strong>, gophers!"" }}
-pluralize: {{ ""cat"" | pluralize }}
 readDir: {{ range (readDir ""."") }}{{ .Name }}{{ end }}
 readFile: {{ readFile ""README.txt"" }}
@@ -156,5 +151,4 @@ safeHTML: {{ ""Bat&Man"" | safeHTML }}
 safeJS: {{ ""(1*2)"" | safeJS | safeJS }}
 safeURL: {{ ""http://gohugo.io"" | safeURL | safeURL }}
-singularize: {{ ""cats"" | singularize }}
 strings.TrimPrefix: {{ strings.TrimPrefix ""Goodbye,, world!"" ""Goodbye,"" }}
 time: {{ (time ""2015-01-21"").Year }}
@@ -176,8 +170,4 @@ htmlUnescape 3: Cathal Garvey &amp; The Sunshine Band &lt;cathal@foo.bar&gt;
 htmlUnescape 4: Cathal Garvey & The Sunshine Band <cathal@foo.bar>
 htmlUnescape 5: Cathal Garvey &amp; The Sunshine Band &lt;cathal@foo.bar&gt;
-humanize 1: My first post
-humanize 2: My camel post
-humanize 3: 52nd
-humanize 4: 103rd
 markdownify: <strong>BatMan</strong>
 print: works!
@@ -185,5 +175,4 @@ printf: works!
 println: works!
 plainify: Hello world, gophers!
-pluralize: cats
 readDir: README.txt
 readFile: Hugo Rocks!
@@ -197,5 +186,4 @@ safeHTML: Bat&Man
 safeJS: (1*2)
 safeURL: http://gohugo.io
-singularize: cat
 strings.TrimPrefix: , world!
 time: 2015
","tpl/inflect: Make it a package that stands on its own

See #3042

"
311,Go,cf95e44cb4ce6f42a318abba0efa77c7311c87c9,https://github.com/junegunn/fzf/commit/cf95e44cb4ce6f42a318abba0efa77c7311c87c9,A,junegunn,fzf,"[3, 18, 0, 3, 0, 0, 0, 1, 6, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 5, 0, 0, 1, 10, 0, 0]","diff --git a/CHANGELOG.md b/CHANGELOG.md
index 4232d68..0984986 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -4,4 +4,9 @@ CHANGELOG
 0.40.0
 ------
+- Added `zero` event that is triggered when there's no match
+  ```sh
+  # Reload the candidate list when there's no match
+  echo $RANDOM | fzf --bind 'zero:reload(echo $RANDOM)+clear-query' --height 3
+  ```
 - New actions
     - Added `track` action which makes fzf track the current item when the
diff --git a/man/man1/fzf.1 b/man/man1/fzf.1
index 0d70675..14bfc26 100644
--- a/man/man1/fzf.1
+++ b/man/man1/fzf.1
@@ -1009,4 +1009,15 @@ e.g.
      seq 10 | fzf --bind one:accept\fR
 .RE
+\fIzero\fR
+.RS
+Triggered when there's no match. \fBzero:abort\fR binding is comparable to
+\fB--exit-0\fR option, but the difference is that \fB--exit-0\fR is only
+effective before the interactive finder starts but \fBzero\fR event is
+triggered by the interactive finder.
+
+e.g.
+     \fB# Reload the candidate list when there's no match
+     echo $RANDOM | fzf --bind 'zero:reload(echo $RANDOM)+clear-query' --height 3\fR
+.RE
 
 \fIbackward-eof\fR
diff --git a/src/options.go b/src/options.go
index e0a5caf..6f6b25e 100644
--- a/src/options.go
+++ b/src/options.go
@@ -633,4 +633,6 @@ func parseKeyChordsImpl(str string, message string, exit func(string)) map[tui.E
 		case ""one"":
 			add(tui.One)
+		case ""zero"":
+			add(tui.Zero)
 		case ""alt-enter"", ""alt-return"":
 			chords[tui.CtrlAltKey('m')] = key
diff --git a/src/terminal.go b/src/terminal.go
index 47991a6..3dc2062 100644
--- a/src/terminal.go
+++ b/src/terminal.go
@@ -957,8 +957,16 @@ func (t *Terminal) UpdateList(merger *Merger, reset bool) {
 		}
 	}
-	if !t.reading && t.merger.Length() == 1 {
-		one := tui.One.AsEvent()
-		if _, prs := t.keymap[one]; prs {
-			t.eventChan <- one
+	if !t.reading {
+		switch t.merger.Length() {
+		case 0:
+			zero := tui.Zero.AsEvent()
+			if _, prs := t.keymap[zero]; prs {
+				t.eventChan <- zero
+			}
+		case 1:
+			one := tui.One.AsEvent()
+			if _, prs := t.keymap[one]; prs {
+				t.eventChan <- one
+			}
 		}
 	}
@@ -2855,5 +2863,5 @@ func (t *Terminal) Loop() {
 			select {
 			case event = <-t.eventChan:
-				needBarrier = event != tui.Load.AsEvent()
+				needBarrier = !event.Is(tui.Load, tui.One, tui.Zero)
 			case actions = <-t.serverChan:
 				event = tui.Invalid.AsEvent()
diff --git a/src/tui/tui.go b/src/tui/tui.go
index b8b7ae6..a0e0b48 100644
--- a/src/tui/tui.go
+++ b/src/tui/tui.go
@@ -95,4 +95,5 @@ const (
 	Focus
 	One
+	Zero
 
 	AltBS
@@ -284,4 +285,13 @@ type Event struct {
 }
 
+func (e Event) Is(types ...EventType) bool {
+	for _, t := range types {
+		if e.Type == t {
+			return true
+		}
+	}
+	return false
+}
+
 type MouseEvent struct {
 	Y      int
diff --git a/test/test_go.rb b/test/test_go.rb
index fc0b9e0..7cdacde 100755
--- a/test/test_go.rb
+++ b/test/test_go.rb
@@ -2836,10 +2836,11 @@ class TestGoFZF < TestBase
   end
 
-  def test_one
-    tmux.send_keys ""seq 10 | #{FZF} --bind 'one:preview:echo {} is the only match'"", :Enter
+  def test_one_and_zero
+    tmux.send_keys ""seq 10 | #{FZF} --bind 'zero:preview(echo no match),one:preview(echo {} is the only match)'"", :Enter
     tmux.send_keys '1'
     tmux.until do |lines|
       assert_equal 2, lines.match_count
       refute(lines.any? { _1.include?('only match') })
+      refute(lines.any? { _1.include?('no match') })
     end
     tmux.send_keys '0'
@@ -2848,4 +2849,9 @@ class TestGoFZF < TestBase
       assert(lines.any? { _1.include?('only match') })
     end
+    tmux.send_keys '0'
+    tmux.until do |lines|
+      assert_equal 0, lines.match_count
+      assert(lines.any? { _1.include?('no match') })
+    end
   end
 
","Add 'zero' event

Close #3263

"
318,Go,ab182e276badc8222962f4d28a052dfa7f016d88,https://github.com/junegunn/fzf/commit/ab182e276badc8222962f4d28a052dfa7f016d88,C,junegunn,fzf,"[3, 7, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/src/tui/light.go b/src/tui/light.go
index be6950c..e690ef9 100644
--- a/src/tui/light.go
+++ b/src/tui/light.go
@@ -252,6 +252,7 @@ func (r *LightRenderer) updateTerminalSize() {
 func (r *LightRenderer) getch(nonblock bool) (int, bool) {
 	b := make([]byte, 1)
+	fd := r.fd()
 	util.SetNonblock(r.ttyin, nonblock)
-	_, err := r.ttyin.Read(b)
+	_, err := util.Read(fd, b)
 	if err != nil {
 		return 0, false
diff --git a/src/util/util_unix.go b/src/util/util_unix.go
index bc1b7b5..d538ee0 100644
--- a/src/util/util_unix.go
+++ b/src/util/util_unix.go
@@ -27,2 +27,7 @@ func SetNonblock(file *os.File, nonblock bool) {
 	syscall.SetNonblock(int(file.Fd()), nonblock)
 }
+
+// Read executes syscall.Read on file descriptor
+func Read(fd int, b []byte) (int, error) {
+	return syscall.Read(int(fd), b)
+}
diff --git a/src/util/util_windows.go b/src/util/util_windows.go
index 9ba4f79..0664416 100644
--- a/src/util/util_windows.go
+++ b/src/util/util_windows.go
@@ -33,2 +33,7 @@ func SetNonblock(file *os.File, nonblock bool) {
 	syscall.SetNonblock(syscall.Handle(file.Fd()), nonblock)
 }
+
+// Read executes syscall.Read on file descriptor
+func Read(fd int, b []byte) (int, error) {
+	return syscall.Read(syscall.Handle(fd), b)
+}
","Use read syscall directly to get character (#931)

Due to go std lib uses poller for os.File introducing in this commit:
https://github.com/golang/go/commit/c05b06a12d005f50e4776095a60d6bd9c2c91fac
There are two changes to watch out:
1. os.File.Fd will always return a blocking fd except on bsd.
2. os.File.Read won't return EAGAIN error for nonblocking fd.

So
For 1, we just get tty's fd in advance and then set its block mode.
For 2, we use read syscall directly to get what we wanted error(EAGAIN).

Fix issue #910.

Signed-off-by: Tw <tw19881113@gmail.com>
"
353,Go,61b7002d262ab748e3db7cc705c8290447fb5b34,https://github.com/caddyserver/caddy/commit/61b7002d262ab748e3db7cc705c8290447fb5b34,P,caddyserver,caddy,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/.github/workflows/release.yml b/.github/workflows/release.yml
index 081bcfa..02129ab 100644
--- a/.github/workflows/release.yml
+++ b/.github/workflows/release.yml
@@ -74,5 +74,5 @@ jobs:
     # Only publish on non-special tags (e.g. non-beta)
     - name: Publish .deb to Gemfury
-      if: ${{ steps.vars.outputs.tag_special == """" }}
+      if: ${{ steps.vars.outputs.tag_special == '' }}
       env:
         GEMFURY_PUSH_TOKEN: ${{ secrets.GEMFURY_PUSH_TOKEN }}
","ci: Apparently only single-quote strings are supported (#3523)

https://help.github.com/en/actions/reference/context-and-expression-syntax-for-github-actions#literals

https://github.com/caddyserver/caddy/actions/runs/147953515
"
360,Go,3b80c505fbb57fbf6f6abc429cacdade2ac08dc9,https://github.com/caddyserver/caddy/commit/3b80c505fbb57fbf6f6abc429cacdade2ac08dc9,P,caddyserver,caddy,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 6, 0, 10, 0, 0, 0, 0]","diff --git a/README.md b/README.md
index 08baecf..3791130 100644
--- a/README.md
+++ b/README.md
@@ -11,5 +11,5 @@ Please file issues to propose new features and report bugs, and after the bug or
 ### Menu
 
-- [Install](#install)
+- [Build from source](#build-from-source)
 - [Quick Start](#quick-start)
 - [Configuration](#configuration)
@@ -19,5 +19,5 @@ Please file issues to propose new features and report bugs, and after the bug or
 
 
-## Install
+## Build from source
 
 Requirements:
@@ -26,5 +26,5 @@ Requirements:
 - Make sure you do not disable [Go modules](https://github.com/golang/go/wiki/Modules) (`export GO111MODULE=auto`)
 
-Download source code:
+Download the `v2` source code:
 
 ```bash
@@ -359,13 +359,13 @@ Caddy 2 and Caddy Enterprise offer equal levels of security and, as mentioned, s
 ### Does Caddy 2 have telemetry?
 
-No. There was not enough academic interest to continue supporting it. If telemetry does get added later, it will not be on by default or will be vastly reduced in its scope so that it simply helps the community gain an understanding of how widely Caddy is deployed (i.e. counts of servers running, number of requests/connections handled, etc).
+No. There was not enough academic interest to continue supporting it. If telemetry does get added later, it will not be on by default or will be vastly reduced in its scope.
 
 ## Does Caddy 2 use HTTPS by default?
 
-Yes. HTTPS is automatic and enabled by default when possible, just like in Caddy 1. Basically, if your HTTP routes specify a `host` matcher with qualifying domain names, those names will be enabled for automatic HTTPS.
+Yes. HTTPS is automatic and enabled by default when possible, just like in Caddy 1. Basically, if your HTTP routes specify a `host` matcher with qualifying domain names, those names will be enabled for automatic HTTPS. Automatic HTTPS is disabled for domains which match certificates that are manually loaded by your config.
 
-## I'm getting HTTPS errors with Caddy 2. The certificates aren't valid?
+## How do I avoid Let's Encrypt rate limits with Caddy 2?
 
-During development, Caddy 2 uses Let's Encrypt's staging endpoint to avoid rate limit issues, so the certificates are not trusted. You can force the production endpoint if you are confident that your setup is correct and will last a while. You can add a catch-all automation policy to your `tls` app that specifies the production CA endpoint:
+As you are testing and developing with Caddy 2, you may wish to use test (""staging"") certificates from Let's Encrypt to avoid rate limits. By default, Caddy 2 uses Let's Encrypt's production endpoint to get real certificates for your domains, but their [rate limits](https://letsencrypt.org/docs/rate-limits/) forbid testing and development use of this endpoint for good reasons. You can switch to their [staging endpoint](https://letsencrypt.org/docs/staging-environment/) by adding the staging CA to your automation policy in the `tls` app:
 
 ```json
@@ -376,5 +376,5 @@ During development, Caddy 2 uses Let's Encrypt's staging endpoint to avoid rate
 				""management"": {
 					""module"": ""acme"",
-					""ca"": ""https://acme-v02.api.letsencrypt.org/directory""
+					""ca"": ""https://acme-staging-v02.api.letsencrypt.org/directory""
 				}
 			}
@@ -384,6 +384,13 @@ During development, Caddy 2 uses Let's Encrypt's staging endpoint to avoid rate
 ```
 
-## Can we get some access controls on the admin endpoint?
+Or with the Caddyfile:
+
+```
+tls {
+	ca https://acme-staging-v02.api.letsencrypt.org/directory
+}
+```
 
-Yeah, that's coming.
+## Can we get some access controls on the admin endpoint?
 
+Yeah, that's coming. For now, you can use a unix socket that is properly permissioned for some basic security.
","Update v2 readme in prep for beta1

"
379,Go,ffb53c07b840e126d6a0d30b8d3c1b3390f530d0,https://github.com/traefik/traefik/commit/ffb53c07b840e126d6a0d30b8d3c1b3390f530d0,P,traefik,traefik,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 4, 1134, 8]","diff --git a/traefik.sample.toml b/traefik.sample.toml
index 5910be48d..ac2e94d9f 100644
--- a/traefik.sample.toml
+++ b/traefik.sample.toml
@@ -3,14 +3,4 @@
 ################################################################
 
-# Duration to give active requests a chance to finish before Traefik stops.
-# Can be provided in a format supported by [time.ParseDuration](https://golang.org/pkg/time/#ParseDuration) or as raw values (digits).
-# If no units are provided, the value is parsed assuming seconds.
-# Note: in this time frame no new requests are accepted.
-#
-# Optional
-# Default: ""10s""
-#
-# graceTimeOut = ""10s""
-
 # Enable debug mode
 #
@@ -20,11 +10,4 @@
 # debug = true
 
-# Periodically check if a new version has been released
-#
-# Optional
-# Default: true
-#
-# checkNewVersion = false
-
 # Traefik logs file
 # If not defined, logs to stdout
@@ -34,11 +17,4 @@
 # traefikLogsFile = ""log/traefik.log""
 
-# Access logs file
-#
-# Optional
-# DEPRECATED - see [accessLog] lower down
-#
-# accessLogsFile = ""log/access.log""
-
 # Log level
 #
@@ -48,40 +24,4 @@
 # logLevel = ""ERROR""
 
-# Backends throttle duration: minimum duration in seconds between 2 events from providers
-# before applying a new configuration. It avoids unnecessary reloads if multiples events
-# are sent in a short amount of time.
-# Can be provided in a format supported by Go's time.ParseDuration function or
-# as raw values (digits). If no units are provided, the value is parsed assuming
-# seconds.
-#
-# Optional
-# Default: ""2s""
-#
-# ProvidersThrottleDuration = ""5s""
-
-# Controls the maximum idle (keep-alive) connections to keep per-host. If zero, DefaultMaxIdleConnsPerHost
-# from the Go standard library net/http module is used.
-# If you encounter 'too many open files' errors, you can either increase this
-# value or change the `ulimit`.
-#
-# Optional
-# Default: 200
-#
-# MaxIdleConnsPerHost = 200
-
-# If set to true invalid SSL certificates are accepted for backends.
-# Note: This disables detection of man-in-the-middle attacks so should only be used on secure backend networks.
-# Optional
-# Default: false
-#
-# InsecureSkipVerify = true
-
-# Register Certificates in the RootCA. This certificates will be use for backends calls.
-# Note: You can use file path or cert content directly
-# Optional
-# Default: []
-#
-# RootCAs = [ ""/mycert.cert"" ]
-
 # Entrypoints to be used by frontends that do not specify any entrypoint.
 # Each frontend can specify its own entrypoints.
@@ -92,139 +32,11 @@
 # defaultEntryPoints = [""http"", ""https""]
 
-# Constraints definition
-#
-# Optional
-#
-# Simple matching constraint
-# constraints = [""tag==api""]
-#
-# Simple mismatching constraint
-# constraints = [""tag!=api""]
-#
-# Globbing
-# constraints = [""tag==us-*""]
-#
-# Backend-specific constraint
-# [consulCatalog]
-#   endpoint = ""127.0.0.1:8500""
-#   constraints = [""tag==api""]
-#
-# Multiple constraints
-#   - ""tag=="" must match with at least one tag
-#   - ""tag!="" must match with none of tags
-# constraints = [""tag!=us-*"", ""tag!=asia-*""]
-# [consulCatalog]
-#   endpoint = ""127.0.0.1:8500""
-#   constraints = [""tag==api"", ""tag!=v*-beta""]
-
-# Enable ACME (Let's Encrypt): automatic SSL
-#
-# Optional
-#
-# [acme]
-
-# Email address used for registration
-#
-# Required
-#
-# email = ""test@traefik.io""
-
-# File or key used for certificates storage.
-# WARNING, if you use Traefik in Docker, you have 2 options:
-#  - create a file on your host and mount it as a volume
-#      storageFile = ""acme.json""
-#      $ docker run -v ""/my/host/acme.json:acme.json"" traefik
-#  - mount the folder containing the file as a volume
-#      storageFile = ""/etc/traefik/acme/acme.json""
-#      $ docker run -v ""/my/host/acme:/etc/traefik/acme"" traefik
-#
-# Required
-#
-# storage = ""acme.json"" # or ""traefik/acme/account"" if using KV store
-
-# Entrypoint to proxy acme challenge/apply certificates to.
-# WARNING, must point to an entrypoint on port 443
-#
-# Required
-#
-# entryPoint = ""https""
-
-# Use a DNS based acme challenge rather than external HTTPS access, e.g. for a firewalled server
-# Select the provider that matches the DNS domain that will host the challenge TXT record,
-# and provide environment variables with access keys to enable setting it:
-#  - cloudflare: CLOUDFLARE_EMAIL, CLOUDFLARE_API_KEY
-#  - digitalocean: DO_AUTH_TOKEN
-#  - dnsimple: DNSIMPLE_EMAIL, DNSIMPLE_OAUTH_TOKEN
-#  - dnsmadeeasy: DNSMADEEASY_API_KEY, DNSMADEEASY_API_SECRET
-#  - exoscale: EXOSCALE_API_KEY, EXOSCALE_API_SECRET
-#  - gandi: GANDI_API_KEY
-#  - linode: LINODE_API_KEY
-#  - manual: none, but run traefik interactively & turn on acmeLogging to see instructions & press Enter
-#  - namecheap: NAMECHEAP_API_USER, NAMECHEAP_API_KEY
-#  - rfc2136: RFC2136_TSIG_KEY, RFC2136_TSIG_SECRET, RFC2136_TSIG_ALGORITHM, RFC2136_NAMESERVER
-#  - route53: AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_REGION, or configured user/instance IAM profile
-#  - dyn: DYN_CUSTOMER_NAME, DYN_USER_NAME, DYN_PASSWORD
-#  - vultr: VULTR_API_KEY
-#  - ovh: OVH_ENDPOINT, OVH_APPLICATION_KEY, OVH_APPLICATION_SECRET, OVH_CONSUMER_KEY
-#  - pdns: PDNS_API_KEY, PDNS_API_URL
-#
-# Optional
-#
-# dnsProvider = ""digitalocean""
-
-# By default, the dnsProvider will verify the TXT DNS challenge record before letting ACME verify
-# If delayDontCheckDNS is greater than zero, avoid this & instead just wait so many seconds.
-# Useful if internal networks block external DNS queries
-#
-# Optional
-#
-# delayDontCheckDNS = 0
-
-# If true, display debug log messages from the acme client library
-#
-# Optional
-#
-# acmeLogging = true
-
-# Enable on demand certificate. This will request a certificate from Let's Encrypt during the first TLS handshake for a hostname that does not yet have a certificate.
-# WARNING, TLS handshakes will be slow when requesting a hostname certificate for the first time, this can leads to DoS attacks.
-# WARNING, Take note that Let's Encrypt have rate limiting: https://letsencrypt.org/docs/rate-limits
-#
-# Optional
-#
-# onDemand = true
-
-# Enable certificate generation on frontends Host rules. This will request a certificate from Let's Encrypt for each frontend with a Host rule.
-# For example, a rule Host:test1.traefik.io,test2.traefik.io will request a certificate with main domain test1.traefik.io and SAN test2.traefik.io.
-#
-# Optional
-#
-# OnHostRule = true
-
-# CA server to use
-# Uncomment the line to run on the staging let's encrypt server
-# Leave comment to go to prod
+# Entrypoints definition
 #
 # Optional
-#
-# caServer = ""https://acme-staging.api.letsencrypt.org/directory""
-
-# Domains list
-# You can provide SANs (alternative domains) to each main domain
-# All domains must have A/AAAA records pointing to Traefik
-# WARNING, Take note that Let's Encrypt have rate limiting: https://letsencrypt.org/docs/rate-limits
-# Each domain & SANs will lead to a certificate request.
-#
-# [[acme.domains]]
-#   main = ""local1.com""
-#   sans = [""test1.local1.com"", ""test2.local1.com""]
-# [[acme.domains]]
-#   main = ""local2.com""
-#   sans = [""test1.local2.com"", ""test2x.local2.com""]
-# [[acme.domains]]
-#   main = ""local3.com""
-# [[acme.domains]]
-#   main = ""local4.com""
-
+# Default:
+[entryPoints]
+    [entryPoints.http]
+    address = "":80""
 
 # Enable access logs
@@ -251,188 +63,4 @@
 # format = ""common""
 
-# Entrypoints definition
-#
-# Optional
-# Default:
-# [entryPoints]
-#   [entryPoints.http]
-#   address = "":80""
-#
-# To redirect an http entrypoint to an https entrypoint (with SNI support):
-# [entryPoints]
-#   [entryPoints.http]
-#   address = "":80""
-#     [entryPoints.http.redirect]
-#       entryPoint = ""https""
-#   [entryPoints.https]
-#   address = "":443""
-#     [entryPoints.https.tls]
-#       [[entryPoints.https.tls.certificates]]
-#       CertFile = ""integration/fixtures/https/snitest.com.cert""
-#       KeyFile = ""integration/fixtures/https/snitest.com.key""
-#       [[entryPoints.https.tls.certificates]]
-#       CertFile = ""integration/fixtures/https/snitest.org.cert""
-#       KeyFile = ""integration/fixtures/https/snitest.org.key""
-#
-# To redirect an entrypoint rewriting the URL:
-# [entryPoints]
-#   [entryPoints.http]
-#   address = "":80""
-#     [entryPoints.http.redirect]
-#       regex = ""^http://localhost/(.*)""
-#       replacement = ""http://mydomain/$1""
-#
-# To enable basic auth on an entrypoint
-# with 2 user/pass: test:test and test2:test2
-# Passwords can be encoded in MD5, SHA1 and BCrypt: you can use htpasswd to generate those ones
-# Users can be specified directly in the toml file, or indirectly by referencing an external file; if both are provided, the two are merged, with external file contents having precedence
-# [entryPoints]
-#   [entryPoints.http]
-#   address = "":80""
-#   [entryPoints.http.auth.basic]
-#   users = [""test:$apr1$H6uskkkW$IgXLP6ewTrSuBkTrqE8wj/"", ""test2:$apr1$d9hr9HBB$4HxwgUir3HP4EsggP/QNo0""]
-#   usersFile = ""/path/to/.htpasswd""
-#
-# To enable digest auth on an entrypoint
-# with 2 user/realm/pass: test:traefik:test and test2:traefik:test2
-# You can use htdigest to generate those ones
-# Users can be specified directly in the toml file, or indirectly by referencing an external file; if both are provided, the two are merged, with external file contents having precedence
-# [entryPoints]
-#   [entryPoints.http]
-#   address = "":80""
-#   [entryPoints.http.auth.basic]
-#   users = [""test:traefik:a2688e031edb4be6a3797f3882655c05 "", ""test2:traefik:518845800f9e2bfb1f1f740ec24f074e""]
-#   usersFile = ""/path/to/.htdigest""
-#
-# To enable forward auth on an entrypoint
-# This configuration will first forward the request to http://authserver.com/auth. If the response code is 2XX,
-# access is granted and the original request is performed. Otherwise, the response from the auth server is returned.
-# [entryPoints]
-#   [entryPoints.http]
-#   address = "":80""
-#     [entryPoints.http.auth.forward]
-#     address = ""http://authserver.com/auth""
-#
-# To specify an https entrypoint with a minimum TLS version, and specifying an array of cipher suites (from crypto/tls):
-# [entryPoints]
-#   [entryPoints.https]
-#   address = "":443""
-#     [entryPoints.https.tls]
-#     MinVersion = ""VersionTLS12""
-#     CipherSuites = [""TLS_RSA_WITH_AES_256_GCM_SHA384""]
-#       [[entryPoints.https.tls.certificates]]
-#       CertFile = ""integration/fixtures/https/snitest.com.cert""
-#       KeyFile = ""integration/fixtures/https/snitest.com.key""
-#       [[entryPoints.https.tls.certificates]]
-#       CertFile = ""integration/fixtures/https/snitest.org.cert""
-#       KeyFile = ""integration/fixtures/https/snitest.org.key""
-
-# To enable compression support using gzip format:
-# [entryPoints]
-#   [entryPoints.http]
-#   address = "":80""
-#   compress = true
-
-# To bind to a particular IP address only:
-# [entryPoints]
-#   [entryPoints.http]
-#   address = ""10.42.13.37:80""
-
-# To enable IP whitelisting at the entrypoint level:
-# [entryPoints]
-#   [entryPoints.http]
-#   address = "":80""
-#   whiteListSourceRange = [""127.0.0.1/32""]
-
-# To enable ProxyProtocol support (https://www.haproxy.org/download/1.8/doc/proxy-protocol.txt):
-# [entryPoints]
-#   [entryPoints.http]
-#   address = "":80""
-#   proxyprotocol = true
-
-# Enable retry sending request if network error
-#
-# Optional
-#
-# [retry]
-
-# Number of attempts
-#
-# Optional
-# Default: (number servers in backend) -1
-#
-# attempts = 3
-
-# Enable custom health check options.
-#
-# Optional
-#
-# [healthcheck]
-
-# Set the default health check interval. Will only be effective if health check
-# paths are defined. Given provider-specific support, the value may be
-# overridden on a per-backend basis.
-# Can be provided in a format supported by Go's time.ParseDuration function or
-# as raw values (digits). If no units are provided, the value is parsed assuming
-# seconds.
-#
-# Optional
-# Default: ""30s""
-#
-# interval = ""30s""
-
-# Timeout settings for the http servers Traefik starts
-#
-# Optional
-#
-# [respondingTimeouts]
-
-# ReadTimeout is the maximum duration for reading the entire request, including the body.
-# If zero, no timeout exists.
-#
-# Optional
-# Default: ""0s""
-#
-# readTimeout = ""5s""
-
-# WriteTimeout is the maximum duration before timing out writes of the response.
-# If zero, no timeout exists.
-#
-# Optional
-# Default: ""0s""
-#
-# writeTimeout = ""5s""
-
-# IdleTimeout is the maximum amount duration an idle (keep-alive) connection will remain idle before closing itself.
-# Defaults to 180 seconds.
-# If zero, no timeout exists.
-#
-# Optional
-# Default: ""180s""
-#
-# idleTimeout = ""360s""
-
-# Timeout settings for requests forwarded to the Backend Servers
-#
-# Optional
-#
-# [forwardingTimeouts]
-
-# The amount of time to wait until a connection to a Backend Server can be established.
-# If zero, no timeout exists.
-#
-# Optional
-# Default: ""30s""
-#
-# dialTimeout = ""30s""
-
-# The amount of time to wait for a server's response headers after fully writing the request (including its body, if any). If zero, no timeout exists
-#
-# Optional
-# Default: ""0s""
-#
-# responseHeaderTimeout = ""0s""
-
-
 ################################################################
 # Web configuration backend
@@ -440,8 +68,5 @@
 
 # Enable web configuration backend
-#
-# Optional
-#
-# [web]
+[web]
 
 # Web administration port
@@ -449,84 +74,5 @@
 # Required
 #
-# address = "":8080""
-
-# SSL certificate and key used
-#
-# Optional
-#
-# CertFile = ""traefik.crt""
-# KeyFile = ""traefik.key""
-
-# Set REST API to read-only mode
-#
-# Optional
-# ReadOnly = false
-
-# Enable more detailed statistics
-# [web.statistics]
-#   RecentErrors = 10
-
-# To enable Traefik to export internal metrics to Prometheus
-# [web.metrics.prometheus]
-#   Buckets=[0.1,0.3,1.2,5.0]
-#
-
-# DataDog metrics exporter type
-# [web.metrics.datadog]
-#   Address = ""localhost:8125""
-#   Pushinterval = ""10s""
-
-# StatsD metrics exporter type
-# [web.metrics.statsd]
-#   Address = ""localhost:8125""
-#   Pushinterval = ""10s""
-
-# To enable basic auth on the webui
-# with 2 user/pass: test:test and test2:test2
-# Passwords can be encoded in MD5, SHA1 and BCrypt: you can use htpasswd to generate those ones
-# Users can be specified directly in the toml file, or indirectly by referencing an external file; if both are provided, the two are merged, with external file contents having precedence
-#   [web.auth.basic]
-#     users = [""test:$apr1$H6uskkkW$IgXLP6ewTrSuBkTrqE8wj/"", ""test2:$apr1$d9hr9HBB$4HxwgUir3HP4EsggP/QNo0""]
-#     usersFile = ""/path/to/.htpasswd""
-# To enable digest auth on the webui
-# with 2 user/realm/pass: test:traefik:test and test2:traefik:test2
-# You can use htdigest to generate those ones
-# Users can be specified directly in the toml file, or indirectly by referencing an external file; if both are provided, the two are merged, with external file contents having precedence
-#   [web.auth.digest]
-#     users = [""test:traefik:a2688e031edb4be6a3797f3882655c05 "", ""test2:traefik:518845800f9e2bfb1f1f740ec24f074e""]
-#     usersFile = ""/path/to/.htdigest""
-
-
-################################################################
-# File configuration backend
-################################################################
-
-# Enable file configuration backend
-#
-# Optional
-#
-# [file]
-
-# Rules file
-# If defined, traefik will load rules from this file,
-# otherwise, it will load rules from current file (cf Sample rules below).
-#
-# Optional
-#
-# filename = ""rules.toml""
-
-# Rules file
-# If defined, traefik will load rules from .toml files in this directory.
-#
-# Optional
-#
-# directory = ""/path/to/config/""
-
-# Enable watch file changes
-#
-# Optional
-#
-# watch = true
-
+address = "":8080""
 
 ################################################################
@@ -535,94 +81,22 @@
 
 # Enable Docker configuration backend
-#
-# Optional
-#
-# [docker]
+[docker]
 
 # Docker server endpoint. Can be a tcp or a unix socket endpoint.
 #
 # Required
+# Default: ""unix:///var/run/docker.sock""
 #
-# endpoint = ""unix:///var/run/docker.sock""
+# endpoint = ""tcp://10.10.10.10:2375""
 
 # Default domain used.
 # Can be overridden by setting the ""traefik.domain"" label on a container.
 #
-# Required
-#
-# domain = ""docker.localhost""
-
-# Enable watch docker changes
-#
-# Optional
-#
-# watch = true
-
-# Override default configuration template. For advanced users :)
-#
-# Optional
-#
-# filename = ""docker.tmpl""
-
-# Expose containers by default in traefik
-#
 # Optional
-# Default: true
-#
-# exposedbydefault = true
-
-# Enable docker TLS connection
-#
-# Optional
-#
-#  [docker.tls]
-#  ca = ""/etc/ssl/ca.crt""
-#  cert = ""/etc/ssl/docker.crt""
-#  key = ""/etc/ssl/docker.key""
-#  insecureskipverify = true
-
-
-################################################################
-# Docker Swarmmode configuration backend
-################################################################
-
-# Enable Docker configuration backend
-#
-# Optional
-#
-# [docker]
-
-# Docker server endpoint. Can be a tcp or a unix socket endpoint.
-#
-# Required
-#
-# endpoint = ""tcp://127.0.0.1:2375""
-
-# Default domain used.
-# Can be overridden by setting the ""traefik.domain"" label on a services.
-#
-# Required
+# Default: """"
 #
 # domain = ""docker.localhost""
 
-# Enable watch docker changes
-#
-# Optional
-#
-# watch = true
-
-# Use Docker Swarm Mode as data provider
-#
-# Optional
-#
-# swarmmode = true
-
-# Override default configuration template. For advanced users :)
-#
-# Optional
-#
-# filename = ""docker.tmpl""
-
-# Expose services by default in traefik
+# Expose containers by default in traefik
 #
 # Optional
@@ -630,798 +104,2 @@
 #
 # exposedbydefault = true
-
-# Enable docker TLS connection
-#
-# Optional
-#
-#  [swarm.tls]
-#  ca = ""/etc/ssl/ca.crt""
-#  cert = ""/etc/ssl/docker.crt""
-#  key = ""/etc/ssl/docker.key""
-#  insecureskipverify = true
-
-# Constraints
-#
-# Optional
-#
-# constraints = [""tag==api"", ""tag==he*ld""]
-# Matching with containers having the label ""traefik.tags"" set to ""api,helloworld""
-# ex: $ docker run -d -P --label traefik.tags=api,helloworld emilevauge/whoami
-
-
-################################################################
-# Mesos/Marathon configuration backend
-################################################################
-
-# Enable Marathon configuration backend
-#
-# Optional
-#
-# [marathon]
-
-# Marathon server endpoint.
-# You can also specify multiple endpoint for Marathon:
-# endpoint := ""http://10.241.1.71:8080,10.241.1.72:8080,10.241.1.73:8080""
-#
-# Required
-#
-# endpoint = ""http://127.0.0.1:8080""
-
-# Enable watch Marathon changes
-#
-# Optional
-#
-# watch = true
-
-# Default domain used.
-# Can be overridden by setting the ""traefik.domain"" label on an application.
-#
-# Required
-#
-# domain = ""marathon.localhost""
-
-# Override default configuration template. For advanced users :)
-#
-# Optional
-#
-# filename = ""marathon.tmpl""
-
-# Expose Marathon apps by default in traefik
-#
-# Optional
-# Default: true
-#
-# exposedByDefault = true
-
-# Convert Marathon groups to subdomains
-# Default behavior: /foo/bar/myapp => foo-bar-myapp.{defaultDomain}
-# with groupsAsSubDomains enabled: /foo/bar/myapp => myapp.bar.foo.{defaultDomain}
-#
-# Optional
-# Default: false
-#
-# groupsAsSubDomains = true
-
-# Enable compatibility with marathon-lb labels
-#
-# Optional
-# Default: false
-#
-# marathonLBCompatibility = true
-
-# Enable Marathon basic authentication
-#
-# Optional
-#
-#  [marathon.basic]
-#  httpBasicAuthUser = ""foo""
-#  httpBasicPassword = ""bar""
-
-# TLS client configuration. https://golang.org/pkg/crypto/tls/#Config
-#
-# Optional
-#
-# [marathon.TLS]
-# CA = ""/etc/ssl/ca.crt""
-# Cert = ""/etc/ssl/marathon.cert""
-# Key = ""/etc/ssl/marathon.key""
-# InsecureSkipVerify = true
-
-# DCOSToken for DCOS environment, This will override the Authorization header
-#
-# Optional
-#
-# dcosToken = ""xxxxxx""
-
-# Override DialerTimeout
-# Amount of time to allow the Marathon provider to wait to open a TCP connection
-# to a Marathon master.
-# Can be provided in a format supported by [time.ParseDuration](https://golang.org/pkg/time/#ParseDuration) or as raw
-# values (digits). If no units are provided, the value is parsed assuming
-# seconds.
-#
-# Optional
-# Default: ""60s""
-# dialerTimeout = ""60s""
-
-# Set the TCP Keep Alive interval for the Marathon HTTP Client.
-# Can be provided in a format supported by [time.ParseDuration](https://golang.org/pkg/time/#ParseDuration) or as raw
-# values (digits). If no units are provided, the value is parsed assuming
-# seconds.
-#
-# Optional
-# Default: ""10s""
-#
-# keepAlive = ""10s""
-
-# By default, a task's IP address (as returned by the Marathon API) is used as
-# backend server if an IP-per-task configuration can be found; otherwise, the
-# name of the host running the task is used.
-# The latter behavior can be enforced by enabling this switch.
-#
-# Optional
-# Default: false
-#
-# forceTaskHostname = false
-
-# Applications may define readiness checks which are probed by Marathon during
-# deployments periodically and the results exposed via the API. Enabling the
-# following parameter causes Traefik to filter out tasks whose readiness checks
-# have not succeeded.
-# Note that the checks are only valid at deployment times. See the Marathon
-# guide for details.
-#
-# Optional
-# Default: false
-#
-# respectReadinessChecks = false
-
-
-################################################################
-# Mesos configuration backend
-################################################################
-
-# Enable Mesos configuration backend
-#
-# Optional
-#
-# [mesos]
-
-# Mesos server endpoint.
-# You can also specify multiple endpoint for Mesos:
-# endpoint = ""192.168.35.40:5050,192.168.35.41:5050,192.168.35.42:5050""
-# endpoint = ""zk://192.168.35.20:2181,192.168.35.21:2181,192.168.35.22:2181/mesos""
-#
-# Required
-#
-# endpoint = ""http://127.0.0.1:8080""
-
-# Enable watch Mesos changes
-#
-# Optional
-#
-# watch = true
-
-# Default domain used.
-# Can be overridden by setting the ""traefik.domain"" label on an application.
-#
-# Required
-#
-# domain = ""mesos.localhost""
-
-# Override default configuration template. For advanced users :)
-#
-# Optional
-#
-# filename = ""mesos.tmpl""
-
-# Expose Mesos apps by default in traefik
-#
-# Optional
-# Default: false
-#
-# ExposedByDefault = true
-
-# TLS client configuration. https://golang.org/pkg/crypto/tls/#Config
-#
-# Optional
-#
-# [mesos.TLS]
-# InsecureSkipVerify = true
-
-# Zookeeper timeout (in seconds)
-#
-# Optional
-# Default: 30
-#
-# ZkDetectionTimeout = 30
-
-# Polling interval (in seconds)
-#
-# Optional
-# Default: 30
-#
-# RefreshSeconds = 30
-
-# IP sources (e.g. host, docker, mesos, rkt)
-#
-# Optional
-#
-# IPSources = ""host""
-
-# HTTP Timeout (in seconds)
-#
-# Optional
-# Default: 30
-#
-# StateTimeoutSecond = ""30""
-
-
-################################################################
-# Kubernetes Ingress configuration backend
-################################################################
-# Enable Kubernetes Ingress configuration backend
-#
-# Optional
-#
-# [kubernetes]
-
-# Kubernetes server endpoint
-#
-# When deployed as a replication controller in Kubernetes, Traefik will use
-# the environment variables KUBERNETES_SERVICE_HOST and KUBERNETES_SERVICE_PORT
-# to construct the endpoint.
-# Secure token will be found in /var/run/secrets/kubernetes.io/serviceaccount/token
-# and SSL CA cert in /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
-#
-# The endpoint may be given to override the environment variable values.
-#
-# When the environment variables are not found, Traefik will try to connect to
-# the Kubernetes API server with an external-cluster client. In this case, the
-# endpoint is required. Specifically, it may be set to the URL used by
-# `kubectl proxy` to connect to a Kubernetes cluster from localhost.
-#
-# Optional for in-cluster configuration, required otherwise
-# Default: empty
-#
-# endpoint = ""http://127.0.0.1:8001""
-
-# Bearer token used for the Kubernetes client configuration.
-#
-# Optional
-# Default: empty
-#
-# token = ""my token""
-
-# Path to the certificate authority file used for the Kubernetes client
-# configuration.
-#
-# Optional
-# Default: empty
-#
-# certAuthFilePath = ""/my/ca.crt""
-
-# Array of namespaces to watch.
-#
-# Optional
-# Default: all namespaces (empty array).
-#
-# namespaces = [""default""]
-
-# Ingress label selector to identify Ingress objects that should be processed.
-# See https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/#label-selectors for details.
-#
-# Optional
-# Default: empty (process all Ingresses)
-#
-# labelselector = ""A and not B""
-
-
-################################################################
-# Consul KV configuration backend
-################################################################
-
-# Enable Consul KV configuration backend
-#
-# Optional
-#
-# [consul]
-
-# Consul server endpoint
-#
-# Required
-#
-# endpoint = ""127.0.0.1:8500""
-
-# Enable watch Consul changes
-#
-# Optional
-#
-# watch = true
-
-# Prefix used for KV store.
-#
-# Optional
-#
-# prefix = ""traefik""
-
-# Override default configuration template. For advanced users :)
-#
-# Optional
-#
-# filename = ""consul.tmpl""
-
-# Enable consul TLS connection
-#
-# Optional
-#
-# [consul.tls]
-# ca = ""/etc/ssl/ca.crt""
-# cert = ""/etc/ssl/consul.crt""
-# key = ""/etc/ssl/consul.key""
-# insecureskipverify = true
-
-
-################################################################
-# Consul Catalog configuration backend
-################################################################
-
-# Enable Consul Catalog configuration backend
-#
-# Optional
-#
-# [consulCatalog]
-
-# Consul server endpoint
-#
-# Required
-#
-# endpoint = ""127.0.0.1:8500""
-
-# Default domain used.
-#
-# Optional
-#
-# domain = ""consul.localhost""
-
-# Expose Consul catalog services by default in traefik
-#
-# Optional
-#
-# exposedByDefault = true
-
-# Prefix for Consul catalog tags
-#
-# Optional
-#
-# prefix = ""traefik""
-
-# Default frontEnd Rule for Consul services
-#
-# The format is a Go Template with:
-# - "".ServiceName"", "".Domain"" and "".Attributes"" available
-# - ""getTag(name, tags, defaultValue)"", ""hasTag(name, tags)"" and ""getAttribute(name, tags, defaultValue)"" functions are available
-# - ""getAttribute(...)"" function uses prefixed tag names based on ""prefix"" value
-#
-# Optional
-#
-#frontEndRule = ""Host:{{.ServiceName}}.{{Domain}}""
-
-# Constraints
-#
-# Optional
-#
-# constraints = [""tag==api"", ""tag==he*ld""]
-# Matching with containers having this tag: ""traefik.tags=api,helloworld""
-
-
-################################################################
-# Etcd configuration backend
-################################################################
-
-# Enable Etcd configuration backend
-#
-# Optional
-#
-# [etcd]
-
-# Etcd server endpoint
-#
-# Required
-#
-# endpoint = ""127.0.0.1:2379""
-
-# Enable watch Etcd changes
-#
-# Optional
-#
-# watch = true
-
-# Prefix used for KV store.
-#
-# Optional
-#
-# prefix = ""/traefik""
-
-# Override default configuration template. For advanced users :)
-#
-# Optional
-#
-# filename = ""etcd.tmpl""
-
-# Use etcd user/pass authentication
-#
-# Optional
-#
-# username = foo
-# password = bar
-
-# Enable etcd TLS connection
-#
-# Optional
-#
-# [etcd.tls]
-# ca = ""/etc/ssl/ca.crt""
-# cert = ""/etc/ssl/etcd.crt""
-# key = ""/etc/ssl/etcd.key""
-# insecureskipverify = true
-
-
-################################################################
-# Eureka configuration backend
-################################################################
-
-# Enable Eureka configuration backend
-#
-# Optional
-#
-# [eureka]
-
-# Eureka server endpoint.
-# endpoint := ""http://my.eureka.server/eureka""
-#
-# Required
-#
-# endpoint = ""http://my.eureka.server/eureka""
-
-# Override default configuration time between refresh
-#
-# Optional
-# default 30s
-# delay = ""1m""
-
-# Override default configuration template. For advanced users :)
-#
-# Optional
-#
-# filename = ""eureka.tmpl""
-
-
-################################################################
-# Zookeeper configuration backend
-################################################################
-
-# Enable Zookeeperconfiguration backend
-#
-# Optional
-#
-# [zookeeper]
-
-# Zookeeper server endpoint
-#
-# Required
-#
-# endpoint = ""127.0.0.1:2181""
-
-# Enable watch Zookeeper changes
-#
-# Optional
-#
-# watch = true
-
-# Prefix used for KV store.
-#
-# Optional
-#
-# prefix = ""/traefik""
-
-# Override default configuration template. For advanced users :)
-#
-# Optional
-#
-# filename = ""zookeeper.tmpl""
-
-
-################################################################
-# BoltDB configuration backend
-################################################################
-
-# Enable BoltDB configuration backend
-#
-# Optional
-#
-# [boltdb]
-
-# BoltDB file
-#
-# Required
-#
-# endpoint = ""/my.db""
-
-# Enable watch BoltDB changes
-#
-# Optional
-#
-# watch = true
-
-# Prefix used for KV store.
-#
-# Optional
-#
-# prefix = ""/traefik""
-
-# Override default configuration template. For advanced users :)
-#
-# Optional
-#
-# filename = ""boltdb.tmpl""
-
-
-################################################################
-# ECS configuration backend
-################################################################
-
-# Enable ECS configuration backend
-#
-# Optional
-#
-# [ecs]
-
-# ECS Cluster Name
-#
-# DEPRECATED - Please use Clusters
-#
-# Cluster = ""default""
-
-# ECS Clusters Name
-#
-# Optional
-# Default: [""default""]
-#
-# Clusters = [""default""]
-
-# Enable watch ECS changes
-#
-# Optional
-# Default: true
-#
-# Watch = true
-
-# Enable auto discover ECS clusters
-#
-# Optional
-# Default: false
-#
-# AutoDiscoverClusters = false
-
-# Polling interval (in seconds)
-#
-# Optional
-# Default: 15
-#
-# RefreshSeconds = 15
-
-# Expose ECS services by default in traefik
-#
-# Optional
-# Default: true
-#
-# ExposedByDefault = false
-
-# Region to use when connecting to AWS
-#
-# Optional
-#
-# Region = ""us-east-1""
-
-# AccessKeyID to use when connecting to AWS
-#
-# Optional
-#
-# AccessKeyID = ""abc""
-
-# SecretAccessKey to use when connecting to AWS
-#
-# Optional
-#
-# SecretAccessKey = ""123""
-
-# Override default configuration template. For advanced users :)
-#
-# Optional
-#
-# filename = ""ecs.tmpl""
-
-
-################################################################
-# Rancher configuration backend
-################################################################
-
-# Enable Rancher configuration backend
-#
-# Optional
-#
-# [rancher]
-
-# Default domain used.
-# Can be overridden by setting the ""traefik.domain"" label on an service.
-#
-# Required
-#
-# domain = ""rancher.localhost""
-
-# Enable watch Rancher changes
-#
-# Optional
-# Default: true
-#
-# Watch = true
-
-# Polling interval (in seconds)
-#
-# Optional
-#
-# RefreshSeconds = 15
-
-# Expose Rancher services by default in traefik
-#
-# Optional
-# Default: true
-#
-# ExposedByDefault = false
-
-# Filter services with unhealthy states and inactive states
-#
-# Optional
-# Default: false
-#
-# EnableServiceHealthFilter = true
-
-# Enable Rancher metadata service configuration backend instead of the API
-# configuration backend
-#
-# Optional
-# Default: false
-#
-# [rancher.metadata]
-
-# Poll the Rancher metadata service for changes every `rancher.RefreshSeconds`
-# NOTE: this is less accurate than the default long polling technique which
-# will provide near instantaneous updates to Traefik
-#
-# Optional
-# Default: false
-#
-# IntervalPoll = true
-
-# Prefix used for accessing the Rancher metadata service
-#
-# Optional
-# Default: ""/latest""
-#
-# Prefix = ""/2016-07-29""
-
-# Enable Rancher API configuration backend
-#
-# Optional
-# Default: true
-#
-# [rancher.api]
-
-# Endpoint to use when connecting to the Rancher API
-#
-# Required
-# Endpoint = ""http://rancherserver.example.com/v1""
-
-# AccessKey to use when connecting to the Rancher API
-#
-# Required
-# AccessKey = ""XXXXXXXXXXXXXXXXXXXX""
-
-# SecretKey to use when connecting to the Rancher API
-#
-# Required
-# SecretKey = ""xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx""
-
-
-################################################################
-# DynamoDB configuration backend
-################################################################
-
-# Enable DynamoDB configuration backend
-#
-# Optional
-#
-# [dynamodb]
-
-# DynamoDB Table Name
-#
-# Optional
-#
-# TableName = ""traefik""
-
-# Enable watch DynamoDB changes
-#
-# Optional
-#
-# Watch = true
-
-# Polling interval (in seconds)
-#
-# Optional
-#
-# RefreshSeconds = 15
-
-# Region to use when connecting to AWS
-#
-# Required
-#
-# Region = ""us-east-1""
-
-# AccessKeyID to use when connecting to AWS
-#
-# Optional
-#
-# AccessKeyID = ""abc""
-
-# SecretAccessKey to use when connecting to AWS
-#
-# Optional
-#
-# SecretAccessKey = ""123""
-
-# Endpoint of dynamodb when testing locally
-#
-# Optional
-#
-# Endpoint = ""http://localhost:8080""
-
-
-################################################################
-# Sample rules
-################################################################
-# [backends]
-#   [backends.backend1]
-#     [backends.backend1.circuitbreaker]
-#       expression = ""NetworkErrorRatio() > 0.5""
-#     [backends.backend1.servers.server1]
-#     url = ""http://172.17.0.2:80""
-#     weight = 10
-#     [backends.backend1.servers.server2]
-#     url = ""http://172.17.0.3:80""
-#     weight = 1
-#   [backends.backend2]
-#     [backends.backend2.LoadBalancer]
-#       method = ""drr""
-#     [backends.backend2.servers.server1]
-#     url = ""http://172.17.0.4:80""
-#     weight = 1
-#     [backends.backend2.servers.server2]
-#     url = ""http://172.17.0.5:80""
-#     weight = 2
-#
-# [frontends]
-#   [frontends.frontend1]
-#   backend = ""backend2""
-#     [frontends.frontend1.routes.test_1]
-#     rule = ""Host: test.localhost, other.localhost""
-#   [frontends.frontend2]
-#   backend = ""backend1""
-#   passHostHeader = true
-#   entrypoints = [""https""] # overrides defaultEntryPoints
-#     [frontends.frontend2.routes.test_1]
-#     rule = ""Host:{subdomain:[a-z]+}.localhost""
-#   [frontends.frontend3]
-#   entrypoints = [""http"", ""https""] # overrides defaultEntryPoints
-#   backend = ""backend2""
-#     rule = ""Path: /test, /other""
","refactor: basic configuration.

"
381,Go,fa1f4f761d4ebd47073e76e50fec5a7d2cb6ce64,https://github.com/traefik/traefik/commit/fa1f4f761d4ebd47073e76e50fec5a7d2cb6ce64,P,traefik,traefik,"[1, 14, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 3, 0, 0]","diff --git a/webui/package.json b/webui/package.json
index daa04ed2d..6b11e6cdb 100644
--- a/webui/package.json
+++ b/webui/package.json
@@ -22,4 +22,5 @@
     ""animate.css"": ""^3.4.0"",
     ""bootstrap"": ""^3.3.6"",
+    ""http-status-codes"": ""^1.3.0"",
     ""moment"": ""^2.14.1"",
     ""nvd3"": ""^1.8.4""
diff --git a/webui/src/app/sections/health/health.controller.js b/webui/src/app/sections/health/health.controller.js
index af8c9e9cf..822175b9d 100644
--- a/webui/src/app/sections/health/health.controller.js
+++ b/webui/src/app/sections/health/health.controller.js
@@ -1,5 +1,6 @@
 'use strict';
 var d3 = require('d3'),
-    moment = require('moment');
+    moment = require('moment'),
+    HttpStatus = require('http-status-codes');
 
 /** @ngInject */
@@ -16,4 +17,10 @@ function HealthController($scope, $interval, $log, Health) {
     ""chart"": {
       type: 'discreteBarChart',
+      tooltip: {
+        contentGenerator: function (e) {
+          var d = e.data;
+          return d.label + "" "" + d.text;
+        }
+      },
       height: 200,
       margin: {
@@ -70,7 +77,15 @@ function HealthController($scope, $interval, $log, Health) {
     for (var code in totalStatusCodeCount) {
       if (totalStatusCodeCount.hasOwnProperty(code)) {
+        var statusCodeText = """";
+        try {
+          statusCodeText = HttpStatus.getStatusText(code);
+        } catch (e) {
+          // HttpStatus.getStatusText throws error on unknown codes
+          statusCodeText = ""Unknown status code"";
+        }
         vm.graph.totalStatusCodeCount.data[0].values.push({
           label: code,
-          value: totalStatusCodeCount[code]
+          value: totalStatusCodeCount[code],
+          text: statusCodeText
         });
       }
diff --git a/webui/yarn.lock b/webui/yarn.lock
index 2c429591d..43038244e 100644
--- a/webui/yarn.lock
+++ b/webui/yarn.lock
@@ -3074,4 +3074,8 @@ http-signature@~1.1.0:
     sshpk ""^1.7.0""
 
+http-status-codes@^1.3.0:
+  version ""1.3.0""
+  resolved ""https://registry.yarnpkg.com/http-status-codes/-/http-status-codes-1.3.0.tgz#9cd0e71391773d0671b489d41cbc5094aa4163b6""
+
 https-browserify@0.0.1:
   version ""0.0.1""
","Add status code text to webui bar chart tooltip


"
382,Go,91b699fbe0fc3878c3673a6d397a95428e823429,https://github.com/traefik/traefik/commit/91b699fbe0fc3878c3673a6d397a95428e823429,P,traefik,traefik,"[1, 10, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 24, 0, 2, 2, 1, 1, 3, 1, 1, 0, 0]","diff --git a/.travis.yml b/.travis.yml
new file mode 100644
index 000000000..baa773733
--- /dev/null
+++ b/.travis.yml
@@ -0,0 +1,30 @@
+env:
+  REPO: $TRAVIS_REPO_SLUG
+  VERSION: v1.0.alpha.$TRAVIS_COMMIT
+
+sudo: required
+
+services:
+  - docker
+
+install:
+  - sudo service docker stop
+  - sudo curl https://get.docker.com/builds/Linux/x86_64/docker-1.10.1 -o /usr/bin/docker
+  - sudo chmod +x /usr/bin/docker
+  - sudo service docker start
+
+before_script:
+  - make validate
+  - make binary
+
+script:
+  - make test-unit
+  - make test-integration
+  - make crossbinary
+  - make image
+
+deploy:
+  provider: script
+  script: script/deploy.sh
+  on:
+    branch: master
diff --git a/Makefile b/Makefile
index 9b7d622aa..790204f44 100644
--- a/Makefile
+++ b/Makefile
@@ -5,6 +5,5 @@ TRAEFIK_ENVS := \
 	-e OS_PLATFORM_ARG \
 	-e TESTFLAGS \
-	-e CIRCLECI
-
+	-e VERSION
 
 SRCS = $(shell git ls-files '*.go' | grep -v '^external/')
@@ -19,5 +18,5 @@ TRAEFIK_IMAGE := $(if $(REPONAME),$(REPONAME),""emilevauge/traefik"")
 INTEGRATION_OPTS := $(if $(MAKE_DOCKER_HOST),-e ""DOCKER_HOST=$(MAKE_DOCKER_HOST)"", -v ""/var/run/docker.sock:/var/run/docker.sock"")
 
-DOCKER_RUN_TRAEFIK := docker run $(if $(CIRCLECI),,--rm) $(INTEGRATION_OPTS) -it $(TRAEFIK_ENVS) $(TRAEFIK_MOUNT) ""$(TRAEFIK_DEV_IMAGE)""
+DOCKER_RUN_TRAEFIK := docker run $(INTEGRATION_OPTS) -it $(TRAEFIK_ENVS) $(TRAEFIK_MOUNT) ""$(TRAEFIK_DEV_IMAGE)""
 
 print-%: ; @echo $*=$($*)
diff --git a/README.md b/README.md
index 543556d68..c2f3fd5da 100644
--- a/README.md
+++ b/README.md
@@ -2,5 +2,5 @@
 ___
 
-[![Circle CI](https://circleci.com/gh/emilevauge/traefik/tree/master.png?circle-token)](https://circleci.com/gh/emilevauge/traefik)
+[![Build Status](https://travis-ci.org/emilevauge/traefik.svg?branch=master)](https://travis-ci.org/emilevauge/traefik)
 [![License](https://img.shields.io/badge/license-MIT-blue.svg?style=flat-square)](https://github.com/EmileVauge/traefik/blob/master/LICENSE.md)
 [![Join the chat at https://traefik.herokuapp.com](https://img.shields.io/badge/style-register-green.svg?style=social&label=Slack)](https://traefik.herokuapp.com)
diff --git a/build.Dockerfile b/build.Dockerfile
index a80241b1c..76883064e 100644
--- a/build.Dockerfile
+++ b/build.Dockerfile
@@ -1,12 +1,13 @@
-FROM golang:1.6
+FROM golang:1.6.0-alpine
+
+RUN apk update && apk add git bash gcc
 
 RUN go get github.com/Masterminds/glide
 RUN go get github.com/mitchellh/gox
-RUN go get github.com/tcnksm/ghr
 RUN go get github.com/jteeuwen/go-bindata/...
 RUN go get github.com/golang/lint/golint
 
 # Which docker version to test on
-ENV DOCKER_VERSION 1.6.2
+ENV DOCKER_VERSION 1.10.1
 
 # enable GO15VENDOREXPERIMENT
diff --git a/script/.validate b/script/.validate
index 7f4a81096..6b55f2a73 100644
--- a/script/.validate
+++ b/script/.validate
@@ -4,21 +4,22 @@ if [ -z ""$VALIDATE_UPSTREAM"" ]; then
 	# this is kind of an expensive check, so let's not do this twice if we
 	# are running more than one validate bundlescript
-	
+
 	VALIDATE_REPO='https://github.com/emilevauge/traefik.git'
 	VALIDATE_BRANCH='master'
-	
-	if [ ""$TRAVIS"" = 'true' -a ""$TRAVIS_PULL_REQUEST"" != 'false' ]; then
-		VALIDATE_REPO=""https://github.com/${TRAVIS_REPO_SLUG}.git""
-		VALIDATE_BRANCH=""${TRAVIS_BRANCH}""
-	fi
-	
+
+        # Should not be needed for now O:)
+	# if [ ""$TRAVIS"" = 'true' -a ""$TRAVIS_PULL_REQUEST"" != 'false' ]; then
+	# 	VALIDATE_REPO=""https://github.com/${TRAVIS_REPO_SLUG}.git""
+	# 	VALIDATE_BRANCH=""${TRAVIS_BRANCH}""
+	# fi
+
 	VALIDATE_HEAD=""$(git rev-parse --verify HEAD)""
-	
+
 	git fetch -q ""$VALIDATE_REPO"" ""refs/heads/$VALIDATE_BRANCH""
 	VALIDATE_UPSTREAM=""$(git rev-parse --verify FETCH_HEAD)""
-	
+
 	VALIDATE_COMMIT_LOG=""$VALIDATE_UPSTREAM..$VALIDATE_HEAD""
 	VALIDATE_COMMIT_DIFF=""$VALIDATE_UPSTREAM...$VALIDATE_HEAD""
-	
+
 	validate_diff() {
 		if [ ""$VALIDATE_UPSTREAM"" != ""$VALIDATE_HEAD"" ]; then
diff --git a/script/deploy.sh b/script/deploy.sh
new file mode 100644
index 000000000..a9b22276a
--- /dev/null
+++ b/script/deploy.sh
@@ -0,0 +1,13 @@
+#!/bin/sh
+set -e
+
+curl -LO https://github.com/tcnksm/ghr/releases/download/pre-release/linux_amd64.zip
+unzip -q linux_amd64.zip
+sudo mv grh /usr/bin/ghr
+sudo chmod +x /usr/bin/ghr
+
+ghr -t $GITHUB_TOKEN -u emilevauge -r traefik --prerelease ${VERSION} dist/
+docker login -e $DOCKER_EMAIL -u $DOCKER_USER -p $DOCKER_PASS
+docker push ${REPO,,}:latest
+docker tag ${REPO,,}:latest ${REPO,,}:${VERSION}
+docker push ${REPO,,}:${VERSION}
diff --git a/script/test-integration b/script/test-integration
index 63f4b46f5..87d22a9e7 100755
--- a/script/test-integration
+++ b/script/test-integration
@@ -1,3 +1,4 @@
 #!/bin/bash
+set -e
 
 export SCRIPTDIR=""$( cd ""$( dirname ""${BASH_SOURCE[0]}"" )"" && pwd )""
@@ -7,4 +8,3 @@ TESTFLAGS=""$TESTFLAGS -test.timeout=30m -check.v""
 
 cd integration
-go test $TESTFLAGS
-
+CGO_ENABLED=0 go test $TESTFLAGS
","Migrate CI to travis

- Add travis build file
- Use golang alpine image
- Clean scripts a little bit
- Disable CGO for test-integration >_<

"
384,Go,8be434aaadfcb14270657980f7ffffa0ebca420b,https://github.com/traefik/traefik/commit/8be434aaadfcb14270657980f7ffffa0ebca420b,P,traefik,traefik,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 7, 0, 0, 1, 0, 0, 3]","diff --git a/CHANGELOG.md b/CHANGELOG.md
index 8da39faff..38704c0db 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -1,2 +1,11 @@
+## [v2.4.12](https://github.com/traefik/traefik/tree/v2.4.12) (2021-07-26)
+[All Commits](https://github.com/traefik/traefik/compare/v2.4.11...v2.4.12)
+
+**Bug fixes:**
+- **[k8s,k8s/ingress]** Get Kubernetes server version early ([#8286](https://github.com/traefik/traefik/pull/8286) by [rtribotte](https://github.com/rtribotte))
+- **[k8s,k8s/ingress]** Don&#39;t remove ingress config on API call failure ([#8185](https://github.com/traefik/traefik/pull/8185) by [dtomcej](https://github.com/dtomcej))
+- **[middleware]** Ratelimiter: use correct ttlSeconds value, and always call Set ([#8254](https://github.com/traefik/traefik/pull/8254) by [mpl](https://github.com/mpl))
+- **[tls]** Check if defaultcertificate is defined in store ([#8274](https://github.com/traefik/traefik/pull/8274) by [dtomcej](https://github.com/dtomcej))
+
 ## [v2.4.11](https://github.com/traefik/traefik/tree/v2.4.11) (2021-07-15)
 [All Commits](https://github.com/traefik/traefik/compare/v2.4.9...v2.4.11)
diff --git a/script/gcg/traefik-bugfix.toml b/script/gcg/traefik-bugfix.toml
index 4d1cc91d3..0e924afaa 100644
--- a/script/gcg/traefik-bugfix.toml
+++ b/script/gcg/traefik-bugfix.toml
@@ -5,9 +5,9 @@ OutputType = ""file""
 FileName = ""traefik_changelog.md""
 
-# example new bugfix v2.4.11
+# example new bugfix v2.4.12
 CurrentRef = ""v2.4""
-PreviousRef = ""v2.4.9""
+PreviousRef = ""v2.4.11""
 BaseBranch = ""v2.4""
-FutureCurrentRefName = ""v2.4.11""
+FutureCurrentRefName = ""v2.4.12""
 
 ThresholdPreviousRef = 10
","Prepare release v2.4.12



"
401,Go,ed09b4ea6a17566b546a9d3ae76876636710c6a0,https://github.com/v2ray/v2ray-core/commit/ed09b4ea6a17566b546a9d3ae76876636710c6a0,A,v2ray,v2ray-core,"[3, 49, 2, 8, 0, 0, 0, 2, 29, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/common/net/json/host.go b/common/net/json/host.go
new file mode 100644
index 00000000..41fade70
--- /dev/null
+++ b/common/net/json/host.go
@@ -0,0 +1,53 @@
+package json
+
+import (
+	""encoding/json""
+	""net""
+)
+
+type Host struct {
+	domain string
+	ip     net.IP
+}
+
+func NewIPHost(ip net.IP) *Host {
+	return &Host{
+		ip: ip,
+	}
+}
+
+func NewDomainHost(domain string) *Host {
+	return &Host{
+		domain: domain,
+	}
+}
+
+func (this *Host) UnmarshalJSON(data []byte) error {
+	var rawStr string
+	if err := json.Unmarshal(data, &rawStr); err != nil {
+		return err
+	}
+	ip := net.ParseIP(rawStr)
+	if ip != nil {
+		this.ip = ip
+	} else {
+		this.domain = rawStr
+	}
+	return nil
+}
+
+func (this *Host) IsIP() bool {
+	return this.ip != nil
+}
+
+func (this *Host) IsDomain() bool {
+	return !this.IsIP()
+}
+
+func (this *Host) IP() net.IP {
+	return this.ip
+}
+
+func (this *Host) Domain() string {
+	return this.domain
+}
diff --git a/common/net/json/host_test.go b/common/net/json/host_test.go
new file mode 100644
index 00000000..6eee6633
--- /dev/null
+++ b/common/net/json/host_test.go
@@ -0,0 +1,35 @@
+package json_test
+
+import (
+	""encoding/json""
+	""net""
+	""testing""
+
+	. ""github.com/v2ray/v2ray-core/common/net/json""
+	v2testing ""github.com/v2ray/v2ray-core/testing""
+	""github.com/v2ray/v2ray-core/testing/assert""
+)
+
+func TestIPParsing(t *testing.T) {
+	v2testing.Current(t)
+
+	rawJson := ""\""8.8.8.8\""""
+	host := &Host{}
+	err := json.Unmarshal([]byte(rawJson), host)
+	assert.Error(err).IsNil()
+	assert.Bool(host.IsIP()).IsTrue()
+	assert.Bool(host.IsDomain()).IsFalse()
+	assert.Bool(host.IP().Equal(net.ParseIP(""8.8.8.8""))).IsTrue()
+}
+
+func TestDomainParsing(t *testing.T) {
+	v2testing.Current(t)
+
+	rawJson := ""\""v2ray.com\""""
+	host := &Host{}
+	err := json.Unmarshal([]byte(rawJson), host)
+	assert.Error(err).IsNil()
+	assert.Bool(host.IsIP()).IsFalse()
+	assert.Bool(host.IsDomain()).IsTrue()
+	assert.StringLiteral(host.Domain()).Equals(""v2ray.com"")
+}
diff --git a/proxy/dokodemo/dokodemo_test.go b/proxy/dokodemo/dokodemo_test.go
index e7dec464..702e566c 100644
--- a/proxy/dokodemo/dokodemo_test.go
+++ b/proxy/dokodemo/dokodemo_test.go
@@ -43,5 +43,5 @@ func TestDokodemoTCP(t *testing.T) {
 			ProtocolValue: ""dokodemo-door"",
 			SettingsValue: &json.DokodemoConfig{
-				Host:         ""127.0.0.1"",
+				Host:         v2netjson.NewIPHost(net.ParseIP(""127.0.0.1"")),
 				Port:         port,
 				NetworkList:  &networkList,
@@ -105,5 +105,5 @@ func TestDokodemoUDP(t *testing.T) {
 			ProtocolValue: ""dokodemo-door"",
 			SettingsValue: &json.DokodemoConfig{
-				Host:         ""127.0.0.1"",
+				Host:         v2netjson.NewIPHost(net.ParseIP(""127.0.0.1"")),
 				Port:         port,
 				NetworkList:  &networkList,
diff --git a/proxy/dokodemo/json/json.go b/proxy/dokodemo/json/json.go
index 72a503c7..560aad72 100644
--- a/proxy/dokodemo/json/json.go
+++ b/proxy/dokodemo/json/json.go
@@ -2,6 +2,4 @@ package json
 
 import (
-	""net""
-
 	v2net ""github.com/v2ray/v2ray-core/common/net""
 	v2netjson ""github.com/v2ray/v2ray-core/common/net/json""
@@ -10,5 +8,5 @@ import (
 
 type DokodemoConfig struct {
-	Host         string                 `json:""address""`
+	Host         *v2netjson.Host        `json:""address""`
 	Port         v2net.Port             `json:""port""`
 	NetworkList  *v2netjson.NetworkList `json:""network""`
@@ -17,9 +15,8 @@ type DokodemoConfig struct {
 
 func (this *DokodemoConfig) Address() v2net.Address {
-	ip := net.ParseIP(this.Host)
-	if ip != nil {
-		return v2net.IPAddress(ip, this.Port)
+	if this.Host.IsIP() {
+		return v2net.IPAddress(this.Host.IP(), this.Port)
 	} else {
-		return v2net.DomainAddress(this.Host, this.Port)
+		return v2net.DomainAddress(this.Host.Domain(), this.Port)
 	}
 }
diff --git a/proxy/vmess/outbound/json/outbound.go b/proxy/vmess/outbound/json/outbound.go
index 47d8e63a..d08b8aa5 100644
--- a/proxy/vmess/outbound/json/outbound.go
+++ b/proxy/vmess/outbound/json/outbound.go
@@ -3,8 +3,8 @@ package json
 import (
 	""encoding/json""
-	""net""
 
 	""github.com/v2ray/v2ray-core/common/log""
 	v2net ""github.com/v2ray/v2ray-core/common/net""
+	v2netjson ""github.com/v2ray/v2ray-core/common/net/json""
 	proxyconfig ""github.com/v2ray/v2ray-core/proxy/common/config""
 	jsonconfig ""github.com/v2ray/v2ray-core/proxy/common/config/json""
@@ -21,5 +21,5 @@ type ConfigTarget struct {
 func (t *ConfigTarget) UnmarshalJSON(data []byte) error {
 	type RawConfigTarget struct {
-		Address string                  `json:""address""`
+		Address *v2netjson.Host         `json:""address""`
 		Port    v2net.Port              `json:""port""`
 		Users   []*vmessjson.ConfigUser `json:""users""`
@@ -34,10 +34,13 @@ func (t *ConfigTarget) UnmarshalJSON(data []byte) error {
 	}
 	t.Users = rawConfig.Users
-	ip := net.ParseIP(rawConfig.Address)
-	if ip == nil {
-		log.Error(""Unable to parse IP: %s"", rawConfig.Address)
+	if rawConfig.Address == nil {
+		log.Error(""Address is not set in VMess outbound config."")
 		return proxyconfig.BadConfiguration
 	}
-	t.Address = v2net.IPAddress(ip, rawConfig.Port)
+	if rawConfig.Address.IsIP() {
+		t.Address = v2net.IPAddress(rawConfig.Address.IP(), rawConfig.Port)
+	} else {
+		t.Address = v2net.DomainAddress(rawConfig.Address.Domain(), rawConfig.Port)
+	}
 	return nil
 }
","support domain as host in VMess outbound config.

"
404,Go,3d2fd372e1d7c7624bdcf238c220ecb93f07c920,https://github.com/v2ray/v2ray-core/commit/3d2fd372e1d7c7624bdcf238c220ecb93f07c920,P,v2ray,v2ray-core,"[1, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/common/buf/writer.go b/common/buf/writer.go
index 6b63e6a7..36fa0edc 100644
--- a/common/buf/writer.go
+++ b/common/buf/writer.go
@@ -91,9 +91,8 @@ func (w *bytesToBufferWriter) ReadFrom(reader io.Reader) (int64, error) {
 	mbReader := NewReader(reader)
 	totalBytes := int64(0)
-	eof := false
-	for !eof {
+	for {
 		mb, err := mbReader.Read()
-		if err == io.EOF {
-			eof = true
+		if errors.Cause(err) == io.EOF {
+			break
 		} else if err != nil {
 			return totalBytes, err
","avoid writing empty payload in bytesToBufferWriter

"
410,Go,c344edd2e1c6742b95eec7777f13ff092cc14ccb,https://github.com/v2ray/v2ray-core/commit/c344edd2e1c6742b95eec7777f13ff092cc14ccb,P,v2ray,v2ray-core,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 5, 4]","diff --git a/go.mod b/go.mod
index 05bc792b..ffbc97f6 100644
--- a/go.mod
+++ b/go.mod
@@ -14,10 +14,10 @@ require (
 	github.com/stretchr/testify v1.6.1
 	github.com/xiaokangwang/VSign v0.0.0-20200828155424-dc1c86b73fbf
-	github.com/xtls/go v0.0.0-20201004051247-520292b68c72
+	github.com/xtls/go v0.0.0-20201005165655-a983bb878c68
 	go.starlark.net v0.0.0-20200929122913-88a10930eb75
 	golang.org/x/crypto v0.0.0-20201002170205-7f63de1d35b0
 	golang.org/x/net v0.0.0-20201002202402-0a1ea396d57c
 	golang.org/x/sync v0.0.0-20200930132711-30421366ff76
-	golang.org/x/sys v0.0.0-20200930185726-fdedc70b468f
+	golang.org/x/sys v0.0.0-20201005170523-935f906f1786
 	google.golang.org/grpc v1.32.0
 	google.golang.org/protobuf v1.25.0
diff --git a/go.sum b/go.sum
index 344d795b..55826a2e 100644
--- a/go.sum
+++ b/go.sum
@@ -10,5 +10,4 @@ github.com/davecgh/go-spew v1.1.0/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSs
 github.com/dgryski/go-metro v0.0.0-20200812162917-85c65e2d0165 h1:BS21ZUJ/B5X2UVUbczfmdWH7GapPWAhxcMsDnjJTU1E=
 github.com/dgryski/go-metro v0.0.0-20200812162917-85c65e2d0165/go.mod h1:c9O8+fpSOX1DM8cPNSkX/qsBWdkD4yd2dpciOWQjpBw=
-github.com/ebfe/bcrypt_pbkdf v0.0.0-20140212075826-3c8d2dcb253a h1:YtdtTUN1iH97s+6PUjLnaiKSQj4oG1/EZ3N9bx6g4kU=
 github.com/ebfe/bcrypt_pbkdf v0.0.0-20140212075826-3c8d2dcb253a/go.mod h1:/CZpbhAusDOobpcb9yubw46kdYjq0zRC0Wpg9a9zFQM=
 github.com/envoyproxy/go-control-plane v0.9.0/go.mod h1:YTl/9mNaCwkRvm6d1a2C3ymFceY/DCBVvsKhRF0iEA4=
@@ -41,6 +40,4 @@ github.com/h12w/go-socks5 v0.0.0-20200522160539-76189e178364/go.mod h1:eDJQioIyy
 github.com/miekg/dns v1.1.31/go.mod h1:KNUDUusw/aVsxyTYZM1oqvCicbwhgbNgztCETuNZ7xM=
 github.com/phayes/freeport v0.0.0-20180830031419-95f893ade6f2/go.mod h1:iIss55rKnNBTvrwdmkUpLnDpZoAHvWaiq5+iMmen4AE=
-github.com/pires/go-proxyproto v0.1.3 h1:2XEuhsQluSNA5QIQkiUv8PfgZ51sNYIQkq/yFquiSQM=
-github.com/pires/go-proxyproto v0.1.3/go.mod h1:Odh9VFOZJCf9G8cLW5o435Xf1J95Jw9Gw5rnCjcwzAY=
 github.com/pires/go-proxyproto v0.2.0 h1:WyYKlv9pkt77b+LjMvPfwrsAxviaGCFhG4KDIy1ofLY=
 github.com/pires/go-proxyproto v0.2.0/go.mod h1:Odh9VFOZJCf9G8cLW5o435Xf1J95Jw9Gw5rnCjcwzAY=
@@ -51,8 +48,7 @@ github.com/seiflotfy/cuckoofilter v0.0.0-20200511222245-56093a4d3841/go.mod h1:E
 github.com/stretchr/objx v0.1.0/go.mod h1:HFkY916IF+rwdDfMAkV7OtwuqBVzrE8GR6GFx+wExME=
 github.com/stretchr/testify v1.6.1/go.mod h1:6Fq8oRcR53rry900zMqJjRRixrwX3KX962/h/Wwjteg=
-github.com/xiaokangwang/VSign v0.0.0-20200828155424-dc1c86b73fbf h1:d4keT3SwLbrgnEe2zbtijPLgKE15n0ZbvJZzRH/a9GM=
 github.com/xiaokangwang/VSign v0.0.0-20200828155424-dc1c86b73fbf/go.mod h1:jTwBnzBuqZP3VX/Z65ErYb9zd4anQprSC7N38TmAp1E=
-github.com/xtls/go v0.0.0-20201004051247-520292b68c72 h1:41vXTk8TdBzGhYV3SqmpaSfwNDlfWZENHsbqlYG+294=
-github.com/xtls/go v0.0.0-20201004051247-520292b68c72/go.mod h1:5TB2+k58gx4A4g2Nf5miSHNDF6CuAzHKpWBooLAshTs=
+github.com/xtls/go v0.0.0-20201005165655-a983bb878c68 h1:5G4detDThLi9P9hFgCvXodg97AMApmtHiI9KjNT++7k=
+github.com/xtls/go v0.0.0-20201005165655-a983bb878c68/go.mod h1:5TB2+k58gx4A4g2Nf5miSHNDF6CuAzHKpWBooLAshTs=
 go.starlark.net v0.0.0-20200929122913-88a10930eb75 h1:YIM6J67guF/8+htFlhuT6gJ36F7hJDzVy61Anea8sJU=
 go.starlark.net v0.0.0-20200929122913-88a10930eb75/go.mod h1:f0znQkUKRrkk36XxWbGjMqQM8wGv/xHBVE2qc3B5oFU=
@@ -86,6 +82,7 @@ golang.org/x/sys v0.0.0-20190412213103-97732733099d/go.mod h1:h1NjWce9XRLGQEsW7w
 golang.org/x/sys v0.0.0-20190924154521-2837fb4f24fe/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
 golang.org/x/sys v0.0.0-20200625212154-ddb9806d33ae/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
-golang.org/x/sys v0.0.0-20200930185726-fdedc70b468f h1:+Nyd8tzPX9R7BWHguqsrbFdRx3WQ/1ib8I44HXV5yTA=
 golang.org/x/sys v0.0.0-20200930185726-fdedc70b468f/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
+golang.org/x/sys v0.0.0-20201005170523-935f906f1786 h1:p+cMwGh5sVWewPAxkfnbIt0oVS5AUlcHZYaHRZg2opI=
+golang.org/x/sys v0.0.0-20201005170523-935f906f1786/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
 golang.org/x/text v0.3.0 h1:g61tztE5qeGQ89tm6NTjjM9VPIm088od1l6aSorWRWg=
 golang.org/x/text v0.3.0/go.mod h1:NqM8EUOU14njkJ3fqMW+pc6Ldnwhi/IjpwHt7yyuwOQ=
","Up
"
415,Go,b628d7276624c2d8ea7dd97d2259a2c2fce7d3cc,https://github.com/ethereum/go-ethereum/commit/b628d7276624c2d8ea7dd97d2259a2c2fce7d3cc,P,ethereum,go-ethereum,"[87, 2, 1, 7, 59, 27, 167, 17, 0, 0, 2, 15, 3, 18, 0, 0, 0, 2, 0, 9, 14, 1, 33, 33, 2, 0, 0, 0, 0]","diff --git a/.golangci.yml b/.golangci.yml
index 4c1297223..8a054667e 100644
--- a/.golangci.yml
+++ b/.golangci.yml
@@ -13,5 +13,4 @@ linters:
   disable-all: true
   enable:
-    - deadcode
     - goconst
     - goimports
@@ -21,5 +20,4 @@ linters:
     - misspell
     - unconvert
-    - varcheck
     - typecheck
     - unused
@@ -28,5 +26,4 @@ linters:
     - durationcheck
     - exportloopref
-    - gosec
     - whitespace
 
@@ -46,9 +43,4 @@ linters-settings:
     min-len: 3 # minimum length of string constant
     min-occurrences: 6 # minimum number of occurrences
-  gosec:
-    excludes:
-      - G404 # Use of weak random number generator - lots of FP
-      - G107 # Potential http request -- those are intentional
-      - G306 # G306: Expect WriteFile permissions to be 0600 or less
 
 issues:
@@ -59,11 +51,11 @@ issues:
         - staticcheck
     - path: internal/build/pgp.go
-      text: 'SA1019: package golang.org/x/crypto/openpgp is deprecated'
+      text: 'SA1019: ""golang.org/x/crypto/openpgp"" is deprecated: this package is unmaintained except for security fixes.'
     - path: core/vm/contracts.go
-      text: 'SA1019: package golang.org/x/crypto/ripemd160 is deprecated'
+      text: 'SA1019: ""golang.org/x/crypto/ripemd160"" is deprecated: RIPEMD-160 is a legacy hash and should not be used for new applications.'
     - path: accounts/usbwallet/trezor.go
-      text: 'SA1019: package github.com/golang/protobuf/proto is deprecated'
+      text: 'SA1019: ""github.com/golang/protobuf/proto"" is deprecated: Use the ""google.golang.org/protobuf/proto"" package instead.'
     - path: accounts/usbwallet/trezor/
-      text: 'SA1019: package github.com/golang/protobuf/proto is deprecated'
+      text: 'SA1019: ""github.com/golang/protobuf/proto"" is deprecated: Use the ""google.golang.org/protobuf/proto"" package instead.'
   exclude:
     - 'SA1019: event.TypeMux is deprecated: use Feed'
@@ -71,3 +63,2 @@ issues:
     - 'SA1019: strings.Title has been deprecated since Go 1.18 and an alternative has been available since Go 1.0: The rule Title uses for word boundaries does not handle Unicode punctuation properly. Use golang.org/x/text/cases instead.'
     - 'SA1029: should not use built-in type string as key for value'
-    - 'G306: Expect WriteFile permissions to be 0600 or less'
diff --git a/.travis.yml b/.travis.yml
index e08e271f3..a32b44506 100644
--- a/.travis.yml
+++ b/.travis.yml
@@ -17,5 +17,5 @@ jobs:
       os: linux
       dist: bionic
-      go: 1.18.x
+      go: 1.19.x
       env:
         - lint
@@ -32,5 +32,5 @@ jobs:
       arch: amd64
       dist: bionic
-      go: 1.18.x
+      go: 1.19.x
       env:
         - docker
@@ -49,5 +49,5 @@ jobs:
       arch: arm64
       dist: bionic
-      go: 1.18.x
+      go: 1.19.x
       env:
         - docker
@@ -66,5 +66,5 @@ jobs:
       os: linux
       dist: bionic
-      go: 1.18.x
+      go: 1.19.x
       env:
         - ubuntu-ppa
@@ -91,5 +91,5 @@ jobs:
       dist: bionic
       sudo: required
-      go: 1.18.x
+      go: 1.19.x
       env:
         - azure-linux
@@ -163,5 +163,5 @@ jobs:
       if: type = push
       os: osx
-      go: 1.18.x
+      go: 1.19.x
       env:
         - azure-osx
@@ -195,5 +195,5 @@ jobs:
       arch: amd64
       dist: bionic
-      go: 1.18.x
+      go: 1.19.x
       env:
         - GO111MODULE=on
@@ -215,5 +215,5 @@ jobs:
       os: linux
       dist: bionic
-      go: 1.17.x
+      go: 1.18.x
       env:
         - GO111MODULE=on
@@ -226,5 +226,5 @@ jobs:
       os: linux
       dist: bionic
-      go: 1.18.x
+      go: 1.19.x
       env:
         - azure-purge
@@ -240,5 +240,5 @@ jobs:
       os: linux
       dist: bionic
-      go: 1.18.x
+      go: 1.19.x
       env:
         - GO111MODULE=on
diff --git a/accounts/abi/abi_test.go b/accounts/abi/abi_test.go
index cd9433ca7..96c11e096 100644
--- a/accounts/abi/abi_test.go
+++ b/accounts/abi/abi_test.go
@@ -166,6 +166,7 @@ func TestInvalidABI(t *testing.T) {
 // TestConstructor tests a constructor function.
 // The test is based on the following contract:
-// 	contract TestConstructor {
-// 		constructor(uint256 a, uint256 b) public{}
+//
+//	contract TestConstructor {
+//		constructor(uint256 a, uint256 b) public{}
 //	}
 func TestConstructor(t *testing.T) {
@@ -725,14 +726,17 @@ func TestBareEvents(t *testing.T) {
 
 // TestUnpackEvent is based on this contract:
-//    contract T {
-//      event received(address sender, uint amount, bytes memo);
-//      event receivedAddr(address sender);
-//      function receive(bytes memo) external payable {
-//        received(msg.sender, msg.value, memo);
-//        receivedAddr(msg.sender);
-//      }
-//    }
+//
+//	contract T {
+//		event received(address sender, uint amount, bytes memo);
+//		event receivedAddr(address sender);
+//		function receive(bytes memo) external payable {
+//			received(msg.sender, msg.value, memo);
+//			receivedAddr(msg.sender);
+//		}
+//	}
+//
 // When receive(""X"") is called with sender 0x00... and value 1, it produces this tx receipt:
-//   receipt{status=1 cgas=23949 bloom=00000000004000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000800000000000000000000000000000000000040200000000000000000000000000000000001000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 logs=[log: b6818c8064f645cd82d99b59a1a267d6d61117ef [75fd880d39c1daf53b6547ab6cb59451fc6452d27caa90e5b6649dd8293b9eed] 000000000000000000000000376c47978271565f56deb45495afa69e59c16ab200000000000000000000000000000000000000000000000000000000000000010000000000000000000000000000000000000000000000000000000000000060000000000000000000000000000000000000000000000000000000000000000158 9ae378b6d4409eada347a5dc0c180f186cb62dc68fcc0f043425eb917335aa28 0 95d429d309bb9d753954195fe2d69bd140b4ae731b9b5b605c34323de162cf00 0]}
+//
+//	receipt{status=1 cgas=23949 bloom=00000000004000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000800000000000000000000000000000000000040200000000000000000000000000000000001000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 logs=[log: b6818c8064f645cd82d99b59a1a267d6d61117ef [75fd880d39c1daf53b6547ab6cb59451fc6452d27caa90e5b6649dd8293b9eed] 000000000000000000000000376c47978271565f56deb45495afa69e59c16ab200000000000000000000000000000000000000000000000000000000000000010000000000000000000000000000000000000000000000000000000000000060000000000000000000000000000000000000000000000000000000000000000158 9ae378b6d4409eada347a5dc0c180f186cb62dc68fcc0f043425eb917335aa28 0 95d429d309bb9d753954195fe2d69bd140b4ae731b9b5b605c34323de162cf00 0]}
 func TestUnpackEvent(t *testing.T) {
 	const abiJSON = `[{""constant"":false,""inputs"":[{""name"":""memo"",""type"":""bytes""}],""name"":""receive"",""outputs"":[],""payable"":true,""stateMutability"":""payable"",""type"":""function""},{""anonymous"":false,""inputs"":[{""indexed"":false,""name"":""sender"",""type"":""address""},{""indexed"":false,""name"":""amount"",""type"":""uint256""},{""indexed"":false,""name"":""memo"",""type"":""bytes""}],""name"":""received"",""type"":""event""},{""anonymous"":false,""inputs"":[{""indexed"":false,""name"":""sender"",""type"":""address""}],""name"":""receivedAddr"",""type"":""event""}]`
@@ -1079,6 +1083,7 @@ func TestDoubleDuplicateMethodNames(t *testing.T) {
 // conflict and that the second send event will be renamed send1.
 // The test runs the abi of the following contract.
-// 	contract DuplicateEvent {
-// 		event send(uint256 a);
+//
+//	contract DuplicateEvent {
+//		event send(uint256 a);
 //		event send0();
 //		event send();
@@ -1107,5 +1112,6 @@ func TestDoubleDuplicateEventNames(t *testing.T) {
 // correctly handled.
 // The test runs the abi of the following contract.
-// 	contract TestEvent {
+//
+//	contract TestEvent {
 //		event send(uint256, uint256);
 //	}
diff --git a/accounts/abi/bind/backends/simulated_test.go b/accounts/abi/bind/backends/simulated_test.go
index 83367f098..bb19b5455 100644
--- a/accounts/abi/bind/backends/simulated_test.go
+++ b/accounts/abi/bind/backends/simulated_test.go
@@ -94,15 +94,16 @@ func TestSimulatedBackend(t *testing.T) {
 var testKey, _ = crypto.HexToECDSA(""b71c71a67e1177ad4e901695e1b4b9ee17ae16c6668d313eac2f96dbcda3f291"")
 
-//  the following is based on this contract:
-//  contract T {
-//  	event received(address sender, uint amount, bytes memo);
-//  	event receivedAddr(address sender);
+// the following is based on this contract:
 //
-//  	function receive(bytes calldata memo) external payable returns (string memory res) {
-//  		emit received(msg.sender, msg.value, memo);
-//  		emit receivedAddr(msg.sender);
-//		    return ""hello world"";
-//  	}
-//  }
+//	 contract T {
+//	 	event received(address sender, uint amount, bytes memo);
+//	 	event receivedAddr(address sender);
+//
+//	 	function receive(bytes calldata memo) external payable returns (string memory res) {
+//	 		emit received(msg.sender, msg.value, memo);
+//	 		emit receivedAddr(msg.sender);
+//			return ""hello world"";
+//	 	}
+//	 }
 const abiJSON = `[ { ""constant"": false, ""inputs"": [ { ""name"": ""memo"", ""type"": ""bytes"" } ], ""name"": ""receive"", ""outputs"": [ { ""name"": ""res"", ""type"": ""string"" } ], ""payable"": true, ""stateMutability"": ""payable"", ""type"": ""function"" }, { ""anonymous"": false, ""inputs"": [ { ""indexed"": false, ""name"": ""sender"", ""type"": ""address"" }, { ""indexed"": false, ""name"": ""amount"", ""type"": ""uint256"" }, { ""indexed"": false, ""name"": ""memo"", ""type"": ""bytes"" } ], ""name"": ""received"", ""type"": ""event"" }, { ""anonymous"": false, ""inputs"": [ { ""indexed"": false, ""name"": ""sender"", ""type"": ""address"" } ], ""name"": ""receivedAddr"", ""type"": ""event"" } ]`
 const abiBin = `0x608060405234801561001057600080fd5b506102a0806100206000396000f3fe60806040526004361061003b576000357c010000000000000000000000000000000000000000000000000000000090048063a69b6ed014610040575b600080fd5b6100b76004803603602081101561005657600080fd5b810190808035906020019064010000000081111561007357600080fd5b82018360208201111561008557600080fd5b803590602001918460018302840111640100000000831117156100a757600080fd5b9091929391929390505050610132565b6040518080602001828103825283818151815260200191508051906020019080838360005b838110156100f75780820151818401526020810190506100dc565b50505050905090810190601f1680156101245780820380516001836020036101000a031916815260200191505b509250505060405180910390f35b60607f75fd880d39c1daf53b6547ab6cb59451fc6452d27caa90e5b6649dd8293b9eed33348585604051808573ffffffffffffffffffffffffffffffffffffffff1673ffffffffffffffffffffffffffffffffffffffff168152602001848152602001806020018281038252848482818152602001925080828437600081840152601f19601f8201169050808301925050509550505050505060405180910390a17f46923992397eac56cf13058aced2a1871933622717e27b24eabc13bf9dd329c833604051808273ffffffffffffffffffffffffffffffffffffffff1673ffffffffffffffffffffffffffffffffffffffff16815260200191505060405180910390a16040805190810160405280600b81526020017f68656c6c6f20776f726c6400000000000000000000000000000000000000000081525090509291505056fea165627a7a72305820ff0c57dad254cfeda48c9cfb47f1353a558bccb4d1bc31da1dae69315772d29e0029`
@@ -418,10 +419,11 @@ func TestEstimateGas(t *testing.T) {
 		pragma solidity ^0.6.4;
 		contract GasEstimation {
-		    function PureRevert() public { revert(); }
-		    function Revert() public { revert(""revert reason"");}
-		    function OOG() public { for (uint i = 0; ; i++) {}}
-		    function Assert() public { assert(false);}
-		    function Valid() public {}
-		}*/
+			function PureRevert() public { revert(); }
+			function Revert() public { revert(""revert reason"");}
+			function OOG() public { for (uint i = 0; ; i++) {}}
+			function Assert() public { assert(false);}
+			function Valid() public {}
+		}
+	*/
 	const contractAbi = ""[{\""inputs\"":[],\""name\"":\""Assert\"",\""outputs\"":[],\""stateMutability\"":\""nonpayable\"",\""type\"":\""function\""},{\""inputs\"":[],\""name\"":\""OOG\"",\""outputs\"":[],\""stateMutability\"":\""nonpayable\"",\""type\"":\""function\""},{\""inputs\"":[],\""name\"":\""PureRevert\"",\""outputs\"":[],\""stateMutability\"":\""nonpayable\"",\""type\"":\""function\""},{\""inputs\"":[],\""name\"":\""Revert\"",\""outputs\"":[],\""stateMutability\"":\""nonpayable\"",\""type\"":\""function\""},{\""inputs\"":[],\""name\"":\""Valid\"",\""outputs\"":[],\""stateMutability\"":\""nonpayable\"",\""type\"":\""function\""}]""
 	const contractBin = ""0x60806040523480156100115760006000fd5b50610017565b61016e806100266000396000f3fe60806040523480156100115760006000fd5b506004361061005c5760003560e01c806350f6fe3414610062578063aa8b1d301461006c578063b9b046f914610076578063d8b9839114610080578063e09fface1461008a5761005c565b60006000fd5b61006a610094565b005b6100746100ad565b005b61007e6100b5565b005b6100886100c2565b005b610092610135565b005b6000600090505b5b808060010191505061009b565b505b565b60006000fd5b565b600015156100bf57fe5b5b565b6040517f08c379a000000000000000000000000000000000000000000000000000000000815260040180806020018281038252600d8152602001807f72657665727420726561736f6e0000000000000000000000000000000000000081526020015060200191505060405180910390fd5b565b5b56fea2646970667358221220345bbcbb1a5ecf22b53a78eaebf95f8ee0eceff6d10d4b9643495084d2ec934a64736f6c63430006040033""
@@ -995,5 +997,6 @@ func TestCodeAt(t *testing.T) {
 
 // When receive(""X"") is called with sender 0x00... and value 1, it produces this tx receipt:
-//   receipt{status=1 cgas=23949 bloom=00000000004000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000800000000000000000000000000000000000040200000000000000000000000000000000001000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 logs=[log: b6818c8064f645cd82d99b59a1a267d6d61117ef [75fd880d39c1daf53b6547ab6cb59451fc6452d27caa90e5b6649dd8293b9eed] 000000000000000000000000376c47978271565f56deb45495afa69e59c16ab200000000000000000000000000000000000000000000000000000000000000010000000000000000000000000000000000000000000000000000000000000060000000000000000000000000000000000000000000000000000000000000000158 9ae378b6d4409eada347a5dc0c180f186cb62dc68fcc0f043425eb917335aa28 0 95d429d309bb9d753954195fe2d69bd140b4ae731b9b5b605c34323de162cf00 0]}
+//
+//	receipt{status=1 cgas=23949 bloom=00000000004000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000800000000000000000000000000000000000040200000000000000000000000000000000001000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 logs=[log: b6818c8064f645cd82d99b59a1a267d6d61117ef [75fd880d39c1daf53b6547ab6cb59451fc6452d27caa90e5b6649dd8293b9eed] 000000000000000000000000376c47978271565f56deb45495afa69e59c16ab200000000000000000000000000000000000000000000000000000000000000010000000000000000000000000000000000000000000000000000000000000060000000000000000000000000000000000000000000000000000000000000000158 9ae378b6d4409eada347a5dc0c180f186cb62dc68fcc0f043425eb917335aa28 0 95d429d309bb9d753954195fe2d69bd140b4ae731b9b5b605c34323de162cf00 0]}
 func TestPendingAndCallContract(t *testing.T) {
 	testAddr := crypto.PubkeyToAddress(testKey.PublicKey)
@@ -1058,25 +1061,25 @@ func TestPendingAndCallContract(t *testing.T) {
 /*
 contract Reverter {
-    function revertString() public pure{
-        require(false, ""some error"");
-    }
-    function revertNoString() public pure {
-        require(false, """");
-    }
-    function revertASM() public pure {
-        assembly {
-            revert(0x0, 0x0)
-        }
-    }
-    function noRevert() public pure {
-        assembly {
-            // Assembles something that looks like require(false, ""some error"") but is not reverted
-            mstore(0x0, 0x08c379a000000000000000000000000000000000000000000000000000000000)
-            mstore(0x4, 0x0000000000000000000000000000000000000000000000000000000000000020)
-            mstore(0x24, 0x000000000000000000000000000000000000000000000000000000000000000a)
-            mstore(0x44, 0x736f6d65206572726f7200000000000000000000000000000000000000000000)
-            return(0x0, 0x64)
-        }
-    }
+	function revertString() public pure{
+		require(false, ""some error"");
+	}
+	function revertNoString() public pure {
+		require(false, """");
+	}
+	function revertASM() public pure {
+		assembly {
+			revert(0x0, 0x0)
+		}
+	}
+	function noRevert() public pure {
+		assembly {
+			// Assembles something that looks like require(false, ""some error"") but is not reverted
+			mstore(0x0, 0x08c379a000000000000000000000000000000000000000000000000000000000)
+			mstore(0x4, 0x0000000000000000000000000000000000000000000000000000000000000020)
+			mstore(0x24, 0x000000000000000000000000000000000000000000000000000000000000000a)
+			mstore(0x44, 0x736f6d65206572726f7200000000000000000000000000000000000000000000)
+			return(0x0, 0x64)
+		}
+	}
 }*/
 func TestCallContractRevert(t *testing.T) {
@@ -1205,9 +1208,9 @@ func TestFork(t *testing.T) {
 Example contract to test event emission:
 
-pragma solidity >=0.7.0 <0.9.0;
-contract Callable {
-    event Called();
-    function Call() public { emit Called(); }
-}
+	pragma solidity >=0.7.0 <0.9.0;
+	contract Callable {
+		event Called();
+		function Call() public { emit Called(); }
+	}
 */
 const callableAbi = ""[{\""anonymous\"":false,\""inputs\"":[],\""name\"":\""Called\"",\""type\"":\""event\""},{\""inputs\"":[],\""name\"":\""Call\"",\""outputs\"":[],\""stateMutability\"":\""nonpayable\"",\""type\"":\""function\""}]""
@@ -1227,5 +1230,5 @@ const callableBin = ""6080604052348015600f57600080fd5b5060998061001e6000396000f3f
 //  8. Check that the event was removed.
 //  9. Re-send the transaction and mine a block.
-// 10. Check that the event was reborn.
+//  10. Check that the event was reborn.
 func TestForkLogsReborn(t *testing.T) {
 	testAddr := crypto.PubkeyToAddress(testKey.PublicKey)
diff --git a/accounts/abi/reflect.go b/accounts/abi/reflect.go
index 7917fa980..1f84b111a 100644
--- a/accounts/abi/reflect.go
+++ b/accounts/abi/reflect.go
@@ -26,14 +26,17 @@ import (
 
 // ConvertType converts an interface of a runtime type into a interface of the
-// given type
-// e.g. turn
-// var fields []reflect.StructField
-// fields = append(fields, reflect.StructField{
-// 		Name: ""X"",
-//		Type: reflect.TypeOf(new(big.Int)),
-//		Tag:  reflect.StructTag(""json:\"""" + ""x"" + ""\""""),
-// }
-// into
-// type TupleT struct { X *big.Int }
+// given type, e.g. turn this code:
+//
+//	var fields []reflect.StructField
+//
+//	fields = append(fields, reflect.StructField{
+//			Name: ""X"",
+//			Type: reflect.TypeOf(new(big.Int)),
+//			Tag:  reflect.StructTag(""json:\"""" + ""x"" + ""\""""),
+//	}
+//
+// into:
+//
+//	type TupleT struct { X *big.Int }
 func ConvertType(in interface{}, proto interface{}) interface{} {
 	protoType := reflect.TypeOf(proto)
@@ -171,9 +174,11 @@ func setStruct(dst, src reflect.Value) error {
 
 // mapArgNamesToStructFields maps a slice of argument names to struct fields.
-// first round: for each Exportable field that contains a `abi:""""` tag
-//   and this field name exists in the given argument name list, pair them together.
-// second round: for each argument name that has not been already linked,
-//   find what variable is expected to be mapped into, if it exists and has not been
-//   used, pair them.
+//
+// first round: for each Exportable field that contains a `abi:""""` tag and this field name
+// exists in the given argument name list, pair them together.
+//
+// second round: for each argument name that has not been already linked, find what
+// variable is expected to be mapped into, if it exists and has not been used, pair them.
+//
 // Note this function assumes the given value is a struct value.
 func mapArgNamesToStructFields(argNames []string, value reflect.Value) (map[string]string, error) {
diff --git a/accounts/abi/utils.go b/accounts/abi/utils.go
index e24df5b70..b1537ca58 100644
--- a/accounts/abi/utils.go
+++ b/accounts/abi/utils.go
@@ -22,13 +22,12 @@ import ""fmt""
 // This helper can be used for lots of purposes:
 //
-// - In solidity function overloading is supported, this function can fix
-//   the name conflicts of overloaded functions.
-// - In golang binding generation, the parameter(in function, event, error,
-//	 and struct definition) name will be converted to camelcase style which
-//	 may eventually lead to name conflicts.
+//   - In solidity function overloading is supported, this function can fix
+//     the name conflicts of overloaded functions.
+//   - In golang binding generation, the parameter(in function, event, error,
+//     and struct definition) name will be converted to camelcase style which
+//     may eventually lead to name conflicts.
 //
-// Name conflicts are mostly resolved by adding number suffix.
-// 	 e.g. if the abi contains Methods send, send1
-//   ResolveNameConflict would return send2 for input send.
+// Name conflicts are mostly resolved by adding number suffix. e.g. if the abi contains
+// Methods ""send"" and ""send1"", ResolveNameConflict would return ""send2"" for input ""send"".
 func ResolveNameConflict(rawName string, used func(string) bool) string {
 	name := rawName
diff --git a/accounts/accounts.go b/accounts/accounts.go
index 179a33c59..6c351a964 100644
--- a/accounts/accounts.go
+++ b/accounts/accounts.go
@@ -178,5 +178,6 @@ type Backend interface {
 //
 // The hash is calculated as
-//   keccak256(""\x19Ethereum Signed Message:\n""${message length}${message}).
+//
+//	keccak256(""\x19Ethereum Signed Message:\n""${message length}${message}).
 //
 // This gives context to the signed message and prevents signing of transactions.
@@ -190,5 +191,6 @@ func TextHash(data []byte) []byte {
 //
 // The hash is calculated as
-//   keccak256(""\x19Ethereum Signed Message:\n""${message length}${message}).
+//
+//	keccak256(""\x19Ethereum Signed Message:\n""${message length}${message}).
 //
 // This gives context to the signed message and prevents signing of transactions.
diff --git a/accounts/hd.go b/accounts/hd.go
index 3009f19b6..daca75ebb 100644
--- a/accounts/hd.go
+++ b/accounts/hd.go
@@ -47,5 +47,5 @@ var LegacyLedgerBaseDerivationPath = DerivationPath{0x80000000 + 44, 0x80000000
 // defines derivation paths to be of the form:
 //
-//   m / purpose' / coin_type' / account' / change / address_index
+//	m / purpose' / coin_type' / account' / change / address_index
 //
 // The BIP-44 spec https://github.com/bitcoin/bips/blob/master/bip-0044.mediawiki
diff --git a/accounts/scwallet/wallet.go b/accounts/scwallet/wallet.go
index 5082dec1c..e66717c3b 100644
--- a/accounts/scwallet/wallet.go
+++ b/accounts/scwallet/wallet.go
@@ -880,4 +880,5 @@ func (s *Session) walletStatus() (*walletStatus, error) {
 
 // derivationPath fetches the wallet's current derivation path from the card.
+//
 //lint:ignore U1000 needs to be added to the console interface
 func (s *Session) derivationPath() (accounts.DerivationPath, error) {
@@ -995,4 +996,5 @@ func (s *Session) derive(path accounts.DerivationPath) (accounts.Account, error)
 
 // keyExport contains information on an exported keypair.
+//
 //lint:ignore U1000 needs to be added to the console interface
 type keyExport struct {
@@ -1002,4 +1004,5 @@ type keyExport struct {
 
 // publicKey returns the public key for the current derivation path.
+//
 //lint:ignore U1000 needs to be added to the console interface
 func (s *Session) publicKey() ([]byte, error) {
diff --git a/accounts/url.go b/accounts/url.go
index 12a84414a..39b00e5b4 100644
--- a/accounts/url.go
+++ b/accounts/url.go
@@ -93,8 +93,7 @@ func (u *URL) UnmarshalJSON(input []byte) error {
 // Cmp compares x and y and returns:
 //
-//   -1 if x <  y
-//    0 if x == y
-//   +1 if x >  y
-//
+//	-1 if x <  y
+//	 0 if x == y
+//	+1 if x >  y
 func (u URL) Cmp(url URL) int {
 	if u.Scheme == url.Scheme {
diff --git a/accounts/usbwallet/ledger.go b/accounts/usbwallet/ledger.go
index 3de3b4091..cda94280f 100644
--- a/accounts/usbwallet/ledger.go
+++ b/accounts/usbwallet/ledger.go
@@ -196,16 +196,16 @@ func (w *ledgerDriver) SignTypedMessage(path accounts.DerivationPath, domainHash
 // The version retrieval protocol is defined as follows:
 //
-//   CLA | INS | P1 | P2 | Lc | Le
-//   ----+-----+----+----+----+---
-//    E0 | 06  | 00 | 00 | 00 | 04
+//	CLA | INS | P1 | P2 | Lc | Le
+//	----+-----+----+----+----+---
+//	 E0 | 06  | 00 | 00 | 00 | 04
 //
 // With no input data, and the output data being:
 //
-//   Description                                        | Length
-//   ---------------------------------------------------+--------
-//   Flags 01: arbitrary data signature enabled by user | 1 byte
-//   Application major version                          | 1 byte
-//   Application minor version                          | 1 byte
-//   Application patch version                          | 1 byte
+//	Description                                        | Length
+//	---------------------------------------------------+--------
+//	Flags 01: arbitrary data signature enabled by user | 1 byte
+//	Application major version                          | 1 byte
+//	Application minor version                          | 1 byte
+//	Application patch version                          | 1 byte
 func (w *ledgerDriver) ledgerVersion() ([3]byte, error) {
 	// Send the request and wait for the response
@@ -228,30 +228,30 @@ func (w *ledgerDriver) ledgerVersion() ([3]byte, error) {
 // The address derivation protocol is defined as follows:
 //
-//   CLA | INS | P1 | P2 | Lc  | Le
-//   ----+-----+----+----+-----+---
-//    E0 | 02  | 00 return address
-//               01 display address and confirm before returning
-//                  | 00: do not return the chain code
-//                  | 01: return the chain code
-//                       | var | 00
+//	CLA | INS | P1 | P2 | Lc  | Le
+//	----+-----+----+----+-----+---
+//	 E0 | 02  | 00 return address
+//	            01 display address and confirm before returning
+//	               | 00: do not return the chain code
+//	               | 01: return the chain code
+//	                    | var | 00
 //
 // Where the input data is:
 //
-//   Description                                      | Length
-//   -------------------------------------------------+--------
-//   Number of BIP 32 derivations to perform (max 10) | 1 byte
-//   First derivation index (big endian)              | 4 bytes
-//   ...                                              | 4 bytes
-//   Last derivation index (big endian)               | 4 bytes
+//	Description                                      | Length
+//	-------------------------------------------------+--------
+//	Number of BIP 32 derivations to perform (max 10) | 1 byte
+//	First derivation index (big endian)              | 4 bytes
+//	...                                              | 4 bytes
+//	Last derivation index (big endian)               | 4 bytes
 //
 // And the output data is:
 //
-//   Description             | Length
-//   ------------------------+-------------------
-//   Public Key length       | 1 byte
-//   Uncompressed Public Key | arbitrary
-//   Ethereum address length | 1 byte
-//   Ethereum address        | 40 bytes hex ascii
-//   Chain code if requested | 32 bytes
+//	Description             | Length
+//	------------------------+-------------------
+//	Public Key length       | 1 byte
+//	Uncompressed Public Key | arbitrary
+//	Ethereum address length | 1 byte
+//	Ethereum address        | 40 bytes hex ascii
+//	Chain code if requested | 32 bytes
 func (w *ledgerDriver) ledgerDerive(derivationPath []uint32) (common.Address, error) {
 	// Flatten the derivation path into the Ledger request
@@ -291,33 +291,33 @@ func (w *ledgerDriver) ledgerDerive(derivationPath []uint32) (common.Address, er
 // The transaction signing protocol is defined as follows:
 //
-//   CLA | INS | P1 | P2 | Lc  | Le
-//   ----+-----+----+----+-----+---
-//    E0 | 04  | 00: first transaction data block
-//               80: subsequent transaction data block
-//                  | 00 | variable | variable
+//	CLA | INS | P1 | P2 | Lc  | Le
+//	----+-----+----+----+-----+---
+//	 E0 | 04  | 00: first transaction data block
+//	            80: subsequent transaction data block
+//	               | 00 | variable | variable
 //
 // Where the input for the first transaction block (first 255 bytes) is:
 //
-//   Description                                      | Length
-//   -------------------------------------------------+----------
-//   Number of BIP 32 derivations to perform (max 10) | 1 byte
-//   First derivation index (big endian)              | 4 bytes
-//   ...                                              | 4 bytes
-//   Last derivation index (big endian)               | 4 bytes
-//   RLP transaction chunk                            | arbitrary
+//	Description                                      | Length
+//	-------------------------------------------------+----------
+//	Number of BIP 32 derivations to perform (max 10) | 1 byte
+//	First derivation index (big endian)              | 4 bytes
+//	...                                              | 4 bytes
+//	Last derivation index (big endian)               | 4 bytes
+//	RLP transaction chunk                            | arbitrary
 //
 // And the input for subsequent transaction blocks (first 255 bytes) are:
 //
-//   Description           | Length
-//   ----------------------+----------
-//   RLP transaction chunk | arbitrary
+//	Description           | Length
+//	----------------------+----------
+//	RLP transaction chunk | arbitrary
 //
 // And the output data is:
 //
-//   Description | Length
-//   ------------+---------
-//   signature V | 1 byte
-//   signature R | 32 bytes
-//   signature S | 32 bytes
+//	Description | Length
+//	------------+---------
+//	signature V | 1 byte
+//	signature R | 32 bytes
+//	signature S | 32 bytes
 func (w *ledgerDriver) ledgerSign(derivationPath []uint32, tx *types.Transaction, chainID *big.Int) (common.Address, *types.Transaction, error) {
 	// Flatten the derivation path into the Ledger request
@@ -393,28 +393,26 @@ func (w *ledgerDriver) ledgerSign(derivationPath []uint32, tx *types.Transaction
 // The signing protocol is defined as follows:
 //
-//   CLA | INS | P1 | P2                          | Lc  | Le
-//   ----+-----+----+-----------------------------+-----+---
-//    E0 | 0C  | 00 | implementation version : 00 | variable | variable
+//	CLA | INS | P1 | P2                          | Lc  | Le
+//	----+-----+----+-----------------------------+-----+---
+//	 E0 | 0C  | 00 | implementation version : 00 | variable | variable
 //
 // Where the input is:
 //
-//   Description                                      | Length
-//   -------------------------------------------------+----------
-//   Number of BIP 32 derivations to perform (max 10) | 1 byte
-//   First derivation index (big endian)              | 4 bytes
-//   ...                                              | 4 bytes
-//   Last derivation index (big endian)               | 4 bytes
-//   domain hash                                      | 32 bytes
-//   message hash                                     | 32 bytes
-//
-//
+//	Description                                      | Length
+//	-------------------------------------------------+----------
+//	Number of BIP 32 derivations to perform (max 10) | 1 byte
+//	First derivation index (big endian)              | 4 bytes
+//	...                                              | 4 bytes
+//	Last derivation index (big endian)               | 4 bytes
+//	domain hash                                      | 32 bytes
+//	message hash                                     | 32 bytes
 //
 // And the output data is:
 //
-//   Description | Length
-//   ------------+---------
-//   signature V | 1 byte
-//   signature R | 32 bytes
-//   signature S | 32 bytes
+//	Description | Length
+//	------------+---------
+//	signature V | 1 byte
+//	signature R | 32 bytes
+//	signature S | 32 bytes
 func (w *ledgerDriver) ledgerSignTypedMessage(derivationPath []uint32, domainHash []byte, messageHash []byte) ([]byte, error) {
 	// Flatten the derivation path into the Ledger request
@@ -455,10 +453,10 @@ func (w *ledgerDriver) ledgerSignTypedMessage(derivationPath []uint32, domainHas
 // The common transport header is defined as follows:
 //
-//  Description                           | Length
-//  --------------------------------------+----------
-//  Communication channel ID (big endian) | 2 bytes
-//  Command tag                           | 1 byte
-//  Packet sequence index (big endian)    | 2 bytes
-//  Payload                               | arbitrary
+//	Description                           | Length
+//	--------------------------------------+----------
+//	Communication channel ID (big endian) | 2 bytes
+//	Command tag                           | 1 byte
+//	Packet sequence index (big endian)    | 2 bytes
+//	Payload                               | arbitrary
 //
 // The Communication channel ID allows commands multiplexing over the same
@@ -474,13 +472,13 @@ func (w *ledgerDriver) ledgerSignTypedMessage(derivationPath []uint32, domainHas
 // APDU Command payloads are encoded as follows:
 //
-//  Description              | Length
-//  -----------------------------------
-//  APDU length (big endian) | 2 bytes
-//  APDU CLA                 | 1 byte
-//  APDU INS                 | 1 byte
-//  APDU P1                  | 1 byte
-//  APDU P2                  | 1 byte
-//  APDU length              | 1 byte
-//  Optional APDU data       | arbitrary
+//	Description              | Length
+//	-----------------------------------
+//	APDU length (big endian) | 2 bytes
+//	APDU CLA                 | 1 byte
+//	APDU INS                 | 1 byte
+//	APDU P1                  | 1 byte
+//	APDU P2                  | 1 byte
+//	APDU length              | 1 byte
+//	Optional APDU data       | arbitrary
 func (w *ledgerDriver) ledgerExchange(opcode ledgerOpcode, p1 ledgerParam1, p2 ledgerParam2, data []byte) ([]byte, error) {
 	// Construct the message payload, possibly split into multiple chunks
diff --git a/accounts/usbwallet/trezor.go b/accounts/usbwallet/trezor.go
index e385682a5..9644dc4e0 100644
--- a/accounts/usbwallet/trezor.go
+++ b/accounts/usbwallet/trezor.go
@@ -85,13 +85,13 @@ func (w *trezorDriver) Status() (string, error) {
 // Open implements usbwallet.driver, attempting to initialize the connection to
 // the Trezor hardware wallet. Initializing the Trezor is a two or three phase operation:
-//  * The first phase is to initialize the connection and read the wallet's
-//    features. This phase is invoked if the provided passphrase is empty. The
-//    device will display the pinpad as a result and will return an appropriate
-//    error to notify the user that a second open phase is needed.
-//  * The second phase is to unlock access to the Trezor, which is done by the
-//    user actually providing a passphrase mapping a keyboard keypad to the pin
-//    number of the user (shuffled according to the pinpad displayed).
-//  * If needed the device will ask for passphrase which will require calling
-//    open again with the actual passphrase (3rd phase)
+//   - The first phase is to initialize the connection and read the wallet's
+//     features. This phase is invoked if the provided passphrase is empty. The
+//     device will display the pinpad as a result and will return an appropriate
+//     error to notify the user that a second open phase is needed.
+//   - The second phase is to unlock access to the Trezor, which is done by the
+//     user actually providing a passphrase mapping a keyboard keypad to the pin
+//     number of the user (shuffled according to the pinpad displayed).
+//   - If needed the device will ask for passphrase which will require calling
+//     open again with the actual passphrase (3rd phase)
 func (w *trezorDriver) Open(device io.ReadWriter, passphrase string) error {
 	w.device, w.failure = device, nil
diff --git a/accounts/usbwallet/trezor/messages-common.pb.go b/accounts/usbwallet/trezor/messages-common.pb.go
index 304bec0e3..b396c6d8b 100644
--- a/accounts/usbwallet/trezor/messages-common.pb.go
+++ b/accounts/usbwallet/trezor/messages-common.pb.go
@@ -95,5 +95,5 @@ func (Failure_FailureType) EnumDescriptor() ([]byte, []int) {
 }
 
-//*
+// *
 // Type of button request
 type ButtonRequest_ButtonRequestType int32
@@ -176,5 +176,5 @@ func (ButtonRequest_ButtonRequestType) EnumDescriptor() ([]byte, []int) {
 }
 
-//*
+// *
 // Type of PIN request
 type PinMatrixRequest_PinMatrixRequestType int32
@@ -221,5 +221,5 @@ func (PinMatrixRequest_PinMatrixRequestType) EnumDescriptor() ([]byte, []int) {
 }
 
-//*
+// *
 // Response: Success of the previous request
 // @end
@@ -263,5 +263,5 @@ func (m *Success) GetMessage() string {
 }
 
-//*
+// *
 // Response: Failure of the previous request
 // @end
@@ -313,5 +313,5 @@ func (m *Failure) GetMessage() string {
 }
 
-//*
+// *
 // Response: Device is waiting for HW button press.
 // @auxstart
@@ -364,5 +364,5 @@ func (m *ButtonRequest) GetData() string {
 }
 
-//*
+// *
 // Request: Computer agrees to wait for HW button press
 // @auxend
@@ -398,5 +398,5 @@ func (m *ButtonAck) XXX_DiscardUnknown() {
 var xxx_messageInfo_ButtonAck proto.InternalMessageInfo
 
-//*
+// *
 // Response: Device is asking computer to show PIN matrix and awaits PIN encoded using this matrix scheme
 // @auxstart
@@ -441,5 +441,5 @@ func (m *PinMatrixRequest) GetType() PinMatrixRequest_PinMatrixRequestType {
 }
 
-//*
+// *
 // Request: Computer responds with encoded PIN
 // @auxend
@@ -483,5 +483,5 @@ func (m *PinMatrixAck) GetPin() string {
 }
 
-//*
+// *
 // Response: Device awaits encryption passphrase
 // @auxstart
@@ -526,5 +526,5 @@ func (m *PassphraseRequest) GetOnDevice() bool {
 }
 
-//*
+// *
 // Request: Send passphrase back
 // @next PassphraseStateRequest
@@ -576,5 +576,5 @@ func (m *PassphraseAck) GetState() []byte {
 }
 
-//*
+// *
 // Response: Device awaits passphrase state
 // @next PassphraseStateAck
@@ -618,5 +618,5 @@ func (m *PassphraseStateRequest) GetState() []byte {
 }
 
-//*
+// *
 // Request: Send passphrase state back
 // @auxend
@@ -652,5 +652,5 @@ func (m *PassphraseStateAck) XXX_DiscardUnknown() {
 var xxx_messageInfo_PassphraseStateAck proto.InternalMessageInfo
 
-//*
+// *
 // Structure representing BIP32 (hierarchical deterministic) node
 // Used for imports of private key into the device and exporting public key out of device
diff --git a/accounts/usbwallet/trezor/messages-ethereum.pb.go b/accounts/usbwallet/trezor/messages-ethereum.pb.go
index 5d664f5ba..230a48279 100644
--- a/accounts/usbwallet/trezor/messages-ethereum.pb.go
+++ b/accounts/usbwallet/trezor/messages-ethereum.pb.go
@@ -22,5 +22,5 @@ var _ = math.Inf
 const _ = proto.ProtoPackageIsVersion3 // please upgrade the proto package
 
-//*
+// *
 // Request: Ask device for public key corresponding to address_n path
 // @start
@@ -74,5 +74,5 @@ func (m *EthereumGetPublicKey) GetShowDisplay() bool {
 }
 
-//*
+// *
 // Response: Contains public key derived from device private seed
 // @end
@@ -124,5 +124,5 @@ func (m *EthereumPublicKey) GetXpub() string {
 }
 
-//*
+// *
 // Request: Ask device for Ethereum address corresponding to address_n path
 // @start
@@ -176,5 +176,5 @@ func (m *EthereumGetAddress) GetShowDisplay() bool {
 }
 
-//*
+// *
 // Response: Contains an Ethereum address derived from device private seed
 // @end
@@ -226,5 +226,5 @@ func (m *EthereumAddress) GetAddressHex() string {
 }
 
-//*
+// *
 // Request: Ask device to sign transaction
 // All fields are optional from the protocol's point of view. Each field defaults to value `0` if missing.
@@ -352,5 +352,5 @@ func (m *EthereumSignTx) GetTxType() uint32 {
 }
 
-//*
+// *
 // Response: Device asks for more data from transaction payload, or returns the signature.
 // If data_length is set, device awaits that many more bytes of payload.
@@ -421,5 +421,5 @@ func (m *EthereumTxRequest) GetSignatureS() []byte {
 }
 
-//*
+// *
 // Request: Transaction payload data.
 // @next EthereumTxRequest
@@ -463,5 +463,5 @@ func (m *EthereumTxAck) GetDataChunk() []byte {
 }
 
-//*
+// *
 // Request: Ask device to sign message
 // @start
@@ -515,5 +515,5 @@ func (m *EthereumSignMessage) GetMessage() []byte {
 }
 
-//*
+// *
 // Response: Signed message
 // @end
@@ -573,5 +573,5 @@ func (m *EthereumMessageSignature) GetAddressHex() string {
 }
 
-//*
+// *
 // Request: Ask device to verify message
 // @start
diff --git a/accounts/usbwallet/trezor/messages-management.pb.go b/accounts/usbwallet/trezor/messages-management.pb.go
index f5c872f1f..91bfca1e3 100644
--- a/accounts/usbwallet/trezor/messages-management.pb.go
+++ b/accounts/usbwallet/trezor/messages-management.pb.go
@@ -22,5 +22,5 @@ var _ = math.Inf
 const _ = proto.ProtoPackageIsVersion3 // please upgrade the proto package
 
-//*
+// *
 // Structure representing passphrase source
 type ApplySettings_PassphraseSourceType int32
@@ -67,5 +67,5 @@ func (ApplySettings_PassphraseSourceType) EnumDescriptor() ([]byte, []int) {
 }
 
-//*
+// *
 // Type of recovery procedure. These should be used as bitmask, e.g.,
 // `RecoveryDeviceType_ScrambledWords | RecoveryDeviceType_Matrix`
@@ -115,5 +115,5 @@ func (RecoveryDevice_RecoveryDeviceType) EnumDescriptor() ([]byte, []int) {
 }
 
-//*
+// *
 // Type of Recovery Word request
 type WordRequest_WordRequestType int32
@@ -160,5 +160,5 @@ func (WordRequest_WordRequestType) EnumDescriptor() ([]byte, []int) {
 }
 
-//*
+// *
 // Request: Reset device to default state and ask for device details
 // @start
@@ -211,5 +211,5 @@ func (m *Initialize) GetSkipPassphrase() bool {
 }
 
-//*
+// *
 // Request: Ask for device details (no device reset)
 // @start
@@ -246,5 +246,5 @@ func (m *GetFeatures) XXX_DiscardUnknown() {
 var xxx_messageInfo_GetFeatures proto.InternalMessageInfo
 
-//*
+// *
 // Response: Reports various information about the device
 // @end
@@ -496,5 +496,5 @@ func (m *Features) GetNoBackup() bool {
 }
 
-//*
+// *
 // Request: clear session (removes cached PIN, passphrase, etc).
 // @start
@@ -531,5 +531,5 @@ func (m *ClearSession) XXX_DiscardUnknown() {
 var xxx_messageInfo_ClearSession proto.InternalMessageInfo
 
-//*
+// *
 // Request: change language and/or label of the device
 // @start
@@ -623,5 +623,5 @@ func (m *ApplySettings) GetDisplayRotation() uint32 {
 }
 
-//*
+// *
 // Request: set flags of the device
 // @start
@@ -667,5 +667,5 @@ func (m *ApplyFlags) GetFlags() uint32 {
 }
 
-//*
+// *
 // Request: Starts workflow for setting/changing/removing the PIN
 // @start
@@ -711,5 +711,5 @@ func (m *ChangePin) GetRemove() bool {
 }
 
-//*
+// *
 // Request: Test if the device is alive, device sends back the message in Success response
 // @start
@@ -778,5 +778,5 @@ func (m *Ping) GetPassphraseProtection() bool {
 }
 
-//*
+// *
 // Request: Abort last operation that required user interaction
 // @start
@@ -813,5 +813,5 @@ func (m *Cancel) XXX_DiscardUnknown() {
 var xxx_messageInfo_Cancel proto.InternalMessageInfo
 
-//*
+// *
 // Request: Request a sample of random data generated by hardware RNG. May be used for testing.
 // @start
@@ -857,5 +857,5 @@ func (m *GetEntropy) GetSize() uint32 {
 }
 
-//*
+// *
 // Response: Reply with random data generated by internal RNG
 // @end
@@ -899,5 +899,5 @@ func (m *Entropy) GetEntropy() []byte {
 }
 
-//*
+// *
 // Request: Request device to wipe all sensitive data and settings
 // @start
@@ -935,5 +935,5 @@ func (m *WipeDevice) XXX_DiscardUnknown() {
 var xxx_messageInfo_WipeDevice proto.InternalMessageInfo
 
-//*
+// *
 // Request: Load seed and related internal settings from the computer
 // @start
@@ -1037,5 +1037,5 @@ func (m *LoadDevice) GetU2FCounter() uint32 {
 }
 
-//*
+// *
 // Request: Ask device to do initialization involving user interaction
 // @start
@@ -1148,5 +1148,5 @@ func (m *ResetDevice) GetNoBackup() bool {
 }
 
-//*
+// *
 // Request: Perform backup of the device seed if not backed up using ResetDevice
 // @start
@@ -1183,5 +1183,5 @@ func (m *BackupDevice) XXX_DiscardUnknown() {
 var xxx_messageInfo_BackupDevice proto.InternalMessageInfo
 
-//*
+// *
 // Response: Ask for additional entropy from host computer
 // @next EntropyAck
@@ -1217,5 +1217,5 @@ func (m *EntropyRequest) XXX_DiscardUnknown() {
 var xxx_messageInfo_EntropyRequest proto.InternalMessageInfo
 
-//*
+// *
 // Request: Provide additional entropy for seed generation function
 // @next Success
@@ -1259,5 +1259,5 @@ func (m *EntropyAck) GetEntropy() []byte {
 }
 
-//*
+// *
 // Request: Start recovery workflow asking user for specific words of mnemonic
 // Used to recovery device safely even on untrusted computer.
@@ -1370,5 +1370,5 @@ func (m *RecoveryDevice) GetDryRun() bool {
 }
 
-//*
+// *
 // Response: Device is waiting for user to enter word of the mnemonic
 // Its position is shown only on device's internal display.
@@ -1413,5 +1413,5 @@ func (m *WordRequest) GetType() WordRequest_WordRequestType {
 }
 
-//*
+// *
 // Request: Computer replies with word from the mnemonic
 // @next WordRequest
@@ -1457,5 +1457,5 @@ func (m *WordAck) GetWord() string {
 }
 
-//*
+// *
 // Request: Set U2F counter
 // @start
diff --git a/accounts/usbwallet/trezor/messages.pb.go b/accounts/usbwallet/trezor/messages.pb.go
index 6278bd8ee..af0c95714 100644
--- a/accounts/usbwallet/trezor/messages.pb.go
+++ b/accounts/usbwallet/trezor/messages.pb.go
@@ -23,5 +23,5 @@ var _ = math.Inf
 const _ = proto.ProtoPackageIsVersion3 // please upgrade the proto package
 
-//*
+// *
 // Mapping between TREZOR wire identifier (uint) and a protobuf message
 type MessageType int32
diff --git a/build/checksums.txt b/build/checksums.txt
index f7b13a033..2725329fb 100644
--- a/build/checksums.txt
+++ b/build/checksums.txt
@@ -1,38 +1,38 @@
 # This file contains sha256 checksums of optional build dependencies.
 
-9920d3306a1ac536cdd2c796d6cb3c54bc559c226fc3cc39c32f1e0bd7f50d2a  go1.18.5.src.tar.gz
-828eeca8b5abea3e56921df8fa4b1101380a5ebcfee10acbc8ffe7ec0bf5876b  go1.18.5.darwin-amd64.tar.gz
-923a377c6fc9a2c789f5db61c24b8f64133f7889056897449891f256af34065f  go1.18.5.darwin-arm64.tar.gz
-c3d90264a706e2d88cfb44126dc6f0d008a48f00732e04bc377cea1a2b716a7c  go1.18.5.freebsd-386.tar.gz
-0de23843c568d388bc0f0e390a8966938cccaae0d74b698325f7175bac04e0c6  go1.18.5.freebsd-amd64.tar.gz
-0c44f85d146c6f98c34e8ff436a42af22e90e36fe232d3d9d3101f23fd61362b  go1.18.5.linux-386.tar.gz
-9e5de37f9c49942c601b191ac5fba404b868bfc21d446d6960acc12283d6e5f2  go1.18.5.linux-amd64.tar.gz
-006f6622718212363fa1ff004a6ab4d87bbbe772ec5631bab7cac10be346e4f1  go1.18.5.linux-arm64.tar.gz
-d5ac34ac5f060a5274319aa04b7b11e41b123bd7887d64efb5f44ead236957af  go1.18.5.linux-armv6l.tar.gz
-2e37fb9c7cbaedd4e729492d658aa4cde821fc94117391a8105c13b25ca1c84b  go1.18.5.linux-ppc64le.tar.gz
-e3d536e7873639f85353e892444f83b14cb6670603961f215986ae8e28e8e07a  go1.18.5.linux-s390x.tar.gz
-7b3142ec0c5db991e7f73a231662a92429b90ee151fe47557acb566d8d9ae4d3  go1.18.5.windows-386.zip
-73753620602d4b4469770040c53db55e5dd6af2ad07ecc18f71f164c3224eaad  go1.18.5.windows-amd64.zip
-4d154626affff12ef73ea1017af0e5b52dbc839ef92f6f9e76cf4f71278a5744  go1.18.5.windows-arm64.zip
+27871baa490f3401414ad793fba49086f6c855b1c584385ed7771e1204c7e179  go1.19.1.src.tar.gz
+b2828a2b05f0d2169afc74c11ed010775bf7cf0061822b275697b2f470495fb7  go1.19.1.darwin-amd64.tar.gz
+e46aecce83a9289be16ce4ba9b8478a5b89b8aa0230171d5c6adbc0c66640548  go1.19.1.darwin-arm64.tar.gz
+cfaca8c1d5784d2bc21e12d8893cfd2dc885a60db4c1a9a95e4ffc694d0925ce  go1.19.1.freebsd-386.tar.gz
+db5b8f232e12c655cc6cde6af1adf4d27d842541807802d747c86161e89efa0a  go1.19.1.freebsd-amd64.tar.gz
+9acc57342400c5b0c2da07b5b01b50da239dd4a7fad41a1fb56af8363ef4133f  go1.19.1.linux-386.tar.gz
+acc512fbab4f716a8f97a8b3fbaa9ddd39606a28be6c2515ef7c6c6311acffde  go1.19.1.linux-amd64.tar.gz
+49960821948b9c6b14041430890eccee58c76b52e2dbaafce971c3c38d43df9f  go1.19.1.linux-arm64.tar.gz
+efe93f5671621ee84ce5e262e1e21acbc72acefbaba360f21778abd083d4ad16  go1.19.1.linux-armv6l.tar.gz
+4137984aa353de9c5ec1bd8fb3cd00a0624b75eafa3d4ec13d2f3f48261dba2e  go1.19.1.linux-ppc64le.tar.gz
+ca1005cc80a3dd726536b4c6ea5fef0318939351ff273eff420bd66a377c74eb  go1.19.1.linux-s390x.tar.gz
+bc7043e7a9a8d34aacd06f8c2f70e166d1d148f6800814cff790c45b9ab31cee  go1.19.1.windows-386.zip
+b33584c1d93b0e9c783de876b7aa99d3018bdeccd396aeb6d516a74e9d88d55f  go1.19.1.windows-amd64.zip
+d8cf3f04762fa7d5d9c82dfa15b5adaae2404463af3bc8dcd7f89837512501fe  go1.19.1.windows-arm64.zip
 
-658078aaaf7608693f37c4cf1380b2af418ab8b2d23fdb33e7e2d4339328590e  golangci-lint-1.46.2-darwin-amd64.tar.gz
-81f9b4afd62ec5e612ef8bc3b1d612a88b56ff289874831845cdad394427385f  golangci-lint-1.46.2-darwin-arm64.tar.gz
-943486e703e62ec55ecd90caeb22bcd39f8cc3962a93eec18c06b7bae12cb46f  golangci-lint-1.46.2-freebsd-386.tar.gz
-a75dd9ba7e08e8315c411697171db5375c0f6a1ece9e6fbeb9e9a4386822e17d  golangci-lint-1.46.2-freebsd-amd64.tar.gz
-83eedca1af72e8be055a1235177eb1b33524fbf08bec5730df2e6c3efade2b23  golangci-lint-1.46.2-freebsd-armv6.tar.gz
-513d276c490de6f82baa01f9346d8d78b385f2ae97608f42f05d1f0f1314cd54  golangci-lint-1.46.2-freebsd-armv7.tar.gz
-461a60016d516c69d406dc3e2d4957b722dbe684b7085dfac4802d0f84409e27  golangci-lint-1.46.2-linux-386.tar.gz
-242cd4f2d6ac0556e315192e8555784d13da5d1874e51304711570769c4f2b9b  golangci-lint-1.46.2-linux-amd64.tar.gz
-ff5448ada2b3982581984d64b0dec614dba0a3ea4cab2d6a343c77927fc89f7e  golangci-lint-1.46.2-linux-arm64.tar.gz
-177f5210ef04aee282bfbc6ec519d36af5fb7d2b2c8d3f4ea5e59fdba71b0a27  golangci-lint-1.46.2-linux-armv6.tar.gz
-10dd512a36ee978a1009edbca3ba3af410f0fda8df4d85f0e4793a24213870cc  golangci-lint-1.46.2-linux-armv7.tar.gz
-67779fa517c688c9db1090c3c456117d95c6b92979c623fe8cce8fb84251f21e  golangci-lint-1.46.2-linux-mips64.tar.gz
-c085f0f57bdccbb2c902a41b72ce210a3dfff16ca856789374745ab52004b6ee  golangci-lint-1.46.2-linux-mips64le.tar.gz
-abecef6421499248e58ed75d2938bc12b4b1f98b057f25060680b77bb51a881e  golangci-lint-1.46.2-linux-ppc64le.tar.gz
-134843a8f5c5c182c11979ea75f5866945d54757b2a04f3e5e04a0cf4fbf3a39  golangci-lint-1.46.2-linux-riscv64.tar.gz
-9fe21a9476567aafe7a2e1a926b9641a39f920d4c0ea8eda9d968bc6136337f9  golangci-lint-1.46.2-linux-s390x.tar.gz
-b48a421ec12a43f8fc8f977b9cf7d4a1ea1c4b97f803a238de7d3ce4ab23a84b  golangci-lint-1.46.2-windows-386.zip
-604acc1378a566abb0eac799362f3a37b7fcb5fa2268aeb2d5d954c829367301  golangci-lint-1.46.2-windows-amd64.zip
-927def10db073da9687594072e6a3d9c891f67fa897105a2cfd715e018e7386c  golangci-lint-1.46.2-windows-arm64.zip
-729b76ed1d8b4e2612e38772b211503cb940e00a137bbaace1aa066f7c943737  golangci-lint-1.46.2-windows-armv6.zip
-ea27c86d91e0b245ecbcfbf6cdb4ac0522d4bc6dca56bba02ea1bc77ad2917ac  golangci-lint-1.46.2-windows-armv7.zip
+20cd1215e0420db8cfa94a6cd3c9d325f7b39c07f2415a02d111568d8bc9e271  golangci-lint-1.49.0-darwin-amd64.tar.gz
+cabb1a4c35fe1dadbe5a81550a00871281a331e7660cd85ae16e936a7f0f6cfc  golangci-lint-1.49.0-darwin-arm64.tar.gz
+f834c3b09580cf763b5d30b0c33c83cb13d7a822b5ed5d724143f121ffe28c97  golangci-lint-1.49.0-freebsd-386.tar.gz
+4ca91c9f3aa79a71da441b7220a3e799365ff7a24caf9f04fcda12066c5ab0f7  golangci-lint-1.49.0-freebsd-amd64.tar.gz
+37de789245248eea375d05080e11b4662a08762c353752575167611e65658454  golangci-lint-1.49.0-freebsd-armv6.tar.gz
+3abed2bd3a8134b501fdc9cc9a0e60d616c86389e4fcdd1f79ceae7458974378  golangci-lint-1.49.0-freebsd-armv7.tar.gz
+ef2860d90d83aee6713f697f23372cd93ac41a16439fdcb3c4ac86ba0f306860  golangci-lint-1.49.0-linux-386.tar.gz
+5badc6e9fee2003621efa07e385910d9a88c89b38f6c35aded153193c5125178  golangci-lint-1.49.0-linux-amd64.tar.gz
+b57ed03d29b8ca69be9925edd67ea305b6013cd5c97507d205fbe2979f71f2b5  golangci-lint-1.49.0-linux-arm64.tar.gz
+4a41cff3af7f5304751f7bbf4ea617c14ebc1f88481a28a013e61b06d1f7102c  golangci-lint-1.49.0-linux-armv6.tar.gz
+14a9683af483ee7052dd0ce7d6140e0b502d6001bea3de606b8e7cce2c673539  golangci-lint-1.49.0-linux-armv7.tar.gz
+33edf757bc2611204fdb40b212900866a57ded4eea62c1b19c10bfc375359afa  golangci-lint-1.49.0-linux-mips64.tar.gz
+280f7902f90d162566f1691a300663dd8db6e225e65384fe66b6fb2362e0b314  golangci-lint-1.49.0-linux-mips64le.tar.gz
+103bcb7ce6c668e0a7e95e5c5355892d74f5d15391443430472e66d652906a15  golangci-lint-1.49.0-linux-ppc64le.tar.gz
+4636ff9b01ddb18a2c1a953fc134207711b0a5d874d04ac66f915e9cfff0e8e0  golangci-lint-1.49.0-linux-riscv64.tar.gz
+029e0844931a2d3edc771d67e17fe17928f04f80c1a9aa165160a543e8a7e8d4  golangci-lint-1.49.0-linux-s390x.tar.gz
+e9cb6f691e62a4d8b28dd52d2eab57cca72acfd5083b3c5417a72d2eb64def09  golangci-lint-1.49.0-windows-386.zip
+d058dfb0c7fbd73be70f285d3f8d4d424192fe9b19760ddbb0b2c4b743b8656c  golangci-lint-1.49.0-windows-amd64.zip
+c049d80297228db7065eabeac5114f77f04415dcd9b944e8d7c6426d9dd6e9dd  golangci-lint-1.49.0-windows-arm64.zip
+ec9164bab7134ddb94f51c17fd37c109b0801ecd5494b6c0e27ca7898fbd7469  golangci-lint-1.49.0-windows-armv6.zip
+68fd9e880d98073f436c58b6f6d2c141881ef49b06ca31137bc19da4e4e3b996  golangci-lint-1.49.0-windows-armv7.zip
diff --git a/build/ci.go b/build/ci.go
index 24f225b72..4c8062eaf 100644
--- a/build/ci.go
+++ b/build/ci.go
@@ -25,17 +25,16 @@ Usage: go run build/ci.go <command> <command flags/arguments>
 Available commands are:
 
-   install    [ -arch architecture ] [ -cc compiler ] [ packages... ]                          -- builds packages and executables
-   test       [ -coverage ] [ packages... ]                                                    -- runs the tests
-   lint                                                                                        -- runs certain pre-selected linters
-   archive    [ -arch architecture ] [ -type zip|tar ] [ -signer key-envvar ] [ -signify key-envvar ] [ -upload dest ] -- archives build artifacts
-   importkeys                                                                                  -- imports signing keys from env
-   debsrc     [ -signer key-id ] [ -upload dest ]                                              -- creates a debian source package
-   nsis                                                                                        -- creates a Windows NSIS installer
-   aar        [ -local ] [ -sign key-id ] [-deploy repo] [ -upload dest ]                      -- creates an Android archive
-   xcode      [ -local ] [ -sign key-id ] [-deploy repo] [ -upload dest ]                      -- creates an iOS XCode framework
-   purge      [ -store blobstore ] [ -days threshold ]                                         -- purges old archives from the blobstore
+	install    [ -arch architecture ] [ -cc compiler ] [ packages... ]                          -- builds packages and executables
+	test       [ -coverage ] [ packages... ]                                                    -- runs the tests
+	lint                                                                                        -- runs certain pre-selected linters
+	archive    [ -arch architecture ] [ -type zip|tar ] [ -signer key-envvar ] [ -signify key-envvar ] [ -upload dest ] -- archives build artifacts
+	importkeys                                                                                  -- imports signing keys from env
+	debsrc     [ -signer key-id ] [ -upload dest ]                                              -- creates a debian source package
+	nsis                                                                                        -- creates a Windows NSIS installer
+	aar        [ -local ] [ -sign key-id ] [-deploy repo] [ -upload dest ]                      -- creates an Android archive
+	xcode      [ -local ] [ -sign key-id ] [-deploy repo] [ -upload dest ]                      -- creates an iOS XCode framework
+	purge      [ -store blobstore ] [ -days threshold ]                                         -- purges old archives from the blobstore
 
 For all commands, -n prevents execution of external programs (dry run mode).
-
 */
 package main
@@ -150,5 +149,5 @@ var (
 	//
 	//     go run ci.go install -dlgo
-	dlgoVersion = ""1.18.5""
+	dlgoVersion = ""1.19.1""
 )
 
@@ -348,5 +347,5 @@ func doLint(cmdline []string) {
 // downloadLinter downloads and unpacks golangci-lint.
 func downloadLinter(cachedir string) string {
-	const version = ""1.46.2""
+	const version = ""1.49.0""
 
 	csdb := build.MustLoadChecksums(""build/checksums.txt"")
diff --git a/cmd/evm/internal/t8ntool/transition.go b/cmd/evm/internal/t8ntool/transition.go
index 73a28e91c..e2d9cced2 100644
--- a/cmd/evm/internal/t8ntool/transition.go
+++ b/cmd/evm/internal/t8ntool/transition.go
@@ -335,6 +335,7 @@ func (t *txWithKey) UnmarshalJSON(input []byte) error {
 //
 // The transactions can have two forms, either
-//   1. unsigned or
-//   2. signed
+//  1. unsigned or
+//  2. signed
+//
 // For (1), r, s, v, need so be zero, and the `secretKey` needs to be set.
 // If so, we sign it here and now, with the given `secretKey`
diff --git a/cmd/p2psim/main.go b/cmd/p2psim/main.go
index 4edb0a9ab..8b3cb29b1 100644
--- a/cmd/p2psim/main.go
+++ b/cmd/p2psim/main.go
@@ -20,19 +20,18 @@
 // connected to the second:
 //
-//     $ p2psim node create
-//     Created node01
+//	$ p2psim node create
+//	Created node01
 //
-//     $ p2psim node start node01
-//     Started node01
+//	$ p2psim node start node01
+//	Started node01
 //
-//     $ p2psim node create
-//     Created node02
+//	$ p2psim node create
+//	Created node02
 //
-//     $ p2psim node start node02
-//     Started node02
-//
-//     $ p2psim node connect node01 node02
-//     Connected node01 to node02
+//	$ p2psim node start node02
+//	Started node02
 //
+//	$ p2psim node connect node01 node02
+//	Connected node01 to node02
 package main
 
diff --git a/common/hexutil/hexutil.go b/common/hexutil/hexutil.go
index e0241f5f2..d3201850a 100644
--- a/common/hexutil/hexutil.go
+++ b/common/hexutil/hexutil.go
@@ -19,5 +19,5 @@ Package hexutil implements hex encoding with 0x prefix.
 This encoding is used by the Ethereum RPC API to transport binary data in JSON payloads.
 
-Encoding Rules
+# Encoding Rules
 
 All hex data must have prefix ""0x"".
diff --git a/common/math/big.go b/common/math/big.go
index 1af5b4d87..48427810e 100644
--- a/common/math/big.go
+++ b/common/math/big.go
@@ -228,8 +228,8 @@ func U256Bytes(n *big.Int) []byte {
 // x must not exceed 256 bits (the result is undefined if it does) and is not modified.
 //
-//   S256(0)        = 0
-//   S256(1)        = 1
-//   S256(2**255)   = -2**255
-//   S256(2**256-1) = -1
+//	S256(0)        = 0
+//	S256(1)        = 1
+//	S256(2**255)   = -2**255
+//	S256(2**256-1) = -1
 func S256(x *big.Int) *big.Int {
 	if x.Cmp(tt255) < 0 {
diff --git a/common/prque/lazyqueue.go b/common/prque/lazyqueue.go
index 6fdb6cc1b..13ef3ed2c 100644
--- a/common/prque/lazyqueue.go
+++ b/common/prque/lazyqueue.go
@@ -27,7 +27,8 @@ import (
 // time and are only evaluated on demand.
 // Two callbacks are required:
-// - priority evaluates the actual priority of an item
-// - maxPriority gives an upper estimate for the priority in any moment between
-//   now and the given absolute time
+//   - priority evaluates the actual priority of an item
+//   - maxPriority gives an upper estimate for the priority in any moment between
+//     now and the given absolute time
+//
 // If the upper estimate is exceeded then Update should be called for that item.
 // A global Refresh function should also be called periodically.
diff --git a/consensus/beacon/consensus.go b/consensus/beacon/consensus.go
index 7e4d65741..6d108856e 100644
--- a/consensus/beacon/consensus.go
+++ b/consensus/beacon/consensus.go
@@ -225,8 +225,9 @@ func (beacon *Beacon) VerifyUncles(chain consensus.ChainReader, block *types.Blo
 // stock Ethereum consensus engine. The difference between the beacon and classic is
 // (a) The following fields are expected to be constants:
-//     - difficulty is expected to be 0
-// 	   - nonce is expected to be 0
-//     - unclehash is expected to be Hash(emptyHeader)
+//   - difficulty is expected to be 0
+//   - nonce is expected to be 0
+//   - unclehash is expected to be Hash(emptyHeader)
 //     to be the desired constants
+//
 // (b) we don't verify if a block is in the future anymore
 // (c) the extradata is limited to 32 bytes
diff --git a/consensus/ethash/api.go b/consensus/ethash/api.go
index f4d3802e0..da3b0751b 100644
--- a/consensus/ethash/api.go
+++ b/consensus/ethash/api.go
@@ -35,8 +35,9 @@ type API struct {
 //
 // The work package consists of 3 strings:
-//   result[0] - 32 bytes hex encoded current block header pow-hash
-//   result[1] - 32 bytes hex encoded seed hash used for DAG
-//   result[2] - 32 bytes hex encoded boundary condition (""target""), 2^256/difficulty
-//   result[3] - hex encoded block number
+//
+//	result[0] - 32 bytes hex encoded current block header pow-hash
+//	result[1] - 32 bytes hex encoded seed hash used for DAG
+//	result[2] - 32 bytes hex encoded boundary condition (""target""), 2^256/difficulty
+//	result[3] - hex encoded block number
 func (api *API) GetWork() ([4]string, error) {
 	if api.ethash.remote == nil {
diff --git a/consensus/ethash/sealer.go b/consensus/ethash/sealer.go
index 6fa60ef6a..ec4696390 100644
--- a/consensus/ethash/sealer.go
+++ b/consensus/ethash/sealer.go
@@ -340,8 +340,9 @@ func (s *remoteSealer) loop() {
 //
 // The work package consists of 3 strings:
-//   result[0], 32 bytes hex encoded current block header pow-hash
-//   result[1], 32 bytes hex encoded seed hash used for DAG
-//   result[2], 32 bytes hex encoded boundary condition (""target""), 2^256/difficulty
-//   result[3], hex encoded block number
+//
+//	result[0], 32 bytes hex encoded current block header pow-hash
+//	result[1], 32 bytes hex encoded seed hash used for DAG
+//	result[2], 32 bytes hex encoded boundary condition (""target""), 2^256/difficulty
+//	result[3], hex encoded block number
 func (s *remoteSealer) makeWork(block *types.Block) {
 	hash := s.ethash.SealHash(block.Header())
diff --git a/consensus/misc/dao.go b/consensus/misc/dao.go
index 36df036f2..96995616d 100644
--- a/consensus/misc/dao.go
+++ b/consensus/misc/dao.go
@@ -41,8 +41,9 @@ var (
 //
 // DAO hard-fork extension to the header validity:
-//   a) if the node is no-fork, do not accept blocks in the [fork, fork+10) range
-//      with the fork specific extra-data set
-//   b) if the node is pro-fork, require blocks in the specific range to have the
-//      unique extra-data set.
+//
+//   - if the node is no-fork, do not accept blocks in the [fork, fork+10) range
+//     with the fork specific extra-data set.
+//   - if the node is pro-fork, require blocks in the specific range to have the
+//     unique extra-data set.
 func VerifyDAOHeaderExtraData(config *params.ChainConfig, header *types.Header) error {
 	// Short circuit validation if the node doesn't care about the DAO fork
diff --git a/core/beacon/types.go b/core/beacon/types.go
index e25d724c0..e06ab5c69 100644
--- a/core/beacon/types.go
+++ b/core/beacon/types.go
@@ -137,7 +137,9 @@ func decodeTransactions(enc [][]byte) ([]*types.Transaction, error) {
 // ExecutableDataToBlock constructs a block from executable data.
 // It verifies that the following fields:
-// 		len(extraData) <= 32
-// 		uncleHash = emptyUncleHash
-// 		difficulty = 0
+//
+//	len(extraData) <= 32
+//	uncleHash = emptyUncleHash
+//	difficulty = 0
+//
 // and that the blockhash of the constructed block matches the parameters.
 func ExecutableDataToBlock(params ExecutableDataV1) (*types.Block, error) {
diff --git a/core/blockchain_test.go b/core/blockchain_test.go
index 06c43658e..08061bc24 100644
--- a/core/blockchain_test.go
+++ b/core/blockchain_test.go
@@ -1876,6 +1876,6 @@ func TestInsertReceiptChainRollback(t *testing.T) {
 //
 // Details at:
-//  - https://github.com/ethereum/go-ethereum/issues/18977
-//  - https://github.com/ethereum/go-ethereum/pull/18988
+//   - https://github.com/ethereum/go-ethereum/issues/18977
+//   - https://github.com/ethereum/go-ethereum/pull/18988
 func TestLowDiffLongChain(t *testing.T) {
 	// Generate a canonical chain to act as the main dataset
@@ -2024,12 +2024,14 @@ func testSideImport(t *testing.T, numCanonBlocksInSidechain, blocksBetweenCommon
 
 // Tests that importing a sidechain (S), where
-// - S is sidechain, containing blocks [Sn...Sm]
-// - C is canon chain, containing blocks [G..Cn..Cm]
-// - The common ancestor Cc is pruned
-// - The first block in S: Sn, is == Cn
+//   - S is sidechain, containing blocks [Sn...Sm]
+//   - C is canon chain, containing blocks [G..Cn..Cm]
+//   - The common ancestor Cc is pruned
+//   - The first block in S: Sn, is == Cn
+//
 // That is: the sidechain for import contains some blocks already present in canon chain.
-// So the blocks are
-// [ Cn, Cn+1, Cc, Sn+3 ... Sm]
-//   ^    ^    ^  pruned
+// So the blocks are:
+//
+//	[ Cn, Cn+1, Cc, Sn+3 ... Sm]
+//	^    ^    ^  pruned
 func TestPrunedImportSide(t *testing.T) {
 	//glogger := log.NewGlogHandler(log.StreamHandler(os.Stdout, log.TerminalFormat(false)))
@@ -2775,7 +2777,7 @@ func BenchmarkBlockChain_1x1000Executions(b *testing.B) {
 // ErrPrunedAncestor error.
 // This may e.g. happen if
-//   1. Downloader rollbacks a batch of inserted blocks and exits
-//   2. Downloader starts to sync again
-//   3. The blocks fetched are all known and canonical blocks
+//  1. Downloader rollbacks a batch of inserted blocks and exits
+//  2. Downloader starts to sync again
+//  3. The blocks fetched are all known and canonical blocks
 func TestSideImportPrunedBlocks(t *testing.T) {
 	// Generate a canonical chain to act as the main dataset
@@ -3270,12 +3272,12 @@ func TestDeleteRecreateSlotsAcrossManyBlocks(t *testing.T) {
 // TestInitThenFailCreateContract tests a pretty notorious case that happened
 // on mainnet over blocks 7338108, 7338110 and 7338115.
-// - Block 7338108: address e771789f5cccac282f23bb7add5690e1f6ca467c is initiated
-//   with 0.001 ether (thus created but no code)
-// - Block 7338110: a CREATE2 is attempted. The CREATE2 would deploy code on
-//   the same address e771789f5cccac282f23bb7add5690e1f6ca467c. However, the
-//   deployment fails due to OOG during initcode execution
-// - Block 7338115: another tx checks the balance of
-//   e771789f5cccac282f23bb7add5690e1f6ca467c, and the snapshotter returned it as
-//   zero.
+//   - Block 7338108: address e771789f5cccac282f23bb7add5690e1f6ca467c is initiated
+//     with 0.001 ether (thus created but no code)
+//   - Block 7338110: a CREATE2 is attempted. The CREATE2 would deploy code on
+//     the same address e771789f5cccac282f23bb7add5690e1f6ca467c. However, the
+//     deployment fails due to OOG during initcode execution
+//   - Block 7338115: another tx checks the balance of
+//     e771789f5cccac282f23bb7add5690e1f6ca467c, and the snapshotter returned it as
+//     zero.
 //
 // The problem being that the snapshotter maintains a destructset, and adds items
@@ -3283,5 +3285,4 @@ func TestDeleteRecreateSlotsAcrossManyBlocks(t *testing.T) {
 // We need to either roll back the snapDestructs, or not place it into snapDestructs
 // in the first place.
-//
 func TestInitThenFailCreateContract(t *testing.T) {
 	var (
@@ -3460,11 +3461,11 @@ func TestEIP2718Transition(t *testing.T) {
 // TestEIP1559Transition tests the following:
 //
-// 1. A transaction whose gasFeeCap is greater than the baseFee is valid.
-// 2. Gas accounting for access lists on EIP-1559 transactions is correct.
-// 3. Only the transaction's tip will be received by the coinbase.
-// 4. The transaction sender pays for both the tip and baseFee.
-// 5. The coinbase receives only the partially realized tip when
-//    gasFeeCap - gasTipCap < baseFee.
-// 6. Legacy transaction behave as expected (e.g. gasPrice = gasFeeCap = gasTipCap).
+//  1. A transaction whose gasFeeCap is greater than the baseFee is valid.
+//  2. Gas accounting for access lists on EIP-1559 transactions is correct.
+//  3. Only the transaction's tip will be received by the coinbase.
+//  4. The transaction sender pays for both the tip and baseFee.
+//  5. The coinbase receives only the partially realized tip when
+//     gasFeeCap - gasTipCap < baseFee.
+//  6. Legacy transaction behave as expected (e.g. gasPrice = gasFeeCap = gasTipCap).
 func TestEIP1559Transition(t *testing.T) {
 	var (
diff --git a/core/genesis.go b/core/genesis.go
index 5b5b9c72a..1c62bb1a1 100644
--- a/core/genesis.go
+++ b/core/genesis.go
@@ -240,8 +240,8 @@ type ChainOverrides struct {
 // The block that will be used is:
 //
-//                          genesis == nil       genesis != nil
-//                       +------------------------------------------
-//     db has no genesis |  main-net default  |  genesis
-//     db has genesis    |  from DB           |  genesis (if compatible)
+//	                     genesis == nil       genesis != nil
+//	                  +------------------------------------------
+//	db has no genesis |  main-net default  |  genesis
+//	db has genesis    |  from DB           |  genesis (if compatible)
 //
 // The stored chain configuration will be updated if it is compatible (i.e. does not
diff --git a/core/mkalloc.go b/core/mkalloc.go
index df167d708..e4c2ec0d8 100644
--- a/core/mkalloc.go
+++ b/core/mkalloc.go
@@ -19,10 +19,8 @@
 
 /*
+The mkalloc tool creates the genesis allocation constants in genesis_alloc.go
+It outputs a const declaration that contains an RLP-encoded list of (address, balance) tuples.
 
-   The mkalloc tool creates the genesis allocation constants in genesis_alloc.go
-   It outputs a const declaration that contains an RLP-encoded list of (address, balance) tuples.
-
-       go run mkalloc.go genesis.json
-
+	go run mkalloc.go genesis.json
 */
 package main
diff --git a/core/rawdb/freezer.go b/core/rawdb/freezer.go
index 6dea98c3d..53bd989a4 100644
--- a/core/rawdb/freezer.go
+++ b/core/rawdb/freezer.go
@@ -58,8 +58,8 @@ const freezerTableSize = 2 * 1000 * 1000 * 1000
 // data into flat files:
 //
-// - The append-only nature ensures that disk writes are minimized.
-// - The memory mapping ensures we can max out system memory for caching without
-//   reserving it for go-ethereum. This would also reduce the memory requirements
-//   of Geth, and thus also GC overhead.
+//   - The append-only nature ensures that disk writes are minimized.
+//   - The memory mapping ensures we can max out system memory for caching without
+//     reserving it for go-ethereum. This would also reduce the memory requirements
+//     of Geth, and thus also GC overhead.
 type Freezer struct {
 	// WARNING: The `frozen` and `tail` fields are accessed atomically. On 32 bit platforms, only
@@ -189,7 +189,7 @@ func (f *Freezer) Ancient(kind string, number uint64) ([]byte, error) {
 // AncientRange retrieves multiple items in sequence, starting from the index 'start'.
 // It will return
-//  - at most 'max' items,
-//  - at least 1 item (even if exceeding the maxByteSize), but will otherwise
-//   return as many items as fit into maxByteSize.
+//   - at most 'max' items,
+//   - at least 1 item (even if exceeding the maxByteSize), but will otherwise
+//     return as many items as fit into maxByteSize.
 func (f *Freezer) AncientRange(kind string, start, count, maxBytes uint64) ([][]byte, error) {
 	if table := f.tables[kind]; table != nil {
diff --git a/core/state/pruner/pruner.go b/core/state/pruner/pruner.go
index 2da2eda8b..87bc357a5 100644
--- a/core/state/pruner/pruner.go
+++ b/core/state/pruner/pruner.go
@@ -67,7 +67,7 @@ var (
 // help of the snapshot. The workflow of pruner is very simple:
 //
-// - iterate the snapshot, reconstruct the relevant state
-// - iterate the database, delete all other state entries which
-//   don't belong to the target state and the genesis state
+//   - iterate the snapshot, reconstruct the relevant state
+//   - iterate the database, delete all other state entries which
+//     don't belong to the target state and the genesis state
 //
 // It can take several hours(around 2 hours for mainnet) to finish
diff --git a/core/state/snapshot/generate_test.go b/core/state/snapshot/generate_test.go
index 447ca80ca..58cfb464f 100644
--- a/core/state/snapshot/generate_test.go
+++ b/core/state/snapshot/generate_test.go
@@ -221,8 +221,10 @@ func (t *testHelper) CommitAndGenerate() (common.Hash, *diskLayer) {
 //   - miss in the middle
 //   - miss in the end
+//
 // - the contract(non-empty storage) has wrong storage slots
 //   - wrong slots in the beginning
 //   - wrong slots in the middle
 //   - wrong slots in the end
+//
 // - the contract(non-empty storage) has extra storage slots
 //   - extra slots in the beginning
diff --git a/core/state/snapshot/snapshot.go b/core/state/snapshot/snapshot.go
index 76200851e..a6c77fbb9 100644
--- a/core/state/snapshot/snapshot.go
+++ b/core/state/snapshot/snapshot.go
@@ -180,8 +180,8 @@ type Tree struct {
 // a gap) or the journal is missing, there are two repair cases:
 //
-// - if the 'recovery' parameter is true, all memory diff-layers will be discarded.
-//   This case happens when the snapshot is 'ahead' of the state trie.
-// - otherwise, the entire snapshot is considered invalid and will be recreated on
-//   a background thread.
+//   - if the 'recovery' parameter is true, all memory diff-layers will be discarded.
+//     This case happens when the snapshot is 'ahead' of the state trie.
+//   - otherwise, the entire snapshot is considered invalid and will be recreated on
+//     a background thread.
 func New(diskdb ethdb.KeyValueStore, triedb *trie.Database, cache int, root common.Hash, async bool, rebuild bool, recovery bool) (*Tree, error) {
 	// Create a new, empty snapshot tree
diff --git a/core/state/statedb.go b/core/state/statedb.go
index a649e0bd1..b05f1742f 100644
--- a/core/state/statedb.go
+++ b/core/state/statedb.go
@@ -601,6 +601,6 @@ func (s *StateDB) createObject(addr common.Address) (newobj, prev *stateObject)
 // a contract does the following:
 //
-//   1. sends funds to sha(account ++ (nonce + 1))
-//   2. tx_create(sha(account ++ nonce)) (note that this gets the address of 1)
+//  1. sends funds to sha(account ++ (nonce + 1))
+//  2. tx_create(sha(account ++ nonce)) (note that this gets the address of 1)
 //
 // Carrying over the balance ensures that Ether doesn't disappear.
diff --git a/core/state_transition.go b/core/state_transition.go
index 0946c0372..4048c0250 100644
--- a/core/state_transition.go
+++ b/core/state_transition.go
@@ -32,21 +32,24 @@ import (
 var emptyCodeHash = crypto.Keccak256Hash(nil)
 
-/*
-The State Transitioning Model
-
-A state transition is a change made when a transaction is applied to the current world state
-The state transitioning model does all the necessary work to work out a valid new state root.
-
-1) Nonce handling
-2) Pre pay gas
-3) Create a new state object if the recipient is \0*32
-4) Value transfer
-== If contract creation ==
-  4a) Attempt to run transaction data
-  4b) If valid, use result as code for the new state object
-== end ==
-5) Run Script section
-6) Derive new state root
-*/
+// The State Transitioning Model
+//
+// A state transition is a change made when a transaction is applied to the current world
+// state. The state transitioning model does all the necessary work to work out a valid new
+// state root.
+//
+//  1. Nonce handling
+//  2. Pre pay gas
+//  3. Create a new state object if the recipient is \0*32
+//  4. Value transfer
+//
+// == If contract creation ==
+//
+//	4a. Attempt to run transaction data
+//	4b. If valid, use result as code for the new state object
+//
+// == end ==
+//
+//  5. Run Script section
+//  6. Derive new state root
 type StateTransition struct {
 	gp         *GasPool
@@ -263,11 +266,8 @@ func (st *StateTransition) preCheck() error {
 // returning the evm execution result with following fields.
 //
-// - used gas:
-//      total gas used (including gas being refunded)
-// - returndata:
-//      the returned data from evm
-// - concrete execution error:
-//      various **EVM** error which aborts the execution,
-//      e.g. ErrOutOfGas, ErrExecutionReverted
+//   - used gas: total gas used (including gas being refunded)
+//   - returndata: the returned data from evm
+//   - concrete execution error: various EVM errors which abort the execution, e.g.
+//     ErrOutOfGas, ErrExecutionReverted
 //
 // However if any consensus issue encountered, return the error directly with
diff --git a/core/vm/contracts.go b/core/vm/contracts.go
index 1b832b638..3a6b956eb 100644
--- a/core/vm/contracts.go
+++ b/core/vm/contracts.go
@@ -264,8 +264,8 @@ var (
 // modexpMultComplexity implements bigModexp multComplexity formula, as defined in EIP-198
 //
-// def mult_complexity(x):
-//    if x <= 64: return x ** 2
-//    elif x <= 1024: return x ** 2 // 4 + 96 * x - 3072
-//    else: return x ** 2 // 16 + 480 * x - 199680
+//	def mult_complexity(x):
+//		if x <= 64: return x ** 2
+//		elif x <= 1024: return x ** 2 // 4 + 96 * x - 3072
+//		else: return x ** 2 // 16 + 480 * x - 199680
 //
 // where is x is max(length_of_MODULUS, length_of_BASE)
diff --git a/core/vm/gas_table.go b/core/vm/gas_table.go
index 4c2cb3e5c..57fb1a8d9 100644
--- a/core/vm/gas_table.go
+++ b/core/vm/gas_table.go
@@ -118,18 +118,19 @@ func gasSStore(evm *EVM, contract *Contract, stack *Stack, mem *Memory, memorySi
 		}
 	}
+
 	// The new gas metering is based on net gas costs (EIP-1283):
 	//
-	// 1. If current value equals new value (this is a no-op), 200 gas is deducted.
-	// 2. If current value does not equal new value
-	//   2.1. If original value equals current value (this storage slot has not been changed by the current execution context)
-	//     2.1.1. If original value is 0, 20000 gas is deducted.
-	// 	   2.1.2. Otherwise, 5000 gas is deducted. If new value is 0, add 15000 gas to refund counter.
-	// 	2.2. If original value does not equal current value (this storage slot is dirty), 200 gas is deducted. Apply both of the following clauses.
-	// 	  2.2.1. If original value is not 0
-	//       2.2.1.1. If current value is 0 (also means that new value is not 0), remove 15000 gas from refund counter. We can prove that refund counter will never go below 0.
-	//       2.2.1.2. If new value is 0 (also means that current value is not 0), add 15000 gas to refund counter.
-	// 	  2.2.2. If original value equals new value (this storage slot is reset)
-	//       2.2.2.1. If original value is 0, add 19800 gas to refund counter.
-	// 	     2.2.2.2. Otherwise, add 4800 gas to refund counter.
+	// (1.) If current value equals new value (this is a no-op), 200 gas is deducted.
+	// (2.) If current value does not equal new value
+	//	(2.1.) If original value equals current value (this storage slot has not been changed by the current execution context)
+	//		(2.1.1.) If original value is 0, 20000 gas is deducted.
+	//		(2.1.2.) Otherwise, 5000 gas is deducted. If new value is 0, add 15000 gas to refund counter.
+	//	(2.2.) If original value does not equal current value (this storage slot is dirty), 200 gas is deducted. Apply both of the following clauses.
+	//		(2.2.1.) If original value is not 0
+	//			(2.2.1.1.) If current value is 0 (also means that new value is not 0), remove 15000 gas from refund counter. We can prove that refund counter will never go below 0.
+	//			(2.2.1.2.) If new value is 0 (also means that current value is not 0), add 15000 gas to refund counter.
+	//		(2.2.2.) If original value equals new value (this storage slot is reset)
+	//			(2.2.2.1.) If original value is 0, add 19800 gas to refund counter.
+	//			(2.2.2.2.) Otherwise, add 4800 gas to refund counter.
 	value := common.Hash(y.Bytes32())
 	if current == value { // noop (1)
@@ -163,17 +164,19 @@ func gasSStore(evm *EVM, contract *Contract, stack *Stack, mem *Memory, memorySi
 }
 
-// 0. If *gasleft* is less than or equal to 2300, fail the current call.
-// 1. If current value equals new value (this is a no-op), SLOAD_GAS is deducted.
-// 2. If current value does not equal new value:
-//   2.1. If original value equals current value (this storage slot has not been changed by the current execution context):
-//     2.1.1. If original value is 0, SSTORE_SET_GAS (20K) gas is deducted.
-//     2.1.2. Otherwise, SSTORE_RESET_GAS gas is deducted. If new value is 0, add SSTORE_CLEARS_SCHEDULE to refund counter.
-//   2.2. If original value does not equal current value (this storage slot is dirty), SLOAD_GAS gas is deducted. Apply both of the following clauses:
-//     2.2.1. If original value is not 0:
-//       2.2.1.1. If current value is 0 (also means that new value is not 0), subtract SSTORE_CLEARS_SCHEDULE gas from refund counter.
-//       2.2.1.2. If new value is 0 (also means that current value is not 0), add SSTORE_CLEARS_SCHEDULE gas to refund counter.
-//     2.2.2. If original value equals new value (this storage slot is reset):
-//       2.2.2.1. If original value is 0, add SSTORE_SET_GAS - SLOAD_GAS to refund counter.
-//       2.2.2.2. Otherwise, add SSTORE_RESET_GAS - SLOAD_GAS gas to refund counter.
+// Here come the EIP220 rules:
+//
+//	(0.) If *gasleft* is less than or equal to 2300, fail the current call.
+//	(1.) If current value equals new value (this is a no-op), SLOAD_GAS is deducted.
+//	(2.) If current value does not equal new value:
+//		(2.1.) If original value equals current value (this storage slot has not been changed by the current execution context):
+//			(2.1.1.) If original value is 0, SSTORE_SET_GAS (20K) gas is deducted.
+//			(2.1.2.) Otherwise, SSTORE_RESET_GAS gas is deducted. If new value is 0, add SSTORE_CLEARS_SCHEDULE to refund counter.
+//		(2.2.) If original value does not equal current value (this storage slot is dirty), SLOAD_GAS gas is deducted. Apply both of the following clauses:
+//			(2.2.1.) If original value is not 0:
+//				(2.2.1.1.) If current value is 0 (also means that new value is not 0), subtract SSTORE_CLEARS_SCHEDULE gas from refund counter.
+//				(2.2.1.2.) If new value is 0 (also means that current value is not 0), add SSTORE_CLEARS_SCHEDULE gas to refund counter.
+//			(2.2.2.) If original value equals new value (this storage slot is reset):
+//				(2.2.2.1.) If original value is 0, add SSTORE_SET_GAS - SLOAD_GAS to refund counter.
+//				(2.2.2.2.) Otherwise, add SSTORE_RESET_GAS - SLOAD_GAS gas to refund counter.
 func gasSStoreEIP2200(evm *EVM, contract *Contract, stack *Stack, mem *Memory, memorySize uint64) (uint64, error) {
 	// If we fail the minimum gas availability invariant, fail (0)
diff --git a/core/vm/instructions.go b/core/vm/instructions.go
index 92be3bf25..104bf6d75 100644
--- a/core/vm/instructions.go
+++ b/core/vm/instructions.go
@@ -393,27 +393,27 @@ func opExtCodeCopy(pc *uint64, interpreter *EVMInterpreter, scope *ScopeContext)
 // There are several cases when the function is called, while we can relay everything
 // to `state.GetCodeHash` function to ensure the correctness.
-//   (1) Caller tries to get the code hash of a normal contract account, state
-// should return the relative code hash and set it as the result.
 //
-//   (2) Caller tries to get the code hash of a non-existent account, state should
-// return common.Hash{} and zero will be set as the result.
+//  1. Caller tries to get the code hash of a normal contract account, state
+//     should return the relative code hash and set it as the result.
 //
-//   (3) Caller tries to get the code hash for an account without contract code,
-// state should return emptyCodeHash(0xc5d246...) as the result.
+//  2. Caller tries to get the code hash of a non-existent account, state should
+//     return common.Hash{} and zero will be set as the result.
 //
-//   (4) Caller tries to get the code hash of a precompiled account, the result
-// should be zero or emptyCodeHash.
+//  3. Caller tries to get the code hash for an account without contract code, state
+//     should return emptyCodeHash(0xc5d246...) as the result.
 //
-// It is worth noting that in order to avoid unnecessary create and clean,
-// all precompile accounts on mainnet have been transferred 1 wei, so the return
-// here should be emptyCodeHash.
-// If the precompile account is not transferred any amount on a private or
+//  4. Caller tries to get the code hash of a precompiled account, the result should be
+//     zero or emptyCodeHash.
+//
+// It is worth noting that in order to avoid unnecessary create and clean, all precompile
+// accounts on mainnet have been transferred 1 wei, so the return here should be
+// emptyCodeHash. If the precompile account is not transferred any amount on a private or
 // customized chain, the return value will be zero.
 //
-//   (5) Caller tries to get the code hash for an account which is marked as suicided
-// in the current transaction, the code hash of this account should be returned.
+//  5. Caller tries to get the code hash for an account which is marked as suicided
+//     in the current transaction, the code hash of this account should be returned.
 //
-//   (6) Caller tries to get the code hash for an account which is marked as deleted,
-// this account should be regarded as a non-existent account and zero should be returned.
+//  6. Caller tries to get the code hash for an account which is marked as deleted, this
+//     account should be regarded as a non-existent account and zero should be returned.
 func opExtCodeHash(pc *uint64, interpreter *EVMInterpreter, scope *ScopeContext) ([]byte, error) {
 	slot := scope.Stack.peek()
diff --git a/crypto/crypto.go b/crypto/crypto.go
index 45ea72747..e51b63bec 100644
--- a/crypto/crypto.go
+++ b/crypto/crypto.go
@@ -36,5 +36,5 @@ import (
 )
 
-//SignatureLength indicates the byte length required to carry a signature with recovery id.
+// SignatureLength indicates the byte length required to carry a signature with recovery id.
 const SignatureLength = 64 + 1 // 64 bytes ECDSA signature + 1 byte recovery id
 
diff --git a/crypto/secp256k1/curve.go b/crypto/secp256k1/curve.go
index fa1b199a3..9b26ab292 100644
--- a/crypto/secp256k1/curve.go
+++ b/crypto/secp256k1/curve.go
@@ -106,5 +106,4 @@ func (BitCurve *BitCurve) IsOnCurve(x, y *big.Int) bool {
 }
 
-//TODO: double check if the function is okay
 // affineFromJacobian reverses the Jacobian transform. See the comment at the
 // top of the file.
diff --git a/crypto/secp256k1/libsecp256k1/contrib/dummy.go b/crypto/secp256k1/libsecp256k1/contrib/dummy.go
index fda594be9..2c946210c 100644
--- a/crypto/secp256k1/libsecp256k1/contrib/dummy.go
+++ b/crypto/secp256k1/libsecp256k1/contrib/dummy.go
@@ -1,2 +1,3 @@
+//go:build dummy
 // +build dummy
 
diff --git a/crypto/secp256k1/libsecp256k1/dummy.go b/crypto/secp256k1/libsecp256k1/dummy.go
index 379b16992..04bbe3d76 100644
--- a/crypto/secp256k1/libsecp256k1/dummy.go
+++ b/crypto/secp256k1/libsecp256k1/dummy.go
@@ -1,2 +1,3 @@
+//go:build dummy
 // +build dummy
 
diff --git a/crypto/secp256k1/libsecp256k1/include/dummy.go b/crypto/secp256k1/libsecp256k1/include/dummy.go
index 5af540c73..64c71b845 100644
--- a/crypto/secp256k1/libsecp256k1/include/dummy.go
+++ b/crypto/secp256k1/libsecp256k1/include/dummy.go
@@ -1,2 +1,3 @@
+//go:build dummy
 // +build dummy
 
diff --git a/crypto/secp256k1/libsecp256k1/src/dummy.go b/crypto/secp256k1/libsecp256k1/src/dummy.go
index 65868f38a..2df270adc 100644
--- a/crypto/secp256k1/libsecp256k1/src/dummy.go
+++ b/crypto/secp256k1/libsecp256k1/src/dummy.go
@@ -1,2 +1,3 @@
+//go:build dummy
 // +build dummy
 
diff --git a/crypto/secp256k1/libsecp256k1/src/modules/dummy.go b/crypto/secp256k1/libsecp256k1/src/modules/dummy.go
index 3c7a69643..99c538db5 100644
--- a/crypto/secp256k1/libsecp256k1/src/modules/dummy.go
+++ b/crypto/secp256k1/libsecp256k1/src/modules/dummy.go
@@ -1,2 +1,3 @@
+//go:build dummy
 // +build dummy
 
diff --git a/crypto/secp256k1/libsecp256k1/src/modules/ecdh/dummy.go b/crypto/secp256k1/libsecp256k1/src/modules/ecdh/dummy.go
index b6fc38327..48c2e0aa5 100644
--- a/crypto/secp256k1/libsecp256k1/src/modules/ecdh/dummy.go
+++ b/crypto/secp256k1/libsecp256k1/src/modules/ecdh/dummy.go
@@ -1,2 +1,3 @@
+//go:build dummy
 // +build dummy
 
diff --git a/crypto/secp256k1/libsecp256k1/src/modules/recovery/dummy.go b/crypto/secp256k1/libsecp256k1/src/modules/recovery/dummy.go
index b9491f0cb..8efbd7abe 100644
--- a/crypto/secp256k1/libsecp256k1/src/modules/recovery/dummy.go
+++ b/crypto/secp256k1/libsecp256k1/src/modules/recovery/dummy.go
@@ -1,2 +1,3 @@
+//go:build dummy
 // +build dummy
 
diff --git a/eth/catalyst/api.go b/eth/catalyst/api.go
index 5ab61524a..754d8b214 100644
--- a/eth/catalyst/api.go
+++ b/eth/catalyst/api.go
@@ -143,13 +143,17 @@ func NewConsensusAPI(eth *eth.Ethereum) *ConsensusAPI {
 
 // ForkchoiceUpdatedV1 has several responsibilities:
-// If the method is called with an empty head block:
-// 		we return success, which can be used to check if the engine API is enabled
-// If the total difficulty was not reached:
-// 		we return INVALID
-// If the finalizedBlockHash is set:
-// 		we check if we have the finalizedBlockHash in our db, if not we start a sync
-// We try to set our blockchain to the headBlock
-// If there are payloadAttributes:
-// 		we try to assemble a block with the payloadAttributes and return its payloadID
+//
+// We try to set our blockchain to the headBlock.
+//
+// If the method is called with an empty head block: we return success, which can be used
+// to check if the engine API is enabled.
+//
+// If the total difficulty was not reached: we return INVALID.
+//
+// If the finalizedBlockHash is set: we check if we have the finalizedBlockHash in our db,
+// if not we start a sync.
+//
+// If there are payloadAttributes: we try to assemble a block with the payloadAttributes
+// and return its payloadID.
 func (api *ConsensusAPI) ForkchoiceUpdatedV1(update beacon.ForkchoiceStateV1, payloadAttributes *beacon.PayloadAttributesV1) (beacon.ForkChoiceResponse, error) {
 	api.forkchoiceLock.Lock()
diff --git a/eth/catalyst/api_test.go b/eth/catalyst/api_test.go
index 7e8f322df..ae53462ff 100644
--- a/eth/catalyst/api_test.go
+++ b/eth/catalyst/api_test.go
@@ -520,5 +520,5 @@ TestNewPayloadOnInvalidChain sets up a valid chain and tries to feed blocks
 from an invalid chain to test if latestValidHash (LVH) works correctly.
 
-We set up the following chain where P1 ... Pn and P1'' are valid while
+We set up the following chain where P1 ... Pn and P1 are valid while
 P1' is invalid.
 We expect
@@ -527,9 +527,9 @@ We expect
 (3) If the parent is unavailable, the LVH should not be set.
 
-CommonAncestor P1  P2   P3   ...  Pn
-				
-				 P1'  P2'  P3'  ...  Pn'
-				
-				 P1''
+	CommonAncestor P1  P2   P3   ...  Pn
+	                
+	                 P1'  P2'  P3'  ...  Pn'
+	                
+	                 P1''
 */
 func TestNewPayloadOnInvalidChain(t *testing.T) {
diff --git a/eth/downloader/downloader.go b/eth/downloader/downloader.go
index c04352f0a..af28d9e82 100644
--- a/eth/downloader/downloader.go
+++ b/eth/downloader/downloader.go
@@ -742,7 +742,9 @@ func (d *Downloader) fetchHead(p *peerConnection) (head *types.Header, pivot *ty
 // common ancestor.
 // It returns parameters to be used for peer.RequestHeadersByNumber:
-//  from - starting block number
-//  count - number of headers to request
-//  skip - number of headers to skip
+//
+//	from  - starting block number
+//	count - number of headers to request
+//	skip  - number of headers to skip
+//
 // and also returns 'max', the last block which is expected to be returned by the remote peers,
 // given the (from,count,skip)
diff --git a/eth/downloader/queue.go b/eth/downloader/queue.go
index a8d2ea83a..26c41711d 100644
--- a/eth/downloader/queue.go
+++ b/eth/downloader/queue.go
@@ -481,7 +481,8 @@ func (q *queue) ReserveReceipts(p *peerConnection, count int) (*fetchRequest, bo
 //
 // Returns:
-//   item     - the fetchRequest
-//   progress - whether any progress was made
-//   throttle - if the caller should throttle for a while
+//
+//	item     - the fetchRequest
+//	progress - whether any progress was made
+//	throttle - if the caller should throttle for a while
 func (q *queue) reserveHeaders(p *peerConnection, count int, taskPool map[common.Hash]*types.Header, taskQueue *prque.Prque,
 	pendPool map[string]*fetchRequest, kind uint) (*fetchRequest, bool, bool) {
diff --git a/eth/downloader/resultstore.go b/eth/downloader/resultstore.go
index 3162cd6d5..2dcbbe16c 100644
--- a/eth/downloader/resultstore.go
+++ b/eth/downloader/resultstore.go
@@ -72,8 +72,9 @@ func (r *resultStore) SetThrottleThreshold(threshold uint64) uint64 {
 //
 // It returns the following:
-//   stale     - if true, this item is already passed, and should not be requested again
-//   throttled - if true, the store is at capacity, this particular header is not prio now
-//   item      - the result to store data into
-//   err       - any error that occurred
+//
+//	stale     - if true, this item is already passed, and should not be requested again
+//	throttled - if true, the store is at capacity, this particular header is not prio now
+//	item      - the result to store data into
+//	err       - any error that occurred
 func (r *resultStore) AddFetch(header *types.Header, fastSync bool) (stale, throttled bool, item *fetchResult, err error) {
 	r.lock.Lock()
diff --git a/eth/gasprice/feehistory.go b/eth/gasprice/feehistory.go
index 91835c164..6028ef03c 100644
--- a/eth/gasprice/feehistory.go
+++ b/eth/gasprice/feehistory.go
@@ -209,8 +209,9 @@ func (oracle *Oracle) resolveBlockRange(ctx context.Context, reqEnd rpc.BlockNum
 // are not available or when the head has changed during processing this request.
 // Three arrays are returned based on the processed blocks:
-// - reward: the requested percentiles of effective priority fees per gas of transactions in each
-//   block, sorted in ascending order and weighted by gas used.
-// - baseFee: base fee per gas in the given block
-// - gasUsedRatio: gasUsed/gasLimit in the given block
+//   - reward: the requested percentiles of effective priority fees per gas of transactions in each
+//     block, sorted in ascending order and weighted by gas used.
+//   - baseFee: base fee per gas in the given block
+//   - gasUsedRatio: gasUsed/gasLimit in the given block
+//
 // Note: baseFee includes the next block after the newest of the returned range, because this
 // value can be derived from the newest block.
diff --git a/eth/protocols/snap/sync_test.go b/eth/protocols/snap/sync_test.go
index 4d9f631b5..451245706 100644
--- a/eth/protocols/snap/sync_test.go
+++ b/eth/protocols/snap/sync_test.go
@@ -369,6 +369,6 @@ func createStorageRequestResponse(t *testPeer, root common.Hash, accounts []comm
 }
 
-//  the createStorageRequestResponseAlwaysProve tests a cornercase, where it always
-// supplies the proof for the last account, even if it is 'complete'.h
+// createStorageRequestResponseAlwaysProve tests a cornercase, where the peer always
+// supplies the proof for the last account, even if it is 'complete'.
 func createStorageRequestResponseAlwaysProve(t *testPeer, root common.Hash, accounts []common.Hash, bOrigin, bLimit []byte, max uint64) (hashes [][]common.Hash, slots [][][]byte, proofs [][]byte) {
 	var size uint64
diff --git a/eth/state_accessor.go b/eth/state_accessor.go
index 4651ef306..ca59024ae 100644
--- a/eth/state_accessor.go
+++ b/eth/state_accessor.go
@@ -47,14 +47,14 @@ var noopReleaser = tracers.StateReleaseFunc(func() {})
 //
 // Parameters:
-// - block:      The block for which we want the state(state = block.Root)
-// - reexec:     The maximum number of blocks to reprocess trying to obtain the desired state
-// - base:       If the caller is tracing multiple blocks, the caller can provide the parent
-//               state continuously from the callsite.
-// - readOnly:   If true, then the live 'blockchain' state database is used. No mutation should
-//               be made from caller, e.g. perform Commit or other 'save-to-disk' changes.
-//               Otherwise, the trash generated by caller may be persisted permanently.
-// - preferDisk: this arg can be used by the caller to signal that even though the 'base' is
-//               provided, it would be preferable to start from a fresh state, if we have it
-//               on disk.
+//   - block:      The block for which we want the state(state = block.Root)
+//   - reexec:     The maximum number of blocks to reprocess trying to obtain the desired state
+//   - base:       If the caller is tracing multiple blocks, the caller can provide the parent
+//     state continuously from the callsite.
+//   - readOnly:   If true, then the live 'blockchain' state database is used. No mutation should
+//     be made from caller, e.g. perform Commit or other 'save-to-disk' changes.
+//     Otherwise, the trash generated by caller may be persisted permanently.
+//   - preferDisk: this arg can be used by the caller to signal that even though the 'base' is
+//     provided, it would be preferable to start from a fresh state, if we have it
+//     on disk.
 func (eth *Ethereum) StateAtBlock(block *types.Block, reexec uint64, base *state.StateDB, readOnly bool, preferDisk bool) (statedb *state.StateDB, release tracers.StateReleaseFunc, err error) {
 	var (
diff --git a/eth/tracers/native/4byte.go b/eth/tracers/native/4byte.go
index 34e608bfd..7fb1c5e6c 100644
--- a/eth/tracers/native/4byte.go
+++ b/eth/tracers/native/4byte.go
@@ -38,12 +38,13 @@ func init() {
 //
 // Example:
-//   > debug.traceTransaction( ""0x214e597e35da083692f5386141e69f47e973b2c56e7a8073b1ea08fd7571e9de"", {tracer: ""4byteTracer""})
-//   {
-//     0x27dc297e-128: 1,
-//     0x38cc4831-0: 2,
-//     0x524f3889-96: 1,
-//     0xadf59f99-288: 1,
-//     0xc281d19e-0: 1
-//   }
+//
+//	> debug.traceTransaction( ""0x214e597e35da083692f5386141e69f47e973b2c56e7a8073b1ea08fd7571e9de"", {tracer: ""4byteTracer""})
+//	{
+//	  0x27dc297e-128: 1,
+//	  0x38cc4831-0: 2,
+//	  0x524f3889-96: 1,
+//	  0xadf59f99-288: 1,
+//	  0xc281d19e-0: 1
+//	}
 type fourByteTracer struct {
 	env               *vm.EVM
diff --git a/eth/tracers/native/tracer.go b/eth/tracers/native/tracer.go
index 9587caf19..f70d4b2af 100644
--- a/eth/tracers/native/tracer.go
+++ b/eth/tracers/native/tracer.go
@@ -15,22 +15,18 @@
 // along with the go-ethereum library. If not, see <http://www.gnu.org/licenses/>.
 
-/*
-Package native is a collection of tracers written in go.
-
-In order to add a native tracer and have it compiled into the binary, a new
-file needs to be added to this folder, containing an implementation of the
-`eth.tracers.Tracer` interface.
-
-Aside from implementing the tracer, it also needs to register itself, using the
-`register` method -- and this needs to be done in the package initialization.
-
-Example:
-
-```golang
-func init() {
-	register(""noopTracerNative"", newNoopTracer)
-}
-```
-*/
+// Package native is a collection of tracers written in go.
+//
+// In order to add a native tracer and have it compiled into the binary, a new
+// file needs to be added to this folder, containing an implementation of the
+// `eth.tracers.Tracer` interface.
+//
+// Aside from implementing the tracer, it also needs to register itself, using the
+// `register` method -- and this needs to be done in the package initialization.
+//
+// Example:
+//
+//	func init() {
+//		register(""noopTracerNative"", newNoopTracer)
+//	}
 package native
 
diff --git a/ethdb/leveldb/leveldb.go b/ethdb/leveldb/leveldb.go
index 15bd4e6eb..046753172 100644
--- a/ethdb/leveldb/leveldb.go
+++ b/ethdb/leveldb/leveldb.go
@@ -267,11 +267,12 @@ func (db *Database) Path() string {
 //
 // This is how a LevelDB stats table looks like (currently):
-//   Compactions
-//    Level |   Tables   |    Size(MB)   |    Time(sec)  |    Read(MB)   |   Write(MB)
-//   -------+------------+---------------+---------------+---------------+---------------
-//      0   |          0 |       0.00000 |       1.27969 |       0.00000 |      12.31098
-//      1   |         85 |     109.27913 |      28.09293 |     213.92493 |     214.26294
-//      2   |        523 |    1000.37159 |       7.26059 |      66.86342 |      66.77884
-//      3   |        570 |    1113.18458 |       0.00000 |       0.00000 |       0.00000
+//
+//	Compactions
+//	 Level |   Tables   |    Size(MB)   |    Time(sec)  |    Read(MB)   |   Write(MB)
+//	-------+------------+---------------+---------------+---------------+---------------
+//	   0   |          0 |       0.00000 |       1.27969 |       0.00000 |      12.31098
+//	   1   |         85 |     109.27913 |      28.09293 |     213.92493 |     214.26294
+//	   2   |        523 |    1000.37159 |       7.26059 |      66.86342 |      66.77884
+//	   3   |        570 |    1113.18458 |       0.00000 |       0.00000 |       0.00000
 //
 // This is how the write delay look like (currently):
diff --git a/ethstats/ethstats.go b/ethstats/ethstats.go
index 5d60efab2..f6ad36051 100644
--- a/ethstats/ethstats.go
+++ b/ethstats/ethstats.go
@@ -103,11 +103,15 @@ type Service struct {
 //
 // From Gorilla websocket docs:
-//   Connections support one concurrent reader and one concurrent writer.
-//   Applications are responsible for ensuring that no more than one goroutine calls the write methods
-//     - NextWriter, SetWriteDeadline, WriteMessage, WriteJSON, EnableWriteCompression, SetCompressionLevel
-//   concurrently and that no more than one goroutine calls the read methods
-//     - NextReader, SetReadDeadline, ReadMessage, ReadJSON, SetPongHandler, SetPingHandler
-//   concurrently.
-//   The Close and WriteControl methods can be called concurrently with all other methods.
+//
+// Connections support one concurrent reader and one concurrent writer. Applications are
+// responsible for ensuring that
+//   - no more than one goroutine calls the write methods
+//     NextWriter, SetWriteDeadline, WriteMessage, WriteJSON, EnableWriteCompression,
+//     SetCompressionLevel concurrently; and
+//   - that no more than one goroutine calls the
+//     read methods NextReader, SetReadDeadline, ReadMessage, ReadJSON, SetPongHandler,
+//     SetPingHandler concurrently.
+//
+// The Close and WriteControl methods can be called concurrently with all other methods.
 type connWrapper struct {
 	conn *websocket.Conn
diff --git a/internal/cmdtest/test_cmd.go b/internal/cmdtest/test_cmd.go
index b837c9c39..fd7a4a8b7 100644
--- a/internal/cmdtest/test_cmd.go
+++ b/internal/cmdtest/test_cmd.go
@@ -84,5 +84,5 @@ func (tt *TestCmd) Run(name string, args ...string) {
 // This method can also be called from an expect template, e.g.:
 //
-//     geth.expect(`Passphrase: {{.InputLine ""password""}}`)
+//	geth.expect(`Passphrase: {{.InputLine ""password""}}`)
 func (tt *TestCmd) InputLine(s string) string {
 	io.WriteString(tt.stdin, s+""\n"")
diff --git a/internal/ethapi/api.go b/internal/ethapi/api.go
index 89c95c507..ac2fab401 100644
--- a/internal/ethapi/api.go
+++ b/internal/ethapi/api.go
@@ -732,8 +732,8 @@ func (s *BlockChainAPI) GetHeaderByHash(ctx context.Context, hash common.Hash) m
 
 // GetBlockByNumber returns the requested canonical block.
-// * When blockNr is -1 the chain head is returned.
-// * When blockNr is -2 the pending chain head is returned.
-// * When fullTx is true all transactions in the block are returned, otherwise
-//   only the transaction hash is returned.
+//   - When blockNr is -1 the chain head is returned.
+//   - When blockNr is -2 the pending chain head is returned.
+//   - When fullTx is true all transactions in the block are returned, otherwise
+//     only the transaction hash is returned.
 func (s *BlockChainAPI) GetBlockByNumber(ctx context.Context, number rpc.BlockNumber, fullTx bool) (map[string]interface{}, error) {
 	block, err := s.b.BlockByNumber(ctx, number)
diff --git a/internal/flags/helpers.go b/internal/flags/helpers.go
index 4bcdc816f..de1d29ffd 100644
--- a/internal/flags/helpers.go
+++ b/internal/flags/helpers.go
@@ -55,9 +55,9 @@ var migrationApplied = map[*cli.Command]struct{}{}
 // Example:
 //
-//    geth account new --keystore /tmp/mykeystore --lightkdf
+//	geth account new --keystore /tmp/mykeystore --lightkdf
 //
 // is equivalent after calling this method with:
 //
-//    geth --keystore /tmp/mykeystore --lightkdf account new
+//	geth --keystore /tmp/mykeystore --lightkdf account new
 //
 // i.e. in the subcommand Action function of 'account new', ctx.Bool(""lightkdf)
diff --git a/les/api.go b/les/api.go
index dc8639381..76714baef 100644
--- a/les/api.go
+++ b/les/api.go
@@ -367,8 +367,9 @@ func NewLightAPI(backend *lesCommons) *LightAPI {
 //
 // The checkpoint package consists of 4 strings:
-//   result[0], hex encoded latest section index
-//   result[1], 32 bytes hex encoded latest section head hash
-//   result[2], 32 bytes hex encoded latest section canonical hash trie root hash
-//   result[3], 32 bytes hex encoded latest section bloom trie root hash
+//
+//	result[0], hex encoded latest section index
+//	result[1], 32 bytes hex encoded latest section head hash
+//	result[2], 32 bytes hex encoded latest section canonical hash trie root hash
+//	result[3], 32 bytes hex encoded latest section bloom trie root hash
 func (api *LightAPI) LatestCheckpoint() ([4]string, error) {
 	var res [4]string
@@ -385,7 +386,8 @@ func (api *LightAPI) LatestCheckpoint() ([4]string, error) {
 //
 // The checkpoint package consists of 3 strings:
-//   result[0], 32 bytes hex encoded latest section head hash
-//   result[1], 32 bytes hex encoded latest section canonical hash trie root hash
-//   result[2], 32 bytes hex encoded latest section bloom trie root hash
+//
+//	result[0], 32 bytes hex encoded latest section head hash
+//	result[1], 32 bytes hex encoded latest section canonical hash trie root hash
+//	result[2], 32 bytes hex encoded latest section bloom trie root hash
 func (api *LightAPI) GetCheckpoint(index uint64) ([3]string, error) {
 	var res [3]string
diff --git a/les/catalyst/api.go b/les/catalyst/api.go
index 983fc7bff..abd1c9a90 100644
--- a/les/catalyst/api.go
+++ b/les/catalyst/api.go
@@ -57,13 +57,17 @@ func NewConsensusAPI(les *les.LightEthereum) *ConsensusAPI {
 
 // ForkchoiceUpdatedV1 has several responsibilities:
-// If the method is called with an empty head block:
-// 		we return success, which can be used to check if the catalyst mode is enabled
-// If the total difficulty was not reached:
-// 		we return INVALID
-// If the finalizedBlockHash is set:
-// 		we check if we have the finalizedBlockHash in our db, if not we start a sync
-// We try to set our blockchain to the headBlock
-// If there are payloadAttributes:
-//      we return an error since block creation is not supported in les mode
+//
+// We try to set our blockchain to the headBlock.
+//
+// If the method is called with an empty head block: we return success, which can be used
+// to check if the catalyst mode is enabled.
+//
+// If the total difficulty was not reached: we return INVALID.
+//
+// If the finalizedBlockHash is set: we check if we have the finalizedBlockHash in our db,
+// if not we start a sync.
+//
+// If there are payloadAttributes: we return an error since block creation is not
+// supported in les mode.
 func (api *ConsensusAPI) ForkchoiceUpdatedV1(heads beacon.ForkchoiceStateV1, payloadAttributes *beacon.PayloadAttributesV1) (beacon.ForkChoiceResponse, error) {
 	if heads.HeadBlockHash == (common.Hash{}) {
diff --git a/les/downloader/downloader.go b/les/downloader/downloader.go
index 6352b1c21..740fdbdad 100644
--- a/les/downloader/downloader.go
+++ b/les/downloader/downloader.go
@@ -694,7 +694,9 @@ func (d *Downloader) fetchHead(p *peerConnection) (head *types.Header, pivot *ty
 // common ancestor.
 // It returns parameters to be used for peer.RequestHeadersByNumber:
-//  from - starting block number
-//  count - number of headers to request
-//  skip - number of headers to skip
+//
+//	from  - starting block number
+//	count - number of headers to request
+//	skip  - number of headers to skip
+//
 // and also returns 'max', the last block which is expected to be returned by the remote peers,
 // given the (from,count,skip)
@@ -1311,20 +1313,20 @@ func (d *Downloader) fetchReceipts(from uint64) error {
 //
 // The instrumentation parameters:
-//  - errCancel:   error type to return if the fetch operation is cancelled (mostly makes logging nicer)
-//  - deliveryCh:  channel from which to retrieve downloaded data packets (merged from all concurrent peers)
-//  - deliver:     processing callback to deliver data packets into type specific download queues (usually within `queue`)
-//  - wakeCh:      notification channel for waking the fetcher when new tasks are available (or sync completed)
-//  - expire:      task callback method to abort requests that took too long and return the faulty peers (traffic shaping)
-//  - pending:     task callback for the number of requests still needing download (detect completion/non-completability)
-//  - inFlight:    task callback for the number of in-progress requests (wait for all active downloads to finish)
-//  - throttle:    task callback to check if the processing queue is full and activate throttling (bound memory use)
-//  - reserve:     task callback to reserve new download tasks to a particular peer (also signals partial completions)
-//  - fetchHook:   tester callback to notify of new tasks being initiated (allows testing the scheduling logic)
-//  - fetch:       network callback to actually send a particular download request to a physical remote peer
-//  - cancel:      task callback to abort an in-flight download request and allow rescheduling it (in case of lost peer)
-//  - capacity:    network callback to retrieve the estimated type-specific bandwidth capacity of a peer (traffic shaping)
-//  - idle:        network callback to retrieve the currently (type specific) idle peers that can be assigned tasks
-//  - setIdle:     network callback to set a peer back to idle and update its estimated capacity (traffic shaping)
-//  - kind:        textual label of the type being downloaded to display in log messages
+//   - errCancel:   error type to return if the fetch operation is cancelled (mostly makes logging nicer)
+//   - deliveryCh:  channel from which to retrieve downloaded data packets (merged from all concurrent peers)
+//   - deliver:     processing callback to deliver data packets into type specific download queues (usually within `queue`)
+//   - wakeCh:      notification channel for waking the fetcher when new tasks are available (or sync completed)
+//   - expire:      task callback method to abort requests that took too long and return the faulty peers (traffic shaping)
+//   - pending:     task callback for the number of requests still needing download (detect completion/non-completability)
+//   - inFlight:    task callback for the number of in-progress requests (wait for all active downloads to finish)
+//   - throttle:    task callback to check if the processing queue is full and activate throttling (bound memory use)
+//   - reserve:     task callback to reserve new download tasks to a particular peer (also signals partial completions)
+//   - fetchHook:   tester callback to notify of new tasks being initiated (allows testing the scheduling logic)
+//   - fetch:       network callback to actually send a particular download request to a physical remote peer
+//   - cancel:      task callback to abort an in-flight download request and allow rescheduling it (in case of lost peer)
+//   - capacity:    network callback to retrieve the estimated type-specific bandwidth capacity of a peer (traffic shaping)
+//   - idle:        network callback to retrieve the currently (type specific) idle peers that can be assigned tasks
+//   - setIdle:     network callback to set a peer back to idle and update its estimated capacity (traffic shaping)
+//   - kind:        textual label of the type being downloaded to display in log messages
 func (d *Downloader) fetchParts(deliveryCh chan dataPack, deliver func(dataPack) (int, error), wakeCh chan bool,
 	expire func() map[string]int, pending func() int, inFlight func() bool, reserve func(*peerConnection, int) (*fetchRequest, bool, bool),
diff --git a/les/downloader/queue.go b/les/downloader/queue.go
index b165b6b5c..98ebff526 100644
--- a/les/downloader/queue.go
+++ b/les/downloader/queue.go
@@ -478,7 +478,8 @@ func (q *queue) ReserveReceipts(p *peerConnection, count int) (*fetchRequest, bo
 //
 // Returns:
-//   item     - the fetchRequest
-//   progress - whether any progress was made
-//   throttle - if the caller should throttle for a while
+//
+//	item     - the fetchRequest
+//	progress - whether any progress was made
+//	throttle - if the caller should throttle for a while
 func (q *queue) reserveHeaders(p *peerConnection, count int, taskPool map[common.Hash]*types.Header, taskQueue *prque.Prque,
 	pendPool map[string]*fetchRequest, kind uint) (*fetchRequest, bool, bool) {
diff --git a/les/downloader/resultstore.go b/les/downloader/resultstore.go
index 3162cd6d5..2dcbbe16c 100644
--- a/les/downloader/resultstore.go
+++ b/les/downloader/resultstore.go
@@ -72,8 +72,9 @@ func (r *resultStore) SetThrottleThreshold(threshold uint64) uint64 {
 //
 // It returns the following:
-//   stale     - if true, this item is already passed, and should not be requested again
-//   throttled - if true, the store is at capacity, this particular header is not prio now
-//   item      - the result to store data into
-//   err       - any error that occurred
+//
+//	stale     - if true, this item is already passed, and should not be requested again
+//	throttled - if true, the store is at capacity, this particular header is not prio now
+//	item      - the result to store data into
+//	err       - any error that occurred
 func (r *resultStore) AddFetch(header *types.Header, fastSync bool) (stale, throttled bool, item *fetchResult, err error) {
 	r.lock.Lock()
diff --git a/les/fetcher.go b/les/fetcher.go
index 6861eebcf..ef37d80cd 100644
--- a/les/fetcher.go
+++ b/les/fetcher.go
@@ -243,16 +243,18 @@ func (f *lightFetcher) forEachPeer(check func(id enode.ID, p *fetcherPeer) bool)
 
 // mainloop is the main event loop of the light fetcher, which is responsible for
-// - announcement maintenance(ulc)
-//   If we are running in ultra light client mode, then all announcements from
-//   the trusted servers are maintained. If the same announcements from trusted
-//   servers reach the threshold, then the relevant header is requested for retrieval.
 //
-// - block header retrieval
-//   Whenever we receive announce with higher td compared with local chain, the
-//   request will be made for header retrieval.
+//   - announcement maintenance(ulc)
 //
-// - re-sync trigger
-//   If the local chain lags too much, then the fetcher will enter ""synchronise""
-//   mode to retrieve missing headers in batch.
+//     If we are running in ultra light client mode, then all announcements from
+//     the trusted servers are maintained. If the same announcements from trusted
+//     servers reach the threshold, then the relevant header is requested for retrieval.
+//
+//   - block header retrieval
+//     Whenever we receive announce with higher td compared with local chain, the
+//     request will be made for header retrieval.
+//
+//   - re-sync trigger
+//     If the local chain lags too much, then the fetcher will enter ""synchronise""
+//     mode to retrieve missing headers in batch.
 func (f *lightFetcher) mainloop() {
 	defer f.wg.Done()
diff --git a/light/txpool.go b/light/txpool.go
index b3e1a62e1..0f24fe1bc 100644
--- a/light/txpool.go
+++ b/light/txpool.go
@@ -72,13 +72,14 @@ type TxPool struct {
 }
 
-// TxRelayBackend provides an interface to the mechanism that forwards transactions
-// to the ETH network. The implementations of the functions should be non-blocking.
+// TxRelayBackend provides an interface to the mechanism that forwards transactions to the
+// ETH network. The implementations of the functions should be non-blocking.
 //
-// Send instructs backend to forward new transactions
-// NewHead notifies backend about a new head after processed by the tx pool,
-//  including  mined and rolled back transactions since the last event
-// Discard notifies backend about transactions that should be discarded either
-//  because they have been replaced by a re-send or because they have been mined
-//  long ago and no rollback is expected
+// Send instructs backend to forward new transactions NewHead notifies backend about a new
+// head after processed by the tx pool, including mined and rolled back transactions since
+// the last event.
+//
+// Discard notifies backend about transactions that should be discarded either because
+// they have been replaced by a re-send or because they have been mined long ago and no
+// rollback is expected.
 type TxRelayBackend interface {
 	Send(txs types.Transactions)
diff --git a/log/doc.go b/log/doc.go
index 993743c0f..d2e15140e 100644
--- a/log/doc.go
+++ b/log/doc.go
@@ -8,25 +8,23 @@ any type that you like. The default output format is logfmt, but you may also ch
 JSON instead if that suits you. Here's how you log:
 
-    log.Info(""page accessed"", ""path"", r.URL.Path, ""user_id"", user.id)
+	log.Info(""page accessed"", ""path"", r.URL.Path, ""user_id"", user.id)
 
 This will output a line that looks like:
 
-     lvl=info t=2014-05-02T16:07:23-0700 msg=""page accessed"" path=/org/71/profile user_id=9
+	lvl=info t=2014-05-02T16:07:23-0700 msg=""page accessed"" path=/org/71/profile user_id=9
 
-Getting Started
+# Getting Started
 
 To get started, you'll want to import the library:
 
-    import log ""github.com/inconshreveable/log15""
-
+	import log ""github.com/inconshreveable/log15""
 
 Now you're ready to start logging:
 
-    func main() {
-        log.Info(""Program starting"", ""args"", os.Args())
-    }
-
+	func main() {
+	    log.Info(""Program starting"", ""args"", os.Args())
+	}
 
-Convention
+# Convention
 
 Because recording a human-meaningful message is common and good practice, the first argument to every
@@ -41,12 +39,11 @@ logging functions. You don't need to explicitly state keys/values, log15 underst
 in the variadic argument list:
 
-    log.Warn(""size out of bounds"", ""low"", lowBound, ""high"", highBound, ""val"", val)
+	log.Warn(""size out of bounds"", ""low"", lowBound, ""high"", highBound, ""val"", val)
 
 If you really do favor your type-safety, you may choose to pass a log.Ctx instead:
 
-    log.Warn(""size out of bounds"", log.Ctx{""low"": lowBound, ""high"": highBound, ""val"": val})
-
+	log.Warn(""size out of bounds"", log.Ctx{""low"": lowBound, ""high"": highBound, ""val"": val})
 
-Context loggers
+# Context loggers
 
 Frequently, you want to add context to a logger so that you can track actions associated with it. An http
@@ -54,23 +51,21 @@ request is a good example. You can easily create new loggers that have context t
 with each log line:
 
-    requestlogger := log.New(""path"", r.URL.Path)
+	requestlogger := log.New(""path"", r.URL.Path)
 
-    // later
-    requestlogger.Debug(""db txn commit"", ""duration"", txnTimer.Finish())
+	// later
+	requestlogger.Debug(""db txn commit"", ""duration"", txnTimer.Finish())
 
 This will output a log line that includes the path context that is attached to the logger:
 
-    lvl=dbug t=2014-05-02T16:07:23-0700 path=/repo/12/add_hook msg=""db txn commit"" duration=0.12
+	lvl=dbug t=2014-05-02T16:07:23-0700 path=/repo/12/add_hook msg=""db txn commit"" duration=0.12
 
-
-Handlers
+# Handlers
 
 The Handler interface defines where log lines are printed to and how they are formatted. Handler is a
 single interface that is inspired by net/http's handler interface:
 
-    type Handler interface {
-        Log(r *Record) error
-    }
-
+	type Handler interface {
+	    Log(r *Record) error
+	}
 
 Handlers can filter records, format them, or dispatch to multiple other Handlers.
@@ -80,5 +75,5 @@ easily composed to create flexible, custom logging structures.
 Here's an example handler that prints logfmt output to Stdout:
 
-    handler := log.StreamHandler(os.Stdout, log.LogfmtFormat())
+	handler := log.StreamHandler(os.Stdout, log.LogfmtFormat())
 
 Here's an example handler that defers to two other handlers. One handler only prints records
@@ -86,10 +81,10 @@ from the rpc package in logfmt to standard out. The other prints records at Erro
 or above in JSON formatted output to the file /var/log/service.json
 
-    handler := log.MultiHandler(
-        log.LvlFilterHandler(log.LvlError, log.Must.FileHandler(""/var/log/service.json"", log.JSONFormat())),
-        log.MatchFilterHandler(""pkg"", ""app/rpc"" log.StdoutHandler())
-    )
+	handler := log.MultiHandler(
+	    log.LvlFilterHandler(log.LvlError, log.Must.FileHandler(""/var/log/service.json"", log.JSONFormat())),
+	    log.MatchFilterHandler(""pkg"", ""app/rpc"" log.StdoutHandler())
+	)
 
-Logging File Names and Line Numbers
+# Logging File Names and Line Numbers
 
 This package implements three Handlers that add debugging information to the
@@ -98,23 +93,23 @@ an example that adds the source file and line number of each logging call to
 the context.
 
-    h := log.CallerFileHandler(log.StdoutHandler)
-    log.Root().SetHandler(h)
-    ...
-    log.Error(""open file"", ""err"", err)
+	h := log.CallerFileHandler(log.StdoutHandler)
+	log.Root().SetHandler(h)
+	...
+	log.Error(""open file"", ""err"", err)
 
 This will output a line that looks like:
 
-    lvl=eror t=2014-05-02T16:07:23-0700 msg=""open file"" err=""file not found"" caller=data.go:42
+	lvl=eror t=2014-05-02T16:07:23-0700 msg=""open file"" err=""file not found"" caller=data.go:42
 
 Here's an example that logs the call stack rather than just the call site.
 
-    h := log.CallerStackHandler(""%+v"", log.StdoutHandler)
-    log.Root().SetHandler(h)
-    ...
-    log.Error(""open file"", ""err"", err)
+	h := log.CallerStackHandler(""%+v"", log.StdoutHandler)
+	log.Root().SetHandler(h)
+	...
+	log.Error(""open file"", ""err"", err)
 
 This will output a line that looks like:
 
-    lvl=eror t=2014-05-02T16:07:23-0700 msg=""open file"" err=""file not found"" stack=""[pkg/data.go:42 pkg/cmd/main.go]""
+	lvl=eror t=2014-05-02T16:07:23-0700 msg=""open file"" err=""file not found"" stack=""[pkg/data.go:42 pkg/cmd/main.go]""
 
 The ""%+v"" format instructs the handler to include the path of the source file
@@ -122,5 +117,5 @@ relative to the compile time GOPATH. The github.com/go-stack/stack package
 documents the full list of formatting verbs and modifiers available.
 
-Custom Handlers
+# Custom Handlers
 
 The Handler interface is so simple that it's also trivial to write your own. Let's create an
@@ -130,22 +125,22 @@ to the primary. This might be useful when trying to log over a network socket, b
 fails you want to log those records to a file on disk.
 
-    type BackupHandler struct {
-        Primary Handler
-        Secondary Handler
-    }
+	type BackupHandler struct {
+	    Primary Handler
+	    Secondary Handler
+	}
 
-    func (h *BackupHandler) Log (r *Record) error {
-        err := h.Primary.Log(r)
-        if err != nil {
-            r.Ctx = append(ctx, ""primary_err"", err)
-            return h.Secondary.Log(r)
-        }
-        return nil
-    }
+	func (h *BackupHandler) Log (r *Record) error {
+	    err := h.Primary.Log(r)
+	    if err != nil {
+	        r.Ctx = append(ctx, ""primary_err"", err)
+	        return h.Secondary.Log(r)
+	    }
+	    return nil
+	}
 
 This pattern is so useful that a generic version that handles an arbitrary number of Handlers
 is included as part of this library called FailoverHandler.
 
-Logging Expensive Operations
+# Logging Expensive Operations
 
 Sometimes, you want to log values that are extremely expensive to compute, but you don't want to pay
@@ -156,14 +151,14 @@ lazily, just when it is about to be logged, so that it would not be evaluated if
 filters it out. Just wrap any function which takes no arguments with the log.Lazy type. For example:
 
-    func factorRSAKey() (factors []int) {
-        // return the factors of a very large number
-    }
+	func factorRSAKey() (factors []int) {
+	    // return the factors of a very large number
+	}
 
-    log.Debug(""factors"", log.Lazy{factorRSAKey})
+	log.Debug(""factors"", log.Lazy{factorRSAKey})
 
 If this message is not logged for any reason (like logging at the Error level), then
 factorRSAKey is never evaluated.
 
-Dynamic context values
+# Dynamic context values
 
 The same log.Lazy mechanism can be used to attach context to a logger which you want to be
@@ -171,15 +166,15 @@ evaluated when the message is logged, but not when the logger is created. For ex
 a game where you have Player objects:
 
-    type Player struct {
-        name string
-        alive bool
-        log.Logger
-    }
+	type Player struct {
+	    name string
+	    alive bool
+	    log.Logger
+	}
 
 You always want to log a player's name and whether they're alive or dead, so when you create the player
 object, you might do:
 
-    p := &Player{name: name, alive: true}
-    p.Logger = log.New(""name"", p.name, ""alive"", p.alive)
+	p := &Player{name: name, alive: true}
+	p.Logger = log.New(""name"", p.name, ""alive"", p.alive)
 
 Only now, even after a player has died, the logger will still report they are alive because the logging
@@ -188,9 +183,9 @@ of whether the player is alive or not to each log message, so that the log recor
 current state no matter when the log message is written:
 
-    p := &Player{name: name, alive: true}
-    isAlive := func() bool { return p.alive }
-    player.Logger = log.New(""name"", p.name, ""alive"", log.Lazy{isAlive})
+	p := &Player{name: name, alive: true}
+	isAlive := func() bool { return p.alive }
+	player.Logger = log.New(""name"", p.name, ""alive"", log.Lazy{isAlive})
 
-Terminal Format
+# Terminal Format
 
 If log15 detects that stdout is a terminal, it will configure the default
@@ -199,5 +194,5 @@ logs records nicely for your terminal, including color-coded output based
 on log level.
 
-Error Handling
+# Error Handling
 
 Becasuse log15 allows you to step around the type system, there are a few ways you can specify
@@ -217,5 +212,5 @@ syslog daemon is not responding. This allows the construction of useful handlers
 like the FailoverHandler.
 
-Library Use
+# Library Use
 
 log15 is intended to be useful for library authors as a way to provide configurable logging to
@@ -223,25 +218,25 @@ users of their library. Best practice for use in a library is to always disable
 by default and to provide a public Logger instance that consumers of your library can configure. Like so:
 
-    package yourlib
+	package yourlib
 
-    import ""github.com/inconshreveable/log15""
+	import ""github.com/inconshreveable/log15""
 
-    var Log = log.New()
+	var Log = log.New()
 
-    func init() {
-        Log.SetHandler(log.DiscardHandler())
-    }
+	func init() {
+	    Log.SetHandler(log.DiscardHandler())
+	}
 
 Users of your library may then enable it if they like:
 
-    import ""github.com/inconshreveable/log15""
-    import ""example.com/yourlib""
+	import ""github.com/inconshreveable/log15""
+	import ""example.com/yourlib""
 
-    func main() {
-        handler := // custom handler setup
-        yourlib.Log.SetHandler(handler)
-    }
+	func main() {
+	    handler := // custom handler setup
+	    yourlib.Log.SetHandler(handler)
+	}
 
-Best practices attaching logger context
+# Best practices attaching logger context
 
 The ability to attach context to a logger is a powerful one. Where should you do it and why?
@@ -249,20 +244,20 @@ I favor embedding a Logger directly into any persistent object in my application
 unique, tracing context keys to it. For instance, imagine I am writing a web browser:
 
-    type Tab struct {
-        url string
-        render *RenderingContext
-        // ...
+	type Tab struct {
+	    url string
+	    render *RenderingContext
+	    // ...
 
-        Logger
-    }
+	    Logger
+	}
 
-    func NewTab(url string) *Tab {
-        return &Tab {
-            // ...
-            url: url,
+	func NewTab(url string) *Tab {
+	    return &Tab {
+	        // ...
+	        url: url,
 
-            Logger: log.New(""url"", url),
-        }
-    }
+	        Logger: log.New(""url"", url),
+	    }
+	}
 
 When a new tab is created, I assign a logger to it with the url of
@@ -271,5 +266,5 @@ Now, whenever we perform any operation with the tab, we'll log with its
 embedded logger and it will include the tab title automatically:
 
-    tab.Debug(""moved position"", ""idx"", tab.idx)
+	tab.Debug(""moved position"", ""idx"", tab.idx)
 
 There's only one problem. What if the tab url changes? We could
@@ -286,18 +281,18 @@ They're just random hex identifiers to use for tracing. Back to our
 Tab example, we would prefer to set up our Logger like so:
 
-        import logext ""github.com/inconshreveable/log15/ext""
+	import logext ""github.com/inconshreveable/log15/ext""
 
-        t := &Tab {
-            // ...
-            url: url,
-        }
+	t := &Tab {
+	    // ...
+	    url: url,
+	}
 
-        t.Logger = log.New(""id"", logext.RandId(8), ""url"", log.Lazy{t.getUrl})
-        return t
+	t.Logger = log.New(""id"", logext.RandId(8), ""url"", log.Lazy{t.getUrl})
+	return t
 
 Now we'll have a unique traceable identifier even across loading new urls, but
 we'll still be able to see the tab's current url in the log messages.
 
-Must
+# Must
 
 For all Handler functions which can return an error, there is a version of that
@@ -305,8 +300,8 @@ function which will return no error but panics on failure. They are all availabl
 on the Must object. For example:
 
-    log.Must.FileHandler(""/path"", log.JSONFormat)
-    log.Must.NetHandler(""tcp"", "":1234"", log.JSONFormat)
+	log.Must.FileHandler(""/path"", log.JSONFormat)
+	log.Must.NetHandler(""tcp"", "":1234"", log.JSONFormat)
 
-Inspiration and Credit
+# Inspiration and Credit
 
 All of the following excellent projects inspired the design of this library:
@@ -326,8 +321,7 @@ github.com/spacemonkeygo/spacelog
 golang's stdlib, notably io and net/http
 
-The Name
+# The Name
 
 https://xkcd.com/927/
-
 */
 package log
diff --git a/log/format.go b/log/format.go
index baf8fddac..613dc33be 100644
--- a/log/format.go
+++ b/log/format.go
@@ -80,10 +80,9 @@ type TerminalStringer interface {
 // This format should only be used for interactive programs or while developing.
 //
-//     [LEVEL] [TIME] MESSAGE key=value key=value ...
+//	[LEVEL] [TIME] MESSAGE key=value key=value ...
 //
 // Example:
 //
-//     [DBUG] [May 16 20:58:45] remove route ns=haproxy addr=127.0.0.1:50002
-//
+//	[DBUG] [May 16 20:58:45] remove route ns=haproxy addr=127.0.0.1:50002
 func TerminalFormat(usecolor bool) Format {
 	return FormatFunc(func(r *Record) []byte {
@@ -150,5 +149,4 @@ func TerminalFormat(usecolor bool) Format {
 //
 // For more details see: http://godoc.org/github.com/kr/logfmt
-//
 func LogfmtFormat() Format {
 	return FormatFunc(func(r *Record) []byte {
diff --git a/log/handler.go b/log/handler.go
index 4b9515fa1..892cfcc3e 100644
--- a/log/handler.go
+++ b/log/handler.go
@@ -137,13 +137,12 @@ func CallerStackHandler(format string, h Handler) Handler {
 // to only log records where the 'err' key is not nil:
 //
-//    logger.SetHandler(FilterHandler(func(r *Record) bool {
-//        for i := 0; i < len(r.Ctx); i += 2 {
-//            if r.Ctx[i] == ""err"" {
-//                return r.Ctx[i+1] != nil
-//            }
-//        }
-//        return false
-//    }, h))
-//
+//	logger.SetHandler(FilterHandler(func(r *Record) bool {
+//	    for i := 0; i < len(r.Ctx); i += 2 {
+//	        if r.Ctx[i] == ""err"" {
+//	            return r.Ctx[i+1] != nil
+//	        }
+//	    }
+//	    return false
+//	}, h))
 func FilterHandler(fn func(r *Record) bool, h Handler) Handler {
 	return FuncHandler(func(r *Record) error {
@@ -160,6 +159,5 @@ func FilterHandler(fn func(r *Record) bool, h Handler) Handler {
 // from your ui package:
 //
-//    log.MatchFilterHandler(""pkg"", ""app/ui"", log.StdoutHandler)
-//
+//	log.MatchFilterHandler(""pkg"", ""app/ui"", log.StdoutHandler)
 func MatchFilterHandler(key string, value interface{}, h Handler) Handler {
 	return FilterHandler(func(r *Record) (pass bool) {
@@ -187,6 +185,5 @@ func MatchFilterHandler(key string, value interface{}, h Handler) Handler {
 // log Error/Crit records:
 //
-//     log.LvlFilterHandler(log.LvlError, log.StdoutHandler)
-//
+//	log.LvlFilterHandler(log.LvlError, log.StdoutHandler)
 func LvlFilterHandler(maxLvl Lvl, h Handler) Handler {
 	return FilterHandler(func(r *Record) (pass bool) {
@@ -200,8 +197,7 @@ func LvlFilterHandler(maxLvl Lvl, h Handler) Handler {
 // standard error:
 //
-//     log.MultiHandler(
-//         log.Must.FileHandler(""/var/log/app.log"", log.LogfmtFormat()),
-//         log.StderrHandler)
-//
+//	log.MultiHandler(
+//	    log.Must.FileHandler(""/var/log/app.log"", log.LogfmtFormat()),
+//	    log.StderrHandler)
 func MultiHandler(hs ...Handler) Handler {
 	return FuncHandler(func(r *Record) error {
@@ -221,8 +217,8 @@ func MultiHandler(hs ...Handler) Handler {
 // standard out if the file write fails:
 //
-//     log.FailoverHandler(
-//         log.Must.NetHandler(""tcp"", "":9090"", log.JSONFormat()),
-//         log.Must.FileHandler(""/var/log/app.log"", log.LogfmtFormat()),
-//         log.StdoutHandler)
+//	log.FailoverHandler(
+//	    log.Must.NetHandler(""tcp"", "":9090"", log.JSONFormat()),
+//	    log.Must.FileHandler(""/var/log/app.log"", log.LogfmtFormat()),
+//	    log.StdoutHandler)
 //
 // All writes that do not go to the first handler will add context with keys of
diff --git a/log/handler_glog.go b/log/handler_glog.go
index 9b1d4efaf..b5186d4b2 100644
--- a/log/handler_glog.go
+++ b/log/handler_glog.go
@@ -83,12 +83,12 @@ func (h *GlogHandler) Verbosity(level Lvl) {
 // For instance:
 //
-//  pattern=""gopher.go=3""
-//   sets the V level to 3 in all Go files named ""gopher.go""
+//	pattern=""gopher.go=3""
+//	 sets the V level to 3 in all Go files named ""gopher.go""
 //
-//  pattern=""foo=3""
-//   sets V to 3 in all files of any packages whose import path ends in ""foo""
+//	pattern=""foo=3""
+//	 sets V to 3 in all files of any packages whose import path ends in ""foo""
 //
-//  pattern=""foo/*=3""
-//   sets V to 3 in all files of any packages whose import path contains ""foo""
+//	pattern=""foo/*=3""
+//	 sets V to 3 in all files of any packages whose import path contains ""foo""
 func (h *GlogHandler) Vmodule(ruleset string) error {
 	var filter []pattern
diff --git a/metrics/influxdb/influxdbv2.go b/metrics/influxdb/influxdbv2.go
index c8eca4161..dc4c04fae 100644
--- a/metrics/influxdb/influxdbv2.go
+++ b/metrics/influxdb/influxdbv2.go
@@ -1,10 +1,2 @@
-//
-// The go-ethereum library is distributed in the hope that it will be useful,
-// but WITHOUT ANY WARRANTY; without even the implied warranty of
-// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
-// GNU Lesser General Public License for more details.
-//
-// You should have received a copy of the GNU Lesser General Public License
-// along with the go-ethereum library. If not, see <http://www.gnu.org/licenses/>.
 package influxdb
 
diff --git a/mobile/big.go b/mobile/big.go
index c08bcf93f..af5f9d891 100644
--- a/mobile/big.go
+++ b/mobile/big.go
@@ -78,5 +78,4 @@ func (bi *BigInt) SetInt64(x int64) {
 //	 0 if x == 0
 //	+1 if x >  0
-//
 func (bi *BigInt) Sign() int {
 	return bi.bigint.Sign()
diff --git a/mobile/discover.go b/mobile/discover.go
index 2c699f08b..0fbc86de2 100644
--- a/mobile/discover.go
+++ b/mobile/discover.go
@@ -39,6 +39,6 @@ type Enode struct {
 // For incomplete nodes, the designator must look like one of these
 //
-//    enode://<hex node id>
-//    <hex node id>
+//	enode://<hex node id>
+//	<hex node id>
 //
 // For complete nodes, the node ID is encoded in the username portion
@@ -53,5 +53,5 @@ type Enode struct {
 // and UDP discovery port 30301.
 //
-//    enode://<hex node id>@10.3.58.6:30303?discport=30301
+//	enode://<hex node id>@10.3.58.6:30303?discport=30301
 func NewEnode(rawurl string) (*Enode, error) {
 	node, err := enode.Parse(enode.ValidSchemes, rawurl)
diff --git a/mobile/doc.go b/mobile/doc.go
index 20131afc2..a4d4949ee 100644
--- a/mobile/doc.go
+++ b/mobile/doc.go
@@ -21,5 +21,5 @@
 // mobile platforms. Keep this in mind when using or extending this package!
 //
-// API limitations
+// # API limitations
 //
 // Since gomobile cannot bridge arbitrary types between Go and Android/iOS, the
diff --git a/node/doc.go b/node/doc.go
index b257f412f..4474e4366 100644
--- a/node/doc.go
+++ b/node/doc.go
@@ -22,23 +22,20 @@ resources to provide RPC APIs. Services can also offer devp2p protocols, which a
 up to the devp2p network when the node instance is started.
 
-
-Node Lifecycle
+# Node Lifecycle
 
 The Node object has a lifecycle consisting of three basic states, INITIALIZING, RUNNING
 and CLOSED.
 
-
-    
-         New()
-            
-            
-      INITIALIZING Start()
-                              
-                              
-        Close()             RUNNING
-                              
-                              
-         CLOSED Close()
-
+	
+	     New()
+	        
+	        
+	  INITIALIZING Start()
+	                          
+	                          
+	    Close()             RUNNING
+	                          
+	                          
+	     CLOSED Close()
 
 Creating a Node allocates basic resources such as the data directory and returns the node
@@ -59,6 +56,5 @@ objects and shuts down RPC and peer-to-peer networking.
 You must always call Close on Node, even if the node was not started.
 
-
-Resources Managed By Node
+# Resources Managed By Node
 
 All file-system resources used by a node instance are located in a directory called the
@@ -84,6 +80,5 @@ Node also creates the shared store of encrypted Ethereum account keys. Services
 the account manager through the service context.
 
-
-Sharing Data Directory Among Instances
+# Sharing Data Directory Among Instances
 
 Multiple node instances can share a single data directory if they have distinct instance
@@ -103,6 +98,5 @@ The account key store is shared among all node instances using the same data dir
 unless its location is changed through the KeyStoreDir configuration option.
 
-
-Data Directory Sharing Example
+# Data Directory Sharing Example
 
 In this example, two node instances named A and B are started with the same data
@@ -110,18 +104,18 @@ directory. Node instance A opens the database ""db"", node instance B opens the da
 ""db"" and ""db-2"". The following files will be created in the data directory:
 
-   data-directory/
-        A/
-            nodekey            -- devp2p node key of instance A
-            nodes/             -- devp2p discovery knowledge database of instance A
-            db/                -- LevelDB content for ""db""
-        A.ipc                  -- JSON-RPC UNIX domain socket endpoint of instance A
-        B/
-            nodekey            -- devp2p node key of node B
-            nodes/             -- devp2p discovery knowledge database of instance B
-            static-nodes.json  -- devp2p static node list of instance B
-            db/                -- LevelDB content for ""db""
-            db-2/              -- LevelDB content for ""db-2""
-        B.ipc                  -- JSON-RPC UNIX domain socket endpoint of instance B
-        keystore/              -- account key store, used by both instances
+	data-directory/
+		A/
+			nodekey            -- devp2p node key of instance A
+			nodes/             -- devp2p discovery knowledge database of instance A
+			db/                -- LevelDB content for ""db""
+		A.ipc                  -- JSON-RPC UNIX domain socket endpoint of instance A
+		B/
+			nodekey            -- devp2p node key of node B
+			nodes/             -- devp2p discovery knowledge database of instance B
+			static-nodes.json  -- devp2p static node list of instance B
+			db/                -- LevelDB content for ""db""
+			db-2/              -- LevelDB content for ""db-2""
+		B.ipc                  -- JSON-RPC UNIX domain socket endpoint of instance B
+		keystore/              -- account key store, used by both instances
 */
 package node
diff --git a/node/node_example_test.go b/node/node_example_test.go
index d54fe0306..e45ee49a2 100644
--- a/node/node_example_test.go
+++ b/node/node_example_test.go
@@ -28,6 +28,6 @@ import (
 //
 // The following methods are needed to implement a node.Lifecycle:
-//  - Start() error              - method invoked when the node is ready to start the service
-//  - Stop() error               - method invoked when the node terminates the service
+//   - Start() error              - method invoked when the node is ready to start the service
+//   - Stop() error               - method invoked when the node terminates the service
 type SampleLifecycle struct{}
 
diff --git a/p2p/dial.go b/p2p/dial.go
index 0d70e6f4a..02878fae4 100644
--- a/p2p/dial.go
+++ b/p2p/dial.go
@@ -85,11 +85,10 @@ var (
 // Two types of peer connections can be created:
 //
-//  - static dials are pre-configured connections. The dialer attempts
-//    keep these nodes connected at all times.
-//
-//  - dynamic dials are created from node discovery results. The dialer
-//    continuously reads candidate nodes from its input iterator and attempts
-//    to create peer connections to nodes arriving through the iterator.
+//   - static dials are pre-configured connections. The dialer attempts
+//     keep these nodes connected at all times.
 //
+//   - dynamic dials are created from node discovery results. The dialer
+//     continuously reads candidate nodes from its input iterator and attempts
+//     to create peer connections to nodes arriving through the iterator.
 type dialScheduler struct {
 	dialConfig
diff --git a/p2p/discover/v5wire/encoding_test.go b/p2p/discover/v5wire/encoding_test.go
index 18aa1db1a..14c9da8c5 100644
--- a/p2p/discover/v5wire/encoding_test.go
+++ b/p2p/discover/v5wire/encoding_test.go
@@ -39,6 +39,5 @@ import (
 // To regenerate discv5 test vectors, run
 //
-//     go test -run TestVectors -write-test-vectors
-//
+//	go test -run TestVectors -write-test-vectors
 var writeTestVectorsFlag = flag.Bool(""write-test-vectors"", false, ""Overwrite discv5 test vectors in testdata/"")
 
diff --git a/p2p/dnsdisc/tree.go b/p2p/dnsdisc/tree.go
index 7d11e07ef..a3f426e42 100644
--- a/p2p/dnsdisc/tree.go
+++ b/p2p/dnsdisc/tree.go
@@ -118,23 +118,23 @@ We want to keep the UDP size below 512 bytes. The UDP size is roughly:
 UDP length = 8 + UDP payload length ( 229 )
 UPD Payload length:
- - dns.id 2
- - dns.flags 2
- - dns.count.queries 2
- - dns.count.answers 2
- - dns.count.auth_rr 2
- - dns.count.add_rr 2
- - queries (query-size + 6)
- - answers :
- 	- dns.resp.name 2
- 	- dns.resp.type 2
- 	- dns.resp.class 2
- 	- dns.resp.ttl 4
- 	- dns.resp.len 2
- 	- dns.txt.length 1
- 	- dns.txt resp_data_size
-
-So the total size is roughly a fixed overhead of `39`, and the size of the
-query (domain name) and response.
-The query size is, for example, FVY6INQ6LZ33WLCHO3BPR3FH6Y.snap.mainnet.ethdisco.net (52)
+  - dns.id 2
+  - dns.flags 2
+  - dns.count.queries 2
+  - dns.count.answers 2
+  - dns.count.auth_rr 2
+  - dns.count.add_rr 2
+  - queries (query-size + 6)
+  - answers :
+  - dns.resp.name 2
+  - dns.resp.type 2
+  - dns.resp.class 2
+  - dns.resp.ttl 4
+  - dns.resp.len 2
+  - dns.txt.length 1
+  - dns.txt resp_data_size
+
+So the total size is roughly a fixed overhead of `39`, and the size of the query (domain
+name) and response. The query size is, for example,
+FVY6INQ6LZ33WLCHO3BPR3FH6Y.snap.mainnet.ethdisco.net (52)
 
 We also have some static data in the response, such as `enrtree-branch:`, and potentially
@@ -142,6 +142,6 @@ splitting the response up with `"" ""`, leaving us with a size of roughly `400` th
 to stay below.
 
-The number `370` is used to have some margin for extra overhead (for example, the dns query
-may be larger - more subdomains).
+The number `370` is used to have some margin for extra overhead (for example, the dns
+query may be larger - more subdomains).
 */
 const (
diff --git a/p2p/enode/urlv4.go b/p2p/enode/urlv4.go
index c44504910..0272eee98 100644
--- a/p2p/enode/urlv4.go
+++ b/p2p/enode/urlv4.go
@@ -55,6 +55,6 @@ func MustParseV4(rawurl string) *Node {
 // For incomplete nodes, the designator must look like one of these
 //
-//    enode://<hex node id>
-//    <hex node id>
+//	enode://<hex node id>
+//	<hex node id>
 //
 // For complete nodes, the node ID is encoded in the username portion
@@ -69,5 +69,5 @@ func MustParseV4(rawurl string) *Node {
 // and UDP discovery port 30301.
 //
-//    enode://<hex node id>@10.3.58.6:30303?discport=30301
+//	enode://<hex node id>@10.3.58.6:30303?discport=30301
 func ParseV4(rawurl string) (*Node, error) {
 	if m := incompleteNodeURL.FindStringSubmatch(rawurl); m != nil {
diff --git a/p2p/enr/enr.go b/p2p/enr/enr.go
index 15891813b..438c7b8a3 100644
--- a/p2p/enr/enr.go
+++ b/p2p/enr/enr.go
@@ -20,5 +20,5 @@
 // interface.
 //
-// Signature Handling
+// # Signature Handling
 //
 // Records must be signed before transmitting them to another node.
diff --git a/p2p/message.go b/p2p/message.go
index 7cbe0f1dc..24f21456d 100644
--- a/p2p/message.go
+++ b/p2p/message.go
@@ -108,10 +108,9 @@ func Send(w MsgWriter, msgcode uint64, data interface{}) error {
 // For a call such as:
 //
-//    SendItems(w, code, e1, e2, e3)
+//	SendItems(w, code, e1, e2, e3)
 //
 // the message payload will be an RLP list containing the items:
 //
-//    [e1, e2, e3]
-//
+//	[e1, e2, e3]
 func SendItems(w MsgWriter, msgcode uint64, elems ...interface{}) error {
 	return Send(w, msgcode, elems)
diff --git a/p2p/nat/nat.go b/p2p/nat/nat.go
index 9d5519b9c..b7c840bc5 100644
--- a/p2p/nat/nat.go
+++ b/p2p/nat/nat.go
@@ -54,10 +54,10 @@ type Interface interface {
 // Note that mechanism names are not case-sensitive.
 //
-//     """" or ""none""         return nil
-//     ""extip:77.12.33.4""   will assume the local machine is reachable on the given IP
-//     ""any""                uses the first auto-detected mechanism
-//     ""upnp""               uses the Universal Plug and Play protocol
-//     ""pmp""                uses NAT-PMP with an auto-detected gateway address
-//     ""pmp:192.168.0.1""    uses NAT-PMP with the given gateway address
+//	"""" or ""none""         return nil
+//	""extip:77.12.33.4""   will assume the local machine is reachable on the given IP
+//	""any""                uses the first auto-detected mechanism
+//	""upnp""               uses the Universal Plug and Play protocol
+//	""pmp""                uses NAT-PMP with an auto-detected gateway address
+//	""pmp:192.168.0.1""    uses NAT-PMP with the given gateway address
 func Parse(spec string) (Interface, error) {
 	var (
diff --git a/p2p/simulations/adapters/types.go b/p2p/simulations/adapters/types.go
index aeb8ef777..3b4e05a90 100644
--- a/p2p/simulations/adapters/types.go
+++ b/p2p/simulations/adapters/types.go
@@ -40,8 +40,7 @@ import (
 // NodeAdapter, for example:
 //
-// * SimNode    - An in-memory node
-// * ExecNode   - A child process node
-// * DockerNode - A Docker container node
-//
+//   - SimNode, an in-memory node in the same process
+//   - ExecNode, a child process node
+//   - DockerNode, a node running in a Docker container
 type Node interface {
 	// Addr returns the node's address (e.g. an Enode URL)
diff --git a/p2p/simulations/mocker.go b/p2p/simulations/mocker.go
index 5a74b02c4..47193d83c 100644
--- a/p2p/simulations/mocker.go
+++ b/p2p/simulations/mocker.go
@@ -30,5 +30,5 @@ import (
 )
 
-//a map of mocker names to its function
+// a map of mocker names to its function
 var mockerList = map[string]func(net *Network, quit chan struct{}, nodeCount int){
 	""startStop"":     startStop,
@@ -37,11 +37,11 @@ var mockerList = map[string]func(net *Network, quit chan struct{}, nodeCount int
 }
 
-//Lookup a mocker by its name, returns the mockerFn
+// Lookup a mocker by its name, returns the mockerFn
 func LookupMocker(mockerType string) func(net *Network, quit chan struct{}, nodeCount int) {
 	return mockerList[mockerType]
 }
 
-//Get a list of mockers (keys of the map)
-//Useful for frontend to build available mocker selection
+// Get a list of mockers (keys of the map)
+// Useful for frontend to build available mocker selection
 func GetMockerList() []string {
 	list := make([]string, 0, len(mockerList))
@@ -52,5 +52,5 @@ func GetMockerList() []string {
 }
 
-//The boot mockerFn only connects the node in a ring and doesn't do anything else
+// The boot mockerFn only connects the node in a ring and doesn't do anything else
 func boot(net *Network, quit chan struct{}, nodeCount int) {
 	_, err := connectNodesInRing(net, nodeCount)
@@ -60,5 +60,5 @@ func boot(net *Network, quit chan struct{}, nodeCount int) {
 }
 
-//The startStop mockerFn stops and starts nodes in a defined period (ticker)
+// The startStop mockerFn stops and starts nodes in a defined period (ticker)
 func startStop(net *Network, quit chan struct{}, nodeCount int) {
 	nodes, err := connectNodesInRing(net, nodeCount)
@@ -97,8 +97,8 @@ func startStop(net *Network, quit chan struct{}, nodeCount int) {
 }
 
-//The probabilistic mocker func has a more probabilistic pattern
-//(the implementation could probably be improved):
-//nodes are connected in a ring, then a varying number of random nodes is selected,
-//mocker then stops and starts them in random intervals, and continues the loop
+// The probabilistic mocker func has a more probabilistic pattern
+// (the implementation could probably be improved):
+// nodes are connected in a ring, then a varying number of random nodes is selected,
+// mocker then stops and starts them in random intervals, and continues the loop
 func probabilistic(net *Network, quit chan struct{}, nodeCount int) {
 	nodes, err := connectNodesInRing(net, nodeCount)
@@ -160,5 +160,5 @@ func probabilistic(net *Network, quit chan struct{}, nodeCount int) {
 }
 
-//connect nodeCount number of nodes in a ring
+// connect nodeCount number of nodes in a ring
 func connectNodesInRing(net *Network, nodeCount int) ([]enode.ID, error) {
 	ids := make([]enode.ID, nodeCount)
diff --git a/params/denomination.go b/params/denomination.go
index fb4da7f41..bcedd271e 100644
--- a/params/denomination.go
+++ b/params/denomination.go
@@ -20,6 +20,5 @@ package params
 // Example: To get the wei value of an amount in 'gwei', use
 //
-//    new(big.Int).Mul(value, big.NewInt(params.GWei))
-//
+//	new(big.Int).Mul(value, big.NewInt(params.GWei))
 const (
 	Wei   = 1
diff --git a/rlp/decode.go b/rlp/decode.go
index 9214dbfb3..c9b265241 100644
--- a/rlp/decode.go
+++ b/rlp/decode.go
@@ -77,5 +77,5 @@ type Decoder interface {
 // panics cause by huge value sizes. If you need an input limit, use
 //
-//     NewStream(r, limit).Decode(val)
+//	NewStream(r, limit).Decode(val)
 func Decode(r io.Reader, val interface{}) error {
 	stream := streamPool.Get().(*Stream)
diff --git a/rlp/doc.go b/rlp/doc.go
index e4404c978..eeeee9a43 100644
--- a/rlp/doc.go
+++ b/rlp/doc.go
@@ -28,6 +28,5 @@ RLP values are distinguished by a type tag. The type tag precedes the value in t
 stream and defines the size and kind of the bytes that follow.
 
-
-Encoding Rules
+# Encoding Rules
 
 Package rlp uses reflection and encodes RLP based on the Go type of the value.
@@ -59,6 +58,5 @@ An interface value encodes as the value contained in the interface.
 Floating point numbers, maps, channels and functions are not supported.
 
-
-Decoding Rules
+# Decoding Rules
 
 Decoding uses the following type-dependent rules:
@@ -94,19 +92,18 @@ or one (true).
 To decode into an interface value, one of these types is stored in the value:
 
-	  []interface{}, for RLP lists
-	  []byte, for RLP strings
+	[]interface{}, for RLP lists
+	[]byte, for RLP strings
 
 Non-empty interface types are not supported when decoding.
 Signed integers, floating point numbers, maps, channels and functions cannot be decoded into.
 
-
-Struct Tags
+# Struct Tags
 
 As with other encoding packages, the ""-"" tag ignores fields.
 
-    type StructWithIgnoredField struct{
-        Ignored uint `rlp:""-""`
-        Field   uint
-    }
+	type StructWithIgnoredField struct{
+	    Ignored uint `rlp:""-""`
+	    Field   uint
+	}
 
 Go struct values encode/decode as RLP lists. There are two ways of influencing the mapping
@@ -114,8 +111,8 @@ of fields to list elements. The ""tail"" tag, which may only be used on the last e
 struct field, allows slurping up any excess list elements into a slice.
 
-    type StructWithTail struct{
-        Field   uint
-        Tail    []string `rlp:""tail""`
-    }
+	type StructWithTail struct{
+	    Field   uint
+	    Tail    []string `rlp:""tail""`
+	}
 
 The ""optional"" tag says that the field may be omitted if it is zero-valued. If this tag is
@@ -129,9 +126,9 @@ list. For the example below, this means input lists of one, two, or three elemen
 accepted.
 
-   type StructWithOptionalFields struct{
-        Required  uint
-        Optional1 uint `rlp:""optional""`
-        Optional2 uint `rlp:""optional""`
-   }
+	type StructWithOptionalFields struct{
+	     Required  uint
+	     Optional1 uint `rlp:""optional""`
+	     Optional2 uint `rlp:""optional""`
+	}
 
 The ""nil"", ""nilList"" and ""nilString"" tags apply to pointer-typed fields only, and change
@@ -141,7 +138,7 @@ produce nil values. When the ""nil"" tag is set, input values of size zero decode
 pointer. This is especially useful for recursive types.
 
-    type StructWithNilField struct {
-        Field *[3]byte `rlp:""nil""`
-    }
+	type StructWithNilField struct {
+	    Field *[3]byte `rlp:""nil""`
+	}
 
 In the example above, Field allows two possible input sizes. For input 0xC180 (a list
diff --git a/rpc/doc.go b/rpc/doc.go
index e0a632467..7c87793dc 100644
--- a/rpc/doc.go
+++ b/rpc/doc.go
@@ -16,5 +16,4 @@
 
 /*
-
 Package rpc implements bi-directional JSON-RPC 2.0 on multiple transports.
 
@@ -24,14 +23,14 @@ them visible as 'services'. Exported methods that follow specific conventions ca
 called remotely. It also has support for the publish/subscribe pattern.
 
-RPC Methods
+# RPC Methods
 
 Methods that satisfy the following criteria are made available for remote access:
 
- - method must be exported
- - method returns 0, 1 (response or error) or 2 (response and error) values
+  - method must be exported
+  - method returns 0, 1 (response or error) or 2 (response and error) values
 
 An example method:
 
- func (s *CalcService) Add(a, b int) (int, error)
+	func (s *CalcService) Add(a, b int) (int, error)
 
 When the returned error isn't nil the returned integer is ignored and the error is sent
@@ -42,5 +41,5 @@ to do the addition in an optional finite field we can accept a mod argument as p
 value.
 
- func (s *CalcService) Add(a, b int, mod *int) (int, error)
+	func (s *CalcService) Add(a, b int, mod *int) (int, error)
 
 This RPC method can be called with 2 integers and a null value as third argument. In that
@@ -57,24 +56,24 @@ to the client out of order.
 An example server which uses the JSON codec:
 
- type CalculatorService struct {}
+	 type CalculatorService struct {}
 
- func (s *CalculatorService) Add(a, b int) int {
-	return a + b
- }
+	 func (s *CalculatorService) Add(a, b int) int {
+		return a + b
+	 }
 
- func (s *CalculatorService) Div(a, b int) (int, error) {
-	if b == 0 {
-		return 0, errors.New(""divide by zero"")
-	}
-	return a/b, nil
- }
+	 func (s *CalculatorService) Div(a, b int) (int, error) {
+		if b == 0 {
+			return 0, errors.New(""divide by zero"")
+		}
+		return a/b, nil
+	 }
 
- calculator := new(CalculatorService)
- server := NewServer()
- server.RegisterName(""calculator"", calculator)
- l, _ := net.ListenUnix(""unix"", &net.UnixAddr{Net: ""unix"", Name: ""/tmp/calculator.sock""})
- server.ServeListener(l)
+	 calculator := new(CalculatorService)
+	 server := NewServer()
+	 server.RegisterName(""calculator"", calculator)
+	 l, _ := net.ListenUnix(""unix"", &net.UnixAddr{Net: ""unix"", Name: ""/tmp/calculator.sock""})
+	 server.ServeListener(l)
 
-Subscriptions
+# Subscriptions
 
 The package also supports the publish subscribe pattern through the use of subscriptions.
@@ -82,13 +81,13 @@ A method that is considered eligible for notifications must satisfy the followin
 criteria:
 
- - method must be exported
- - first method argument type must be context.Context
- - method must have return types (rpc.Subscription, error)
+  - method must be exported
+  - first method argument type must be context.Context
+  - method must have return types (rpc.Subscription, error)
 
 An example method:
 
- func (s *BlockChainService) NewBlocks(ctx context.Context) (rpc.Subscription, error) {
- 	...
- }
+	func (s *BlockChainService) NewBlocks(ctx context.Context) (rpc.Subscription, error) {
+		...
+	}
 
 When the service containing the subscription method is registered to the server, for
@@ -102,5 +101,5 @@ the client and server. The server will close the connection for any write error.
 For more information about subscriptions, see https://github.com/ethereum/go-ethereum/wiki/RPC-PUB-SUB.
 
-Reverse Calls
+# Reverse Calls
 
 In any method handler, an instance of rpc.Client can be accessed through the
diff --git a/rpc/handler.go b/rpc/handler.go
index 22ad98149..f3052e7eb 100644
--- a/rpc/handler.go
+++ b/rpc/handler.go
@@ -35,18 +35,18 @@ import (
 // The entry points for incoming messages are:
 //
-//    h.handleMsg(message)
-//    h.handleBatch(message)
+//	h.handleMsg(message)
+//	h.handleBatch(message)
 //
 // Outgoing calls use the requestOp struct. Register the request before sending it
 // on the connection:
 //
-//    op := &requestOp{ids: ...}
-//    h.addRequestOp(op)
+//	op := &requestOp{ids: ...}
+//	h.addRequestOp(op)
 //
 // Now send the request, then wait for the reply to be delivered through handleMsg:
 //
-//    if err := op.wait(...); err != nil {
-//        h.removeRequestOp(op) // timeout, etc.
-//    }
+//	if err := op.wait(...); err != nil {
+//		h.removeRequestOp(op) // timeout, etc.
+//	}
 type handler struct {
 	reg            *serviceRegistry
diff --git a/signer/core/api_test.go b/signer/core/api_test.go
index 6fa2af183..9bb55bddc 100644
--- a/signer/core/api_test.go
+++ b/signer/core/api_test.go
@@ -40,5 +40,5 @@ import (
 )
 
-//Used for testing
+// Used for testing
 type headlessUi struct {
 	approveCh chan string // to send approve/deny
diff --git a/signer/core/apitypes/types.go b/signer/core/apitypes/types.go
index 0652108f8..2c8907ac8 100644
--- a/signer/core/apitypes/types.go
+++ b/signer/core/apitypes/types.go
@@ -65,5 +65,5 @@ func (vs *ValidationMessages) Info(msg string) {
 }
 
-/// getWarnings returns an error with all messages of type WARN of above, or nil if no warnings were present
+// getWarnings returns an error with all messages of type WARN of above, or nil if no warnings were present
 func (v *ValidationMessages) GetWarnings() error {
 	var messages []string
diff --git a/tests/block_test_util.go b/tests/block_test_util.go
index 80f93d7c0..313a703fa 100644
--- a/tests/block_test_util.go
+++ b/tests/block_test_util.go
@@ -176,15 +176,16 @@ func (t *BlockTest) genesis(config *params.ChainConfig) *core.Genesis {
 }
 
-/* See https://github.com/ethereum/tests/wiki/Blockchain-Tests-II
+/*
+See https://github.com/ethereum/tests/wiki/Blockchain-Tests-II
 
-   Whether a block is valid or not is a bit subtle, it's defined by presence of
-   blockHeader, transactions and uncleHeaders fields. If they are missing, the block is
-   invalid and we must verify that we do not accept it.
+	Whether a block is valid or not is a bit subtle, it's defined by presence of
+	blockHeader, transactions and uncleHeaders fields. If they are missing, the block is
+	invalid and we must verify that we do not accept it.
 
-   Since some tests mix valid and invalid blocks we need to check this for every block.
+	Since some tests mix valid and invalid blocks we need to check this for every block.
 
-   If a block is invalid it does not necessarily fail the test, if it's invalidness is
-   expected we are expected to ignore it and continue processing and then validate the
-   post state.
+	If a block is invalid it does not necessarily fail the test, if it's invalidness is
+	expected we are expected to ignore it and continue processing and then validate the
+	post state.
 */
 func (t *BlockTest) insertBlocks(blockchain *core.BlockChain) ([]btBlock, error) {
diff --git a/tests/fuzzers/bls12381/precompile_fuzzer.go b/tests/fuzzers/bls12381/precompile_fuzzer.go
index bc3c45652..cab2bcba3 100644
--- a/tests/fuzzers/bls12381/precompile_fuzzer.go
+++ b/tests/fuzzers/bls12381/precompile_fuzzer.go
@@ -71,10 +71,12 @@ func checkInput(id byte, inputLen int) bool {
 }
 
-// The fuzzer functions must return
-// 1 if the fuzzer should increase priority of the
-//    given input during subsequent fuzzing (for example, the input is lexically
-//    correct and was parsed successfully);
-// -1 if the input must not be added to corpus even if gives new coverage; and
-// 0  otherwise
+// The function must return
+//
+//   - 1 if the fuzzer should increase priority of the
+//     given input during subsequent fuzzing (for example, the input is lexically
+//     correct and was parsed successfully);
+//   - -1 if the input must not be added to corpus even if gives new coverage; and
+//   - 0 otherwise
+//
 // other values are reserved for future use.
 func fuzz(id byte, data []byte) int {
diff --git a/tests/fuzzers/difficulty/difficulty-fuzz.go b/tests/fuzzers/difficulty/difficulty-fuzz.go
index 2112abac1..5612a4e70 100644
--- a/tests/fuzzers/difficulty/difficulty-fuzz.go
+++ b/tests/fuzzers/difficulty/difficulty-fuzz.go
@@ -68,9 +68,11 @@ func (f *fuzzer) readBool() bool {
 
 // The function must return
-// 1 if the fuzzer should increase priority of the
-//    given input during subsequent fuzzing (for example, the input is lexically
-//    correct and was parsed successfully);
-// -1 if the input must not be added to corpus even if gives new coverage; and
-// 0  otherwise
+//
+//   - 1 if the fuzzer should increase priority of the
+//     given input during subsequent fuzzing (for example, the input is lexically
+//     correct and was parsed successfully);
+//   - -1 if the input must not be added to corpus even if gives new coverage; and
+//   - 0 otherwise
+//
 // other values are reserved for future use.
 func Fuzz(data []byte) int {
diff --git a/tests/fuzzers/rangeproof/rangeproof-fuzzer.go b/tests/fuzzers/rangeproof/rangeproof-fuzzer.go
index c2db919d5..16242a66e 100644
--- a/tests/fuzzers/rangeproof/rangeproof-fuzzer.go
+++ b/tests/fuzzers/rangeproof/rangeproof-fuzzer.go
@@ -181,9 +181,12 @@ func (f *fuzzer) fuzz() int {
 
 // The function must return
-// 1 if the fuzzer should increase priority of the
-//   given input during subsequent fuzzing (for example, the input is lexically
-//   correct and was parsed successfully);
-// -1 if the input must not be added to corpus even if gives new coverage; and
-// 0 otherwise; other values are reserved for future use.
+//
+//   - 1 if the fuzzer should increase priority of the
+//     given input during subsequent fuzzing (for example, the input is lexically
+//     correct and was parsed successfully);
+//   - -1 if the input must not be added to corpus even if gives new coverage; and
+//   - 0 otherwise
+//
+// other values are reserved for future use.
 func Fuzz(input []byte) int {
 	if len(input) < 100 {
diff --git a/tests/fuzzers/stacktrie/trie_fuzzer.go b/tests/fuzzers/stacktrie/trie_fuzzer.go
index e6165df08..95a1fc464 100644
--- a/tests/fuzzers/stacktrie/trie_fuzzer.go
+++ b/tests/fuzzers/stacktrie/trie_fuzzer.go
@@ -115,9 +115,11 @@ func (k kvs) Swap(i, j int) {
 
 // The function must return
-// 1 if the fuzzer should increase priority of the
-//    given input during subsequent fuzzing (for example, the input is lexically
-//    correct and was parsed successfully);
-// -1 if the input must not be added to corpus even if gives new coverage; and
-// 0  otherwise
+//
+//   - 1 if the fuzzer should increase priority of the
+//     given input during subsequent fuzzing (for example, the input is lexically
+//     correct and was parsed successfully);
+//   - -1 if the input must not be added to corpus even if gives new coverage; and
+//   - 0 otherwise
+//
 // other values are reserved for future use.
 func Fuzz(data []byte) int {
diff --git a/tests/fuzzers/trie/trie-fuzzer.go b/tests/fuzzers/trie/trie-fuzzer.go
index f36b613d4..25e137602 100644
--- a/tests/fuzzers/trie/trie-fuzzer.go
+++ b/tests/fuzzers/trie/trie-fuzzer.go
@@ -120,9 +120,11 @@ func Generate(input []byte) randTest {
 
 // The function must return
-// 1 if the fuzzer should increase priority of the
-//    given input during subsequent fuzzing (for example, the input is lexically
-//    correct and was parsed successfully);
-// -1 if the input must not be added to corpus even if gives new coverage; and
-// 0  otherwise
+//
+//   - 1 if the fuzzer should increase priority of the
+//     given input during subsequent fuzzing (for example, the input is lexically
+//     correct and was parsed successfully);
+//   - -1 if the input must not be added to corpus even if gives new coverage; and
+//   - 0 otherwise
+//
 // other values are reserved for future use.
 func Fuzz(input []byte) int {
diff --git a/tests/init_test.go b/tests/init_test.go
index 4ef5aaf73..9d315f951 100644
--- a/tests/init_test.go
+++ b/tests/init_test.go
@@ -117,4 +117,5 @@ func (tm *testMatcher) skipLoad(pattern string) {
 
 // fails adds an expected failure for tests matching the pattern.
+//
 //nolint:unused
 func (tm *testMatcher) fails(pattern string, reason string) {
diff --git a/trie/hasher.go b/trie/hasher.go
index 183e96c22..e594d6d6b 100644
--- a/trie/hasher.go
+++ b/trie/hasher.go
@@ -171,6 +171,6 @@ func (h *hasher) fullnodeToHash(n *fullNode, force bool) node {
 // All node encoding must be done like this:
 //
-//     node.encode(h.encbuf)
-//     enc := h.encodedBytes()
+//	node.encode(h.encbuf)
+//	enc := h.encodedBytes()
 //
 // This convention exists because node.encode can only be inlined/escape-analyzed when
diff --git a/trie/proof.go b/trie/proof.go
index ef73aed2e..8c00bcf53 100644
--- a/trie/proof.go
+++ b/trie/proof.go
@@ -340,7 +340,7 @@ findFork:
 // It can meet these scenarios:
 //
-// - The given path is existent in the trie, unset the associated nodes with the
-//   specific direction
-// - The given path is non-existent in the trie
+//   - The given path is existent in the trie, unset the associated nodes with the
+//     specific direction
+//   - The given path is non-existent in the trie
 //   - the fork point is a fullnode, the corresponding child pointed by path
 //     is nil, return
@@ -459,13 +459,13 @@ func hasRightElement(node node, key []byte) bool {
 // range proofs:
 //
-// - All elements proof. In this case the proof can be nil, but the range should
-//   be all the leaves in the trie.
+//   - All elements proof. In this case the proof can be nil, but the range should
+//     be all the leaves in the trie.
 //
-// - One element proof. In this case no matter the edge proof is a non-existent
-//   proof or not, we can always verify the correctness of the proof.
+//   - One element proof. In this case no matter the edge proof is a non-existent
+//     proof or not, we can always verify the correctness of the proof.
 //
-// - Zero element proof. In this case a single non-existent proof is enough to prove.
-//   Besides, if there are still some other leaves available on the right side, then
-//   an error will be returned.
+//   - Zero element proof. In this case a single non-existent proof is enough to prove.
+//     Besides, if there are still some other leaves available on the right side, then
+//     an error will be returned.
 //
 // Except returning the error to indicate the proof is valid or not, the function will
diff --git a/trie/stacktrie.go b/trie/stacktrie.go
index cc50b817b..d37375d35 100644
--- a/trie/stacktrie.go
+++ b/trie/stacktrie.go
@@ -376,9 +376,10 @@ func (st *StackTrie) insert(key, value []byte) {
 //
 // 1. The rlp-encoded value was >= 32 bytes:
-//  - Then the 32-byte `hash` will be accessible in `st.val`.
-//  - And the 'st.type' will be 'hashedNode'
+//   - Then the 32-byte `hash` will be accessible in `st.val`.
+//   - And the 'st.type' will be 'hashedNode'
+//
 // 2. The rlp-encoded value was < 32 bytes
-//  - Then the <32 byte rlp-encoded value will be accessible in 'st.val'.
-//  - And the 'st.type' will be 'hashedNode' AGAIN
+//   - Then the <32 byte rlp-encoded value will be accessible in 'st.val'.
+//   - And the 'st.type' will be 'hashedNode' AGAIN
 //
 // This method also sets 'st.type' to hashedNode, and clears 'st.key'.
","build: upgrade to go 1.19 (#25726)

This changes the CI / release builds to use the latest Go version. It also
upgrades golangci-lint to a newer version compatible with Go 1.19.

In Go 1.19, godoc has gained official support for links and lists. The
syntax for code blocks in doc comments has changed and now requires a
leading tab character. gofmt adapts comments to the new syntax
automatically, so there are a lot of comment re-formatting changes in this
PR. We need to apply the new format in order to pass the CI lint stage with
Go 1.19.

With the linter upgrade, I have decided to disable 'gosec' - it produces
too many false-positive warnings. The 'deadcode' and 'varcheck' linters
have also been removed because golangci-lint warns about them being
unmaintained. 'unused' provides similar coverage and we already have it
enabled, so we don't lose much with this change.

"
425,Go,2f4996a9b2abefd1741a096660f08ab1cf44cbb8,https://github.com/ethereum/go-ethereum/commit/2f4996a9b2abefd1741a096660f08ab1cf44cbb8,C,ethereum,go-ethereum,"[1, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/ethdb/remotedb/remotedb.go b/ethdb/remotedb/remotedb.go
index a645760b9..59a570bb5 100644
--- a/ethdb/remotedb/remotedb.go
+++ b/ethdb/remotedb/remotedb.go
@@ -38,7 +38,7 @@ type Database struct {
 func (db *Database) Has(key []byte) (bool, error) {
 	if _, err := db.Get(key); err != nil {
-		return true, nil
+		return false, nil
 	}
-	return false, nil
+	return true, nil
 }
 
@@ -54,7 +54,7 @@ func (db *Database) Get(key []byte) ([]byte, error) {
 func (db *Database) HasAncient(kind string, number uint64) (bool, error) {
 	if _, err := db.Ancient(kind, number); err != nil {
-		return true, nil
+		return false, nil
 	}
-	return false, nil
+	return true, nil
 }
 
","ethdb/remotedb: fix flawed check in Has/HasAncient

"
430,Go,63117f46ee5f8cade4443cfea08fb9402ebedf38,https://github.com/gogs/gogs/commit/63117f46ee5f8cade4443cfea08fb9402ebedf38,P,gogs,gogs,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 3]","diff --git a/go.mod b/go.mod
index 6711cc4b..394a403f 100644
--- a/go.mod
+++ b/go.mod
@@ -36,5 +36,5 @@ require (
 	github.com/russross/blackfriday v1.6.0
 	github.com/satori/go.uuid v1.2.0
-	github.com/sergi/go-diff v1.2.0
+	github.com/sergi/go-diff v1.3.1
 	github.com/stretchr/testify v1.8.1
 	github.com/unknwon/cae v1.0.2
diff --git a/go.sum b/go.sum
index be3aab4a..30b87e57 100644
--- a/go.sum
+++ b/go.sum
@@ -413,6 +413,6 @@ github.com/saintfish/chardet v0.0.0-20120816061221-3af4cd4741ca/go.mod h1:uugorj
 github.com/satori/go.uuid v1.2.0 h1:0uYX9dsZ2yD7q2RtLRtPSdGDWzjeM3TbMJP9utgA0ww=
 github.com/satori/go.uuid v1.2.0/go.mod h1:dA0hQrYB0VpLJoorglMZABFdXlWrHn1NEOzdhQKdks0=
-github.com/sergi/go-diff v1.2.0 h1:XU+rvMAioB0UC3q1MFrIQy4Vo5/4VsRDQQXHsEya6xQ=
-github.com/sergi/go-diff v1.2.0/go.mod h1:STckp+ISIX8hZLjrqAeVduY0gWCT9IjLuqbuNXdaHfM=
+github.com/sergi/go-diff v1.3.1 h1:xkr+Oxo4BOQKmkn/B9eMK0g5Kg/983T9DqqPHwYqD+8=
+github.com/sergi/go-diff v1.3.1/go.mod h1:aMJSSKb2lpPvRNec0+w3fl7LP9IOFzdc9Pa4NFbPK1I=
 github.com/shurcooL/sanitized_anchor_name v1.0.0 h1:PdmoCO6wvbs+7yrJyMORt4/BmY5IYyJwS/kOiWx8mHo=
 github.com/shurcooL/sanitized_anchor_name v1.0.0/go.mod h1:1NzhyTcUVG4SuEtjjoZeVRXNmyL/1OwPU0+IJeTBvfc=
","mod: bump github.com/sergi/go-diff from 1.2.0 to 1.3.1 (#7312)

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>
"
433,Go,d725c41b56e072122faf539d5a14d36c18f5c312,https://github.com/gogs/gogs/commit/d725c41b56e072122faf539d5a14d36c18f5c312,P,gogs,gogs,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]","diff --git a/conf/gitignore/C++ b/conf/gitignore/C++
index 5a1b6ec4..620d3dc8 100644
--- a/conf/gitignore/C++
+++ b/conf/gitignore/C++
@@ -11,3 +11,3 @@
 *.lai
 *.la
-*.a
\ No newline at end of file
+*.a
","add CR in C++ gitignore

And try if I can commit.

"
442,Go,3a8faf24157f19a25a401410af86cc74073ba8c0,https://github.com/FiloSottile/mkcert/commit/3a8faf24157f19a25a401410af86cc74073ba8c0,P,FiloSottile,mkcert,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0]","diff --git a/README.md b/README.md
index c7327b9..cb20975 100644
--- a/README.md
+++ b/README.md
@@ -35,5 +35,5 @@ brew install --HEAD FiloSottile/mkcert/mkcert
 ```
 
-On Linux, use [the pre-built binaries](https://github.com/FiloSottile/mkcert/releases), or build from source.
+On Linux (support coming soon!), use [the pre-built binaries](https://github.com/FiloSottile/mkcert/releases), or build from source.
 
 ```
","Defer Linux support

https://github.com/golang/go/blob/master/src/crypto/x509/root_linux.go
https://github.com/golang/go/blob/master/src/crypto/x509/root_unix.go
https://www.brightbox.com/blog/2014/03/04/add-cacert-ubuntu-debian/
https://chromium.googlesource.com/chromium/src/+/lkcr/docs/linux_cert_management.md

"
444,Go,bf4af2d977b30daa753cea057d56514e8e93636b,https://github.com/FiloSottile/mkcert/commit/bf4af2d977b30daa753cea057d56514e8e93636b,P,FiloSottile,mkcert,"[2, 12, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/cert.go b/cert.go
index a7e9abe..314322f 100644
--- a/cert.go
+++ b/cert.go
@@ -12,4 +12,6 @@ import (
 	""net""
 	""os""
+	""os/exec""
+	""os/user""
 	""path/filepath""
 	""regexp""
@@ -19,6 +21,13 @@ import (
 )
 
-var rootSubject = pkix.Name{
-	Organization: []string{""mkcert development CA""},
+var userAndHostname string
+
+func init() {
+	u, _ := user.Current()
+	if u != nil {
+		userAndHostname = u.Username + ""@""
+	}
+	out, _ := exec.Command(""hostname"").Output()
+	userAndHostname += strings.TrimSpace(string(out))
 }
 
@@ -38,9 +47,10 @@ func (m *mkcert) makeCert(hosts []string) {
 		SerialNumber: serialNumber,
 		Subject: pkix.Name{
-			Organization: []string{""mkcert development certificate""},
+			Organization:       []string{""mkcert development certificate""},
+			OrganizationalUnit: []string{userAndHostname},
 		},
 
 		NotAfter:  time.Now().AddDate(10, 0, 0),
-		NotBefore: time.Now().AddDate(0, 0, -1),
+		NotBefore: time.Now(),
 
 		KeyUsage:              x509.KeyUsageKeyEncipherment | x509.KeyUsageDigitalSignature,
@@ -128,8 +138,11 @@ func (m *mkcert) newCA() {
 	tpl := &x509.Certificate{
 		SerialNumber: serialNumber,
-		Subject:      rootSubject,
+		Subject: pkix.Name{
+			Organization:       []string{""mkcert development CA""},
+			OrganizationalUnit: []string{userAndHostname},
+		},
 
 		NotAfter:  time.Now().AddDate(10, 0, 0),
-		NotBefore: time.Now().AddDate(0, 0, -1),
+		NotBefore: time.Now(),
 
 		KeyUsage: x509.KeyUsageCertSign,
diff --git a/truststore_darwin.go b/truststore_darwin.go
index 9022158..3e38ca5 100644
--- a/truststore_darwin.go
+++ b/truststore_darwin.go
@@ -73,5 +73,5 @@ func (m *mkcert) installPlatform() {
 	fatalIfErr(err, ""failed to parse trust settings"")
 
-	rootSubjectASN1, _ := asn1.Marshal(rootSubject.ToRDNSequence())
+	rootSubjectASN1, _ := asn1.Marshal(m.caCert.Subject.ToRDNSequence())
 
 	if plistRoot[""trustVersion""].(uint64) != 1 {
","Add user@hostname to the OU, and set NotBefore to now

This will help figuring out where and when a certificate was created.

Fixes #31

"
446,Go,2d05f3b4d80da3b20560535ab363ce3d7b3d9fd9,https://github.com/FiloSottile/mkcert/commit/2d05f3b4d80da3b20560535ab363ce3d7b3d9fd9,P,FiloSottile,mkcert,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0]","diff --git a/README.md b/README.md
index f24333f..d0e0adb 100644
--- a/README.md
+++ b/README.md
@@ -89,5 +89,5 @@ makepkg -si
 ### Windows
 
-On Windows, use Chocolatey
+On Windows, use [Chocolatey](https://chocolatey.org)
 
 ```
","Add link to Chocolatey in README (#181)


"
451,Go,1b4bb94ac4fd328e49af2d5e0fe23c912335ed9b,https://github.com/minio/minio/commit/1b4bb94ac4fd328e49af2d5e0fe23c912335ed9b,P,minio,minio,"[16, 200, 134, 34, 21, 14, 0, 4, 1, 0, 23, 15, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/cmd/bucket-notification-utils.go b/cmd/bucket-notification-utils.go
index 2c0e735f5..8845c5cdb 100644
--- a/cmd/bucket-notification-utils.go
+++ b/cmd/bucket-notification-utils.go
@@ -134,25 +134,25 @@ func isValidQueueID(queueARN string) bool {
 
 	if isAMQPQueue(sqsARN) { // AMQP eueue.
-		amqpN := serverConfig.GetAMQPNotifyByID(sqsARN.AccountID)
+		amqpN := serverConfig.Notify.GetAMQPByID(sqsARN.AccountID)
 		return amqpN.Enable && amqpN.URL != """"
 	} else if isNATSQueue(sqsARN) {
-		natsN := serverConfig.GetNATSNotifyByID(sqsARN.AccountID)
+		natsN := serverConfig.Notify.GetNATSByID(sqsARN.AccountID)
 		return natsN.Enable && natsN.Address != """"
 	} else if isElasticQueue(sqsARN) { // Elastic queue.
-		elasticN := serverConfig.GetElasticSearchNotifyByID(sqsARN.AccountID)
+		elasticN := serverConfig.Notify.GetElasticSearchByID(sqsARN.AccountID)
 		return elasticN.Enable && elasticN.URL != """"
 	} else if isRedisQueue(sqsARN) { // Redis queue.
-		redisN := serverConfig.GetRedisNotifyByID(sqsARN.AccountID)
+		redisN := serverConfig.Notify.GetRedisByID(sqsARN.AccountID)
 		return redisN.Enable && redisN.Addr != """"
 	} else if isPostgreSQLQueue(sqsARN) {
-		pgN := serverConfig.GetPostgreSQLNotifyByID(sqsARN.AccountID)
+		pgN := serverConfig.Notify.GetPostgreSQLByID(sqsARN.AccountID)
 		// Postgres can work with only default conn. info.
 		return pgN.Enable
 	} else if isKafkaQueue(sqsARN) {
-		kafkaN := serverConfig.GetKafkaNotifyByID(sqsARN.AccountID)
+		kafkaN := serverConfig.Notify.GetKafkaByID(sqsARN.AccountID)
 		return (kafkaN.Enable && len(kafkaN.Brokers) > 0 &&
 			kafkaN.Topic != """")
 	} else if isWebhookQueue(sqsARN) {
-		webhookN := serverConfig.GetWebhookNotifyByID(sqsARN.AccountID)
+		webhookN := serverConfig.Notify.GetWebhookByID(sqsARN.AccountID)
 		return webhookN.Enable && webhookN.Endpoint != """"
 	}
diff --git a/cmd/config-migrate.go b/cmd/config-migrate.go
index f153f17ff..d6a07b045 100644
--- a/cmd/config-migrate.go
+++ b/cmd/config-migrate.go
@@ -856,5 +856,8 @@ func migrateV12ToV13() error {
 
 	// Copy over fields from V12 into V13 config struct
-	srvConfig := &serverConfigV13{}
+	srvConfig := &serverConfigV13{
+		Logger: &logger{},
+		Notify: &notifier{},
+	}
 	srvConfig.Version = ""13""
 	srvConfig.Credential = cv12.Credential
diff --git a/cmd/config-v13.go b/cmd/config-v13.go
index 8e66c5f70..f1ee32b90 100644
--- a/cmd/config-v13.go
+++ b/cmd/config-v13.go
@@ -37,8 +37,8 @@ type serverConfigV13 struct {
 
 	// Additional error logging configuration.
-	Logger logger `json:""logger""`
+	Logger *logger `json:""logger""`
 
 	// Notification queue configuration.
-	Notify notifier `json:""notify""`
+	Notify *notifier `json:""notify""`
 }
 
@@ -48,5 +48,8 @@ type serverConfigV13 struct {
 func newConfig(envCreds credential) error {
 	// Initialize server config.
-	srvCfg := &serverConfigV13{}
+	srvCfg := &serverConfigV13{
+		Logger: &logger{},
+		Notify: &notifier{},
+	}
 	srvCfg.Version = globalMinioConfigVersion
 	srvCfg.Region = globalMinioDefaultRegion
@@ -149,191 +152,4 @@ func (s serverConfigV13) GetVersion() string {
 }
 
-/// Logger related.
-
-func (s *serverConfigV13) SetAMQPNotifyByID(accountID string, amqpn amqpNotify) {
-	serverConfigMu.Lock()
-	defer serverConfigMu.Unlock()
-
-	s.Notify.AMQP[accountID] = amqpn
-}
-
-func (s serverConfigV13) GetAMQP() map[string]amqpNotify {
-	serverConfigMu.RLock()
-	defer serverConfigMu.RUnlock()
-
-	return s.Notify.AMQP
-}
-
-// GetAMQPNotify get current AMQP logger.
-func (s serverConfigV13) GetAMQPNotifyByID(accountID string) amqpNotify {
-	serverConfigMu.RLock()
-	defer serverConfigMu.RUnlock()
-
-	return s.Notify.AMQP[accountID]
-}
-
-//
-func (s *serverConfigV13) SetNATSNotifyByID(accountID string, natsn natsNotify) {
-	serverConfigMu.Lock()
-	defer serverConfigMu.Unlock()
-
-	s.Notify.NATS[accountID] = natsn
-}
-
-func (s serverConfigV13) GetNATS() map[string]natsNotify {
-	serverConfigMu.RLock()
-	defer serverConfigMu.RUnlock()
-	return s.Notify.NATS
-}
-
-// GetNATSNotify get current NATS logger.
-func (s serverConfigV13) GetNATSNotifyByID(accountID string) natsNotify {
-	serverConfigMu.RLock()
-	defer serverConfigMu.RUnlock()
-
-	return s.Notify.NATS[accountID]
-}
-
-func (s *serverConfigV13) SetElasticSearchNotifyByID(accountID string, esNotify elasticSearchNotify) {
-	serverConfigMu.Lock()
-	defer serverConfigMu.Unlock()
-
-	s.Notify.ElasticSearch[accountID] = esNotify
-}
-
-func (s serverConfigV13) GetElasticSearch() map[string]elasticSearchNotify {
-	serverConfigMu.RLock()
-	defer serverConfigMu.RUnlock()
-
-	return s.Notify.ElasticSearch
-}
-
-// GetElasticSearchNotify get current ElasicSearch logger.
-func (s serverConfigV13) GetElasticSearchNotifyByID(accountID string) elasticSearchNotify {
-	serverConfigMu.RLock()
-	defer serverConfigMu.RUnlock()
-
-	return s.Notify.ElasticSearch[accountID]
-}
-
-func (s *serverConfigV13) SetRedisNotifyByID(accountID string, rNotify redisNotify) {
-	serverConfigMu.Lock()
-	defer serverConfigMu.Unlock()
-
-	s.Notify.Redis[accountID] = rNotify
-}
-
-func (s serverConfigV13) GetRedis() map[string]redisNotify {
-	serverConfigMu.RLock()
-	defer serverConfigMu.RUnlock()
-
-	return s.Notify.Redis
-}
-
-func (s serverConfigV13) GetWebhook() map[string]webhookNotify {
-	serverConfigMu.RLock()
-	defer serverConfigMu.RUnlock()
-
-	return s.Notify.Webhook
-}
-
-// GetWebhookNotifyByID get current Webhook logger.
-func (s serverConfigV13) GetWebhookNotifyByID(accountID string) webhookNotify {
-	serverConfigMu.RLock()
-	defer serverConfigMu.RUnlock()
-
-	return s.Notify.Webhook[accountID]
-}
-
-func (s *serverConfigV13) SetWebhookNotifyByID(accountID string, pgn webhookNotify) {
-	serverConfigMu.Lock()
-	defer serverConfigMu.Unlock()
-
-	s.Notify.Webhook[accountID] = pgn
-}
-
-// GetRedisNotify get current Redis logger.
-func (s serverConfigV13) GetRedisNotifyByID(accountID string) redisNotify {
-	serverConfigMu.RLock()
-	defer serverConfigMu.RUnlock()
-
-	return s.Notify.Redis[accountID]
-}
-
-func (s *serverConfigV13) SetPostgreSQLNotifyByID(accountID string, pgn postgreSQLNotify) {
-	serverConfigMu.Lock()
-	defer serverConfigMu.Unlock()
-
-	s.Notify.PostgreSQL[accountID] = pgn
-}
-
-func (s serverConfigV13) GetPostgreSQL() map[string]postgreSQLNotify {
-	serverConfigMu.RLock()
-	defer serverConfigMu.RUnlock()
-
-	return s.Notify.PostgreSQL
-}
-
-func (s serverConfigV13) GetPostgreSQLNotifyByID(accountID string) postgreSQLNotify {
-	serverConfigMu.RLock()
-	defer serverConfigMu.RUnlock()
-
-	return s.Notify.PostgreSQL[accountID]
-}
-
-// Kafka related functions
-func (s *serverConfigV13) SetKafkaNotifyByID(accountID string, kn kafkaNotify) {
-	serverConfigMu.Lock()
-	defer serverConfigMu.Unlock()
-
-	s.Notify.Kafka[accountID] = kn
-}
-
-func (s serverConfigV13) GetKafka() map[string]kafkaNotify {
-	serverConfigMu.RLock()
-	defer serverConfigMu.RUnlock()
-
-	return s.Notify.Kafka
-}
-
-func (s serverConfigV13) GetKafkaNotifyByID(accountID string) kafkaNotify {
-	serverConfigMu.RLock()
-	defer serverConfigMu.RUnlock()
-
-	return s.Notify.Kafka[accountID]
-}
-
-// SetFileLogger set new file logger.
-func (s *serverConfigV13) SetFileLogger(flogger fileLogger) {
-	serverConfigMu.Lock()
-	defer serverConfigMu.Unlock()
-
-	s.Logger.File = flogger
-}
-
-// GetFileLogger get current file logger.
-func (s serverConfigV13) GetFileLogger() fileLogger {
-	serverConfigMu.RLock()
-	defer serverConfigMu.RUnlock()
-
-	return s.Logger.File
-}
-
-// SetConsoleLogger set new console logger.
-func (s *serverConfigV13) SetConsoleLogger(clogger consoleLogger) {
-	serverConfigMu.Lock()
-	defer serverConfigMu.Unlock()
-
-	s.Logger.Console = clogger
-}
-
-// GetConsoleLogger get current console logger.
-func (s serverConfigV13) GetConsoleLogger() consoleLogger {
-	serverConfigMu.RLock()
-	defer serverConfigMu.RUnlock()
-
-	return s.Logger.Console
-}
-
 // SetRegion set new region.
 func (s *serverConfigV13) SetRegion(region string) {
diff --git a/cmd/config-v13_test.go b/cmd/config-v13_test.go
index b620b00ff..bd505c743 100644
--- a/cmd/config-v13_test.go
+++ b/cmd/config-v13_test.go
@@ -41,6 +41,6 @@ func TestServerConfig(t *testing.T) {
 
 	// Set new amqp notification id.
-	serverConfig.SetAMQPNotifyByID(""2"", amqpNotify{})
-	savedNotifyCfg1 := serverConfig.GetAMQPNotifyByID(""2"")
+	serverConfig.Notify.SetAMQPByID(""2"", amqpNotify{})
+	savedNotifyCfg1 := serverConfig.Notify.GetAMQPByID(""2"")
 	if !reflect.DeepEqual(savedNotifyCfg1, amqpNotify{}) {
 		t.Errorf(""Expecting AMQP config %#v found %#v"", amqpNotify{}, savedNotifyCfg1)
@@ -48,6 +48,6 @@ func TestServerConfig(t *testing.T) {
 
 	// Set new elastic search notification id.
-	serverConfig.SetElasticSearchNotifyByID(""2"", elasticSearchNotify{})
-	savedNotifyCfg2 := serverConfig.GetElasticSearchNotifyByID(""2"")
+	serverConfig.Notify.SetElasticSearchByID(""2"", elasticSearchNotify{})
+	savedNotifyCfg2 := serverConfig.Notify.GetElasticSearchByID(""2"")
 	if !reflect.DeepEqual(savedNotifyCfg2, elasticSearchNotify{}) {
 		t.Errorf(""Expecting Elasticsearch config %#v found %#v"", elasticSearchNotify{}, savedNotifyCfg2)
@@ -55,6 +55,6 @@ func TestServerConfig(t *testing.T) {
 
 	// Set new redis notification id.
-	serverConfig.SetRedisNotifyByID(""2"", redisNotify{})
-	savedNotifyCfg3 := serverConfig.GetRedisNotifyByID(""2"")
+	serverConfig.Notify.SetRedisByID(""2"", redisNotify{})
+	savedNotifyCfg3 := serverConfig.Notify.GetRedisByID(""2"")
 	if !reflect.DeepEqual(savedNotifyCfg3, redisNotify{}) {
 		t.Errorf(""Expecting Redis config %#v found %#v"", redisNotify{}, savedNotifyCfg3)
@@ -62,6 +62,6 @@ func TestServerConfig(t *testing.T) {
 
 	// Set new kafka notification id.
-	serverConfig.SetKafkaNotifyByID(""2"", kafkaNotify{})
-	savedNotifyCfg4 := serverConfig.GetKafkaNotifyByID(""2"")
+	serverConfig.Notify.SetKafkaByID(""2"", kafkaNotify{})
+	savedNotifyCfg4 := serverConfig.Notify.GetKafkaByID(""2"")
 	if !reflect.DeepEqual(savedNotifyCfg4, kafkaNotify{}) {
 		t.Errorf(""Expecting Kafka config %#v found %#v"", kafkaNotify{}, savedNotifyCfg4)
@@ -69,6 +69,6 @@ func TestServerConfig(t *testing.T) {
 
 	// Set new Webhook notification id.
-	serverConfig.SetWebhookNotifyByID(""2"", webhookNotify{})
-	savedNotifyCfg5 := serverConfig.GetWebhookNotifyByID(""2"")
+	serverConfig.Notify.SetWebhookByID(""2"", webhookNotify{})
+	savedNotifyCfg5 := serverConfig.Notify.GetWebhookByID(""2"")
 	if !reflect.DeepEqual(savedNotifyCfg5, webhookNotify{}) {
 		t.Errorf(""Expecting Webhook config %#v found %#v"", webhookNotify{}, savedNotifyCfg3)
@@ -76,8 +76,8 @@ func TestServerConfig(t *testing.T) {
 
 	// Set new console logger.
-	serverConfig.SetConsoleLogger(consoleLogger{
+	serverConfig.Logger.SetConsole(consoleLogger{
 		Enable: true,
 	})
-	consoleCfg := serverConfig.GetConsoleLogger()
+	consoleCfg := serverConfig.Logger.GetConsole()
 	if !reflect.DeepEqual(consoleCfg, consoleLogger{Enable: true}) {
 		t.Errorf(""Expecting console logger config %#v found %#v"", consoleLogger{Enable: true}, consoleCfg)
@@ -85,8 +85,8 @@ func TestServerConfig(t *testing.T) {
 
 	// Set new file logger.
-	serverConfig.SetFileLogger(fileLogger{
+	serverConfig.Logger.SetFile(fileLogger{
 		Enable: true,
 	})
-	fileCfg := serverConfig.GetFileLogger()
+	fileCfg := serverConfig.Logger.GetFile()
 	if !reflect.DeepEqual(fileCfg, fileLogger{Enable: true}) {
 		t.Errorf(""Expecting file logger config %#v found %#v"", fileLogger{Enable: true}, consoleCfg)
diff --git a/cmd/event-notifier.go b/cmd/event-notifier.go
index fa3eb5b7b..8ebc5462d 100644
--- a/cmd/event-notifier.go
+++ b/cmd/event-notifier.go
@@ -532,5 +532,5 @@ func loadAllQueueTargets() (map[string]*logrus.Logger, error) {
 	queueTargets := make(map[string]*logrus.Logger)
 	// Load all amqp targets, initialize their respective loggers.
-	for accountID, amqpN := range serverConfig.GetAMQP() {
+	for accountID, amqpN := range serverConfig.Notify.GetAMQP() {
 		if !amqpN.Enable {
 			continue
@@ -559,5 +559,5 @@ func loadAllQueueTargets() (map[string]*logrus.Logger, error) {
 	}
 	// Load all nats targets, initialize their respective loggers.
-	for accountID, natsN := range serverConfig.GetNATS() {
+	for accountID, natsN := range serverConfig.Notify.GetNATS() {
 		if !natsN.Enable {
 			continue
@@ -587,5 +587,5 @@ func loadAllQueueTargets() (map[string]*logrus.Logger, error) {
 
 	// Load redis targets, initialize their respective loggers.
-	for accountID, redisN := range serverConfig.GetRedis() {
+	for accountID, redisN := range serverConfig.Notify.GetRedis() {
 		if !redisN.Enable {
 			continue
@@ -615,5 +615,5 @@ func loadAllQueueTargets() (map[string]*logrus.Logger, error) {
 
 	// Load Webhook targets, initialize their respective loggers.
-	for accountID, webhookN := range serverConfig.GetWebhook() {
+	for accountID, webhookN := range serverConfig.Notify.GetWebhook() {
 		if !webhookN.Enable {
 			continue
@@ -636,5 +636,5 @@ func loadAllQueueTargets() (map[string]*logrus.Logger, error) {
 
 	// Load elastic targets, initialize their respective loggers.
-	for accountID, elasticN := range serverConfig.GetElasticSearch() {
+	for accountID, elasticN := range serverConfig.Notify.GetElasticSearch() {
 		if !elasticN.Enable {
 			continue
@@ -662,5 +662,5 @@ func loadAllQueueTargets() (map[string]*logrus.Logger, error) {
 
 	// Load PostgreSQL targets, initialize their respective loggers.
-	for accountID, pgN := range serverConfig.GetPostgreSQL() {
+	for accountID, pgN := range serverConfig.Notify.GetPostgreSQL() {
 		if !pgN.Enable {
 			continue
@@ -687,5 +687,5 @@ func loadAllQueueTargets() (map[string]*logrus.Logger, error) {
 	}
 	// Load Kafka targets, initialize their respective loggers.
-	for accountID, kafkaN := range serverConfig.GetKafka() {
+	for accountID, kafkaN := range serverConfig.Notify.GetKafka() {
 		if !kafkaN.Enable {
 			continue
diff --git a/cmd/event-notifier_test.go b/cmd/event-notifier_test.go
index 0b52f65da..415350c24 100644
--- a/cmd/event-notifier_test.go
+++ b/cmd/event-notifier_test.go
@@ -107,5 +107,5 @@ func TestInitEventNotifierWithPostgreSQL(t *testing.T) {
 	}
 
-	serverConfig.SetPostgreSQLNotifyByID(""1"", postgreSQLNotify{Enable: true})
+	serverConfig.Notify.SetPostgreSQLByID(""1"", postgreSQLNotify{Enable: true})
 	if err := initEventNotifier(fs); err == nil {
 		t.Fatal(""PostgreSQL config didn't fail."")
@@ -138,5 +138,5 @@ func TestInitEventNotifierWithNATS(t *testing.T) {
 	}
 
-	serverConfig.SetNATSNotifyByID(""1"", natsNotify{Enable: true})
+	serverConfig.Notify.SetNATSByID(""1"", natsNotify{Enable: true})
 	if err := initEventNotifier(fs); err == nil {
 		t.Fatal(""NATS config didn't fail."")
@@ -169,5 +169,5 @@ func TestInitEventNotifierWithWebHook(t *testing.T) {
 	}
 
-	serverConfig.SetWebhookNotifyByID(""1"", webhookNotify{Enable: true})
+	serverConfig.Notify.SetWebhookByID(""1"", webhookNotify{Enable: true})
 	if err := initEventNotifier(fs); err == nil {
 		t.Fatal(""WebHook config didn't fail."")
@@ -200,5 +200,5 @@ func TestInitEventNotifierWithAMQP(t *testing.T) {
 	}
 
-	serverConfig.SetAMQPNotifyByID(""1"", amqpNotify{Enable: true})
+	serverConfig.Notify.SetAMQPByID(""1"", amqpNotify{Enable: true})
 	if err := initEventNotifier(fs); err == nil {
 		t.Fatal(""AMQP config didn't fail."")
@@ -231,5 +231,5 @@ func TestInitEventNotifierWithElasticSearch(t *testing.T) {
 	}
 
-	serverConfig.SetElasticSearchNotifyByID(""1"", elasticSearchNotify{Enable: true})
+	serverConfig.Notify.SetElasticSearchByID(""1"", elasticSearchNotify{Enable: true})
 	if err := initEventNotifier(fs); err == nil {
 		t.Fatal(""ElasticSearch config didn't fail."")
@@ -262,5 +262,5 @@ func TestInitEventNotifierWithRedis(t *testing.T) {
 	}
 
-	serverConfig.SetRedisNotifyByID(""1"", redisNotify{Enable: true})
+	serverConfig.Notify.SetRedisByID(""1"", redisNotify{Enable: true})
 	if err := initEventNotifier(fs); err == nil {
 		t.Fatal(""Redis config didn't fail."")
diff --git a/cmd/logger-console-hook.go b/cmd/logger-console-hook.go
index 653b6ff04..fdc5264e8 100644
--- a/cmd/logger-console-hook.go
+++ b/cmd/logger-console-hook.go
@@ -27,5 +27,5 @@ type consoleLogger struct {
 // enable console logger.
 func enableConsoleLogger() {
-	clogger := serverConfig.GetConsoleLogger()
+	clogger := serverConfig.Logger.GetConsole()
 	if !clogger.Enable {
 		return
diff --git a/cmd/logger-file-hook.go b/cmd/logger-file-hook.go
index a0aad40a5..c7b5f6652 100644
--- a/cmd/logger-file-hook.go
+++ b/cmd/logger-file-hook.go
@@ -36,5 +36,5 @@ type localFile struct {
 
 func enableFileLogger() {
-	flogger := serverConfig.GetFileLogger()
+	flogger := serverConfig.Logger.GetFile()
 	if !flogger.Enable || flogger.Filename == """" {
 		return
diff --git a/cmd/logger.go b/cmd/logger.go
index 733e5606e..4aba14543 100644
--- a/cmd/logger.go
+++ b/cmd/logger.go
@@ -40,4 +40,5 @@ var log = struct {
 //   - file
 type logger struct {
+	sync.RWMutex
 	Console consoleLogger `json:""console""`
 	File    fileLogger    `json:""file""`
@@ -45,4 +46,33 @@ type logger struct {
 }
 
+/// Logger related.
+
+// SetFile set new file logger.
+func (l *logger) SetFile(flogger fileLogger) {
+	l.Lock()
+	defer l.Unlock()
+	l.File = flogger
+}
+
+// GetFileLogger get current file logger.
+func (l *logger) GetFile() fileLogger {
+	l.RLock()
+	defer l.RUnlock()
+	return l.File
+}
+
+// SetConsole set new console logger.
+func (l *logger) SetConsole(clogger consoleLogger) {
+	l.Lock()
+	defer l.Unlock()
+	l.Console = clogger
+}
+
+func (l *logger) GetConsole() consoleLogger {
+	l.RLock()
+	defer l.RUnlock()
+	return l.Console
+}
+
 // Get file, line, function name of the caller.
 func callerSource() string {
diff --git a/cmd/notifier-config.go b/cmd/notifier-config.go
new file mode 100644
index 000000000..2c9728158
--- /dev/null
+++ b/cmd/notifier-config.go
@@ -0,0 +1,228 @@
+/*
+ * Minio Cloud Storage, (C) 2017 Minio, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package cmd
+
+import ""sync""
+
+// Notifier represents collection of supported notification queues.
+type notifier struct {
+	sync.RWMutex
+	AMQP          amqpConfigs          `json:""amqp""`
+	NATS          natsConfigs          `json:""nats""`
+	ElasticSearch elasticSearchConfigs `json:""elasticsearch""`
+	Redis         redisConfigs         `json:""redis""`
+	PostgreSQL    postgreSQLConfigs    `json:""postgresql""`
+	Kafka         kafkaConfigs         `json:""kafka""`
+	Webhook       webhookConfigs       `json:""webhook""`
+	// Add new notification queues.
+}
+
+type amqpConfigs map[string]amqpNotify
+
+func (a amqpConfigs) Clone() amqpConfigs {
+	a2 := make(amqpConfigs, len(a))
+	for k, v := range a {
+		a2[k] = v
+	}
+	return a2
+}
+
+type natsConfigs map[string]natsNotify
+
+func (a natsConfigs) Clone() natsConfigs {
+	a2 := make(natsConfigs, len(a))
+	for k, v := range a {
+		a2[k] = v
+	}
+	return a2
+}
+
+type elasticSearchConfigs map[string]elasticSearchNotify
+
+func (a elasticSearchConfigs) Clone() elasticSearchConfigs {
+	a2 := make(elasticSearchConfigs, len(a))
+	for k, v := range a {
+		a2[k] = v
+	}
+	return a2
+}
+
+type redisConfigs map[string]redisNotify
+
+func (a redisConfigs) Clone() redisConfigs {
+	a2 := make(redisConfigs, len(a))
+	for k, v := range a {
+		a2[k] = v
+	}
+	return a2
+}
+
+type postgreSQLConfigs map[string]postgreSQLNotify
+
+func (a postgreSQLConfigs) Clone() postgreSQLConfigs {
+	a2 := make(postgreSQLConfigs, len(a))
+	for k, v := range a {
+		a2[k] = v
+	}
+	return a2
+}
+
+type kafkaConfigs map[string]kafkaNotify
+
+func (a kafkaConfigs) Clone() kafkaConfigs {
+	a2 := make(kafkaConfigs, len(a))
+	for k, v := range a {
+		a2[k] = v
+	}
+	return a2
+}
+
+type webhookConfigs map[string]webhookNotify
+
+func (a webhookConfigs) Clone() webhookConfigs {
+	a2 := make(webhookConfigs, len(a))
+	for k, v := range a {
+		a2[k] = v
+	}
+	return a2
+}
+
+func (n *notifier) SetAMQPByID(accountID string, amqpn amqpNotify) {
+	n.Lock()
+	defer n.Unlock()
+	n.AMQP[accountID] = amqpn
+}
+
+func (n *notifier) GetAMQP() map[string]amqpNotify {
+	n.RLock()
+	defer n.RUnlock()
+	return n.AMQP.Clone()
+}
+
+func (n *notifier) GetAMQPByID(accountID string) amqpNotify {
+	n.RLock()
+	defer n.RUnlock()
+	return n.AMQP[accountID]
+}
+
+func (n *notifier) SetNATSByID(accountID string, natsn natsNotify) {
+	n.Lock()
+	defer n.Unlock()
+	n.NATS[accountID] = natsn
+}
+
+func (n *notifier) GetNATS() map[string]natsNotify {
+	n.RLock()
+	defer n.RUnlock()
+	return n.NATS.Clone()
+}
+
+func (n *notifier) GetNATSByID(accountID string) natsNotify {
+	n.RLock()
+	defer n.RUnlock()
+	return n.NATS[accountID]
+}
+
+func (n *notifier) SetElasticSearchByID(accountID string, es elasticSearchNotify) {
+	n.Lock()
+	defer n.Unlock()
+	n.ElasticSearch[accountID] = es
+}
+
+func (n *notifier) GetElasticSearchByID(accountID string) elasticSearchNotify {
+	n.RLock()
+	defer n.RUnlock()
+	return n.ElasticSearch[accountID]
+}
+
+func (n *notifier) GetElasticSearch() map[string]elasticSearchNotify {
+	n.RLock()
+	defer n.RUnlock()
+	return n.ElasticSearch.Clone()
+}
+
+func (n *notifier) SetRedisByID(accountID string, r redisNotify) {
+	n.Lock()
+	defer n.Unlock()
+	n.Redis[accountID] = r
+}
+
+func (n *notifier) GetRedis() map[string]redisNotify {
+	n.RLock()
+	defer n.RUnlock()
+	return n.Redis.Clone()
+}
+
+func (n *notifier) GetRedisByID(accountID string) redisNotify {
+	n.RLock()
+	defer n.RUnlock()
+	return n.Redis[accountID]
+}
+
+func (n *notifier) GetWebhook() map[string]webhookNotify {
+	n.RLock()
+	defer n.RUnlock()
+	return n.Webhook.Clone()
+}
+
+func (n *notifier) GetWebhookByID(accountID string) webhookNotify {
+	n.RLock()
+	defer n.RUnlock()
+	return n.Webhook[accountID]
+}
+
+func (n *notifier) SetWebhookByID(accountID string, pgn webhookNotify) {
+	n.Lock()
+	defer n.Unlock()
+	n.Webhook[accountID] = pgn
+}
+
+func (n *notifier) SetPostgreSQLByID(accountID string, pgn postgreSQLNotify) {
+	n.Lock()
+	defer n.Unlock()
+	n.PostgreSQL[accountID] = pgn
+}
+
+func (n *notifier) GetPostgreSQL() map[string]postgreSQLNotify {
+	n.RLock()
+	defer n.RUnlock()
+	return n.PostgreSQL.Clone()
+}
+
+func (n *notifier) GetPostgreSQLByID(accountID string) postgreSQLNotify {
+	n.RLock()
+	defer n.RUnlock()
+	return n.PostgreSQL[accountID]
+}
+
+func (n *notifier) SetKafkaByID(accountID string, kn kafkaNotify) {
+	n.Lock()
+	defer n.Unlock()
+	n.Kafka[accountID] = kn
+}
+
+func (n *notifier) GetKafka() map[string]kafkaNotify {
+	n.RLock()
+	defer n.RUnlock()
+	return n.Kafka.Clone()
+}
+
+func (n *notifier) GetKafkaByID(accountID string) kafkaNotify {
+	n.RLock()
+	defer n.RUnlock()
+	return n.Kafka[accountID]
+}
diff --git a/cmd/notifier-config_test.go b/cmd/notifier-config_test.go
new file mode 100644
index 000000000..a416825a9
--- /dev/null
+++ b/cmd/notifier-config_test.go
@@ -0,0 +1,17 @@
+/*
+ * Minio Cloud Storage, (C) 2017 Minio, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package cmd
diff --git a/cmd/notifiers.go b/cmd/notifiers.go
index f1f1c4cbc..1d3ed1bfd 100644
--- a/cmd/notifiers.go
+++ b/cmd/notifiers.go
@@ -55,16 +55,4 @@ const (
 var errNotifyNotEnabled = errors.New(""requested notifier not enabled"")
 
-// Notifier represents collection of supported notification queues.
-type notifier struct {
-	AMQP          map[string]amqpNotify          `json:""amqp""`
-	NATS          map[string]natsNotify          `json:""nats""`
-	ElasticSearch map[string]elasticSearchNotify `json:""elasticsearch""`
-	Redis         map[string]redisNotify         `json:""redis""`
-	PostgreSQL    map[string]postgreSQLNotify    `json:""postgresql""`
-	Kafka         map[string]kafkaNotify         `json:""kafka""`
-	Webhook       map[string]webhookNotify       `json:""webhook""`
-	// Add new notification queues.
-}
-
 // Returns true if queueArn is for an AMQP queue.
 func isAMQPQueue(sqsArn arnSQS) bool {
@@ -72,5 +60,5 @@ func isAMQPQueue(sqsArn arnSQS) bool {
 		return false
 	}
-	amqpL := serverConfig.GetAMQPNotifyByID(sqsArn.AccountID)
+	amqpL := serverConfig.Notify.GetAMQPByID(sqsArn.AccountID)
 	if !amqpL.Enable {
 		return false
@@ -91,5 +79,5 @@ func isNATSQueue(sqsArn arnSQS) bool {
 		return false
 	}
-	natsL := serverConfig.GetNATSNotifyByID(sqsArn.AccountID)
+	natsL := serverConfig.Notify.GetNATSByID(sqsArn.AccountID)
 	if !natsL.Enable {
 		return false
@@ -110,5 +98,5 @@ func isWebhookQueue(sqsArn arnSQS) bool {
 		return false
 	}
-	rNotify := serverConfig.GetWebhookNotifyByID(sqsArn.AccountID)
+	rNotify := serverConfig.Notify.GetWebhookByID(sqsArn.AccountID)
 	if !rNotify.Enable {
 		return false
@@ -122,5 +110,5 @@ func isRedisQueue(sqsArn arnSQS) bool {
 		return false
 	}
-	rNotify := serverConfig.GetRedisNotifyByID(sqsArn.AccountID)
+	rNotify := serverConfig.Notify.GetRedisByID(sqsArn.AccountID)
 	if !rNotify.Enable {
 		return false
@@ -141,5 +129,5 @@ func isElasticQueue(sqsArn arnSQS) bool {
 		return false
 	}
-	esNotify := serverConfig.GetElasticSearchNotifyByID(sqsArn.AccountID)
+	esNotify := serverConfig.Notify.GetElasticSearchByID(sqsArn.AccountID)
 	if !esNotify.Enable {
 		return false
@@ -159,5 +147,5 @@ func isPostgreSQLQueue(sqsArn arnSQS) bool {
 		return false
 	}
-	pgNotify := serverConfig.GetPostgreSQLNotifyByID(sqsArn.AccountID)
+	pgNotify := serverConfig.Notify.GetPostgreSQLByID(sqsArn.AccountID)
 	if !pgNotify.Enable {
 		return false
@@ -177,5 +165,5 @@ func isKafkaQueue(sqsArn arnSQS) bool {
 		return false
 	}
-	kafkaNotifyCfg := serverConfig.GetKafkaNotifyByID(sqsArn.AccountID)
+	kafkaNotifyCfg := serverConfig.Notify.GetKafkaByID(sqsArn.AccountID)
 	if !kafkaNotifyCfg.Enable {
 		return false
diff --git a/cmd/notify-amqp.go b/cmd/notify-amqp.go
index a5b87f72d..9168cc959 100644
--- a/cmd/notify-amqp.go
+++ b/cmd/notify-amqp.go
@@ -60,5 +60,5 @@ func dialAMQP(amqpL amqpNotify) (amqpConn, error) {
 
 func newAMQPNotify(accountID string) (*logrus.Logger, error) {
-	amqpL := serverConfig.GetAMQPNotifyByID(accountID)
+	amqpL := serverConfig.Notify.GetAMQPByID(accountID)
 
 	// Connect to amqp server.
diff --git a/cmd/notify-elasticsearch.go b/cmd/notify-elasticsearch.go
index 98249d16d..508b7ed9e 100644
--- a/cmd/notify-elasticsearch.go
+++ b/cmd/notify-elasticsearch.go
@@ -56,5 +56,5 @@ func dialElastic(esNotify elasticSearchNotify) (*elastic.Client, error) {
 
 func newElasticNotify(accountID string) (*logrus.Logger, error) {
-	esNotify := serverConfig.GetElasticSearchNotifyByID(accountID)
+	esNotify := serverConfig.Notify.GetElasticSearchByID(accountID)
 
 	// Dial to elastic search.
diff --git a/cmd/notify-kafka.go b/cmd/notify-kafka.go
index d6e5d1f66..7ddf454b8 100644
--- a/cmd/notify-kafka.go
+++ b/cmd/notify-kafka.go
@@ -76,5 +76,5 @@ func dialKafka(kn kafkaNotify) (kafkaConn, error) {
 
 func newKafkaNotify(accountID string) (*logrus.Logger, error) {
-	kafkaNotifyCfg := serverConfig.GetKafkaNotifyByID(accountID)
+	kafkaNotifyCfg := serverConfig.Notify.GetKafkaByID(accountID)
 
 	// Try connecting to the configured Kafka broker(s).
diff --git a/cmd/notify-nats.go b/cmd/notify-nats.go
index bec7cdcdf..b18751ded 100644
--- a/cmd/notify-nats.go
+++ b/cmd/notify-nats.go
@@ -128,5 +128,5 @@ func closeNATS(conn natsIOConn) {
 
 func newNATSNotify(accountID string) (*logrus.Logger, error) {
-	natsL := serverConfig.GetNATSNotifyByID(accountID)
+	natsL := serverConfig.Notify.GetNATSByID(accountID)
 
 	// Connect to nats server.
diff --git a/cmd/notify-postgresql.go b/cmd/notify-postgresql.go
index 5e1634655..116092520 100644
--- a/cmd/notify-postgresql.go
+++ b/cmd/notify-postgresql.go
@@ -175,5 +175,5 @@ func dialPostgreSQL(pgN postgreSQLNotify) (pgConn, error) {
 
 func newPostgreSQLNotify(accountID string) (*logrus.Logger, error) {
-	pgNotify := serverConfig.GetPostgreSQLNotifyByID(accountID)
+	pgNotify := serverConfig.Notify.GetPostgreSQLByID(accountID)
 
 	// Dial postgres
diff --git a/cmd/notify-redis.go b/cmd/notify-redis.go
index f44333cca..8e382edb5 100644
--- a/cmd/notify-redis.go
+++ b/cmd/notify-redis.go
@@ -84,5 +84,5 @@ func dialRedis(rNotify redisNotify) (*redis.Pool, error) {
 
 func newRedisNotify(accountID string) (*logrus.Logger, error) {
-	rNotify := serverConfig.GetRedisNotifyByID(accountID)
+	rNotify := serverConfig.Notify.GetRedisByID(accountID)
 
 	// Dial redis.
diff --git a/cmd/notify-webhook.go b/cmd/notify-webhook.go
index 875167f79..7bdb8f086 100644
--- a/cmd/notify-webhook.go
+++ b/cmd/notify-webhook.go
@@ -53,5 +53,5 @@ func lookupEndpoint(u *url.URL) error {
 // Initializes new webhook logrus notifier.
 func newWebhookNotify(accountID string) (*logrus.Logger, error) {
-	rNotify := serverConfig.GetWebhookNotifyByID(accountID)
+	rNotify := serverConfig.Notify.GetWebhookByID(accountID)
 
 	if rNotify.Endpoint == """" {
diff --git a/cmd/notify-webhook_test.go b/cmd/notify-webhook_test.go
index 4740901f0..ff974f751 100644
--- a/cmd/notify-webhook_test.go
+++ b/cmd/notify-webhook_test.go
@@ -52,5 +52,5 @@ func TestNewWebHookNotify(t *testing.T) {
 	}
 
-	serverConfig.SetWebhookNotifyByID(""10"", webhookNotify{Enable: true, Endpoint: ""http://www.""})
+	serverConfig.Notify.SetWebhookByID(""10"", webhookNotify{Enable: true, Endpoint: ""http://www.""})
 	_, err = newWebhookNotify(""10"")
 	if err == nil {
@@ -58,5 +58,5 @@ func TestNewWebHookNotify(t *testing.T) {
 	}
 
-	serverConfig.SetWebhookNotifyByID(""15"", webhookNotify{Enable: true, Endpoint: ""http://%""})
+	serverConfig.Notify.SetWebhookByID(""15"", webhookNotify{Enable: true, Endpoint: ""http://%""})
 	_, err = newWebhookNotify(""15"")
 	if err == nil {
@@ -67,5 +67,5 @@ func TestNewWebHookNotify(t *testing.T) {
 	defer server.Close()
 
-	serverConfig.SetWebhookNotifyByID(""20"", webhookNotify{Enable: true, Endpoint: server.URL})
+	serverConfig.Notify.SetWebhookByID(""20"", webhookNotify{Enable: true, Endpoint: server.URL})
 	webhook, err := newWebhookNotify(""20"")
 	if err != nil {
","config: setter/getter for Notifier and Logger into its own struct. (#3721)

This is an attempt cleanup code and keep the top level config
functions simpler and easy to understand where as move the
notifier related code and logger setter/getter methods as part
of their own struct.

Locks are now held properly not globally by configMutex, but
instead as private variables.

Final fix for #3700
"
456,Go,2871cb5775184f993a10f5ea44bb50d312257ce0,https://github.com/minio/minio/commit/2871cb5775184f993a10f5ea44bb50d312257ce0,P,minio,minio,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 22, 0, 66, 0, 0, 0, 0, 1, 0, 0, 0]","diff --git a/helm-releases/minio-4.0.9.tgz b/helm-releases/minio-4.0.9.tgz
new file mode 100644
index 000000000..d28cc7627
Binary files /dev/null and b/helm-releases/minio-4.0.9.tgz differ
diff --git a/helm/minio/Chart.yaml b/helm/minio/Chart.yaml
index afd588715..e48469e9c 100644
--- a/helm/minio/Chart.yaml
+++ b/helm/minio/Chart.yaml
@@ -2,6 +2,6 @@ apiVersion: v1
 description: Multi-Cloud Object Storage
 name: minio
-version: 4.0.8
-appVersion: RELEASE.2022-07-29T19-40-48Z
+version: 4.0.9
+appVersion: RELEASE.2022-08-02T23-59-16Z
 keywords:
   - minio
diff --git a/helm/minio/values.yaml b/helm/minio/values.yaml
index 9260d66db..169697cea 100644
--- a/helm/minio/values.yaml
+++ b/helm/minio/values.yaml
@@ -15,5 +15,5 @@ clusterDomain: cluster.local
 image:
   repository: quay.io/minio/minio
-  tag: RELEASE.2022-07-29T19-40-48Z
+  tag: RELEASE.2022-08-02T23-59-16Z
   pullPolicy: IfNotPresent
 
diff --git a/index.yaml b/index.yaml
index 80fc006bf..d6ff066c6 100644
--- a/index.yaml
+++ b/index.yaml
@@ -2,7 +2,29 @@ apiVersion: v1
 entries:
   minio:
+  - apiVersion: v1
+    appVersion: RELEASE.2022-08-02T23-59-16Z
+    created: ""2022-08-02T19:11:04.044756156-07:00""
+    description: Multi-Cloud Object Storage
+    digest: 6f1a78382df3215deac07495a5e7de7009a1153b4cf6cb565630652a69aec4cf
+    home: https://min.io
+    icon: https://min.io/resources/img/logo/MINIO_wordmark.png
+    keywords:
+    - minio
+    - storage
+    - object-storage
+    - s3
+    - cluster
+    maintainers:
+    - email: dev@minio.io
+      name: MinIO, Inc
+    name: minio
+    sources:
+    - https://github.com/minio/minio
+    urls:
+    - https://charts.min.io/helm-releases/minio-4.0.9.tgz
+    version: 4.0.9
   - apiVersion: v1
     appVersion: RELEASE.2022-07-29T19-40-48Z
-    created: ""2022-07-29T16:39:37.342971174-07:00""
+    created: ""2022-08-02T19:11:04.043158337-07:00""
     description: Multi-Cloud Object Storage
     digest: d11db37963636922cb778b6bc0ad2ca4724cb391ea7b785995ada52467d7dd83
@@ -26,5 +48,5 @@ entries:
   - apiVersion: v1
     appVersion: RELEASE.2022-07-26T00-53-03Z
-    created: ""2022-07-29T16:39:37.341994234-07:00""
+    created: ""2022-08-02T19:11:04.041646103-07:00""
     description: Multi-Cloud Object Storage
     digest: ca775e08c84331bb5029d4d29867d30c16e2c62e897788eb432212a756e91e4e
@@ -48,5 +70,5 @@ entries:
   - apiVersion: v1
     appVersion: RELEASE.2022-05-08T23-50-31Z
-    created: ""2022-07-29T16:39:37.340289687-07:00""
+    created: ""2022-08-02T19:11:04.040028607-07:00""
     description: Multi-Cloud Object Storage
     digest: 06542b8f3d149d5908b15de9a8d6f8cf304af0213830be56dc315785d14f9ccd
@@ -70,5 +92,5 @@ entries:
   - apiVersion: v1
     appVersion: RELEASE.2022-05-08T23-50-31Z
-    created: ""2022-07-29T16:39:37.339109559-07:00""
+    created: ""2022-08-02T19:11:04.037467543-07:00""
     description: Multi-Cloud Object Storage
     digest: dd2676362f067454a496cdd293609d0c904b08f521625af49f95402a024ba1f5
@@ -92,5 +114,5 @@ entries:
   - apiVersion: v1
     appVersion: RELEASE.2022-05-08T23-50-31Z
-    created: ""2022-07-29T16:39:37.338080173-07:00""
+    created: ""2022-08-02T19:11:04.035960022-07:00""
     description: Multi-Cloud Object Storage
     digest: bab9ef192d4eda4c572ad0ce0cf551736c847f582d1837d6833ee10543c23167
@@ -114,5 +136,5 @@ entries:
   - apiVersion: v1
     appVersion: RELEASE.2022-05-08T23-50-31Z
-    created: ""2022-07-29T16:39:37.336960542-07:00""
+    created: ""2022-08-02T19:11:04.034453636-07:00""
     description: Multi-Cloud Object Storage
     digest: c770bb9841c76576e4e8573f78b0ec33e0d729504c9667e67ad62d48df5ed64c
@@ -136,5 +158,5 @@ entries:
   - apiVersion: v1
     appVersion: RELEASE.2022-05-08T23-50-31Z
-    created: ""2022-07-29T16:39:37.335803796-07:00""
+    created: ""2022-08-02T19:11:04.032944259-07:00""
     description: Multi-Cloud Object Storage
     digest: 95835f4199d963e2a23a2493610b348e6f2ff8b71c1a648c4a3b84af9b7a83eb
@@ -158,5 +180,5 @@ entries:
   - apiVersion: v1
     appVersion: RELEASE.2022-04-30T22-23-53Z
-    created: ""2022-07-29T16:39:37.334606142-07:00""
+    created: ""2022-08-02T19:11:04.031423184-07:00""
     description: Multi-Cloud Object Storage
     digest: 55a088c403b056e1f055a97426aa11759c3d6cbad38face170fe6cbbec7d568f
@@ -180,5 +202,5 @@ entries:
   - apiVersion: v1
     appVersion: RELEASE.2022-04-26T01-20-24Z
-    created: ""2022-07-29T16:39:37.332950952-07:00""
+    created: ""2022-08-02T19:11:04.0296977-07:00""
     description: Multi-Cloud Object Storage
     digest: f541237e24336ec3f7f45ae0d523fef694e3a2f9ef648c5b11c15734db6ba2b2
@@ -202,5 +224,5 @@ entries:
   - apiVersion: v1
     appVersion: RELEASE.2022-04-16T04-26-02Z
-    created: ""2022-07-29T16:39:37.331747344-07:00""
+    created: ""2022-08-02T19:11:04.02752185-07:00""
     description: Multi-Cloud Object Storage
     digest: edc0c3dd6d5246a06b74ba16bb4aff80a6d7225dc9aecf064fd89a8af371b9c1
@@ -224,5 +246,5 @@ entries:
   - apiVersion: v1
     appVersion: RELEASE.2022-04-12T06-55-35Z
-    created: ""2022-07-29T16:39:37.330499201-07:00""
+    created: ""2022-08-02T19:11:04.026014079-07:00""
     description: Multi-Cloud Object Storage
     digest: 211e89f6b9eb0b9a3583abaa127be60e1f9717a098e6b2858cb9dc1cc50c1650
@@ -246,5 +268,5 @@ entries:
   - apiVersion: v1
     appVersion: RELEASE.2022-04-09T15-09-52Z
-    created: ""2022-07-29T16:39:37.329403232-07:00""
+    created: ""2022-08-02T19:11:04.024470054-07:00""
     description: Multi-Cloud Object Storage
     digest: 534a879d73b370a18b554b93d0930e1c115419619c4ce4ec7dbaae632acacf06
@@ -268,5 +290,5 @@ entries:
   - apiVersion: v1
     appVersion: RELEASE.2022-03-24T00-43-44Z
-    created: ""2022-07-29T16:39:37.32830842-07:00""
+    created: ""2022-08-02T19:11:04.022978955-07:00""
     description: Multi-Cloud Object Storage
     digest: 99508b20eb0083a567dcccaf9a6c237e09575ed1d70cd2e8333f89c472d13d75
@@ -290,5 +312,5 @@ entries:
   - apiVersion: v1
     appVersion: RELEASE.2022-03-17T06-34-49Z
-    created: ""2022-07-29T16:39:37.326794288-07:00""
+    created: ""2022-08-02T19:11:04.021130343-07:00""
     description: Multi-Cloud Object Storage
     digest: b4cd25611ca322b1d23d23112fdfa6b068fd91eefe0b0663b88ff87ea4282495
@@ -312,5 +334,5 @@ entries:
   - apiVersion: v1
     appVersion: RELEASE.2022-03-14T18-25-24Z
-    created: ""2022-07-29T16:39:37.325583838-07:00""
+    created: ""2022-08-02T19:11:04.018749858-07:00""
     description: Multi-Cloud Object Storage
     digest: d75b88162bfe54740a233bcecf87328bba2ae23d170bec3a35c828bc6fdc224c
@@ -334,5 +356,5 @@ entries:
   - apiVersion: v1
     appVersion: RELEASE.2022-03-11T23-57-45Z
-    created: ""2022-07-29T16:39:37.324523917-07:00""
+    created: ""2022-08-02T19:11:04.017261024-07:00""
     description: Multi-Cloud Object Storage
     digest: 22e53a1184a21a679bc7d8b94e955777f3506340fc29da5ab0cb6d729bdbde8d
@@ -356,5 +378,5 @@ entries:
   - apiVersion: v1
     appVersion: RELEASE.2022-03-03T21-21-16Z
-    created: ""2022-07-29T16:39:37.323310007-07:00""
+    created: ""2022-08-02T19:11:04.015749153-07:00""
     description: Multi-Cloud Object Storage
     digest: 6fda968d3fdfd60470c0055a4e1a3bd8e5aee9ad0af5ba2fb7b7b926fdc9e4a0
@@ -378,5 +400,5 @@ entries:
   - apiVersion: v1
     appVersion: RELEASE.2022-02-26T02-54-46Z
-    created: ""2022-07-29T16:39:37.322290091-07:00""
+    created: ""2022-08-02T19:11:04.014286718-07:00""
     description: Multi-Cloud Object Storage
     digest: 8e015369048a3a82bbd53ad36696786f18561c6b25d14eee9e2c93a7336cef46
@@ -400,5 +422,5 @@ entries:
   - apiVersion: v1
     appVersion: RELEASE.2022-02-18T01-50-10Z
-    created: ""2022-07-29T16:39:37.321127622-07:00""
+    created: ""2022-08-02T19:11:04.012767577-07:00""
     description: Multi-Cloud Object Storage
     digest: cb3543fe748e5f0d59b3ccf4ab9af8e10b731405ae445d1f5715e30013632373
@@ -422,5 +444,5 @@ entries:
   - apiVersion: v1
     appVersion: RELEASE.2022-02-18T01-50-10Z
-    created: ""2022-07-29T16:39:37.319472315-07:00""
+    created: ""2022-08-02T19:11:04.010921623-07:00""
     description: Multi-Cloud Object Storage
     digest: f2e359fa5eefffc59abb3d14a8fa94b11ddeaa99f6cd8dd5f40f4e04121000d6
@@ -444,5 +466,5 @@ entries:
   - apiVersion: v1
     appVersion: RELEASE.2022-02-16T00-35-27Z
-    created: ""2022-07-29T16:39:37.318382809-07:00""
+    created: ""2022-08-02T19:11:04.009039193-07:00""
     description: Multi-Cloud Object Storage
     digest: 529d56cca9d83a3d0e5672e63b6e87b5bcbe10a6b45f7a55ba998cceb32f9c81
@@ -466,5 +488,5 @@ entries:
   - apiVersion: v1
     appVersion: RELEASE.2022-02-12T00-51-25Z
-    created: ""2022-07-29T16:39:37.317505771-07:00""
+    created: ""2022-08-02T19:11:04.007607279-07:00""
     description: Multi-Cloud Object Storage
     digest: 3d530598f8ece67bec5b7f990d206584893987c713502f9228e4ee24b5535414
@@ -488,5 +510,5 @@ entries:
   - apiVersion: v1
     appVersion: RELEASE.2022-02-12T00-51-25Z
-    created: ""2022-07-29T16:39:37.316559972-07:00""
+    created: ""2022-08-02T19:11:04.006218004-07:00""
     description: Multi-Cloud Object Storage
     digest: 53937031348b29615f07fc4869b2d668391d8ba9084630a497abd7a7dea9dfb0
@@ -510,5 +532,5 @@ entries:
   - apiVersion: v1
     appVersion: RELEASE.2022-02-07T08-17-33Z
-    created: ""2022-07-29T16:39:37.315513135-07:00""
+    created: ""2022-08-02T19:11:04.004943951-07:00""
     description: Multi-Cloud Object Storage
     digest: 68d643414ff0d565716c5715034fcbf1af262e041915a5c02eb51ec1a65c1ea0
@@ -532,5 +554,5 @@ entries:
   - apiVersion: v1
     appVersion: RELEASE.2022-02-01T18-00-14Z
-    created: ""2022-07-29T16:39:37.314462761-07:00""
+    created: ""2022-08-02T19:11:04.00365907-07:00""
     description: Multi-Cloud Object Storage
     digest: a3e855ed0f31233b989fffd775a29d6fbfa0590089010ff16783fd7f142ef6e7
@@ -554,5 +576,5 @@ entries:
   - apiVersion: v1
     appVersion: RELEASE.2022-02-01T18-00-14Z
-    created: ""2022-07-29T16:39:37.312756217-07:00""
+    created: ""2022-08-02T19:11:04.002230283-07:00""
     description: Multi-Cloud Object Storage
     digest: b1b0ae3c54b4260a698753e11d7781bb8ddc67b7e3fbf0af82796e4cd4ef92a3
@@ -576,5 +598,5 @@ entries:
   - apiVersion: v1
     appVersion: RELEASE.2022-01-28T02-28-16Z
-    created: ""2022-07-29T16:39:37.311587946-07:00""
+    created: ""2022-08-02T19:11:04.000168601-07:00""
     description: Multi-Cloud Object Storage
     digest: fecf25d2d3fb208c6f894fed642a60780a570b7f6d0adddde846af7236dc80aa
@@ -598,5 +620,5 @@ entries:
   - apiVersion: v1
     appVersion: RELEASE.2022-01-25T19-56-04Z
-    created: ""2022-07-29T16:39:37.310732127-07:00""
+    created: ""2022-08-02T19:11:03.998865847-07:00""
     description: Multi-Cloud Object Storage
     digest: c78008caa5ce98f64c887630f59d0cbd481cb3f19a7d4e9d3e81bf4e1e45cadc
@@ -620,5 +642,5 @@ entries:
   - apiVersion: v1
     appVersion: RELEASE.2022-01-08T03-11-54Z
-    created: ""2022-07-29T16:39:37.309890982-07:00""
+    created: ""2022-08-02T19:11:03.997585673-07:00""
     description: Multi-Cloud Object Storage
     digest: 8f2e2691bf897f74ff094dd370ec56ba9d417e5e8926710c14c2ba346330238d
@@ -642,5 +664,5 @@ entries:
   - apiVersion: v1
     appVersion: RELEASE.2022-01-04T07-41-07Z
-    created: ""2022-07-29T16:39:37.309060266-07:00""
+    created: ""2022-08-02T19:11:03.996323481-07:00""
     description: Multi-Cloud Object Storage
     digest: bacd140f0016fab35f516bde787da6449b3a960c071fad9e4b6563118033ac84
@@ -664,5 +686,5 @@ entries:
   - apiVersion: v1
     appVersion: RELEASE.2021-12-29T06-49-06Z
-    created: ""2022-07-29T16:39:37.308047332-07:00""
+    created: ""2022-08-02T19:11:03.995093554-07:00""
     description: Multi-Cloud Object Storage
     digest: 48a453ea5ffeef25933904caefd9470bfb26224dfc2d1096bd0031467ba53007
@@ -686,5 +708,5 @@ entries:
   - apiVersion: v1
     appVersion: RELEASE.2021-12-20T22-07-16Z
-    created: ""2022-07-29T16:39:37.307006274-07:00""
+    created: ""2022-08-02T19:11:03.993796937-07:00""
     description: Multi-Cloud Object Storage
     digest: 47ef4a930713b98f9438ceca913c6e700f85bb25dba5624b056486254b5f0c60
@@ -708,5 +730,5 @@ entries:
   - apiVersion: v1
     appVersion: RELEASE.2021-12-20T22-07-16Z
-    created: ""2022-07-29T16:39:37.305297449-07:00""
+    created: ""2022-08-02T19:11:03.991624281-07:00""
     description: Multi-Cloud Object Storage
     digest: d6763f7e2ea66810bd55eb225579a9c3b968f9ae1256f45fd469362e55d846ff
@@ -730,5 +752,5 @@ entries:
   - apiVersion: v1
     appVersion: RELEASE.2021-12-10T23-03-39Z
-    created: ""2022-07-29T16:39:37.304414066-07:00""
+    created: ""2022-08-02T19:11:03.990340312-07:00""
     description: Multi-Cloud Object Storage
     digest: 2fb822c87216ba3fc2ae51a54a0a3e239aa560d86542991504a841cc2a2b9a37
@@ -752,5 +774,5 @@ entries:
   - apiVersion: v1
     appVersion: RELEASE.2021-12-18T04-42-33Z
-    created: ""2022-07-29T16:39:37.303623867-07:00""
+    created: ""2022-08-02T19:11:03.98907423-07:00""
     description: Multi-Cloud Object Storage
     digest: fa8ba1aeb1a15316c6be8403416a5e6b5e6139b7166592087e7bddc9e6db5453
@@ -774,5 +796,5 @@ entries:
   - apiVersion: v1
     appVersion: RELEASE.2021-12-10T23-03-39Z
-    created: ""2022-07-29T16:39:37.302730128-07:00""
+    created: ""2022-08-02T19:11:03.987843029-07:00""
     description: Multi-Cloud Object Storage
     digest: b9b0af9ca50b8d00868e1f1b989dca275829d9110af6de91bb9b3a398341e894
@@ -796,5 +818,5 @@ entries:
   - apiVersion: v1
     appVersion: RELEASE.2021-12-10T23-03-39Z
-    created: ""2022-07-29T16:39:37.301936062-07:00""
+    created: ""2022-08-02T19:11:03.986671987-07:00""
     description: Multi-Cloud Object Storage
     digest: f8b22a5b8fe95a7ddf61b825e17d11c9345fb10e4c126b0d78381608aa300a08
@@ -818,5 +840,5 @@ entries:
   - apiVersion: v1
     appVersion: RELEASE.2021-12-10T23-03-39Z
-    created: ""2022-07-29T16:39:37.301077896-07:00""
+    created: ""2022-08-02T19:11:03.985462954-07:00""
     description: Multi-Cloud Object Storage
     digest: c48d474f269427abe5ab446f00687d0625b3d1adfc5c73bdb4b21ca9e42853fb
@@ -840,5 +862,5 @@ entries:
   - apiVersion: v1
     appVersion: RELEASE.2021-11-24T23-19-33Z
-    created: ""2022-07-29T16:39:37.299632923-07:00""
+    created: ""2022-08-02T19:11:03.984023083-07:00""
     description: Multi-Cloud Object Storage
     digest: 7c3da39d9b0090cbf5efedf0cc163a1e2df05becc5152c3add8e837384690bc4
@@ -862,5 +884,5 @@ entries:
   - apiVersion: v1
     appVersion: RELEASE.2021-11-24T23-19-33Z
-    created: ""2022-07-29T16:39:37.298683702-07:00""
+    created: ""2022-08-02T19:11:03.982443698-07:00""
     description: Multi-Cloud Object Storage
     digest: 50d6590b4cc779c40f81cc13b1586fbe508aa7f3230036c760bfc5f4154fbce4
@@ -884,5 +906,5 @@ entries:
   - apiVersion: v1
     appVersion: RELEASE.2021-10-13T00-23-17Z
-    created: ""2022-07-29T16:39:37.297437447-07:00""
+    created: ""2022-08-02T19:11:03.981241476-07:00""
     description: Multi-Cloud Object Storage
     digest: 5b797b7208cd904c11a76cd72938c8652160cb5fcd7f09fa41e4e703e6d64054
@@ -906,5 +928,5 @@ entries:
   - apiVersion: v1
     appVersion: RELEASE.2021-10-10T16-53-30Z
-    created: ""2022-07-29T16:39:37.296638572-07:00""
+    created: ""2022-08-02T19:11:03.980004766-07:00""
     description: Multi-Cloud Object Storage
     digest: e084ac4bb095f071e59f8f08bd092e4ab2404c1ddadacfdce7dbe248f1bafff8
@@ -928,5 +950,5 @@ entries:
   - apiVersion: v1
     appVersion: RELEASE.2021-10-06T23-36-31Z
-    created: ""2022-07-29T16:39:37.295702714-07:00""
+    created: ""2022-08-02T19:11:03.978848439-07:00""
     description: Multi-Cloud Object Storage
     digest: 2890430a8d9487d1fa5508c26776e4881d0086b2c052aa6bdc65c0e4423b9159
@@ -950,5 +972,5 @@ entries:
   - apiVersion: v1
     appVersion: RELEASE.2021-10-02T16-31-05Z
-    created: ""2022-07-29T16:39:37.294809819-07:00""
+    created: ""2022-08-02T19:11:03.977640904-07:00""
     description: Multi-Cloud Object Storage
     digest: 01a92196af6c47e3a01e1c68d7cf693a8bc487cba810c2cecff155071e4d6a11
@@ -972,5 +994,5 @@ entries:
   - apiVersion: v1
     appVersion: RELEASE.2021-09-18T18-09-59Z
-    created: ""2022-07-29T16:39:37.294026222-07:00""
+    created: ""2022-08-02T19:11:03.976378442-07:00""
     description: Multi-Cloud Object Storage
     digest: e779d73f80b75f33b9c9d995ab10fa455c9c57ee575ebc54e06725a64cd04310
@@ -994,5 +1016,5 @@ entries:
   - apiVersion: v1
     appVersion: RELEASE.2021-09-18T18-09-59Z
-    created: ""2022-07-29T16:39:37.291665007-07:00""
+    created: ""2022-08-02T19:11:03.974375742-07:00""
     description: Multi-Cloud Object Storage
     digest: 19de4bbc8a400f0c2a94c5e85fc25c9bfc666e773fb3e368dd621d5a57dd1c2a
@@ -1016,5 +1038,5 @@ entries:
   - apiVersion: v1
     appVersion: RELEASE.2021-09-18T18-09-59Z
-    created: ""2022-07-29T16:39:37.290864229-07:00""
+    created: ""2022-08-02T19:11:03.973111156-07:00""
     description: Multi-Cloud Object Storage
     digest: f789d93a171296dd01af0105a5ce067c663597afbb2432faeda293b752b355c0
@@ -1038,5 +1060,5 @@ entries:
   - apiVersion: v1
     appVersion: RELEASE.2021-09-09T21-37-07Z
-    created: ""2022-07-29T16:39:37.289936482-07:00""
+    created: ""2022-08-02T19:11:03.971853851-07:00""
     description: Multi-Cloud Object Storage
     digest: e2eb34d31560b012ef6581f0ff6004ea4376c968cbe0daed2d8f3a614a892afb
@@ -1060,5 +1082,5 @@ entries:
   - apiVersion: v1
     appVersion: RELEASE.2021-09-09T21-37-07Z
-    created: ""2022-07-29T16:39:37.289095277-07:00""
+    created: ""2022-08-02T19:11:03.970642759-07:00""
     description: Multi-Cloud Object Storage
     digest: 8d7e0cc46b3583abd71b97dc0c071f98321101f90eca17348f1e9e0831be64cd
@@ -1082,5 +1104,5 @@ entries:
   - apiVersion: v1
     appVersion: RELEASE.2021-09-09T21-37-07Z
-    created: ""2022-07-29T16:39:37.288205835-07:00""
+    created: ""2022-08-02T19:11:03.96941149-07:00""
     description: Multi-Cloud Object Storage
     digest: 50dcbf366b1b21f4a6fc429d0b884c0c7ff481d0fb95c5e9b3ae157c348dd124
@@ -1104,5 +1126,5 @@ entries:
   - apiVersion: v1
     appVersion: RELEASE.2021-09-09T21-37-07Z
-    created: ""2022-07-29T16:39:37.287243808-07:00""
+    created: ""2022-08-02T19:11:03.968117178-07:00""
     description: Multi-Cloud Object Storage
     digest: 6c01af55d2e2e5f716eabf6fef3a92a8464d0674529e9bacab292e5478a73b7a
@@ -1126,5 +1148,5 @@ entries:
   - apiVersion: v1
     appVersion: RELEASE.2021-09-03T03-56-13Z
-    created: ""2022-07-29T16:39:37.286100178-07:00""
+    created: ""2022-08-02T19:11:03.966468625-07:00""
     description: Multi-Cloud Object Storage
     digest: 18e10be4d0458bc590ca9abf753227e0c70f60511495387b8d4fb15a4daf932e
@@ -1148,5 +1170,5 @@ entries:
   - apiVersion: v1
     appVersion: RELEASE.2021-08-31T05-46-54Z
-    created: ""2022-07-29T16:39:37.284950859-07:00""
+    created: ""2022-08-02T19:11:03.965066966-07:00""
     description: Multi-Cloud Object Storage
     digest: f5b6e7f6272a9e71aef3b75555f6f756a39eef65cb78873f26451dba79b19906
@@ -1170,5 +1192,5 @@ entries:
   - apiVersion: v1
     appVersion: RELEASE.2021-08-31T05-46-54Z
-    created: ""2022-07-29T16:39:37.284048713-07:00""
+    created: ""2022-08-02T19:11:03.963834888-07:00""
     description: Multi-Cloud Object Storage
     digest: 6d2ee1336c412affaaf209fdb80215be2a6ebb23ab2443adbaffef9e7df13fab
@@ -1192,5 +1214,5 @@ entries:
   - apiVersion: v1
     appVersion: RELEASE.2021-08-31T05-46-54Z
-    created: ""2022-07-29T16:39:37.283103024-07:00""
+    created: ""2022-08-02T19:11:03.96265087-07:00""
     description: Multi-Cloud Object Storage
     digest: 0a004aaf5bb61deed6a5c88256d1695ebe2f9ff1553874a93e4acfd75e8d339b
@@ -1212,5 +1234,5 @@ entries:
   - apiVersion: v1
     appVersion: RELEASE.2021-08-25T00-41-18Z
-    created: ""2022-07-29T16:39:37.282144407-07:00""
+    created: ""2022-08-02T19:11:03.961414581-07:00""
     description: Multi-Cloud Object Storage
     digest: fcd944e837ee481307de6aa3d387ea18c234f995a84c15abb211aab4a4054afc
@@ -1232,5 +1254,5 @@ entries:
   - apiVersion: v1
     appVersion: RELEASE.2021-08-25T00-41-18Z
-    created: ""2022-07-29T16:39:37.280943466-07:00""
+    created: ""2022-08-02T19:11:03.960111677-07:00""
     description: Multi-Cloud Object Storage
     digest: 7b6c033d43a856479eb493ab8ca05b230f77c3e42e209e8f298fac6af1a9796f
@@ -1252,5 +1274,5 @@ entries:
   - apiVersion: v1
     appVersion: RELEASE.2021-08-25T00-41-18Z
-    created: ""2022-07-29T16:39:37.279677527-07:00""
+    created: ""2022-08-02T19:11:03.958894086-07:00""
     description: Multi-Cloud Object Storage
     digest: abd221245ace16c8e0c6c851cf262d1474a5219dcbf25c4b2e7b77142f9c59ed
@@ -1272,5 +1294,5 @@ entries:
   - apiVersion: v1
     appVersion: RELEASE.2021-08-20T18-32-01Z
-    created: ""2022-07-29T16:39:37.278589589-07:00""
+    created: ""2022-08-02T19:11:03.957387759-07:00""
     description: Multi-Cloud Object Storage
     digest: 922a333f5413d1042f7aa81929f43767f6ffca9b260c46713f04ce1dda86d57d
@@ -1292,5 +1314,5 @@ entries:
   - apiVersion: v1
     appVersion: RELEASE.2021-08-20T18-32-01Z
-    created: ""2022-07-29T16:39:37.277344409-07:00""
+    created: ""2022-08-02T19:11:03.955827342-07:00""
     description: High Performance, Kubernetes Native Object Storage
     digest: 10e22773506bbfb1c66442937956534cf4057b94f06a977db78b8cd223588388
@@ -1312,5 +1334,5 @@ entries:
   - apiVersion: v1
     appVersion: RELEASE.2021-08-20T18-32-01Z
-    created: ""2022-07-29T16:39:37.27655914-07:00""
+    created: ""2022-08-02T19:11:03.954606236-07:00""
     description: High Performance, Kubernetes Native Object Storage
     digest: ef86ab6df23d6942705da9ef70991b649638c51bc310587d37a425268ba4a06c
@@ -1332,5 +1354,5 @@ entries:
   - apiVersion: v1
     appVersion: RELEASE.2021-08-17T20-53-08Z
-    created: ""2022-07-29T16:39:37.275640295-07:00""
+    created: ""2022-08-02T19:11:03.953438494-07:00""
     description: High Performance, Kubernetes Native Object Storage
     digest: 1add7608692cbf39aaf9b1252530e566f7b2f306a14e390b0f49b97a20f2b188
@@ -1350,3 +1372,3 @@ entries:
     - https://charts.min.io/helm-releases/minio-1.0.0.tgz
     version: 1.0.0
-generated: ""2022-07-29T16:39:37.272439913-07:00""
+generated: ""2022-08-02T19:11:03.952087375-07:00""
","upgrade helm v4.0.9

"
457,Go,c1a6ca0c335d66a004f452efcaf278ad63135de1,https://github.com/minio/minio/commit/c1a6ca0c335d66a004f452efcaf278ad63135de1,P,minio,minio,"[1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/cmd/lock-rpc-server.go b/cmd/lock-rpc-server.go
index 6de6a965d..70c5d77ff 100644
--- a/cmd/lock-rpc-server.go
+++ b/cmd/lock-rpc-server.go
@@ -65,5 +65,5 @@ type lockServer struct {
 
 // Start lock maintenance from all lock servers.
-func startLockMaintainence(lockServers []*lockServer) {
+func startLockMaintenance(lockServers []*lockServer) {
 	for _, locker := range lockServers {
 		// Start loop for stale lock maintenance
@@ -91,5 +91,5 @@ func startLockMaintainence(lockServers []*lockServer) {
 func registerDistNSLockRouter(mux *router.Router, endpoints EndpointList) error {
 	// Start lock maintenance from all lock servers.
-	startLockMaintainence(globalLockServers)
+	startLockMaintenance(globalLockServers)
 
 	// Register initialized lock servers to their respective rpc endpoints.
","Fix spelling of function name to `startLockMaintenance` (#4561)


"
460,Go,856e0100c07448a6711ed77b6a2cf3439a424892,https://github.com/minio/minio/commit/856e0100c07448a6711ed77b6a2cf3439a424892,P,minio,minio,"[2, 54, 64, 0, 31, 27, 0, 1, 2, 4, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/pkg/storage/donut/erasure/erasure1/erasure.go b/pkg/storage/donut/erasure/erasure1/erasure.go
new file mode 100644
index 000000000..b4719f94a
--- /dev/null
+++ b/pkg/storage/donut/erasure/erasure1/erasure.go
@@ -0,0 +1,98 @@
+/*
+ * Mini Object Storage, (C) 2015 Minio, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package erasure1
+
+import (
+	""bytes""
+	""encoding/binary""
+	""encoding/gob""
+	""errors""
+	""io""
+)
+
+// DataHeader represents the structure serialized to gob.
+type DataHeader struct {
+	// object + block stored
+	Key string
+	// chunk index of encoded block
+	ChunkIndex uint8
+	// Original Length of the block output
+	OriginalLength uint32
+	// Data Blocks
+	EncoderK uint8
+	// Parity Blocks
+	EncoderM uint8
+	// Matrix Technique
+	EncoderTechnique EncoderTechnique
+}
+
+// EncoderTechnique specified the Matrix type used in encoding
+type EncoderTechnique int
+
+const (
+	// Vandermonde matrix type
+	Vandermonde EncoderTechnique = iota
+	// Cauchy matrix type
+	Cauchy
+)
+
+// validate populated header
+func validateHeader(header DataHeader) error {
+	if header.Key == """" {
+		return errors.New(""Empty Key"")
+	}
+
+	if header.EncoderTechnique > 1 {
+		return errors.New(""Invalid encoder technique"")
+	}
+
+	return nil
+}
+
+// WriteData returns error upon any failure
+func Write(target io.Writer, key string, part uint8, length uint32, k, m uint8, technique EncoderTechnique, data io.Reader) error {
+	header := DataHeader{
+		Key:              key,
+		ChunkIndex:       part,
+		OriginalLength:   length,
+		EncoderK:         k,
+		EncoderM:         m,
+		EncoderTechnique: technique,
+	}
+
+	if err := validateHeader(header); err != nil {
+		return err
+	}
+
+	var headerBuffer bytes.Buffer
+	// encode header
+	encoder := gob.NewEncoder(&headerBuffer)
+	encoder.Encode(header)
+
+	// write version
+	binary.Write(target, binary.LittleEndian, uint32(1))
+
+	// write encoded header
+	if _, err := io.Copy(target, &headerBuffer); err != nil {
+		return err
+	}
+	// write data
+	if _, err := io.Copy(target, data); err != nil {
+		return err
+	}
+	return nil
+}
diff --git a/pkg/storage/donut/erasure/erasure_v1/erasure_test.go b/pkg/storage/donut/erasure/erasure1/erasure_test.go
similarity index 75%
rename from pkg/storage/donut/erasure/erasure_v1/erasure_test.go
rename to pkg/storage/donut/erasure/erasure1/erasure_test.go
index a5bcce02a..8111aeab8 100644
--- a/pkg/storage/donut/erasure/erasure_v1/erasure_test.go
+++ b/pkg/storage/donut/erasure/erasure1/erasure_test.go
@@ -15,5 +15,5 @@
  */
 
-package erasure
+package erasure1
 
 import (
@@ -36,17 +36,14 @@ func (s *MySuite) TestSingleWrite(c *C) {
 	var testBuffer bytes.Buffer
 	testData := ""Hello, World""
-	encoderParams := EncoderParams{
-		Length:    uint32(len(testData)),
-		K:         8,
-		M:         8,
-		Technique: Cauchy,
+	testHeader := DataHeader{
+		Key:              ""testobj"",
+		ChunkIndex:       1,
+		OriginalLength:   uint32(len(testData)),
+		EncoderK:         8,
+		EncoderM:         8,
+		EncoderTechnique: Cauchy,
 	}
-	metadata := make(Metadata)
-	metadata[""Content-Type""] = ""application/octet-stream""
-	metadata[""Content-MD5""] = ""testing""
 
-	header := NewHeader(""testobj"", 1, metadata, encoderParams)
-
-	err := WriteData(&testBuffer, header, bytes.NewBufferString(testData))
+	err := Write(&testBuffer, testHeader.Key, testHeader.ChunkIndex, testHeader.OriginalLength, testHeader.EncoderK, testHeader.EncoderM, testHeader.EncoderTechnique, bytes.NewBufferString(testData))
 	c.Assert(err, IsNil)
 
@@ -61,5 +58,5 @@ func (s *MySuite) TestSingleWrite(c *C) {
 	decoder.Decode(&actualHeader)
 
-	c.Assert(actualHeader, DeepEquals, header)
+	c.Assert(actualHeader, DeepEquals, testHeader)
 
 	var actualData bytes.Buffer
diff --git a/pkg/storage/donut/erasure/erasure_v1/erasure.go b/pkg/storage/donut/erasure/erasure_v1/erasure.go
deleted file mode 100644
index 16ba4ba4a..000000000
--- a/pkg/storage/donut/erasure/erasure_v1/erasure.go
+++ /dev/null
@@ -1,106 +0,0 @@
-/*
- * Mini Object Storage, (C) 2015 Minio, Inc.
- *
- * Licensed under the Apache License, Version 2.0 (the ""License"");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an ""AS IS"" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package erasure
-
-import (
-	""bytes""
-	""encoding/binary""
-	""encoding/gob""
-	""fmt""
-	""io""
-)
-
-// Metadata map
-type Metadata map[string]string
-
-// DataHeader struct
-type DataHeader struct {
-	Key           string
-	Part          uint8
-	Metadata      Metadata
-	EncoderParams EncoderParams
-}
-
-// EncoderTechnique type
-type EncoderTechnique int
-
-// EncoderTechniques
-const (
-	Vandermonde EncoderTechnique = iota
-	Cauchy
-)
-
-// EncoderParams struct
-type EncoderParams struct {
-	Length    uint32
-	K         uint8
-	M         uint8
-	Technique EncoderTechnique
-}
-
-// NewHeader populate new header
-func NewHeader(key string, part uint8, metadata Metadata, encoderParams EncoderParams) DataHeader {
-	header := DataHeader{}
-	header.Key = key
-	header.Part = part
-	header.Metadata = metadata
-	header.EncoderParams = EncoderParams{
-		Length:    encoderParams.Length,
-		K:         encoderParams.K,
-		M:         encoderParams.M,
-		Technique: encoderParams.Technique,
-	}
-	return header
-}
-
-// ValidateHeader validate populated header
-func ValidateHeader(header DataHeader) bool {
-	if header.Key == """" || header.Part < 0 || len(header.Metadata) < 2 {
-		return false
-	}
-
-	if header.EncoderParams.Length < 0 || header.EncoderParams.Technique > 1 {
-		return false
-	}
-
-	return true
-}
-
-// WriteData write data, returns error upon any failure
-func WriteData(target io.Writer, header DataHeader, data io.Reader) error {
-	if !ValidateHeader(header) {
-		return fmt.Errorf(""Invalid header"")
-	}
-
-	var headerBuffer bytes.Buffer
-	// encode header
-	encoder := gob.NewEncoder(&headerBuffer)
-	encoder.Encode(header)
-
-	// write version
-	binary.Write(target, binary.LittleEndian, uint32(1))
-
-	// write encoded header
-	if _, err := io.Copy(target, &headerBuffer); err != nil {
-		return err
-	}
-	// write data
-	if _, err := io.Copy(target, data); err != nil {
-		return err
-	}
-	return nil
-}
","Erasure layer now writes using new technique

"
473,JavaScript,cb4a0af7dd32130b58bcfe9bcf2bdb9978c92cf5,https://github.com/facebook/react/commit/cb4a0af7dd32130b58bcfe9bcf2bdb9978c92cf5,P,facebook,react,"[1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/src/renderers/art/ReactART.js b/src/renderers/art/ReactART.js
index e01df8939..be85e1f23 100644
--- a/src/renderers/art/ReactART.js
+++ b/src/renderers/art/ReactART.js
@@ -235,10 +235,8 @@ const Surface = React.createClass({
     return (
       <Tag
-        accesskey={props.accesskey}
         className={props.className}
         draggable={props.draggable}
         role={props.role}
         style={props.style}
-        tabindex={props.tabindex}
         title={props.title}
       />
","Remove unknown props in ART (#6861)
"
476,JavaScript,9ebd0c9e9a167f6cf30138a7b64c0c36d5bbbd11,https://github.com/facebook/react/commit/9ebd0c9e9a167f6cf30138a7b64c0c36d5bbbd11,P,facebook,react,"[1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 6, 0, 0, 69, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/package.json b/package.json
index 062609c3a..265f96259 100644
--- a/package.json
+++ b/package.json
@@ -2,5 +2,5 @@
   ""name"": ""react-build"",
   ""private"": true,
-  ""version"": ""16.0.0-beta.3"",
+  ""version"": ""16.0.0-beta.4"",
   ""devDependencies"": {
     ""aliasify"": ""^2.0.0"",
diff --git a/packages/react-art/package.json b/packages/react-art/package.json
index 0b349da33..d152e880a 100644
--- a/packages/react-art/package.json
+++ b/packages/react-art/package.json
@@ -1,5 +1,5 @@
 {
   ""name"": ""react-art"",
-  ""version"": ""16.0.0-beta.3"",
+  ""version"": ""16.0.0-beta.4"",
   ""description"": ""React ART is a JavaScript library for drawing vector graphics using React. It provides declarative and reactive bindings to the ART library. Using the same declarative API you can render the output to either Canvas, SVG or VML (IE8)."",
   ""main"": ""index.js"",
@@ -24,5 +24,5 @@
   },
   ""peerDependencies"": {
-    ""react"": ""^16.0.0-beta.3""
+    ""react"": ""^16.0.0-beta.4""
   },
   ""files"": [
diff --git a/packages/react-dom/package.json b/packages/react-dom/package.json
index 5d08c1ebb..3a97d254c 100644
--- a/packages/react-dom/package.json
+++ b/packages/react-dom/package.json
@@ -1,5 +1,5 @@
 {
   ""name"": ""react-dom"",
-  ""version"": ""16.0.0-beta.3"",
+  ""version"": ""16.0.0-beta.4"",
   ""description"": ""React package for working with the DOM."",
   ""main"": ""index.js"",
@@ -20,5 +20,5 @@
   },
   ""peerDependencies"": {
-    ""react"": ""^16.0.0-beta.3""
+    ""react"": ""^16.0.0-beta.4""
   },
   ""files"": [
diff --git a/packages/react-noop-renderer/package.json b/packages/react-noop-renderer/package.json
index caebf22c9..ad0691c7d 100644
--- a/packages/react-noop-renderer/package.json
+++ b/packages/react-noop-renderer/package.json
@@ -1,5 +1,5 @@
 {
   ""name"": ""react-noop-renderer"",
-  ""version"": ""16.0.0-beta.3"",
+  ""version"": ""16.0.0-beta.4"",
   ""private"": true,
   ""description"": ""React package for testing the Fiber reconciler."",
diff --git a/packages/react-test-renderer/package.json b/packages/react-test-renderer/package.json
index d32555139..af547b983 100644
--- a/packages/react-test-renderer/package.json
+++ b/packages/react-test-renderer/package.json
@@ -1,5 +1,5 @@
 {
   ""name"": ""react-test-renderer"",
-  ""version"": ""16.0.0-beta.3"",
+  ""version"": ""16.0.0-beta.4"",
   ""description"": ""React package for snapshot testing."",
   ""main"": ""index.js"",
@@ -20,5 +20,5 @@
   },
   ""peerDependencies"": {
-    ""react"": ""^16.0.0-beta.3""
+    ""react"": ""^16.0.0-beta.4""
   },
   ""files"": [
diff --git a/packages/react/package.json b/packages/react/package.json
index ab3aedb2a..1daa84830 100644
--- a/packages/react/package.json
+++ b/packages/react/package.json
@@ -2,5 +2,5 @@
   ""name"": ""react"",
   ""description"": ""React is a JavaScript library for building user interfaces."",
-  ""version"": ""16.0.0-beta.3"",
+  ""version"": ""16.0.0-beta.4"",
   ""keywords"": [
     ""react""
diff --git a/scripts/rollup/results.json b/scripts/rollup/results.json
index 1141df423..883acc03a 100644
--- a/scripts/rollup/results.json
+++ b/scripts/rollup/results.json
@@ -26,38 +26,38 @@
     },
     ""react-dom.development.js (UMD_DEV)"": {
-      ""size"": 634973,
-      ""gzip"": 144789
+      ""size"": 634231,
+      ""gzip"": 144541
     },
     ""react-dom.production.min.js (UMD_PROD)"": {
-      ""size"": 119734,
-      ""gzip"": 38187
+      ""size"": 119426,
+      ""gzip"": 38138
     },
     ""react-dom.development.js (NODE_DEV)"": {
-      ""size"": 594382,
-      ""gzip"": 135201
+      ""size"": 593640,
+      ""gzip"": 134958
     },
     ""react-dom.production.min.js (NODE_PROD)"": {
-      ""size"": 116650,
-      ""gzip"": 37146
+      ""size"": 116342,
+      ""gzip"": 37065
     },
     ""ReactDOMFiber-dev.js (FB_DEV)"": {
-      ""size"": 591210,
-      ""gzip"": 134689
+      ""size"": 590470,
+      ""gzip"": 134456
     },
     ""ReactDOMFiber-prod.js (FB_PROD)"": {
-      ""size"": 424757,
-      ""gzip"": 95144
+      ""size"": 424217,
+      ""gzip"": 94997
     },
     ""react-dom-test-utils.development.js (NODE_DEV)"": {
-      ""size"": 53568,
-      ""gzip"": 13486
+      ""size"": 53312,
+      ""gzip"": 13394
     },
     ""ReactTestUtils-dev.js (FB_DEV)"": {
-      ""size"": 53378,
-      ""gzip"": 13448
+      ""size"": 53124,
+      ""gzip"": 13357
     },
     ""react-dom-unstable-native-dependencies.development.js (UMD_DEV)"": {
       ""size"": 88255,
-      ""gzip"": 22338
+      ""gzip"": 22340
     },
     ""react-dom-unstable-native-dependencies.production.min.js (UMD_PROD)"": {
@@ -82,94 +82,94 @@
     },
     ""react-dom-server.browser.development.js (UMD_DEV)"": {
-      ""size"": 123129,
-      ""gzip"": 31128
+      ""size"": 122873,
+      ""gzip"": 31036
     },
     ""react-dom-server.browser.production.min.js (UMD_PROD)"": {
-      ""size"": 21353,
-      ""gzip"": 8162
+      ""size"": 21199,
+      ""gzip"": 8114
     },
     ""react-dom-server.browser.development.js (NODE_DEV)"": {
-      ""size"": 92285,
-      ""gzip"": 23724
+      ""size"": 92049,
+      ""gzip"": 23628
     },
     ""react-dom-server.browser.production.min.js (NODE_PROD)"": {
-      ""size"": 20116,
-      ""gzip"": 7657
+      ""size"": 19962,
+      ""gzip"": 7604
     },
     ""ReactDOMServer-dev.js (FB_DEV)"": {
-      ""size"": 91498,
-      ""gzip"": 23652
+      ""size"": 91242,
+      ""gzip"": 23555
     },
     ""ReactDOMServer-prod.js (FB_PROD)"": {
-      ""size"": 49904,
-      ""gzip"": 13944
+      ""size"": 49636,
+      ""gzip"": 13861
     },
     ""react-dom-server.node.development.js (NODE_DEV)"": {
-      ""size"": 95018,
-      ""gzip"": 24291
+      ""size"": 94782,
+      ""gzip"": 24195
     },
     ""react-dom-server.node.production.min.js (NODE_PROD)"": {
-      ""size"": 21207,
-      ""gzip"": 8013
+      ""size"": 21053,
+      ""gzip"": 7964
     },
     ""react-art.development.js (UMD_DEV)"": {
-      ""size"": 373741,
-      ""gzip"": 82785
+      ""size"": 373477,
+      ""gzip"": 82691
     },
     ""react-art.production.min.js (UMD_PROD)"": {
-      ""size"": 93224,
-      ""gzip"": 28829
+      ""size"": 93070,
+      ""gzip"": 28782
     },
     ""react-art.development.js (NODE_DEV)"": {
-      ""size"": 295128,
-      ""gzip"": 62771
+      ""size"": 294864,
+      ""gzip"": 62680
     },
     ""react-art.production.min.js (NODE_PROD)"": {
-      ""size"": 55164,
+      ""size"": 55010,
       ""gzip"": 16977
     },
     ""ReactARTFiber-dev.js (FB_DEV)"": {
-      ""size"": 294057,
-      ""gzip"": 62846
+      ""size"": 293795,
+      ""gzip"": 62752
     },
     ""ReactARTFiber-prod.js (FB_PROD)"": {
-      ""size"": 219827,
-      ""gzip"": 45605
+      ""size"": 219555,
+      ""gzip"": 45520
     },
     ""ReactNativeStack-dev.js (RN_DEV)"": {
-      ""size"": 201902,
-      ""gzip"": 37570
+      ""size"": 201024,
+      ""gzip"": 37385
     },
     ""ReactNativeStack-prod.js (RN_PROD)"": {
-      ""size"": 138226,
-      ""gzip"": 26573
+      ""size"": 137686,
+      ""gzip"": 26481
     },
     ""ReactNativeFiber-dev.js (RN_DEV)"": {
-      ""size"": 307333,
-      ""gzip"": 53302
+      ""size"": 306159,
+      ""gzip"": 53035
     },
     ""ReactNativeFiber-prod.js (RN_PROD)"": {
-      ""size"": 222948,
-      ""gzip"": 38742
+      ""size"": 222136,
+      ""gzip"": 38567
     },
     ""react-test-renderer.development.js (NODE_DEV)"": {
-      ""size"": 292928,
-      ""gzip"": 61669
+      ""size"": 299936,
+      ""gzip"": 63221
     },
     ""ReactTestRendererFiber-dev.js (FB_DEV)"": {
-      ""size"": 291856,
-      ""gzip"": 61755
+      ""size"": 298876,
+      ""gzip"": 63302
     },
     ""react-test-renderer-shallow.development.js (NODE_DEV)"": {
-      ""size"": 9812,
-      ""gzip"": 2482
+      ""size"": 9556,
+      ""gzip"": 2379
     },
     ""ReactShallowRenderer-dev.js (FB_DEV)"": {
-      ""size"": 9718,
-      ""gzip"": 2439
+      ""size"": 9464,
+      ""gzip"": 2338
     },
     ""react-noop-renderer.development.js (NODE_DEV)"": {
-      ""size"": 286835,
-      ""gzip"": 60082
+      ""size"": 286575,
+      ""gzip"": 59988
     }
   }
diff --git a/src/ReactVersion.js b/src/ReactVersion.js
index 6ff15cb23..eca02fefe 100644
--- a/src/ReactVersion.js
+++ b/src/ReactVersion.js
@@ -12,3 +12,3 @@
 'use strict';
 
-module.exports = '16.0.0-beta.3';
+module.exports = '16.0.0-beta.4';
","Updated packages and results JSON for 16 beta 4

"
487,JavaScript,1965f032ca27c6a44df08131fca691b246fd0b91,https://github.com/twbs/bootstrap/commit/1965f032ca27c6a44df08131fca691b246fd0b91,P,twbs,bootstrap,"[1, 0, 6, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/Gruntfile.js b/Gruntfile.js
index 486b0417f..7738ab89f 100644
--- a/Gruntfile.js
+++ b/Gruntfile.js
@@ -292,17 +292,10 @@ module.exports = function (grunt) {
     copy: {
       fonts: {
-        expand: true,
         src: 'fonts/*',
         dest: 'dist/'
       },
       docs: {
-        expand: true,
-        cwd: './dist',
-        src: [
-          'css/*',
-          'js/*',
-          'fonts/*'
-        ],
-        dest: 'docs/dist'
+        src: 'dist/*/*',
+        dest: 'docs/'
       }
     },
","Gruntfile.js: Simplify copy task.

"
498,JavaScript,269efc8dc90836f54eb2695cf6463481d35ad48f,https://github.com/twbs/bootstrap/commit/269efc8dc90836f54eb2695cf6463481d35ad48f,P,twbs,bootstrap,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/config.yml b/config.yml
index 616993e15..a54d5bc6c 100644
--- a/config.yml
+++ b/config.yml
@@ -76,4 +76,4 @@ params:
     js_bundle:        ""https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta1/dist/js/bootstrap.bundle.min.js""
     js_bundle_hash:   ""sha384-ygbV9kiqUc6oa4msXn9868pTtWMgiQaeYH7/t7LECLbyPA2x65Kgf80OJFdroafW""
-    popper:           ""https://cdn.jsdelivr.net/npm/@popperjs/core@2.5.4/dist/umd/popper.min.js""
-    popper_hash:      ""sha384-q2kxQ16AaE6UbzuKqyBE9/u/KzioAlnx2maXQHiDX9d4/zp8Ok3f+M7DPm+Ib6IU""
+    popper:           ""https://cdn.jsdelivr.net/npm/@popperjs/core@2.6.0/dist/umd/popper.min.js""
+    popper_hash:      ""sha384-KsvD1yqQ1/1+IA7gi3P0tyJcT3vR+NdBTt13hSJ2lnve8agRGXTTyNaBYmCR/Nwi""
diff --git a/package-lock.json b/package-lock.json
index 8a88da988..8d835ff5b 100644
--- a/package-lock.json
+++ b/package-lock.json
@@ -1141,7 +1141,7 @@
     },
     ""@popperjs/core"": {
-      ""version"": ""2.5.4"",
-      ""resolved"": ""https://registry.npmjs.org/@popperjs/core/-/core-2.5.4.tgz"",
-      ""integrity"": ""sha512-ZpKr+WTb8zsajqgDkvCEWgp6d5eJT6Q63Ng2neTbzBO76Lbe91vX/iVIW9dikq+Fs3yEo+ls4cxeXABD2LtcbQ=="",
+      ""version"": ""2.6.0"",
+      ""resolved"": ""https://registry.npmjs.org/@popperjs/core/-/core-2.6.0.tgz"",
+      ""integrity"": ""sha512-cPqjjzuFWNK3BSKLm0abspP0sp/IGOli4p5I5fKFAzdS8fvjdOwDCfZqAaIiXd9lPkOWi3SUUfZof3hEb7J/uw=="",
       ""dev"": true
     },
diff --git a/package.json b/package.json
index e1e601760..4e82b78ca 100644
--- a/package.json
+++ b/package.json
@@ -96,5 +96,5 @@
   ""dependencies"": {},
   ""peerDependencies"": {
-    ""@popperjs/core"": ""^2.5.4""
+    ""@popperjs/core"": ""^2.6.0""
   },
   ""devDependencies"": {
@@ -102,5 +102,5 @@
     ""@babel/core"": ""^7.12.10"",
     ""@babel/preset-env"": ""^7.12.10"",
-    ""@popperjs/core"": ""^2.5.4"",
+    ""@popperjs/core"": ""^2.6.0"",
     ""@rollup/plugin-babel"": ""^5.2.2"",
     ""@rollup/plugin-commonjs"": ""^17.0.0"",
@@ -169,5 +169,5 @@
     ""dependencies"": {},
     ""peerDependencies"": {
-      ""@popperjs/core"": ""^2.5.4""
+      ""@popperjs/core"": ""^2.6.0""
     }
   }
","Bump @popperjs/core from 2.5.4 to 2.6.0 (#32487)

* Bump @popperjs/core from 2.5.4 to 2.6.0

Bumps [@popperjs/core](https://github.com/popperjs/popper-core) from 2.5.4 to 2.6.0.
- [Release notes](https://github.com/popperjs/popper-core/releases)
- [Commits](https://github.com/popperjs/popper-core/compare/v2.5.4...v2.6.0)

Signed-off-by: dependabot[bot] <support@github.com>

* Update config.yml

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>
Co-authored-by: XhmikosR <xhmikosr@gmail.com>
"
520,JavaScript,f012eab00f9abd2b34f82edc42d84458cbf414a8,https://github.com/vercel/next.js/commit/f012eab00f9abd2b34f82edc42d84458cbf414a8,P,vercel,next.js,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1]","diff --git a/packages/next/server/app-render.tsx b/packages/next/server/app-render.tsx
index 472103a98..be0bf6eb6 100644
--- a/packages/next/server/app-render.tsx
+++ b/packages/next/server/app-render.tsx
@@ -53,5 +53,5 @@ function preloadComponent(Component: any, props: any) {
   const prev = console.error
   // Hide invalid hook call warning when calling component
-  console.error = (msg) => {
+  console.error = function (msg) {
     if (msg.startsWith('Invalid hook call..')) {
       // ignore
","use a function expression to access arguments binding (#43987)

arrow function was trying to use arguments binding but wanted arguments
of the lambda not the nearest normal function. The narrowest change is
to convert to function expression. We could also use varargs rest syntax
since this runs in runtimes that should all support that I think. I
don't think it really matters though.

## Bug

- [ ] Related issues linked using `fixes #number`
- [ ] Integration tests added
- [ ] Errors have a helpful link attached, see
[`contributing.md`](https://github.com/vercel/next.js/blob/canary/contributing.md)

## Documentation / Examples

- [ ] Make sure the linting passes by running `pnpm build && pnpm lint`
"
543,JavaScript,9a4d7ac236eb101a290f2809c20538fd87677ec9,https://github.com/axios/axios/commit/9a4d7ac236eb101a290f2809c20538fd87677ec9,P,axios,axios,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/package.json b/package.json
index 90702cc..321b6d3 100644
--- a/package.json
+++ b/package.json
@@ -53,4 +53,5 @@
     ""karma-jasmine-ajax"": ""^0.1.13"",
     ""karma-safari-launcher"": ""^1.0.0"",
+    ""karma-sauce-launcher"": ""^1.2.0"",
     ""karma-sinon"": ""^1.0.5"",
     ""karma-sourcemap-loader"": ""^0.3.8"",
","Fix the missing launcher (#3538)

Co-authored-by: Jay <jasonsaayman@gmail.com>
"
554,JavaScript,7cf4de71fad6d5654dc6a2875f3d2cb2da5b9e20,https://github.com/facebook/create-react-app/commit/7cf4de71fad6d5654dc6a2875f3d2cb2da5b9e20,P,facebook,create-react-app,"[2, 34, 0, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/packages/react-dev-utils/FileSizeReporter.js b/packages/react-dev-utils/FileSizeReporter.js
index 8f822d20..0ec62333 100644
--- a/packages/react-dev-utils/FileSizeReporter.js
+++ b/packages/react-dev-utils/FileSizeReporter.js
@@ -19,5 +19,11 @@ var gzipSize = require('gzip-size').sync;
 
 // Prints a detailed summary of build files.
-function printFileSizesAfterBuild(webpackStats, previousSizeMap, buildFolder) {
+function printFileSizesAfterBuild(
+  webpackStats,
+  previousSizeMap,
+  buildFolder,
+  maxBundleGzipSize,
+  maxChunkGzipSize
+) {
   var root = previousSizeMap.root;
   var sizes = previousSizeMap.sizes;
@@ -42,4 +48,5 @@ function printFileSizesAfterBuild(webpackStats, previousSizeMap, buildFolder) {
     assets.map(a => stripAnsi(a.sizeLabel).length)
   );
+  var suggestBundleSplitting = false;
   assets.forEach(asset => {
     var sizeLabel = asset.sizeLabel;
@@ -49,7 +56,15 @@ function printFileSizesAfterBuild(webpackStats, previousSizeMap, buildFolder) {
       sizeLabel += rightPadding;
     }
+    var isMainBundle = asset.name.indexOf('main.') === 0;
+    var maxRecommendedSize = isMainBundle
+      ? maxBundleGzipSize
+      : maxChunkGzipSize;
+    var isLarge = maxRecommendedSize && asset.size > maxRecommendedSize;
+    if (isLarge && path.extname(asset.name) === '.js') {
+      suggestBundleSplitting = true;
+    }
     console.log(
       '  ' +
-        sizeLabel +
+        (isLarge ? chalk.yellow(sizeLabel) : sizeLabel) +
         '  ' +
         chalk.dim(asset.folder + path.sep) +
@@ -57,4 +72,20 @@ function printFileSizesAfterBuild(webpackStats, previousSizeMap, buildFolder) {
     );
   });
+  if (suggestBundleSplitting) {
+    console.log();
+    console.log(
+      chalk.yellow('The bundle size is significantly larger than recommended.')
+    );
+    console.log(
+      chalk.yellow(
+        'Consider reducing it with code splitting: https://goo.gl/9VhYWB'
+      )
+    );
+    console.log(
+      chalk.yellow(
+        'You can also analyze the project dependencies: https://goo.gl/LeUzfb'
+      )
+    );
+  }
 }
 
diff --git a/packages/react-scripts/scripts/build.js b/packages/react-scripts/scripts/build.js
index 2e4bc21e..06eb0695 100644
--- a/packages/react-scripts/scripts/build.js
+++ b/packages/react-scripts/scripts/build.js
@@ -40,4 +40,8 @@ const printFileSizesAfterBuild = FileSizeReporter.printFileSizesAfterBuild;
 const useYarn = fs.existsSync(paths.yarnLockFile);
 
+// These sizes are pretty large. We'll warn for bundles exceeding them.
+const WARN_AFTER_BUNDLE_GZIP_SIZE = 512 * 1024;
+const WARN_AFTER_CHUNK_GZIP_SIZE = 1024 * 1024;
+
 // Warn and crash if required files are missing
 if (!checkRequiredFiles([paths.appHtml, paths.appIndexJs])) {
@@ -77,5 +81,11 @@ measureFileSizesBeforeBuild(paths.appBuild)
 
       console.log('File sizes after gzip:\n');
-      printFileSizesAfterBuild(stats, previousFileSizes, paths.appBuild);
+      printFileSizesAfterBuild(
+        stats,
+        previousFileSizes,
+        paths.appBuild,
+        WARN_AFTER_BUNDLE_GZIP_SIZE,
+        WARN_AFTER_CHUNK_GZIP_SIZE
+      );
       console.log();
 
","Warn about large bundle sizes (#2648)


"
582,JavaScript,d3028270ec5ea4245629b0e5dca34b555169f1d2,https://github.com/nodejs/node/commit/d3028270ec5ea4245629b0e5dca34b555169f1d2,P,nodejs,node,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 475, 650, 0, 0, 0, 0, 0]","diff --git a/tools/certdata.txt b/tools/certdata.txt
index 24df334ea0..020db76b18 100644
--- a/tools/certdata.txt
+++ b/tools/certdata.txt
@@ -192,4 +192,5 @@ CKA_VALUE MULTILINE_OCTAL
 \125\342\374\110\311\051\046\151\340
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""GlobalSign Root CA""
@@ -325,4 +326,5 @@ CKA_VALUE MULTILINE_OCTAL
 \152\374\176\102\070\100\144\022\367\236\201\341\223\056
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""GlobalSign Root CA - R2""
@@ -480,4 +482,5 @@ CKA_VALUE MULTILINE_OCTAL
 \113\336\006\226\161\054\362\333\266\037\244\357\077\356
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""Verisign Class 1 Public Primary Certification Authority - G3""
@@ -644,4 +647,5 @@ CKA_VALUE MULTILINE_OCTAL
 \311\130\020\371\252\357\132\266\317\113\113\337\052
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""Verisign Class 2 Public Primary Certification Authority - G3""
@@ -808,4 +812,5 @@ CKA_VALUE MULTILINE_OCTAL
 \153\271\012\172\116\117\113\204\356\113\361\175\335\021
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""Verisign Class 3 Public Primary Certification Authority - G3""
@@ -1082,4 +1087,5 @@ CKA_VALUE MULTILINE_OCTAL
 \174\136\232\166\351\131\220\305\174\203\065\021\145\121
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""Entrust.net Premium 2048 Secure Server CA""
@@ -1219,4 +1225,5 @@ CKA_VALUE MULTILINE_OCTAL
 \347\201\035\031\303\044\102\352\143\071\251
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""Baltimore CyberTrust Root""
@@ -1362,4 +1369,5 @@ CKA_VALUE MULTILINE_OCTAL
 \065\341\035\026\034\320\274\053\216\326\161\331
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""AddTrust Low-Value Services Root""
@@ -1510,4 +1518,5 @@ CKA_VALUE MULTILINE_OCTAL
 \027\132\173\320\274\307\217\116\206\004
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""AddTrust External Root""
@@ -1655,4 +1664,5 @@ CKA_VALUE MULTILINE_OCTAL
 \116\072\063\014\053\263\055\220\006
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""AddTrust Public Services Root""
@@ -1800,4 +1810,5 @@ CKA_VALUE MULTILINE_OCTAL
 \306\241
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""AddTrust Qualified Certificates Root""
@@ -1962,4 +1973,5 @@ CKA_VALUE MULTILINE_OCTAL
 \036\177\132\264\074
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""Entrust Root Certification Authority""
@@ -2095,4 +2107,5 @@ CKA_VALUE MULTILINE_OCTAL
 \302\005\146\200\241\313\346\063
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""GeoTrust Global CA""
@@ -2222,4 +2235,5 @@ CKA_VALUE MULTILINE_OCTAL
 \342\042\051\256\175\203\100\250\272\154
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""GeoTrust Global CA 2""
@@ -2381,4 +2395,5 @@ CKA_VALUE MULTILINE_OCTAL
 \244\346\216\330\371\051\110\212\316\163\376\054
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""GeoTrust Universal CA""
@@ -2540,4 +2555,5 @@ CKA_VALUE MULTILINE_OCTAL
 \362\034\054\176\256\002\026\322\126\320\057\127\123\107\350\222
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""GeoTrust Universal CA 2""
@@ -2676,4 +2692,5 @@ CKA_VALUE MULTILINE_OCTAL
 \222\340\134\366\007\017
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""Visa eCommerce Root""
@@ -2798,4 +2815,5 @@ CKA_VALUE MULTILINE_OCTAL
 \350\140\052\233\205\112\100\363\153\212\044\354\006\026\054\163
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""Certum Root CA""
@@ -2943,4 +2961,5 @@ CKA_VALUE MULTILINE_OCTAL
 \225\351\066\226\230\156
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""Comodo AAA Services root""
@@ -3093,4 +3112,5 @@ CKA_VALUE MULTILINE_OCTAL
 \354\375\051
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""Comodo Secure Services root""
@@ -3245,4 +3265,5 @@ CKA_VALUE MULTILINE_OCTAL
 \160\136\310\304\170\260\142
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""Comodo Trusted Services root""
@@ -3423,4 +3444,5 @@ CKA_VALUE MULTILINE_OCTAL
 \112\164\066\371
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""QuoVadis Root CA""
@@ -3591,4 +3613,5 @@ CKA_VALUE MULTILINE_OCTAL
 \020\005\145\325\202\020\352\302\061\315\056
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""QuoVadis Root CA 2""
@@ -3770,4 +3793,5 @@ CKA_VALUE MULTILINE_OCTAL
 \332
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""QuoVadis Root CA 3""
@@ -3898,4 +3922,5 @@ CKA_VALUE MULTILINE_OCTAL
 \057\317\246\356\311\160\042\024\275\375\276\154\013\003
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""Security Communication Root CA""
@@ -4020,4 +4045,5 @@ CKA_VALUE MULTILINE_OCTAL
 \160\254\337\114
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""Sonera Class 2 Root CA""
@@ -4181,4 +4207,5 @@ CKA_VALUE MULTILINE_OCTAL
 \005\323\312\003\112\124
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""UTN USERFirst Email Root CA""
@@ -4344,4 +4371,5 @@ CKA_VALUE MULTILINE_OCTAL
 \062\234\036\273\235\370\146\250
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""UTN USERFirst Hardware Root CA""
@@ -4504,4 +4532,5 @@ CKA_VALUE MULTILINE_OCTAL
 \275\023\122\035\250\076\315\000\037\310
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""UTN USERFirst Object Root CA""
@@ -4667,4 +4696,5 @@ CKA_VALUE MULTILINE_OCTAL
 \334
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""Camerfirma Chambers of Commerce Root""
@@ -4826,4 +4856,5 @@ CKA_VALUE MULTILINE_OCTAL
 \166\135\165\220\032\365\046\217\360
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""Camerfirma Global Chambersign Root""
@@ -4978,4 +5009,5 @@ CKA_VALUE MULTILINE_OCTAL
 \264\003\045\274
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""XRamp Global CA Root""
@@ -5124,4 +5156,5 @@ CKA_VALUE MULTILINE_OCTAL
 \177\333\275\237
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""Go Daddy Class 2 CA""
@@ -5268,4 +5301,5 @@ CKA_VALUE MULTILINE_OCTAL
 \037\027\224
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""Starfield Class 2 CA""
@@ -5473,4 +5507,5 @@ CKA_VALUE MULTILINE_OCTAL
 \152\263\364\210\034\200\015\374\162\212\350\203\136
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""StartCom Certification Authority""
@@ -5637,4 +5672,5 @@ CKA_VALUE MULTILINE_OCTAL
 \245\206\054\174\364\022
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""Taiwan GRCA""
@@ -5809,4 +5845,5 @@ CKA_VALUE MULTILINE_OCTAL
 \060\032\365\232\154\364\016\123\371\072\133\321\034
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""Swisscom Root CA 1""
@@ -5949,4 +5986,5 @@ CKA_VALUE MULTILINE_OCTAL
 \346\120\262\247\372\012\105\057\242\360\362
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""DigiCert Assured ID Root CA""
@@ -6089,4 +6127,5 @@ CKA_VALUE MULTILINE_OCTAL
 \225\155\336
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""DigiCert Global Root CA""
@@ -6230,4 +6269,5 @@ CKA_VALUE MULTILINE_OCTAL
 \370\351\056\023\243\167\350\037\112
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""DigiCert High Assurance EV Root CA""
@@ -6362,4 +6402,5 @@ CKA_VALUE MULTILINE_OCTAL
 \227\277\242\216\264\124
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""Certplus Class 2 Primary CA""
@@ -6488,4 +6529,5 @@ CKA_VALUE MULTILINE_OCTAL
 \013\004\216\007\333\051\266\012\356\235\202\065\065\020
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""DST Root CA X3""
@@ -6629,4 +6671,5 @@ CKA_VALUE MULTILINE_OCTAL
 \363\267\240\247\315\345\172\063\066\152\372\232\053
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""DST ACES CA X6""
@@ -6796,4 +6839,5 @@ CKA_VALUE MULTILINE_OCTAL
 \205\206\171\145\322
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""SwissSign Platinum CA - G2""
@@ -6960,4 +7004,5 @@ CKA_VALUE MULTILINE_OCTAL
 \111\044\133\311\260\320\127\301\372\076\172\341\227\311
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""SwissSign Gold CA - G2""
@@ -7125,4 +7170,5 @@ CKA_VALUE MULTILINE_OCTAL
 \156
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""SwissSign Silver CA - G2""
@@ -7256,4 +7302,5 @@ CKA_VALUE MULTILINE_OCTAL
 \253\022\350\263\336\132\345\240\174\350\017\042\035\132\351\131
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""GeoTrust Primary Certification Authority""
@@ -7410,4 +7457,5 @@ CKA_VALUE MULTILINE_OCTAL
 \215\126\214\150
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""thawte Primary Root CA""
@@ -7584,4 +7632,5 @@ CKA_VALUE MULTILINE_OCTAL
 \254\021\326\250\355\143\152
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""VeriSign Class 3 Public Primary Certification Authority - G5""
@@ -7726,4 +7775,5 @@ CKA_VALUE MULTILINE_OCTAL
 \113\035\236\054\302\270\150\274\355\002\356\061
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""SecureTrust CA""
@@ -7860,4 +7910,5 @@ CKA_VALUE MULTILINE_OCTAL
 \117\043\037\332\154\254\037\104\341\335\043\170\121\133\307\026
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""Secure Global CA""
@@ -8009,4 +8060,5 @@ CKA_VALUE MULTILINE_OCTAL
 \145
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""COMODO Certification Authority""
@@ -8154,4 +8206,5 @@ CKA_VALUE MULTILINE_OCTAL
 \244\140\114\260\125\240\240\173\127\262
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""Network Solutions Certificate Authority""
@@ -8193,165 +8246,4 @@ CKA_TRUST_CODE_SIGNING CK_TRUST CKT_NSS_MUST_VERIFY_TRUST
 CKA_TRUST_STEP_UP_APPROVED CK_BBOOL CK_FALSE
 
-#
-# Certificate ""WellsSecure Public Root Certificate Authority""
-#
-# Issuer: CN=WellsSecure Public Root Certificate Authority,OU=Wells Fargo Bank NA,O=Wells Fargo WellsSecure,C=US
-# Serial Number: 1 (0x1)
-# Subject: CN=WellsSecure Public Root Certificate Authority,OU=Wells Fargo Bank NA,O=Wells Fargo WellsSecure,C=US
-# Not Valid Before: Thu Dec 13 17:07:54 2007
-# Not Valid After : Wed Dec 14 00:07:54 2022
-# Fingerprint (MD5): 15:AC:A5:C2:92:2D:79:BC:E8:7F:CB:67:ED:02:CF:36
-# Fingerprint (SHA1): E7:B4:F6:9D:61:EC:90:69:DB:7E:90:A7:40:1A:3C:F4:7D:4F:E8:EE
-CKA_CLASS CK_OBJECT_CLASS CKO_CERTIFICATE
-CKA_TOKEN CK_BBOOL CK_TRUE
-CKA_PRIVATE CK_BBOOL CK_FALSE
-CKA_MODIFIABLE CK_BBOOL CK_FALSE
-CKA_LABEL UTF8 ""WellsSecure Public Root Certificate Authority""
-CKA_CERTIFICATE_TYPE CK_CERTIFICATE_TYPE CKC_X_509
-CKA_SUBJECT MULTILINE_OCTAL
-\060\201\205\061\013\060\011\006\003\125\004\006\023\002\125\123
-\061\040\060\036\006\003\125\004\012\014\027\127\145\154\154\163
-\040\106\141\162\147\157\040\127\145\154\154\163\123\145\143\165
-\162\145\061\034\060\032\006\003\125\004\013\014\023\127\145\154
-\154\163\040\106\141\162\147\157\040\102\141\156\153\040\116\101
-\061\066\060\064\006\003\125\004\003\014\055\127\145\154\154\163
-\123\145\143\165\162\145\040\120\165\142\154\151\143\040\122\157
-\157\164\040\103\145\162\164\151\146\151\143\141\164\145\040\101
-\165\164\150\157\162\151\164\171
-END
-CKA_ID UTF8 ""0""
-CKA_ISSUER MULTILINE_OCTAL
-\060\201\205\061\013\060\011\006\003\125\004\006\023\002\125\123
-\061\040\060\036\006\003\125\004\012\014\027\127\145\154\154\163
-\040\106\141\162\147\157\040\127\145\154\154\163\123\145\143\165
-\162\145\061\034\060\032\006\003\125\004\013\014\023\127\145\154
-\154\163\040\106\141\162\147\157\040\102\141\156\153\040\116\101
-\061\066\060\064\006\003\125\004\003\014\055\127\145\154\154\163
-\123\145\143\165\162\145\040\120\165\142\154\151\143\040\122\157
-\157\164\040\103\145\162\164\151\146\151\143\141\164\145\040\101
-\165\164\150\157\162\151\164\171
-END
-CKA_SERIAL_NUMBER MULTILINE_OCTAL
-\002\001\001
-END
-CKA_VALUE MULTILINE_OCTAL
-\060\202\004\275\060\202\003\245\240\003\002\001\002\002\001\001
-\060\015\006\011\052\206\110\206\367\015\001\001\005\005\000\060
-\201\205\061\013\060\011\006\003\125\004\006\023\002\125\123\061
-\040\060\036\006\003\125\004\012\014\027\127\145\154\154\163\040
-\106\141\162\147\157\040\127\145\154\154\163\123\145\143\165\162
-\145\061\034\060\032\006\003\125\004\013\014\023\127\145\154\154
-\163\040\106\141\162\147\157\040\102\141\156\153\040\116\101\061
-\066\060\064\006\003\125\004\003\014\055\127\145\154\154\163\123
-\145\143\165\162\145\040\120\165\142\154\151\143\040\122\157\157
-\164\040\103\145\162\164\151\146\151\143\141\164\145\040\101\165
-\164\150\157\162\151\164\171\060\036\027\015\060\067\061\062\061
-\063\061\067\060\067\065\064\132\027\015\062\062\061\062\061\064
-\060\060\060\067\065\064\132\060\201\205\061\013\060\011\006\003
-\125\004\006\023\002\125\123\061\040\060\036\006\003\125\004\012
-\014\027\127\145\154\154\163\040\106\141\162\147\157\040\127\145
-\154\154\163\123\145\143\165\162\145\061\034\060\032\006\003\125
-\004\013\014\023\127\145\154\154\163\040\106\141\162\147\157\040
-\102\141\156\153\040\116\101\061\066\060\064\006\003\125\004\003
-\014\055\127\145\154\154\163\123\145\143\165\162\145\040\120\165
-\142\154\151\143\040\122\157\157\164\040\103\145\162\164\151\146
-\151\143\141\164\145\040\101\165\164\150\157\162\151\164\171\060
-\202\001\042\060\015\006\011\052\206\110\206\367\015\001\001\001
-\005\000\003\202\001\017\000\060\202\001\012\002\202\001\001\000
-\356\157\264\275\171\342\217\010\041\236\070\004\101\045\357\253
-\133\034\123\222\254\155\236\335\302\304\056\105\224\003\065\210
-\147\164\127\343\337\214\270\247\166\217\073\367\250\304\333\051
-\143\016\221\150\066\212\227\216\212\161\150\011\007\344\350\324
-\016\117\370\326\053\114\244\026\371\357\103\230\217\263\236\122
-\337\155\221\071\217\070\275\167\213\103\143\353\267\223\374\060
-\114\034\001\223\266\023\373\367\241\037\277\045\341\164\067\054
-\036\244\136\074\150\370\113\277\015\271\036\056\066\350\251\344
-\247\370\017\313\202\165\174\065\055\042\326\302\277\013\363\264
-\374\154\225\141\036\127\327\004\201\062\203\122\171\346\203\143
-\317\267\313\143\213\021\342\275\136\353\366\215\355\225\162\050
-\264\254\022\142\351\112\063\346\203\062\256\005\165\225\275\204
-\225\333\052\134\233\216\056\014\270\201\053\101\346\070\126\237
-\111\233\154\166\372\212\135\367\001\171\201\174\301\203\100\005
-\376\161\375\014\077\314\116\140\011\016\145\107\020\057\001\300
-\005\077\217\370\263\101\357\132\102\176\131\357\322\227\014\145
-\002\003\001\000\001\243\202\001\064\060\202\001\060\060\017\006
-\003\125\035\023\001\001\377\004\005\060\003\001\001\377\060\071
-\006\003\125\035\037\004\062\060\060\060\056\240\054\240\052\206
-\050\150\164\164\160\072\057\057\143\162\154\056\160\153\151\056
-\167\145\154\154\163\146\141\162\147\157\056\143\157\155\057\167
-\163\160\162\143\141\056\143\162\154\060\016\006\003\125\035\017
-\001\001\377\004\004\003\002\001\306\060\035\006\003\125\035\016
-\004\026\004\024\046\225\031\020\331\350\241\227\221\377\334\031
-\331\265\004\076\322\163\012\152\060\201\262\006\003\125\035\043
-\004\201\252\060\201\247\200\024\046\225\031\020\331\350\241\227
-\221\377\334\031\331\265\004\076\322\163\012\152\241\201\213\244
-\201\210\060\201\205\061\013\060\011\006\003\125\004\006\023\002
-\125\123\061\040\060\036\006\003\125\004\012\014\027\127\145\154
-\154\163\040\106\141\162\147\157\040\127\145\154\154\163\123\145
-\143\165\162\145\061\034\060\032\006\003\125\004\013\014\023\127
-\145\154\154\163\040\106\141\162\147\157\040\102\141\156\153\040
-\116\101\061\066\060\064\006\003\125\004\003\014\055\127\145\154
-\154\163\123\145\143\165\162\145\040\120\165\142\154\151\143\040
-\122\157\157\164\040\103\145\162\164\151\146\151\143\141\164\145
-\040\101\165\164\150\157\162\151\164\171\202\001\001\060\015\006
-\011\052\206\110\206\367\015\001\001\005\005\000\003\202\001\001
-\000\271\025\261\104\221\314\043\310\053\115\167\343\370\232\173
-\047\015\315\162\273\231\000\312\174\146\031\120\306\325\230\355
-\253\277\003\132\345\115\345\036\310\117\161\227\206\325\343\035
-\375\220\311\074\165\167\127\172\175\370\336\364\324\325\367\225
-\346\164\156\035\074\256\174\235\333\002\003\005\054\161\113\045
-\076\007\343\136\232\365\146\027\051\210\032\070\237\317\252\101
-\003\204\227\153\223\070\172\312\060\104\033\044\104\063\320\344
-\321\334\050\070\364\023\103\065\065\051\143\250\174\242\265\255
-\070\244\355\255\375\306\232\037\377\227\163\376\373\263\065\247
-\223\206\306\166\221\000\346\254\121\026\304\047\062\134\333\163
-\332\245\223\127\216\076\155\065\046\010\131\325\347\104\327\166
-\040\143\347\254\023\147\303\155\261\160\106\174\325\226\021\075
-\211\157\135\250\241\353\215\012\332\303\035\063\154\243\352\147
-\031\232\231\177\113\075\203\121\052\035\312\057\206\014\242\176
-\020\055\053\324\026\225\013\007\252\056\024\222\111\267\051\157
-\330\155\061\175\365\374\241\020\007\207\316\057\131\334\076\130
-\333
-END
-
-# Trust for Certificate ""WellsSecure Public Root Certificate Authority""
-# Issuer: CN=WellsSecure Public Root Certificate Authority,OU=Wells Fargo Bank NA,O=Wells Fargo WellsSecure,C=US
-# Serial Number: 1 (0x1)
-# Subject: CN=WellsSecure Public Root Certificate Authority,OU=Wells Fargo Bank NA,O=Wells Fargo WellsSecure,C=US
-# Not Valid Before: Thu Dec 13 17:07:54 2007
-# Not Valid After : Wed Dec 14 00:07:54 2022
-# Fingerprint (MD5): 15:AC:A5:C2:92:2D:79:BC:E8:7F:CB:67:ED:02:CF:36
-# Fingerprint (SHA1): E7:B4:F6:9D:61:EC:90:69:DB:7E:90:A7:40:1A:3C:F4:7D:4F:E8:EE
-CKA_CLASS CK_OBJECT_CLASS CKO_NSS_TRUST
-CKA_TOKEN CK_BBOOL CK_TRUE
-CKA_PRIVATE CK_BBOOL CK_FALSE
-CKA_MODIFIABLE CK_BBOOL CK_FALSE
-CKA_LABEL UTF8 ""WellsSecure Public Root Certificate Authority""
-CKA_CERT_SHA1_HASH MULTILINE_OCTAL
-\347\264\366\235\141\354\220\151\333\176\220\247\100\032\074\364
-\175\117\350\356
-END
-CKA_CERT_MD5_HASH MULTILINE_OCTAL
-\025\254\245\302\222\055\171\274\350\177\313\147\355\002\317\066
-END
-CKA_ISSUER MULTILINE_OCTAL
-\060\201\205\061\013\060\011\006\003\125\004\006\023\002\125\123
-\061\040\060\036\006\003\125\004\012\014\027\127\145\154\154\163
-\040\106\141\162\147\157\040\127\145\154\154\163\123\145\143\165
-\162\145\061\034\060\032\006\003\125\004\013\014\023\127\145\154
-\154\163\040\106\141\162\147\157\040\102\141\156\153\040\116\101
-\061\066\060\064\006\003\125\004\003\014\055\127\145\154\154\163
-\123\145\143\165\162\145\040\120\165\142\154\151\143\040\122\157
-\157\164\040\103\145\162\164\151\146\151\143\141\164\145\040\101
-\165\164\150\157\162\151\164\171
-END
-CKA_SERIAL_NUMBER MULTILINE_OCTAL
-\002\001\001
-END
-CKA_TRUST_SERVER_AUTH CK_TRUST CKT_NSS_TRUSTED_DELEGATOR
-CKA_TRUST_EMAIL_PROTECTION CK_TRUST CKT_NSS_MUST_VERIFY_TRUST
-CKA_TRUST_CODE_SIGNING CK_TRUST CKT_NSS_MUST_VERIFY_TRUST
-CKA_TRUST_STEP_UP_APPROVED CK_BBOOL CK_FALSE
-
 #
 # Certificate ""COMODO ECC Certification Authority""
@@ -8440,4 +8332,5 @@ CKA_VALUE MULTILINE_OCTAL
 \334\335\363\377\035\054\072\026\127\331\222\071\326
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""COMODO ECC Certification Authority""
@@ -8747,4 +8640,5 @@ CKA_VALUE MULTILINE_OCTAL
 \164
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""Security Communication EV RootCA1""
@@ -8894,4 +8788,5 @@ CKA_VALUE MULTILINE_OCTAL
 \374\276\337\012\015
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""OISTE WISeKey Global Root GA CA""
@@ -8935,210 +8830,4 @@ CKA_TRUST_CODE_SIGNING CK_TRUST CKT_NSS_MUST_VERIFY_TRUST
 CKA_TRUST_STEP_UP_APPROVED CK_BBOOL CK_FALSE
 
-#
-# Certificate ""Microsec e-Szigno Root CA""
-#
-# Issuer: CN=Microsec e-Szigno Root CA,OU=e-Szigno CA,O=Microsec Ltd.,L=Budapest,C=HU
-# Serial Number:00:cc:b8:e7:bf:4e:29:1a:fd:a2:dc:66:a5:1c:2c:0f:11
-# Subject: CN=Microsec e-Szigno Root CA,OU=e-Szigno CA,O=Microsec Ltd.,L=Budapest,C=HU
-# Not Valid Before: Wed Apr 06 12:28:44 2005
-# Not Valid After : Thu Apr 06 12:28:44 2017
-# Fingerprint (MD5): F0:96:B6:2F:C5:10:D5:67:8E:83:25:32:E8:5E:2E:E5
-# Fingerprint (SHA1): 23:88:C9:D3:71:CC:9E:96:3D:FF:7D:3C:A7:CE:FC:D6:25:EC:19:0D
-CKA_CLASS CK_OBJECT_CLASS CKO_CERTIFICATE
-CKA_TOKEN CK_BBOOL CK_TRUE
-CKA_PRIVATE CK_BBOOL CK_FALSE
-CKA_MODIFIABLE CK_BBOOL CK_FALSE
-CKA_LABEL UTF8 ""Microsec e-Szigno Root CA""
-CKA_CERTIFICATE_TYPE CK_CERTIFICATE_TYPE CKC_X_509
-CKA_SUBJECT MULTILINE_OCTAL
-\060\162\061\013\060\011\006\003\125\004\006\023\002\110\125\061
-\021\060\017\006\003\125\004\007\023\010\102\165\144\141\160\145
-\163\164\061\026\060\024\006\003\125\004\012\023\015\115\151\143
-\162\157\163\145\143\040\114\164\144\056\061\024\060\022\006\003
-\125\004\013\023\013\145\055\123\172\151\147\156\157\040\103\101
-\061\042\060\040\006\003\125\004\003\023\031\115\151\143\162\157
-\163\145\143\040\145\055\123\172\151\147\156\157\040\122\157\157
-\164\040\103\101
-END
-CKA_ID UTF8 ""0""
-CKA_ISSUER MULTILINE_OCTAL
-\060\162\061\013\060\011\006\003\125\004\006\023\002\110\125\061
-\021\060\017\006\003\125\004\007\023\010\102\165\144\141\160\145
-\163\164\061\026\060\024\006\003\125\004\012\023\015\115\151\143
-\162\157\163\145\143\040\114\164\144\056\061\024\060\022\006\003
-\125\004\013\023\013\145\055\123\172\151\147\156\157\040\103\101
-\061\042\060\040\006\003\125\004\003\023\031\115\151\143\162\157
-\163\145\143\040\145\055\123\172\151\147\156\157\040\122\157\157
-\164\040\103\101
-END
-CKA_SERIAL_NUMBER MULTILINE_OCTAL
-\002\021\000\314\270\347\277\116\051\032\375\242\334\146\245\034
-\054\017\021
-END
-CKA_VALUE MULTILINE_OCTAL
-\060\202\007\250\060\202\006\220\240\003\002\001\002\002\021\000
-\314\270\347\277\116\051\032\375\242\334\146\245\034\054\017\021
-\060\015\006\011\052\206\110\206\367\015\001\001\005\005\000\060
-\162\061\013\060\011\006\003\125\004\006\023\002\110\125\061\021
-\060\017\006\003\125\004\007\023\010\102\165\144\141\160\145\163
-\164\061\026\060\024\006\003\125\004\012\023\015\115\151\143\162
-\157\163\145\143\040\114\164\144\056\061\024\060\022\006\003\125
-\004\013\023\013\145\055\123\172\151\147\156\157\040\103\101\061
-\042\060\040\006\003\125\004\003\023\031\115\151\143\162\157\163
-\145\143\040\145\055\123\172\151\147\156\157\040\122\157\157\164
-\040\103\101\060\036\027\015\060\065\060\064\060\066\061\062\062
-\070\064\064\132\027\015\061\067\060\064\060\066\061\062\062\070
-\064\064\132\060\162\061\013\060\011\006\003\125\004\006\023\002
-\110\125\061\021\060\017\006\003\125\004\007\023\010\102\165\144
-\141\160\145\163\164\061\026\060\024\006\003\125\004\012\023\015
-\115\151\143\162\157\163\145\143\040\114\164\144\056\061\024\060
-\022\006\003\125\004\013\023\013\145\055\123\172\151\147\156\157
-\040\103\101\061\042\060\040\006\003\125\004\003\023\031\115\151
-\143\162\157\163\145\143\040\145\055\123\172\151\147\156\157\040
-\122\157\157\164\040\103\101\060\202\001\042\060\015\006\011\052
-\206\110\206\367\015\001\001\001\005\000\003\202\001\017\000\060
-\202\001\012\002\202\001\001\000\355\310\000\325\201\173\315\070
-\000\107\314\333\204\301\041\151\054\164\220\014\041\331\123\207
-\355\076\103\104\123\257\253\370\200\233\074\170\215\324\215\256
-\270\357\323\021\334\201\346\317\073\226\214\326\157\025\306\167
-\176\241\057\340\137\222\266\047\327\166\232\035\103\074\352\331
-\354\057\356\071\363\152\147\113\213\202\317\042\370\145\125\376
-\054\313\057\175\110\172\075\165\371\252\240\047\273\170\302\006
-\312\121\302\176\146\113\257\315\242\247\115\002\202\077\202\254
-\205\306\341\017\220\107\231\224\012\161\162\223\052\311\246\300
-\276\074\126\114\163\222\047\361\153\265\365\375\374\060\005\140
-\222\306\353\226\176\001\221\302\151\261\036\035\173\123\105\270
-\334\101\037\311\213\161\326\124\024\343\213\124\170\077\276\364
-\142\073\133\365\243\354\325\222\164\342\164\060\357\001\333\341
-\324\253\231\233\052\153\370\275\246\034\206\043\102\137\354\111
-\336\232\213\133\364\162\072\100\305\111\076\245\276\216\252\161
-\353\154\372\365\032\344\152\375\173\175\125\100\357\130\156\346
-\331\325\274\044\253\301\357\267\002\003\001\000\001\243\202\004
-\067\060\202\004\063\060\147\006\010\053\006\001\005\005\007\001
-\001\004\133\060\131\060\050\006\010\053\006\001\005\005\007\060
-\001\206\034\150\164\164\160\163\072\057\057\162\143\141\056\145
-\055\163\172\151\147\156\157\056\150\165\057\157\143\163\160\060
-\055\006\010\053\006\001\005\005\007\060\002\206\041\150\164\164
-\160\072\057\057\167\167\167\056\145\055\163\172\151\147\156\157
-\056\150\165\057\122\157\157\164\103\101\056\143\162\164\060\017
-\006\003\125\035\023\001\001\377\004\005\060\003\001\001\377\060
-\202\001\163\006\003\125\035\040\004\202\001\152\060\202\001\146
-\060\202\001\142\006\014\053\006\001\004\001\201\250\030\002\001
-\001\001\060\202\001\120\060\050\006\010\053\006\001\005\005\007
-\002\001\026\034\150\164\164\160\072\057\057\167\167\167\056\145
-\055\163\172\151\147\156\157\056\150\165\057\123\132\123\132\057
-\060\202\001\042\006\010\053\006\001\005\005\007\002\002\060\202
-\001\024\036\202\001\020\000\101\000\040\000\164\000\141\000\156
-\000\372\000\163\000\355\000\164\000\166\000\341\000\156\000\171
-\000\040\000\351\000\162\000\164\000\145\000\154\000\155\000\145
-\000\172\000\351\000\163\000\351\000\150\000\145\000\172\000\040
-\000\351\000\163\000\040\000\145\000\154\000\146\000\157\000\147
-\000\141\000\144\000\341\000\163\000\341\000\150\000\157\000\172
-\000\040\000\141\000\040\000\123\000\172\000\157\000\154\000\147
-\000\341\000\154\000\164\000\141\000\164\000\363\000\040\000\123
-\000\172\000\157\000\154\000\147\000\341\000\154\000\164\000\141
-\000\164\000\341\000\163\000\151\000\040\000\123\000\172\000\141
-\000\142\000\341\000\154\000\171\000\172\000\141\000\164\000\141
-\000\040\000\163\000\172\000\145\000\162\000\151\000\156\000\164
-\000\040\000\153\000\145\000\154\000\154\000\040\000\145\000\154
-\000\152\000\341\000\162\000\156\000\151\000\072\000\040\000\150
-\000\164\000\164\000\160\000\072\000\057\000\057\000\167\000\167
-\000\167\000\056\000\145\000\055\000\163\000\172\000\151\000\147
-\000\156\000\157\000\056\000\150\000\165\000\057\000\123\000\132
-\000\123\000\132\000\057\060\201\310\006\003\125\035\037\004\201
-\300\060\201\275\060\201\272\240\201\267\240\201\264\206\041\150
-\164\164\160\072\057\057\167\167\167\056\145\055\163\172\151\147
-\156\157\056\150\165\057\122\157\157\164\103\101\056\143\162\154
-\206\201\216\154\144\141\160\072\057\057\154\144\141\160\056\145
-\055\163\172\151\147\156\157\056\150\165\057\103\116\075\115\151
-\143\162\157\163\145\143\045\062\060\145\055\123\172\151\147\156
-\157\045\062\060\122\157\157\164\045\062\060\103\101\054\117\125
-\075\145\055\123\172\151\147\156\157\045\062\060\103\101\054\117
-\075\115\151\143\162\157\163\145\143\045\062\060\114\164\144\056
-\054\114\075\102\165\144\141\160\145\163\164\054\103\075\110\125
-\077\143\145\162\164\151\146\151\143\141\164\145\122\145\166\157
-\143\141\164\151\157\156\114\151\163\164\073\142\151\156\141\162
-\171\060\016\006\003\125\035\017\001\001\377\004\004\003\002\001
-\006\060\201\226\006\003\125\035\021\004\201\216\060\201\213\201
-\020\151\156\146\157\100\145\055\163\172\151\147\156\157\056\150
-\165\244\167\060\165\061\043\060\041\006\003\125\004\003\014\032
-\115\151\143\162\157\163\145\143\040\145\055\123\172\151\147\156
-\303\263\040\122\157\157\164\040\103\101\061\026\060\024\006\003
-\125\004\013\014\015\145\055\123\172\151\147\156\303\263\040\110
-\123\132\061\026\060\024\006\003\125\004\012\023\015\115\151\143
-\162\157\163\145\143\040\113\146\164\056\061\021\060\017\006\003
-\125\004\007\023\010\102\165\144\141\160\145\163\164\061\013\060
-\011\006\003\125\004\006\023\002\110\125\060\201\254\006\003\125
-\035\043\004\201\244\060\201\241\200\024\307\240\111\165\026\141
-\204\333\061\113\204\322\361\067\100\220\357\116\334\367\241\166
-\244\164\060\162\061\013\060\011\006\003\125\004\006\023\002\110
-\125\061\021\060\017\006\003\125\004\007\023\010\102\165\144\141
-\160\145\163\164\061\026\060\024\006\003\125\004\012\023\015\115
-\151\143\162\157\163\145\143\040\114\164\144\056\061\024\060\022
-\006\003\125\004\013\023\013\145\055\123\172\151\147\156\157\040
-\103\101\061\042\060\040\006\003\125\004\003\023\031\115\151\143
-\162\157\163\145\143\040\145\055\123\172\151\147\156\157\040\122
-\157\157\164\040\103\101\202\021\000\314\270\347\277\116\051\032
-\375\242\334\146\245\034\054\017\021\060\035\006\003\125\035\016
-\004\026\004\024\307\240\111\165\026\141\204\333\061\113\204\322
-\361\067\100\220\357\116\334\367\060\015\006\011\052\206\110\206
-\367\015\001\001\005\005\000\003\202\001\001\000\323\023\234\146
-\143\131\056\312\134\160\014\374\203\274\125\261\364\216\007\154
-\146\047\316\301\073\040\251\034\273\106\124\160\356\132\314\240
-\167\352\150\104\047\353\362\051\335\167\251\325\373\343\324\247
-\004\304\225\270\013\341\104\150\140\007\103\060\061\102\141\345
-\356\331\345\044\325\033\337\341\112\033\252\237\307\137\370\172
-\021\352\023\223\000\312\212\130\261\356\355\016\115\264\327\250
-\066\046\174\340\072\301\325\127\202\361\165\266\375\211\137\332
-\363\250\070\237\065\006\010\316\042\225\276\315\325\374\276\133
-\336\171\153\334\172\251\145\146\276\261\045\132\137\355\176\323
-\254\106\155\114\364\062\207\264\040\004\340\154\170\260\167\321
-\205\106\113\246\022\267\165\350\112\311\126\154\327\222\253\235
-\365\111\070\322\117\123\343\125\220\021\333\230\226\306\111\362
-\076\364\237\033\340\367\210\334\045\142\231\104\330\163\277\077
-\060\363\014\067\076\324\302\050\200\163\261\001\267\235\132\226
-\024\001\113\251\021\235\051\152\056\320\135\201\300\317\262\040
-\103\307\003\340\067\116\135\012\334\131\040\045
-END
-
-# Trust for Certificate ""Microsec e-Szigno Root CA""
-# Issuer: CN=Microsec e-Szigno Root CA,OU=e-Szigno CA,O=Microsec Ltd.,L=Budapest,C=HU
-# Serial Number:00:cc:b8:e7:bf:4e:29:1a:fd:a2:dc:66:a5:1c:2c:0f:11
-# Subject: CN=Microsec e-Szigno Root CA,OU=e-Szigno CA,O=Microsec Ltd.,L=Budapest,C=HU
-# Not Valid Before: Wed Apr 06 12:28:44 2005
-# Not Valid After : Thu Apr 06 12:28:44 2017
-# Fingerprint (MD5): F0:96:B6:2F:C5:10:D5:67:8E:83:25:32:E8:5E:2E:E5
-# Fingerprint (SHA1): 23:88:C9:D3:71:CC:9E:96:3D:FF:7D:3C:A7:CE:FC:D6:25:EC:19:0D
-CKA_CLASS CK_OBJECT_CLASS CKO_NSS_TRUST
-CKA_TOKEN CK_BBOOL CK_TRUE
-CKA_PRIVATE CK_BBOOL CK_FALSE
-CKA_MODIFIABLE CK_BBOOL CK_FALSE
-CKA_LABEL UTF8 ""Microsec e-Szigno Root CA""
-CKA_CERT_SHA1_HASH MULTILINE_OCTAL
-\043\210\311\323\161\314\236\226\075\377\175\074\247\316\374\326
-\045\354\031\015
-END
-CKA_CERT_MD5_HASH MULTILINE_OCTAL
-\360\226\266\057\305\020\325\147\216\203\045\062\350\136\056\345
-END
-CKA_ISSUER MULTILINE_OCTAL
-\060\162\061\013\060\011\006\003\125\004\006\023\002\110\125\061
-\021\060\017\006\003\125\004\007\023\010\102\165\144\141\160\145
-\163\164\061\026\060\024\006\003\125\004\012\023\015\115\151\143
-\162\157\163\145\143\040\114\164\144\056\061\024\060\022\006\003
-\125\004\013\023\013\145\055\123\172\151\147\156\157\040\103\101
-\061\042\060\040\006\003\125\004\003\023\031\115\151\143\162\157
-\163\145\143\040\145\055\123\172\151\147\156\157\040\122\157\157
-\164\040\103\101
-END
-CKA_SERIAL_NUMBER MULTILINE_OCTAL
-\002\021\000\314\270\347\277\116\051\032\375\242\334\146\245\034
-\054\017\021
-END
-CKA_TRUST_SERVER_AUTH CK_TRUST CKT_NSS_TRUSTED_DELEGATOR
-CKA_TRUST_EMAIL_PROTECTION CK_TRUST CKT_NSS_TRUSTED_DELEGATOR
-CKA_TRUST_CODE_SIGNING CK_TRUST CKT_NSS_TRUSTED_DELEGATOR
-CKA_TRUST_STEP_UP_APPROVED CK_BBOOL CK_FALSE
-
 #
 # Certificate ""Certigna""
@@ -9234,4 +8923,5 @@ CKA_VALUE MULTILINE_OCTAL
 \300\226\130\057\352\273\106\327\273\344\331\056
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""Certigna""
@@ -9415,4 +9105,5 @@ CKA_VALUE MULTILINE_OCTAL
 \005\211\374\170\326\134\054\046\103\251
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""AC Raiz Certicamara S.A.""
@@ -9572,4 +9263,5 @@ CKA_VALUE MULTILINE_OCTAL
 \016\121\075\157\373\226\126\200\342\066\027\321\334\344
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""TC TrustCenter Class 3 CA II""
@@ -9712,4 +9404,5 @@ CKA_VALUE MULTILINE_OCTAL
 \126\144\127
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""Deutsche Telekom Root CA 2""
@@ -9844,4 +9537,5 @@ CKA_VALUE MULTILINE_OCTAL
 \000\147\240\161\000\202\110
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""ComSign CA""
@@ -9974,4 +9668,5 @@ CKA_VALUE MULTILINE_OCTAL
 \316\145\006\056\135\322\052\123\164\136\323\156\047\236\217
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""ComSign Secured CA""
@@ -10103,4 +9798,5 @@ CKA_VALUE MULTILINE_OCTAL
 \246\210\070\316\125
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""Cybertrust Global Root""
@@ -10269,4 +9965,5 @@ CKA_VALUE MULTILINE_OCTAL
 \201\370\021\234
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""ePKI Root Certification Authority""
@@ -10453,4 +10150,5 @@ CKA_VALUE MULTILINE_OCTAL
 \311\234\220\332\354\251\102\074\255\266\002
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""TUBITAK UEKAE Kok Sertifika Hizmet Saglayicisi - Surum 3""
@@ -10589,4 +10287,5 @@ CKA_VALUE MULTILINE_OCTAL
 \366\356\260\132\116\111\104\124\130\137\102\203
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""certSIGN ROOT CA""
@@ -10712,4 +10411,5 @@ CKA_VALUE MULTILINE_OCTAL
 \011\333\212\101\202\236\146\233\021
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""CNNIC ROOT""
@@ -10747,135 +10447,4 @@ CKA_TRUST_CODE_SIGNING CK_TRUST CKT_NSS_MUST_VERIFY_TRUST
 CKA_TRUST_STEP_UP_APPROVED CK_BBOOL CK_FALSE
 
-#
-# Certificate ""ApplicationCA - Japanese Government""
-#
-# Issuer: OU=ApplicationCA,O=Japanese Government,C=JP
-# Serial Number: 49 (0x31)
-# Subject: OU=ApplicationCA,O=Japanese Government,C=JP
-# Not Valid Before: Wed Dec 12 15:00:00 2007
-# Not Valid After : Tue Dec 12 15:00:00 2017
-# Fingerprint (MD5): 7E:23:4E:5B:A7:A5:B4:25:E9:00:07:74:11:62:AE:D6
-# Fingerprint (SHA1): 7F:8A:B0:CF:D0:51:87:6A:66:F3:36:0F:47:C8:8D:8C:D3:35:FC:74
-CKA_CLASS CK_OBJECT_CLASS CKO_CERTIFICATE
-CKA_TOKEN CK_BBOOL CK_TRUE
-CKA_PRIVATE CK_BBOOL CK_FALSE
-CKA_MODIFIABLE CK_BBOOL CK_FALSE
-CKA_LABEL UTF8 ""ApplicationCA - Japanese Government""
-CKA_CERTIFICATE_TYPE CK_CERTIFICATE_TYPE CKC_X_509
-CKA_SUBJECT MULTILINE_OCTAL
-\060\103\061\013\060\011\006\003\125\004\006\023\002\112\120\061
-\034\060\032\006\003\125\004\012\023\023\112\141\160\141\156\145
-\163\145\040\107\157\166\145\162\156\155\145\156\164\061\026\060
-\024\006\003\125\004\013\023\015\101\160\160\154\151\143\141\164
-\151\157\156\103\101
-END
-CKA_ID UTF8 ""0""
-CKA_ISSUER MULTILINE_OCTAL
-\060\103\061\013\060\011\006\003\125\004\006\023\002\112\120\061
-\034\060\032\006\003\125\004\012\023\023\112\141\160\141\156\145
-\163\145\040\107\157\166\145\162\156\155\145\156\164\061\026\060
-\024\006\003\125\004\013\023\015\101\160\160\154\151\143\141\164
-\151\157\156\103\101
-END
-CKA_SERIAL_NUMBER MULTILINE_OCTAL
-\002\001\061
-END
-CKA_VALUE MULTILINE_OCTAL
-\060\202\003\240\060\202\002\210\240\003\002\001\002\002\001\061
-\060\015\006\011\052\206\110\206\367\015\001\001\005\005\000\060
-\103\061\013\060\011\006\003\125\004\006\023\002\112\120\061\034
-\060\032\006\003\125\004\012\023\023\112\141\160\141\156\145\163
-\145\040\107\157\166\145\162\156\155\145\156\164\061\026\060\024
-\006\003\125\004\013\023\015\101\160\160\154\151\143\141\164\151
-\157\156\103\101\060\036\027\015\060\067\061\062\061\062\061\065
-\060\060\060\060\132\027\015\061\067\061\062\061\062\061\065\060
-\060\060\060\132\060\103\061\013\060\011\006\003\125\004\006\023
-\002\112\120\061\034\060\032\006\003\125\004\012\023\023\112\141
-\160\141\156\145\163\145\040\107\157\166\145\162\156\155\145\156
-\164\061\026\060\024\006\003\125\004\013\023\015\101\160\160\154
-\151\143\141\164\151\157\156\103\101\060\202\001\042\060\015\006
-\011\052\206\110\206\367\015\001\001\001\005\000\003\202\001\017
-\000\060\202\001\012\002\202\001\001\000\247\155\340\164\116\207
-\217\245\006\336\150\242\333\206\231\113\144\015\161\360\012\005
-\233\216\252\341\314\056\322\152\073\301\172\264\227\141\215\212
-\276\306\232\234\006\264\206\121\344\067\016\164\170\176\137\212
-\177\224\244\327\107\010\375\120\132\126\344\150\254\050\163\240
-\173\351\177\030\222\100\117\055\235\365\256\104\110\163\066\006
-\236\144\054\073\064\043\333\134\046\344\161\171\217\324\156\171
-\042\271\223\301\312\315\301\126\355\210\152\327\240\071\041\004
-\127\054\242\365\274\107\101\117\136\064\042\225\265\037\051\155
-\136\112\363\115\162\276\101\126\040\207\374\351\120\107\327\060
-\024\356\134\214\125\272\131\215\207\374\043\336\223\320\004\214
-\375\357\155\275\320\172\311\245\072\152\162\063\306\112\015\005
-\027\052\055\173\261\247\330\326\360\276\364\077\352\016\050\155
-\101\141\043\166\170\303\270\145\244\363\132\256\314\302\252\331
-\347\130\336\266\176\235\205\156\237\052\012\157\237\003\051\060
-\227\050\035\274\267\317\124\051\116\121\061\371\047\266\050\046
-\376\242\143\346\101\026\360\063\230\107\002\003\001\000\001\243
-\201\236\060\201\233\060\035\006\003\125\035\016\004\026\004\024
-\124\132\313\046\077\161\314\224\106\015\226\123\352\153\110\320
-\223\376\102\165\060\016\006\003\125\035\017\001\001\377\004\004
-\003\002\001\006\060\131\006\003\125\035\021\004\122\060\120\244
-\116\060\114\061\013\060\011\006\003\125\004\006\023\002\112\120
-\061\030\060\026\006\003\125\004\012\014\017\346\227\245\346\234
-\254\345\233\275\346\224\277\345\272\234\061\043\060\041\006\003
-\125\004\013\014\032\343\202\242\343\203\227\343\203\252\343\202
-\261\343\203\274\343\202\267\343\203\247\343\203\263\103\101\060
-\017\006\003\125\035\023\001\001\377\004\005\060\003\001\001\377
-\060\015\006\011\052\206\110\206\367\015\001\001\005\005\000\003
-\202\001\001\000\071\152\104\166\167\070\072\354\243\147\106\017
-\371\213\006\250\373\152\220\061\316\176\354\332\321\211\174\172
-\353\056\014\275\231\062\347\260\044\326\303\377\365\262\210\011
-\207\054\343\124\341\243\246\262\010\013\300\205\250\310\322\234
-\161\366\035\237\140\374\070\063\023\341\236\334\013\137\332\026
-\120\051\173\057\160\221\017\231\272\064\064\215\225\164\305\176
-\170\251\146\135\275\312\041\167\102\020\254\146\046\075\336\221
-\253\375\025\360\157\355\154\137\020\370\363\026\366\003\212\217
-\247\022\021\014\313\375\077\171\301\234\375\142\356\243\317\124
-\014\321\053\137\027\076\343\076\277\300\053\076\011\233\376\210
-\246\176\264\222\027\374\043\224\201\275\156\247\305\214\302\353
-\021\105\333\370\101\311\226\166\352\160\137\171\022\153\344\243
-\007\132\005\357\047\111\317\041\237\212\114\011\160\146\251\046
-\301\053\021\116\063\322\016\374\326\154\322\016\062\144\150\377
-\255\005\170\137\003\035\250\343\220\254\044\340\017\100\247\113
-\256\213\050\267\202\312\030\007\346\267\133\164\351\040\031\177
-\262\033\211\124
-END
-
-# Trust for Certificate ""ApplicationCA - Japanese Government""
-# Issuer: OU=ApplicationCA,O=Japanese Government,C=JP
-# Serial Number: 49 (0x31)
-# Subject: OU=ApplicationCA,O=Japanese Government,C=JP
-# Not Valid Before: Wed Dec 12 15:00:00 2007
-# Not Valid After : Tue Dec 12 15:00:00 2017
-# Fingerprint (MD5): 7E:23:4E:5B:A7:A5:B4:25:E9:00:07:74:11:62:AE:D6
-# Fingerprint (SHA1): 7F:8A:B0:CF:D0:51:87:6A:66:F3:36:0F:47:C8:8D:8C:D3:35:FC:74
-CKA_CLASS CK_OBJECT_CLASS CKO_NSS_TRUST
-CKA_TOKEN CK_BBOOL CK_TRUE
-CKA_PRIVATE CK_BBOOL CK_FALSE
-CKA_MODIFIABLE CK_BBOOL CK_FALSE
-CKA_LABEL UTF8 ""ApplicationCA - Japanese Government""
-CKA_CERT_SHA1_HASH MULTILINE_OCTAL
-\177\212\260\317\320\121\207\152\146\363\066\017\107\310\215\214
-\323\065\374\164
-END
-CKA_CERT_MD5_HASH MULTILINE_OCTAL
-\176\043\116\133\247\245\264\045\351\000\007\164\021\142\256\326
-END
-CKA_ISSUER MULTILINE_OCTAL
-\060\103\061\013\060\011\006\003\125\004\006\023\002\112\120\061
-\034\060\032\006\003\125\004\012\023\023\112\141\160\141\156\145
-\163\145\040\107\157\166\145\162\156\155\145\156\164\061\026\060
-\024\006\003\125\004\013\023\015\101\160\160\154\151\143\141\164
-\151\157\156\103\101
-END
-CKA_SERIAL_NUMBER MULTILINE_OCTAL
-\002\001\061
-END
-CKA_TRUST_SERVER_AUTH CK_TRUST CKT_NSS_TRUSTED_DELEGATOR
-CKA_TRUST_EMAIL_PROTECTION CK_TRUST CKT_NSS_MUST_VERIFY_TRUST
-CKA_TRUST_CODE_SIGNING CK_TRUST CKT_NSS_TRUSTED_DELEGATOR
-CKA_TRUST_STEP_UP_APPROVED CK_BBOOL CK_FALSE
-
 #
 # Certificate ""GeoTrust Primary Certification Authority - G3""
@@ -10990,4 +10559,5 @@ CKA_VALUE MULTILINE_OCTAL
 \021\055
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""GeoTrust Primary Certification Authority - G3""
@@ -11118,4 +10688,5 @@ CKA_VALUE MULTILINE_OCTAL
 \367\130\077\056\162\002\127\243\217\241\024\056
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""thawte Primary Root CA - G2""
@@ -11277,4 +10848,5 @@ CKA_VALUE MULTILINE_OCTAL
 \061\324\100\032\142\064\066\077\065\001\256\254\143\240
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""thawte Primary Root CA - G3""
@@ -11412,4 +10984,5 @@ CKA_VALUE MULTILINE_OCTAL
 \017\212
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""GeoTrust Primary Certification Authority - G2""
@@ -11581,4 +11154,5 @@ CKA_VALUE MULTILINE_OCTAL
 \354\315\202\141\361\070\346\117\227\230\052\132\215
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""VeriSign Universal Root Certification Authority""
@@ -11735,4 +11309,5 @@ CKA_VALUE MULTILINE_OCTAL
 \055\247\330\206\052\335\056\020
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""VeriSign Class 3 Public Primary Certification Authority - G4""
@@ -11894,4 +11469,5 @@ CKA_VALUE MULTILINE_OCTAL
 \330\316\304\143\165\077\131\107\261
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""NetLock Arany (Class Gold) Ftanstvny""
@@ -12067,4 +11643,5 @@ CKA_VALUE MULTILINE_OCTAL
 \370\161\012\334\271\374\175\062\140\346\353\257\212\001
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""Staat der Nederlanden Root CA - G2""
@@ -12192,4 +11769,5 @@ CKA_VALUE MULTILINE_OCTAL
 \002\153\331\132
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""Hongkong Post Root CA 1""
@@ -12322,4 +11900,5 @@ CKA_VALUE MULTILINE_OCTAL
 \362
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""SecureSign RootCA11""
@@ -12487,4 +12066,5 @@ CKA_VALUE MULTILINE_OCTAL
 \113\076\053\070\007\125\230\136\244
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""ACEDICOM Root""
@@ -12633,4 +12213,5 @@ CKA_VALUE MULTILINE_OCTAL
 \202\042\055\172\124\253\160\303\175\042\145\202\160\226
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""Microsec e-Szigno Root CA 2009""
@@ -12764,4 +12345,5 @@ CKA_VALUE MULTILINE_OCTAL
 \130\077\137
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""GlobalSign Root CA - R3""
@@ -12936,4 +12518,5 @@ CKA_VALUE MULTILINE_OCTAL
 \156\117\022\176\012\074\235\225
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""Autoridad de Certificacion Firmaprofesional CIF A62634068""
@@ -13104,4 +12687,5 @@ CKA_VALUE MULTILINE_OCTAL
 \333\374\046\210\307
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""Izenpe.com""
@@ -13308,4 +12892,5 @@ CKA_VALUE MULTILINE_OCTAL
 \167\110\320
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""Chambers of Commerce Root - 2008""
@@ -13516,4 +13101,5 @@ CKA_VALUE MULTILINE_OCTAL
 \351\233\256\325\124\300\164\200\321\013\102\237\301
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""Global Chambersign Root - 2008""
@@ -15382,4 +14968,5 @@ CKA_VALUE MULTILINE_OCTAL
 \342\342\104\276\134\367\352\034\365
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""Go Daddy Root Certificate Authority - G2""
@@ -15531,4 +15118,5 @@ CKA_VALUE MULTILINE_OCTAL
 \364
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""Starfield Root Certificate Authority - G2""
@@ -15682,4 +15270,5 @@ CKA_VALUE MULTILINE_OCTAL
 \261\050\272
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""Starfield Services Root Certificate Authority - G2""
@@ -15812,4 +15401,5 @@ CKA_VALUE MULTILINE_OCTAL
 \007\072\027\144\265\004\265\043\041\231\012\225\073\227\174\357
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""AffirmTrust Commercial""
@@ -15937,4 +15527,5 @@ CKA_VALUE MULTILINE_OCTAL
 \355\132\000\124\205\034\026\066\222\014\134\372\246\255\277\333
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""AffirmTrust Networking""
@@ -16094,4 +15685,5 @@ CKA_VALUE MULTILINE_OCTAL
 \051\340\266\270\011\150\031\034\030\103
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""AffirmTrust Premium""
@@ -16199,4 +15791,5 @@ CKA_VALUE MULTILINE_OCTAL
 \214\171
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""AffirmTrust Premium ECC""
@@ -16337,4 +15930,5 @@ CKA_VALUE MULTILINE_OCTAL
 \326\267\064\365\176\316\071\232\331\070\361\121\367\117\054
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""Certum Trusted Network CA""
@@ -16506,4 +16100,5 @@ CKA_VALUE MULTILINE_OCTAL
 \377\276\013\166\026\136\067\067\346\330\164\227\242\231\105\171
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""Certinomis - Autorit Racine""
@@ -16640,4 +16235,5 @@ CKA_VALUE MULTILINE_OCTAL
 \274\060\376\173\016\063\220\373\355\322\024\221\037\007\257
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""TWCA Root Certification Authority""
@@ -18030,4 +17626,5 @@ CKA_VALUE MULTILINE_OCTAL
 \201\050\174\247\175\047\353\000\256\215\067
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""Security Communication RootCA2""
@@ -18212,4 +17809,5 @@ CKA_VALUE MULTILINE_OCTAL
 \371\210\075\176\270\157\156\003\344\102
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""EC-ACC""
@@ -18374,4 +17972,5 @@ CKA_VALUE MULTILINE_OCTAL
 \113\321\047\327\270
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for Certificate ""Hellenic Academic and Research Institutions RootCA 2011""
@@ -18609,4 +18208,5 @@ CKA_VALUE MULTILINE_OCTAL
 \216\362\024\212\314\351\265\174\373\154\235\014\245\341\226
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""Actalis Authentication Root CA""
@@ -18739,4 +18339,5 @@ CKA_VALUE MULTILINE_OCTAL
 \145\353\127\331\363\127\226\273\110\315\201
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""Trustis FPS Root CA""
@@ -18939,4 +18540,5 @@ CKA_VALUE MULTILINE_OCTAL
 \177\045\245\362\110\000\300\244\001\332\077
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""StartCom Certification Authority""
@@ -19103,4 +18705,5 @@ CKA_VALUE MULTILINE_OCTAL
 \127\055\366\320\341\327\110
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""StartCom Certification Authority G2""
@@ -19262,4 +18865,5 @@ CKA_VALUE MULTILINE_OCTAL
 \327\201\011\361\311\307\046\015\254\230\026\126\240
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""Buypass Class 2 Root CA""
@@ -19420,4 +19024,5 @@ CKA_VALUE MULTILINE_OCTAL
 \061\356\006\274\163\277\023\142\012\237\307\271\227
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""Buypass Class 3 Root CA""
@@ -19561,4 +19166,5 @@ CKA_VALUE MULTILINE_OCTAL
 \116\223\303\244\124\024\133
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""T-TeleSec GlobalRoot Class 3""
@@ -19709,4 +19315,5 @@ CKA_VALUE MULTILINE_OCTAL
 \307\314\165\301\226\305\235
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""EE Certification Centre Root CA""
@@ -19938,4 +19545,5 @@ CKA_VALUE MULTILINE_OCTAL
 \175
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""TURKTRUST Certificate Services Provider Root 2007""
@@ -20086,4 +19694,5 @@ CKA_VALUE MULTILINE_OCTAL
 \164\145\327\134\376\243\342
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""D-TRUST Root Class 3 CA 2 2009""
@@ -20229,4 +19838,5 @@ CKA_VALUE MULTILINE_OCTAL
 \352\237\026\361\054\124\265
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""D-TRUST Root Class 3 CA 2 EV 2009""
@@ -20478,4 +20088,5 @@ CKA_VALUE MULTILINE_OCTAL
 \376\206\364\274\340\032\161\263\142\246
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""PSCProcert""
@@ -20636,4 +20247,5 @@ CKA_VALUE MULTILINE_OCTAL
 \303\055\375\024\052\220\231\271\007\314\237
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""China Internet Network Information Center EV Certificates Root""
@@ -20811,4 +20423,5 @@ CKA_VALUE MULTILINE_OCTAL
 \301\053\022\236\246\236\033\305\346\016\331\061\331
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""Swisscom Root CA 2""
@@ -20986,4 +20599,5 @@ CKA_VALUE MULTILINE_OCTAL
 \046\277\242\367
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""Swisscom Root EV CA 2""
@@ -21150,4 +20764,5 @@ CKA_VALUE MULTILINE_OCTAL
 \360\343\355\144\236\075\057\226\122\117\200\123\213
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""CA Disig Root R1""
@@ -21312,4 +20927,5 @@ CKA_VALUE MULTILINE_OCTAL
 \363\154\033\165\106\243\345\112\027\351\244\327\013
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""CA Disig Root R2""
@@ -21511,4 +21127,5 @@ CKA_VALUE MULTILINE_OCTAL
 \125\064\106\052\213\206\073
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""ACCVRAIZ1""
@@ -21670,4 +21287,5 @@ CKA_VALUE MULTILINE_OCTAL
 \053\006\320\004\315
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""TWCA Global Root CA""
@@ -21826,4 +21444,5 @@ CKA_VALUE MULTILINE_OCTAL
 \245\240\314\277\323\366\165\244\165\226\155\126
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""TeliaSonera Root CA v1""
@@ -22013,4 +21632,5 @@ CKA_VALUE MULTILINE_OCTAL
 \243\253\157\134\035\266\176\350\263\202\064\355\006\134\044
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""E-Tugra Certification Authority""
@@ -22161,4 +21781,5 @@ CKA_VALUE MULTILINE_OCTAL
 \005\047\216\023\241\156\302
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""T-TeleSec GlobalRoot Class 2""
@@ -22291,4 +21912,5 @@ CKA_VALUE MULTILINE_OCTAL
 \035\362\376\011\021\260\360\207\173\247\235
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""Atos TrustedRoot 2011""
@@ -22450,4 +22072,5 @@ CKA_VALUE MULTILINE_OCTAL
 \063\140\345\303
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""QuoVadis Root CA 1 G3""
@@ -22611,4 +22234,5 @@ CKA_VALUE MULTILINE_OCTAL
 \203\336\177\214
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""QuoVadis Root CA 2 G3""
@@ -22772,4 +22396,5 @@ CKA_VALUE MULTILINE_OCTAL
 \130\371\230\364
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""QuoVadis Root CA 3 G3""
@@ -22908,4 +22533,5 @@ CKA_VALUE MULTILINE_OCTAL
 \042\023\163\154\317\046\365\212\051\347
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""DigiCert Assured ID Root G2""
@@ -23025,4 +22651,5 @@ CKA_VALUE MULTILINE_OCTAL
 \352\226\143\152\145\105\222\225\001\264
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""DigiCert Assured ID Root G3""
@@ -23163,4 +22790,5 @@ CKA_VALUE MULTILINE_OCTAL
 \062\266
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""DigiCert Global Root G2""
@@ -23280,4 +22908,5 @@ CKA_VALUE MULTILINE_OCTAL
 \263\047\027
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""DigiCert Global Root G3""
@@ -23450,4 +23079,5 @@ CKA_VALUE MULTILINE_OCTAL
 \317\363\146\176
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""DigiCert Trusted Root G4""
@@ -23616,4 +23246,5 @@ CKA_VALUE MULTILINE_OCTAL
 \171\356\104\206\276\327\036\344\036\373
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""WoSign""
@@ -23777,4 +23408,5 @@ CKA_VALUE MULTILINE_OCTAL
 \234\313\051\213\070\112\013\016\220\215\272\241
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""WoSign China""
@@ -23953,4 +23585,5 @@ CKA_VALUE MULTILINE_OCTAL
 \065\123\205\006\112\135\237\255\273\033\137\164
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""COMODO RSA Certification Authority""
@@ -24134,4 +23767,5 @@ CKA_VALUE MULTILINE_OCTAL
 \250\375
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""USERTrust RSA Certification Authority""
@@ -24262,4 +23896,5 @@ CKA_VALUE MULTILINE_OCTAL
 \127\152\030
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""USERTrust ECC Certification Authority""
@@ -24373,4 +24008,5 @@ CKA_VALUE MULTILINE_OCTAL
 \173\013\370\237\204
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""GlobalSign ECC Root CA - R4""
@@ -24485,4 +24121,5 @@ CKA_VALUE MULTILINE_OCTAL
 \220\067
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""GlobalSign ECC Root CA - R5""
@@ -24659,4 +24296,5 @@ CKA_VALUE MULTILINE_OCTAL
 \145\110\041\012\057\327\334\176\240\314\145\176\171
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""VeriSign-C3SSA-G2-temporary-intermediate-after-1024bit-removal""
@@ -24830,4 +24468,5 @@ CKA_VALUE MULTILINE_OCTAL
 \367\200\173\041\147\047\060\131
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""Staat der Nederlanden Root CA - G3""
@@ -24993,4 +24632,5 @@ CKA_VALUE MULTILINE_OCTAL
 \356\354\327\056
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""Staat der Nederlanden EV Root CA""
@@ -25154,4 +24794,5 @@ CKA_VALUE MULTILINE_OCTAL
 \272\204\156\207
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""IdenTrust Commercial Root CA 1""
@@ -25315,4 +24956,5 @@ CKA_VALUE MULTILINE_OCTAL
 \267\254\266\255\267\312\076\001\357\234
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""IdenTrust Public Sector Root CA 1""
@@ -25459,4 +25101,5 @@ CKA_VALUE MULTILINE_OCTAL
 \073\303\035\374\377\262\117\250\342\366\060\036
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""S-TRUST Universal Root CA""
@@ -25621,4 +25264,5 @@ CKA_VALUE MULTILINE_OCTAL
 \105\366
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""Entrust Root Certification Authority - G2""
@@ -25765,4 +25409,5 @@ CKA_VALUE MULTILINE_OCTAL
 \231\267\046\101\133\045\140\256\320\110\032\356\006
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""Entrust Root Certification Authority - EC1""
@@ -25937,4 +25582,5 @@ CKA_VALUE MULTILINE_OCTAL
 \056
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""CFCA EV ROOT""
@@ -26234,4 +25880,5 @@ CKA_VALUE MULTILINE_OCTAL
 \372\253\101\341\113\266\065\013\300\233\025
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""TRKTRUST Elektronik Sertifika Hizmet Salaycs H5""
@@ -26277,164 +25924,4 @@ CKA_TRUST_CODE_SIGNING CK_TRUST CKT_NSS_TRUSTED_DELEGATOR
 CKA_TRUST_STEP_UP_APPROVED CK_BBOOL CK_FALSE
 
-#
-# Certificate ""TRKTRUST Elektronik Sertifika Hizmet Salaycs H6""
-#
-# Issuer: CN=T..RKTRUST Elektronik Sertifika Hizmet Sa..lay..c..s.. H6,O=T..RKTRUST Bilgi ..leti..im ve Bili..im G..venli..i Hizmetleri A....,L=Ankara,C=TR
-# Serial Number:7d:a1:f2:65:ec:8a
-# Subject: CN=T..RKTRUST Elektronik Sertifika Hizmet Sa..lay..c..s.. H6,O=T..RKTRUST Bilgi ..leti..im ve Bili..im G..venli..i Hizmetleri A....,L=Ankara,C=TR
-# Not Valid Before: Wed Dec 18 09:04:10 2013
-# Not Valid After : Sat Dec 16 09:04:10 2023
-# Fingerprint (SHA-256): 8D:E7:86:55:E1:BE:7F:78:47:80:0B:93:F6:94:D2:1D:36:8C:C0:6E:03:3E:7F:AB:04:BB:5E:B9:9D:A6:B7:00
-# Fingerprint (SHA1): 8A:5C:8C:EE:A5:03:E6:05:56:BA:D8:1B:D4:F6:C9:B0:ED:E5:2F:E0
-CKA_CLASS CK_OBJECT_CLASS CKO_CERTIFICATE
-CKA_TOKEN CK_BBOOL CK_TRUE
-CKA_PRIVATE CK_BBOOL CK_FALSE
-CKA_MODIFIABLE CK_BBOOL CK_FALSE
-CKA_LABEL UTF8 ""TRKTRUST Elektronik Sertifika Hizmet Salaycs H6""
-CKA_CERTIFICATE_TYPE CK_CERTIFICATE_TYPE CKC_X_509
-CKA_SUBJECT MULTILINE_OCTAL
-\060\201\261\061\013\060\011\006\003\125\004\006\023\002\124\122
-\061\017\060\015\006\003\125\004\007\014\006\101\156\153\141\162
-\141\061\115\060\113\006\003\125\004\012\014\104\124\303\234\122
-\113\124\122\125\123\124\040\102\151\154\147\151\040\304\260\154
-\145\164\151\305\237\151\155\040\166\145\040\102\151\154\151\305
-\237\151\155\040\107\303\274\166\145\156\154\151\304\237\151\040
-\110\151\172\155\145\164\154\145\162\151\040\101\056\305\236\056
-\061\102\060\100\006\003\125\004\003\014\071\124\303\234\122\113
-\124\122\125\123\124\040\105\154\145\153\164\162\157\156\151\153
-\040\123\145\162\164\151\146\151\153\141\040\110\151\172\155\145
-\164\040\123\141\304\237\154\141\171\304\261\143\304\261\163\304
-\261\040\110\066
-END
-CKA_ID UTF8 ""0""
-CKA_ISSUER MULTILINE_OCTAL
-\060\201\261\061\013\060\011\006\003\125\004\006\023\002\124\122
-\061\017\060\015\006\003\125\004\007\014\006\101\156\153\141\162
-\141\061\115\060\113\006\003\125\004\012\014\104\124\303\234\122
-\113\124\122\125\123\124\040\102\151\154\147\151\040\304\260\154
-\145\164\151\305\237\151\155\040\166\145\040\102\151\154\151\305
-\237\151\155\040\107\303\274\166\145\156\154\151\304\237\151\040
-\110\151\172\155\145\164\154\145\162\151\040\101\056\305\236\056
-\061\102\060\100\006\003\125\004\003\014\071\124\303\234\122\113
-\124\122\125\123\124\040\105\154\145\153\164\162\157\156\151\153
-\040\123\145\162\164\151\146\151\153\141\040\110\151\172\155\145
-\164\040\123\141\304\237\154\141\171\304\261\143\304\261\163\304
-\261\040\110\066
-END
-CKA_SERIAL_NUMBER MULTILINE_OCTAL
-\002\006\175\241\362\145\354\212
-END
-CKA_VALUE MULTILINE_OCTAL
-\060\202\004\046\060\202\003\016\240\003\002\001\002\002\006\175
-\241\362\145\354\212\060\015\006\011\052\206\110\206\367\015\001
-\001\013\005\000\060\201\261\061\013\060\011\006\003\125\004\006
-\023\002\124\122\061\017\060\015\006\003\125\004\007\014\006\101
-\156\153\141\162\141\061\115\060\113\006\003\125\004\012\014\104
-\124\303\234\122\113\124\122\125\123\124\040\102\151\154\147\151
-\040\304\260\154\145\164\151\305\237\151\155\040\166\145\040\102
-\151\154\151\305\237\151\155\040\107\303\274\166\145\156\154\151
-\304\237\151\040\110\151\172\155\145\164\154\145\162\151\040\101
-\056\305\236\056\061\102\060\100\006\003\125\004\003\014\071\124
-\303\234\122\113\124\122\125\123\124\040\105\154\145\153\164\162
-\157\156\151\153\040\123\145\162\164\151\146\151\153\141\040\110
-\151\172\155\145\164\040\123\141\304\237\154\141\171\304\261\143
-\304\261\163\304\261\040\110\066\060\036\027\015\061\063\061\062
-\061\070\060\071\060\064\061\060\132\027\015\062\063\061\062\061
-\066\060\071\060\064\061\060\132\060\201\261\061\013\060\011\006
-\003\125\004\006\023\002\124\122\061\017\060\015\006\003\125\004
-\007\014\006\101\156\153\141\162\141\061\115\060\113\006\003\125
-\004\012\014\104\124\303\234\122\113\124\122\125\123\124\040\102
-\151\154\147\151\040\304\260\154\145\164\151\305\237\151\155\040
-\166\145\040\102\151\154\151\305\237\151\155\040\107\303\274\166
-\145\156\154\151\304\237\151\040\110\151\172\155\145\164\154\145
-\162\151\040\101\056\305\236\056\061\102\060\100\006\003\125\004
-\003\014\071\124\303\234\122\113\124\122\125\123\124\040\105\154
-\145\153\164\162\157\156\151\153\040\123\145\162\164\151\146\151
-\153\141\040\110\151\172\155\145\164\040\123\141\304\237\154\141
-\171\304\261\143\304\261\163\304\261\040\110\066\060\202\001\042
-\060\015\006\011\052\206\110\206\367\015\001\001\001\005\000\003
-\202\001\017\000\060\202\001\012\002\202\001\001\000\235\260\150
-\326\350\275\024\226\243\000\012\232\361\364\307\314\221\115\161
-\170\167\271\367\041\046\025\163\121\026\224\011\107\005\342\063
-\365\150\232\065\377\334\113\057\062\307\260\355\342\202\345\157
-\332\332\352\254\306\006\317\045\015\101\201\366\301\070\042\275
-\371\261\245\246\263\001\274\077\120\027\053\366\351\146\125\324
-\063\263\134\370\103\040\170\223\125\026\160\031\062\346\211\327
-\144\353\275\110\120\375\366\320\101\003\302\164\267\375\366\200
-\317\133\305\253\244\326\225\022\233\347\227\023\062\003\351\324
-\253\103\133\026\355\063\042\144\051\266\322\223\255\057\154\330
-\075\266\366\035\016\064\356\322\175\251\125\017\040\364\375\051
-\273\221\133\034\175\306\102\070\155\102\050\155\324\001\373\315
-\210\227\111\176\270\363\203\370\265\230\057\263\047\013\110\136
-\126\347\116\243\063\263\104\326\245\362\030\224\355\034\036\251
-\225\134\142\112\370\015\147\121\251\257\041\325\370\062\235\171
-\272\032\137\345\004\125\115\023\106\377\362\317\164\307\032\143
-\155\303\037\027\022\303\036\020\076\140\010\263\061\002\003\001
-\000\001\243\102\060\100\060\035\006\003\125\035\016\004\026\004
-\024\335\125\027\023\366\254\350\110\041\312\357\265\257\321\000
-\062\355\236\214\265\060\016\006\003\125\035\017\001\001\377\004
-\004\003\002\001\006\060\017\006\003\125\035\023\001\001\377\004
-\005\060\003\001\001\377\060\015\006\011\052\206\110\206\367\015
-\001\001\013\005\000\003\202\001\001\000\157\130\015\227\103\252
-\026\124\076\277\251\337\222\105\077\205\013\273\126\323\014\122
-\314\310\277\166\147\136\346\252\263\247\357\271\254\264\020\024
-\015\164\176\075\155\255\321\175\320\232\251\245\312\030\073\002
-\100\056\052\234\120\024\213\376\127\176\127\134\021\011\113\066
-\105\122\367\075\254\024\375\104\337\213\227\043\324\303\301\356
-\324\123\225\376\054\112\376\015\160\252\273\213\057\055\313\062
-\243\202\362\124\337\330\362\335\327\110\162\356\112\243\051\226
-\303\104\316\156\265\222\207\166\244\273\364\222\154\316\054\024
-\011\146\216\215\255\026\265\307\033\011\141\073\343\040\242\003
-\200\216\255\176\121\000\116\307\226\206\373\103\230\167\175\050
-\307\217\330\052\156\347\204\157\227\101\051\000\026\136\115\342
-\023\352\131\300\143\147\072\104\373\230\374\004\323\060\162\246
-\366\207\011\127\255\166\246\035\143\232\375\327\145\310\170\203
-\053\165\073\245\133\270\015\135\177\276\043\256\126\125\224\130
-\357\037\201\214\052\262\315\346\233\143\236\030\274\345\153\006
-\264\013\230\113\050\136\257\210\130\313
-END
-
-# Trust for ""TRKTRUST Elektronik Sertifika Hizmet Salaycs H6""
-# Issuer: CN=T..RKTRUST Elektronik Sertifika Hizmet Sa..lay..c..s.. H6,O=T..RKTRUST Bilgi ..leti..im ve Bili..im G..venli..i Hizmetleri A....,L=Ankara,C=TR
-# Serial Number:7d:a1:f2:65:ec:8a
-# Subject: CN=T..RKTRUST Elektronik Sertifika Hizmet Sa..lay..c..s.. H6,O=T..RKTRUST Bilgi ..leti..im ve Bili..im G..venli..i Hizmetleri A....,L=Ankara,C=TR
-# Not Valid Before: Wed Dec 18 09:04:10 2013
-# Not Valid After : Sat Dec 16 09:04:10 2023
-# Fingerprint (SHA-256): 8D:E7:86:55:E1:BE:7F:78:47:80:0B:93:F6:94:D2:1D:36:8C:C0:6E:03:3E:7F:AB:04:BB:5E:B9:9D:A6:B7:00
-# Fingerprint (SHA1): 8A:5C:8C:EE:A5:03:E6:05:56:BA:D8:1B:D4:F6:C9:B0:ED:E5:2F:E0
-CKA_CLASS CK_OBJECT_CLASS CKO_NSS_TRUST
-CKA_TOKEN CK_BBOOL CK_TRUE
-CKA_PRIVATE CK_BBOOL CK_FALSE
-CKA_MODIFIABLE CK_BBOOL CK_FALSE
-CKA_LABEL UTF8 ""TRKTRUST Elektronik Sertifika Hizmet Salaycs H6""
-CKA_CERT_SHA1_HASH MULTILINE_OCTAL
-\212\134\214\356\245\003\346\005\126\272\330\033\324\366\311\260
-\355\345\057\340
-END
-CKA_CERT_MD5_HASH MULTILINE_OCTAL
-\370\305\356\052\153\276\225\215\010\367\045\112\352\161\076\106
-END
-CKA_ISSUER MULTILINE_OCTAL
-\060\201\261\061\013\060\011\006\003\125\004\006\023\002\124\122
-\061\017\060\015\006\003\125\004\007\014\006\101\156\153\141\162
-\141\061\115\060\113\006\003\125\004\012\014\104\124\303\234\122
-\113\124\122\125\123\124\040\102\151\154\147\151\040\304\260\154
-\145\164\151\305\237\151\155\040\166\145\040\102\151\154\151\305
-\237\151\155\040\107\303\274\166\145\156\154\151\304\237\151\040
-\110\151\172\155\145\164\154\145\162\151\040\101\056\305\236\056
-\061\102\060\100\006\003\125\004\003\014\071\124\303\234\122\113
-\124\122\125\123\124\040\105\154\145\153\164\162\157\156\151\153
-\040\123\145\162\164\151\146\151\153\141\040\110\151\172\155\145
-\164\040\123\141\304\237\154\141\171\304\261\143\304\261\163\304
-\261\040\110\066
-END
-CKA_SERIAL_NUMBER MULTILINE_OCTAL
-\002\006\175\241\362\145\354\212
-END
-CKA_TRUST_SERVER_AUTH CK_TRUST CKT_NSS_TRUSTED_DELEGATOR
-CKA_TRUST_EMAIL_PROTECTION CK_TRUST CKT_NSS_MUST_VERIFY_TRUST
-CKA_TRUST_CODE_SIGNING CK_TRUST CKT_NSS_MUST_VERIFY_TRUST
-CKA_TRUST_STEP_UP_APPROVED CK_BBOOL CK_FALSE
-
 #
 # Certificate ""Certinomis - Root CA""
@@ -26565,4 +26052,5 @@ CKA_VALUE MULTILINE_OCTAL
 \153\206\102\006\271\101
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""Certinomis - Root CA""
@@ -26703,4 +26191,5 @@ CKA_VALUE MULTILINE_OCTAL
 \065\255\201\307\116\161\272\210\023
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""OISTE WISeKey Global Root GB CA""
@@ -26837,4 +26326,5 @@ CKA_VALUE MULTILINE_OCTAL
 \217\271\312\314\156\201\061\366\173\234\172\171\344\147\161\030
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""Certification Authority of WoSign G2""
@@ -26945,4 +26435,5 @@ CKA_VALUE MULTILINE_OCTAL
 \056\153\361\221\262\220\145\364\232\346\220\356\112
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""CA WoSign ECC Root""
@@ -27077,4 +26568,5 @@ CKA_VALUE MULTILINE_OCTAL
 \326\040\036\343\163\267
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""SZAFIR ROOT CA2""
@@ -27254,4 +26746,5 @@ CKA_VALUE MULTILINE_OCTAL
 \016\265\271\276\044\217
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""Certum Trusted Network CA 2""
@@ -27440,4 +26933,5 @@ CKA_VALUE MULTILINE_OCTAL
 \276\157\152\247\365\054\102\355\062\255\266\041\236\276\274
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""Hellenic Academic and Research Institutions RootCA 2015""
@@ -27575,4 +27069,5 @@ CKA_VALUE MULTILINE_OCTAL
 \342\174\352\002\130\042\221
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""Hellenic Academic and Research Institutions ECC RootCA 2015""
@@ -27739,4 +27234,5 @@ CKA_VALUE MULTILINE_OCTAL
 \014\115\123\315\044\261\114\133\036\121\364\337\351\222\372
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""Certplus Root CA G1""
@@ -27844,4 +27340,5 @@ CKA_VALUE MULTILINE_OCTAL
 \123\223\221\032\223\256\160\152\147\272\327\236\345\141\032\137
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""Certplus Root CA G2""
@@ -28005,4 +27502,5 @@ CKA_VALUE MULTILINE_OCTAL
 \326\214\161
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""OpenTrust Root CA G1""
@@ -28167,4 +27665,5 @@ CKA_VALUE MULTILINE_OCTAL
 \113\122\012
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""OpenTrust Root CA G2""
@@ -28276,4 +27775,5 @@ CKA_VALUE MULTILINE_OCTAL
 \315\215\361\373\301
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""OpenTrust Root CA G3""
@@ -28439,4 +27939,5 @@ CKA_VALUE MULTILINE_OCTAL
 \376\216\036\127\242\315\100\235\176\142\042\332\336\030\047
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""ISRG Root X1""
@@ -28601,4 +28102,5 @@ CKA_VALUE MULTILINE_OCTAL
 \072\117\110\366\213\266\263
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""AC RAIZ FNMT-RCM""
@@ -28725,4 +28227,5 @@ CKA_VALUE MULTILINE_OCTAL
 \304\220\276\361\271
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""Amazon Root CA 1""
@@ -28881,4 +28384,5 @@ CKA_VALUE MULTILINE_OCTAL
 \340\373\011\140\154
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""Amazon Root CA 2""
@@ -28980,4 +28484,5 @@ CKA_VALUE MULTILINE_OCTAL
 \143\044\110\034\337\060\175\325\150\073
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""Amazon Root CA 3""
@@ -29083,4 +28588,5 @@ CKA_VALUE MULTILINE_OCTAL
 \012\166\324\245\274\020
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""Amazon Root CA 4""
@@ -29249,4 +28755,5 @@ CKA_VALUE MULTILINE_OCTAL
 \045\307\043\200\203\012\353
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""LuxTrust Global Root 2""
@@ -29397,4 +28904,5 @@ CKA_VALUE MULTILINE_OCTAL
 \322\063\340\377\275\321\124\071\051\017
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""Symantec Class 1 Public Primary Certification Authority - G6""
@@ -29550,4 +29058,5 @@ CKA_VALUE MULTILINE_OCTAL
 \157\374\132\344\202\125\131\257\061\251
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""Symantec Class 2 Public Primary Certification Authority - G6""
@@ -29682,4 +29191,5 @@ CKA_VALUE MULTILINE_OCTAL
 \362\014\105\111\071\277\231\004\034\323\020\240
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""Symantec Class 1 Public Primary Certification Authority - G4""
@@ -29814,4 +29324,5 @@ CKA_VALUE MULTILINE_OCTAL
 \051\246\330\107\331\240\226\030\333\362\105\263
 END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
 
 # Trust for ""Symantec Class 2 Public Primary Certification Authority - G4""
@@ -29855,2 +29366,312 @@ CKA_TRUST_EMAIL_PROTECTION CK_TRUST CKT_NSS_TRUSTED_DELEGATOR
 CKA_TRUST_CODE_SIGNING CK_TRUST CKT_NSS_MUST_VERIFY_TRUST
 CKA_TRUST_STEP_UP_APPROVED CK_BBOOL CK_FALSE
+
+#
+# Certificate ""D-TRUST Root CA 3 2013""
+#
+# Issuer: CN=D-TRUST Root CA 3 2013,O=D-Trust GmbH,C=DE
+# Serial Number: 1039788 (0xfddac)
+# Subject: CN=D-TRUST Root CA 3 2013,O=D-Trust GmbH,C=DE
+# Not Valid Before: Fri Sep 20 08:25:51 2013
+# Not Valid After : Wed Sep 20 08:25:51 2028
+# Fingerprint (SHA-256): A1:A8:6D:04:12:1E:B8:7F:02:7C:66:F5:33:03:C2:8E:57:39:F9:43:FC:84:B3:8A:D6:AF:00:90:35:DD:94:57
+# Fingerprint (SHA1): 6C:7C:CC:E7:D4:AE:51:5F:99:08:CD:3F:F6:E8:C3:78:DF:6F:EF:97
+CKA_CLASS CK_OBJECT_CLASS CKO_CERTIFICATE
+CKA_TOKEN CK_BBOOL CK_TRUE
+CKA_PRIVATE CK_BBOOL CK_FALSE
+CKA_MODIFIABLE CK_BBOOL CK_FALSE
+CKA_LABEL UTF8 ""D-TRUST Root CA 3 2013""
+CKA_CERTIFICATE_TYPE CK_CERTIFICATE_TYPE CKC_X_509
+CKA_SUBJECT MULTILINE_OCTAL
+\060\105\061\013\060\011\006\003\125\004\006\023\002\104\105\061
+\025\060\023\006\003\125\004\012\014\014\104\055\124\162\165\163
+\164\040\107\155\142\110\061\037\060\035\006\003\125\004\003\014
+\026\104\055\124\122\125\123\124\040\122\157\157\164\040\103\101
+\040\063\040\062\060\061\063
+END
+CKA_ID UTF8 ""0""
+CKA_ISSUER MULTILINE_OCTAL
+\060\105\061\013\060\011\006\003\125\004\006\023\002\104\105\061
+\025\060\023\006\003\125\004\012\014\014\104\055\124\162\165\163
+\164\040\107\155\142\110\061\037\060\035\006\003\125\004\003\014
+\026\104\055\124\122\125\123\124\040\122\157\157\164\040\103\101
+\040\063\040\062\060\061\063
+END
+CKA_SERIAL_NUMBER MULTILINE_OCTAL
+\002\003\017\335\254
+END
+CKA_VALUE MULTILINE_OCTAL
+\060\202\004\016\060\202\002\366\240\003\002\001\002\002\003\017
+\335\254\060\015\006\011\052\206\110\206\367\015\001\001\013\005
+\000\060\105\061\013\060\011\006\003\125\004\006\023\002\104\105
+\061\025\060\023\006\003\125\004\012\014\014\104\055\124\162\165
+\163\164\040\107\155\142\110\061\037\060\035\006\003\125\004\003
+\014\026\104\055\124\122\125\123\124\040\122\157\157\164\040\103
+\101\040\063\040\062\060\061\063\060\036\027\015\061\063\060\071
+\062\060\060\070\062\065\065\061\132\027\015\062\070\060\071\062
+\060\060\070\062\065\065\061\132\060\105\061\013\060\011\006\003
+\125\004\006\023\002\104\105\061\025\060\023\006\003\125\004\012
+\014\014\104\055\124\162\165\163\164\040\107\155\142\110\061\037
+\060\035\006\003\125\004\003\014\026\104\055\124\122\125\123\124
+\040\122\157\157\164\040\103\101\040\063\040\062\060\061\063\060
+\202\001\042\060\015\006\011\052\206\110\206\367\015\001\001\001
+\005\000\003\202\001\017\000\060\202\001\012\002\202\001\001\000
+\304\173\102\222\202\037\354\355\124\230\216\022\300\312\011\337
+\223\156\072\223\134\033\344\020\167\236\116\151\210\154\366\341
+\151\362\366\233\242\141\261\275\007\040\164\230\145\361\214\046
+\010\315\250\065\312\200\066\321\143\155\350\104\172\202\303\154
+\136\336\273\350\066\322\304\150\066\214\237\062\275\204\042\340
+\334\302\356\020\106\071\155\257\223\071\256\207\346\303\274\011
+\311\054\153\147\133\331\233\166\165\114\013\340\273\305\327\274
+\076\171\362\137\276\321\220\127\371\256\366\146\137\061\277\323
+\155\217\247\272\112\363\043\145\273\267\357\243\045\327\012\352
+\130\266\357\210\372\372\171\262\122\130\325\360\254\214\241\121
+\164\051\225\252\121\073\220\062\003\237\034\162\164\220\336\075
+\355\141\322\345\343\375\144\107\345\271\267\112\251\367\037\256
+\226\206\004\254\057\343\244\201\167\267\132\026\377\330\017\077
+\366\267\170\314\244\257\372\133\074\022\133\250\122\211\162\357
+\210\363\325\104\201\206\225\043\237\173\335\274\331\064\357\174
+\224\074\252\300\101\302\343\235\120\032\300\344\031\042\374\263
+\002\003\001\000\001\243\202\001\005\060\202\001\001\060\017\006
+\003\125\035\023\001\001\377\004\005\060\003\001\001\377\060\035
+\006\003\125\035\016\004\026\004\024\077\220\310\175\307\025\157
+\363\044\217\251\303\057\113\242\017\041\262\057\347\060\016\006
+\003\125\035\017\001\001\377\004\004\003\002\001\006\060\201\276
+\006\003\125\035\037\004\201\266\060\201\263\060\164\240\162\240
+\160\206\156\154\144\141\160\072\057\057\144\151\162\145\143\164
+\157\162\171\056\144\055\164\162\165\163\164\056\156\145\164\057
+\103\116\075\104\055\124\122\125\123\124\045\062\060\122\157\157
+\164\045\062\060\103\101\045\062\060\063\045\062\060\062\060\061
+\063\054\117\075\104\055\124\162\165\163\164\045\062\060\107\155
+\142\110\054\103\075\104\105\077\143\145\162\164\151\146\151\143
+\141\164\145\162\145\166\157\143\141\164\151\157\156\154\151\163
+\164\060\073\240\071\240\067\206\065\150\164\164\160\072\057\057
+\143\162\154\056\144\055\164\162\165\163\164\056\156\145\164\057
+\143\162\154\057\144\055\164\162\165\163\164\137\162\157\157\164
+\137\143\141\137\063\137\062\060\061\063\056\143\162\154\060\015
+\006\011\052\206\110\206\367\015\001\001\013\005\000\003\202\001
+\001\000\016\131\016\130\344\164\110\043\104\317\064\041\265\234
+\024\032\255\232\113\267\263\210\155\134\251\027\160\360\052\237
+\215\173\371\173\205\372\307\071\350\020\010\260\065\053\137\317
+\002\322\323\234\310\013\036\356\005\124\256\067\223\004\011\175
+\154\217\302\164\274\370\034\224\276\061\001\100\055\363\044\040
+\267\204\125\054\134\310\365\164\112\020\031\213\243\307\355\065
+\326\011\110\323\016\300\272\071\250\260\106\002\260\333\306\210
+\131\302\276\374\173\261\053\317\176\142\207\125\226\314\001\157
+\233\147\041\225\065\213\370\020\374\161\033\267\113\067\151\246
+\073\326\354\213\356\301\260\363\045\311\217\222\175\241\352\303
+\312\104\277\046\245\164\222\234\343\164\353\235\164\331\313\115
+\207\330\374\264\151\154\213\240\103\007\140\170\227\351\331\223
+\174\302\106\274\233\067\122\243\355\212\074\023\251\173\123\113
+\111\232\021\005\054\013\156\126\254\037\056\202\154\340\151\147
+\265\016\155\055\331\344\300\025\361\077\372\030\162\341\025\155
+\047\133\055\060\050\053\237\110\232\144\053\231\357\362\165\111
+\137\134
+END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
+
+# Trust for ""D-TRUST Root CA 3 2013""
+# Issuer: CN=D-TRUST Root CA 3 2013,O=D-Trust GmbH,C=DE
+# Serial Number: 1039788 (0xfddac)
+# Subject: CN=D-TRUST Root CA 3 2013,O=D-Trust GmbH,C=DE
+# Not Valid Before: Fri Sep 20 08:25:51 2013
+# Not Valid After : Wed Sep 20 08:25:51 2028
+# Fingerprint (SHA-256): A1:A8:6D:04:12:1E:B8:7F:02:7C:66:F5:33:03:C2:8E:57:39:F9:43:FC:84:B3:8A:D6:AF:00:90:35:DD:94:57
+# Fingerprint (SHA1): 6C:7C:CC:E7:D4:AE:51:5F:99:08:CD:3F:F6:E8:C3:78:DF:6F:EF:97
+CKA_CLASS CK_OBJECT_CLASS CKO_NSS_TRUST
+CKA_TOKEN CK_BBOOL CK_TRUE
+CKA_PRIVATE CK_BBOOL CK_FALSE
+CKA_MODIFIABLE CK_BBOOL CK_FALSE
+CKA_LABEL UTF8 ""D-TRUST Root CA 3 2013""
+CKA_CERT_SHA1_HASH MULTILINE_OCTAL
+\154\174\314\347\324\256\121\137\231\010\315\077\366\350\303\170
+\337\157\357\227
+END
+CKA_CERT_MD5_HASH MULTILINE_OCTAL
+\267\042\146\230\176\326\003\340\301\161\346\165\315\126\105\277
+END
+CKA_ISSUER MULTILINE_OCTAL
+\060\105\061\013\060\011\006\003\125\004\006\023\002\104\105\061
+\025\060\023\006\003\125\004\012\014\014\104\055\124\162\165\163
+\164\040\107\155\142\110\061\037\060\035\006\003\125\004\003\014
+\026\104\055\124\122\125\123\124\040\122\157\157\164\040\103\101
+\040\063\040\062\060\061\063
+END
+CKA_SERIAL_NUMBER MULTILINE_OCTAL
+\002\003\017\335\254
+END
+CKA_TRUST_SERVER_AUTH CK_TRUST CKT_NSS_MUST_VERIFY_TRUST
+CKA_TRUST_EMAIL_PROTECTION CK_TRUST CKT_NSS_TRUSTED_DELEGATOR
+CKA_TRUST_CODE_SIGNING CK_TRUST CKT_NSS_MUST_VERIFY_TRUST
+CKA_TRUST_STEP_UP_APPROVED CK_BBOOL CK_FALSE
+
+#
+# Certificate ""TUBITAK Kamu SM SSL Kok Sertifikasi - Surum 1""
+#
+# Issuer: CN=TUBITAK Kamu SM SSL Kok Sertifikasi - Surum 1,OU=Kamu Sertifikasyon Merkezi - Kamu SM,O=Turkiye Bilimsel ve Teknolojik Arastirma Kurumu - TUBITAK,L=Gebze - Kocaeli,C=TR
+# Serial Number: 1 (0x1)
+# Subject: CN=TUBITAK Kamu SM SSL Kok Sertifikasi - Surum 1,OU=Kamu Sertifikasyon Merkezi - Kamu SM,O=Turkiye Bilimsel ve Teknolojik Arastirma Kurumu - TUBITAK,L=Gebze - Kocaeli,C=TR
+# Not Valid Before: Mon Nov 25 08:25:55 2013
+# Not Valid After : Sun Oct 25 08:25:55 2043
+# Fingerprint (SHA-256): 46:ED:C3:68:90:46:D5:3A:45:3F:B3:10:4A:B8:0D:CA:EC:65:8B:26:60:EA:16:29:DD:7E:86:79:90:64:87:16
+# Fingerprint (SHA1): 31:43:64:9B:EC:CE:27:EC:ED:3A:3F:0B:8F:0D:E4:E8:91:DD:EE:CA
+CKA_CLASS CK_OBJECT_CLASS CKO_CERTIFICATE
+CKA_TOKEN CK_BBOOL CK_TRUE
+CKA_PRIVATE CK_BBOOL CK_FALSE
+CKA_MODIFIABLE CK_BBOOL CK_FALSE
+CKA_LABEL UTF8 ""TUBITAK Kamu SM SSL Kok Sertifikasi - Surum 1""
+CKA_CERTIFICATE_TYPE CK_CERTIFICATE_TYPE CKC_X_509
+CKA_SUBJECT MULTILINE_OCTAL
+\060\201\322\061\013\060\011\006\003\125\004\006\023\002\124\122
+\061\030\060\026\006\003\125\004\007\023\017\107\145\142\172\145
+\040\055\040\113\157\143\141\145\154\151\061\102\060\100\006\003
+\125\004\012\023\071\124\165\162\153\151\171\145\040\102\151\154
+\151\155\163\145\154\040\166\145\040\124\145\153\156\157\154\157
+\152\151\153\040\101\162\141\163\164\151\162\155\141\040\113\165
+\162\165\155\165\040\055\040\124\125\102\111\124\101\113\061\055
+\060\053\006\003\125\004\013\023\044\113\141\155\165\040\123\145
+\162\164\151\146\151\153\141\163\171\157\156\040\115\145\162\153
+\145\172\151\040\055\040\113\141\155\165\040\123\115\061\066\060
+\064\006\003\125\004\003\023\055\124\125\102\111\124\101\113\040
+\113\141\155\165\040\123\115\040\123\123\114\040\113\157\153\040
+\123\145\162\164\151\146\151\153\141\163\151\040\055\040\123\165
+\162\165\155\040\061
+END
+CKA_ID UTF8 ""0""
+CKA_ISSUER MULTILINE_OCTAL
+\060\201\322\061\013\060\011\006\003\125\004\006\023\002\124\122
+\061\030\060\026\006\003\125\004\007\023\017\107\145\142\172\145
+\040\055\040\113\157\143\141\145\154\151\061\102\060\100\006\003
+\125\004\012\023\071\124\165\162\153\151\171\145\040\102\151\154
+\151\155\163\145\154\040\166\145\040\124\145\153\156\157\154\157
+\152\151\153\040\101\162\141\163\164\151\162\155\141\040\113\165
+\162\165\155\165\040\055\040\124\125\102\111\124\101\113\061\055
+\060\053\006\003\125\004\013\023\044\113\141\155\165\040\123\145
+\162\164\151\146\151\153\141\163\171\157\156\040\115\145\162\153
+\145\172\151\040\055\040\113\141\155\165\040\123\115\061\066\060
+\064\006\003\125\004\003\023\055\124\125\102\111\124\101\113\040
+\113\141\155\165\040\123\115\040\123\123\114\040\113\157\153\040
+\123\145\162\164\151\146\151\153\141\163\151\040\055\040\123\165
+\162\165\155\040\061
+END
+CKA_SERIAL_NUMBER MULTILINE_OCTAL
+\002\001\001
+END
+CKA_VALUE MULTILINE_OCTAL
+\060\202\004\143\060\202\003\113\240\003\002\001\002\002\001\001
+\060\015\006\011\052\206\110\206\367\015\001\001\013\005\000\060
+\201\322\061\013\060\011\006\003\125\004\006\023\002\124\122\061
+\030\060\026\006\003\125\004\007\023\017\107\145\142\172\145\040
+\055\040\113\157\143\141\145\154\151\061\102\060\100\006\003\125
+\004\012\023\071\124\165\162\153\151\171\145\040\102\151\154\151
+\155\163\145\154\040\166\145\040\124\145\153\156\157\154\157\152
+\151\153\040\101\162\141\163\164\151\162\155\141\040\113\165\162
+\165\155\165\040\055\040\124\125\102\111\124\101\113\061\055\060
+\053\006\003\125\004\013\023\044\113\141\155\165\040\123\145\162
+\164\151\146\151\153\141\163\171\157\156\040\115\145\162\153\145
+\172\151\040\055\040\113\141\155\165\040\123\115\061\066\060\064
+\006\003\125\004\003\023\055\124\125\102\111\124\101\113\040\113
+\141\155\165\040\123\115\040\123\123\114\040\113\157\153\040\123
+\145\162\164\151\146\151\153\141\163\151\040\055\040\123\165\162
+\165\155\040\061\060\036\027\015\061\063\061\061\062\065\060\070
+\062\065\065\065\132\027\015\064\063\061\060\062\065\060\070\062
+\065\065\065\132\060\201\322\061\013\060\011\006\003\125\004\006
+\023\002\124\122\061\030\060\026\006\003\125\004\007\023\017\107
+\145\142\172\145\040\055\040\113\157\143\141\145\154\151\061\102
+\060\100\006\003\125\004\012\023\071\124\165\162\153\151\171\145
+\040\102\151\154\151\155\163\145\154\040\166\145\040\124\145\153
+\156\157\154\157\152\151\153\040\101\162\141\163\164\151\162\155
+\141\040\113\165\162\165\155\165\040\055\040\124\125\102\111\124
+\101\113\061\055\060\053\006\003\125\004\013\023\044\113\141\155
+\165\040\123\145\162\164\151\146\151\153\141\163\171\157\156\040
+\115\145\162\153\145\172\151\040\055\040\113\141\155\165\040\123
+\115\061\066\060\064\006\003\125\004\003\023\055\124\125\102\111
+\124\101\113\040\113\141\155\165\040\123\115\040\123\123\114\040
+\113\157\153\040\123\145\162\164\151\146\151\153\141\163\151\040
+\055\040\123\165\162\165\155\040\061\060\202\001\042\060\015\006
+\011\052\206\110\206\367\015\001\001\001\005\000\003\202\001\017
+\000\060\202\001\012\002\202\001\001\000\257\165\060\063\252\273
+\153\323\231\054\022\067\204\331\215\173\227\200\323\156\347\377
+\233\120\225\076\220\225\126\102\327\031\174\046\204\215\222\372
+\001\035\072\017\342\144\070\267\214\274\350\210\371\213\044\253
+\056\243\365\067\344\100\216\030\045\171\203\165\037\073\377\154
+\250\305\306\126\370\264\355\212\104\243\253\154\114\374\035\320
+\334\357\150\275\317\344\252\316\360\125\367\242\064\324\203\153
+\067\174\034\302\376\265\003\354\127\316\274\264\265\305\355\000
+\017\123\067\052\115\364\117\014\203\373\206\317\313\376\214\116
+\275\207\371\247\213\041\127\234\172\337\003\147\211\054\235\227
+\141\247\020\270\125\220\177\016\055\047\070\164\337\347\375\332
+\116\022\343\115\025\042\002\310\340\340\374\017\255\212\327\311
+\124\120\314\073\017\312\026\200\204\320\121\126\303\216\126\177
+\211\042\063\057\346\205\012\275\245\250\033\066\336\323\334\054
+\155\073\307\023\275\131\043\054\346\345\244\367\330\013\355\352
+\220\100\104\250\225\273\223\325\320\200\064\266\106\170\016\037
+\000\223\106\341\356\351\371\354\117\027\002\003\001\000\001\243
+\102\060\100\060\035\006\003\125\035\016\004\026\004\024\145\077
+\307\212\206\306\074\335\074\124\134\065\370\072\355\122\014\107
+\127\310\060\016\006\003\125\035\017\001\001\377\004\004\003\002
+\001\006\060\017\006\003\125\035\023\001\001\377\004\005\060\003
+\001\001\377\060\015\006\011\052\206\110\206\367\015\001\001\013
+\005\000\003\202\001\001\000\052\077\341\361\062\216\256\341\230
+\134\113\136\317\153\036\152\011\322\042\251\022\307\136\127\175
+\163\126\144\200\204\172\223\344\011\271\020\315\237\052\047\341
+\000\167\276\110\310\065\250\201\237\344\270\054\311\177\016\260
+\322\113\067\135\352\271\325\013\136\064\275\364\163\051\303\355
+\046\025\234\176\010\123\212\130\215\320\113\050\337\301\263\337
+\040\363\371\343\343\072\337\314\234\224\330\116\117\303\153\027
+\267\367\162\350\255\146\063\265\045\123\253\340\370\114\251\235
+\375\362\015\272\256\271\331\252\306\153\371\223\273\256\253\270
+\227\074\003\032\272\103\306\226\271\105\162\070\263\247\241\226
+\075\221\173\176\300\041\123\114\207\355\362\013\124\225\121\223
+\325\042\245\015\212\361\223\016\076\124\016\260\330\311\116\334
+\362\061\062\126\352\144\371\352\265\235\026\146\102\162\363\177
+\323\261\061\103\374\244\216\027\361\155\043\253\224\146\370\255
+\373\017\010\156\046\055\177\027\007\011\262\214\373\120\300\237
+\226\215\317\266\375\000\235\132\024\232\277\002\104\365\301\302
+\237\042\136\242\017\241\343
+END
+CKA_NSS_MOZILLA_CA_POLICY CK_BBOOL CK_TRUE
+
+# Trust for ""TUBITAK Kamu SM SSL Kok Sertifikasi - Surum 1""
+# Issuer: CN=TUBITAK Kamu SM SSL Kok Sertifikasi - Surum 1,OU=Kamu Sertifikasyon Merkezi - Kamu SM,O=Turkiye Bilimsel ve Teknolojik Arastirma Kurumu - TUBITAK,L=Gebze - Kocaeli,C=TR
+# Serial Number: 1 (0x1)
+# Subject: CN=TUBITAK Kamu SM SSL Kok Sertifikasi - Surum 1,OU=Kamu Sertifikasyon Merkezi - Kamu SM,O=Turkiye Bilimsel ve Teknolojik Arastirma Kurumu - TUBITAK,L=Gebze - Kocaeli,C=TR
+# Not Valid Before: Mon Nov 25 08:25:55 2013
+# Not Valid After : Sun Oct 25 08:25:55 2043
+# Fingerprint (SHA-256): 46:ED:C3:68:90:46:D5:3A:45:3F:B3:10:4A:B8:0D:CA:EC:65:8B:26:60:EA:16:29:DD:7E:86:79:90:64:87:16
+# Fingerprint (SHA1): 31:43:64:9B:EC:CE:27:EC:ED:3A:3F:0B:8F:0D:E4:E8:91:DD:EE:CA
+CKA_CLASS CK_OBJECT_CLASS CKO_NSS_TRUST
+CKA_TOKEN CK_BBOOL CK_TRUE
+CKA_PRIVATE CK_BBOOL CK_FALSE
+CKA_MODIFIABLE CK_BBOOL CK_FALSE
+CKA_LABEL UTF8 ""TUBITAK Kamu SM SSL Kok Sertifikasi - Surum 1""
+CKA_CERT_SHA1_HASH MULTILINE_OCTAL
+\061\103\144\233\354\316\047\354\355\072\077\013\217\015\344\350
+\221\335\356\312
+END
+CKA_CERT_MD5_HASH MULTILINE_OCTAL
+\334\000\201\334\151\057\076\057\260\073\366\075\132\221\216\111
+END
+CKA_ISSUER MULTILINE_OCTAL
+\060\201\322\061\013\060\011\006\003\125\004\006\023\002\124\122
+\061\030\060\026\006\003\125\004\007\023\017\107\145\142\172\145
+\040\055\040\113\157\143\141\145\154\151\061\102\060\100\006\003
+\125\004\012\023\071\124\165\162\153\151\171\145\040\102\151\154
+\151\155\163\145\154\040\166\145\040\124\145\153\156\157\154\157
+\152\151\153\040\101\162\141\163\164\151\162\155\141\040\113\165
+\162\165\155\165\040\055\040\124\125\102\111\124\101\113\061\055
+\060\053\006\003\125\004\013\023\044\113\141\155\165\040\123\145
+\162\164\151\146\151\153\141\163\171\157\156\040\115\145\162\153
+\145\172\151\040\055\040\113\141\155\165\040\123\115\061\066\060
+\064\006\003\125\004\003\023\055\124\125\102\111\124\101\113\040
+\113\141\155\165\040\123\115\040\123\123\114\040\113\157\153\040
+\123\145\162\164\151\146\151\153\141\163\151\040\055\040\123\165
+\162\165\155\040\061
+END
+CKA_SERIAL_NUMBER MULTILINE_OCTAL
+\002\001\001
+END
+CKA_TRUST_SERVER_AUTH CK_TRUST CKT_NSS_TRUSTED_DELEGATOR
+CKA_TRUST_EMAIL_PROTECTION CK_TRUST CKT_NSS_MUST_VERIFY_TRUST
+CKA_TRUST_CODE_SIGNING CK_TRUST CKT_NSS_MUST_VERIFY_TRUST
+CKA_TRUST_STEP_UP_APPROVED CK_BBOOL CK_FALSE
","tools: update certdata.txt

This is the certdata.txt[0] that ships in NSS 3.30.2, released on
2017-04-20.

[0] https://hg.mozilla.org/projects/nss/raw-file/NSS_3_30_2_RTM/lib/ckfw/builtins/certdata.txt

PR-URL: https://github.com/nodejs/node/pull/13279
Reviewed-By: Sam Roberts <vieuxtech@gmail.com>
Reviewed-By: Colin Ihrig <cjihrig@gmail.com>
Reviewed-By: James M Snell <jasnell@gmail.com>

"
589,JavaScript,9e6c2ba68a46ee693cf0b4875966f96a6dc261cf,https://github.com/nodejs/node/commit/9e6c2ba68a46ee693cf0b4875966f96a6dc261cf,P,nodejs,node,"[0, 0, 0, 0, 0, 0, 0, 1, 6, 4, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/test/parallel/test-http2-client-upload.js b/test/parallel/test-http2-client-upload.js
index 78c6d47cbb..c5b052d2fe 100644
--- a/test/parallel/test-http2-client-upload.js
+++ b/test/parallel/test-http2-client-upload.js
@@ -22,4 +22,10 @@ fs.readFile(loc, common.mustCall((err, data) => {
 
   const server = http2.createServer();
+  let client;
+
+  const countdown = new Countdown(3, () => {
+    server.close();
+    client.close();
+  });
 
   server.on('stream', common.mustCall((stream) => {
@@ -29,4 +35,8 @@ fs.readFile(loc, common.mustCall((err, data) => {
       assert.deepStrictEqual(data, fileData);
     }));
+    // Waiting on close avoids spurious ECONNRESET seen in windows CI.
+    // Not sure if this is actually a bug; more details at
+    // https://github.com/nodejs/node/issues/20750#issuecomment-511015247
+    stream.on('close', () => countdown.dec());
     stream.respond();
     stream.end();
@@ -34,10 +44,5 @@ fs.readFile(loc, common.mustCall((err, data) => {
 
   server.listen(0, common.mustCall(() => {
-    const client = http2.connect(`http://localhost:${server.address().port}`);
-
-    const countdown = new Countdown(2, () => {
-      server.close();
-      client.close();
-    });
+    client = http2.connect(`http://localhost:${server.address().port}`);
 
     const req = client.request({ ':method': 'POST' });
","test: fix flaky test-http2-client-upload

Wait for close event on server stream before shuting down server and
client to avoid races seen on windows CI.

Refs: https://github.com/nodejs/node/issues/20750#issuecomment-511015247

PR-URL: https://github.com/nodejs/node/pull/29889
Refs: https://github.com/nodejs/node/issues/29852
Reviewed-By: Anna Henningsen <anna@addaleax.net>
Reviewed-By: Rich Trott <rtrott@gmail.com>
Reviewed-By: James M Snell <jasnell@gmail.com>

"
593,JavaScript,28d79716ffbf33a21652d431a9215d608cfb1286,https://github.com/mrdoob/three.js/commit/28d79716ffbf33a21652d431a9215d608cfb1286,P,mrdoob,three.js,"[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/test/unit/editor/TestCmdSerialization.js b/test/unit/editor/TestCmdSerialization.js
index 84aac8916c..178937f61a 100755
--- a/test/unit/editor/TestCmdSerialization.js
+++ b/test/unit/editor/TestCmdSerialization.js
@@ -50,11 +50,11 @@ test( ""Test Serialization (simple)"", function() {
 	};
 
-	var functions = [ addObject, addScript, moveObject ];
+	var setups = [ addObject, addScript, moveObject ];
 
 	// Forward tests
 
-	for (var i = 0; i < functions.length ; i++ ) {
+	for (var i = 0; i < setups.length ; i++ ) {
 
-		functions[i]();
+		setups[i]();
 
 		// Check for correct serialization
@@ -79,7 +79,7 @@ test( ""Test Serialization (simple)"", function() {
 	// Backward tests
 
-	for (var i = 0; i < functions.length ; i++ ) {
+	for (var i = 0; i < setups.length ; i++ ) {
 
-		functions[i]();
+		setups[i]();
 
 		editor.history.goToState( 0 );
","rename

"
599,JavaScript,15c9c4f88851808c0d4380d267e389c3ac435289,https://github.com/mrdoob/three.js/commit/15c9c4f88851808c0d4380d267e389c3ac435289,P,mrdoob,three.js,"[1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/docs/api/en/scenes/Scene.html b/docs/api/en/scenes/Scene.html
index da0f666b8e..2ff3d1f101 100644
--- a/docs/api/en/scenes/Scene.html
+++ b/docs/api/en/scenes/Scene.html
@@ -58,5 +58,5 @@
 		</p>
 
-		<h3>[method:Object toJSON]</h3>
+		<h3>[method:Object toJSON]( [param:Object meta] )</h3>
 		<p>
 		meta -- object containing metadata such as textures or images for the scene.<br />
","update scene.html

`toJSON` should be a func.
"
610,JavaScript,3b4a01ec59c3ccc30509379121d922c2bf52b0d6,https://github.com/typicode/json-server/commit/3b4a01ec59c3ccc30509379121d922c2bf52b0d6,P,typicode,json-server,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 0, 1, 0, 0, 0, 0]","diff --git a/CHANGELOG.md b/CHANGELOG.md
index 874a54b..777d047 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -1,4 +1,10 @@
 # Change Log
 
+## [0.8.10][Unreleased]
+
+### Added 
+
+* CLI option `-ng/--no-gzip` to disable `gzip` compression
+
 ## [0.8.9][2016-03-17]
 
@@ -14,5 +20,5 @@
 ## [0.8.7][2016-01-22]
 
-## Added
+### Added
 
 * `gzip` compression to improve performances
","Update CHANGELOG.md
"
616,JavaScript,6051dde5f41cf58eb30e7154ea14cfafba23ee6a,https://github.com/typicode/json-server/commit/6051dde5f41cf58eb30e7154ea14cfafba23ee6a,P,typicode,json-server,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 0, 0, 0, 0, 0, 0]","diff --git a/CHANGELOG.md b/CHANGELOG.md
index 1b4cbfd..8e1505d 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -1,4 +1,9 @@
 # Change Log
 
+## [0.9.1][2016-11-21]
+
+* Fix
+ * [#412](https://github.com/typicode/json-server/issues/412)
+
 ## [0.9.0][2016-11-11]
 
","Update CHANGELOG.md

"
628,JavaScript,6a2c5b4de833c73f656945253e7b72e31870c88a,https://github.com/hakimel/reveal.js/commit/6a2c5b4de833c73f656945253e7b72e31870c88a,P,hakimel,reveal.js,"[3, 3, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/js/reveal.js b/js/reveal.js
index 091372e..9a1422f 100644
--- a/js/reveal.js
+++ b/js/reveal.js
@@ -3902,4 +3902,7 @@
 	}
 
+	/**
+	 * Returns an array of objects where each object represents the attributes on its respective slide.
+	 */
 	function getSlidesMetaInfo() {
 
diff --git a/plugin/notes/notes.html b/plugin/notes/notes.html
index eff1275..a6bd5e2 100644
--- a/plugin/notes/notes.html
+++ b/plugin/notes/notes.html
@@ -379,4 +379,7 @@
 				} );
 
+				/**
+				 * Asynchronously calls the Reveal.js API of the main frame.
+				 */
 				function callRevealApi( methodName, methodArguments, callback ) {
 					var callId = ++lastRevealApiCallId;
diff --git a/plugin/notes/notes.js b/plugin/notes/notes.js
index dd7df8e..dce9b4e 100644
--- a/plugin/notes/notes.js
+++ b/plugin/notes/notes.js
@@ -52,4 +52,8 @@ var RevealNotes = (function() {
 		}
 
+		/**
+		 * Calls the specified Reveal.js method with the provided argument and then pushes the result to the notes
+		 * frame.
+		 */
 		function callRevealApi( methodName, methodArguments, callId ) {
 			var result = Reveal[methodName].call(Reveal, methodArguments);
","documentation

"
669,JavaScript,7d5f06b0488f9cd439c17abf861cd91c304fc548,https://github.com/expressjs/express/commit/7d5f06b0488f9cd439c17abf861cd91c304fc548,P,expressjs,express,"[1, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/lib/express/plugins/session.js b/lib/express/plugins/session.js
index 96fced90..f658d378 100644
--- a/lib/express/plugins/session.js
+++ b/lib/express/plugins/session.js
@@ -6,5 +6,6 @@
  */
  
-var utils = require('express/utils')
+var utils = require('express/utils'),
+    Cookie = require('express/plugins/cookie').Cookie
 
 // --- Session
@@ -158,5 +159,5 @@ exports.Session = Plugin.extend({
     
     init: function(options) {
-      use(require('express/plugins/cookie').Cookie)
+      use(Cookie)
       process.mixin(this, options)
       this.store = new (this.dataStore || exports.Store.Memory)(options)
","Better use(Cookie)

"
670,JavaScript,8fdf76f8f02d31684d34704341a5d9217e977491,https://github.com/chartjs/Chart.js/commit/8fdf76f8f02d31684d34704341a5d9217e977491,P,chartjs,Chart.js,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2]","diff --git a/.size-limit.cjs b/.size-limit.cjs
index 2b421ffc..aad4948e 100644
--- a/.size-limit.cjs
+++ b/.size-limit.cjs
@@ -35,6 +35,6 @@ module.exports = [
   {
     path: 'dist/chart.js',
-    limit: '27.5 KB',
-    import: '{ Decimation, Filler, Legend, SubTitle, Title, Tooltip }',
+    limit: '35.5 KB',
+    import: '{ Decimation, Filler, Legend, SubTitle, Title, Tooltip, Colors }',
     running: false,
     modifyWebpackConfig
","Add colors plugin to size limit (#11174)

* Add colors plugin to size limit

* Increase size limit
"
671,JavaScript,aa0933e040b456e23557a999408f6047578e631c,https://github.com/chartjs/Chart.js/commit/aa0933e040b456e23557a999408f6047578e631c,C,chartjs,Chart.js,"[2, 11, 3, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/src/controllers/controller.doughnut.js b/src/controllers/controller.doughnut.js
index 6044dc89..cb428548 100644
--- a/src/controllers/controller.doughnut.js
+++ b/src/controllers/controller.doughnut.js
@@ -266,9 +266,12 @@ module.exports = function(Chart) {
 
 		calculateTotal: function() {
+			var dataset = this.getDataset();
 			var meta = this.getMeta();
 			var total = 0;
+			var value;
 
-			this.getDataset().data.forEach(function(value, index) {
-				if (!isNaN(value) && !meta.data[index].hidden) {
+			helpers.each(meta.data, function(element, index) {
+				value = dataset.data[index];
+				if (!isNaN(value) && !element.hidden) {
 					total += Math.abs(value);
 				}
diff --git a/src/controllers/controller.polarArea.js b/src/controllers/controller.polarArea.js
index c7dd87ca..1882ffca 100644
--- a/src/controllers/controller.polarArea.js
+++ b/src/controllers/controller.polarArea.js
@@ -120,4 +120,5 @@ module.exports = function(Chart) {
 
 		update: function update(reset) {
+			var meta = this.getMeta();
 			var minSize = Math.min(this.chart.chartArea.right - this.chart.chartArea.left, this.chart.chartArea.bottom - this.chart.chartArea.top);
 			this.chart.outerRadius = Math.max((minSize - this.chart.options.elements.arc.borderWidth / 2) / 2, 0);
@@ -128,5 +129,7 @@ module.exports = function(Chart) {
 			this.innerRadius = this.outerRadius - this.chart.radiusLength;
 
-			helpers.each(this.getMeta().data, function(arc, index) {
+			meta.count = this.countVisibleElements();
+
+			helpers.each(meta.data, function(arc, index) {
 				this.updateElement(arc, index, reset);
 			}, this);
@@ -219,22 +222,26 @@ module.exports = function(Chart) {
 		},
 
-		calculateCircumference: function(value) {
-			if (isNaN(value)) {
-				return 0;
-			}
-
-			// Count the number of ""visible"""" values
+		countVisibleElements: function() {
+			var dataset = this.getDataset();
 			var meta = this.getMeta();
 			var count = 0;
 
-			this.getDataset().data.forEach(function(value, index) {
-				if (!isNaN(value) && !meta.data[index].hidden) {
+			helpers.each(meta.data, function(element, index) {
+				if (!isNaN(dataset.data[index]) && !element.hidden) {
 					count++;
 				}
 			});
 
-			return (2 * Math.PI) / count;
+			return count;
+		},
+
+		calculateCircumference: function(value) {
+			var count = this.getMeta().count;
+			if (count > 0 && !isNaN(value)) {
+				return (2 * Math.PI) / count;
+			} else {
+				return 0;
+			}
 		}
 	});
-
 };
","Avoid meta data access in calculateCircumference

Fix access of uninitialized meta data while calculating circumference in the polar area chart by caching the number of visible elements in the update() method. Also make the calculateTotal() of the doughnut chart tolerant of uninitialized meta data.

"
674,JavaScript,f170fd1b8d73427e8f1762d252101c6f44b0d5f8,https://github.com/chartjs/Chart.js/commit/f170fd1b8d73427e8f1762d252101c6f44b0d5f8,P,chartjs,Chart.js,"[2, 65, 9, 31, 2, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/src/core/core.controller.js b/src/core/core.controller.js
index d57ebcc8..17b875c5 100644
--- a/src/core/core.controller.js
+++ b/src/core/core.controller.js
@@ -401,4 +401,5 @@
 			this.tooltip = new Chart.Tooltip({
 				_chart: this.chart,
+				_chartInstance: this,
 				_data: this.data,
 				_options: this.options,
diff --git a/src/core/core.tooltip.js b/src/core/core.tooltip.js
index 3fdc54d1..10cef30b 100644
--- a/src/core/core.tooltip.js
+++ b/src/core/core.tooltip.js
@@ -284,7 +284,13 @@
 					x: Math.round(tooltipPosition.x),
 					y: Math.round(tooltipPosition.y),
-					caretPadding: tooltipPosition.padding,
+					caretPadding: helpers.getValueOrDefault(tooltipPosition.padding, 2),
 					labelColors: labelColors,
 				});
+
+				// We need to determine alignment of 
+				var tooltipSize = this.getTooltipSize(this._model);
+				this.determineAlignment(tooltipSize); // Smart Tooltip placement to stay on the canvas
+
+				helpers.extend(this._model, this.getBackgroundPoint(this._model, tooltipSize));
 			}
 			else{
@@ -298,6 +304,5 @@
 			return this;
 		},
-		getTooltipSize: function getTooltipSize() {
-			var vm = this._view;
+		getTooltipSize: function getTooltipSize(vm) {
 			var ctx = this._chart.ctx;
 
@@ -340,20 +345,31 @@
 		},
 		determineAlignment: function determineAlignment(size) {
-			var vm = this._view;
-			vm.yAlign = ""center"";
-			if (vm.y - (size.height / 2) < 0) {
-				vm.yAlign = ""top"";
-			} else if (vm.y + (size.height / 2) > this._chart.height) {
-				vm.yAlign = ""bottom"";
+			this._model.xAlign = this._model.yAlign = ""center"";
+
+			if (this._model.y < size.height) {
+				this._model.yAlign = 'top';
+			} else if (this._model.y > (this._chart.height - size.height)) {
+				this._model.yAlign = 'bottom';
+			}
+
+			var lf, rf;
+			var _this = this;
+			var midX = (this._chartInstance.chartArea.left + this._chartInstance.chartArea.right) / 2;
+
+			if (this._model.yAlign === 'center') {
+				lf = function(x) { return x <= midX; };
+				rf = function(x) { return x > midX; };
+			} else {
+				lf = function(x) { return x <= (size.width / 2); };
+				rf = function(x) { return x >= (_this._chart.width - (size.width / 2)); };
 			}
 
-			// Left or Right
-			vm.xAlign = ""right"";
-			if (vm.x + size.width > this._chart.width) {
-				vm.xAlign = ""left"";
+			if (lf(this._model.x)) {
+				this._model.xAlign = 'left';
+			} else if (rf(this._model.x)) {
+				this._model.xAlign = 'right';
 			}
 		},
-		getBackgroundPoint: function getBackgroundPoint(size, caretPadding) {
-			var vm = this._view;
+		getBackgroundPoint: function getBackgroundPoint(vm, size) {
 			// Background Position
 			var pt = {
@@ -362,39 +378,86 @@
 			};
 
+			if (vm.xAlign === 'right') {
+				pt.x -= size.width;
+			} else if (vm.xAlign === 'center') {
+				pt.x -= (size.width / 2);
+			}
+
 			if (vm.yAlign === 'top') {
-				pt.y = vm.y - vm.caretSize - vm.cornerRadius;
+				pt.y += vm.caretPadding + vm.caretSize;
 			} else if (vm.yAlign === 'bottom') {
-				pt.y = vm.y - size.height + vm.caretSize + vm.cornerRadius;
+				pt.y -= size.height + vm.caretPadding + vm.caretSize;
 			} else {
-				pt.y = vm.y - (size.height / 2);
+				pt.y -= (size.height / 2);
 			}
 
-			if (vm.xAlign === 'left') {
-				pt.x = vm.x - size.width;
-			} else if (vm.xAlign === 'right') {
-				pt.x = vm.x + caretPadding + vm.caretSize;
+			if (vm.yAlign == 'center') {
+				if (vm.xAlign === 'left') {
+					pt.x += vm.caretPadding + vm.caretSize;
+				} else if (vm.xAlign === 'right') {
+					pt.x -= vm.caretPadding + vm.caretSize;
+				}
 			} else {
-				pt.x = vm.x + (size.width / 2);
+				if (vm.xAlign === 'left') {
+					pt.x -= vm.cornerRadius + vm.caretPadding;
+				} else if (vm.xAlign === 'right') {
+					pt.x += vm.cornerRadius + vm.caretPadding;
+				}
 			}
 
 			return pt;
 		},
-		drawCaret: function drawCaret(opacity, caretPadding) {
+		drawCaret: function drawCaret(tooltipPoint, size, opacity, caretPadding) {
 			var vm = this._view;
 			var ctx = this._chart.ctx;
+			var x1, x2, x3;
+			var y1, y2, y3;
+
+			if (vm.yAlign === 'center') {
+				// Left or right side
+				if (vm.xAlign === 'left') {
+					x1 = tooltipPoint.x;
+					x2 = x1 - vm.caretSize;
+					x3 = x1;
+				} else {
+					x1 = tooltipPoint.x + size.width;
+					x2 = x1 + vm.caretSize;
+					x3 = x1;
+				}
 
-			ctx.fillStyle = helpers.color(vm.backgroundColor).alpha(opacity).rgbString();
-			ctx.beginPath();
-
-			if (vm.xAlign === 'left') {
-				ctx.moveTo(vm.x - caretPadding, vm.y);
-				ctx.lineTo(vm.x - caretPadding - vm.caretSize, vm.y - vm.caretSize);
-				ctx.lineTo(vm.x - caretPadding - vm.caretSize, vm.y + vm.caretSize);
+				y2 = tooltipPoint.y + (size.height / 2);
+				y1 = y2 - vm.caretSize;
+				y3 = y2 + vm.caretSize;
 			} else {
-				ctx.moveTo(vm.x + caretPadding, vm.y);
-				ctx.lineTo(vm.x + caretPadding + vm.caretSize, vm.y - vm.caretSize);
-				ctx.lineTo(vm.x + caretPadding + vm.caretSize, vm.y + vm.caretSize);
+				if (vm.xAlign === 'left') {
+					x1 = tooltipPoint.x + vm.cornerRadius;
+					x2 = x1 + vm.caretSize;
+					x3 = x2 + vm.caretSize;
+				} else if (vm.xAlign === 'right') {
+					x1 = tooltipPoint.x + size.width - vm.cornerRadius;
+					x2 = x1 - vm.caretSize;
+					x3 = x2 - vm.caretSize;
+				} else {
+					x2 = tooltipPoint.x + (size.width / 2);
+					x1 = x2 - vm.caretSize;
+					x3 = x2 + vm.caretSize;
+				}
+
+				if (vm.yAlign === 'top') {
+					y1 = tooltipPoint.y;
+					y2 = y1 - vm.caretSize;
+					y3 = y1;
+				} else {
+					y1 = tooltipPoint.y + size.height;
+					y2 = y1 + vm.caretSize;
+					y3 = y1;
+				}
 			}
 
+			ctx.fillStyle = helpers.color(vm.backgroundColor).alpha(opacity).rgbString();
+			ctx.beginPath();
+			ctx.moveTo(x1, y1);
+			ctx.lineTo(x2, y2);
+			ctx.lineTo(x3, y3);
 			ctx.closePath();
 			ctx.fill();
@@ -484,16 +547,10 @@
 			}
 
-			var caretPadding = vm.caretPadding || 2;
-			var tooltipSize = this.getTooltipSize();
-			var backgroundWidth = tooltipSize.width;
-			
-			// Expand to be new total size (including caret)
-			tooltipSize.width += vm.caretSize + caretPadding;
-
-			// Smart Tooltip placement to stay on the canvas
-			// Top, center, or bottom
-			this.determineAlignment(tooltipSize);
-
-			var pt = this.getBackgroundPoint(tooltipSize, caretPadding);
+			var caretPadding = vm.caretPadding;
+			var tooltipSize = this.getTooltipSize(vm);
+			var pt = {
+				x: vm.x,
+				y: vm.y
+			};
 
 			// IE11/Edge does not like very small opacities, so snap to 0
@@ -503,9 +560,9 @@
 				// Draw Background
 				ctx.fillStyle = helpers.color(vm.backgroundColor).alpha(opacity).rgbString();
-				helpers.drawRoundedRectangle(ctx, pt.x, pt.y, backgroundWidth, tooltipSize.height, vm.cornerRadius);
+				helpers.drawRoundedRectangle(ctx, pt.x, pt.y, tooltipSize.width, tooltipSize.height, vm.cornerRadius);
 				ctx.fill();
 
 				// Draw Caret
-				this.drawCaret(opacity, caretPadding);
+				this.drawCaret(pt, tooltipSize, opacity, caretPadding);
 				
 				// Draw Title, Body, and Footer
","Improvements to tooltip alignment to avoid the canvas edges

"
683,JavaScript,ec7be48470e42472a07572b7f1ca2abc91bfdad3,https://github.com/chartjs/Chart.js/commit/ec7be48470e42472a07572b7f1ca2abc91bfdad3,C,chartjs,Chart.js,"[1, 6, 0, 0, 2, 0, 0, 2, 34, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/src/controllers/controller.scatter.js b/src/controllers/controller.scatter.js
index aae36ed6..15445ea8 100644
--- a/src/controllers/controller.scatter.js
+++ b/src/controllers/controller.scatter.js
@@ -71,4 +71,8 @@ export default class ScatterController extends DatasetController {
     if (this.options.showLine) {
 
+      // https://github.com/chartjs/Chart.js/issues/11333
+      if (!this.datasetElementType) {
+        this.addElements();
+      }
       const {dataset: line, _dataset} = meta;
 
@@ -85,4 +89,8 @@ export default class ScatterController extends DatasetController {
         options
       }, mode);
+    } else if (this.datasetElementType) {
+      // https://github.com/chartjs/Chart.js/issues/11333
+      delete meta.dataset;
+      this.datasetElementType = false;
     }
 
diff --git a/test/fixtures/controller.scatter/showLine/changed.js b/test/fixtures/controller.scatter/showLine/changed.js
new file mode 100644
index 00000000..ac85be49
--- /dev/null
+++ b/test/fixtures/controller.scatter/showLine/changed.js
@@ -0,0 +1,34 @@
+module.exports = {
+  description: 'showLine option should draw a line if true',
+  config: {
+    type: 'scatter',
+    data: {
+      datasets: [{
+        data: [{x: 10, y: 15}, {x: 15, y: 10}],
+        pointRadius: 10,
+        backgroundColor: 'red',
+        label: 'dataset1'
+      }],
+    },
+    options: {
+      scales: {
+        x: {
+          display: false
+        },
+        y: {
+          display: false
+        }
+      }
+    }
+  },
+  options: {
+    canvas: {
+      width: 256,
+      height: 256
+    },
+    run(chart) {
+      chart.options.showLine = true;
+      chart.update();
+    }
+  }
+};
diff --git a/test/fixtures/controller.scatter/showLine/changed.png b/test/fixtures/controller.scatter/showLine/changed.png
new file mode 100644
index 00000000..9e5eae7c
Binary files /dev/null and b/test/fixtures/controller.scatter/showLine/changed.png differ
","Fix toggling showLine option on scatter controller (#11334)


"
687,Python,1513be4acdcc85b27869219938ed90610a7db673,https://github.com/Significant-Gravitas/Auto-GPT/commit/1513be4acdcc85b27869219938ed90610a7db673,C,Significant-Gravitas,Auto-GPT,"[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/autogpt/agent/agent.py b/autogpt/agent/agent.py
index 9853f6a..dca614c 100644
--- a/autogpt/agent/agent.py
+++ b/autogpt/agent/agent.py
@@ -56,4 +56,6 @@ class Agent:
         command_name = None
         arguments = None
+        user_input = """"
+
         while True:
             # Discontinue if continuous limit is reached
@@ -98,5 +100,4 @@ class Agent:
                 # Get key press: Prompt the user to press enter to continue or escape
                 # to exit
-                user_input = """"
                 logger.typewriter_log(
                     ""NEXT ACTION: "",
","hotfix user input

"
688,Python,85428df9fc1dd72bf5a959c92e37803fa9fcc8bc,https://github.com/Significant-Gravitas/Auto-GPT/commit/85428df9fc1dd72bf5a959c92e37803fa9fcc8bc,P,Significant-Gravitas,Auto-GPT,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0]","diff --git a/.github/PULL_REQUEST_TEMPLATE.md b/.github/PULL_REQUEST_TEMPLATE.md
index 6397f78..cb8ce34 100644
--- a/.github/PULL_REQUEST_TEMPLATE.md
+++ b/.github/PULL_REQUEST_TEMPLATE.md
@@ -9,5 +9,5 @@
 ### Test Plan
 
-<!-- Explain how you tested this functionality. Include the testing environment, steps to reproduce, and any relevant test cases. -->
+<!-- Explain how you tested this functionality. Include the steps to reproduce and any relevant test cases. -->
 
 ### Change Safety
","Update PULL_REQUEST_TEMPLATE.md
"
689,Python,3ae6c1b03f2a22e364ed522828318dcd492bbf3b,https://github.com/Significant-Gravitas/Auto-GPT/commit/3ae6c1b03f2a22e364ed522828318dcd492bbf3b,P,Significant-Gravitas,Auto-GPT,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0]","diff --git a/docs/installation.md b/docs/installation.md
index e959535..034814d 100644
--- a/docs/installation.md
+++ b/docs/installation.md
@@ -63,5 +63,5 @@ azure_model_map:
 ```
 Details can be found here: [https://pypi.org/project/openai/](https://pypi.org/project/openai/) in the `Microsoft Azure Endpoints` section and here: [learn.microsoft.com](https://learn.microsoft.com/en-us/azure/cognitive-services/openai/tutorials/embeddings?tabs=command-line) for the embedding model.
-If you're on Windows you may need to install [msvc-170](https://learn.microsoft.com/en-us/cpp/windows/latest-supported-vc-redist?view=msvc-170)
+If you're on Windows you may need to install [msvc-170](https://learn.microsoft.com/en-us/cpp/windows/latest-supported-vc-redist?view=msvc-170).
 
 4. Follow the further instructions for running Auto-GPT with [Docker](#run-with-docker) (*recommended*), or [Docker-less](#run-docker-less)
","Update installation.md (#3325)


"
702,Python,ddf59273e6b4607562f7e73e7780260c281b687e,https://github.com/Significant-Gravitas/Auto-GPT/commit/ddf59273e6b4607562f7e73e7780260c281b687e,P,Significant-Gravitas,Auto-GPT,"[0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/tests/integration/agent_factory.py b/tests/integration/agent_factory.py
index 1781a3f..19af503 100644
--- a/tests/integration/agent_factory.py
+++ b/tests/integration/agent_factory.py
@@ -159,5 +159,4 @@ def get_company_revenue_agent(
         ai_name=""Get-CompanyRevenue"",
         memory=memory_json_file,
-        full_message_history=[],
         command_registry=command_registry,
         config=ai_config,
@@ -192,5 +191,4 @@ def kubernetes_agent(memory_json_file, workspace: Workspace):
         ai_name=""Kubernetes-Demo"",
         memory=memory_json_file,
-        full_message_history=[],
         command_registry=command_registry,
         config=ai_config,
","Remove obsolete full_message_history kwarg from tests (#4411)


"
713,Python,4b879984eacbb5b6d19e2a9e8627953d51caa8b2,https://github.com/ytdl-org/youtube-dl/commit/4b879984eacbb5b6d19e2a9e8627953d51caa8b2,P,ytdl-org,youtube-dl,"[1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/youtube_dl/version.py b/youtube_dl/version.py
index a4e9d2478..8a82fd2f2 100644
--- a/youtube_dl/version.py
+++ b/youtube_dl/version.py
@@ -1,2 +1,2 @@
 
-__version__ = '2013.01.02'
+__version__ = '2013.01.06'
","release 2013.01.06

"
729,Python,893e51a53fd3de17cfe3bc164177f2ed51183b0c,https://github.com/huggingface/transformers/commit/893e51a53fd3de17cfe3bc164177f2ed51183b0c,P,huggingface,transformers,"[2, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/.circleci/deploy.sh b/.circleci/deploy.sh
index f66bf3cbe..11716e9df 100755
--- a/.circleci/deploy.sh
+++ b/.circleci/deploy.sh
@@ -62,3 +62,4 @@ deploy_doc ""c988db5"" v4.4.0
 deploy_doc ""c5d6a28"" v4.4.1
 deploy_doc ""6bc89ed"" v4.4.2
-deploy_doc ""4906a29""  # v4.5.0 Latest stable release
\ No newline at end of file
+deploy_doc ""4906a29"" v4.5.0
+deploy_doc ""4bae96e""  # v4.5.1 Latest stable release
\ No newline at end of file
diff --git a/docs/source/_static/js/custom.js b/docs/source/_static/js/custom.js
index 5fdab31a0..3b975a81f 100644
--- a/docs/source/_static/js/custom.js
+++ b/docs/source/_static/js/custom.js
@@ -1,9 +1,9 @@
 // These two things need to be updated at each release for the version selector.
 // Last stable version
-const stableVersion = ""v4.5.0""
+const stableVersion = ""v4.5.1""
 // Dictionary doc folder to label. The last stable version should have an empty key.
 const versionMapping = {
     ""master"": ""master"",
-    """": ""v4.5.0 (stable)"",
+    """": ""v4.5.0/v4.5.1 (stable)"",
     ""v4.4.2"": ""v4.4.0/v4.4.1/v4.4.2"",
     ""v4.3.3"": ""v4.3.0/v4.3.1/v4.3.2/v4.3.3"",
","Document v4.5.1


"
738,Python,c715ef04d1edb1a112a602639ed3bb292fdeb0e2,https://github.com/AUTOMATIC1111/stable-diffusion-webui/commit/c715ef04d1edb1a112a602639ed3bb292fdeb0e2,C,AUTOMATIC1111,stable-diffusion-webui,"[2, 9, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/modules/sd_hijack.py b/modules/sd_hijack.py
index 2848a251..5945b7c2 100644
--- a/modules/sd_hijack.py
+++ b/modules/sd_hijack.py
@@ -246,4 +246,5 @@ class StableDiffusionModelHijack:
         model_embeddings.token_embedding = EmbeddingsWithFixes(model_embeddings.token_embedding, self)
         m.cond_stage_model = FrozenCLIPEmbedderWithCustomWords(m.cond_stage_model, self)
+
         self.clip = m.cond_stage_model
 
@@ -264,4 +265,12 @@ class StableDiffusionModelHijack:
         self.layers = flatten(m)
 
+    def undo_hijack(self, m):
+        if type(m.cond_stage_model) == FrozenCLIPEmbedderWithCustomWords:
+            m.cond_stage_model = m.cond_stage_model.wrapped
+
+        model_embeddings = m.cond_stage_model.transformer.text_model.embeddings
+        if type(model_embeddings.token_embedding) == EmbeddingsWithFixes:
+            model_embeddings.token_embedding = model_embeddings.token_embedding.wrapped
+
     def apply_circular(self, enable):
         if self.circular_enabled == enable:
diff --git a/modules/sd_models.py b/modules/sd_models.py
index 7a5edced..eb21e498 100644
--- a/modules/sd_models.py
+++ b/modules/sd_models.py
@@ -138,5 +138,5 @@ def load_model():
 
 def reload_model_weights(sd_model, info=None):
-    from modules import lowvram, devices
+    from modules import lowvram, devices, sd_hijack
     checkpoint_info = info or select_checkpoint()
 
@@ -149,6 +149,10 @@ def reload_model_weights(sd_model, info=None):
         sd_model.to(devices.cpu)
 
+    sd_hijack.model_hijack.undo_hijack(sd_model)
+
     load_model_weights(sd_model, checkpoint_info.filename, checkpoint_info.hash)
 
+    sd_hijack.model_hijack.hijack(sd_model)
+
     if not shared.cmd_opts.lowvram and not shared.cmd_opts.medvram:
         sd_model.to(devices.device)
","fix for incorrect model weight loading for #814

"
742,Python,cc8c9b7474d917888a0bd069fcd59a458c67ae4b,https://github.com/AUTOMATIC1111/stable-diffusion-webui/commit/cc8c9b7474d917888a0bd069fcd59a458c67ae4b,C,AUTOMATIC1111,stable-diffusion-webui,"[2, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/modules/extras.py b/modules/extras.py
index 36123aa5..4f842be9 100644
--- a/modules/extras.py
+++ b/modules/extras.py
@@ -7,5 +7,5 @@ import torch
 import tqdm
 
-from modules import shared, images, sd_models, sd_vae
+from modules import shared, images, sd_models, sd_vae, sd_models_config
 from modules.ui_common import plaintext_to_html
 import gradio as gr
@@ -38,5 +38,5 @@ def run_pnginfo(image):
 def create_config(ckpt_result, config_source, a, b, c):
     def config(x):
-        res = sd_models.find_checkpoint_config(x) if x else None
+        res = sd_models_config.find_checkpoint_config_near_filename(x) if x else None
         return res if res != shared.sd_default_config else None
 
diff --git a/modules/sd_hijack_ip2p.py b/modules/sd_hijack_ip2p.py
index 635f015f..3c727d3b 100644
--- a/modules/sd_hijack_ip2p.py
+++ b/modules/sd_hijack_ip2p.py
@@ -6,8 +6,8 @@ import time
 
 def should_hijack_ip2p(checkpoint_info):
-    from modules import sd_models
+    from modules import sd_models_config
 
     ckpt_basename = os.path.basename(checkpoint_info.filename).lower()
-    cfg_basename = os.path.basename(sd_models.find_checkpoint_config(checkpoint_info)).lower()
+    cfg_basename = os.path.basename(sd_models_config.find_checkpoint_config_near_filename(checkpoint_info)).lower()
 
     return ""pix2pix"" in ckpt_basename and not ""pix2pix"" in cfg_basename
","fix broken calls to find_checkpoint_config

"
777,Python,ddf7d7ab0257c6a6dc9ea141cba4b437431a85d1,https://github.com/django/django/commit/ddf7d7ab0257c6a6dc9ea141cba4b437431a85d1,C,django,django,"[0, 0, 0, 0, 0, 0, 0, 1, 5, 2, 0, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/tests/regressiontests/serializers_regress/tests.py b/tests/regressiontests/serializers_regress/tests.py
index 6430c5b38d..c6167b12e7 100644
--- a/tests/regressiontests/serializers_regress/tests.py
+++ b/tests/regressiontests/serializers_regress/tests.py
@@ -261,9 +261,5 @@ The end.""""""),
 
     (fk_obj, 460, FKDataToO2O, 300),
-    
-    # Regression test for #8651 -- FK = 0
-    (data_obj, 0, Anchor, ""Anchor 0""),
-    (fk_obj, 465, FKData, 0),
-    
+        
     (im2m_obj, 470, M2MIntermediateData, None),
     
@@ -337,4 +333,13 @@ if settings.DATABASE_ENGINE == 'oracle':
                          data[3] is None)]
 
+# Regression test for #8651 -- a FK to an object iwth PK of 0
+# This won't work on MySQL since it won't let you create an object
+# with a primary key of 0,
+if settings.DATABASE_ENGINE != 'mysql':
+    test_data.extend([
+        (data_obj, 0, Anchor, ""Anchor 0""),
+        (fk_obj, 465, FKData, 0),
+    ])
+
 # Dynamically create serializer tests to ensure that all
 # registered serializers are automatically tested.
","Fixed #8668: prevent MySQL from running the new test from [8676].

git-svn-id: http://code.djangoproject.com/svn/django/trunk@8703 bcc190cf-cafb-0310-a4f2-bffc1f526a37

"
790,Python,be56f74f93e97118dca32d83697803e3f9f42db0,https://github.com/django/django/commit/be56f74f93e97118dca32d83697803e3f9f42db0,C,django,django,"[3, 1, 1, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/django/contrib/staticfiles/management/commands/collectstatic.py b/django/contrib/staticfiles/management/commands/collectstatic.py
index 8882ae20db..10f9fdd016 100644
--- a/django/contrib/staticfiles/management/commands/collectstatic.py
+++ b/django/contrib/staticfiles/management/commands/collectstatic.py
@@ -101,5 +101,5 @@ Type 'yes' to continue, or 'no' to cancel: """""")
             source_last_modified = None
         if prefix:
-            destination = '/'.join([prefix, source])
+            destination = os.path.join(prefix, source)
         else:
             destination = source
diff --git a/django/contrib/staticfiles/storage.py b/django/contrib/staticfiles/storage.py
index eb0eabf861..56e5c0dec0 100644
--- a/django/contrib/staticfiles/storage.py
+++ b/django/contrib/staticfiles/storage.py
@@ -83,5 +83,5 @@ class AppStaticStorage(FileSystemStorage):
         for path in utils.get_files(self, ignore_patterns):
             if prefix:
-                path = '/'.join([prefix, path])
+                path = os.path.join(prefix, path)
             files.append(path)
         return files
diff --git a/django/contrib/staticfiles/utils.py b/django/contrib/staticfiles/utils.py
index 428bb69b1e..187a6d3429 100644
--- a/django/contrib/staticfiles/utils.py
+++ b/django/contrib/staticfiles/utils.py
@@ -1,2 +1,3 @@
+import os
 import fnmatch
 from django.conf import settings
@@ -5,7 +6,6 @@ from django.core.exceptions import ImproperlyConfigured
 def get_files(storage, ignore_patterns=[], location=''):
     """"""
-    Recursively walk the storage directories gathering a complete list of files
-    that should be copied, returning this list.
-    
+    Recursively walk the storage directories gathering a complete
+    list of files that should be copied, returning this list.
     """"""
     def is_ignored(path):
@@ -13,5 +13,4 @@ def get_files(storage, ignore_patterns=[], location=''):
         Return True or False depending on whether the ``path`` should be
         ignored (if it matches any pattern in ``ignore_patterns``).
-        
         """"""
         for pattern in ignore_patterns:
@@ -21,5 +20,5 @@ def get_files(storage, ignore_patterns=[], location=''):
 
     directories, files = storage.listdir(location)
-    static_files = [location and '/'.join([location, fn]) or fn
+    static_files = [location and os.path.join(location, fn) or fn
                     for fn in files
                     if not is_ignored(fn)]
@@ -28,5 +27,5 @@ def get_files(storage, ignore_patterns=[], location=''):
             continue
         if location:
-            dir = '/'.join([location, dir])
+            dir = os.path.join(location, dir)
         static_files.extend(get_files(storage, ignore_patterns, dir))
     return static_files
","Fixed #14998 -- Made use of os.path.join to make sure this works on all platforms. Thanks for the pointer, CarlFK.

git-svn-id: http://code.djangoproject.com/svn/django/trunk@15128 bcc190cf-cafb-0310-a4f2-bffc1f526a37

"
801,Python,71cfbc45b4b56ffee49dcdd976bc68df54683e05,https://github.com/pytorch/pytorch/commit/71cfbc45b4b56ffee49dcdd976bc68df54683e05,P,pytorch,pytorch,"[0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/torch/testing/_internal/distributed/distributed_test.py b/torch/testing/_internal/distributed/distributed_test.py
index 8b07d2d163..6651eb3c8c 100644
--- a/torch/testing/_internal/distributed/distributed_test.py
+++ b/torch/testing/_internal/distributed/distributed_test.py
@@ -5289,5 +5289,4 @@ class DistributedTest:
 
         def _test_ddp_profiling(self, profiler_ctx):
-            torch.cuda.set_device(self.rank)
             batch = 3
             dim = 10
","Remove redundant `torch.cuda.set_device(self.rank)` (#62097)

Summary:
Pull Request resolved: https://github.com/pytorch/pytorch/pull/62097

as title
ghstack-source-id: 134196740

Test Plan: buck test mode/dev-nosan caffe2/test/distributed:distributed_nccl_fork -- test_ddp_profiling_autograd_profiler

Reviewed By: rohan-varma

Differential Revision: D29880040

fbshipit-source-id: 6a06fb2d87e9a7dfa1d7c81bf0c3fe115c1a1abb

"
821,Python,c6a619af833416160475c25aa3d11ef14ed74618,https://github.com/pallets/flask/commit/c6a619af833416160475c25aa3d11ef14ed74618,P,pallets,flask,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 6, 0, 0, 0, 0]","diff --git a/docs/cli.rst b/docs/cli.rst
index 96c5396f..c50872a7 100644
--- a/docs/cli.rst
+++ b/docs/cli.rst
@@ -492,8 +492,8 @@ PyCharm Integration
 -------------------
 
-Prior to PyCharm 2018.1, the Flask CLI features weren't yet fully
-integrated into PyCharm. We have to do a few tweaks to get them working
-smoothly. These instructions should be similar for any other IDE you
-might want to use.
+PyCharm Professional provides a special Flask run configuration. For
+the Community Edition, we need to configure it to call the ``flask run``
+CLI command with the correct environment variables. These instructions
+should be similar for any other IDE you might want to use.
 
 In PyCharm, with your project open, click on *Run* from the menu bar and
@@ -504,5 +504,5 @@ this:
     :align: center
     :class: screenshot
-    :alt: screenshot of pycharm's run configuration settings
+    :alt: Screenshot of PyCharms's run configuration settings.
 
 There's quite a few options to change, but once we've done it for one
@@ -512,7 +512,7 @@ may implement yourself.
 
 Click the + (*Add New Configuration*) button and select *Python*. Give
-the configuration a good descriptive name such as ""Run Flask Server"".
-For the ``flask run`` command, check ""Single instance only"" since you
-can't run the server more than once at the same time.
+the configuration a name such as ""flask run"". For the ``flask run``
+command, check ""Single instance only"" since you can't run the server
+more than once at the same time.
 
 Select *Module name* from the dropdown (**A**) then input ``flask``.
@@ -525,5 +525,6 @@ You can skip this next step if you're using :ref:`dotenv`. We need to
 add an environment variable (**C**) to identify our application. Click
 on the browse button and add an entry with ``FLASK_APP`` on the left and
-the Python import or file on the right (``hello`` for example).
+the Python import or file on the right (``hello`` for example). Add an
+entry with ``FLASK_ENV`` and set it to ``development``.
 
 Next we need to set the working directory (**D**) to be the folder where
","update CLI docs IDE integration

"
854,Python,e8ee816b2fcf6cdcb48db81c946a8ffe534f125a,https://github.com/keras-team/keras/commit/e8ee816b2fcf6cdcb48db81c946a8ffe534f125a,A,keras-team,keras,"[1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/keras/applications/convnext.py b/keras/applications/convnext.py
index 48a74aa9..eec53eaa 100644
--- a/keras/applications/convnext.py
+++ b/keras/applications/convnext.py
@@ -403,6 +403,10 @@ def ConvNeXt(depths,
 
   x = inputs
+  
   if include_preprocessing:
-    x = PreStem(name=model_name)(x)
+    channel_axis = 3 if backend.image_data_format() == ""channels_last"" else 1
+    num_channels = input_shape[channel_axis - 1]
+    if num_channels == 3:
+      x = PreStem(name=model_name)(x)
   
   # Stem block.
","feat: application of normalization for 3-channel inputs.

"
871,Python,daf4c358f7d382e7fc0466b06e3c528d24b3f760,https://github.com/ansible/ansible/commit/daf4c358f7d382e7fc0466b06e3c528d24b3f760,C,ansible,ansible,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 29, 29, 0]","diff --git a/library/packaging/pip b/library/packaging/pip
index d4311c6f36..cc16556848 100644
--- a/library/packaging/pip
+++ b/library/packaging/pip
@@ -21,4 +21,5 @@
 
 import tempfile
+import os
 
 DOCUMENTATION = '''
@@ -33,5 +34,5 @@ options:
   name:
     description:
-      - The name of a Python library to install or the url of the remote package. 
+      - The name of a Python library to install or the url of the remote package.
     required: false
     default: null
@@ -185,20 +186,4 @@ def main():
         module.fail_json(msg='version is incompatible with state=latest')
 
-    # pip can accept a path to a local project or a VCS url beginning
-    # with svn+, git+, hg+, or bz+ and these sources usually do not qualify
-    # --use-mirrors. Furthermore, the -e option is applied only when
-    # source is a VCS url. Therefore, we will have branch cases for each
-    # type of sources.
-    #
-    # is_vcs includes those begin with svn+, git+, hg+ or bzr+
-    # is_tar ends with .zip, .tar.gz, or .tar.bz2
-    is_vcs = False
-    is_tar = False
-    if name.endswith('.tar.gz') or name.endswith('.tar.bz2') or name.endswith('.zip'):
-        is_tar = True
-    elif name.startswith('svn+') or name.startswith('git+') or \
-       name.startswith('hg+') or name.startswith('bzr+'):
-        is_vcs = True
-       
     err = ''
     out = ''
@@ -227,25 +212,39 @@ def main():
     cmd = '%s %s' % (pip, state_map[state])
 
-
-    # If is_vcs=True, we must add -e option (we assume users won't add that to extra_args). 
-    if is_vcs:
-        args_list = []  # used if extra_args is not used at all
-        if extra_args:
-            args_list = extra_args.split(' ')            
-        if '-e' not in args_list:
-            args_list.append('-e')
-            # Ok, we will reconstruct the option string
-            extra_args = ' '.join(args_list)
-    # for tarball or vcs source, applying --use-mirrors doesn't really make sense
-    is_package = is_vcs or is_tar       # just a shortcut for bool
-    if not is_package and state != 'absent' and use_mirrors:
-        cmd += ' --use-mirrors'
     if extra_args:
         cmd += ' %s' % extra_args
     if name:
+        # pip can accept a path to a local project or a VCS url beginning
+        # with svn+, git+, hg+, or bz+ and these sources usually do not qualify
+        # --use-mirrors. Furthermore, the -e option is applied only when
+        # source is a VCS url. Therefore, we will have branch cases for each
+        # type of sources.
+        #
+        # is_vcs includes those begin with svn+, git+, hg+ or bzr+
+        # is_tar ends with .zip, .tar.gz, or .tar.bz2
+        is_vcs = False
+        is_tar = False
+        if name.endswith('.tar.gz') or name.endswith('.tar.bz2') or name.endswith('.zip'):
+            is_tar = True
+        elif name.startswith('svn+') or name.startswith('git+') or \
+                name.startswith('hg+') or name.startswith('bzr+'):
+            is_vcs = True
+        # If is_vcs=True, we must add -e option (we assume users won't add that to extra_args).
+        if is_vcs:
+            args_list = []  # used if extra_args is not used at all
+            if extra_args:
+                args_list = extra_args.split(' ')
+            if '-e' not in args_list:
+                args_list.append('-e')
+                # Ok, we will reconstruct the option string
+                extra_args = ' '.join(args_list)
+        # for tarball or vcs source, applying --use-mirrors doesn't really make sense
+        is_package = is_vcs or is_tar       # just a shortcut for bool
+        if not is_package and state != 'absent' and use_mirrors:
+            cmd += ' --use-mirrors'
         cmd += ' %s' % _get_full_name(name, version)
     elif requirements:
         cmd += ' -r %s' % requirements
-    
+
     if module.check_mode:
         module.exit_json(changed=True)
","fixes case where name is omitted from pip arg list

This code:
```
    if name.endswith('.tar.gz') or name.endswith('.tar.bz2') or
name.endswith('.zip'):
        is_tar = True
```
was not checking whether name is defined since it is an
optional param.

"
885,Python,03a6fc0c5677122ee7fe03eeb7012cc78656627b,https://github.com/ansible/ansible/commit/03a6fc0c5677122ee7fe03eeb7012cc78656627b,C,ansible,ansible,"[1, 3, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/lib/ansible/modules/extras/cloud/cloudstack/cs_instance.py b/lib/ansible/modules/extras/cloud/cloudstack/cs_instance.py
index c378f588dd..c2a4c06686 100644
--- a/lib/ansible/modules/extras/cloud/cloudstack/cs_instance.py
+++ b/lib/ansible/modules/extras/cloud/cloudstack/cs_instance.py
@@ -71,6 +71,6 @@ options:
     description:
       - Name the hypervisor to be used for creating the new instance.
-      - Relevant when using C(state=present) and option C(ISO) is used.
-      - If not set, first found hypervisor will be used.
+      - Relevant when using C(state=present), but only considered if not set on ISO/template.
+      - If not set or found on ISO/template, first found hypervisor will be used.
     required: false
     default: null
@@ -521,5 +521,4 @@ class AnsibleCloudStackInstance(AnsibleCloudStack):
         args['diskofferingid']      = self.get_disk_offering_id()
         args['networkids']          = self.get_network_ids()
-        args['hypervisor']          = self.get_hypervisor()
         args['userdata']            = self.get_user_data()
         args['keyboard']            = self.module.params.get('keyboard')
@@ -533,4 +532,8 @@ class AnsibleCloudStackInstance(AnsibleCloudStack):
         args['affinitygroupnames']  = ','.join(self.module.params.get('affinity_groups'))
 
+        template_iso = self.get_template_or_iso()
+        if 'hypervisor' not in template_iso:
+            args['hypervisor'] = self.get_hypervisor()
+
         instance = None
         if not self.module.check_mode:
","cloudstack: fix cs_instance hypervisor must be omitted if set on template/iso

Fix related to issue reported in PR GH-646

"
888,Python,79f16a011c5aff115010e705c2a3a3b50bbfa13b,https://github.com/scikit-learn/scikit-learn/commit/79f16a011c5aff115010e705c2a3a3b50bbfa13b,P,scikit-learn,scikit-learn,"[1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/examples/lda.py b/examples/lda.py
index 856002655..a1f3cade4 100644
--- a/examples/lda.py
+++ b/examples/lda.py
@@ -4,5 +4,5 @@ Linear Discriminant Analysis
 ============================
 
-A classification example using Linear Discriminant Anlysis (LDA).
+A classification example using Linear Discriminant Analysis (LDA).
 
 """"""
","MISC: Typo.



git-svn-id: https://scikit-learn.svn.sourceforge.net/svnroot/scikit-learn/trunk@705 22fbfee3-77ab-4535-9bad-27d1bd3bc7d8

"
912,Rust,2fa0096821cd04334210fcae6f54f85d304dc17a,https://github.com/denoland/deno/commit/2fa0096821cd04334210fcae6f54f85d304dc17a,A,denoland,deno,"[7, 116, 1, 14, 14, 0, 2, 4, 4, 0, 0, 0, 0, 0, 24, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/cli/main.rs b/cli/main.rs
index ecadf65bd..acf49bb3f 100644
--- a/cli/main.rs
+++ b/cli/main.rs
@@ -72,4 +72,5 @@ use deno_core::error::generic_error;
 use deno_core::error::AnyError;
 use deno_core::futures::future::FutureExt;
+use deno_core::futures::future::LocalFutureObj;
 use deno_core::futures::Future;
 use deno_core::located_script_name;
@@ -83,4 +84,5 @@ use deno_core::ModuleSpecifier;
 use deno_runtime::colors;
 use deno_runtime::ops::worker_host::CreateWebWorkerCb;
+use deno_runtime::ops::worker_host::PreloadModuleCb;
 use deno_runtime::permissions::Permissions;
 use deno_runtime::tokio_util::run_basic;
@@ -101,4 +103,22 @@ use std::rc::Rc;
 use std::sync::Arc;
 
+fn create_web_worker_preload_module_callback(
+  ps: ProcState,
+) -> Arc<PreloadModuleCb> {
+  let compat = ps.flags.compat;
+
+  Arc::new(move |mut worker| {
+    let fut = async move {
+      if compat {
+        worker.execute_side_module(&compat::GLOBAL_URL).await?;
+        worker.execute_side_module(&compat::MODULE_URL).await?;
+      }
+
+      Ok(worker)
+    };
+    LocalFutureObj::new(Box::new(fut))
+  })
+}
+
 fn create_web_worker_callback(ps: ProcState) -> Arc<CreateWebWorkerCb> {
   Arc::new(move |args| {
@@ -117,4 +137,6 @@ fn create_web_worker_callback(ps: ProcState) -> Arc<CreateWebWorkerCb> {
     );
     let create_web_worker_cb = create_web_worker_callback(ps.clone());
+    let preload_module_cb =
+      create_web_worker_preload_module_callback(ps.clone());
 
     let extensions = ops::cli_exts(ps.clone(), args.use_deno_namespace);
@@ -146,4 +168,5 @@ fn create_web_worker_callback(ps: ProcState) -> Arc<CreateWebWorkerCb> {
       module_loader,
       create_web_worker_cb,
+      preload_module_cb,
       js_error_create_fn: Some(js_error_create_fn),
       use_deno_namespace: args.use_deno_namespace,
@@ -188,4 +211,6 @@ pub fn create_main_worker(
 
   let create_web_worker_cb = create_web_worker_callback(ps.clone());
+  let web_worker_preload_module_cb =
+    create_web_worker_preload_module_callback(ps.clone());
 
   let maybe_storage_key = if let Some(location) = &ps.flags.location {
@@ -241,4 +266,5 @@ pub fn create_main_worker(
     js_error_create_fn: Some(js_error_create_fn),
     create_web_worker_cb,
+    web_worker_preload_module_cb,
     maybe_inspector_server,
     should_break_on_first_statement,
diff --git a/cli/standalone.rs b/cli/standalone.rs
index e31fa15f7..a50e7d80d 100644
--- a/cli/standalone.rs
+++ b/cli/standalone.rs
@@ -209,4 +209,7 @@ pub async fn run(
     todo!(""Worker are currently not supported in standalone binaries"");
   });
+  let web_worker_preload_module_cb = Arc::new(|_| {
+    todo!(""Worker are currently not supported in standalone binaries"");
+  });
 
   // Keep in sync with `main.rs`.
@@ -258,4 +261,5 @@ pub async fn run(
     js_error_create_fn: None,
     create_web_worker_cb,
+    web_worker_preload_module_cb,
     maybe_inspector_server: None,
     should_break_on_first_statement: false,
diff --git a/cli/tests/integration/compat_tests.rs b/cli/tests/integration/compat_tests.rs
index bafe24af3..189e1eb41 100644
--- a/cli/tests/integration/compat_tests.rs
+++ b/cli/tests/integration/compat_tests.rs
@@ -91,4 +91,9 @@ itest!(top_level_fail_esm {
 });
 
+itest!(compat_worker {
+  args: ""run --compat --unstable -A --quiet --no-check compat/worker/worker_test.mjs"",
+  output: ""compat/worker/worker_test.out"",
+});
+
 #[test]
 fn globals_in_repl() {
diff --git a/cli/tests/testdata/compat/worker/worker.mjs b/cli/tests/testdata/compat/worker/worker.mjs
new file mode 100644
index 000000000..eb7cfed19
--- /dev/null
+++ b/cli/tests/testdata/compat/worker/worker.mjs
@@ -0,0 +1,9 @@
+console.log(""hello from worker"");
+
+self.onmessage = (e) => {
+    if (e.data != ""hello"") {
+        throw new Error(""wrong message"");
+    }
+
+    self.postMessage({ pid: process.pid });
+}
diff --git a/cli/tests/testdata/compat/worker/worker_test.mjs b/cli/tests/testdata/compat/worker/worker_test.mjs
new file mode 100644
index 000000000..215605487
--- /dev/null
+++ b/cli/tests/testdata/compat/worker/worker_test.mjs
@@ -0,0 +1,18 @@
+import { deferred } from ""../../../../../test_util/std/async/deferred.ts"";
+
+const promise = deferred();
+const url = new URL(""./worker.mjs"", import.meta.url);
+const worker = new Worker(url.href, { type: ""module"", deno: true });
+
+worker.onmessage = (e) => {
+    const pid = e.data.pid;
+    if (typeof pid != ""number"") {
+        throw new Error(""pid is not a number"");
+    }
+    console.log(""process.pid from worker:"", pid);
+    promise.resolve();
+};
+
+worker.postMessage(""hello"");
+await promise;
+worker.terminate();
diff --git a/cli/tests/testdata/compat/worker/worker_test.out b/cli/tests/testdata/compat/worker/worker_test.out
new file mode 100644
index 000000000..373841945
--- /dev/null
+++ b/cli/tests/testdata/compat/worker/worker_test.out
@@ -0,0 +1,2 @@
+hello from worker
+process.pid from worker: [WILDCARD]
diff --git a/runtime/examples/hello_runtime.rs b/runtime/examples/hello_runtime.rs
index 74a9ef398..e74920c34 100644
--- a/runtime/examples/hello_runtime.rs
+++ b/runtime/examples/hello_runtime.rs
@@ -23,4 +23,7 @@ async fn main() -> Result<(), AnyError> {
     todo!(""Web workers are not supported in the example"");
   });
+  let web_worker_preload_module_cb = Arc::new(|_| {
+    todo!(""Web workers are not supported in the example"");
+  });
 
   let options = WorkerOptions {
@@ -43,4 +46,5 @@ async fn main() -> Result<(), AnyError> {
     seed: None,
     js_error_create_fn: None,
+    web_worker_preload_module_cb,
     create_web_worker_cb,
     maybe_inspector_server: None,
diff --git a/runtime/js/99_main.js b/runtime/js/99_main.js
index 5a4d7e989..fb5de250c 100644
--- a/runtime/js/99_main.js
+++ b/runtime/js/99_main.js
@@ -677,5 +677,5 @@ delete Object.prototype.__proto__;
     registerErrors();
 
-    pollForMessages();
+    globalThis.pollForMessages = pollForMessages;
 
     const internalSymbol = Symbol(""Deno.internal"");
diff --git a/runtime/ops/worker_host.rs b/runtime/ops/worker_host.rs
index c241e9a54..1213da6d2 100644
--- a/runtime/ops/worker_host.rs
+++ b/runtime/ops/worker_host.rs
@@ -13,4 +13,5 @@ use crate::web_worker::WorkerControlEvent;
 use crate::web_worker::WorkerId;
 use deno_core::error::AnyError;
+use deno_core::futures::future::LocalFutureObj;
 use deno_core::op_async;
 use deno_core::op_sync;
@@ -43,11 +44,22 @@ pub type CreateWebWorkerCb = dyn Fn(CreateWebWorkerArgs) -> (WebWorker, Sendable
   + Send;
 
+pub type PreloadModuleCb = dyn Fn(WebWorker) -> LocalFutureObj<'static, Result<WebWorker, AnyError>>
+  + Sync
+  + Send;
+
 /// A holder for callback that is used to create a new
 /// WebWorker. It's a struct instead of a type alias
 /// because `GothamState` used in `OpState` overrides
-/// value if type alises have the same underlying type
+/// value if type aliases have the same underlying type
 #[derive(Clone)]
 pub struct CreateWebWorkerCbHolder(Arc<CreateWebWorkerCb>);
 
+/// A holder for callback that can used to preload some modules into a WebWorker
+/// before actual worker code is executed. It's a struct instead of a type
+/// because `GothamState` used in `OpState` overrides
+/// value if type aliases have the same underlying type
+#[derive(Clone)]
+pub struct PreloadModuleCbHolder(Arc<PreloadModuleCb>);
+
 pub struct WorkerThread {
   // It's an Option so we can take the value before dropping the WorkerThread.
@@ -92,5 +104,8 @@ impl Drop for WorkerThread {
 pub type WorkersTable = HashMap<WorkerId, WorkerThread>;
 
-pub fn init(create_web_worker_cb: Arc<CreateWebWorkerCb>) -> Extension {
+pub fn init(
+  create_web_worker_cb: Arc<CreateWebWorkerCb>,
+  preload_module_cb: Arc<PreloadModuleCb>,
+) -> Extension {
   Extension::builder()
     .state(move |state| {
@@ -98,7 +113,10 @@ pub fn init(create_web_worker_cb: Arc<CreateWebWorkerCb>) -> Extension {
       state.put::<WorkerId>(WorkerId::default());
 
-      let create_module_loader =
+      let create_web_worker_cb_holder =
         CreateWebWorkerCbHolder(create_web_worker_cb.clone());
-      state.put::<CreateWebWorkerCbHolder>(create_module_loader);
+      state.put::<CreateWebWorkerCbHolder>(create_web_worker_cb_holder);
+      let preload_module_cb_holder =
+        PreloadModuleCbHolder(preload_module_cb.clone());
+      state.put::<PreloadModuleCbHolder>(preload_module_cb_holder);
 
       Ok(())
@@ -175,6 +193,8 @@ fn op_create_worker(
   let maybe_exit_code = state.try_borrow::<Arc<AtomicI32>>().cloned();
   let worker_id = state.take::<WorkerId>();
-  let create_module_loader = state.take::<CreateWebWorkerCbHolder>();
-  state.put::<CreateWebWorkerCbHolder>(create_module_loader.clone());
+  let create_web_worker_cb = state.take::<CreateWebWorkerCbHolder>();
+  state.put::<CreateWebWorkerCbHolder>(create_web_worker_cb.clone());
+  let preload_module_cb = state.take::<PreloadModuleCbHolder>();
+  state.put::<PreloadModuleCbHolder>(preload_module_cb.clone());
   state.put::<WorkerId>(worker_id.next().unwrap());
 
@@ -198,5 +218,5 @@ fn op_create_worker(
 
     let (worker, external_handle) =
-      (create_module_loader.0)(CreateWebWorkerArgs {
+      (create_web_worker_cb.0)(CreateWebWorkerArgs {
         name: worker_name,
         worker_id,
@@ -217,5 +237,10 @@ fn op_create_worker(
     //
     // Host can already push messages and interact with worker.
-    run_web_worker(worker, module_specifier, maybe_source_code)
+    run_web_worker(
+      worker,
+      module_specifier,
+      maybe_source_code,
+      preload_module_cb.0,
+    )
   })?;
 
diff --git a/runtime/web_worker.rs b/runtime/web_worker.rs
index 130b13dc0..8cbbb5d4f 100644
--- a/runtime/web_worker.rs
+++ b/runtime/web_worker.rs
@@ -305,4 +305,5 @@ pub struct WebWorker {
   pub worker_type: WebWorkerType,
   pub main_module: ModuleSpecifier,
+  poll_for_messages_fn: Option<v8::Global<v8::Value>>,
 }
 
@@ -316,4 +317,5 @@ pub struct WebWorkerOptions {
   pub module_loader: Rc<dyn ModuleLoader>,
   pub create_web_worker_cb: Arc<ops::worker_host::CreateWebWorkerCb>,
+  pub preload_module_cb: Arc<ops::worker_host::PreloadModuleCb>,
   pub js_error_create_fn: Option<Rc<JsErrorCreateFn>>,
   pub use_deno_namespace: bool,
@@ -396,5 +398,8 @@ impl WebWorker {
       ops::web_worker::init(),
       ops::runtime::init(main_module.clone()),
-      ops::worker_host::init(options.create_web_worker_cb.clone()),
+      ops::worker_host::init(
+        options.create_web_worker_cb.clone(),
+        options.preload_module_cb.clone(),
+      ),
       ops::io::init(),
     ];
@@ -469,4 +474,5 @@ impl WebWorker {
         worker_type: options.worker_type,
         main_module,
+        poll_for_messages_fn: None,
       },
       external_handle,
@@ -487,4 +493,16 @@ impl WebWorker {
       .execute_script(&located_script_name!(), &script)
       .expect(""Failed to execute worker bootstrap script"");
+    // Save a reference to function that will start polling for messages
+    // from a worker host; it will be called after the user code is loaded.
+    let script = r#""
+    const pollForMessages = globalThis.pollForMessages;
+    delete globalThis.pollForMessages;
+    pollForMessages
+    ""#;
+    let poll_for_messages_fn = self
+      .js_runtime
+      .execute_script(&located_script_name!(), script)
+      .expect(""Failed to execute worker bootstrap script"");
+    self.poll_for_messages_fn = Some(poll_for_messages_fn);
   }
 
@@ -520,9 +538,34 @@ impl WebWorker {
 
   /// Loads, instantiates and executes specified JavaScript module.
-  pub async fn execute_main_module(
+  ///
+  /// This method assumes that worker can't be terminated when executing
+  /// side module code.
+  pub async fn execute_side_module(
     &mut self,
     module_specifier: &ModuleSpecifier,
   ) -> Result<(), AnyError> {
-    let id = self.preload_module(module_specifier, true).await?;
+    let id = self.preload_module(module_specifier, false).await?;
+    let mut receiver = self.js_runtime.mod_evaluate(id);
+    tokio::select! {
+      maybe_result = &mut receiver => {
+        debug!(""received module evaluate {:#?}"", maybe_result);
+        maybe_result.expect(""Module evaluation result not provided."")
+      }
+
+      event_loop_result = self.js_runtime.run_event_loop(false) => {
+        event_loop_result?;
+        let maybe_result = receiver.await;
+        maybe_result.expect(""Module evaluation result not provided."")
+      }
+    }
+  }
+
+  /// Loads, instantiates and executes specified JavaScript module.
+  ///
+  /// This module will have ""import.meta.main"" equal to true.
+  pub async fn execute_main_module(
+    &mut self,
+    id: ModuleId,
+  ) -> Result<(), AnyError> {
     let mut receiver = self.js_runtime.mod_evaluate(id);
     tokio::select! {
@@ -583,4 +626,15 @@ impl WebWorker {
     poll_fn(|cx| self.poll_event_loop(cx, wait_for_inspector)).await
   }
+
+  // Starts polling for messages from worker host from JavaScript.
+  fn start_polling_for_messages(&mut self) {
+    let poll_for_messages_fn = self.poll_for_messages_fn.take().unwrap();
+    let scope = &mut self.js_runtime.handle_scope();
+    let poll_for_messages =
+      v8::Local::<v8::Value>::new(scope, poll_for_messages_fn);
+    let fn_ = v8::Local::<v8::Function>::try_from(poll_for_messages).unwrap();
+    let undefined = v8::undefined(scope);
+    fn_.call(scope, undefined.into(), &[]).unwrap();
+  }
 }
 
@@ -597,7 +651,8 @@ fn print_worker_error(error_str: String, name: &str) {
 // TODO(bartlomieju): check if order of actions is aligned to Worker spec
 pub fn run_web_worker(
-  mut worker: WebWorker,
+  worker: WebWorker,
   specifier: ModuleSpecifier,
   maybe_source_code: Option<String>,
+  preload_module_cb: Arc<ops::worker_host::PreloadModuleCb>,
 ) -> Result<(), AnyError> {
   let name = worker.name.to_string();
@@ -607,15 +662,37 @@ pub fn run_web_worker(
 
   let fut = async move {
+    let internal_handle = worker.internal_handle.clone();
+    let result = (preload_module_cb)(worker).await;
+
+    let mut worker = match result {
+      Ok(worker) => worker,
+      Err(e) => {
+        print_worker_error(e.to_string(), &name);
+        internal_handle
+          .post_event(WorkerControlEvent::TerminalError(e))
+          .expect(""Failed to post message to host"");
+
+        // Failure to execute script is a terminal error, bye, bye.
+        return Ok(());
+      }
+    };
+
     // Execute provided source code immediately
     let result = if let Some(source_code) = maybe_source_code {
-      worker.execute_script(&located_script_name!(), &source_code)
+      let r = worker.execute_script(&located_script_name!(), &source_code);
+      worker.start_polling_for_messages();
+      r
     } else {
       // TODO(bartlomieju): add ""type"": ""classic"", ie. ability to load
       // script instead of module
-      worker.execute_main_module(&specifier).await
+      match worker.preload_module(&specifier, true).await {
+        Ok(id) => {
+          worker.start_polling_for_messages();
+          worker.execute_main_module(id).await
+        }
+        Err(e) => Err(e),
+      }
     };
 
-    let internal_handle = worker.internal_handle.clone();
-
     // If sender is closed it means that worker has already been closed from
     // within using ""globalThis.close()""
diff --git a/runtime/worker.rs b/runtime/worker.rs
index 7a3a6c1c3..1dc9504d6 100644
--- a/runtime/worker.rs
+++ b/runtime/worker.rs
@@ -52,6 +52,7 @@ pub struct WorkerOptions {
   pub seed: Option<u64>,
   pub module_loader: Rc<dyn ModuleLoader>,
-  // Callback invoked when creating new instance of WebWorker
+  // Callbacks invoked when creating new instance of WebWorker
   pub create_web_worker_cb: Arc<ops::worker_host::CreateWebWorkerCb>,
+  pub web_worker_preload_module_cb: Arc<ops::worker_host::PreloadModuleCb>,
   pub js_error_create_fn: Option<Rc<JsErrorCreateFn>>,
   pub maybe_inspector_server: Option<Arc<InspectorServer>>,
@@ -127,5 +128,8 @@ impl MainWorker {
       // Runtime ops
       ops::runtime::init(main_module.clone()),
-      ops::worker_host::init(options.create_web_worker_cb.clone()),
+      ops::worker_host::init(
+        options.create_web_worker_cb.clone(),
+        options.web_worker_preload_module_cb.clone(),
+      ),
       ops::fs_events::init(),
       ops::fs::init(),
@@ -368,4 +372,5 @@ mod tests {
       seed: None,
       js_error_create_fn: None,
+      web_worker_preload_module_cb: Arc::new(|_| unreachable!()),
       create_web_worker_cb: Arc::new(|_| unreachable!()),
       maybe_inspector_server: None,
","compat: support --compat in web workers (#13629)

Adds another callback to WebWorkerOptions that allows to execute
some modules before actual worker code executes. This allows to set up Node
global using std/node.
"
933,Rust,eae0150b0a7a89f76f7b8910786e86cece3e9830,https://github.com/tauri-apps/tauri/commit/eae0150b0a7a89f76f7b8910786e86cece3e9830,P,tauri-apps,tauri,"[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/tooling/cli/node/test/jest/fixtures/app/src-tauri/Cargo.toml b/tooling/cli/node/test/jest/fixtures/app/src-tauri/Cargo.toml
index de550fef..d1260971 100644
--- a/tooling/cli/node/test/jest/fixtures/app/src-tauri/Cargo.toml
+++ b/tooling/cli/node/test/jest/fixtures/app/src-tauri/Cargo.toml
@@ -25,5 +25,5 @@ tauri-build = { path = ""../../../../../../../../core/tauri-build"", features = []
 
 [dependencies]
-serde_json = ""1.0.95""
+serde_json = ""1.0.96""
 serde = ""1.0""
 serde_derive = ""1.0""
","chore(deps) Update Rust crate serde_json to 1.0.96 (#6738)

Co-authored-by: renovate[bot] <29139614+renovate[bot]@users.noreply.github.com>
"
941,Rust,95726ebb6180d371be44bff9f16ca1eee049006a,https://github.com/tauri-apps/tauri/commit/95726ebb6180d371be44bff9f16ca1eee049006a,A,tauri-apps,tauri,"[1, 4, 0, 0, 0, 0, 0, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 4, 1, 5, 0, 0, 1, 0, 1, 1]","diff --git a/.changes/validate-bundle-identifier.md b/.changes/validate-bundle-identifier.md
new file mode 100644
index 00000000..d8d36396
--- /dev/null
+++ b/.changes/validate-bundle-identifier.md
@@ -0,0 +1,6 @@
+---
+""cli.rs"": patch
+""cli.js"": patch
+---
+
+Prevent building when the bundle identifier is the default `com.tauri.dev`.
diff --git a/Cargo.toml b/Cargo.toml
index cc56de52..7368cf18 100644
--- a/Cargo.toml
+++ b/Cargo.toml
@@ -20,6 +20,5 @@ exclude = [
   ""examples/updater/src-tauri"",
   ""examples/resources/src-tauri"",
-  ""examples/sidecar/src-tauri"",
-  ""examples/isolation/src-tauri""
+  ""examples/sidecar/src-tauri""
 ]
 
diff --git a/examples/isolation/tauri.conf.json b/examples/isolation/tauri.conf.json
index f3936127..5b84f642 100644
--- a/examples/isolation/tauri.conf.json
+++ b/examples/isolation/tauri.conf.json
@@ -22,5 +22,5 @@
       ""active"": true,
       ""targets"": ""all"",
-      ""identifier"": ""com.tauri.isolation"",
+      ""identifier"": ""com.tauri.dev"",
       ""icon"": [
         ""../.icons/32x32.png"",
diff --git a/examples/resources/src-tauri/tauri.conf.json b/examples/resources/src-tauri/tauri.conf.json
index 5033d4a5..078e5fc4 100644
--- a/examples/resources/src-tauri/tauri.conf.json
+++ b/examples/resources/src-tauri/tauri.conf.json
@@ -12,5 +12,5 @@
       ""active"": true,
       ""targets"": ""all"",
-      ""identifier"": ""com.tauri.dev"",
+      ""identifier"": ""com.tauri.resources"",
       ""icon"": [
         ""../../.icons/32x32.png"",
diff --git a/examples/sidecar/src-tauri/tauri.conf.json b/examples/sidecar/src-tauri/tauri.conf.json
index 09e869b7..ad36028e 100644
--- a/examples/sidecar/src-tauri/tauri.conf.json
+++ b/examples/sidecar/src-tauri/tauri.conf.json
@@ -12,5 +12,5 @@
       ""active"": true,
       ""targets"": ""all"",
-      ""identifier"": ""com.tauri.dev"",
+      ""identifier"": ""com.tauri.sidecar"",
       ""icon"": [
         ""../../.icons/32x32.png"",
diff --git a/examples/updater/src-tauri/tauri.conf.json b/examples/updater/src-tauri/tauri.conf.json
index e9c8bd2b..700dfd82 100644
--- a/examples/updater/src-tauri/tauri.conf.json
+++ b/examples/updater/src-tauri/tauri.conf.json
@@ -11,5 +11,5 @@
       ""active"": true,
       ""targets"": ""all"",
-      ""identifier"": ""com.tauri.dev"",
+      ""identifier"": ""com.tauri.updater"",
       ""icon"": [
         ""../../.icons/32x32.png"",
diff --git a/tooling/cli/node/test/jest/__tests__/template.spec.js b/tooling/cli/node/test/jest/__tests__/template.spec.js
index 102ef727..7a9bf68e 100644
--- a/tooling/cli/node/test/jest/__tests__/template.spec.js
+++ b/tooling/cli/node/test/jest/__tests__/template.spec.js
@@ -40,4 +40,8 @@ describe('[CLI] cli.js template', () => {
     writeFileSync(manifestPath, `workspace = { }\n${manifestFile}`)
 
+    const configPath = resolve(tauriFixturePath, 'tauri.conf.json')
+    const config = readFileSync(configPath).toString()
+    writeFileSync(configPath, config.replace('com.tauri.dev', 'com.tauri.test'))
+
     await cli.run(['build', '--verbose']).catch(err => {
       console.error(err)
diff --git a/tooling/cli/src/build.rs b/tooling/cli/src/build.rs
index c613a497..95f186f6 100644
--- a/tooling/cli/src/build.rs
+++ b/tooling/cli/src/build.rs
@@ -71,4 +71,9 @@ pub fn command(options: Options) -> Result<()> {
   let config_ = config_guard.as_ref().unwrap();
 
+  if config_.tauri.bundle.identifier == ""com.tauri.dev"" {
+    logger.error(""You must change the bundle identifier in `tauri.conf.json > tauri > bundle > identifier`. The default value `com.tauri.dev` is not allowed as it must be unique across applications."");
+    std::process::exit(1);
+  }
+
   if let Some(before_build) = &config_.build.before_build_command {
     if !before_build.is_empty() {
","feat(cli): prevent default bundle identifier from building, closes #4041 (#4042)


"
960,Rust,eb2f3ddb7cedff7331d8f296275f8d83d10b63be,https://github.com/sharkdp/bat/commit/eb2f3ddb7cedff7331d8f296275f8d83d10b63be,P,sharkdp,bat,"[1, 3, 0, 22, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/src/assets.rs b/src/assets.rs
index 23f8234..bc87eb3 100644
--- a/src/assets.rs
+++ b/src/assets.rs
@@ -247,5 +247,5 @@ mod tests {
         }
 
-        fn syntax_name_with_content(&self, file_name: &str, first_line: &str) -> String {
+        fn synax_for_file_with_content(&self, file_name: &str, first_line: &str) -> String {
             let file_path = self.temp_dir.path().join(file_name);
             {
@@ -265,6 +265,6 @@ mod tests {
         }
 
-        fn syntax_name(&self, file_name: &str) -> String {
-            self.syntax_name_with_content(file_name, """")
+        fn syntax_for_file(&self, file_name: &str) -> String {
+            self.synax_for_file_with_content(file_name, """")
         }
     }
@@ -274,10 +274,13 @@ mod tests {
         let test = SyntaxDetectionTest::new();
 
-        assert_eq!(test.syntax_name(""test.rs""), ""Rust"");
-        assert_eq!(test.syntax_name(""test.cpp""), ""C++"");
-        assert_eq!(test.syntax_name(""test.build""), ""NAnt Build File"");
-        assert_eq!(test.syntax_name(""PKGBUILD""), ""Bourne Again Shell (bash)"");
-        assert_eq!(test.syntax_name("".bashrc""), ""Bourne Again Shell (bash)"");
-        assert_eq!(test.syntax_name(""Makefile""), ""Makefile"");
+        assert_eq!(test.syntax_for_file(""test.rs""), ""Rust"");
+        assert_eq!(test.syntax_for_file(""test.cpp""), ""C++"");
+        assert_eq!(test.syntax_for_file(""test.build""), ""NAnt Build File"");
+        assert_eq!(
+            test.syntax_for_file(""PKGBUILD""),
+            ""Bourne Again Shell (bash)""
+        );
+        assert_eq!(test.syntax_for_file("".bashrc""), ""Bourne Again Shell (bash)"");
+        assert_eq!(test.syntax_for_file(""Makefile""), ""Makefile"");
     }
 
@@ -286,8 +289,8 @@ mod tests {
         let test = SyntaxDetectionTest::new();
 
-        assert_eq!(test.syntax_name(""test.h""), ""C++"");
-        assert_eq!(test.syntax_name(""test.sass""), ""Sass"");
-        assert_eq!(test.syntax_name(""test.hs""), ""Haskell (improved)"");
-        assert_eq!(test.syntax_name(""test.js""), ""JavaScript (Babel)"");
+        assert_eq!(test.syntax_for_file(""test.h""), ""C++"");
+        assert_eq!(test.syntax_for_file(""test.sass""), ""Sass"");
+        assert_eq!(test.syntax_for_file(""test.hs""), ""Haskell (improved)"");
+        assert_eq!(test.syntax_for_file(""test.js""), ""JavaScript (Babel)"");
     }
 
@@ -297,12 +300,15 @@ mod tests {
 
         assert_eq!(
-            test.syntax_name_with_content(""my_script"", ""#!/bin/bash""),
+            test.synax_for_file_with_content(""my_script"", ""#!/bin/bash""),
             ""Bourne Again Shell (bash)""
         );
         assert_eq!(
-            test.syntax_name_with_content(""build"", ""#!/bin/bash""),
+            test.synax_for_file_with_content(""build"", ""#!/bin/bash""),
             ""Bourne Again Shell (bash)""
         );
-        assert_eq!(test.syntax_name_with_content(""my_script"", ""<?php""), ""PHP"");
+        assert_eq!(
+            test.synax_for_file_with_content(""my_script"", ""<?php""),
+            ""PHP""
+        );
     }
 
@@ -311,9 +317,9 @@ mod tests {
         let mut test = SyntaxDetectionTest::new();
 
-        assert_eq!(test.syntax_name(""test.h""), ""C++"");
+        assert_eq!(test.syntax_for_file(""test.h""), ""C++"");
         test.syntax_mapping
             .insert(""*.h"", MappingTarget::MapTo(""C""))
             .ok();
-        assert_eq!(test.syntax_name(""test.h""), ""C"");
+        assert_eq!(test.syntax_for_file(""test.h""), ""C"");
     }
 
@@ -322,9 +328,9 @@ mod tests {
         let mut test = SyntaxDetectionTest::new();
 
-        assert_ne!(test.syntax_name(""README.MD""), ""Markdown"");
+        assert_ne!(test.syntax_for_file(""README.MD""), ""Markdown"");
         test.syntax_mapping
             .insert(""*.MD"", MappingTarget::MapTo(""Markdown""))
             .ok();
-        assert_eq!(test.syntax_name(""README.MD""), ""Markdown"");
+        assert_eq!(test.syntax_for_file(""README.MD""), ""Markdown"");
     }
 }
","Rename test methods

"
968,Rust,6a0e0147e03a0322fc8e7e959e787f7a635df906,https://github.com/BurntSushi/ripgrep/commit/6a0e0147e03a0322fc8e7e959e787f7a635df906,P,BurntSushi,ripgrep,"[2, 28, 0, 1, 27, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0]","diff --git a/CHANGELOG.md b/CHANGELOG.md
index 49b7a69..34caeaa 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -11,4 +11,6 @@ Performance improvements:
   e.g., ` +Sherlock Holmes +` now has ` Sherlock Holmes ` extracted instead
   of ` `.
+* PERF:
+  Improve literal detection when the `-w/--word-regexp` flag is used.
 
 Feature enhancements:
diff --git a/grep-regex/src/literal.rs b/grep-regex/src/literal.rs
index cc1e896..e4c8e65 100644
--- a/grep-regex/src/literal.rs
+++ b/grep-regex/src/literal.rs
@@ -111,5 +111,61 @@ impl LiteralSets {
             Some(format!(""(?-u:{})"", alts.join(""|"")))
         } else if lit.is_empty() {
-            None
+            // If we're here, then we have no LCP. No LCS. And no detected
+            // inner required literals. In theory this shouldn't happen, but
+            // the inner literal detector isn't as nice as we hope and doens't
+            // actually support returning a set of alternating required
+            // literals. (Instead, it only returns a set where EVERY literal
+            // in it is required. It cannot currently express ""either P or Q
+            // is required."")
+            //
+            // In this case, it is possible that we still have meaningful
+            // prefixes or suffixes to use. So we look for the set of literals
+            // with the highest minimum length and use that to build our ""fast""
+            // regex.
+            //
+            // This manifest in fairly common scenarios. e.g.,
+            //
+            //     rg -w 'foo|bar|baz|quux'
+            //
+            // Normally, without the `-w`, the regex engine itself would
+            // detect the prefix correctly. Unfortunately, the `-w` option
+            // turns the regex into something like this:
+            //
+            //     rg '(^|\W)(foo|bar|baz|quux)($|\W)'
+            //
+            // Which will defeat all prefix and suffix literal optimizations.
+            // (Not in theory---it could be better. But the current
+            // implementation isn't good enough.) ... So we make up for it
+            // here.
+            let p_min_len = self.prefixes.min_len();
+            let s_min_len = self.suffixes.min_len();
+            let lits = match (p_min_len, s_min_len) {
+                (None, None) => return None,
+                (Some(_), None) => {
+                    debug!(""prefix literals found"");
+                    self.prefixes.literals()
+                }
+                (None, Some(_)) => {
+                    debug!(""suffix literals found"");
+                    self.suffixes.literals()
+                }
+                (Some(p), Some(s)) => {
+                    if p >= s {
+                        debug!(""prefix literals found"");
+                        self.prefixes.literals()
+                    } else {
+                        debug!(""suffix literals found"");
+                        self.suffixes.literals()
+                    }
+                }
+            };
+
+            debug!(""prefix/suffix literals found: {:?}"", lits);
+            let alts: Vec<String> = lits
+                .into_iter()
+                .map(|x| util::bytes_to_regex(x))
+                .collect();
+            // We're matching raw bytes, so disable Unicode mode.
+            Some(format!(""(?-u:{})"", alts.join(""|"")))
         } else {
             debug!(""required literal found: {:?}"", util::show_bytes(lit));
diff --git a/grep-regex/src/matcher.rs b/grep-regex/src/matcher.rs
index 61af051..4250465 100644
--- a/grep-regex/src/matcher.rs
+++ b/grep-regex/src/matcher.rs
@@ -50,5 +50,5 @@ impl RegexMatcherBuilder {
         let non_matching_bytes = chir.non_matching_bytes();
         if let Some(ref re) = fast_line_regex {
-            trace!(""extracted fast line regex: {:?}"", re);
+            debug!(""extracted fast line regex: {:?}"", re);
         }
 
","grep-regex: improve literal detection with -w

When the -w/--word-regexp was used, ripgrep would in many cases fail to
apply literal optimizations. This occurs specifically when the regex
given by the user is an alternation of literals with no common prefixes
or suffixes, e.g.,

    rg -w 'foo|bar|baz|quux'

In this case, the inner literal detector fails. Normally, this would
result in literal prefixes being detected by the regex engine. But
because of the -w/--word-regexp flag, the actual regex that we run ends
up looking like this:

    (^|\W)(foo|bar|baz|quux)($|\W)

which of course defeats any prefix or suffix literal optimizations in
the regex crate's somewhat naive extractor. (A better extractor could
still do literal optimizations in the above case.)

So this commit fixes this by falling back to prefix or suffix literals
when they're available instead of prematurely giving up and assuming the
regex engine will do the rest.

"
969,Rust,0f7494216f55bb5d373027c2039d8c26dbc4a564,https://github.com/BurntSushi/ripgrep/commit/0f7494216f55bb5d373027c2039d8c26dbc4a564,P,BurntSushi,ripgrep,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0]","diff --git a/README.md b/README.md
index 7438fbd..9e2b01f 100644
--- a/README.md
+++ b/README.md
@@ -293,6 +293,6 @@ ripgrep is not in the official Debian or Ubuntu repositories.
 
 ```
-$ curl -LO https://github.com/BurntSushi/ripgrep/releases/download/0.9.0/ripgrep_0.9.0_amd64.deb
-$ sudo dpkg -i ripgrep_0.9.0_amd64.deb
+$ curl -LO https://github.com/BurntSushi/ripgrep/releases/download/0.10.0/ripgrep_0.10.0_amd64.deb
+$ sudo dpkg -i ripgrep_0.10.0_amd64.deb
 ```
 
","readme: update dpkg version

"
1016,Rust,2a2126c40a6330d5dc54c6c3a54e58d0637b101c,https://github.com/sharkdp/fd/commit/2a2126c40a6330d5dc54c6c3a54e58d0637b101c,P,sharkdp,fd,"[7, 0, 3, 24, 0, 0, 0, 1, 3, 0, 5, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0]","diff --git a/.github/workflows/CICD.yml b/.github/workflows/CICD.yml
index 1f80cb3..22ba12d 100644
--- a/.github/workflows/CICD.yml
+++ b/.github/workflows/CICD.yml
@@ -2,5 +2,5 @@ name: CICD
 
 env:
-  MIN_SUPPORTED_RUST_VERSION: ""1.40.0""
+  MIN_SUPPORTED_RUST_VERSION: ""1.42.0""
   CICD_INTERMEDIATES_DIR: ""_cicd-intermediates""
 
diff --git a/README.md b/README.md
index 8c991d1..66d5752 100644
--- a/README.md
+++ b/README.md
@@ -622,5 +622,5 @@ With Rust's package manager [cargo](https://github.com/rust-lang/cargo), you can
 cargo install fd-find
 ```
-Note that rust version *1.36.0* or later is required.
+Note that rust version *1.42.0* or later is required.
 
 ### From binaries
diff --git a/build.rs b/build.rs
index a560325..ddf9e15 100644
--- a/build.rs
+++ b/build.rs
@@ -6,5 +6,5 @@ include!(""src/app.rs"");
 
 fn main() {
-    let min_version = ""1.36"";
+    let min_version = ""1.42"";
 
     match version_check::is_min_version(min_version) {
diff --git a/src/exec/mod.rs b/src/exec/mod.rs
index c47e32c..f24c0e3 100644
--- a/src/exec/mod.rs
+++ b/src/exec/mod.rs
@@ -202,8 +202,5 @@ enum ArgumentTemplate {
 impl ArgumentTemplate {
     pub fn has_tokens(&self) -> bool {
-        match self {
-            ArgumentTemplate::Tokens(_) => true,
-            _ => false,
-        }
+        matches!(self, ArgumentTemplate::Tokens(_))
     }
 
diff --git a/src/exit_codes.rs b/src/exit_codes.rs
index 96bce96..720440f 100644
--- a/src/exit_codes.rs
+++ b/src/exit_codes.rs
@@ -6,7 +6,7 @@ pub enum ExitCode {
 }
 
-impl Into<i32> for ExitCode {
-    fn into(self) -> i32 {
-        match self {
+impl From<ExitCode> for i32 {
+    fn from(code: ExitCode) -> Self {
+        match code {
             ExitCode::Success => 0,
             ExitCode::GeneralError => 1,
@@ -17,11 +17,11 @@ impl Into<i32> for ExitCode {
 
 impl ExitCode {
-    fn is_error(&self) -> bool {
-        *self != ExitCode::Success
+    fn is_error(self) -> bool {
+        self != ExitCode::Success
     }
 }
 
 pub fn merge_exitcodes(results: &[ExitCode]) -> ExitCode {
-    if results.iter().any(ExitCode::is_error) {
+    if results.iter().any(|&c| ExitCode::is_error(c)) {
         return ExitCode::GeneralError;
     }
diff --git a/src/filesystem.rs b/src/filesystem.rs
index 15ca56d..19fc0e6 100644
--- a/src/filesystem.rs
+++ b/src/filesystem.rs
@@ -69,20 +69,20 @@ pub fn is_empty(entry: &walk::DirEntry) -> bool {
 
 #[cfg(any(unix, target_os = ""redox""))]
-pub fn is_socket(ft: &fs::FileType) -> bool {
+pub fn is_socket(ft: fs::FileType) -> bool {
     ft.is_socket()
 }
 
 #[cfg(windows)]
-pub fn is_socket(_: &fs::FileType) -> bool {
+pub fn is_socket(_: fs::FileType) -> bool {
     false
 }
 
 #[cfg(any(unix, target_os = ""redox""))]
-pub fn is_pipe(ft: &fs::FileType) -> bool {
+pub fn is_pipe(ft: fs::FileType) -> bool {
     ft.is_fifo()
 }
 
 #[cfg(windows)]
-pub fn is_pipe(_: &fs::FileType) -> bool {
+pub fn is_pipe(_: fs::FileType) -> bool {
     false
 }
diff --git a/src/main.rs b/src/main.rs
index 6f0eece..4b5f71c 100644
--- a/src/main.rs
+++ b/src/main.rs
@@ -332,5 +332,5 @@ fn run() -> Result<ExitCode> {
             .or_else(|| matches.value_of(""rg-depth""))
             .or_else(|| matches.value_of(""exact-depth""))
-            .map(|n| usize::from_str_radix(n, 10))
+            .map(|n| n.parse::<usize>())
             .transpose()
             .context(""Failed to parse argument to --max-depth/--exact-depth"")?,
@@ -338,5 +338,5 @@ fn run() -> Result<ExitCode> {
             .value_of(""min-depth"")
             .or_else(|| matches.value_of(""exact-depth""))
-            .map(|n| usize::from_str_radix(n, 10))
+            .map(|n| n.parse::<usize>())
             .transpose()
             .context(""Failed to parse argument to --min-depth/--exact-depth"")?,
@@ -345,5 +345,5 @@ fn run() -> Result<ExitCode> {
             matches
                 .value_of(""threads"")
-                .map(|n| usize::from_str_radix(n, 10))
+                .map(|n| n.parse::<usize>())
                 .transpose()
                 .context(""Failed to parse number of threads"")?
@@ -361,5 +361,5 @@ fn run() -> Result<ExitCode> {
         max_buffer_time: matches
             .value_of(""max-buffer-time"")
-            .map(|n| u64::from_str_radix(n, 10))
+            .map(|n| n.parse::<u64>())
             .transpose()
             .context(""Failed to parse max. buffer time argument"")?
@@ -421,5 +421,5 @@ fn run() -> Result<ExitCode> {
         max_results: matches
             .value_of(""max-results"")
-            .map(|n| usize::from_str_radix(n, 10))
+            .map(|n| n.parse::<usize>())
             .transpose()
             .context(""Failed to parse --max-results argument"")?
diff --git a/src/output.rs b/src/output.rs
index 008f3a9..aa5e344 100644
--- a/src/output.rs
+++ b/src/output.rs
@@ -1,4 +1,4 @@
 use std::io::{self, StdoutLock, Write};
-use std::path::{Path, PathBuf};
+use std::path::Path;
 use std::process;
 use std::sync::atomic::{AtomicBool, Ordering};
@@ -18,10 +18,10 @@ fn replace_path_separator(path: &str, new_path_separator: &str) -> String {
 pub fn print_entry(
     stdout: &mut StdoutLock,
-    entry: &PathBuf,
+    entry: &Path,
     config: &Options,
     wants_to_quit: &Arc<AtomicBool>,
 ) {
     let path = if entry.is_absolute() {
-        entry.as_path()
+        entry
     } else {
         strip_current_dir(entry)
diff --git a/src/walk.rs b/src/walk.rs
index 456b717..7b0db30 100644
--- a/src/walk.rs
+++ b/src/walk.rs
@@ -427,6 +427,6 @@ fn spawn_senders(
                         || (!file_types.directories && entry_type.is_dir())
                         || (!file_types.symlinks && entry_type.is_symlink())
-                        || (!file_types.sockets && filesystem::is_socket(entry_type))
-                        || (!file_types.pipes && filesystem::is_pipe(entry_type))
+                        || (!file_types.sockets && filesystem::is_socket(*entry_type))
+                        || (!file_types.pipes && filesystem::is_pipe(*entry_type))
                         || (file_types.executables_only
                             && !entry
@@ -438,6 +438,6 @@ fn spawn_senders(
                             || entry_type.is_dir()
                             || entry_type.is_symlink()
-                            || filesystem::is_socket(entry_type)
-                            || filesystem::is_pipe(entry_type))
+                            || filesystem::is_socket(*entry_type)
+                            || filesystem::is_pipe(*entry_type))
                     {
                         return ignore::WalkState::Continue;
diff --git a/tests/testenv/mod.rs b/tests/testenv/mod.rs
index 6b58fc0..cc439bc 100644
--- a/tests/testenv/mod.rs
+++ b/tests/testenv/mod.rs
@@ -120,5 +120,5 @@ fn normalize_output(s: &str, trim_start: bool, normalize_line: bool) -> String {
             if normalize_line {
                 let mut words: Vec<_> = line.split_whitespace().collect();
-                words.sort();
+                words.sort_unstable();
                 return words.join("" "");
             }
@@ -198,5 +198,5 @@ impl TestEnv {
         // Check for exit status.
         if !output.status.success() {
-            panic!(format_exit_error(args, &output));
+            panic!(""{}"", format_exit_error(args, &output));
         }
 
@@ -237,5 +237,5 @@ impl TestEnv {
         // Compare actual output to expected output.
         if expected != actual {
-            panic!(format_output_error(args, &expected, &actual));
+            panic!(""{}"", format_output_error(args, &expected, &actual));
         }
     }
@@ -290,9 +290,12 @@ impl TestEnv {
             // Compare actual output to expected output.
             if !actual_err.trim_start().starts_with(&expected_error) {
-                panic!(format_output_error(args, &expected_error, &actual_err));
+                panic!(
+                    ""{}"",
+                    format_output_error(args, &expected_error, &actual_err)
+                );
             }
         }
 
-        return output.status;
+        output.status
     }
 }
","Fix clippy warnings

"
1022,Rust,feac240eb50ebbd422bbfe61ebecb4edf9d29a59,https://github.com/sharkdp/fd/commit/feac240eb50ebbd422bbfe61ebecb4edf9d29a59,P,sharkdp,fd,"[3, 15, 3, 23, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/src/exec/job.rs b/src/exec/job.rs
index aa8164c..85b30f1 100644
--- a/src/exec/job.rs
+++ b/src/exec/job.rs
@@ -27,5 +27,5 @@ pub fn job(
         // has closed, exit from the loop
         let value: PathBuf = match lock.recv() {
-            Ok(WorkerResult::Entry(val)) => val,
+            Ok(WorkerResult::Entry(path)) => path,
             Ok(WorkerResult::Error(err)) => {
                 if show_filesystem_errors {
@@ -54,5 +54,5 @@ pub fn batch(
 ) -> ExitCode {
     let paths = rx.iter().filter_map(|value| match value {
-        WorkerResult::Entry(val) => Some(val),
+        WorkerResult::Entry(path) => Some(path),
         WorkerResult::Error(err) => {
             if show_filesystem_errors {
diff --git a/src/output.rs b/src/output.rs
index 5fae330..772e29a 100644
--- a/src/output.rs
+++ b/src/output.rs
@@ -1,7 +1,6 @@
 use std::borrow::Cow;
-use std::io::{self, StdoutLock, Write};
+use std::io::{self, Write};
 use std::path::Path;
 use std::sync::atomic::{AtomicBool, Ordering};
-use std::sync::Arc;
 
 use lscolors::{Indicator, LsColors, Style};
@@ -17,9 +16,9 @@ fn replace_path_separator(path: &str, new_path_separator: &str) -> String {
 
 // TODO: this function is performance critical and can probably be optimized
-pub fn print_entry(
-    stdout: &mut StdoutLock,
+pub fn print_entry<W: Write>(
+    stdout: &mut W,
     entry: &Path,
     config: &Config,
-    wants_to_quit: &Arc<AtomicBool>,
+    wants_to_quit: &AtomicBool,
 ) {
     let path = if config.strip_cwd_prefix {
@@ -47,10 +46,10 @@ pub fn print_entry(
 
 // TODO: this function is performance critical and can probably be optimized
-fn print_entry_colorized(
-    stdout: &mut StdoutLock,
+fn print_entry_colorized<W: Write>(
+    stdout: &mut W,
     path: &Path,
     config: &Config,
     ls_colors: &LsColors,
-    wants_to_quit: &Arc<AtomicBool>,
+    wants_to_quit: &AtomicBool,
 ) -> io::Result<()> {
     // Split the path between the parent and the last component
@@ -95,4 +94,5 @@ fn print_entry_colorized(
 
     if wants_to_quit.load(Ordering::Relaxed) {
+        stdout.flush()?;
         ExitCode::KilledBySigint.exit();
     }
@@ -102,6 +102,6 @@ fn print_entry_colorized(
 
 // TODO: this function is performance critical and can probably be optimized
-fn print_entry_uncolorized_base(
-    stdout: &mut StdoutLock,
+fn print_entry_uncolorized_base<W: Write>(
+    stdout: &mut W,
     path: &Path,
     config: &Config,
@@ -117,6 +117,6 @@ fn print_entry_uncolorized_base(
 
 #[cfg(not(unix))]
-fn print_entry_uncolorized(
-    stdout: &mut StdoutLock,
+fn print_entry_uncolorized<W: Write>(
+    stdout: &mut W,
     path: &Path,
     config: &Config,
@@ -126,6 +126,6 @@ fn print_entry_uncolorized(
 
 #[cfg(unix)]
-fn print_entry_uncolorized(
-    stdout: &mut StdoutLock,
+fn print_entry_uncolorized<W: Write>(
+    stdout: &mut W,
     path: &Path,
     config: &Config,
diff --git a/src/walk.rs b/src/walk.rs
index ed3bf9f..61e38e4 100644
--- a/src/walk.rs
+++ b/src/walk.rs
@@ -1,3 +1,2 @@
-use std::borrow::Cow;
 use std::ffi::OsStr;
 use std::fs::{FileType, Metadata};
@@ -5,8 +4,9 @@ use std::io;
 use std::path::{Path, PathBuf};
 use std::sync::atomic::{AtomicBool, Ordering};
-use std::sync::mpsc::{channel, Receiver, Sender};
+use std::sync::mpsc::{sync_channel, Receiver, SyncSender as Sender};
 use std::sync::{Arc, Mutex};
 use std::thread;
 use std::time;
+use std::{borrow::Cow, io::Write};
 
 use anyhow::{anyhow, Result};
@@ -23,4 +23,10 @@ use crate::filesystem;
 use crate::output;
 
+pub const WORKER_CHANNEL_DEFAULT_BOUND: usize = 1000;
+
+pub fn make_worker_channel() -> (Sender<WorkerResult>, Receiver<WorkerResult>) {
+    sync_channel(WORKER_CHANNEL_DEFAULT_BOUND)
+}
+
 /// The receiver thread can either be buffering results or directly streaming to the console.
 enum ReceiverMode {
@@ -54,5 +60,5 @@ pub fn scan(path_vec: &[PathBuf], pattern: Arc<Regex>, config: Arc<Config>) -> R
         .next()
         .expect(""Error: Path vector can not be empty"");
-    let (tx, rx) = channel();
+    let (tx, rx) = make_worker_channel();
 
     let mut override_builder = OverrideBuilder::new(first_path_buf.as_path());
@@ -221,6 +227,4 @@ fn spawn_receiver(
             let start = time::Instant::now();
 
-            let mut buffer = vec![];
-
             // Start in buffering mode
             let mut mode = ReceiverMode::Buffering;
@@ -230,11 +234,13 @@ fn spawn_receiver(
 
             let stdout = io::stdout();
-            let mut stdout = stdout.lock();
+            let stdout = stdout.lock();
+            let mut stdout = io::BufWriter::new(stdout);
 
             let mut num_results = 0;
-
+            let is_interactive = config.interactive_terminal;
+            let mut buffer = Vec::with_capacity(MAX_BUFFER_LENGTH);
             for worker_result in rx {
                 match worker_result {
-                    WorkerResult::Entry(value) => {
+                    WorkerResult::Entry(path) => {
                         if config.quiet {
                             return ExitCode::HasResults(true);
@@ -243,5 +249,5 @@ fn spawn_receiver(
                         match mode {
                             ReceiverMode::Buffering => {
-                                buffer.push(value);
+                                buffer.push(path);
 
                                 // Have we reached the maximum buffer size or maximum buffering time?
@@ -250,8 +256,8 @@ fn spawn_receiver(
                                 {
                                     // Flush the buffer
-                                    for v in &buffer {
+                                    for path in &buffer {
                                         output::print_entry(
                                             &mut stdout,
-                                            v,
+                                            path,
                                             &config,
                                             &wants_to_quit,
@@ -259,5 +265,8 @@ fn spawn_receiver(
                                     }
                                     buffer.clear();
-
+                                    if is_interactive && stdout.flush().is_err() {
+                                        // Probably a broken pipe. Exit gracefully.
+                                        return ExitCode::GeneralError;
+                                    }
                                     // Start streaming
                                     mode = ReceiverMode::Streaming;
@@ -265,8 +274,11 @@ fn spawn_receiver(
                             }
                             ReceiverMode::Streaming => {
-                                output::print_entry(&mut stdout, &value, &config, &wants_to_quit);
+                                output::print_entry(&mut stdout, &path, &config, &wants_to_quit);
+                                if is_interactive && stdout.flush().is_err() {
+                                    // Probably a broken pipe. Exit gracefully.
+                                    return ExitCode::GeneralError;
+                                }
                             }
                         }
-
                         num_results += 1;
                         if let Some(max_results) = config.max_results {
@@ -283,5 +295,4 @@ fn spawn_receiver(
                 }
             }
-
             // If we have finished fast enough (faster than max_buffer_time), we haven't streamed
             // anything to the console, yet. In this case, sort the results and print them:
","Add buffering to stdout when it's not a terminal

This is based on the work of #736 by @sourlemon207.

I've added the suggestion I recommended on that PR.

"
1028,Rust,782df7056028fd6ac573b23295f9bd052e35ac09,https://github.com/swc-project/swc/commit/782df7056028fd6ac573b23295f9bd052e35ac09,P,swc-project,swc,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 2, 0, 0, 2]","diff --git a/CHANGELOG.md b/CHANGELOG.md
index b1c239cbcc..e0045e3d82 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -6,4 +6,7 @@
 
 
+- **(es/module)** Make exported vars follow specification (#3906) ([534fc52](https://github.com/swc-project/swc/commit/534fc52a727e5be43adfad47ed3fcdd606967c5c))
+
+
 - **(es/module/cjs)** Allow re-exports to be lazy (#3856) ([f575b1b](https://github.com/swc-project/swc/commit/f575b1bc4868dd46c572c3ef61767fdd2ee2c2b3))
 
diff --git a/Cargo.lock b/Cargo.lock
index 5f68e5b2f6..b2e4be0909 100644
--- a/Cargo.lock
+++ b/Cargo.lock
@@ -3314,5 +3314,5 @@ dependencies = [
 [[package]]
 name = ""swc_ecma_transforms_module""
-version = ""0.89.3""
+version = ""0.89.4""
 dependencies = [
  ""Inflector"",
diff --git a/crates/swc_ecma_transforms_module/Cargo.toml b/crates/swc_ecma_transforms_module/Cargo.toml
index 3be6cd132c..bf2b1a83d9 100644
--- a/crates/swc_ecma_transforms_module/Cargo.toml
+++ b/crates/swc_ecma_transforms_module/Cargo.toml
@@ -7,5 +7,5 @@ license = ""Apache-2.0""
 name = ""swc_ecma_transforms_module""
 repository = ""https://github.com/swc-project/swc.git""
-version = ""0.89.3""
+version = ""0.89.4""
 # See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html
 
","chore: Publish crates

"
1075,Rust,ac117019e2e9bf2d9f1859939e6dab119aad28df,https://github.com/bevyengine/bevy/commit/ac117019e2e9bf2d9f1859939e6dab119aad28df,P,bevyengine,bevy,"[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/crates/bevy_ecs/src/schedule/parallel_executor.rs b/crates/bevy_ecs/src/schedule/parallel_executor.rs
index 7ae49740..64f2efbf 100644
--- a/crates/bevy_ecs/src/schedule/parallel_executor.rs
+++ b/crates/bevy_ecs/src/schedule/parallel_executor.rs
@@ -339,5 +339,4 @@ impl ExecutorStage {
                 let resources_ref = &*resources;
 
-                let dependent_systems = &self.system_dependents[system_index];
                 let trigger_events = &self.ready_events_of_dependents[system_index];
 
@@ -349,4 +348,5 @@ impl ExecutorStage {
                 #[cfg(debug_assertions)]
                 {
+                    let dependent_systems = &self.system_dependents[system_index];
                     debug_assert_eq!(trigger_events.len(), dependent_systems.len());
                     for (trigger_event, dependent_system_index) in
","resolve unused variable warning in release builds

"
1094,Rust,bb1fd8d980c41931ef5bf76ebd29266aafc2a175,https://github.com/rome/tools/commit/bb1fd8d980c41931ef5bf76ebd29266aafc2a175,P,rome,tools,"[6, 158, 55, 39, 31, 10, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/crates/rome_formatter/src/arguments.rs b/crates/rome_formatter/src/arguments.rs
index ce38a1a585..c470a2ec1f 100644
--- a/crates/rome_formatter/src/arguments.rs
+++ b/crates/rome_formatter/src/arguments.rs
@@ -145,8 +145,8 @@ mod tests {
                 FormatElement::Token(Token::Static { text: ""a"" }),
                 FormatElement::Space,
-                FormatElement::Group(Group::new(FormatElement::List(List::new(vec![
+                FormatElement::Group(Group::new(vec![
                     FormatElement::Token(Token::Static { text: ""("" }),
                     FormatElement::Token(Token::Static { text: "")"" }),
-                ]))))
+                ]))
             ]))
         );
diff --git a/crates/rome_formatter/src/builders.rs b/crates/rome_formatter/src/builders.rs
index f40df38300..9df696c957 100644
--- a/crates/rome_formatter/src/builders.rs
+++ b/crates/rome_formatter/src/builders.rs
@@ -1,5 +1,6 @@
 use crate::prelude::*;
 use crate::{
-    format_element, write, Argument, Arguments, GroupId, PreambleBuffer, TextRange, TextSize,
+    format_element, write, Argument, Arguments, BufferSnapshot, FormatState, GroupId,
+    PreambleBuffer, TextRange, TextSize,
 };
 use crate::{Buffer, VecBuffer};
@@ -8,4 +9,5 @@ use std::borrow::Cow;
 use std::cell::Cell;
 use std::marker::PhantomData;
+use std::ops::Deref;
 
 /// A line break that only gets printed if the enclosing `Group` doesn't fit on a single line.
@@ -463,5 +465,5 @@ impl<Context> Format<Context> for LineSuffixBoundary {
 ///
 /// ```
-/// use rome_formatter::{format, format_args};
+/// use rome_formatter::{format, write, format_args};
 /// use rome_formatter::prelude::*;
 ///
@@ -470,8 +472,15 @@ impl<Context> Format<Context> for LineSuffixBoundary {
 ///     [
 ///         group_elements(&format_args![
-///             comment(&empty_line()),
-///             token(""a""),
+///             comment(&format_args![token(""// test""), hard_line_break()]),
+///             format_with(|f| {
+///                 write!(f, [
+///                     comment(&format_args![token(""/* inline */""), hard_line_break()]).memoized(),
+///                     token(""a""),
+///                     soft_line_break_or_space(),
+///                 ])
+///             }).memoized(),
+///             token(""b""),
 ///             soft_line_break_or_space(),
-///             token(""b"")
+///             token(""c"")
 ///         ])
 ///     ]
@@ -479,5 +488,5 @@ impl<Context> Format<Context> for LineSuffixBoundary {
 ///
 /// assert_eq!(
-///     ""\na b"",
+///     ""// test\n/* inline */\na b c"",
 ///     elements.print().as_code()
 /// );
@@ -503,7 +512,7 @@ impl<Context> Format<Context> for FormatComment<'_, Context> {
 
         buffer.write_fmt(Arguments::from(&self.content))?;
-        let content = buffer.into_element();
+        let content = buffer.into_vec();
 
-        f.write_element(FormatElement::Comment(Box::new(content)))
+        f.write_element(FormatElement::Comment(content.into_boxed_slice()))
     }
 }
@@ -927,22 +936,16 @@ impl<Context> GroupElements<'_, Context> {
 impl<Context> Format<Context> for GroupElements<'_, Context> {
     fn fmt(&self, f: &mut Formatter<Context>) -> FormatResult<()> {
-        let mut buffer = VecBuffer::new(f.state_mut());
-
+        let mut buffer = GroupElementsBuffer::new(f);
         buffer.write_fmt(Arguments::from(&self.content))?;
+        let content = buffer.into_vec();
 
-        let content = buffer.into_element();
+        if content.is_empty() && self.group_id.is_none() {
+            return Ok(());
+        }
 
-        let (leading, content, trailing) = content.split_trivia();
         let group = Group::new(content).with_id(self.group_id);
 
-        if !leading.is_empty() {
-            f.write_element(leading)?;
-        }
         f.write_element(FormatElement::Group(group))?;
 
-        if !trailing.is_empty() {
-            f.write_element(trailing)?;
-        }
-
         Ok(())
     }
@@ -958,4 +961,148 @@ impl<Context> std::fmt::Debug for GroupElements<'_, Context> {
 }
 
+/// Custom buffer implementation for `GroupElements` that moves the leading comments out of the group
+/// to prevent that a leading line comment expands the token's enclosing group.
+///
+/// # Examples
+///
+/// ```javascript
+/// /* a comment */
+/// [1]
+/// ```
+///
+/// The `/* a comment */` belongs to the `[` group token that is part of a group wrapping the whole
+/// `[1]` expression. It's important that the comment `/* a comment */` gets moved out of the group element
+/// to avoid that the `[1]` group expands because of the line break inserted by the comment.
+struct GroupElementsBuffer<'inner, Context> {
+    inner: &'inner mut dyn Buffer<Context = Context>,
+
+    /// The group inner content
+    content: Vec<FormatElement>,
+}
+
+impl<'inner, Context> GroupElementsBuffer<'inner, Context> {
+    fn new(inner: &'inner mut dyn Buffer<Context = Context>) -> Self {
+        Self {
+            inner,
+            content: Vec::new(),
+        }
+    }
+
+    fn into_vec(self) -> Vec<FormatElement> {
+        self.content
+    }
+
+    fn write_interned(&mut self, interned: Interned) -> FormatResult<()> {
+        debug_assert!(self.content.is_empty());
+
+        match interned.deref() {
+            FormatElement::Comment(_) => {
+                self.inner.write_element(FormatElement::Interned(interned))
+            }
+            FormatElement::List(list) => {
+                let mut content_start = 0;
+
+                for element in list.iter() {
+                    match element {
+                        element @ FormatElement::Comment(_) => {
+                            content_start += 1;
+                            // Cloning comments should be alright as they are rarely nested
+                            // and the case where all elements of an interned data structure are comments
+                            // are rare
+                            self.inner.write_element(element.clone())?;
+                        }
+                        FormatElement::Interned(interned) => {
+                            self.write_interned(interned.clone())?;
+                            content_start += 1;
+
+                            if !self.content.is_empty() {
+                                // Interned struct contained non-comment
+                                break;
+                            }
+                        }
+                        _ => {
+                            // Found the first non-comment / nested interned element
+                            break;
+                        }
+                    }
+                }
+
+                // No leading comments, this group has no comments
+                if content_start == 0 {
+                    self.content.push(FormatElement::Interned(interned));
+                    return Ok(());
+                }
+
+                let content = &list[content_start..];
+
+                // It is necessary to mutate the interned elements, write cloned elements
+                self.write_elements(content.iter().cloned())
+            }
+            FormatElement::Interned(interned) => self.write_interned(interned.clone()),
+            _ => {
+                self.content.push(FormatElement::Interned(interned));
+                Ok(())
+            }
+        }
+    }
+}
+
+impl<Context> Buffer for GroupElementsBuffer<'_, Context> {
+    type Context = Context;
+
+    fn write_element(&mut self, element: FormatElement) -> FormatResult<()> {
+        if self.content.is_empty() {
+            match element {
+                FormatElement::List(list) => {
+                    self.write_elements(list.into_vec())?;
+                }
+                FormatElement::Interned(interned) => match Interned::try_unwrap(interned) {
+                    Ok(owned) => self.write_element(owned)?,
+                    Err(interned) => self.write_interned(interned)?,
+                },
+                comment @ FormatElement::Comment { .. } => {
+                    self.inner.write_element(comment)?;
+                }
+                element => self.content.push(element),
+            }
+        } else {
+            match element {
+                FormatElement::List(list) => {
+                    self.content.extend(list.into_vec());
+                }
+                element => self.content.push(element),
+            }
+        }
+
+        Ok(())
+    }
+
+    fn state(&self) -> &FormatState<Self::Context> {
+        self.inner.state()
+    }
+
+    fn state_mut(&mut self) -> &mut FormatState<Self::Context> {
+        self.inner.state_mut()
+    }
+
+    fn snapshot(&self) -> BufferSnapshot {
+        BufferSnapshot::Any(Box::new(GroupElementsBufferSnapshot {
+            inner: self.inner.snapshot(),
+            content_len: self.content.len(),
+        }))
+    }
+
+    fn restore_snapshot(&mut self, snapshot: BufferSnapshot) {
+        let snapshot = snapshot.unwrap_any::<GroupElementsBufferSnapshot>();
+        self.inner.restore_snapshot(snapshot.inner);
+        self.content.truncate(snapshot.content_len);
+    }
+}
+
+struct GroupElementsBufferSnapshot {
+    inner: BufferSnapshot,
+    content_len: usize,
+}
+
 /// IR element that forces the parent group to print in expanded mode.
 ///
diff --git a/crates/rome_formatter/src/format_element.rs b/crates/rome_formatter/src/format_element.rs
index 6d9013e632..72555b6675 100644
--- a/crates/rome_formatter/src/format_element.rs
+++ b/crates/rome_formatter/src/format_element.rs
@@ -56,8 +56,8 @@ pub enum FormatElement {
 
     /// Special semantic element letting the printer and formatter know this is
-    /// a trivia content, and it should only have a limited influence on the
+    /// a comment content, and it should only have a limited influence on the
     /// formatting (for instance line breaks contained within will not cause
-    /// the parent group to break if this element is at the start of it)
-    Comment(Content),
+    /// the parent group to break if this element is at the start of it).
+    Comment(Box<[FormatElement]>),
 
     /// A token that tracks tokens/nodes that are printed using [`format_verbatim`](crate::Formatter::format_verbatim) API
@@ -68,7 +68,7 @@ pub enum FormatElement {
     BestFitting(BestFitting),
 
-    /// Reference counted format element content. Useful when the same content must be emitted twice
-    /// because it avoids deep cloning of the inner content and instead only requires bumping a ref counter.
-    Rc(Rc<FormatElement>),
+    /// An interned format element. Useful when the same content must be emitted multiple times to avoid
+    /// deep cloning the IR when using the `best_fitting!` macro or `if_group_fits_on_line` and `if_group_breaks`.
+    Interned(Interned),
 }
 
@@ -150,5 +150,5 @@ impl Debug for FormatElement {
             }
             FormatElement::ExpandParent => write!(fmt, ""ExpandParent""),
-            FormatElement::Rc(inner) => inner.fmt(fmt),
+            FormatElement::Interned(inner) => inner.fmt(fmt),
         }
     }
@@ -223,5 +223,5 @@ impl Fill {
 #[derive(Clone, PartialEq, Eq)]
 pub struct Group {
-    pub(crate) content: Content,
+    pub(crate) content: Box<[FormatElement]>,
     pub(crate) id: Option<GroupId>,
 }
@@ -241,7 +241,7 @@ impl Debug for Group {
 
 impl Group {
-    pub fn new(content: FormatElement) -> Self {
+    pub fn new(content: Vec<FormatElement>) -> Self {
         Self {
-            content: Box::new(content),
+            content: content.into_boxed_slice(),
             id: None,
         }
@@ -330,4 +330,27 @@ impl Debug for BestFitting {
 }
 
+#[derive(Clone, Eq, PartialEq)]
+pub struct Interned(Rc<FormatElement>);
+
+impl Interned {
+    pub(crate) fn try_unwrap(this: Interned) -> Result<FormatElement, Interned> {
+        Rc::try_unwrap(this.0).map_err(Interned)
+    }
+}
+
+impl Debug for Interned {
+    fn fmt(&self, f: &mut Formatter<'_>) -> fmt::Result {
+        self.0.fmt(f)
+    }
+}
+
+impl Deref for Interned {
+    type Target = FormatElement;
+
+    fn deref(&self) -> &Self::Target {
+        self.0.deref()
+    }
+}
+
 #[derive(Debug, Clone, Eq, PartialEq)]
 pub struct ConditionalGroupContent {
@@ -471,5 +494,4 @@ impl FormatElement {
         match self {
             FormatElement::List(list) => list.is_empty(),
-            FormatElement::Rc(inner) => inner.is_empty(),
             _ => false,
         }
@@ -488,5 +510,7 @@ impl FormatElement {
             FormatElement::Line(line_mode) => matches!(line_mode, LineMode::Hard | LineMode::Empty),
             FormatElement::Indent(content) => content.will_break(),
-            FormatElement::Group(group) => group.content.will_break(),
+            FormatElement::Group(Group { content, .. }) | FormatElement::Comment(content) => {
+                content.iter().any(FormatElement::will_break)
+            }
             FormatElement::ConditionalGroupContent(group) => group.content.will_break(),
             FormatElement::List(list) => list.content.iter().any(FormatElement::will_break),
@@ -494,65 +518,9 @@ impl FormatElement {
             FormatElement::Token(token) => token.contains('\n'),
             FormatElement::LineSuffix(_) => false,
-            FormatElement::Comment(content) => content.will_break(),
             FormatElement::Verbatim(verbatim) => verbatim.element.will_break(),
             FormatElement::BestFitting(_) => false,
             FormatElement::LineSuffixBoundary => false,
             FormatElement::ExpandParent => true,
-            FormatElement::Rc(inner) => inner.will_break(),
-        }
-    }
-
-    /// Splits off the leading and trailing trivias (comments) from this [FormatElement]
-    ///
-    /// For [FormatElement::HardGroup], the trailing trivia
-    /// is automatically moved  outside of the group. The group itself is then recreated around the
-    /// content itself.
-    pub fn split_trivia(self) -> (FormatElement, FormatElement, FormatElement) {
-        match self {
-            FormatElement::List(mut list) => {
-                // Find the index of the first non-comment element in the list
-                let content_start = list
-                    .content
-                    .iter()
-                    .position(|elem| !matches!(elem, FormatElement::Comment(_)));
-
-                // List contains at least one non trivia element.
-                if let Some(content_start) = content_start {
-                    let (leading, mut content) = if content_start > 0 {
-                        let content = list.content.split_off(content_start);
-                        (FormatElement::List(list), content)
-                    } else {
-                        // No leading trivia
-                        (FormatElement::List(List::default()), list.content)
-                    };
-
-                    let content_end = content
-                        .iter()
-                        .rposition(|elem| !matches!(elem, FormatElement::Comment(_)))
-                        .expect(""List guaranteed to contain at least one non trivia element."");
-                    let trailing_start = content_end + 1;
-
-                    let trailing = if trailing_start < content.len() {
-                        FormatElement::List(List::new(content.split_off(trailing_start)))
-                    } else {
-                        FormatElement::List(List::default())
-                    };
-
-                    (leading, FormatElement::List(List::new(content)), trailing)
-                } else {
-                    // All leading trivia
-                    (
-                        FormatElement::List(list),
-                        FormatElement::List(List::default()),
-                        FormatElement::List(List::default()),
-                    )
-                }
-            }
-            // Non-list elements are returned directly
-            _ => (
-                FormatElement::List(List::default()),
-                self,
-                FormatElement::List(List::default()),
-            ),
+            FormatElement::Interned(inner) => inner.0.will_break(),
         }
     }
@@ -574,9 +542,24 @@ impl FormatElement {
 
             FormatElement::Indent(indent) => indent.last_element(),
-            FormatElement::Group(group) => group.content.last_element(),
+            FormatElement::Group(group) => group
+                .content
+                .iter()
+                .rev()
+                .find_map(FormatElement::last_element),
 
             _ => Some(self),
         }
     }
+
+    /// Interns a format element.
+    ///
+    /// Returns `self` for an empty list AND an already interned elements.
+    pub fn intern(self) -> FormatElement {
+        match self {
+            FormatElement::List(list) if list.is_empty() => list.into(),
+            element @ FormatElement::Interned(_) => element,
+            element => FormatElement::Interned(Interned(Rc::new(element))),
+        }
+    }
 }
 
diff --git a/crates/rome_formatter/src/format_extensions.rs b/crates/rome_formatter/src/format_extensions.rs
index b61fb58569..92f0f40cef 100644
--- a/crates/rome_formatter/src/format_extensions.rs
+++ b/crates/rome_formatter/src/format_extensions.rs
@@ -2,5 +2,4 @@ use crate::prelude::*;
 use std::cell::RefCell;
 use std::marker::PhantomData;
-use std::rc::Rc;
 
 use crate::{write, Buffer, VecBuffer};
@@ -146,5 +145,5 @@ impl<T, Context> MemoizeFormat<Context> for T where T: Format<Context> {}
 pub struct Memoized<F, Context> {
     inner: F,
-    memory: RefCell<Option<FormatResult<Rc<FormatElement>>>>,
+    memory: RefCell<Option<FormatResult<FormatElement>>>,
     options: PhantomData<Context>,
 }
@@ -172,5 +171,5 @@ where
             return match memory {
                 Ok(elements) => {
-                    f.write_element(FormatElement::Rc(elements.clone()))?;
+                    f.write_element(elements.clone())?;
 
                     Ok(())
@@ -186,7 +185,9 @@ where
             Ok(_) => {
                 let elements = buffer.into_element();
-                let reference = Rc::new(elements);
-                f.write_element(FormatElement::Rc(reference.clone()))?;
-                *self.memory.borrow_mut() = Some(Ok(reference));
+                let interned = elements.intern();
+
+                f.write_element(interned.clone())?;
+
+                *self.memory.borrow_mut() = Some(Ok(interned));
 
                 Ok(())
diff --git a/crates/rome_formatter/src/printer/mod.rs b/crates/rome_formatter/src/printer/mod.rs
index 32f04d0e88..bd96e827a4 100644
--- a/crates/rome_formatter/src/printer/mod.rs
+++ b/crates/rome_formatter/src/printer/mod.rs
@@ -130,5 +130,9 @@ impl<'a> Printer<'a> {
                         // A parent group has already verified that this group fits on a single line
                         // Thus, just continue in flat mode
-                        queue.enqueue(PrintElementCall::new(content.as_ref(), args));
+                        queue.extend(
+                            content
+                                .iter()
+                                .map(|element| PrintElementCall::new(element, args)),
+                        );
                         PrintMode::Flat
                     }
@@ -140,13 +144,14 @@ impl<'a> Printer<'a> {
 
                         let flat_args = args.with_print_mode(PrintMode::Flat);
-                        if fits_on_line(&[content], flat_args, queue, self) {
-                            queue.enqueue(PrintElementCall::new(content, flat_args));
+                        if fits_on_line(content.iter(), flat_args, queue, self) {
+                            queue.extend(
+                                content.iter().map(|e| PrintElementCall::new(e, flat_args)),
+                            );
                             self.state.measured_group_fits = true;
                             PrintMode::Flat
                         } else {
-                            queue.enqueue(PrintElementCall::new(
-                                content,
-                                args.with_print_mode(PrintMode::Expanded),
-                            ));
+                            queue.extend(content.iter().map(|e| {
+                                PrintElementCall::new(e, args.with_print_mode(PrintMode::Expanded))
+                            }));
                             PrintMode::Expanded
                         }
@@ -234,5 +239,5 @@ impl<'a> Printer<'a> {
 
             FormatElement::Comment(content) => {
-                queue.enqueue(PrintElementCall::new(content.as_ref(), args));
+                queue.extend(content.iter().map(|e| PrintElementCall::new(e, args)))
             }
 
@@ -280,5 +285,5 @@ impl<'a> Printer<'a> {
                                 };
 
-                                if fits_on_line(&[variant], args.with_print_mode(mode), queue, self)
+                                if fits_on_line([variant], args.with_print_mode(mode), queue, self)
                                 {
                                     self.state.measured_group_fits = true;
@@ -294,5 +299,5 @@ impl<'a> Printer<'a> {
                 }
             }
-            FormatElement::Rc(content) => queue.enqueue(PrintElementCall::new(content, args)),
+            FormatElement::Interned(content) => queue.enqueue(PrintElementCall::new(content, args)),
         }
     }
@@ -363,5 +368,5 @@ impl<'a> Printer<'a> {
 
         let mut current_fits = fits_on_line(
-            &[current_content],
+            [current_content],
             args.with_print_mode(PrintMode::Flat),
             &empty_rest,
@@ -385,5 +390,5 @@ impl<'a> Printer<'a> {
             let current_and_next_fit = current_fits
                 && fits_on_line(
-                    &[separator, next_item],
+                    [separator, next_item],
                     args.with_print_mode(PrintMode::Flat),
                     &empty_rest,
@@ -407,5 +412,5 @@ impl<'a> Printer<'a> {
 
                 let next_fits = fits_on_line(
-                    &[next_item],
+                    [next_item],
                     args.with_print_mode(PrintMode::Flat),
                     &empty_rest,
@@ -627,10 +632,14 @@ impl<'a> ElementCallQueue<'a> {
 /// or the end of the document on a single line without exceeding the line width.
 #[must_use = ""Only determines if content fits on a single line but doesn't print it""]
-fn fits_on_line<'a>(
-    elements: &[&'a FormatElement],
+fn fits_on_line<'a, I>(
+    elements: I,
     args: PrintElementArgs,
     queue: &ElementCallQueue<'a>,
     printer: &mut Printer<'a>,
-) -> bool {
+) -> bool
+where
+    I: IntoIterator<Item = &'a FormatElement>,
+    I::IntoIter: DoubleEndedIterator,
+{
     let shared_buffer = std::mem::take(&mut printer.state.measure_queue);
     debug_assert!(shared_buffer.is_empty());
@@ -642,5 +651,5 @@ fn fits_on_line<'a>(
     measure_queue.extend(
         elements
-            .iter()
+            .into_iter()
             .map(|element| PrintElementCall::new(element, args)),
     );
@@ -727,5 +736,7 @@ fn fits_element_on_line<'a, 'rest>(
         )),
 
-        FormatElement::Group(group) => queue.enqueue(PrintElementCall::new(&group.content, args)),
+        FormatElement::Group(group) => {
+            queue.extend(group.content.iter().map(|e| PrintElementCall::new(e, args)))
+        }
 
         FormatElement::ConditionalGroupContent(conditional) => {
@@ -746,4 +757,5 @@ fn fits_element_on_line<'a, 'rest>(
         FormatElement::Token(token) => {
             state.line_width += state.pending_indent as usize * options.indent_string.len();
+            state.pending_indent = 0;
 
             if state.pending_space {
@@ -770,5 +782,4 @@ fn fits_element_on_line<'a, 'rest>(
 
             state.pending_space = false;
-            state.pending_indent = 0;
         }
 
@@ -783,5 +794,7 @@ fn fits_element_on_line<'a, 'rest>(
         }
 
-        FormatElement::Comment(content) => queue.enqueue(PrintElementCall::new(content, args)),
+        FormatElement::Comment(content) => {
+            queue.extend(content.iter().map(|e| PrintElementCall::new(e, args)))
+        }
 
         FormatElement::Verbatim(verbatim) => {
@@ -801,5 +814,5 @@ fn fits_element_on_line<'a, 'rest>(
             }
         }
-        FormatElement::Rc(content) => queue.enqueue(PrintElementCall::new(content, args)),
+        FormatElement::Interned(content) => queue.enqueue(PrintElementCall::new(content, args)),
     }
 
@@ -1165,5 +1178,5 @@ two lines`,
                 token(""// trailing""),
                 space_token()
-            ]))
+            ]),)
         ]);
 
diff --git a/crates/rome_formatter/src/token.rs b/crates/rome_formatter/src/token.rs
index 32e6af0b13..09e83a3aea 100644
--- a/crates/rome_formatter/src/token.rs
+++ b/crates/rome_formatter/src/token.rs
@@ -902,5 +902,5 @@ where
                         _ => space_token().fmt(f)?,
                     }
-                    comment.piece().fmt(f)?;
+                    comment.piece().fmt(f)
                 } else {
                     write![
@@ -910,8 +910,6 @@ where
                             expand_parent()
                         ]
-                    ]?;
+                    ]
                 }
-
-                Ok(())
             });
 
","refactor(rome_formatter): `GroupElementsBuffer` (#2724)


"
1096,Rust,b12c65678aacc577b070c70307ef6fce528e4d85,https://github.com/helix-editor/helix/commit/b12c65678aacc577b070c70307ef6fce528e4d85,P,helix-editor,helix,"[1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/helix-term/src/health.rs b/helix-term/src/health.rs
index e8fbb84d..6558fe19 100644
--- a/helix-term/src/health.rs
+++ b/helix-term/src/health.rs
@@ -282,7 +282,7 @@ fn probe_protocol(protocol_name: &str, server_cmd: Option<String>) -> std::io::R
 
     if let Some(cmd) = server_cmd {
-        let path = match which::which(cmd) {
+        let path = match which::which(&cmd) {
             Ok(path) => path.display().to_string().green(),
-            Err(_) => ""Not found in $PATH"".to_string().red(),
+            Err(_) => format!(""'{}' not found in $PATH"", cmd).red(),
         };
         writeln!(stdout, ""Binary for {}: {}"", protocol_name, path)?;
","Print the binary required by the debug adapter (#5195)

This commit addresses issue 5193, where the author
requested that the name of the binary needed is printed along
with the rest of the health information.

This commit adds a format! macro which formats in the name of the
binary and then it will be printed along with the rest of the
debug information. The value in cmd is referenced to the call
to which, and then consumed upon the call to format!
"
1097,Rust,d20c1632a7331876215db59410361f0605f2f3ed,https://github.com/helix-editor/helix/commit/d20c1632a7331876215db59410361f0605f2f3ed,P,helix-editor,helix,"[1, 0, 3, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/helix-term/src/keymap.rs b/helix-term/src/keymap.rs
index dc578e66..79d6b46a 100644
--- a/helix-term/src/keymap.rs
+++ b/helix-term/src/keymap.rs
@@ -112,8 +112,4 @@ pub fn infobox(&self) -> Info {
         Info::from_keymap(self.name(), body)
     }
-    /// Get a reference to the key trie node's order.
-    pub fn order(&self) -> &[KeyEvent] {
-        self.order.as_slice()
-    }
 }
 
@@ -535,5 +531,5 @@ fn order_should_be_set() {
         // Make sure an order was set during merge
         let node = keymap.search(&[crate::key!(' ')]).unwrap();
-        assert!(!node.node().unwrap().order().is_empty())
+        assert!(!node.node().unwrap().order.as_slice().is_empty())
     }
 
","`helix_term::keymap`: Remove one-liner solely used for a test.

"
1137,TypeScript,e1a436091d16992e8e0855cc4544d8bfb2f25c01,https://github.com/microsoft/vscode/commit/e1a436091d16992e8e0855cc4544d8bfb2f25c01,P,microsoft,vscode,"[7, 0, 0, 23, 0, 0, 2, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/src/vs/base/node/encoding.ts b/src/vs/base/node/encoding.ts
index d6995d62040..f6b9ae6d7c5 100644
--- a/src/vs/base/node/encoding.ts
+++ b/src/vs/base/node/encoding.ts
@@ -98,14 +98,14 @@ export function detectEncodingByBOM(file: string): TPromise<string> {
 const IGNORE_ENCODINGS = ['ascii', 'utf-8', 'utf-16', 'utf-32'];
 /**
- * Detects the encoding from buffer.
+ * Guesses the encoding from buffer.
  */
-export function detectEncodingByBuffer(buffer: NodeBuffer): string {
-	let detected = jschardet.detect(buffer);
-	if (!detected || !detected.encoding) {
+export function guessEncodingByBuffer(buffer: NodeBuffer): string {
+	let guessed = jschardet.detect(buffer);
+	if (!guessed || !guessed.encoding) {
 		return null;
 	}
-	let enc = detected.encoding.toLowerCase();
+	let enc = guessed.encoding.toLowerCase();
 
-	// Ignore encodings that cannot detect correctly
+	// Ignore encodings that cannot guess correctly
 	// (http://chardet.readthedocs.io/en/latest/supported-encodings.html)
 	if (0 <= IGNORE_ENCODINGS.indexOf(enc)) {
@@ -113,5 +113,5 @@ export function detectEncodingByBuffer(buffer: NodeBuffer): string {
 	}
 
-	return detected.encoding;
+	return guessed.encoding;
 }
 /**
diff --git a/src/vs/base/node/mime.ts b/src/vs/base/node/mime.ts
index 714f1bf700d..e562fb0f1a5 100644
--- a/src/vs/base/node/mime.ts
+++ b/src/vs/base/node/mime.ts
@@ -59,17 +59,17 @@ export interface IMimeAndEncoding {
 }
 
-function doDetectMimesFromStream(instream: streams.Readable, autoDetectEncoding: boolean): TPromise<IMimeAndEncoding> {
+function doDetectMimesFromStream(instream: streams.Readable, autoGuessEncoding: boolean): TPromise<IMimeAndEncoding> {
 	return stream.readExactlyByStream(instream, BUFFER_READ_MAX_LEN).then((readResult: stream.ReadResult) => {
-		return detectMimeAndEncodingFromBuffer(readResult, autoDetectEncoding);
+		return detectMimeAndEncodingFromBuffer(readResult, autoGuessEncoding);
 	});
 }
 
-function doDetectMimesFromFile(absolutePath: string, autoDetectEncoding: boolean): TPromise<IMimeAndEncoding> {
+function doDetectMimesFromFile(absolutePath: string, autoGuessEncoding: boolean): TPromise<IMimeAndEncoding> {
 	return stream.readExactlyByFile(absolutePath, BUFFER_READ_MAX_LEN).then((readResult: stream.ReadResult) => {
-		return detectMimeAndEncodingFromBuffer(readResult, autoDetectEncoding);
+		return detectMimeAndEncodingFromBuffer(readResult, autoGuessEncoding);
 	});
 }
 
-export function detectMimeAndEncodingFromBuffer({buffer, bytesRead}: stream.ReadResult, autoDetectEncoding: boolean): IMimeAndEncoding {
+export function detectMimeAndEncodingFromBuffer({ buffer, bytesRead }: stream.ReadResult, autoGuessEncoding: boolean): IMimeAndEncoding {
 	let enc = encoding.detectEncodingByBOMFromBuffer(buffer, bytesRead);
 
@@ -84,6 +84,6 @@ export function detectMimeAndEncodingFromBuffer({buffer, bytesRead}: stream.Read
 		}
 	}
-	if (autoDetectEncoding && isText && !enc) {
-		enc = encoding.detectEncodingByBuffer(buffer);
+	if (autoGuessEncoding && isText && !enc) {
+		enc = encoding.guessEncodingByBuffer(buffer);
 	}
 
@@ -124,6 +124,6 @@ function filterAndSortMimes(detectedMimes: string[], guessedMimes: string[]): st
  * @param nameHint an additional hint that can be used to detect a mime from a file extension.
  */
-export function detectMimesFromStream(instream: streams.Readable, nameHint: string, autoDetectEncoding: boolean): TPromise<IMimeAndEncoding> {
-	return doDetectMimesFromStream(instream, autoDetectEncoding).then(encoding =>
+export function detectMimesFromStream(instream: streams.Readable, nameHint: string, autoGuessEncoding: boolean): TPromise<IMimeAndEncoding> {
+	return doDetectMimesFromStream(instream, autoGuessEncoding).then(encoding =>
 		handleMimeResult(nameHint, encoding)
 	);
@@ -134,6 +134,6 @@ export function detectMimesFromStream(instream: streams.Readable, nameHint: stri
  * @param absolutePath the absolute path of the file.
  */
-export function detectMimesFromFile(absolutePath: string, autoDetectEncoding: boolean): TPromise<IMimeAndEncoding> {
-	return doDetectMimesFromFile(absolutePath, autoDetectEncoding).then(encoding =>
+export function detectMimesFromFile(absolutePath: string, autoGuessEncoding: boolean): TPromise<IMimeAndEncoding> {
+	return doDetectMimesFromFile(absolutePath, autoGuessEncoding).then(encoding =>
 		handleMimeResult(absolutePath, encoding)
 	);
diff --git a/src/vs/base/test/node/mime/mime.test.ts b/src/vs/base/test/node/mime/mime.test.ts
index 4cea75481f9..e788296eb4c 100644
--- a/src/vs/base/test/node/mime/mime.test.ts
+++ b/src/vs/base/test/node/mime/mime.test.ts
@@ -62,5 +62,5 @@ suite('Mime', () => {
 	});
 
-	test('autoDetectEncoding (ShiftJIS)', function (done: () => void) {
+	test('autoGuessEncoding (ShiftJIS)', function (done: () => void) {
 		const file = require.toUrl('./fixtures/some.shiftjis.txt');
 		mime.detectMimesFromFile(file, true).then(mimes => {
diff --git a/src/vs/platform/files/common/files.ts b/src/vs/platform/files/common/files.ts
index bb4ef763d5e..b681492ab91 100644
--- a/src/vs/platform/files/common/files.ts
+++ b/src/vs/platform/files/common/files.ts
@@ -576,5 +576,5 @@ export interface IFilesConfiguration {
 		watcherExclude: { [filepattern: string]: boolean };
 		encoding: string;
-		autoDetectEncoding: boolean;
+		autoGuessEncoding: boolean;
 		trimTrailingWhitespace: boolean;
 		autoSave: string;
diff --git a/src/vs/platform/telemetry/common/telemetryUtils.ts b/src/vs/platform/telemetry/common/telemetryUtils.ts
index c4e6e296fe5..e0548ff4c55 100644
--- a/src/vs/platform/telemetry/common/telemetryUtils.ts
+++ b/src/vs/platform/telemetry/common/telemetryUtils.ts
@@ -241,5 +241,5 @@ const configurationValueWhitelist = [
 	'workbench.editor.showTabs',
 	'files.encoding',
-	'files.autoDetectEncoding',
+	'files.autoGuessEncoding',
 	'editor.quickSuggestionsDelay',
 	'editor.snippetSuggestions',
diff --git a/src/vs/workbench/parts/files/browser/files.contribution.ts b/src/vs/workbench/parts/files/browser/files.contribution.ts
index 9d1d0adf0d5..fea25156614 100644
--- a/src/vs/workbench/parts/files/browser/files.contribution.ts
+++ b/src/vs/workbench/parts/files/browser/files.contribution.ts
@@ -213,8 +213,8 @@ configurationRegistry.registerConfiguration({
 			'description': nls.localize('encoding', ""The default character set encoding to use when reading and writing files.""),
 		},
-		'files.autoDetectEncoding': {
+		'files.autoGuessEncoding': {
 			'type': 'boolean',
 			'default': false,
-			'description': nls.localize('autoDetetEncoding', ""whem enabled, will use detected encoding in opening a text file."")
+			'description': nls.localize('autoGuessEncoding', ""When enabled, will attempt to guess the character set encoding when opening files"")
 		},
 		'files.eol': {
diff --git a/src/vs/workbench/services/files/electron-browser/fileService.ts b/src/vs/workbench/services/files/electron-browser/fileService.ts
index eef6299d457..0e03ecb888c 100644
--- a/src/vs/workbench/services/files/electron-browser/fileService.ts
+++ b/src/vs/workbench/services/files/electron-browser/fileService.ts
@@ -82,5 +82,5 @@ export class FileService implements IFileService {
 			errorLogger: (msg: string) => this.onFileServiceError(msg),
 			encoding: configuration.files && configuration.files.encoding,
-			autoDetectEncoding: configuration.files && configuration.files.autoDetectEncoding,
+			autoGuessEncoding: configuration.files && configuration.files.autoGuessEncoding,
 			encodingOverride,
 			watcherIgnoredPatterns,
diff --git a/src/vs/workbench/services/files/node/fileService.ts b/src/vs/workbench/services/files/node/fileService.ts
index a660f60daeb..9718f499d0c 100644
--- a/src/vs/workbench/services/files/node/fileService.ts
+++ b/src/vs/workbench/services/files/node/fileService.ts
@@ -45,5 +45,5 @@ export interface IFileServiceOptions {
 	errorLogger?: (msg: string) => void;
 	encoding?: string;
-	autoDetectEncoding?: boolean;
+	autoGuessEncoding?: boolean;
 	bom?: string;
 	encodingOverride?: IEncodingOverride[];
@@ -207,5 +207,5 @@ export class FileService implements IFileService {
 
 			// 2.) detect mimes
-			return mime.detectMimesFromFile(absolutePath, this.options.autoDetectEncoding).then((detected: mime.IMimeAndEncoding) => {
+			return mime.detectMimesFromFile(absolutePath, this.options.autoGuessEncoding).then((detected: mime.IMimeAndEncoding) => {
 				const isText = detected.mimes.indexOf(baseMime.MIME_BINARY) === -1;
 
","Rename autoDetectEncoding to autoGuessEncoding

"
1144,TypeScript,061f4967f9d10172d61a149bbdfa9322f3a7ea01,https://github.com/microsoft/vscode/commit/061f4967f9d10172d61a149bbdfa9322f3a7ea01,C,microsoft,vscode,"[7, 24, 23, 23, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/extensions/github-authentication/src/extension.ts b/extensions/github-authentication/src/extension.ts
index dee2f40bafa..e8189ff42ac 100644
--- a/extensions/github-authentication/src/extension.ts
+++ b/extensions/github-authentication/src/extension.ts
@@ -19,9 +19,11 @@ export async function activate(context: vscode.ExtensionContext) {
 		id: 'github',
 		displayName: 'GitHub',
+		supportsMultipleAccounts: false,
 		onDidChangeSessions: onDidChangeSessions.event,
 		getSessions: () => Promise.resolve(loginService.sessions),
-		login: async (scopeList: string[]) => {
+		login: async (scopeList: string[] | undefined) => {
 			try {
-				const session = await loginService.login(scopeList.join(' '));
+				const loginScopes = scopeList ? scopeList.sort().join(' ') : 'user:email';
+				const session = await loginService.login(loginScopes);
 				Logger.info('Login success!');
 				onDidChangeSessions.fire({ added: [session.id], removed: [], changed: [] });
diff --git a/extensions/vscode-account/src/extension.ts b/extensions/vscode-account/src/extension.ts
index 83f4135b753..5c7ce631ee2 100644
--- a/extensions/vscode-account/src/extension.ts
+++ b/extensions/vscode-account/src/extension.ts
@@ -21,15 +21,13 @@ export async function activate(context: vscode.ExtensionContext) {
 		id: 'microsoft',
 		displayName: 'Microsoft',
+		supportsMultipleAccounts: true,
 		onDidChangeSessions: onDidChangeSessions.event,
 		getSessions: () => Promise.resolve(loginService.sessions),
-		login: async (scopes: string[]) => {
-			try {
-				await loginService.login(scopes.sort().join(' '));
-				const session = loginService.sessions[loginService.sessions.length - 1];
-				onDidChangeSessions.fire({ added: [session.id], removed: [], changed: [] });
-				return loginService.sessions[0]!;
-			} catch (e) {
-				throw e;
-			}
+		login: async (scopes: string[] | undefined) => {
+			const loginScopes = scopes ? scopes.sort().join(' ') : 'https://management.core.windows.net/.default offline_access';
+			await loginService.login(loginScopes);
+			const session = loginService.sessions[loginService.sessions.length - 1];
+			onDidChangeSessions.fire({ added: [session.id], removed: [], changed: [] });
+			return loginService.sessions[0]!;
 		},
 		logout: async (id: string) => {
diff --git a/src/vs/vscode.proposed.d.ts b/src/vs/vscode.proposed.d.ts
index 72b565efc75..12ef0a1c953 100644
--- a/src/vs/vscode.proposed.d.ts
+++ b/src/vs/vscode.proposed.d.ts
@@ -75,4 +75,10 @@ declare module 'vscode' {
 		readonly displayName: string;
 
+		/**
+		 * Whether the authentication provider supports the user being logged into
+		 * multiple different accounts at the same time.
+		 */
+		supportsMultipleAccounts: boolean;
+
 		/**
 		 * An [event](#Event) which fires when the array of sessions has changed, or data
@@ -89,5 +95,5 @@ declare module 'vscode' {
 		 * Prompts a user to login.
 		 */
-		login(scopes: string[]): Thenable<AuthenticationSession>;
+		login(scopes?: string[]): Thenable<AuthenticationSession>;
 		logout(sessionId: string): Thenable<void>;
 	}
diff --git a/src/vs/workbench/api/browser/mainThreadAuthentication.ts b/src/vs/workbench/api/browser/mainThreadAuthentication.ts
index 0d5df383d83..5ba33c07cf6 100644
--- a/src/vs/workbench/api/browser/mainThreadAuthentication.ts
+++ b/src/vs/workbench/api/browser/mainThreadAuthentication.ts
@@ -18,20 +18,4 @@ import { IQuickInputService } from 'vs/platform/quickinput/common/quickInput';
 import { INotificationService } from 'vs/platform/notification/common/notification';
 
-interface AuthDependent {
-	providerId: string;
-	label: string;
-	scopes: string[];
-	scopeDescriptions?: string;
-}
-
-const BUILT_IN_AUTH_DEPENDENTS: AuthDependent[] = [
-	{
-		providerId: 'microsoft',
-		label: 'Settings sync',
-		scopes: ['https://management.core.windows.net/.default', 'offline_access'],
-		scopeDescriptions: 'Read user email'
-	}
-];
-
 interface AllowedExtension {
 	id: string;
@@ -75,4 +59,5 @@ export class MainThreadAuthenticationProvider extends Disposable {
 	private _sessions = new Map<string, string>(); // Map account id to name
 	private _signInMenuItem: IMenuItem | undefined;
+	private _signInMenuDisposables: IDisposable[] = [];
 
 	constructor(
@@ -80,5 +65,5 @@ export class MainThreadAuthenticationProvider extends Disposable {
 		public readonly id: string,
 		public readonly displayName: string,
-		public readonly dependents: AuthDependent[],
+		private readonly supportsMultipleAccounts: boolean,
 		private readonly notificationService: INotificationService
 	) {
@@ -136,27 +121,31 @@ export class MainThreadAuthenticationProvider extends Disposable {
 	}
 
-	private async registerCommandsAndContextMenuItems(): Promise<void> {
-		const sessions = await this._proxy.$getSessions(this.id);
+	private createSignInMenu(hasSessions: boolean): void {
+		this._signInMenuDisposables.push(CommandsRegistry.registerCommand({
+			id: `signIn${this.id}`,
+			handler: (accessor, args) => {
+				this.login();
+			},
+		}));
 
-		if (this.dependents.length) {
-			this._register(CommandsRegistry.registerCommand({
+		this._signInMenuItem = {
+			group: '2_providers',
+			command: {
 				id: `signIn${this.id}`,
-				handler: (accessor, args) => {
-					this.login(this.dependents.reduce((previous: string[], current) => previous.concat(current.scopes), []));
-				},
-			}));
-
-			this._signInMenuItem = {
-				group: '2_providers',
-				command: {
-					id: `signIn${this.id}`,
-					title: sessions.length
-						? nls.localize('addAnotherAccount', ""Sign in to another {0} account"", this.displayName)
-						: nls.localize('addAccount', ""Sign in to {0}"", this.displayName)
-				},
-				order: 3
-			};
+				title: hasSessions
+					? nls.localize('addAnotherAccount', ""Sign in to another {0} account"", this.displayName)
+					: nls.localize('addAccount', ""Sign in to {0}"", this.displayName)
+			},
+			order: 3
+		};
 
-			this._register(MenuRegistry.appendMenuItem(MenuId.AccountsContext, this._signInMenuItem));
+		this._signInMenuDisposables.push(MenuRegistry.appendMenuItem(MenuId.AccountsContext, this._signInMenuItem));
+	}
+
+	private async registerCommandsAndContextMenuItems(): Promise<void> {
+		const sessions = await this._proxy.$getSessions(this.id);
+
+		if (!sessions.length || (sessions.length && this.supportsMultipleAccounts)) {
+			this.createSignInMenu(!!sessions.length);
 		}
 
@@ -262,4 +251,6 @@ export class MainThreadAuthenticationProvider extends Disposable {
 					if (this._signInMenuItem) {
 						this._signInMenuItem.command.title = nls.localize('addAccount', ""Sign in to {0}"", this.displayName);
+					} else {
+						this.createSignInMenu(false);
 					}
 				}
@@ -270,9 +261,14 @@ export class MainThreadAuthenticationProvider extends Disposable {
 
 		if (addedSessions.length && this._signInMenuItem) {
-			this._signInMenuItem.command.title = nls.localize('addAnotherAccount', ""Sign in to another {0} account"", this.displayName);
+			if (this.supportsMultipleAccounts) {
+				this._signInMenuItem.command.title = nls.localize('addAnotherAccount', ""Sign in to another {0} account"", this.displayName);
+			} else {
+				this._signInMenuDisposables.forEach(item => item.dispose());
+				this._signInMenuItem = undefined;
+			}
 		}
 	}
 
-	login(scopes: string[]): Promise<modes.AuthenticationSession> {
+	login(scopes?: string[]): Promise<modes.AuthenticationSession> {
 		return this._proxy.$login(this.id, scopes).then(session => {
 			return {
@@ -293,4 +289,5 @@ export class MainThreadAuthenticationProvider extends Disposable {
 		this._sessionMenuItems.forEach(item => item.forEach(d => d.dispose()));
 		this._sessionMenuItems.clear();
+		this._signInMenuDisposables.forEach(item => item.dispose());
 	}
 }
@@ -311,8 +308,6 @@ export class MainThreadAuthentication extends Disposable implements MainThreadAu
 	}
 
-	async $registerAuthenticationProvider(id: string, displayName: string): Promise<void> {
-		const dependentBuiltIns = BUILT_IN_AUTH_DEPENDENTS.filter(dependency => dependency.providerId === id);
-
-		const provider = new MainThreadAuthenticationProvider(this._proxy, id, displayName, dependentBuiltIns, this.notificationService);
+	async $registerAuthenticationProvider(id: string, displayName: string, supportsMultipleAccounts: boolean): Promise<void> {
+		const provider = new MainThreadAuthenticationProvider(this._proxy, id, displayName, supportsMultipleAccounts, this.notificationService);
 		this.authenticationService.registerAuthenticationProvider(id, provider);
 	}
diff --git a/src/vs/workbench/api/common/extHost.protocol.ts b/src/vs/workbench/api/common/extHost.protocol.ts
index f8b8b781752..279cb6cbc13 100644
--- a/src/vs/workbench/api/common/extHost.protocol.ts
+++ b/src/vs/workbench/api/common/extHost.protocol.ts
@@ -156,5 +156,5 @@ export interface MainThreadCommentsShape extends IDisposable {
 
 export interface MainThreadAuthenticationShape extends IDisposable {
-	$registerAuthenticationProvider(id: string, displayName: string): void;
+	$registerAuthenticationProvider(id: string, displayName: string, supportsMultipleAccounts: boolean): void;
 	$unregisterAuthenticationProvider(id: string): void;
 	$onDidChangeSessions(providerId: string, event: modes.AuthenticationSessionsChangeEvent): void;
@@ -998,5 +998,5 @@ export interface ExtHostAuthenticationShape {
 	$getSessions(id: string): Promise<ReadonlyArray<modes.AuthenticationSession>>;
 	$getSessionAccessToken(id: string, sessionId: string): Promise<string>;
-	$login(id: string, scopes: string[]): Promise<modes.AuthenticationSession>;
+	$login(id: string, scopes: string[] | undefined): Promise<modes.AuthenticationSession>;
 	$logout(id: string, sessionId: string): Promise<void>;
 }
diff --git a/src/vs/workbench/api/common/extHostAuthentication.ts b/src/vs/workbench/api/common/extHostAuthentication.ts
index 65b1b760ecd..f47cd62f39c 100644
--- a/src/vs/workbench/api/common/extHostAuthentication.ts
+++ b/src/vs/workbench/api/common/extHostAuthentication.ts
@@ -115,5 +115,5 @@ export class ExtHostAuthentication implements ExtHostAuthenticationShape {
 		});
 
-		this._proxy.$registerAuthenticationProvider(provider.id, provider.displayName);
+		this._proxy.$registerAuthenticationProvider(provider.id, provider.displayName, provider.supportsMultipleAccounts);
 		this._onDidChangeAuthenticationProviders.fire({ added: [provider.id], removed: [] });
 
@@ -126,5 +126,5 @@ export class ExtHostAuthentication implements ExtHostAuthenticationShape {
 	}
 
-	$login(providerId: string, scopes: string[]): Promise<modes.AuthenticationSession> {
+	$login(providerId: string, scopes: string[] | undefined): Promise<modes.AuthenticationSession> {
 		const authProvider = this._authenticationProviders.get(providerId);
 		if (authProvider) {
diff --git a/src/vs/workbench/services/authentication/browser/authenticationService.ts b/src/vs/workbench/services/authentication/browser/authenticationService.ts
index 81c61d8f718..1409dd9baaa 100644
--- a/src/vs/workbench/services/authentication/browser/authenticationService.ts
+++ b/src/vs/workbench/services/authentication/browser/authenticationService.ts
@@ -61,5 +61,5 @@ export class AuthenticationService extends Disposable implements IAuthentication
 		this._onDidRegisterAuthenticationProvider.fire(id);
 
-		if (authenticationProvider.dependents.length && this._placeholderMenuItem) {
+		if (this._placeholderMenuItem) {
 			this._placeholderMenuItem.dispose();
 			this._placeholderMenuItem = undefined;
","Show sign in entry for all auth providers in accounts menu, fixes #94488

"
1151,TypeScript,4d2cd6f88bc0e1c4fde15e9fe5494136428b4b37,https://github.com/microsoft/TypeScript/commit/4d2cd6f88bc0e1c4fde15e9fe5494136428b4b37,C,microsoft,TypeScript,"[1, 0, 0, 2, 0, 0, 0, 4, 39, 0, 0, 3, 0, 0, 45, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/src/compiler/emitter.ts b/src/compiler/emitter.ts
index a62739e133..98ad7c874d 100644
--- a/src/compiler/emitter.ts
+++ b/src/compiler/emitter.ts
@@ -2584,10 +2584,10 @@ var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, ge
                 }
 
-                let current: Node = node;
+                let current = getRootDeclaration(node).parent;
                 while (current) {
                     if (current.kind === SyntaxKind.SourceFile) {
                         return !isExported || ((getCombinedNodeFlags(node) & NodeFlags.Export) !== 0);
                     }
-                    else if (isFunctionLike(current) || current.kind === SyntaxKind.ModuleBlock) {
+                    else if (isDeclaration(current)) {
                         return false;
                     }
diff --git a/tests/baselines/reference/dottedNamesInSystem.js b/tests/baselines/reference/dottedNamesInSystem.js
new file mode 100644
index 0000000000..4f1814f393
--- /dev/null
+++ b/tests/baselines/reference/dottedNamesInSystem.js
@@ -0,0 +1,35 @@
+//// [dottedNamesInSystem.ts]
+export namespace A.B.C {
+    export function foo() {}
+}
+
+export function bar() {
+    return A.B.C.foo();
+}
+
+//// [dottedNamesInSystem.js]
+System.register([], function(exports_1, context_1) {
+    ""use strict"";
+    var __moduleName = context_1 && context_1.id;
+    var A;
+    function bar() {
+        return A.B.C.foo();
+    }
+    exports_1(""bar"", bar);
+    return {
+        setters:[],
+        execute: function() {
+            (function (A) {
+                var B;
+                (function (B) {
+                    var C;
+                    (function (C) {
+                        function foo() { }
+                        C.foo = foo;
+                    })(C = B.C || (B.C = {}));
+                })(B = A.B || (A.B = {}));
+            })(A = A || (A = {}));
+            exports_1(""A"", A);
+        }
+    }
+});
diff --git a/tests/baselines/reference/dottedNamesInSystem.symbols b/tests/baselines/reference/dottedNamesInSystem.symbols
new file mode 100644
index 0000000000..bfbc57ed1b
--- /dev/null
+++ b/tests/baselines/reference/dottedNamesInSystem.symbols
@@ -0,0 +1,22 @@
+=== tests/cases/compiler/dottedNamesInSystem.ts ===
+export namespace A.B.C {
+>A : Symbol(A, Decl(dottedNamesInSystem.ts, 0, 0))
+>B : Symbol(B, Decl(dottedNamesInSystem.ts, 0, 19))
+>C : Symbol(C, Decl(dottedNamesInSystem.ts, 0, 21))
+
+    export function foo() {}
+>foo : Symbol(foo, Decl(dottedNamesInSystem.ts, 0, 24))
+}
+
+export function bar() {
+>bar : Symbol(bar, Decl(dottedNamesInSystem.ts, 2, 1))
+
+    return A.B.C.foo();
+>A.B.C.foo : Symbol(A.B.C.foo, Decl(dottedNamesInSystem.ts, 0, 24))
+>A.B.C : Symbol(A.B.C, Decl(dottedNamesInSystem.ts, 0, 21))
+>A.B : Symbol(A.B, Decl(dottedNamesInSystem.ts, 0, 19))
+>A : Symbol(A, Decl(dottedNamesInSystem.ts, 0, 0))
+>B : Symbol(A.B, Decl(dottedNamesInSystem.ts, 0, 19))
+>C : Symbol(A.B.C, Decl(dottedNamesInSystem.ts, 0, 21))
+>foo : Symbol(A.B.C.foo, Decl(dottedNamesInSystem.ts, 0, 24))
+}
diff --git a/tests/baselines/reference/dottedNamesInSystem.types b/tests/baselines/reference/dottedNamesInSystem.types
new file mode 100644
index 0000000000..78de0e3388
--- /dev/null
+++ b/tests/baselines/reference/dottedNamesInSystem.types
@@ -0,0 +1,23 @@
+=== tests/cases/compiler/dottedNamesInSystem.ts ===
+export namespace A.B.C {
+>A : typeof A
+>B : typeof B
+>C : typeof C
+
+    export function foo() {}
+>foo : () => void
+}
+
+export function bar() {
+>bar : () => void
+
+    return A.B.C.foo();
+>A.B.C.foo() : void
+>A.B.C.foo : () => void
+>A.B.C : typeof A.B.C
+>A.B : typeof A.B
+>A : typeof A
+>B : typeof A.B
+>C : typeof A.B.C
+>foo : () => void
+}
diff --git a/tests/cases/compiler/dottedNamesInSystem.ts b/tests/cases/compiler/dottedNamesInSystem.ts
new file mode 100644
index 0000000000..43b8eb233b
--- /dev/null
+++ b/tests/cases/compiler/dottedNamesInSystem.ts
@@ -0,0 +1,8 @@
+// @module: system
+export namespace A.B.C {
+    export function foo() {}
+}
+
+export function bar() {
+    return A.B.C.foo();
+}
\ No newline at end of file
","properly dotted namespace names in System modules

"
1197,TypeScript,347101883f159acd2ee4fbfad017998f02985195,https://github.com/puppeteer/puppeteer/commit/347101883f159acd2ee4fbfad017998f02985195,P,puppeteer,puppeteer,"[6, 411, 387, 19, 51, 46, 0, 1, 0, 17, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/src/api-docs-entry.ts b/src/api-docs-entry.ts
index c3a7c02c..dbcf1438 100644
--- a/src/api-docs-entry.ts
+++ b/src/api-docs-entry.ts
@@ -62,5 +62,5 @@ export * from './common/Product.js';
 export * from './common/Puppeteer.js';
 export * from './common/BrowserConnector.js';
-export * from './node/Launcher.js';
+export * from './node/ProductLauncher.js';
 export * from './node/LaunchOptions.js';
 export * from './common/HTTPRequest.js';
diff --git a/src/node/ChromeLauncher.ts b/src/node/ChromeLauncher.ts
new file mode 100644
index 00000000..26b8ef28
--- /dev/null
+++ b/src/node/ChromeLauncher.ts
@@ -0,0 +1,263 @@
+import fs from 'fs';
+import path from 'path';
+import {assert} from '../common/assert.js';
+import {Browser} from '../common/Browser.js';
+import {Product} from '../common/Product.js';
+import {BrowserRunner} from './BrowserRunner.js';
+import {
+  BrowserLaunchArgumentOptions,
+  ChromeReleaseChannel,
+  PuppeteerNodeLaunchOptions,
+} from './LaunchOptions.js';
+import {
+  executablePathForChannel,
+  ProductLauncher,
+  resolveExecutablePath,
+} from './ProductLauncher.js';
+import {tmpdir} from './util.js';
+
+/**
+ * @internal
+ */
+export class ChromeLauncher implements ProductLauncher {
+  /**
+   * @internal
+   */
+  _projectRoot: string | undefined;
+  /**
+   * @internal
+   */
+  _preferredRevision: string;
+  /**
+   * @internal
+   */
+  _isPuppeteerCore: boolean;
+
+  constructor(
+    projectRoot: string | undefined,
+    preferredRevision: string,
+    isPuppeteerCore: boolean
+  ) {
+    this._projectRoot = projectRoot;
+    this._preferredRevision = preferredRevision;
+    this._isPuppeteerCore = isPuppeteerCore;
+  }
+
+  async launch(options: PuppeteerNodeLaunchOptions = {}): Promise<Browser> {
+    const {
+      ignoreDefaultArgs = false,
+      args = [],
+      dumpio = false,
+      channel,
+      executablePath,
+      pipe = false,
+      env = process.env,
+      handleSIGINT = true,
+      handleSIGTERM = true,
+      handleSIGHUP = true,
+      ignoreHTTPSErrors = false,
+      defaultViewport = {width: 800, height: 600},
+      slowMo = 0,
+      timeout = 30000,
+      waitForInitialPage = true,
+      debuggingPort,
+    } = options;
+
+    const chromeArguments = [];
+    if (!ignoreDefaultArgs) {
+      chromeArguments.push(...this.defaultArgs(options));
+    } else if (Array.isArray(ignoreDefaultArgs)) {
+      chromeArguments.push(
+        ...this.defaultArgs(options).filter(arg => {
+          return !ignoreDefaultArgs.includes(arg);
+        })
+      );
+    } else {
+      chromeArguments.push(...args);
+    }
+
+    if (
+      !chromeArguments.some(argument => {
+        return argument.startsWith('--remote-debugging-');
+      })
+    ) {
+      if (pipe) {
+        assert(
+          !debuggingPort,
+          'Browser should be launched with either pipe or debugging port - not both.'
+        );
+        chromeArguments.push('--remote-debugging-pipe');
+      } else {
+        chromeArguments.push(`--remote-debugging-port=${debuggingPort || 0}`);
+      }
+    }
+
+    let isTempUserDataDir = true;
+
+    // Check for the user data dir argument, which will always be set even
+    // with a custom directory specified via the userDataDir option.
+    let userDataDirIndex = chromeArguments.findIndex(arg => {
+      return arg.startsWith('--user-data-dir');
+    });
+    if (userDataDirIndex < 0) {
+      chromeArguments.push(
+        `--user-data-dir=${await fs.promises.mkdtemp(
+          path.join(tmpdir(), 'puppeteer_dev_chrome_profile-')
+        )}`
+      );
+      userDataDirIndex = chromeArguments.length - 1;
+    }
+
+    const userDataDir = chromeArguments[userDataDirIndex]!.split('=', 2)[1];
+    assert(typeof userDataDir === 'string', '`--user-data-dir` is malformed');
+
+    isTempUserDataDir = false;
+
+    let chromeExecutable = executablePath;
+    if (channel) {
+      // executablePath is detected by channel, so it should not be specified by user.
+      assert(
+        !chromeExecutable,
+        '`executablePath` must not be specified when `channel` is given.'
+      );
+
+      chromeExecutable = executablePathForChannel(channel);
+    } else if (!chromeExecutable) {
+      const {missingText, executablePath} = resolveExecutablePath(this);
+      if (missingText) {
+        throw new Error(missingText);
+      }
+      chromeExecutable = executablePath;
+    }
+
+    const usePipe = chromeArguments.includes('--remote-debugging-pipe');
+    const runner = new BrowserRunner(
+      this.product,
+      chromeExecutable,
+      chromeArguments,
+      userDataDir,
+      isTempUserDataDir
+    );
+    runner.start({
+      handleSIGHUP,
+      handleSIGTERM,
+      handleSIGINT,
+      dumpio,
+      env,
+      pipe: usePipe,
+    });
+
+    let browser;
+    try {
+      const connection = await runner.setupConnection({
+        usePipe,
+        timeout,
+        slowMo,
+        preferredRevision: this._preferredRevision,
+      });
+      browser = await Browser._create(
+        connection,
+        [],
+        ignoreHTTPSErrors,
+        defaultViewport,
+        runner.proc,
+        runner.close.bind(runner)
+      );
+    } catch (error) {
+      runner.kill();
+      throw error;
+    }
+
+    if (waitForInitialPage) {
+      try {
+        await browser.waitForTarget(
+          t => {
+            return t.type() === 'page';
+          },
+          {timeout}
+        );
+      } catch (error) {
+        await browser.close();
+        throw error;
+      }
+    }
+
+    return browser;
+  }
+
+  defaultArgs(options: BrowserLaunchArgumentOptions = {}): string[] {
+    const chromeArguments = [
+      '--allow-pre-commit-input',
+      '--disable-background-networking',
+      '--enable-features=NetworkServiceInProcess2',
+      '--disable-background-timer-throttling',
+      '--disable-backgrounding-occluded-windows',
+      '--disable-breakpad',
+      '--disable-client-side-phishing-detection',
+      '--disable-component-extensions-with-background-pages',
+      '--disable-default-apps',
+      '--disable-dev-shm-usage',
+      '--disable-extensions',
+      // TODO: remove AvoidUnnecessaryBeforeUnloadCheckSync below
+      // once crbug.com/1324138 is fixed and released.
+      '--disable-features=Translate,BackForwardCache,AvoidUnnecessaryBeforeUnloadCheckSync',
+      '--disable-hang-monitor',
+      '--disable-ipc-flooding-protection',
+      '--disable-popup-blocking',
+      '--disable-prompt-on-repost',
+      '--disable-renderer-backgrounding',
+      '--disable-sync',
+      '--force-color-profile=srgb',
+      '--metrics-recording-only',
+      '--no-first-run',
+      '--enable-automation',
+      '--password-store=basic',
+      '--use-mock-keychain',
+      // TODO(sadym): remove '--enable-blink-features=IdleDetection'
+      // once IdleDetection is turned on by default.
+      '--enable-blink-features=IdleDetection',
+      '--export-tagged-pdf',
+    ];
+    const {
+      devtools = false,
+      headless = !devtools,
+      args = [],
+      userDataDir,
+    } = options;
+    if (userDataDir) {
+      chromeArguments.push(`--user-data-dir=${path.resolve(userDataDir)}`);
+    }
+    if (devtools) {
+      chromeArguments.push('--auto-open-devtools-for-tabs');
+    }
+    if (headless) {
+      chromeArguments.push(
+        headless === 'chrome' ? '--headless=chrome' : '--headless',
+        '--hide-scrollbars',
+        '--mute-audio'
+      );
+    }
+    if (
+      args.every(arg => {
+        return arg.startsWith('-');
+      })
+    ) {
+      chromeArguments.push('about:blank');
+    }
+    chromeArguments.push(...args);
+    return chromeArguments;
+  }
+
+  executablePath(channel?: ChromeReleaseChannel): string {
+    if (channel) {
+      return executablePathForChannel(channel);
+    } else {
+      const results = resolveExecutablePath(this);
+      return results.executablePath;
+    }
+  }
+
+  get product(): Product {
+    return 'chrome';
+  }
+}
diff --git a/src/node/Launcher.ts b/src/node/FirefoxLauncher.ts
similarity index 51%
rename from src/node/Launcher.ts
rename to src/node/FirefoxLauncher.ts
index 7d152723..6a4316a3 100644
--- a/src/node/Launcher.ts
+++ b/src/node/FirefoxLauncher.ts
@@ -1,304 +1,21 @@
-/**
- * Copyright 2017 Google Inc. All rights reserved.
- *
- * Licensed under the Apache License, Version 2.0 (the ""License"");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an ""AS IS"" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-import * as os from 'os';
-import * as path from 'path';
-import * as fs from 'fs';
-
+import fs from 'fs';
+import os from 'os';
+import path from 'path';
 import {assert} from '../common/assert.js';
-import {BrowserFetcher} from './BrowserFetcher.js';
 import {Browser} from '../common/Browser.js';
+import {Product} from '../common/Product.js';
+import {BrowserFetcher} from './BrowserFetcher.js';
 import {BrowserRunner} from './BrowserRunner.js';
-import {promisify} from 'util';
-
-const copyFileAsync = promisify(fs.copyFile);
-const mkdtempAsync = promisify(fs.mkdtemp);
-const writeFileAsync = promisify(fs.writeFile);
-
 import {
   BrowserLaunchArgumentOptions,
-  ChromeReleaseChannel,
   PuppeteerNodeLaunchOptions,
 } from './LaunchOptions.js';
-
-import {Product} from '../common/Product.js';
-
-const tmpDir = () => {
-  return process.env['PUPPETEER_TMP_DIR'] || os.tmpdir();
-};
-
-/**
- * Describes a launcher - a class that is able to create and launch a browser instance.
- * @public
- */
-export interface ProductLauncher {
-  launch(object: PuppeteerNodeLaunchOptions): Promise<Browser>;
-  executablePath: (path?: any) => string;
-  defaultArgs(object: BrowserLaunchArgumentOptions): string[];
-  product: Product;
-}
+import {ProductLauncher, resolveExecutablePath} from './ProductLauncher.js';
+import {tmpdir} from './util.js';
 
 /**
  * @internal
  */
-class ChromeLauncher implements ProductLauncher {
-  /**
-   * @internal
-   */
-  _projectRoot: string | undefined;
-  /**
-   * @internal
-   */
-  _preferredRevision: string;
-  /**
-   * @internal
-   */
-  _isPuppeteerCore: boolean;
-
-  constructor(
-    projectRoot: string | undefined,
-    preferredRevision: string,
-    isPuppeteerCore: boolean
-  ) {
-    this._projectRoot = projectRoot;
-    this._preferredRevision = preferredRevision;
-    this._isPuppeteerCore = isPuppeteerCore;
-  }
-
-  async launch(options: PuppeteerNodeLaunchOptions = {}): Promise<Browser> {
-    const {
-      ignoreDefaultArgs = false,
-      args = [],
-      dumpio = false,
-      channel,
-      executablePath,
-      pipe = false,
-      env = process.env,
-      handleSIGINT = true,
-      handleSIGTERM = true,
-      handleSIGHUP = true,
-      ignoreHTTPSErrors = false,
-      defaultViewport = {width: 800, height: 600},
-      slowMo = 0,
-      timeout = 30000,
-      waitForInitialPage = true,
-      debuggingPort,
-    } = options;
-
-    const chromeArguments = [];
-    if (!ignoreDefaultArgs) {
-      chromeArguments.push(...this.defaultArgs(options));
-    } else if (Array.isArray(ignoreDefaultArgs)) {
-      chromeArguments.push(
-        ...this.defaultArgs(options).filter(arg => {
-          return !ignoreDefaultArgs.includes(arg);
-        })
-      );
-    } else {
-      chromeArguments.push(...args);
-    }
-
-    if (
-      !chromeArguments.some(argument => {
-        return argument.startsWith('--remote-debugging-');
-      })
-    ) {
-      if (pipe) {
-        assert(
-          !debuggingPort,
-          'Browser should be launched with either pipe or debugging port - not both.'
-        );
-        chromeArguments.push('--remote-debugging-pipe');
-      } else {
-        chromeArguments.push(`--remote-debugging-port=${debuggingPort || 0}`);
-      }
-    }
-
-    let isTempUserDataDir = true;
-
-    // Check for the user data dir argument, which will always be set even
-    // with a custom directory specified via the userDataDir option.
-    let userDataDirIndex = chromeArguments.findIndex(arg => {
-      return arg.startsWith('--user-data-dir');
-    });
-    if (userDataDirIndex < 0) {
-      chromeArguments.push(
-        `--user-data-dir=${await mkdtempAsync(
-          path.join(tmpDir(), 'puppeteer_dev_chrome_profile-')
-        )}`
-      );
-      userDataDirIndex = chromeArguments.length - 1;
-    }
-
-    const userDataDir = chromeArguments[userDataDirIndex]!.split('=', 2)[1];
-    assert(typeof userDataDir === 'string', '`--user-data-dir` is malformed');
-
-    isTempUserDataDir = false;
-
-    let chromeExecutable = executablePath;
-    if (channel) {
-      // executablePath is detected by channel, so it should not be specified by user.
-      assert(
-        !chromeExecutable,
-        '`executablePath` must not be specified when `channel` is given.'
-      );
-
-      chromeExecutable = executablePathForChannel(channel);
-    } else if (!chromeExecutable) {
-      const {missingText, executablePath} = resolveExecutablePath(this);
-      if (missingText) {
-        throw new Error(missingText);
-      }
-      chromeExecutable = executablePath;
-    }
-
-    const usePipe = chromeArguments.includes('--remote-debugging-pipe');
-    const runner = new BrowserRunner(
-      this.product,
-      chromeExecutable,
-      chromeArguments,
-      userDataDir,
-      isTempUserDataDir
-    );
-    runner.start({
-      handleSIGHUP,
-      handleSIGTERM,
-      handleSIGINT,
-      dumpio,
-      env,
-      pipe: usePipe,
-    });
-
-    let browser;
-    try {
-      const connection = await runner.setupConnection({
-        usePipe,
-        timeout,
-        slowMo,
-        preferredRevision: this._preferredRevision,
-      });
-      browser = await Browser._create(
-        connection,
-        [],
-        ignoreHTTPSErrors,
-        defaultViewport,
-        runner.proc,
-        runner.close.bind(runner)
-      );
-    } catch (error) {
-      runner.kill();
-      throw error;
-    }
-
-    if (waitForInitialPage) {
-      try {
-        await browser.waitForTarget(
-          t => {
-            return t.type() === 'page';
-          },
-          {timeout}
-        );
-      } catch (error) {
-        await browser.close();
-        throw error;
-      }
-    }
-
-    return browser;
-  }
-
-  defaultArgs(options: BrowserLaunchArgumentOptions = {}): string[] {
-    const chromeArguments = [
-      '--allow-pre-commit-input', // TODO(crbug.com/1320996): neither headful nor headless should rely on this flag.
-      '--disable-background-networking',
-      '--enable-features=NetworkServiceInProcess2',
-      '--disable-background-timer-throttling',
-      '--disable-backgrounding-occluded-windows',
-      '--disable-breakpad',
-      '--disable-client-side-phishing-detection',
-      '--disable-component-extensions-with-background-pages',
-      '--disable-default-apps',
-      '--disable-dev-shm-usage',
-      '--disable-extensions',
-      // TODO: remove AvoidUnnecessaryBeforeUnloadCheckSync below
-      // once crbug.com/1324138 is fixed and released.
-      '--disable-features=Translate,BackForwardCache,AvoidUnnecessaryBeforeUnloadCheckSync',
-      '--disable-hang-monitor',
-      '--disable-ipc-flooding-protection',
-      '--disable-popup-blocking',
-      '--disable-prompt-on-repost',
-      '--disable-renderer-backgrounding',
-      '--disable-sync',
-      '--force-color-profile=srgb',
-      '--metrics-recording-only',
-      '--no-first-run',
-      '--enable-automation',
-      '--password-store=basic',
-      '--use-mock-keychain',
-      // TODO(sadym): remove '--enable-blink-features=IdleDetection'
-      // once IdleDetection is turned on by default.
-      '--enable-blink-features=IdleDetection',
-      '--export-tagged-pdf',
-    ];
-    const {
-      devtools = false,
-      headless = !devtools,
-      args = [],
-      userDataDir,
-    } = options;
-    if (userDataDir) {
-      chromeArguments.push(`--user-data-dir=${path.resolve(userDataDir)}`);
-    }
-    if (devtools) {
-      chromeArguments.push('--auto-open-devtools-for-tabs');
-    }
-    if (headless) {
-      chromeArguments.push(
-        headless === 'chrome' ? '--headless=chrome' : '--headless',
-        '--hide-scrollbars',
-        '--mute-audio'
-      );
-    }
-    if (
-      args.every(arg => {
-        return arg.startsWith('-');
-      })
-    ) {
-      chromeArguments.push('about:blank');
-    }
-    chromeArguments.push(...args);
-    return chromeArguments;
-  }
-
-  executablePath(channel?: ChromeReleaseChannel): string {
-    if (channel) {
-      return executablePathForChannel(channel);
-    } else {
-      const results = resolveExecutablePath(this);
-      return results.executablePath;
-    }
-  }
-
-  get product(): Product {
-    return 'chrome';
-  }
-}
-
-/**
- * @internal
- */
-class FirefoxLauncher implements ProductLauncher {
+export class FirefoxLauncher implements ProductLauncher {
   /**
    * @internal
@@ -501,8 +218,11 @@ class FirefoxLauncher implements ProductLauncher {
     const firefoxArguments = ['--no-remote'];
 
-    if (os.platform() === 'darwin') {
-      firefoxArguments.push('--foreground');
-    } else if (os.platform().startsWith('win')) {
-      firefoxArguments.push('--wait-for-browser');
+    switch (os.platform()) {
+      case 'darwin':
+        firefoxArguments.push('--foreground');
+        break;
+      case 'win32':
+        firefoxArguments.push('--wait-for-browser');
+        break;
     }
     if (userDataDir) {
@@ -755,5 +475,8 @@ class FirefoxLauncher implements ProductLauncher {
     });
 
-    await writeFileAsync(path.join(profilePath, 'user.js'), lines.join('\n'));
+    await fs.promises.writeFile(
+      path.join(profilePath, 'user.js'),
+      lines.join('\n')
+    );
 
     // Create a backup of the preferences file if it already exitsts.
@@ -761,11 +484,11 @@ class FirefoxLauncher implements ProductLauncher {
     if (fs.existsSync(prefsPath)) {
       const prefsBackupPath = path.join(profilePath, 'prefs.js.puppeteer');
-      await copyFileAsync(prefsPath, prefsBackupPath);
+      await fs.promises.copyFile(prefsPath, prefsBackupPath);
     }
   }
 
   async _createProfile(extraPrefs: {[x: string]: unknown}): Promise<string> {
-    const temporaryProfilePath = await mkdtempAsync(
-      path.join(tmpDir(), 'puppeteer_dev_firefox_profile-')
+    const temporaryProfilePath = await fs.promises.mkdtemp(
+      path.join(tmpdir(), 'puppeteer_dev_firefox_profile-')
     );
 
@@ -776,185 +499,2 @@ class FirefoxLauncher implements ProductLauncher {
   }
 }
-
-function executablePathForChannel(channel: ChromeReleaseChannel): string {
-  const platform = os.platform();
-
-  let chromePath: string | undefined;
-  switch (platform) {
-    case 'win32':
-      switch (channel) {
-        case 'chrome':
-          chromePath = `${process.env['PROGRAMFILES']}\\Google\\Chrome\\Application\\chrome.exe`;
-          break;
-        case 'chrome-beta':
-          chromePath = `${process.env['PROGRAMFILES']}\\Google\\Chrome Beta\\Application\\chrome.exe`;
-          break;
-        case 'chrome-canary':
-          chromePath = `${process.env['PROGRAMFILES']}\\Google\\Chrome SxS\\Application\\chrome.exe`;
-          break;
-        case 'chrome-dev':
-          chromePath = `${process.env['PROGRAMFILES']}\\Google\\Chrome Dev\\Application\\chrome.exe`;
-          break;
-      }
-      break;
-    case 'darwin':
-      switch (channel) {
-        case 'chrome':
-          chromePath =
-            '/Applications/Google Chrome.app/Contents/MacOS/Google Chrome';
-          break;
-        case 'chrome-beta':
-          chromePath =
-            '/Applications/Google Chrome Beta.app/Contents/MacOS/Google Chrome Beta';
-          break;
-        case 'chrome-canary':
-          chromePath =
-            '/Applications/Google Chrome Canary.app/Contents/MacOS/Google Chrome Canary';
-          break;
-        case 'chrome-dev':
-          chromePath =
-            '/Applications/Google Chrome Dev.app/Contents/MacOS/Google Chrome Dev';
-          break;
-      }
-      break;
-    case 'linux':
-      switch (channel) {
-        case 'chrome':
-          chromePath = '/opt/google/chrome/chrome';
-          break;
-        case 'chrome-beta':
-          chromePath = '/opt/google/chrome-beta/chrome';
-          break;
-        case 'chrome-dev':
-          chromePath = '/opt/google/chrome-unstable/chrome';
-          break;
-      }
-      break;
-  }
-
-  if (!chromePath) {
-    throw new Error(
-      `Unable to detect browser executable path for '${channel}' on ${platform}.`
-    );
-  }
-
-  // Check if Chrome exists and is accessible.
-  try {
-    fs.accessSync(chromePath);
-  } catch (error) {
-    throw new Error(
-      `Could not find Google Chrome executable for channel '${channel}' at '${chromePath}'.`
-    );
-  }
-
-  return chromePath;
-}
-
-function resolveExecutablePath(launcher: ChromeLauncher | FirefoxLauncher): {
-  executablePath: string;
-  missingText?: string;
-} {
-  const {product, _isPuppeteerCore, _projectRoot, _preferredRevision} =
-    launcher;
-  let downloadPath: string | undefined;
-  // puppeteer-core doesn't take into account PUPPETEER_* env variables.
-  if (!_isPuppeteerCore) {
-    const executablePath =
-      process.env['PUPPETEER_EXECUTABLE_PATH'] ||
-      process.env['npm_config_puppeteer_executable_path'] ||
-      process.env['npm_package_config_puppeteer_executable_path'];
-    if (executablePath) {
-      const missingText = !fs.existsSync(executablePath)
-        ? 'Tried to use PUPPETEER_EXECUTABLE_PATH env variable to launch browser but did not find any executable at: ' +
-          executablePath
-        : undefined;
-      return {executablePath, missingText};
-    }
-    const ubuntuChromiumPath = '/usr/bin/chromium-browser';
-    if (
-      product === 'chrome' &&
-      os.platform() !== 'darwin' &&
-      os.arch() === 'arm64' &&
-      fs.existsSync(ubuntuChromiumPath)
-    ) {
-      return {executablePath: ubuntuChromiumPath, missingText: undefined};
-    }
-    downloadPath =
-      process.env['PUPPETEER_DOWNLOAD_PATH'] ||
-      process.env['npm_config_puppeteer_download_path'] ||
-      process.env['npm_package_config_puppeteer_download_path'];
-  }
-  if (!_projectRoot) {
-    throw new Error(
-      '_projectRoot is undefined. Unable to create a BrowserFetcher.'
-    );
-  }
-  const browserFetcher = new BrowserFetcher(_projectRoot, {
-    product: product,
-    path: downloadPath,
-  });
-
-  if (!_isPuppeteerCore && product === 'chrome') {
-    const revision = process.env['PUPPETEER_CHROMIUM_REVISION'];
-    if (revision) {
-      const revisionInfo = browserFetcher.revisionInfo(revision);
-      const missingText = !revisionInfo.local
-        ? 'Tried to use PUPPETEER_CHROMIUM_REVISION env variable to launch browser but did not find executable at: ' +
-          revisionInfo.executablePath
-        : undefined;
-      return {executablePath: revisionInfo.executablePath, missingText};
-    }
-  }
-  const revisionInfo = browserFetcher.revisionInfo(_preferredRevision);
-
-  const firefoxHelp = `Run \`PUPPETEER_PRODUCT=firefox npm install\` to download a supported Firefox browser binary.`;
-  const chromeHelp = `Run \`npm install\` to download the correct Chromium revision (${launcher._preferredRevision}).`;
-  const missingText = !revisionInfo.local
-    ? `Could not find expected browser (${product}) locally. ${
-        product === 'chrome' ? chromeHelp : firefoxHelp
-      }`
-    : undefined;
-  return {executablePath: revisionInfo.executablePath, missingText};
-}
-
-/**
- * @internal
- */
-export default function Launcher(
-  projectRoot: string | undefined,
-  preferredRevision: string,
-  isPuppeteerCore: boolean,
-  product?: string
-): ProductLauncher {
-  // puppeteer-core doesn't take into account PUPPETEER_* env variables.
-  if (!product && !isPuppeteerCore) {
-    product =
-      process.env['PUPPETEER_PRODUCT'] ||
-      process.env['npm_config_puppeteer_product'] ||
-      process.env['npm_package_config_puppeteer_product'];
-  }
-  switch (product) {
-    case 'firefox':
-      return new FirefoxLauncher(
-        projectRoot,
-        preferredRevision,
-        isPuppeteerCore
-      );
-    case 'chrome':
-    default:
-      if (typeof product !== 'undefined' && product !== 'chrome') {
-        /* The user gave us an incorrect product name
-         * we'll default to launching Chrome, but log to the console
-         * to let the user know (they've probably typoed).
-         */
-        console.warn(
-          `Warning: unknown product name ${product}. Falling back to chrome.`
-        );
-      }
-      return new ChromeLauncher(
-        projectRoot,
-        preferredRevision,
-        isPuppeteerCore
-      );
-  }
-}
diff --git a/src/node/ProductLauncher.ts b/src/node/ProductLauncher.ts
new file mode 100644
index 00000000..8d5c233d
--- /dev/null
+++ b/src/node/ProductLauncher.ts
@@ -0,0 +1,211 @@
+/**
+ * Copyright 2017 Google Inc. All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+import os from 'os';
+
+import {Browser} from '../common/Browser.js';
+import {BrowserFetcher} from './BrowserFetcher.js';
+
+import {
+  BrowserLaunchArgumentOptions,
+  ChromeReleaseChannel,
+  PuppeteerNodeLaunchOptions,
+} from './LaunchOptions.js';
+
+import {Product} from '../common/Product.js';
+import {ChromeLauncher} from './ChromeLauncher.js';
+import {FirefoxLauncher} from './FirefoxLauncher.js';
+import {accessSync, existsSync} from 'fs';
+
+/**
+ * Describes a launcher - a class that is able to create and launch a browser instance.
+ * @public
+ */
+export interface ProductLauncher {
+  launch(object: PuppeteerNodeLaunchOptions): Promise<Browser>;
+  executablePath: (path?: any) => string;
+  defaultArgs(object: BrowserLaunchArgumentOptions): string[];
+  product: Product;
+}
+
+export function executablePathForChannel(
+  channel: ChromeReleaseChannel
+): string {
+  const platform = os.platform();
+
+  let chromePath: string | undefined;
+  switch (platform) {
+    case 'win32':
+      switch (channel) {
+        case 'chrome':
+          chromePath = `${process.env['PROGRAMFILES']}\\Google\\Chrome\\Application\\chrome.exe`;
+          break;
+        case 'chrome-beta':
+          chromePath = `${process.env['PROGRAMFILES']}\\Google\\Chrome Beta\\Application\\chrome.exe`;
+          break;
+        case 'chrome-canary':
+          chromePath = `${process.env['PROGRAMFILES']}\\Google\\Chrome SxS\\Application\\chrome.exe`;
+          break;
+        case 'chrome-dev':
+          chromePath = `${process.env['PROGRAMFILES']}\\Google\\Chrome Dev\\Application\\chrome.exe`;
+          break;
+      }
+      break;
+    case 'darwin':
+      switch (channel) {
+        case 'chrome':
+          chromePath =
+            '/Applications/Google Chrome.app/Contents/MacOS/Google Chrome';
+          break;
+        case 'chrome-beta':
+          chromePath =
+            '/Applications/Google Chrome Beta.app/Contents/MacOS/Google Chrome Beta';
+          break;
+        case 'chrome-canary':
+          chromePath =
+            '/Applications/Google Chrome Canary.app/Contents/MacOS/Google Chrome Canary';
+          break;
+        case 'chrome-dev':
+          chromePath =
+            '/Applications/Google Chrome Dev.app/Contents/MacOS/Google Chrome Dev';
+          break;
+      }
+      break;
+    case 'linux':
+      switch (channel) {
+        case 'chrome':
+          chromePath = '/opt/google/chrome/chrome';
+          break;
+        case 'chrome-beta':
+          chromePath = '/opt/google/chrome-beta/chrome';
+          break;
+        case 'chrome-dev':
+          chromePath = '/opt/google/chrome-unstable/chrome';
+          break;
+      }
+      break;
+  }
+
+  if (!chromePath) {
+    throw new Error(
+      `Unable to detect browser executable path for '${channel}' on ${platform}.`
+    );
+  }
+
+  // Check if Chrome exists and is accessible.
+  try {
+    accessSync(chromePath);
+  } catch (error) {
+    throw new Error(
+      `Could not find Google Chrome executable for channel '${channel}' at '${chromePath}'.`
+    );
+  }
+
+  return chromePath;
+}
+
+export function resolveExecutablePath(
+  launcher: ChromeLauncher | FirefoxLauncher
+): {
+  executablePath: string;
+  missingText?: string;
+} {
+  const {product, _isPuppeteerCore, _projectRoot, _preferredRevision} =
+    launcher;
+  let downloadPath: string | undefined;
+  // puppeteer-core doesn't take into account PUPPETEER_* env variables.
+  if (!_isPuppeteerCore) {
+    const executablePath =
+      process.env['PUPPETEER_EXECUTABLE_PATH'] ||
+      process.env['npm_config_puppeteer_executable_path'] ||
+      process.env['npm_package_config_puppeteer_executable_path'];
+    if (executablePath) {
+      const missingText = !existsSync(executablePath)
+        ? 'Tried to use PUPPETEER_EXECUTABLE_PATH env variable to launch browser but did not find any executable at: ' +
+          executablePath
+        : undefined;
+      return {executablePath, missingText};
+    }
+    const ubuntuChromiumPath = '/usr/bin/chromium-browser';
+    if (
+      product === 'chrome' &&
+      os.platform() !== 'darwin' &&
+      os.arch() === 'arm64' &&
+      existsSync(ubuntuChromiumPath)
+    ) {
+      return {executablePath: ubuntuChromiumPath, missingText: undefined};
+    }
+    downloadPath =
+      process.env['PUPPETEER_DOWNLOAD_PATH'] ||
+      process.env['npm_config_puppeteer_download_path'] ||
+      process.env['npm_package_config_puppeteer_download_path'];
+  }
+  if (!_projectRoot) {
+    throw new Error(
+      '_projectRoot is undefined. Unable to create a BrowserFetcher.'
+    );
+  }
+  const browserFetcher = new BrowserFetcher(_projectRoot, {
+    product: product,
+    path: downloadPath,
+  });
+
+  if (!_isPuppeteerCore && product === 'chrome') {
+    const revision = process.env['PUPPETEER_CHROMIUM_REVISION'];
+    if (revision) {
+      const revisionInfo = browserFetcher.revisionInfo(revision);
+      const missingText = !revisionInfo.local
+        ? 'Tried to use PUPPETEER_CHROMIUM_REVISION env variable to launch browser but did not find executable at: ' +
+          revisionInfo.executablePath
+        : undefined;
+      return {executablePath: revisionInfo.executablePath, missingText};
+    }
+  }
+  const revisionInfo = browserFetcher.revisionInfo(_preferredRevision);
+
+  const firefoxHelp = `Run \`PUPPETEER_PRODUCT=firefox npm install\` to download a supported Firefox browser binary.`;
+  const chromeHelp = `Run \`npm install\` to download the correct Chromium revision (${launcher._preferredRevision}).`;
+  const missingText = !revisionInfo.local
+    ? `Could not find expected browser (${product}) locally. ${
+        product === 'chrome' ? chromeHelp : firefoxHelp
+      }`
+    : undefined;
+  return {executablePath: revisionInfo.executablePath, missingText};
+}
+
+/**
+ * @internal
+ */
+export function createLauncher(
+  projectRoot: string | undefined,
+  preferredRevision: string,
+  isPuppeteerCore: boolean,
+  product: Product = 'chrome'
+): ProductLauncher {
+  switch (product) {
+    case 'firefox':
+      return new FirefoxLauncher(
+        projectRoot,
+        preferredRevision,
+        isPuppeteerCore
+      );
+    case 'chrome':
+      return new ChromeLauncher(
+        projectRoot,
+        preferredRevision,
+        isPuppeteerCore
+      );
+  }
+}
diff --git a/src/node/Puppeteer.ts b/src/node/Puppeteer.ts
index 539845d8..fb9af91a 100644
--- a/src/node/Puppeteer.ts
+++ b/src/node/Puppeteer.ts
@@ -24,5 +24,5 @@ import {LaunchOptions, BrowserLaunchArgumentOptions} from './LaunchOptions.js';
 import {BrowserConnectOptions} from '../common/BrowserConnector.js';
 import {Browser} from '../common/Browser.js';
-import Launcher, {ProductLauncher} from './Launcher.js';
+import {createLauncher, ProductLauncher} from './ProductLauncher.js';
 import {PUPPETEER_REVISIONS} from '../revisions.js';
 import {Product} from '../common/Product.js';
@@ -75,5 +75,5 @@ export interface PuppeteerLaunchOptions
  */
 export class PuppeteerNode extends Puppeteer {
-  #lazyLauncher?: ProductLauncher;
+  #launcher?: ProductLauncher;
   #projectRoot?: string;
   #productName?: Product;
@@ -188,6 +188,6 @@ export class PuppeteerNode extends Puppeteer {
   get _launcher(): ProductLauncher {
     if (
-      !this.#lazyLauncher ||
-      this.#lazyLauncher.product !== this._productName ||
+      !this.#launcher ||
+      this.#launcher.product !== this._productName ||
       this._changedProduct
     ) {
@@ -201,5 +201,5 @@ export class PuppeteerNode extends Puppeteer {
       }
       this._changedProduct = false;
-      this.#lazyLauncher = Launcher(
+      this.#launcher = createLauncher(
         this.#projectRoot,
         this._preferredRevision,
@@ -208,5 +208,5 @@ export class PuppeteerNode extends Puppeteer {
       );
     }
-    return this.#lazyLauncher;
+    return this.#launcher;
   }
 
diff --git a/src/node/util.ts b/src/node/util.ts
new file mode 100644
index 00000000..c362a39e
--- /dev/null
+++ b/src/node/util.ts
@@ -0,0 +1,13 @@
+import * as os from 'os';
+
+/**
+ * Gets the temporary directory, either from the environmental variable
+ * `PUPPETEER_TMP_DIR` or the `os.tmpdir`.
+ *
+ * @returns The temporary directory path.
+ *
+ * @internal
+ */
+export const tmpdir = (): string => {
+  return process.env['PUPPETEER_TMP_DIR'] || os.tmpdir();
+};
diff --git a/test/src/launcher.spec.ts b/test/src/launcher.spec.ts
index cdc38dc5..4c934063 100644
--- a/test/src/launcher.spec.ts
+++ b/test/src/launcher.spec.ts
@@ -625,23 +625,4 @@ describe('Launcher specs', function () {
       });
 
-      itOnlyRegularInstall(
-        'falls back to launching chrome if there is an unknown product but logs a warning',
-        async () => {
-          const {puppeteer} = getTestState();
-          const consoleStub = sinon.stub(console, 'warn');
-          const browser = await puppeteer.launch({
-            // @ts-expect-error purposeful bad input
-            product: 'SO_NOT_A_PRODUCT',
-          });
-          const userAgent = await browser.userAgent();
-          await browser.close();
-          expect(userAgent).toContain('Chrome');
-          expect(consoleStub.callCount).toEqual(1);
-          expect(consoleStub.firstCall.args).toEqual([
-            'Warning: unknown product name SO_NOT_A_PRODUCT. Falling back to chrome.',
-          ]);
-        }
-      );
-
       itOnlyRegularInstall(
         'should be able to launch Firefox',
","chore: split `Launcher.ts` (#8544)


"
1199,TypeScript,f67ae5711d88f5c50be48326c5cfe4145c95e88a,https://github.com/puppeteer/puppeteer/commit/f67ae5711d88f5c50be48326c5cfe4145c95e88a,P,puppeteer,puppeteer,"[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/test/test.js b/test/test.js
index c626c548..7fbca221 100644
--- a/test/test.js
+++ b/test/test.js
@@ -150,7 +150,5 @@ describe('Puppeteer', function() {
       rm(userDataDir);
     }));
-    // Headless has issues storing cookies
-    // @see https://crbug.com/775261
-    (headless ? xit : it)('userDataDir option should restore cookies', SX(async function() {
+    it('userDataDir option should restore cookies', SX(async function() {
       const userDataDir = fs.mkdtempSync(path.join(__dirname, 'test-user-data-dir'));
       const options = Object.assign({userDataDir}, defaultBrowserOptions);
","test(cookies): enable cookies restoration test (#1075)


"
1209,TypeScript,40beb217bbf7afeebac8b8ff616cc98958b7e1e6,https://github.com/storybookjs/storybook/commit/40beb217bbf7afeebac8b8ff616cc98958b7e1e6,A,storybookjs,storybook,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 34, 3, 4]","diff --git a/code/ui/blocks/src/blocks/Canvas.stories.tsx b/code/ui/blocks/src/blocks/Canvas.stories.tsx
index 0194b952f3..21286a4635 100644
--- a/code/ui/blocks/src/blocks/Canvas.stories.tsx
+++ b/code/ui/blocks/src/blocks/Canvas.stories.tsx
@@ -2,5 +2,5 @@ import React from 'react';
 import type { Meta, StoryObj } from '@storybook/react';
 import { Canvas } from './Canvas';
-import { Story as StoryComponent } from './Story';
+import SourceStoriesMeta from './Source.stories';
 import * as ButtonStories from '../examples/Button.stories';
 
@@ -9,5 +9,11 @@ const meta: Meta<typeof Canvas> = {
   parameters: {
     relativeCsfPaths: ['../examples/Button.stories'],
+    snippets: {
+      'storybook-blocks-example-button--primary': {
+        code: `const emitted = 'source';`,
+      },
+    },
   },
+  decorators: SourceStoriesMeta.decorators,
 };
 export default meta;
@@ -60,4 +66,30 @@ export const SourceStateShown: Story = {
 };
 
+export const SourceStateHidden: Story = {
+  args: {
+    of: ButtonStories.Primary,
+    sourceState: 'hidden',
+  },
+};
+
+export const SourceStateNone: Story = {
+  args: {
+    of: ButtonStories.Primary,
+    sourceState: 'none',
+  },
+};
+
+export const WithSourceProps: Story = {
+  args: {
+    of: ButtonStories.Primary,
+    sourceState: 'shown',
+    source: {
+      language: 'html',
+      code: '<button>           Button          </button>', // spaces should be removed by the prettier formatter
+      format: 'html',
+    },
+  },
+};
+
 const ClassNameStoryDescription = () => (
   <p>
diff --git a/code/ui/blocks/src/blocks/Canvas.tsx b/code/ui/blocks/src/blocks/Canvas.tsx
index 068156e49e..2e9a92ebda 100644
--- a/code/ui/blocks/src/blocks/Canvas.tsx
+++ b/code/ui/blocks/src/blocks/Canvas.tsx
@@ -8,4 +8,5 @@ import { DocsContext } from './DocsContext';
 import type { SourceContextProps } from './SourceContainer';
 import { SourceContext } from './SourceContainer';
+import type { SourceProps } from './Source';
 import { useSourceProps, SourceState as DeprecatedSourceState, SourceState } from './Source';
 import { useStories } from './useStory';
@@ -38,5 +39,5 @@ type CanvasProps = Pick<PurePreviewProps, 'withToolbar' | 'additionalActions' |
   of: ModuleExport;
   sourceState?: 'hidden' | 'shown' | 'none';
-  source?: any; // TODO: get from Source component (and or block) when that is ready
+  source?: Omit<SourceProps, 'dark'>;
   story?: any; // TODO: get from Story component (and or block) when that is ready
 };
@@ -101,9 +102,14 @@ export const Canvas: FC<CanvasProps & DeprecatedCanvasProps> = (props) => {
   const { isLoading, previewProps } = useDeprecatedPreviewProps(props, docsContext, sourceContext);
 
+  if (!of && !children) {
+    throw new Error('No story passed to the Canvas block. Did you forget to pass the `of` prop?');
+  }
+
   if (of) {
     // TODO: loading?
     return (
       <PurePreview
-        withSource={sourceProps}
+        withSource={sourceState === 'none' ? undefined : sourceProps}
+        isExpanded={sourceState === 'shown'}
         withToolbar={withToolbar}
         additionalActions={additionalActions}
@@ -114,7 +120,4 @@ export const Canvas: FC<CanvasProps & DeprecatedCanvasProps> = (props) => {
     );
   }
-  if (!of && !children) {
-    throw new Error('No story passed to the Canvas block. Did you forget to pass the `of` prop?');
-  }
 
   if (isLoading) return <PreviewSkeleton />;
diff --git a/code/ui/blocks/src/blocks/Source.tsx b/code/ui/blocks/src/blocks/Source.tsx
index a990dd7c87..03e0653ce3 100644
--- a/code/ui/blocks/src/blocks/Source.tsx
+++ b/code/ui/blocks/src/blocks/Source.tsx
@@ -34,5 +34,5 @@ type SourceParameters = SourceCodeProps & {
 };
 
-type SourceProps = Omit<SourceParameters, 'transformSource' | 'storySource'> & {
+export type SourceProps = Omit<SourceParameters, 'transformSource' | 'storySource'> & {
   /**
    * Pass the export defining a story to render its source
@@ -113,5 +113,5 @@ export const useSourceProps = (
   let stories: PreparedStory[] = storiesFromIds as PreparedStory[];
   if (props.of) {
-    const resolved = docsContext.resolveModuleExport(props.of);
+    const resolved = docsContext.resolveOf(props.of);
     if (resolved.type !== 'story')
       throw new Error(`Invalid value passed to the 'of' prop, it should be a story export.`);
@@ -120,5 +120,4 @@ export const useSourceProps = (
     stories = [docsContext.storyById()];
   }
-
   const sourceParameters = (stories[0].parameters.docs?.source || {}) as SourceParameters;
   let { code } = props; // We will fall back to `sourceParameters.code`, but per story below
@@ -141,5 +140,4 @@ export const useSourceProps = (
 
   const state = getSourceState(stories as PreparedStory[]);
-
   return code
     ? {
","support source props

"
1213,TypeScript,412cd179849fdc442206b93616d57faf30a0c0cd,https://github.com/storybookjs/storybook/commit/412cd179849fdc442206b93616d57faf30a0c0cd,P,storybookjs,storybook,"[1, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 3, 1, 4, 0, 5]","diff --git a/addons/cssresources/README.md b/addons/cssresources/README.md
index 14bec5d981..bdc7fe79ef 100644
--- a/addons/cssresources/README.md
+++ b/addons/cssresources/README.md
@@ -36,5 +36,5 @@ addDecorator(
   withCssResources({
     cssresources: [{
-        name: `bluetheme`,
+        id: `bluetheme`,
         code: `<style>body { background-color: lightblue; }</style>`,
         picked: false,
@@ -49,9 +49,9 @@ storiesOf('Addons|Cssresources', module)
     withCssResources({
       cssresources: [{
-          name: `fontawesome`,
+          id: `fontawesome`,
           code: `<link rel=""stylesheet"" type=""text/css"" href=""https://stackpath.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css""></link>`,
           picked: true,
         }, {
-          name: `whitetheme`,
+          id: `whitetheme`,
           code: `<style>.fa { color: #fff }</style>`,
           picked: true,
diff --git a/addons/cssresources/src/CssResource.ts b/addons/cssresources/src/CssResource.ts
new file mode 100644
index 0000000000..0067ca6774
--- /dev/null
+++ b/addons/cssresources/src/CssResource.ts
@@ -0,0 +1,5 @@
+export interface CssResource {
+  id: string;
+  code: string;
+  picked: boolean;
+}
diff --git a/addons/cssresources/src/css-resource-panel.tsx b/addons/cssresources/src/css-resource-panel.tsx
index 09dc55e39b..77ba5cc0fd 100644
--- a/addons/cssresources/src/css-resource-panel.tsx
+++ b/addons/cssresources/src/css-resource-panel.tsx
@@ -6,4 +6,5 @@ import events, { STORY_CHANGED } from '@storybook/core-events';
 import EVENTS, { PARAM_KEY } from './constants';
 import Channel from '@storybook/channels';
+import { CssResource } from './CssResource';
 
 interface CssResourcePanelProps {
@@ -20,5 +21,9 @@ interface CssResourcePanelProps {
 }
 
-export default class CssResourcePanel extends Component<CssResourcePanelProps, any> {
+interface CssResourcePanelState {
+  list: CssResource[];
+}
+
+export default class CssResourcePanel extends Component<CssResourcePanelProps, CssResourcePanelState> {
   constructor(props: CssResourcePanelProps) {
     super(props);
@@ -41,5 +46,5 @@ export default class CssResourcePanel extends Component<CssResourcePanelProps, a
   onStoryChange = (id: string) => {
     const { api } = this.props;
-    const list = api.getParameters(id, PARAM_KEY) as any[];
+    const list = api.getParameters(id, PARAM_KEY) as CssResource[];
 
     if (list) {
@@ -51,5 +56,5 @@ export default class CssResourcePanel extends Component<CssResourcePanelProps, a
   onChange = (event: any) => {
     const { list: oldList } = this.state;
-    const list = oldList.map((i: any) => ({
+    const list = oldList.map(i => ({
       ...i,
       picked: i.id === event.target.id ? event.target.checked : i.picked,
@@ -58,5 +63,5 @@ export default class CssResourcePanel extends Component<CssResourcePanelProps, a
   };
 
-  emit(list: any[]) {
+  emit(list: CssResource[]) {
     const { api } = this.props;
     api.emit(EVENTS.SET, list);
@@ -74,5 +79,5 @@ export default class CssResourcePanel extends Component<CssResourcePanelProps, a
       <Fragment>
         {list &&
-          list.map(({ id, code, picked }: any) => (
+          list.map(({ id, code, picked }) => (
             <div key={id} style={{ padding: 10 }}>
               <label>
","Improve addon-cssresources typing and fix README

Create `CssResource` interface and use it in `CssSourcePanel`.

Also update README because some commits ago, `name` attribute used in cssresources conf has been renamed to `id`

"
1216,TypeScript,194a8045666f60f6a7afc1d6ed1d2dfff5752342,https://github.com/gothinkster/realworld/commit/194a8045666f60f6a7afc1d6ed1d2dfff5752342,P,gothinkster,realworld,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0]","diff --git a/README.md b/README.md
index dc84710..30f7602 100644
--- a/README.md
+++ b/README.md
@@ -74,5 +74,5 @@ Forks, tutorials, workshops, and other resources based on the RealWorld project:
 # Who made this?
 
-The core creators are **[Eric Simons](https://twitter.com/ericsimons40)** and **[Albert Pai](https://twitter.com/iamalbertpai)** &mdash; we personally run [Thinkster.io](https://thinkster.io), the developer tutorial site where all of these stacks are taught. Thinkster funds this entire project, so please consider investing in [a Pro subscription](https://thinkster.io/pro) to **support the ongoing development of RealWorld**!
+RealWorld would not be possible without the [open source community](#special-thanks-to) helping push the project forward each day. In addition, we have a core project team composed of:
 
 #### [Eric Simons](https://twitter.com/ericsimons40) - Founder/Lead
","Update README.md
"
1224,TypeScript,09db8208bdfcebb8b5e2aa3b2b91590825b19747,https://github.com/gothinkster/realworld/commit/09db8208bdfcebb8b5e2aa3b2b91590825b19747,P,gothinkster,realworld,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0]","diff --git a/README.md b/README.md
index 648a0f9..041adc2 100644
--- a/README.md
+++ b/README.md
@@ -58,5 +58,5 @@ Work In Progress:
 
 Work In Progress:
-**[ React Native](https://github.com/gothinkster/realworld/issues/10) | [ Ionic 2+](https://github.com/gothinkster/realworld/issues/16) | [ Jasonette](https://github.com/gothinkster/realworld/issues/39) | [ Swift](https://github.com/gothinkster/realworld/issues/43) | [ C# on Xamarin](https://github.com/gothinkster/realworld/issues/70) | [  Kotlin/Android](https://github.com/gothinkster/realworld/issues/84) | [ Onymos](https://github.com/gothinkster/realworld/issues/91) | [Quasar framework](https://github.com/gothinkster/realworld/issues/171) | [Swift Vapor](https://github.com/gothinkster/realworld/issues/175) | [Swift Perfect](https://github.com/gothinkster/realworld/issues/181)**
+**[ Jasonette](https://github.com/gothinkster/realworld/issues/39) | [ Swift](https://github.com/gothinkster/realworld/issues/43) | [ C# on Xamarin](https://github.com/gothinkster/realworld/issues/70) | [  Kotlin/Android](https://github.com/gothinkster/realworld/issues/84) | [ Onymos](https://github.com/gothinkster/realworld/issues/91) | [Quasar framework](https://github.com/gothinkster/realworld/issues/171) | [Swift Vapor](https://github.com/gothinkster/realworld/issues/175) | [Swift Perfect](https://github.com/gothinkster/realworld/issues/181)**
 
 # Fullstack
","Auto-update README (#231)


"
1226,TypeScript,a1bdc69f63ab12acf2f46fca7c5cde1276ef8e22,https://github.com/gothinkster/realworld/commit/a1bdc69f63ab12acf2f46fca7c5cde1276ef8e22,P,gothinkster,realworld,"[1, 18, 2, 25, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11, 47, 127, 25]","diff --git a/apps/demo/public/index.css b/apps/demo/public/index.css
index 6e5de2d..b657213 100644
--- a/apps/demo/public/index.css
+++ b/apps/demo/public/index.css
@@ -13,9 +13,9 @@ body {
   --color-default-light: lightgray;
 
-  --color-primary: #9d439d;
-  --color-primary-light: rgba(209, 103, 203, 0.5);
-  --color-primary-dark: #6e2c6e;
+  --color-secondary: #9d439d;
+  --color-secondary-light: rgba(209, 103, 203, 0.5);
+  --color-secondary-dark: #6e2c6e;
 
-  --color-secondary: #5cb85c;
+  --color-primary: #5cb85c;
 
   --color-warn: grey;
@@ -25,6 +25,25 @@ body {
 }
 
+/* Layout */
+
+.rl-main {
+  max-width: 700px;
+  margin-inline-start: auto;
+  margin-inline-end: auto;
+  padding-block-start: 2rem;
+}
+
 /* Generic */
 
+.rl-page-title {
+  text-align: center;
+  background: var(--color-primary);
+  color: white;
+  border-radius: var(--border-radius);
+  padding: 0.5rem 1rem;
+  margin-block-end: 2rem;
+  width: calc(100% - 2rem);
+}
+
 .rl-tag-list-vertical,
 .rl-tag-list-horizontal {
@@ -88,6 +107,6 @@ dialog {
 
 .rl-form-control:focus {
-  outline: 2px solid var(--color-primary-dark);
-  border-color: var(--color-primary-dark);
+  outline: 2px solid var(--color-secondary-dark);
+  border-color: var(--color-secondary-dark);
   box-shadow: 0 0 5px 5px rgb(110 44 110 / 50%);
 }
@@ -147,5 +166,5 @@ dialog {
 .rl-form-group--avatar:focus,
 .rl-form-group--avatar:hover {
-  border: 2px solid var(--color-primary-dark);
+  border: 2px solid var(--color-secondary-dark);
   box-shadow: 0 0 5px 5px rgb(110 44 110 / 50%);
   border-radius: 50%;
@@ -156,8 +175,8 @@ dialog {
 .rl-link,
 .rl-link-underlined {
-  color: var(--color-primary-dark);
+  color: var(--color-secondary-dark);
   font-weight: bold;
   text-decoration: none;
-  outline-color: var(--color-primary-dark);
+  outline-color: var(--color-secondary-dark);
 }
 
@@ -193,5 +212,5 @@ dialog {
 
 .navbar-title {
-  color: var(--color-secondary);
+  color: var(--color-primary);
   font-family: 'Titillium Web', sans-serif;
   font-size: 1.5rem;
@@ -229,5 +248,5 @@ dialog {
 
 .rl-article-author__content {
-  color: var(--color-primary-dark);
+  color: var(--color-secondary-dark);
   display: flex;
   flex-direction: column;
@@ -285,9 +304,8 @@ dialog {
   flex-direction: column;
   align-items: center;
+  width: 20rem;
 }
 
 .auth-title {
-  color: #000;
-  text-align: center;
   margin-block-end: 0.5rem;
 }
@@ -295,6 +313,5 @@ dialog {
 .auth-form {
   margin-block-start: 2rem;
-  width: 20rem;
-  max-width: 100%;
+  width: 100%;
   margin-block-end: 2rem;
 }
@@ -373,9 +390,9 @@ dialog {
 
 .rl-navbar-horizontal ul a:focus-visible {
-  border-bottom: 4px solid var(--color-primary-dark);
+  border-bottom: 4px solid var(--color-secondary-dark);
 }
 
 .rl-navbar-vertical ul a:focus-visible {
-  border-right: 4px solid var(--color-primary-dark);
+  border-right: 4px solid var(--color-secondary-dark);
 }
 
@@ -383,14 +400,14 @@ dialog {
 .rl-navbar-horizontal ul a.rl-active,
 .rl-navbar-vertical ul a.rl-active {
-  color: var(--color-primary-dark);
+  color: var(--color-secondary-dark);
   font-weight: bold;
 }
 
 .rl-navbar-vertical ul a.rl-active {
-  border-right: 4px solid var(--color-primary-dark);
+  border-right: 4px solid var(--color-secondary-dark);
 }
 
 .rl-navbar-horizontal ul a.rl-active {
-  border-bottom: 4px solid var(--color-primary-dark);
+  border-bottom: 4px solid var(--color-secondary-dark);
 }
 
@@ -402,5 +419,5 @@ dialog {
   color: #fff;
   display: inline-block;
-  font-weight: normal;
+  font-weight: bold;
   line-height: 1.25;
   text-align: center;
@@ -423,6 +440,6 @@ dialog {
 
 .rl-btn-primary {
-  background-color: var(--color-primary-dark);
-  border-color: var(--color-primary-dark);
+  background-color: var(--color-primary);
+  border-color: var(--color-primary);
 }
 
@@ -432,6 +449,6 @@ dialog {
 
 .rl-btn-secondary {
-  background-color: var(--color-secondary);
-  border-color: var(--color-secondary);
+  background-color: var(--color-secondary-dark);
+  border-color: var(--color-secondary-dark);
 }
 
@@ -496,4 +513,5 @@ dialog {
 }
 
+.rl-tag,
 .rl-tag a {
   color: black;
@@ -531,5 +549,5 @@ dialog {
 
 .rl-favorite-active {
-  fill: var(--color-primary);
+  fill: var(--color-secondary-dark);
 }
 
@@ -541,9 +559,9 @@ dialog {
 .rl-favorite:hover,
 .rl-favorite-active:hover {
-  background: var(--color-primary-light);
+  background: var(--color-secondary-light);
 }
 
 .rl-favorite:hover svg {
-  fill: var(--color-primary);
+  fill: var(--color-secondary);
 }
 
diff --git a/apps/demo/src/app/stories/molecules/upload.stories.tsx b/apps/demo/src/app/stories/molecules/upload.stories.tsx
index bde097c..29195fb 100644
--- a/apps/demo/src/app/stories/molecules/upload.stories.tsx
+++ b/apps/demo/src/app/stories/molecules/upload.stories.tsx
@@ -12,5 +12,5 @@ export const InputFile = () => (
         <div>Drag and drop the file here</div>
         <div>- OR -</div>
-        <button type=""button"" className=""rl-btn-secondary"">
+        <button type=""button"" className=""rl-btn-primary"">
           Browse files
         </button>
@@ -24,5 +24,5 @@ export const InputFile = () => (
         <img className=""rl-file-form-group__preview"" src={coverImage} alt="""" />
         <div className=""rl-file-form-group__button-container"">
-          <button type=""button"" className=""rl-btn-secondary"">
+          <button type=""button"" className=""rl-btn-primary"">
             Browse files
           </button>
diff --git a/apps/demo/src/app/stories/organisms/article-form.stories.tsx b/apps/demo/src/app/stories/organisms/article-form.stories.tsx
index 53391ec..2209d4a 100644
--- a/apps/demo/src/app/stories/organisms/article-form.stories.tsx
+++ b/apps/demo/src/app/stories/organisms/article-form.stories.tsx
@@ -7,5 +7,5 @@ export const ArticleForm = () => (
     <fieldset className=""rl-form-group"">
       <label htmlFor=""title"">Title</label>
-      <input id=""title"" type=""text"" className=""rl-form-control"" />
+      <input id=""title"" type=""text"" className=""rl-form-control"" autoFocus />
     </fieldset>
     <fieldset className=""rl-file-form-group"">
@@ -14,5 +14,5 @@ export const ArticleForm = () => (
         <div>Drag and drop the file here</div>
         <div>- OR -</div>
-        <button type=""button"" className=""rl-btn-secondary"">
+        <button type=""button"" className=""rl-btn-primary"">
           Browse files
         </button>
@@ -33,5 +33,5 @@ export const ArticleForm = () => (
       <div className=""tag-list""></div>
     </fieldset>
-    <button className=""rl-btn-secondary"" type=""submit"">
+    <button className=""rl-btn-primary"" type=""submit"">
       Publish
     </button>
diff --git a/apps/demo/src/app/stories/organisms/auth/create-account.stories.tsx b/apps/demo/src/app/stories/organisms/auth/create-account.stories.tsx
index b368124..d27084d 100644
--- a/apps/demo/src/app/stories/organisms/auth/create-account.stories.tsx
+++ b/apps/demo/src/app/stories/organisms/auth/create-account.stories.tsx
@@ -5,5 +5,5 @@ export default {
 export const CreateAccount = () => (
   <dialog id=""create-account-dialog"" className=""auth-page"">
-    <h1 className=""auth-title"">Create account</h1>
+    <h1 className=""rl-page-title auth-title"">Create account</h1>
 
     <form method=""dialog"" className=""auth-form"">
diff --git a/apps/demo/src/app/stories/organisms/auth/login.stories.tsx b/apps/demo/src/app/stories/organisms/auth/login.stories.tsx
index 16c999e..2bd41a0 100644
--- a/apps/demo/src/app/stories/organisms/auth/login.stories.tsx
+++ b/apps/demo/src/app/stories/organisms/auth/login.stories.tsx
@@ -5,5 +5,5 @@ export default {
 export const Login = () => (
   <dialog id=""login-dialog"" className=""auth-page"">
-    <h1 className=""auth-title"">Log in</h1>
+    <h1 className=""rl-page-title auth-title"">Log in</h1>
 
     <form className=""auth-form"">
diff --git a/apps/demo/src/app/stories/organisms/home.stories.tsx b/apps/demo/src/app/stories/organisms/home.stories.tsx
deleted file mode 100644
index 83e0366..0000000
--- a/apps/demo/src/app/stories/organisms/home.stories.tsx
+++ /dev/null
@@ -1,112 +0,0 @@
-export default {
-  title: 'Organisms/Home',
-};
-
-export const Home = () => (
-  <div className=""home-page"">
-    <div className=""banner"">
-      <div className=""container"">
-        <h1 className=""logo-font"">conduit</h1>
-        <p>A place to share your knowledge.</p>
-      </div>
-    </div>
-
-    <div className=""container page"">
-      <div className=""row"">
-        <div className=""col-md-9"">
-          <div className=""feed-toggle"">
-            <ul className=""nav nav-pills outline-active"">
-              <li className=""nav-item"">
-                <a className=""rl-link disabled"" href="""">
-                  Your Feed
-                </a>
-              </li>
-              <li className=""nav-item"">
-                <a className=""rl-link active"" href="""">
-                  Global Feed
-                </a>
-              </li>
-            </ul>
-          </div>
-
-          <div className=""article-preview"">
-            <div className=""article-meta"">
-              <a href=""profile.html"">
-                <img src=""http://i.imgur.com/Qr71crq.jpg"" />
-              </a>
-              <div className=""info"">
-                <a href=""apps/demo/src/app/stories/organisms/home.stories"" className=""author"">
-                  Eric Simons
-                </a>
-                <span className=""date"">January 20th</span>
-              </div>
-              <button className=""btn btn-outline-primary btn-sm pull-xs-right"">
-                <i className=""ion-heart""></i> 29
-              </button>
-            </div>
-            <a href=""apps/demo/src/app/stories/organisms/home.stories"" className=""preview-link"">
-              <h1>How to build webapps that scale</h1>
-              <p>This is the description for the post.</p>
-              <span>Read more...</span>
-            </a>
-          </div>
-
-          <div className=""article-preview"">
-            <div className=""article-meta"">
-              <a href=""profile.html"">
-                <img src=""http://i.imgur.com/N4VcUeJ.jpg"" />
-              </a>
-              <div className=""info"">
-                <a href=""apps/demo/src/app/stories/organisms/home.stories"" className=""author"">
-                  Albert Pai
-                </a>
-                <span className=""date"">January 20th</span>
-              </div>
-              <button className=""btn btn-outline-primary btn-sm pull-xs-right"">
-                <i className=""ion-heart""></i> 32
-              </button>
-            </div>
-            <a href=""apps/demo/src/app/stories/organisms/home.stories"" className=""preview-link"">
-              <h1>The song you won't ever stop singing. No matter how hard you try.</h1>
-              <p>This is the description for the post.</p>
-              <span>Read more...</span>
-            </a>
-          </div>
-        </div>
-
-        <div className=""col-md-3"">
-          <div className=""sidebar"">
-            <p>Popular Tags</p>
-
-            <div className=""tag-list"">
-              <a href="""" className=""tag-pill tag-default"">
-                programming
-              </a>
-              <a href="""" className=""tag-pill tag-default"">
-                javascript
-              </a>
-              <a href="""" className=""tag-pill tag-default"">
-                emberjs
-              </a>
-              <a href="""" className=""tag-pill tag-default"">
-                angularjs
-              </a>
-              <a href="""" className=""tag-pill tag-default"">
-                react
-              </a>
-              <a href="""" className=""tag-pill tag-default"">
-                mean
-              </a>
-              <a href="""" className=""tag-pill tag-default"">
-                node
-              </a>
-              <a href="""" className=""tag-pill tag-default"">
-                rails
-              </a>
-            </div>
-          </div>
-        </div>
-      </div>
-    </div>
-  </div>
-);
diff --git a/apps/demo/src/app/stories/organisms/settings.stories.tsx b/apps/demo/src/app/stories/organisms/settings.stories.tsx
index 79a535e..a3437ca 100644
--- a/apps/demo/src/app/stories/organisms/settings.stories.tsx
+++ b/apps/demo/src/app/stories/organisms/settings.stories.tsx
@@ -47,5 +47,5 @@ export const Settings = () => (
           <textarea id=""bio"" className=""rl-form-control"" rows={8}></textarea>
         </fieldset>
-        <button type=""submit"" className=""rl-btn-secondary"">
+        <button type=""submit"" className=""rl-btn-primary"">
           Update
         </button>
diff --git a/apps/demo/src/app/stories/pages/article-form.stories.tsx b/apps/demo/src/app/stories/pages/article-form.stories.tsx
index 3240936..65b68f7 100644
--- a/apps/demo/src/app/stories/pages/article-form.stories.tsx
+++ b/apps/demo/src/app/stories/pages/article-form.stories.tsx
@@ -1,45 +1,65 @@
 export default {
   title: 'Pages/Article Form',
-  parameters: {
-    backgrounds: {
-      default: 'realworld',
-    },
-  },
 };
 
 export const ArticleForm = () => (
-  <div className=""container page"">
-    <div className=""row"">
-      <div className=""col-md-10 offset-md-1 col-xs-12"">
-        <form>
-          <fieldset>
-            <fieldset className=""rl-form-group"">
-              <label htmlFor=""title"">Title</label>
-              <input id=""title"" type=""text"" className=""rl-form-control"" />
-            </fieldset>
-            <fieldset className=""rl-form-group"">
-              <label htmlFor=""description"">Description</label>
-              <input id=""description"" type=""text"" className=""rl-form-control"" />
-            </fieldset>
-            <fieldset className=""rl-form-group"">
-              <label htmlFor=""image"">Cover image</label>
-              <input id=""image"" type=""text"" className=""rl-form-control"" />
-            </fieldset>
-            <fieldset className=""rl-form-group"">
-              <label htmlFor=""body"">Article content</label>
-              <textarea id=""body"" className=""rl-form-control"" rows={8}></textarea>
-            </fieldset>
-            <fieldset className=""rl-form-group"">
-              <label htmlFor=""tags"">Tags</label>
-              <input id=""tags"" type=""text"" className=""rl-form-control"" />
-              <div className=""tag-list""></div>
-            </fieldset>
-            <button className=""rl-btn-primary"" type=""submit"">
-              Publish
+  <>
+    <nav className=""navbar"">
+      <a className=""navbar-title"" href="""">
+        conduit
+      </a>
+
+      <ul className=""navbar-links"">
+        <li className=""nav-item"">
+          <input className=""rl-form-control"" type=""text"" placeholder=""Search"" />
+        </li>
+        <li className=""nav-item"">
+          <a className=""rl-btn-primary"" href="""">
+            Create article
+          </a>
+        </li>
+        <li className=""nav-item"">
+          <a className=""rl-link"" href="""">
+            <img className=""rl-avatar"" src=""avatar.png"" alt=""user avatar image"" />
+          </a>
+        </li>
+      </ul>
+    </nav>
+    <main className=""rl-main"">
+      <h1 className=""rl-page-title"">Create new article</h1>
+      <form>
+        <fieldset className=""rl-form-group"">
+          <label htmlFor=""title"">Title</label>
+          <input id=""title"" type=""text"" className=""rl-form-control"" autoFocus />
+        </fieldset>
+        <fieldset className=""rl-file-form-group"">
+          <label>Cover image</label>
+          <div className=""rl-file-form-group__input"">
+            <div>Drag and drop the file here</div>
+            <div>- OR -</div>
+            <button type=""button"" className=""rl-btn-primary"">
+              Browse files
             </button>
-          </fieldset>
-        </form>
-      </div>
-    </div>
-  </div>
+          </div>
+          <input type=""file"" className=""rl-input-file"" />
+        </fieldset>
+        <fieldset className=""rl-form-group"">
+          <label htmlFor=""description"">Description</label>
+          <input id=""description"" type=""text"" className=""rl-form-control"" />
+        </fieldset>
+        <fieldset className=""rl-form-group"">
+          <label htmlFor=""body"">Article content</label>
+          <textarea id=""body"" className=""rl-form-control"" rows={8}></textarea>
+        </fieldset>
+        <fieldset className=""rl-form-group"">
+          <label htmlFor=""tags"">Tags</label>
+          <input id=""tags"" type=""text"" className=""rl-form-control"" />
+          <div className=""tag-list""></div>
+        </fieldset>
+        <button className=""rl-btn-primary"" type=""submit"">
+          Publish
+        </button>
+      </form>
+    </main>
+  </>
 );
diff --git a/apps/demo/src/app/stories/pages/auth/create-account.stories.tsx b/apps/demo/src/app/stories/pages/auth/create-account.stories.tsx
index 7d9164f..5060fb7 100644
--- a/apps/demo/src/app/stories/pages/auth/create-account.stories.tsx
+++ b/apps/demo/src/app/stories/pages/auth/create-account.stories.tsx
@@ -1,9 +1,12 @@
 export default {
   title: 'Pages/Auth/Create Account',
+  parameters: {
+    layout: 'centered',
+  },
 };
 
 export const CreateAccount = () => (
   <div className=""auth-page"">
-    <h1 className=""auth-title"">Create account</h1>
+    <h1 className=""rl-page-title auth-title"">Create account</h1>
     <a className=""rl-link-underlined"" href="""">
       Have an account?
diff --git a/apps/demo/src/app/stories/pages/auth/login.stories.tsx b/apps/demo/src/app/stories/pages/auth/login.stories.tsx
index 4063fcd..4391677 100644
--- a/apps/demo/src/app/stories/pages/auth/login.stories.tsx
+++ b/apps/demo/src/app/stories/pages/auth/login.stories.tsx
@@ -5,5 +5,5 @@ export default {
 export const Login = () => (
   <div className=""auth-page"">
-    <h1 className=""auth-title"">Log in</h1>
+    <h1 className=""rl-page-title auth-title"">Log in</h1>
     <a className=""rl-link-underlined"" href="""">
       Need an account?
diff --git a/apps/demo/src/app/stories/templates/auth/create-account.stories.tsx b/apps/demo/src/app/stories/templates/auth/create-account.stories.tsx
index 7936e71..1778b72 100644
--- a/apps/demo/src/app/stories/templates/auth/create-account.stories.tsx
+++ b/apps/demo/src/app/stories/templates/auth/create-account.stories.tsx
@@ -7,5 +7,5 @@ export default {
 export const CreateAccount = () => (
   <dialog id=""create-account-dialog"" className=""auth-page"">
-    <h1 className=""auth-title"">Create account</h1>
+    <h1 className=""rl-page-title auth-title"">Create account</h1>
 
     <form method=""dialog"" className=""auth-form"">
diff --git a/apps/demo/src/app/stories/templates/auth/login.stories.tsx b/apps/demo/src/app/stories/templates/auth/login.stories.tsx
index ed8ca16..90cecd0 100644
--- a/apps/demo/src/app/stories/templates/auth/login.stories.tsx
+++ b/apps/demo/src/app/stories/templates/auth/login.stories.tsx
@@ -7,5 +7,5 @@ export default {
 export const Login = () => (
   <dialog id=""login-dialog"" className=""auth-page"">
-    <h1 className=""auth-title"">Log in</h1>
+    <h1 className=""rl-page-title auth-title"">Log in</h1>
 
     <form className=""auth-form"">
","refactor(design-system): update colors

"
1252,TypeScript,637e58f255342221699f92b044ed0c32f9dcf5f0,https://github.com/coder/code-server/commit/637e58f255342221699f92b044ed0c32f9dcf5f0,P,coder,code-server,"[1, 21, 6, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/src/server.ts b/src/server.ts
index 4312d36d..139dc64e 100644
--- a/src/server.ts
+++ b/src/server.ts
@@ -532,28 +532,43 @@ export class MainServer extends Server {
 			this.servicesPromise,
 		]);
+
 		const logger = this.services.get(ILogService) as ILogService;
 		logger.info(""request.url"", `""${request.url}""`);
-		const environment = this.services.get(IEnvironmentService) as IEnvironmentService;
-		const locale = environment.args.locale || await getLocaleFromConfig(environment.userDataPath);
+
 		const cwd = process.env.VSCODE_CWD || process.cwd();
-		const workspacePath = parsedUrl.query.workspace as string | undefined;
-		const folderPath = !workspacePath ? parsedUrl.query.folder as string | undefined || this.options.folderUri : undefined;
+
 		const remoteAuthority = request.headers.host as string;
 		const transformer = getUriTransformer(remoteAuthority);
+		const validatePath = async (filePath: string[] | string | undefined, isDirectory: boolean, unsetFallback?: string): Promise<UriComponents | undefined> => {
+			if (!filePath || filePath.length === 0) {
+				if (!unsetFallback) {
+					return undefined;
+				}
+				filePath = unsetFallback;
+			} else if (Array.isArray(filePath)) {
+				filePath = filePath[0];
+			}
+			const uri = URI.file(sanitizeFilePath(filePath, cwd));
+			try {
+				const stat = await util.promisify(fs.stat)(uri.fsPath);
+				if (isDirectory !== stat.isDirectory()) {
+					return undefined;
+				}
+			} catch (error) {
+				return undefined;
+			}
+			return transformer.transformOutgoing(uri);
+		};
+
+		const environment = this.services.get(IEnvironmentService) as IEnvironmentService;
 		const options: Options = {
 			WORKBENCH_WEB_CONGIGURATION: {
-				workspaceUri: workspacePath
-					? transformer.transformOutgoing(URI.file(sanitizeFilePath(workspacePath, cwd)))
-					: undefined,
-				folderUri: folderPath
-					? transformer.transformOutgoing(URI.file(sanitizeFilePath(folderPath, cwd)))
-					: undefined,
+				workspaceUri: await validatePath(parsedUrl.query.workspace, false),
+				folderUri: !parsedUrl.query.workspace ? await validatePath(parsedUrl.query.folder, true, this.options.folderUri) : undefined,
 				remoteAuthority,
 				productConfiguration: product,
 			},
-			REMOTE_USER_DATA_URI: transformer.transformOutgoing(
-				(this.services.get(IEnvironmentService) as EnvironmentService).webUserDataHome,
-			),
-			NLS_CONFIGURATION: await getNlsConfiguration(locale, environment.userDataPath),
+			REMOTE_USER_DATA_URI: transformer.transformOutgoing((<EnvironmentService>environment).webUserDataHome),
+			NLS_CONFIGURATION: await getNlsConfiguration(environment.args.locale || await getLocaleFromConfig(environment.userDataPath), environment.userDataPath),
 		};
 
","Prevent opening invalid paths

"
1262,TypeScript,294107eca5313af9045bc9ce228a6c55210dc118,https://github.com/reduxjs/redux/commit/294107eca5313af9045bc9ce228a6c55210dc118,P,reduxjs,redux,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 2, 0, 0, 0, 0]","diff --git a/docs/recipes/UsingObjectSpreadOperator.md b/docs/recipes/UsingObjectSpreadOperator.md
index 04136cf7..cb881a05 100644
--- a/docs/recipes/UsingObjectSpreadOperator.md
+++ b/docs/recipes/UsingObjectSpreadOperator.md
@@ -18,5 +18,5 @@ function todoApp(state = initialState, action) {
 While effective, using `Object.assign()` can quickly make simple reducers difficult to read given its rather verbose syntax.
 
-An alternative approach is to use the [object spread syntax](https://github.com/sebmarkbage/ecmascript-rest-spread) proposed for the next versions of JavaScript which lets you use the spread (`...`) operator to copy enumerable properties from one object to another in a more succinct way. The object spread operator is conceptually similar to the ES6 [array spread operator](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Spread_operator). We can simplify the `todoApp` example above by using the object spread syntax:
+An alternative approach is to use the [object spread syntax](https://github.com/tc39/proposal-object-rest-spread) recent added to the JavaScript specification. It lets you use the spread (`...`) operator to copy enumerable properties from one object to another in a more succinct way. The object spread operator is conceptually similar to the ES6 [array spread operator](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Spread_operator). We can simplify the `todoApp` example above by using the object spread syntax:
 
 ```js
@@ -50,5 +50,5 @@ return getAddedIds(state.cart).map(id => ({
 ```
 
-Since the object spread syntax is still a [Stage 3](https://github.com/sebmarkbage/ecmascript-rest-spread#status-of-this-proposal) proposal for ECMAScript you'll need to use a transpiler such as [Babel](http://babeljs.io/) to use it in production. You should use the [`env`](https://github.com/babel/babel/tree/master/packages/babel-preset-env) preset, install [`babel-plugin-transform-object-rest-spread`](http://babeljs.io/docs/plugins/transform-object-rest-spread/) and add it individually to the `plugins` array in your `.babelrc`.
+While the object spread syntax is a [Stage 4](https://github.com/tc39/proposal-object-rest-spread#status-of-this-proposal) proposal for ECMAScript and accepted for the 2018 specification release, you will still need to use a transpiler such as [Babel](http://babeljs.io/) to use it in production systems. You should use the [`env`](https://github.com/babel/babel/tree/master/packages/babel-preset-env) preset, install [`babel-plugin-transform-object-rest-spread`](http://babeljs.io/docs/plugins/transform-object-rest-spread/) and add it individually to the `plugins` array in your `.babelrc`.
 
 ```json
@@ -58,4 +58,2 @@ Since the object spread syntax is still a [Stage 3](https://github.com/sebmarkba
 }
 ```
-
-Note that this is still an experimental language feature proposal so it may change in the future. Nevertheless some large projects such as [React Native](https://github.com/facebook/react-native) already use it extensively so it is safe to say that there will be a good automated migration path if it changes.
","Update UsingObjectSpreadOperator.md (#3015)

* Update UsingObjectSpreadOperator.md

* Some further cleanups

"
1282,TypeScript,b3f51cc9c110017ebc8f6ec12da6b92d96f37caa,https://github.com/nestjs/nest/commit/b3f51cc9c110017ebc8f6ec12da6b92d96f37caa,C,nestjs,nest,"[1, 10, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/package.json b/package.json
index 886b86707..ee5130d06 100644
--- a/package.json
+++ b/package.json
@@ -1,5 +1,5 @@
 {
   ""name"": ""nestjs"",
-  ""version"": ""6.2.2"",
+  ""version"": ""6.2.3"",
   ""description"": ""Modern, fast, powerful node.js web framework"",
   ""scripts"": {
diff --git a/packages/common/pipes/validation.pipe.ts b/packages/common/pipes/validation.pipe.ts
index 84a68586b..ea7bda2bf 100644
--- a/packages/common/pipes/validation.pipe.ts
+++ b/packages/common/pipes/validation.pipe.ts
@@ -1,5 +1,9 @@
 import { Optional } from '../decorators';
 import { Injectable } from '../decorators/core';
-import { ArgumentMetadata, BadRequestException, ValidationError } from '../index';
+import {
+  ArgumentMetadata,
+  BadRequestException,
+  ValidationError,
+} from '../index';
 import { ClassTransformOptions } from '../interfaces/external/class-transform-options.interface';
 import { ValidatorOptions } from '../interfaces/external/validator-options.interface';
@@ -58,8 +62,11 @@ export class ValidationPipe implements PipeTransform<any> {
       return value;
     }
+    value = this.toEmptyIfNil(value);
+
+    this.stripProtoKeys(value);
     const entity = classTransformer.plainToClass(
       metatype,
-      this.toEmptyIfNil(value),
-      this.transformOptions
+      value,
+      this.transformOptions,
     );
     const errors = await classValidator.validate(entity, this.validatorOptions);
@@ -70,6 +77,6 @@ export class ValidationPipe implements PipeTransform<any> {
       ? entity
       : Object.keys(this.validatorOptions).length > 0
-        ? classTransformer.classToPlain(entity, this.transformOptions)
-        : value;
+      ? classTransformer.classToPlain(entity, this.transformOptions)
+      : value;
   }
 
@@ -83,6 +90,14 @@ export class ValidationPipe implements PipeTransform<any> {
   }
 
-  toEmptyIfNil<T = any, R = any>(value: T): R | {} {
+  private toEmptyIfNil<T = any, R = any>(value: T): R | {} {
     return isNil(value) ? {} : value;
   }
+
+  private stripProtoKeys(value: Record<string, any>) {
+    delete value.__proto__;
+    const keys = Object.keys(value);
+    keys
+      .filter(key => typeof value[key] === 'object')
+      .forEach(key => this.stripProtoKeys(value[key]));
+  }
 }
","hotfix(): fix validation pipe (strip proto properties)

"
1292,TypeScript,de7140853140029a3f48600b60e700464e7662b5,https://github.com/vitejs/vite/commit/de7140853140029a3f48600b60e700464e7662b5,P,vitejs,vite,"[1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/packages/plugin-legacy/index.js b/packages/plugin-legacy/index.js
index c91286be..ba8acc10 100644
--- a/packages/plugin-legacy/index.js
+++ b/packages/plugin-legacy/index.js
@@ -21,5 +21,5 @@ const systemJSInlineCode = `System.import(document.getElementById('${legacyEntry
 const dynamicFallbackInlineCode = `!function(){try{new Function(""m"",""return import(m)"")}catch(o){console.warn(""vite: loading legacy build because dynamic import is unsupported, syntax error above should be ignored"");var e=document.getElementById(""${legacyPolyfillId}""),n=document.createElement(""script"");n.src=e.src,n.onload=function(){${systemJSInlineCode}},document.body.appendChild(n)}}();`
 
-const blankDynamicImport = `import('data:text/javascript;base64,Cg==');`
+const forceDynamicImportUsage = `export function __vite_legacy_guard(){import('data:text/javascript,')};`
 
 const legacyEnvVarMarker = `__VITE_IS_LEGACY__`
@@ -239,5 +239,5 @@ function viteLegacyPlugin(options = {}) {
 
         if (genDynamicFallback && chunk.isEntry) {
-          ms.prepend(blankDynamicImport)
+          ms.prepend(forceDynamicImportUsage)
         }
 
","fix(plugin-legacy): avoid executing blank dynamic import (#4767)

Closes #4568
"
1299,TypeScript,8c0412cc310afb1ef05e87a65d09a40e60f4ece2,https://github.com/vitejs/vite/commit/8c0412cc310afb1ef05e87a65d09a40e60f4ece2,P,vitejs,vite,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]","diff --git a/CHANGELOG.md b/CHANGELOG.md
index 72d95282..f2c9ef6f 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -1,2 +1,6 @@
+# [1.0.0-beta.4](https://github.com/vuejs/vite/compare/v1.0.0-beta.3...v1.0.0-beta.4) (2020-06-22)
+
+
+
 # [1.0.0-beta.3](https://github.com/vuejs/vite/compare/v1.0.0-beta.1...v1.0.0-beta.3) (2020-06-22)
 
","chore: changelog [ci skip]

"
1300,TypeScript,cb5c3f99bfe8ea1f4b43a1d81030b95bc704720b,https://github.com/vitejs/vite/commit/cb5c3f99bfe8ea1f4b43a1d81030b95bc704720b,P,vitejs,vite,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 2, 0, 0, 0, 0, 0, 0]","diff --git a/packages/vite/CHANGELOG.md b/packages/vite/CHANGELOG.md
index b011910c..822d801d 100644
--- a/packages/vite/CHANGELOG.md
+++ b/packages/vite/CHANGELOG.md
@@ -1,2 +1,8 @@
+## <small>2.9.3 (2022-04-13)</small>
+
+* fix: revert #7665 (#7716) ([26862c4](https://github.com/vitejs/vite/commit/26862c4)), closes [#7665](https://github.com/vitejs/vite/issues/7665) [#7716](https://github.com/vitejs/vite/issues/7716)
+
+
+
 ## <small>2.9.2 (2022-04-13)</small>
 
diff --git a/packages/vite/package.json b/packages/vite/package.json
index 1a749f66..eeecf5b2 100644
--- a/packages/vite/package.json
+++ b/packages/vite/package.json
@@ -1,5 +1,5 @@
 {
   ""name"": ""vite"",
-  ""version"": ""2.9.2"",
+  ""version"": ""2.9.3"",
   ""license"": ""MIT"",
   ""author"": ""Evan You"",
","release: v2.9.3

"
1302,TypeScript,a9687954872be4e33faaee203261f882d003f493,https://github.com/vitejs/vite/commit/a9687954872be4e33faaee203261f882d003f493,P,vitejs,vite,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 5, 2, 2, 0, 0, 0, 0]","diff --git a/.github/ISSUE_TEMPLATE/bug_report.md b/.github/ISSUE_TEMPLATE/bug_report.md
index 433a21ff..fe69510c 100644
--- a/.github/ISSUE_TEMPLATE/bug_report.md
+++ b/.github/ISSUE_TEMPLATE/bug_report.md
@@ -8,7 +8,11 @@ assignees: ''
 ---
 
-## Before you continue...
+<!--
+Before you continue...
 
 If you just upgraded Vite and suddenly everything stops working, try opening the Network tab in your browser devtools, tick ""disable cache"" and refresh the page.
+-->
+
+> Do NOT ignore this template or your issue will have a very high chance to be closed without comment.
 
 ## Describe the bug
@@ -16,4 +20,10 @@ If you just upgraded Vite and suddenly everything stops working, try opening the
 A clear and concise description of what the bug is.
 
+## Reproduction
+
+Please provide a link to a repo that can reproduce the problem you ran into.
+
+A reproduction is **required** unless you are absolutely sure that the the problem is obvious and the information you provided is enough for us to understand what the problem is. If a report has only vague description (e.g. just a generic error message) and has no reproduction, it will be closed immediately.
+
 ## System Info
 
@@ -26,10 +36,6 @@ A clear and concise description of what the bug is.
   - Installed `@vue/compiler-sfc` version
 
-## Logs
+## Logs (Optional if provided reproduction)
 
 1. Run `vite` or `vite build` with the `--debug` flag.
 2. Provide the error log here.
-
-## Reproduction
-
-Provide a link to a reproduction repo if applicable.
","chore: tweak issue template

"
1315,TypeScript,0c67194b455a176f132e4139d72415741f897d26,https://github.com/grafana/grafana/commit/0c67194b455a176f132e4139d72415741f897d26,P,grafana,grafana,"[2, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/pkg/cmd/grafana-server/server.go b/pkg/cmd/grafana-server/server.go
index a1db5cd4b4..e27db3d874 100644
--- a/pkg/cmd/grafana-server/server.go
+++ b/pkg/cmd/grafana-server/server.go
@@ -31,4 +31,5 @@ import (
 	_ ""github.com/grafana/grafana/pkg/infra/metrics""
 	_ ""github.com/grafana/grafana/pkg/infra/serverlock""
+	_ ""github.com/grafana/grafana/pkg/infra/tracing""
 	_ ""github.com/grafana/grafana/pkg/plugins""
 	_ ""github.com/grafana/grafana/pkg/services/alerting""
@@ -40,5 +41,4 @@ import (
 	_ ""github.com/grafana/grafana/pkg/services/search""
 	_ ""github.com/grafana/grafana/pkg/services/sqlstore""
-	_ ""github.com/grafana/grafana/pkg/tracing""
 )
 
diff --git a/pkg/tracing/tracing.go b/pkg/infra/tracing/tracing.go
similarity index 100%
rename from pkg/tracing/tracing.go
rename to pkg/infra/tracing/tracing.go
diff --git a/pkg/tracing/tracing_test.go b/pkg/infra/tracing/tracing_test.go
similarity index 100%
rename from pkg/tracing/tracing_test.go
rename to pkg/infra/tracing/tracing_test.go
","moves tracing packge into /infra

"
1330,TypeScript,cc7d04ed793d8de1a3f4e17ce4fc79e6d81047e9,https://github.com/apache/echarts/commit/cc7d04ed793d8de1a3f4e17ce4fc79e6d81047e9,C,apache,echarts,"[2, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/src/chart/line/LineSeries.js b/src/chart/line/LineSeries.js
index 38f60b8ba..b55e47379 100644
--- a/src/chart/line/LineSeries.js
+++ b/src/chart/line/LineSeries.js
@@ -9,6 +9,6 @@ define(function(require) {
         type: 'line',
 
-        getInitialData: function (option) {
-            return List.fromArray(option.data, 1, this);
+        getInitialData: function (option, ecModel) {
+            return List.fromArray(option.data, this, ecModel);
         },
 
diff --git a/src/chart/line/LineView.js b/src/chart/line/LineView.js
index 4101830e1..38918baa1 100644
--- a/src/chart/line/LineView.js
+++ b/src/chart/line/LineView.js
@@ -30,6 +30,6 @@ define(function(require) {
                 var xAxis = cartesian.getAxis('x');
                 var yAxis = cartesian.getAxis('y');
-                var xExtent = xAxis.getCoordExtent();
-                var yExtent = yAxis.getCoordExtent();
+                var xExtent = xAxis.getExtent();
+                var yExtent = yAxis.getExtent();
 
                 var clipPath = new api.Rect({
","Fix line

"
1333,Java,990ddf5896045704ec43ac0e5a3e2df7022fed12,,A,kiegroup,drools,"[5, 157, 4, 4, 0, 0, 0, 2, 172, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 30, 0, 0]","diff --git a/drools-compiler/src/main/java/org/drools/xml/ProcessSemanticModule.java b/drools-compiler/src/main/java/org/drools/xml/ProcessSemanticModule.java
index f9d4407309..4969dd5a68 100644
--- a/drools-compiler/src/main/java/org/drools/xml/ProcessSemanticModule.java
+++ b/drools-compiler/src/main/java/org/drools/xml/ProcessSemanticModule.java
@@ -7,4 +7,5 @@ import org.drools.xml.processes.ConstraintHandler;
 import org.drools.xml.processes.EndNodeHandler;
 import org.drools.xml.processes.GlobalHandler;
+import org.drools.xml.processes.HumanTaskNodeHandler;
 import org.drools.xml.processes.ImportHandler;
 import org.drools.xml.processes.InPortHandler;
@@ -19,4 +20,5 @@ import org.drools.xml.processes.SplitNodeHandler;
 import org.drools.xml.processes.StartNodeHandler;
 import org.drools.xml.processes.SubProcessNodeHandler;
+import org.drools.xml.processes.SwimlaneHandler;
 import org.drools.xml.processes.TimerNodeHandler;
 import org.drools.xml.processes.TypeHandler;
@@ -52,4 +54,6 @@ public class ProcessSemanticModule extends DefaultSemanticModule implements Sema
         addHandler( ""timer"",
                            new TimerNodeHandler() );
+        addHandler( ""humanTask"",
+                           new HumanTaskNodeHandler() );
         addHandler( ""composite"",
                            new CompositeNodeHandler() );
@@ -62,4 +66,6 @@ public class ProcessSemanticModule extends DefaultSemanticModule implements Sema
         addHandler( ""variable"",
                            new VariableHandler() );        
+        addHandler( ""swimlane"",
+                           new SwimlaneHandler() );        
         addHandler( ""type"",
                            new TypeHandler() );        
diff --git a/drools-compiler/src/main/java/org/drools/xml/XmlWorkflowProcessDumper.java b/drools-compiler/src/main/java/org/drools/xml/XmlWorkflowProcessDumper.java
index 12bccde50e..bd4272c12b 100644
--- a/drools-compiler/src/main/java/org/drools/xml/XmlWorkflowProcessDumper.java
+++ b/drools-compiler/src/main/java/org/drools/xml/XmlWorkflowProcessDumper.java
@@ -2,7 +2,10 @@ package org.drools.xml;
 
 import java.util.ArrayList;
+import java.util.Collection;
 import java.util.List;
 import java.util.Map;
 
+import org.drools.process.core.context.swimlane.Swimlane;
+import org.drools.process.core.context.swimlane.SwimlaneContext;
 import org.drools.process.core.context.variable.Variable;
 import org.drools.process.core.context.variable.VariableScope;
@@ -79,4 +82,8 @@ public class XmlWorkflowProcessDumper {
             visitVariables(variableScope.getVariables(), xmlDump);
         }
+        SwimlaneContext swimlaneContext = (SwimlaneContext) process.getDefaultContext(SwimlaneContext.SWIMLANE_SCOPE);
+        if (swimlaneContext != null) {
+            visitSwimlanes(swimlaneContext.getSwimlanes(), xmlDump);
+        }
         xmlDump.append(""  </header>"" + EOL + EOL);
     }
@@ -118,4 +125,14 @@ public class XmlWorkflowProcessDumper {
     }
     
+    private void visitSwimlanes(Collection<Swimlane> swimlanes, StringBuffer xmlDump) {
+        if (swimlanes != null && swimlanes.size() > 0) {
+            xmlDump.append(""    <swimlanes>"" + EOL);
+            for (Swimlane swimlane: swimlanes) {
+                xmlDump.append(""      <swimlane name=\"""" + swimlane.getName() + ""\"" />"" + EOL);
+            }
+            xmlDump.append(""    </swimlanes>"" + EOL);
+        }
+    }
+    
     private void visitDataType(DataType dataType, StringBuffer xmlDump) {
         xmlDump.append(""        <type name=\"""" + dataType.getClass().getName() + ""\"" />"" + EOL);
diff --git a/drools-compiler/src/main/java/org/drools/xml/processes/HumanTaskNodeHandler.java b/drools-compiler/src/main/java/org/drools/xml/processes/HumanTaskNodeHandler.java
new file mode 100644
index 0000000000..0f0cd84370
--- /dev/null
+++ b/drools-compiler/src/main/java/org/drools/xml/processes/HumanTaskNodeHandler.java
@@ -0,0 +1,53 @@
+package org.drools.xml.processes;
+
+import org.drools.process.core.Work;
+import org.drools.workflow.core.Node;
+import org.drools.workflow.core.node.HumanTaskNode;
+import org.drools.workflow.core.node.WorkItemNode;
+import org.drools.xml.ExtensibleXmlParser;
+import org.w3c.dom.Element;
+import org.xml.sax.SAXException;
+
+public class HumanTaskNodeHandler extends WorkItemNodeHandler {
+
+    public void handleNode(final Node node, final Element element, final String uri,
+            final String localName, final ExtensibleXmlParser parser)
+            throws SAXException {
+        super.handleNode(node, element, uri, localName, parser);
+        HumanTaskNode humanTaskNode = (HumanTaskNode) node;
+        final String swimlane = element.getAttribute(""swimlane"");
+        if (swimlane != null && !"""".equals(swimlane)) {
+            humanTaskNode.setSwimlane(swimlane);
+        }
+    }
+
+    protected Node createNode() {
+        return new HumanTaskNode();
+    }
+
+    public Class generateNodeFor() {
+        return HumanTaskNode.class;
+    }
+
+    public void writeNode(Node node, StringBuffer xmlDump, boolean includeMeta) {
+        WorkItemNode workItemNode = (WorkItemNode) node;
+        writeNode(""humanTask"", workItemNode, xmlDump, includeMeta);
+        visitParameters(workItemNode, xmlDump);
+        xmlDump.append("">"" + EOL);
+        Work work = workItemNode.getWork();
+        visitWork(work, xmlDump, includeMeta);
+        visitInMappings(workItemNode.getInMappings(), xmlDump);
+        visitOutMappings(workItemNode.getOutMappings(), xmlDump);
+        endNode(""humanTask"", xmlDump);
+    }
+    
+	protected void visitParameters(WorkItemNode workItemNode, StringBuffer xmlDump) {
+	    super.visitParameters(workItemNode, xmlDump);
+	    HumanTaskNode humanTaskNode = (HumanTaskNode) workItemNode;
+	    String swimlane = humanTaskNode.getSwimlane();
+	    if (swimlane != null) {
+	        xmlDump.append(""swimlane=\"""" + swimlane + ""\"" "");
+	    }
+	}
+    
+}
diff --git a/drools-compiler/src/main/java/org/drools/xml/processes/SwimlaneHandler.java b/drools-compiler/src/main/java/org/drools/xml/processes/SwimlaneHandler.java
new file mode 100644
index 0000000000..9ad5da8d54
--- /dev/null
+++ b/drools-compiler/src/main/java/org/drools/xml/processes/SwimlaneHandler.java
@@ -0,0 +1,67 @@
+package org.drools.xml.processes;
+
+import java.util.HashSet;
+
+import org.drools.process.core.Process;
+import org.drools.process.core.context.swimlane.Swimlane;
+import org.drools.process.core.context.swimlane.SwimlaneContext;
+import org.drools.workflow.core.impl.WorkflowProcessImpl;
+import org.drools.xml.BaseAbstractHandler;
+import org.drools.xml.ExtensibleXmlParser;
+import org.drools.xml.Handler;
+import org.xml.sax.Attributes;
+import org.xml.sax.SAXException;
+import org.xml.sax.SAXParseException;
+
+public class SwimlaneHandler extends BaseAbstractHandler
+    implements
+    Handler {
+    public SwimlaneHandler() {
+        if ( (this.validParents == null) && (this.validPeers == null) ) {
+            this.validParents = new HashSet();
+            this.validParents.add( Process.class );
+
+            this.validPeers = new HashSet();         
+            this.validPeers.add( null );            
+
+            this.allowNesting = false;
+        }
+    }
+    
+
+    
+    public Object start(final String uri,
+                        final String localName,
+                        final Attributes attrs,
+                        final ExtensibleXmlParser parser) throws SAXException {
+        parser.startElementBuilder( localName,
+                                    attrs );
+        WorkflowProcessImpl process = (WorkflowProcessImpl) parser.getParent();
+        final String name = attrs.getValue(""name"");
+        emptyAttributeCheck(localName, ""name"", name, parser);
+        
+        SwimlaneContext swimlaneContext = (SwimlaneContext) 
+            process.getDefaultContext(SwimlaneContext.SWIMLANE_SCOPE);
+        if (swimlaneContext != null) {
+            Swimlane swimlane = new Swimlane(name);
+            swimlaneContext.addSwimlane(swimlane);
+        } else {
+            throw new SAXParseException(
+                ""Could not find default swimlane context."", parser.getLocator());
+        }
+        
+        return null;
+    }    
+    
+    public Object end(final String uri,
+                      final String localName,
+                      final ExtensibleXmlParser parser) throws SAXException {
+        parser.endElementBuilder();
+        return null;
+    }
+
+    public Class generateNodeFor() {
+        return Swimlane.class;
+    }    
+
+}
diff --git a/drools-compiler/src/main/java/org/drools/xml/processes/WorkItemNodeHandler.java b/drools-compiler/src/main/java/org/drools/xml/processes/WorkItemNodeHandler.java
index 91ad673494..f4628f3df5 100644
--- a/drools-compiler/src/main/java/org/drools/xml/processes/WorkItemNodeHandler.java
+++ b/drools-compiler/src/main/java/org/drools/xml/processes/WorkItemNodeHandler.java
@@ -33,13 +33,20 @@ public class WorkItemNodeHandler extends AbstractNodeHandler {
 		WorkItemNode workItemNode = (WorkItemNode) node;
 		writeNode(""workItem"", workItemNode, xmlDump, includeMeta);
-        if (!workItemNode.isWaitForCompletion()) {
-            xmlDump.append(""waitForCompletion=\""false\"" "");
-        }
+        visitParameters(workItemNode, xmlDump);
         xmlDump.append("">"" + EOL);
         Work work = workItemNode.getWork();
-        if (work != null) {
-            visitWork(work, xmlDump, includeMeta);
+        visitWork(work, xmlDump, includeMeta);
+        visitInMappings(workItemNode.getInMappings(), xmlDump);
+        visitOutMappings(workItemNode.getOutMappings(), xmlDump);
+        endNode(""workItem"", xmlDump);
+	}
+	
+	protected void visitParameters(WorkItemNode workItemNode, StringBuffer xmlDump) {
+	    if (!workItemNode.isWaitForCompletion()) {
+            xmlDump.append(""waitForCompletion=\""false\"" "");
         }
-        Map<String, String> inMappings = workItemNode.getInMappings();
+	}
+	
+	protected void visitInMappings(Map<String, String> inMappings, StringBuffer xmlDump) {
         for (Map.Entry<String, String> inMapping: inMappings.entrySet()) {
             xmlDump.append(
@@ -48,5 +55,7 @@ public class WorkItemNodeHandler extends AbstractNodeHandler {
                              + ""to=\"""" + inMapping.getKey() + ""\"" />"" + EOL);
         }
-        Map<String, String> outMappings = workItemNode.getOutMappings();
+	}
+	
+	protected void visitOutMappings(Map<String, String> outMappings, StringBuffer xmlDump) {
         for (Map.Entry<String, String> outMapping: outMappings.entrySet()) {
             xmlDump.append(
@@ -55,25 +64,26 @@ public class WorkItemNodeHandler extends AbstractNodeHandler {
                              + ""to=\"""" + outMapping.getValue() + ""\"" />"" + EOL);
         }
-        endNode(""workItem"", xmlDump);
     }
     
-    private void visitWork(Work work, StringBuffer xmlDump, boolean includeMeta) {
-        xmlDump.append(""      <work name=\"""" + work.getName() + ""\"" >"" + EOL);
-        for (ParameterDefinition paramDefinition: work.getParameterDefinitions()) {
-            if (paramDefinition == null) {
-                throw new IllegalArgumentException(
-                    ""Could not find parameter definition "" + paramDefinition.getName()
-                        + "" for work "" + work.getName());
-            }
-            xmlDump.append(""        <parameter name=\"""" + paramDefinition.getName() + ""\"" "" + 
-                                              ""type=\"""" + paramDefinition.getType().getClass().getName() + ""\"" "");
-            Object value = work.getParameter(paramDefinition.getName());
-            if (value == null) {
-                xmlDump.append(""/>"" + EOL);
-            } else {
-                xmlDump.append("">"" + value + ""</parameter>"" + EOL);
+    protected void visitWork(Work work, StringBuffer xmlDump, boolean includeMeta) {
+        if (work != null) {
+            xmlDump.append(""      <work name=\"""" + work.getName() + ""\"" >"" + EOL);
+            for (ParameterDefinition paramDefinition: work.getParameterDefinitions()) {
+                if (paramDefinition == null) {
+                    throw new IllegalArgumentException(
+                        ""Could not find parameter definition "" + paramDefinition.getName()
+                            + "" for work "" + work.getName());
+                }
+                xmlDump.append(""        <parameter name=\"""" + paramDefinition.getName() + ""\"" "" + 
+                                                  ""type=\"""" + paramDefinition.getType().getClass().getName() + ""\"" "");
+                Object value = work.getParameter(paramDefinition.getName());
+                if (value == null) {
+                    xmlDump.append(""/>"" + EOL);
+                } else {
+                    xmlDump.append("">"" + value + ""</parameter>"" + EOL);
+                }
             }
+            xmlDump.append(""      </work>"" + EOL);
         }
-        xmlDump.append(""      </work>"" + EOL);
     }
 }
diff --git a/drools-compiler/src/main/resources/META-INF/drools-processes-4.0.xsd b/drools-compiler/src/main/resources/META-INF/drools-processes-4.0.xsd
index 65a1fd188c..a8fab793d0 100644
--- a/drools-compiler/src/main/resources/META-INF/drools-processes-4.0.xsd
+++ b/drools-compiler/src/main/resources/META-INF/drools-processes-4.0.xsd
@@ -22,4 +22,5 @@
 				<xs:element ref=""drools:globals""/>
 				<xs:element ref=""drools:variables""/>
+				<xs:element ref=""drools:swimlanes""/>
 			</xs:choice>
 		</xs:complexType>
@@ -78,4 +79,16 @@
 		</xs:complexType>
 	</xs:element>
+	<xs:element name=""swimlanes"">
+		<xs:complexType>
+			<xs:sequence minOccurs=""0"" maxOccurs=""unbounded"">
+				<xs:element ref=""drools:swimlane""/>
+			</xs:sequence>
+		</xs:complexType>
+	</xs:element>
+	<xs:element name=""swimlane"">
+		<xs:complexType>
+			<xs:attribute name=""name"" type=""xs:string"" use=""required""/>
+		</xs:complexType>
+	</xs:element>
 	<xs:element name=""nodes"">
 		<xs:complexType>
@@ -91,4 +104,5 @@
 				<xs:element ref=""drools:workItem""/>
 				<xs:element ref=""drools:timer""/>
+				<xs:element ref=""drools:humanTask""/>
 				<xs:element ref=""drools:composite""/>
 			</xs:choice>
@@ -269,4 +283,20 @@
 		</xs:complexType>
 	</xs:element>
+	<xs:element name=""humanTask"">
+		<xs:complexType>
+			<xs:choice minOccurs=""0"" maxOccurs=""unbounded"">
+				<xs:element ref=""drools:work""/>
+				<xs:element ref=""drools:mapping""/>
+			</xs:choice>
+			<xs:attribute name=""id"" type=""xs:string"" use=""required""/>
+			<xs:attribute name=""name"" type=""xs:string""/>
+			<xs:attribute name=""x"" type=""xs:string""/>
+			<xs:attribute name=""y"" type=""xs:string""/>
+			<xs:attribute name=""width"" type=""xs:string""/>
+			<xs:attribute name=""height"" type=""xs:string""/>
+			<xs:attribute name=""waitForCompletion"" type=""xs:string""/>
+			<xs:attribute name=""swimlane"" type=""xs:string""/>
+		</xs:complexType>
+	</xs:element>
 	<xs:element name=""composite"">
 		<xs:complexType>
diff --git a/drools-compiler/src/test/java/org/drools/integrationtests/ProcessHumanTaskTest.java b/drools-compiler/src/test/java/org/drools/integrationtests/ProcessHumanTaskTest.java
new file mode 100644
index 0000000000..3cd48fbd66
--- /dev/null
+++ b/drools-compiler/src/test/java/org/drools/integrationtests/ProcessHumanTaskTest.java
@@ -0,0 +1,150 @@
+package org.drools.integrationtests;
+
+import java.io.Reader;
+import java.io.StringReader;
+import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+
+import org.drools.RuleBase;
+import org.drools.RuleBaseFactory;
+import org.drools.WorkingMemory;
+import org.drools.compiler.PackageBuilder;
+import org.drools.process.instance.ProcessInstance;
+import org.drools.process.instance.WorkItem;
+import org.drools.process.instance.WorkItemHandler;
+import org.drools.process.instance.WorkItemManager;
+import org.drools.rule.Package;
+
+import junit.framework.TestCase;
+
+public class ProcessHumanTaskTest extends TestCase {
+    
+    public void testHumanTask() {
+        PackageBuilder builder = new PackageBuilder();
+        Reader source = new StringReader(
+            ""<?xml version=\""1.0\"" encoding=\""UTF-8\""?>\n"" +
+            ""<process xmlns=\""http://drools.org/drools-4.0/process\""\n"" +
+            ""         xmlns:xs=\""http://www.w3.org/2001/XMLSchema-instance\""\n"" +
+            ""         xs:schemaLocation=\""http://drools.org/drools-4.0/process drools-processes-4.0.xsd\""\n"" +
+            ""         type=\""RuleFlow\"" name=\""flow\"" id=\""org.drools.humantask\"" package-name=\""org.drools\"" version=\""1\"" >\n"" +
+            ""\n"" +
+            ""  <header>\n"" +
+            ""  </header>\n"" +
+            ""\n"" +
+            ""  <nodes>\n"" +
+            ""    <start id=\""1\"" name=\""Start\"" />\n"" +
+            ""    <humanTask id=\""2\"" name=\""HumanTask\"" >\n"" +
+            ""      <work name=\""Human Task\"" >\n"" +
+            ""        <parameter name=\""ActorId\"" type=\""org.drools.process.core.datatype.impl.type.StringDataType\"" >John Doe</parameter>\n"" +
+            ""        <parameter name=\""TaskName\"" type=\""org.drools.process.core.datatype.impl.type.StringDataType\"" >Do something</parameter>\n"" +
+            ""        <parameter name=\""Priority\"" type=\""org.drools.process.core.datatype.impl.type.StringDataType\"" />\n"" +
+            ""        <parameter name=\""Comment\"" type=\""org.drools.process.core.datatype.impl.type.StringDataType\"" />\n"" +
+            ""      </work>\n"" +
+            ""    </humanTask>\n"" +
+            ""    <end id=\""3\"" name=\""End\"" />\n"" +
+            ""  </nodes>\n"" +
+            ""\n"" +
+            ""  <connections>\n"" +
+            ""    <connection from=\""1\"" to=\""2\"" />\n"" +
+            ""    <connection from=\""2\"" to=\""3\"" />\n"" +
+            ""  </connections>\n"" +
+            ""\n"" +
+            ""</process>"");
+        builder.addRuleFlow(source);
+        Package pkg = builder.getPackage();
+        RuleBase ruleBase = RuleBaseFactory.newRuleBase();
+        ruleBase.addPackage( pkg );
+        WorkingMemory workingMemory = ruleBase.newStatefulSession();
+        TestWorkItemHandler handler = new TestWorkItemHandler();
+        workingMemory.getWorkItemManager().registerWorkItemHandler(""Human Task"", handler);
+        ProcessInstance processInstance =
+            workingMemory.startProcess(""org.drools.humantask"");
+        assertEquals(ProcessInstance.STATE_ACTIVE, processInstance.getState());
+        WorkItem workItem = handler.getWorkItem();
+        assertNotNull(workItem);
+        workingMemory.getWorkItemManager().completeWorkItem(workItem.getId(), null);
+        assertEquals(ProcessInstance.STATE_COMPLETED, processInstance.getState());
+    }
+    
+    public void testSwimlane() {
+        PackageBuilder builder = new PackageBuilder();
+        Reader source = new StringReader(
+            ""<?xml version=\""1.0\"" encoding=\""UTF-8\""?>\n"" +
+            ""<process xmlns=\""http://drools.org/drools-4.0/process\""\n"" +
+            ""         xmlns:xs=\""http://www.w3.org/2001/XMLSchema-instance\""\n"" +
+            ""         xs:schemaLocation=\""http://drools.org/drools-4.0/process drools-processes-4.0.xsd\""\n"" +
+            ""         type=\""RuleFlow\"" name=\""flow\"" id=\""org.drools.humantask\"" package-name=\""org.drools\"" version=\""1\"" >\n"" +
+            ""\n"" +
+            ""  <header>\n"" +
+            ""    <swimlanes>\n"" +
+            ""      <swimlane name=\""actor1\"" />\n"" +
+            ""    </swimlanes>\n"" +
+            ""  </header>\n"" +
+            ""\n"" +
+            ""  <nodes>\n"" +
+            ""    <start id=\""1\"" name=\""Start\"" />\n"" +
+            ""    <humanTask id=\""2\"" name=\""HumanTask\"" swimlane=\""actor1\"" >\n"" +
+            ""      <work name=\""Human Task\"" >\n"" +
+            ""        <parameter name=\""ActorId\"" type=\""org.drools.process.core.datatype.impl.type.StringDataType\"" >John Doe</parameter>\n"" +
+            ""        <parameter name=\""TaskName\"" type=\""org.drools.process.core.datatype.impl.type.StringDataType\"" >Do something</parameter>\n"" +
+            ""        <parameter name=\""Priority\"" type=\""org.drools.process.core.datatype.impl.type.StringDataType\"" />\n"" +
+            ""        <parameter name=\""Comment\"" type=\""org.drools.process.core.datatype.impl.type.StringDataType\"" />\n"" +
+            ""      </work>\n"" +
+            ""    </humanTask>\n"" +
+            ""    <humanTask id=\""3\"" name=\""HumanTask\"" swimlane=\""actor1\"" >\n"" +
+            ""      <work name=\""Human Task\"" >\n"" +
+            ""        <parameter name=\""ActorId\"" type=\""org.drools.process.core.datatype.impl.type.StringDataType\"" />\n"" +
+            ""        <parameter name=\""TaskName\"" type=\""org.drools.process.core.datatype.impl.type.StringDataType\"" >Do something else</parameter>\n"" +
+            ""        <parameter name=\""Priority\"" type=\""org.drools.process.core.datatype.impl.type.StringDataType\"" />\n"" +
+            ""        <parameter name=\""Comment\"" type=\""org.drools.process.core.datatype.impl.type.StringDataType\"" />\n"" +
+            ""      </work>\n"" +
+            ""    </humanTask>\n"" +
+            ""    <end id=\""4\"" name=\""End\"" />\n"" +
+            ""  </nodes>\n"" +
+            ""\n"" +
+            ""  <connections>\n"" +
+            ""    <connection from=\""1\"" to=\""2\"" />\n"" +
+            ""    <connection from=\""2\"" to=\""3\"" />\n"" +
+            ""    <connection from=\""3\"" to=\""4\"" />\n"" +
+            ""  </connections>\n"" +
+            ""\n"" +
+            ""</process>"");
+        builder.addRuleFlow(source);
+        Package pkg = builder.getPackage();
+        RuleBase ruleBase = RuleBaseFactory.newRuleBase();
+        ruleBase.addPackage( pkg );
+        WorkingMemory workingMemory = ruleBase.newStatefulSession();
+        TestWorkItemHandler handler = new TestWorkItemHandler();
+        workingMemory.getWorkItemManager().registerWorkItemHandler(""Human Task"", handler);
+        ProcessInstance processInstance =
+            workingMemory.startProcess(""org.drools.humantask"");
+        assertEquals(ProcessInstance.STATE_ACTIVE, processInstance.getState());
+        WorkItem workItem = handler.getWorkItem();
+        assertNotNull(workItem);
+        assertEquals(""Do something"", workItem.getParameter(""TaskName""));
+        assertEquals(""John Doe"", workItem.getParameter(""ActorId""));
+        Map<String, Object> results = new HashMap<String, Object>();
+        results.put(""ActorId"", ""Jane Doe"");
+        workingMemory.getWorkItemManager().completeWorkItem(workItem.getId(), results);
+        workItem = handler.getWorkItem();
+        assertNotNull(workItem);
+        assertEquals(""Do something else"", workItem.getParameter(""TaskName""));
+        assertEquals(""Jane Doe"", workItem.getParameter(""ActorId""));
+        workingMemory.getWorkItemManager().completeWorkItem(workItem.getId(), null);
+        assertEquals(ProcessInstance.STATE_COMPLETED, processInstance.getState());
+    }
+
+    private static class TestWorkItemHandler implements WorkItemHandler {
+        private WorkItem workItem;
+        public void executeWorkItem(WorkItem workItem, WorkItemManager manager) {
+            this.workItem = workItem;
+        }
+        public void abortWorkItem(WorkItem workItem, WorkItemManager manager) {
+        }
+        public WorkItem getWorkItem() {
+            return workItem;
+        }
+    }
+}
diff --git a/drools-compiler/src/test/java/org/drools/xml/processes/XMLPersistenceTest.java b/drools-compiler/src/test/java/org/drools/xml/processes/XMLPersistenceTest.java
index 63dc64f742..c1e4e01c26 100644
--- a/drools-compiler/src/test/java/org/drools/xml/processes/XMLPersistenceTest.java
+++ b/drools-compiler/src/test/java/org/drools/xml/processes/XMLPersistenceTest.java
@@ -14,4 +14,5 @@ import org.drools.compiler.PackageBuilderConfiguration;
 import org.drools.process.core.ParameterDefinition;
 import org.drools.process.core.Work;
+import org.drools.process.core.context.swimlane.Swimlane;
 import org.drools.process.core.context.variable.Variable;
 import org.drools.process.core.datatype.impl.type.IntegerDataType;
@@ -29,4 +30,5 @@ import org.drools.workflow.core.impl.DroolsConsequenceAction;
 import org.drools.workflow.core.node.ActionNode;
 import org.drools.workflow.core.node.EndNode;
+import org.drools.workflow.core.node.HumanTaskNode;
 import org.drools.workflow.core.node.Join;
 import org.drools.workflow.core.node.MilestoneNode;
@@ -61,4 +63,5 @@ public class XMLPersistenceTest extends TestCase {
         process.addNode(new WorkItemNode());
         process.addNode(new TimerNode());
+        process.addNode(new HumanTaskNode());
         
         String xml = XmlRuleFlowProcessDumper.INSTANCE.dump(process, false);
@@ -77,5 +80,5 @@ public class XMLPersistenceTest extends TestCase {
         }
         
-        assertEquals(10, process.getNodes().length);
+        assertEquals(11, process.getNodes().length);
         
 //        System.out.println(""************************************"");
@@ -125,4 +128,7 @@ public class XMLPersistenceTest extends TestCase {
         process.getVariableScope().setVariables(variables);
         
+        process.getSwimlaneContext().addSwimlane(new Swimlane(""actor1""));
+        process.getSwimlaneContext().addSwimlane(new Swimlane(""actor2""));
+        
         StartNode startNode = new StartNode();
         startNode.setName(""start"");
@@ -188,5 +194,4 @@ public class XMLPersistenceTest extends TestCase {
         new ConnectionImpl(actionNode, Node.CONNECTION_DEFAULT_TYPE, join, Node.CONNECTION_DEFAULT_TYPE);
         new ConnectionImpl(ruleSetNode, Node.CONNECTION_DEFAULT_TYPE, join, Node.CONNECTION_DEFAULT_TYPE);
-
         
         MilestoneNode milestone = new MilestoneNode();
@@ -235,4 +240,22 @@ public class XMLPersistenceTest extends TestCase {
         connection.setMetaData(""bendpoints"", ""[]"");
         
+        HumanTaskNode humanTaskNode = new HumanTaskNode();
+        work = humanTaskNode.getWork();
+        parameterDefinitions = new HashSet<ParameterDefinition>();
+        parameterDefinition = new ParameterDefinitionImpl(""TaskName"", new StringDataType());
+        parameterDefinitions.add(parameterDefinition);
+        parameterDefinition = new ParameterDefinitionImpl(""ActorId"", new StringDataType());
+        parameterDefinitions.add(parameterDefinition);
+        parameterDefinition = new ParameterDefinitionImpl(""Priority"", new StringDataType());
+        parameterDefinitions.add(parameterDefinition);
+        parameterDefinition = new ParameterDefinitionImpl(""Comment"", new StringDataType());
+        parameterDefinitions.add(parameterDefinition);
+        work.setParameterDefinitions(parameterDefinitions);
+        work.setParameter(""TaskName"", ""Do something"");
+        work.setParameter(""ActorId"", ""John Doe"");
+        workItemNode.setWaitForCompletion(false);
+        process.addNode(humanTaskNode);
+        connection = new ConnectionImpl(workItemNode, Node.CONNECTION_DEFAULT_TYPE, humanTaskNode, Node.CONNECTION_DEFAULT_TYPE);
+        
         TimerNode timerNode = new TimerNode();
         timerNode.setName(""timer"");
@@ -246,5 +269,5 @@ public class XMLPersistenceTest extends TestCase {
         timerNode.setTimer(timer);
         process.addNode(timerNode);
-        new ConnectionImpl(workItemNode, Node.CONNECTION_DEFAULT_TYPE, timerNode, Node.CONNECTION_DEFAULT_TYPE);
+        new ConnectionImpl(humanTaskNode, Node.CONNECTION_DEFAULT_TYPE, timerNode, Node.CONNECTION_DEFAULT_TYPE);
         
         EndNode endNode = new EndNode();
@@ -271,5 +294,5 @@ public class XMLPersistenceTest extends TestCase {
         }
         
-        assertEquals(10, process.getNodes().length);
+        assertEquals(11, process.getNodes().length);
         
 //        System.out.println(""************************************"");
",JBRULES-1641: ForEach node  - initial core- implementation of a for each node JBRULES-1551: Workflow human tasks  - human- task node with swimlane integration--git-svn-id: https://svn.jboss.org/repos/labs/labs/jbossrules/trunk@20429 c60d74c8-e8f6-0310-9e8f-d4a2fc68ab70-
1361,Java,322578b7736f174b9b8e47914c87e9b77c1c1fd4,,P,JetBrains,kotlin,"[3, 18, 5, 1, 0, 0, 0, 6, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/idea/src/org/jetbrains/jet/plugin/intentions/SpecifyTypeExplicitlyAction.java b/idea/src/org/jetbrains/jet/plugin/intentions/SpecifyTypeExplicitlyAction.java
index f10680dddf5..ae3269014cf 100644
--- a/idea/src/org/jetbrains/jet/plugin/intentions/SpecifyTypeExplicitlyAction.java
+++ b/idea/src/org/jetbrains/jet/plugin/intentions/SpecifyTypeExplicitlyAction.java
@@ -21,9 +21,10 @@ import com.intellij.openapi.editor.Editor;
 import com.intellij.openapi.project.Project;
 import com.intellij.psi.PsiElement;
-import com.intellij.psi.impl.source.tree.LeafPsiElement;
 import com.intellij.psi.util.PsiTreeUtil;
 import org.jetbrains.annotations.NotNull;
 import org.jetbrains.jet.lang.descriptors.DeclarationDescriptor;
 import org.jetbrains.jet.lang.descriptors.VariableDescriptor;
+import org.jetbrains.jet.lang.diagnostics.Diagnostic;
+import org.jetbrains.jet.lang.diagnostics.Errors;
 import org.jetbrains.jet.lang.psi.JetFile;
 import org.jetbrains.jet.lang.psi.JetProperty;
@@ -31,5 +32,4 @@ import org.jetbrains.jet.lang.resolve.BindingContext;
 import org.jetbrains.jet.lang.types.ErrorUtils;
 import org.jetbrains.jet.lang.types.JetType;
-import org.jetbrains.jet.lexer.JetTokens;
 import org.jetbrains.jet.plugin.JetBundle;
 import org.jetbrains.jet.plugin.project.AnalyzeSingleFileUtil;
@@ -42,4 +42,13 @@ import org.jetbrains.jet.plugin.refactoring.introduceVariable.JetChangePropertyA
 public class SpecifyTypeExplicitlyAction extends PsiElementBaseIntentionAction {
     private JetType targetType;
+    private boolean disabledForError;
+
+    public SpecifyTypeExplicitlyAction() {
+        this(true);
+    }
+
+    public SpecifyTypeExplicitlyAction(boolean disabledForError) {
+        this.disabledForError = disabledForError;
+    }
 
     @NotNull
@@ -83,4 +92,11 @@ public class SpecifyTypeExplicitlyAction extends PsiElementBaseIntentionAction {
                 return false;
             }
+            if (disabledForError) {
+                for (Diagnostic diagnostic : bindingContext.getDiagnostics()) {
+                    if (Errors.PUBLIC_MEMBER_SHOULD_SPECIFY_TYPE == diagnostic.getFactory() && property == diagnostic.getPsiElement()) {
+                        return false;
+                    }
+                }
+            }
         }
         return true;
diff --git a/idea/src/org/jetbrains/jet/plugin/quickfix/AddReturnTypeFix.java b/idea/src/org/jetbrains/jet/plugin/quickfix/AddReturnTypeFix.java
index 6a55bbfd471..ec9a070deda 100644
--- a/idea/src/org/jetbrains/jet/plugin/quickfix/AddReturnTypeFix.java
+++ b/idea/src/org/jetbrains/jet/plugin/quickfix/AddReturnTypeFix.java
@@ -53,5 +53,5 @@ public class AddReturnTypeFix extends JetIntentionAction<JetNamedDeclaration> {
     public boolean isAvailable(@NotNull Project project, Editor editor, PsiFile file) {
         JetType type = QuickFixUtil.getDeclarationReturnType(element);
-        return super.isAvailable(project, editor, file) && type != null && !ErrorUtils.isErrorType(type);
+        return super.isAvailable(project, editor, file) && type != null && !ErrorUtils.isErrorType(type) && element instanceof JetFunction;
     }
 
@@ -62,7 +62,4 @@ public class AddReturnTypeFix extends JetIntentionAction<JetNamedDeclaration> {
         JetType type = QuickFixUtil.getDeclarationReturnType(element);
         if (type == null) return;
-        if (element instanceof JetProperty) {
-            newElement = addPropertyType(project, (JetProperty) element, type);
-        }
         else {
             assert element instanceof JetFunction;
diff --git a/idea/src/org/jetbrains/jet/plugin/quickfix/QuickFixes.java b/idea/src/org/jetbrains/jet/plugin/quickfix/QuickFixes.java
index dda1344366b..ebd50c228ed 100644
--- a/idea/src/org/jetbrains/jet/plugin/quickfix/QuickFixes.java
+++ b/idea/src/org/jetbrains/jet/plugin/quickfix/QuickFixes.java
@@ -24,4 +24,5 @@ import org.jetbrains.jet.lang.diagnostics.Errors;
 import org.jetbrains.jet.lang.psi.JetClass;
 import org.jetbrains.jet.plugin.codeInsight.ImplementMethodsHandler;
+import org.jetbrains.jet.plugin.intentions.SpecifyTypeExplicitlyAction;
 
 import java.util.Collection;
@@ -138,4 +139,5 @@ public class QuickFixes {
         actions.put(UNNECESSARY_SAFE_CALL, new ReplaceCallFix(false));
         actions.put(UNSAFE_CALL, new ReplaceCallFix(true));
+        actions.put(PUBLIC_MEMBER_SHOULD_SPECIFY_TYPE, new SpecifyTypeExplicitlyAction(false));
     }
 }
\ No newline at end of file
diff --git a/idea/testData/quickfix/typeAddition/afterPublicValWithoutReturnType.kt b/idea/testData/quickfix/typeAddition/afterPublicValWithoutReturnType.kt
index 9f661482552..d0796a7cd74 100644
--- a/idea/testData/quickfix/typeAddition/afterPublicValWithoutReturnType.kt
+++ b/idea/testData/quickfix/typeAddition/afterPublicValWithoutReturnType.kt
@@ -1,3 +1,3 @@
-// ""Add return type declaration"" ""true""
+// ""Specify Type Explicitly"" ""true""
 package a
 
diff --git a/idea/testData/quickfix/typeAddition/beforePublicValWithoutReturnType.kt b/idea/testData/quickfix/typeAddition/beforePublicValWithoutReturnType.kt
index 5fb773845c1..6155ec71868 100644
--- a/idea/testData/quickfix/typeAddition/beforePublicValWithoutReturnType.kt
+++ b/idea/testData/quickfix/typeAddition/beforePublicValWithoutReturnType.kt
@@ -1,3 +1,3 @@
-// ""Add return type declaration"" ""true""
+// ""Specify Type Explicitly"" ""true""
 package a
 
diff --git a/idea/testData/quickfix/typeImports/afterImportFromAnotherFile.kt b/idea/testData/quickfix/typeImports/afterImportFromAnotherFile.kt
index 40d4462c1fa..5794bf9f573 100644
--- a/idea/testData/quickfix/typeImports/afterImportFromAnotherFile.kt
+++ b/idea/testData/quickfix/typeImports/afterImportFromAnotherFile.kt
@@ -1,3 +1,3 @@
-// ""Add return type declaration"" ""true""
+// ""Specify Type Explicitly"" ""true""
 
 package a
diff --git a/idea/testData/quickfix/typeImports/afterNoImportFromTheSameFile.kt b/idea/testData/quickfix/typeImports/afterNoImportFromTheSameFile.kt
index dbf8c11c53b..5acd2b8b7e5 100644
--- a/idea/testData/quickfix/typeImports/afterNoImportFromTheSameFile.kt
+++ b/idea/testData/quickfix/typeImports/afterNoImportFromTheSameFile.kt
@@ -1,3 +1,3 @@
-// ""Add return type declaration"" ""true""
+// ""Specify Type Explicitly"" ""true""
 
 class A() {}
diff --git a/idea/testData/quickfix/typeImports/beforeImportFromAnotherFile.Main.kt b/idea/testData/quickfix/typeImports/beforeImportFromAnotherFile.Main.kt
index 66f32cb95a8..bc5de5d7d13 100644
--- a/idea/testData/quickfix/typeImports/beforeImportFromAnotherFile.Main.kt
+++ b/idea/testData/quickfix/typeImports/beforeImportFromAnotherFile.Main.kt
@@ -1,3 +1,3 @@
-// ""Add return type declaration"" ""true""
+// ""Specify Type Explicitly"" ""true""
 
 package a
diff --git a/idea/testData/quickfix/typeImports/beforeNoImportFromTheSameFile.kt b/idea/testData/quickfix/typeImports/beforeNoImportFromTheSameFile.kt
index 2b6d8501e56..973d53507d7 100644
--- a/idea/testData/quickfix/typeImports/beforeNoImportFromTheSameFile.kt
+++ b/idea/testData/quickfix/typeImports/beforeNoImportFromTheSameFile.kt
@@ -1,3 +1,3 @@
-// ""Add return type declaration"" ""true""
+// ""Specify Type Explicitly"" ""true""
 
 class A() {}
",Replaced AddReturnTypeFix with- SpecifyTypeExplicitlyAction for properties.--
1379,Java,4e446e768912ca08b30d74b3c570ddb336b837a6,,C,apache,hbase,"[1, 0, 0, 2, 0, 0, 0, 1, 23, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/src/contrib/transactional/src/java/org/apache/hadoop/hbase/regionserver/tableindexed/IndexedRegion.java b/src/contrib/transactional/src/java/org/apache/hadoop/hbase/regionserver/tableindexed/IndexedRegion.java
index 4d9563bc56..fcd12873cc 100644
--- a/src/contrib/transactional/src/java/org/apache/hadoop/hbase/regionserver/tableindexed/IndexedRegion.java
+++ b/src/contrib/transactional/src/java/org/apache/hadoop/hbase/regionserver/tableindexed/IndexedRegion.java
@@ -245,5 +245,5 @@ class IndexedRegion extends TransactionalRegion {
       }
       
-      Result oldRow = super.get(get, null);
+      Result oldRow = super.get(get, lockid);
       SortedMap<byte[], byte[]> oldColumnValues = convertToValueMap(oldRow);
       
@@ -256,5 +256,5 @@ class IndexedRegion extends TransactionalRegion {
       if (delete.getTimeStamp() != HConstants.LATEST_TIMESTAMP) {
         get.setTimeRange(1, delete.getTimeStamp());
-        oldRow = super.get(get, null);
+        oldRow = super.get(get, lockid);
         SortedMap<byte[], byte[]> currentColumnValues = convertToValueMap(oldRow);
         
diff --git a/src/contrib/transactional/src/test/org/apache/hadoop/hbase/client/tableindexed/TestIndexedTable.java b/src/contrib/transactional/src/test/org/apache/hadoop/hbase/client/tableindexed/TestIndexedTable.java
index 0cd440acd1..d7c1b15c02 100644
--- a/src/contrib/transactional/src/test/org/apache/hadoop/hbase/client/tableindexed/TestIndexedTable.java
+++ b/src/contrib/transactional/src/test/org/apache/hadoop/hbase/client/tableindexed/TestIndexedTable.java
@@ -37,4 +37,5 @@ import org.apache.hadoop.hbase.client.Result;
 import org.apache.hadoop.hbase.client.ResultScanner;
 import org.apache.hadoop.hbase.client.RowLock; 
+import org.apache.hadoop.hbase.client.Scan;
 import org.apache.hadoop.hbase.regionserver.tableindexed.IndexedRegionServer;
 import org.apache.hadoop.hbase.util.Bytes;
@@ -145,4 +146,22 @@ public class TestIndexedTable extends HBaseClusterTestCase {
   }
 
+  private void assertRowDeleted(int numRowsExpected)
+      throws IndexNotFoundException, IOException {
+    // Check the size of the primary table
+    ResultScanner scanner = table.getScanner(new Scan());
+    int numRows = 0;
+    for (Result rowResult : scanner) {
+      byte[] colA = rowResult.getValue(FAMILY, QUAL_A);
+      LOG.info(""primary scan : row ["" + Bytes.toString(rowResult.getRow())
+          + ""] value ["" + Bytes.toString(colA) + ""]"");
+      numRows++;
+    }
+    scanner.close();
+    Assert.assertEquals(numRowsExpected, numRows);
+
+    // Check the size of the index tables
+    assertRowsInOrder(numRowsExpected); 
+  }
+
   private void updateRow(int row, int newValue) throws IOException {
       Put update = new Put(PerformanceEvaluation.format(row));
@@ -221,3 +240,14 @@ public class TestIndexedTable extends HBaseClusterTestCase {
     assertRowUpdated(row, value);
   } 
+
+  public void testLockedRowDelete() throws IOException {
+    writeInitalRows();
+    // Delete the first row;
+    byte[] row = PerformanceEvaluation.format(0);
+    RowLock lock = table.lockRow(row);
+    table.delete(new Delete(row, HConstants.LATEST_TIMESTAMP, lock));
+    table.unlockRow(lock);    
+
+    assertRowDeleted(NUM_ROWS - 1);  
+  }
 }
",HBASE-1869 IndexedTable delete fails when used in- conjunction with RowLock()--git-svn-id: https://svn.apache.org/repos/asf/hadoop/hbase/trunk@819060 13f79535-47bb-0310-9956-ffa450edef68-
1399,Java,b9e1d6c698b589368f4a155134e8b2ba00608dc8,,P,apache,hbase,"[1, 7, 1, 3, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]","diff --git a/CHANGES.txt b/CHANGES.txt
index 21c60235fb..70366e5a2e 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -78,4 +78,5 @@ Release 0.91.0 - Unreleased
    HBASE-3440  Clean out load_table.rb and make sure all roads lead to
                completebulkload tool (Vidhyashankar Venkataraman via Stack)
+   HBASE-3653  Parallelize Server Requests on HBase Client
 
   TASK
diff --git a/src/main/java/org/apache/hadoop/hbase/client/HConnectionManager.java b/src/main/java/org/apache/hadoop/hbase/client/HConnectionManager.java
index 3d2c5ea8b8..644de1fa6b 100644
--- a/src/main/java/org/apache/hadoop/hbase/client/HConnectionManager.java
+++ b/src/main/java/org/apache/hadoop/hbase/client/HConnectionManager.java
@@ -241,4 +241,5 @@ public class HConnectionManager {
     private final Map<String, HRegionInterface> servers =
       new ConcurrentHashMap<String, HRegionInterface>();
+    private final ConcurrentHashMap<String, String> connectionLock = new ConcurrentHashMap<String, String>();
 
     /**
@@ -942,19 +943,28 @@ public class HConnectionManager {
       }
       HRegionInterface server;
-      synchronized (this.servers) {
-        // See if we already have a connection
-        server = this.servers.get(regionServer.toString());
-        if (server == null) { // Get a connection
-          try {
-            server = (HRegionInterface)HBaseRPC.waitForProxy(
-                serverInterfaceClass, HRegionInterface.VERSION,
-                regionServer.getInetSocketAddress(), this.conf,
-                this.maxRPCAttempts, this.rpcTimeout, this.rpcTimeout);
-          } catch (RemoteException e) {
-            LOG.warn(""RemoteException connecting to RS"", e);
-            // Throw what the RemoteException was carrying.
-            throw RemoteExceptionHandler.decodeRemoteException(e);
+      String rsName = regionServer.toString();
+      // See if we already have a connection (common case)
+      server = this.servers.get(rsName);
+      if (server == null) {
+        // create a unique lock for this RS (if necessary)
+        this.connectionLock.putIfAbsent(rsName, rsName);
+        // get the RS lock
+        synchronized (this.connectionLock.get(rsName)) {
+          // do one more lookup in case we were stalled above
+          server = this.servers.get(rsName);
+          if (server == null) {
+            try {
+              // definitely a cache miss. establish an RPC for this RS
+              server = (HRegionInterface) HBaseRPC.waitForProxy(
+                  serverInterfaceClass, HRegionInterface.VERSION,
+                  regionServer.getInetSocketAddress(), this.conf,
+                  this.maxRPCAttempts, this.rpcTimeout, this.rpcTimeout);
+              this.servers.put(rsName, server);
+            } catch (RemoteException e) {
+              LOG.warn(""RemoteException connecting to RS"", e);
+              // Throw what the RemoteException was carrying.
+              throw RemoteExceptionHandler.decodeRemoteException(e);
+            }
           }
-          this.servers.put(regionServer.toString(), server);
         }
       }
",HBASE-3653 : Parallelize Server Requests on HBase- Client--git-svn-id: https://svn.apache.org/repos/asf/hbase/trunk@1082648 13f79535-47bb-0310-9956-ffa450edef68-
1400,Java,bc6ad67d673dfdebd216b021193f736dcf5a76f8,,C,apache,hbase,"[1, 4, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]","diff --git a/CHANGES.txt b/CHANGES.txt
index 537c12dea5..254a4e3149 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -116,4 +116,5 @@ Release 0.20.0 - Unreleased
    HBASE-1344  WARN IllegalStateException: Cannot set a region as open if it has
                not been pending
+   HBASE-1386  NPE in housekeeping
 
   IMPROVEMENTS
diff --git a/src/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java b/src/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java
index 656c395d81..9f6b1db91e 100644
--- a/src/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java
+++ b/src/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java
@@ -1125,4 +1125,5 @@ public class HRegionServer implements HConstants, HRegionInterface,
     return true;
   }
+
   /*
    * Run some housekeeping tasks before we go into 'hibernation' sleeping at
@@ -1133,5 +1134,5 @@ public class HRegionServer implements HConstants, HRegionInterface,
     // messages. Send the master a message that we're working on its
     // processing so it doesn't assign the region elsewhere.
-    if (this.toDo.size() <= 0) {
+    if (this.toDo.isEmpty()) {
       return;
     }
@@ -1139,4 +1140,8 @@ public class HRegionServer implements HConstants, HRegionInterface,
     // queue at time iterator was taken out.  Apparently goes from oldest.
     for (ToDoEntry e: this.toDo) {
+      HMsg msg = e.msg;
+      if (msg == null) {
+        LOG.warn(""Message is empty: "" + e);
+      }
       if (e.msg.isType(HMsg.Type.MSG_REGION_OPEN)) {
         addProcessingMessage(e.msg.getRegionInfo());
@@ -1300,13 +1305,14 @@ public class HRegionServer implements HConstants, HRegionInterface,
    * Data structure to hold a HMsg and retries count.
    */
-  private static class ToDoEntry {
-    protected int tries;
+  private static final class ToDoEntry {
+    protected volatile int tries;
     protected final HMsg msg;
-    ToDoEntry(HMsg msg) {
+
+    ToDoEntry(final HMsg msg) {
       this.tries = 0;
       this.msg = msg;
     }
   }
-  
+
   final BlockingQueue<ToDoEntry> toDo = new LinkedBlockingQueue<ToDoEntry>();
   private Worker worker;
",HBASE-1386 NPE in housekeeping--git-svn-id: https://svn.apache.org/repos/asf/hadoop/hbase/trunk@772703 13f79535-47bb-0310-9956-ffa450edef68-
1404,Java,5c575c099f69e87b7bbd605f492022912096f3cf,,P,restlet,restlet-framework-java,"[19, 550, 475, 0, 354, 211, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/build/tmpl/eclipse/dictionary.xml b/build/tmpl/eclipse/dictionary.xml
index 615e88778..f73042022 100644
--- a/build/tmpl/eclipse/dictionary.xml
+++ b/build/tmpl/eclipse/dictionary.xml
@@ -57,2 +57,4 @@ evolvability
 introspecting
 deprecated
+datatype
+namespaces
diff --git a/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/Literal.java b/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/Literal.java
index 35eb60a57..d52906b36 100644
--- a/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/Literal.java
+++ b/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/Literal.java
@@ -28,5 +28,5 @@
  * Restlet is a registered trademark of Noelios Technologies.
  */
- 
+
 package org.restlet.ext.rdf;
 
@@ -39,5 +39,6 @@ import org.restlet.data.Reference;
  * 
  * @author Jerome Louvel
- * @see <a href=""http://www.w3.org/TR/rdf-concepts/#section-Graph-Literal"">RDF literals</a>
+ * @see <a href=""http://www.w3.org/TR/rdf-concepts/#section-Graph-Literal"">RDF
+ *      literals</a>
  */
 public class Literal {
diff --git a/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/RdfN3Representation.java b/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/RdfN3Representation.java
index 1b42db512..e7d6b6beb 100644
--- a/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/RdfN3Representation.java
+++ b/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/RdfN3Representation.java
@@ -46,34 +46,34 @@ import org.restlet.representation.Representation;
 public class RdfN3Representation extends RdfRepresentation {
 
-	/**
-	 * Constructor.
-	 * 
-	 * @param linkSet
-	 *            The given graph of links.
-	 */
-	public RdfN3Representation(Graph linkSet) {
-		super(linkSet);
-	}
+    /**
+     * Constructor.
+     * 
+     * @param linkSet
+     *            The given graph of links.
+     */
+    public RdfN3Representation(Graph linkSet) {
+        super(linkSet);
+    }
 
-	/**
-	 * Constructor. Parses the given representation into the given graph.
-	 * 
-	 * @param rdfRepresentation
-	 *            The RDF N3 representation to parse.
-	 * @param linkSet
-	 *            The graph to update.
-	 * @throws IOException
-	 */
-	public RdfN3Representation(Representation rdfRepresentation, Graph linkSet)
-			throws IOException {
-		super(linkSet);
-		new RdfN3ParsingContentHandler(linkSet, rdfRepresentation);
-	}
+    /**
+     * Constructor. Parses the given representation into the given graph.
+     * 
+     * @param rdfRepresentation
+     *            The RDF N3 representation to parse.
+     * @param linkSet
+     *            The graph to update.
+     * @throws IOException
+     */
+    public RdfN3Representation(Representation rdfRepresentation, Graph linkSet)
+            throws IOException {
+        super(linkSet);
+        new RdfN3ParsingContentHandler(linkSet, rdfRepresentation);
+    }
 
-	@Override
-	public void write(OutputStream outputStream) throws IOException {
-		if (getGraph() != null) {
-			new RdfN3WritingContentHandler(getGraph(), outputStream);
-		}
-	}
+    @Override
+    public void write(OutputStream outputStream) throws IOException {
+        if (getGraph() != null) {
+            new RdfN3WritingContentHandler(getGraph(), outputStream);
+        }
+    }
 }
diff --git a/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/RdfRepresentation.java b/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/RdfRepresentation.java
index 2fd7a5841..dcab4f14e 100644
--- a/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/RdfRepresentation.java
+++ b/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/RdfRepresentation.java
@@ -46,70 +46,70 @@ import org.restlet.representation.Representation;
 public abstract class RdfRepresentation extends OutputRepresentation {
 
-	/** The inner graph of links. */
-	private Graph graph;
+    /** The inner graph of links. */
+    private Graph graph;
 
-	/**
-	 * Constructor with argument.
-	 * 
-	 * @param linkSet
-	 *            The graph of link.
-	 */
-	public RdfRepresentation(Graph linkSet) {
-		super(null);
-		this.graph = linkSet;
-	}
+    /**
+     * Constructor with argument.
+     * 
+     * @param linkSet
+     *            The graph of link.
+     */
+    public RdfRepresentation(Graph linkSet) {
+        super(null);
+        this.graph = linkSet;
+    }
 
-	/**
-	 * Constructor that parsed a given RDF representation into a link set.
-	 * 
-	 * @param rdfRepresentation
-	 *            The RDF representation to parse.
-	 * @param linkSet
-	 *            The link set to update.
-	 * @throws IOException
-	 */
-	public RdfRepresentation(Representation rdfRepresentation, Graph linkSet)
-			throws IOException {
-		this(linkSet);
-		if (MediaType.TEXT_RDF_N3.equals(rdfRepresentation.getMediaType())) {
-			new RdfN3Representation(rdfRepresentation, linkSet);
-		} else if (MediaType.TEXT_XML.equals(rdfRepresentation.getMediaType())) {
-			new RdfXmlRepresentation(rdfRepresentation, linkSet);
-		} else if (MediaType.APPLICATION_ALL_XML.includes(rdfRepresentation
-				.getMediaType())) {
-			new RdfXmlRepresentation(rdfRepresentation, linkSet);
-		}
-		// Parsing for other media types goes here.
-	}
+    /**
+     * Constructor that parsed a given RDF representation into a link set.
+     * 
+     * @param rdfRepresentation
+     *            The RDF representation to parse.
+     * @param linkSet
+     *            The link set to update.
+     * @throws IOException
+     */
+    public RdfRepresentation(Representation rdfRepresentation, Graph linkSet)
+            throws IOException {
+        this(linkSet);
+        if (MediaType.TEXT_RDF_N3.equals(rdfRepresentation.getMediaType())) {
+            new RdfN3Representation(rdfRepresentation, linkSet);
+        } else if (MediaType.TEXT_XML.equals(rdfRepresentation.getMediaType())) {
+            new RdfXmlRepresentation(rdfRepresentation, linkSet);
+        } else if (MediaType.APPLICATION_ALL_XML.includes(rdfRepresentation
+                .getMediaType())) {
+            new RdfXmlRepresentation(rdfRepresentation, linkSet);
+        }
+        // Parsing for other media types goes here.
+    }
 
-	/**
-	 * Returns the graph of links.
-	 * 
-	 * @return The graph of links.
-	 */
-	public Graph getGraph() {
-		return graph;
-	}
+    /**
+     * Returns the graph of links.
+     * 
+     * @return The graph of links.
+     */
+    public Graph getGraph() {
+        return graph;
+    }
 
-	/**
-	 * Sets the graph of links.
-	 * 
-	 * @param linkSet
-	 *            The graph of links.
-	 */
-	public void setGraph(Graph linkSet) {
-		this.graph = linkSet;
-	}
+    /**
+     * Sets the graph of links.
+     * 
+     * @param linkSet
+     *            The graph of links.
+     */
+    public void setGraph(Graph linkSet) {
+        this.graph = linkSet;
+    }
 
-	@Override
-	public void write(OutputStream outputStream) throws IOException {
-		if (MediaType.TEXT_RDF_N3.equals(getMediaType())) {
-			new RdfN3Representation(getGraph()).write(outputStream);
-		} else if (MediaType.TEXT_XML.equals(getMediaType())) {
-			new RdfXmlRepresentation(getGraph()).write(outputStream);
-		} else if (MediaType.APPLICATION_ALL_XML.includes(getMediaType())) {
-			new RdfXmlRepresentation(getGraph()).write(outputStream);
-		}
-		// Writing for other media types goes here.
-	}
+    @Override
+    public void write(OutputStream outputStream) throws IOException {
+        if (MediaType.TEXT_RDF_N3.equals(getMediaType())) {
+            new RdfN3Representation(getGraph()).write(outputStream);
+        } else if (MediaType.TEXT_XML.equals(getMediaType())) {
+            new RdfXmlRepresentation(getGraph()).write(outputStream);
+        } else if (MediaType.APPLICATION_ALL_XML.includes(getMediaType())) {
+            new RdfXmlRepresentation(getGraph()).write(outputStream);
+        }
+        // Writing for other media types goes here.
+    }
 }
diff --git a/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/RdfXmlRepresentation.java b/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/RdfXmlRepresentation.java
index da509570d..0f9ee75e3 100644
--- a/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/RdfXmlRepresentation.java
+++ b/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/RdfXmlRepresentation.java
@@ -46,34 +46,34 @@ import org.restlet.representation.Representation;
 public class RdfXmlRepresentation extends RdfRepresentation {
 
-	/**
-	 * Constructor.
-	 * 
-	 * @param linkSet
-	 *            The given graph of links.
-	 */
-	public RdfXmlRepresentation(Graph linkSet) {
-		super(linkSet);
-	}
+    /**
+     * Constructor.
+     * 
+     * @param linkSet
+     *            The given graph of links.
+     */
+    public RdfXmlRepresentation(Graph linkSet) {
+        super(linkSet);
+    }
 
-	/**
-	 * Constructor. Parses the given representation into the given graph.
-	 * 
-	 * @param rdfRepresentation
-	 *            The RDF N3 representation to parse.
-	 * @param linkSet
-	 *            The graph to update.
-	 * @throws IOException
-	 */
-	public RdfXmlRepresentation(Representation rdfRepresentation, Graph linkSet)
-			throws IOException {
-		super(linkSet);
-		new RdfXmlParsingContentHandler(linkSet, rdfRepresentation);
-	}
+    /**
+     * Constructor. Parses the given representation into the given graph.
+     * 
+     * @param rdfRepresentation
+     *            The RDF N3 representation to parse.
+     * @param linkSet
+     *            The graph to update.
+     * @throws IOException
+     */
+    public RdfXmlRepresentation(Representation rdfRepresentation, Graph linkSet)
+            throws IOException {
+        super(linkSet);
+        new RdfXmlParsingContentHandler(linkSet, rdfRepresentation);
+    }
 
-	@Override
-	public void write(OutputStream outputStream) throws IOException {
-		if (getGraph() != null) {
-			new RdfXmlWritingContentHandler(getGraph(), outputStream);
-		}
-	}
+    @Override
+    public void write(OutputStream outputStream) throws IOException {
+        if (getGraph() != null) {
+            new RdfXmlWritingContentHandler(getGraph(), outputStream);
+        }
+    }
 }
diff --git a/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/internal/RdfConstants.java b/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/internal/RdfConstants.java
index 724a89436..0ea71f7fc 100644
--- a/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/internal/RdfConstants.java
+++ b/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/internal/RdfConstants.java
@@ -1,2 +1,32 @@
+/**
+ * Copyright 2005-2009 Noelios Technologies.
+ * 
+ * The contents of this file are subject to the terms of one of the following
+ * open source licenses: LGPL 3.0 or LGPL 2.1 or CDDL 1.0 or EPL 1.0 (the
+ * ""Licenses""). You can select the license that you prefer but you may not use
+ * this file except in compliance with one of these Licenses.
+ * 
+ * You can obtain a copy of the LGPL 3.0 license at
+ * http://www.opensource.org/licenses/lgpl-3.0.html
+ * 
+ * You can obtain a copy of the LGPL 2.1 license at
+ * http://www.opensource.org/licenses/lgpl-2.1.php
+ * 
+ * You can obtain a copy of the CDDL 1.0 license at
+ * http://www.opensource.org/licenses/cddl1.php
+ * 
+ * You can obtain a copy of the EPL 1.0 license at
+ * http://www.opensource.org/licenses/eclipse-1.0.php
+ * 
+ * See the Licenses for the specific language governing permissions and
+ * limitations under the Licenses.
+ * 
+ * Alternatively, you can obtain a royalty free commercial license with less
+ * limitations, transferable or non-transferable, directly at
+ * http://www.noelios.com/products/restlet-engine
+ * 
+ * Restlet is a registered trademark of Noelios Technologies.
+ */
+
 package org.restlet.ext.rdf.internal;
 
@@ -6,66 +36,67 @@ import org.restlet.data.Reference;
  * Constants related to RDF documents.
  * 
+ * @author Thierry Boileau
  */
 public class RdfConstants {
 
-	/** List ""first"". */
-	public static final Reference LIST_FIRST = new Reference(
-			""http://www.w3.org/1999/02/22-rdf-syntax-ns#first"");
-
-	/** List ""rest"". */
-	public static final Reference LIST_REST = new Reference(
-			""http://www.w3.org/1999/02/22-rdf-syntax-ns#rest"");
-
-	/** Object ""nil"". */
-	public static final Reference OBJECT_NIL = new Reference(
-			""http://www.w3.org/1999/02/22-rdf-syntax-ns#nil"");
-
-	/** Predicate ""implies"" . */
-	public static final Reference PREDICATE_IMPLIES = new Reference(
-			""http://www.w3.org/2000/10/swap/log#implies"");
-
-	/** Predicate ""object"". */
-	public static final Reference PREDICATE_OBJECT = new Reference(
-			""http://www.w3.org/1999/02/22-rdf-syntax-ns#object"");
-
-	/** Predicate ""predicate"". */
-	public static final Reference PREDICATE_PREDICATE = new Reference(
-			""http://www.w3.org/1999/02/22-rdf-syntax-ns#predicate"");
-
-	/** Predicate ""same as"". */
-	public static final Reference PREDICATE_SAME = new Reference(
-			""http://www.w3.org/2002/07/owl#sameAs"");
-	
-	/** Predicate ""statement"". */
-	public static final Reference PREDICATE_STATEMENT = new Reference(
-			""http://www.w3.org/1999/02/22-rdf-syntax-ns#Statement"");
-
-	/** Predicate ""subject"". */
-	public static final Reference PREDICATE_SUBJECT = new Reference(
-			""http://www.w3.org/1999/02/22-rdf-syntax-ns#subject"");
-
-	/** Predicate ""is a"". */
-	public static final Reference PREDICATE_TYPE = new Reference(
-			""http://www.w3.org/1999/02/22-rdf-syntax-ns#type"");
-
-	/** Rdf schema. */
-	public static final Reference RDF_SCHEMA = new Reference(
-			""http://www.w3.org/2000/01/rdf-schema#"");
-
-	/** Rdf syntax. */
-	public static final Reference RDF_SYNTAX = new Reference(
-			""http://www.w3.org/1999/02/22-rdf-syntax-ns#"");
-
-	/** XML schema. */
-	public static final Reference XML_SCHEMA = new Reference(
-			""http://www.w3.org/2001/XMLSchema#"");
-
-	/** Float type of the XML schema. */
-	public static final Reference XML_SCHEMA_TYPE_FLOAT = new Reference(
-			""http://www.w3.org/2001/XMLSchema#float"");
-
-	/** Integer type of the XML schema. */
-	public static final Reference XML_SCHEMA_TYPE_INTEGER = new Reference(
-			""http://www.w3.org/2001/XMLSchema#int"");
+    /** List ""first"". */
+    public static final Reference LIST_FIRST = new Reference(
+            ""http://www.w3.org/1999/02/22-rdf-syntax-ns#first"");
+
+    /** List ""rest"". */
+    public static final Reference LIST_REST = new Reference(
+            ""http://www.w3.org/1999/02/22-rdf-syntax-ns#rest"");
+
+    /** Object ""nil"". */
+    public static final Reference OBJECT_NIL = new Reference(
+            ""http://www.w3.org/1999/02/22-rdf-syntax-ns#nil"");
+
+    /** Predicate ""implies"" . */
+    public static final Reference PREDICATE_IMPLIES = new Reference(
+            ""http://www.w3.org/2000/10/swap/log#implies"");
+
+    /** Predicate ""object"". */
+    public static final Reference PREDICATE_OBJECT = new Reference(
+            ""http://www.w3.org/1999/02/22-rdf-syntax-ns#object"");
+
+    /** Predicate ""predicate"". */
+    public static final Reference PREDICATE_PREDICATE = new Reference(
+            ""http://www.w3.org/1999/02/22-rdf-syntax-ns#predicate"");
+
+    /** Predicate ""same as"". */
+    public static final Reference PREDICATE_SAME = new Reference(
+            ""http://www.w3.org/2002/07/owl#sameAs"");
+
+    /** Predicate ""statement"". */
+    public static final Reference PREDICATE_STATEMENT = new Reference(
+            ""http://www.w3.org/1999/02/22-rdf-syntax-ns#Statement"");
+
+    /** Predicate ""subject"". */
+    public static final Reference PREDICATE_SUBJECT = new Reference(
+            ""http://www.w3.org/1999/02/22-rdf-syntax-ns#subject"");
+
+    /** Predicate ""is a"". */
+    public static final Reference PREDICATE_TYPE = new Reference(
+            ""http://www.w3.org/1999/02/22-rdf-syntax-ns#type"");
+
+    /** Rdf schema. */
+    public static final Reference RDF_SCHEMA = new Reference(
+            ""http://www.w3.org/2000/01/rdf-schema#"");
+
+    /** Rdf syntax. */
+    public static final Reference RDF_SYNTAX = new Reference(
+            ""http://www.w3.org/1999/02/22-rdf-syntax-ns#"");
+
+    /** XML schema. */
+    public static final Reference XML_SCHEMA = new Reference(
+            ""http://www.w3.org/2001/XMLSchema#"");
+
+    /** Float type of the XML schema. */
+    public static final Reference XML_SCHEMA_TYPE_FLOAT = new Reference(
+            ""http://www.w3.org/2001/XMLSchema#float"");
+
+    /** Integer type of the XML schema. */
+    public static final Reference XML_SCHEMA_TYPE_INTEGER = new Reference(
+            ""http://www.w3.org/2001/XMLSchema#int"");
 
 }
diff --git a/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/internal/n3/BlankNodeToken.java b/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/internal/n3/BlankNodeToken.java
index 1ef91baf1..046105b54 100644
--- a/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/internal/n3/BlankNodeToken.java
+++ b/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/internal/n3/BlankNodeToken.java
@@ -41,9 +41,11 @@ import org.restlet.ext.rdf.LinkReference;
  * Represents a blank node inside a RDF N3 document. Contains all the logic to
  * parse a blank node in N3 documents.
+ * 
+ * @author Thierry Boileau
  */
 public class BlankNodeToken extends LexicalUnit {
 
     /** List of lexical units contained by this blank node. */
-    List<LexicalUnit> lexicalUnits;
+    private List<LexicalUnit> lexicalUnits;
 
     /** Indicates if the given blank node has been already resolved. */
diff --git a/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/internal/n3/Context.java b/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/internal/n3/Context.java
index ffb3bfbd5..ae5917f65 100644
--- a/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/internal/n3/Context.java
+++ b/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/internal/n3/Context.java
@@ -41,6 +41,9 @@ import org.restlet.data.Reference;
  * Contains essentials data updated during the parsing of a N3 document such as
  * the list of known namespaces, keywords.
+ * 
+ * @author Thierry Boileau
  */
 public class Context {
+
     /** The value of the ""base"" keyword. */
     private Reference base;
diff --git a/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/internal/n3/FormulaToken.java b/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/internal/n3/FormulaToken.java
index a0714de14..af049ed7c 100644
--- a/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/internal/n3/FormulaToken.java
+++ b/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/internal/n3/FormulaToken.java
@@ -36,4 +36,6 @@ import java.io.IOException;
  * Allows to parse a formula in RDF N3 notation. Please note that this kind of
  * feature is not supported yet.
+ * 
+ * @author Thierry Boileau
  */
 public class FormulaToken extends LexicalUnit {
@@ -45,6 +47,6 @@ public class FormulaToken extends LexicalUnit {
     }
 
-    public FormulaToken(RdfN3ParsingContentHandler contentHandler, Context context)
-            throws IOException {
+    public FormulaToken(RdfN3ParsingContentHandler contentHandler,
+            Context context) throws IOException {
         super(contentHandler, context);
         this.parse();
diff --git a/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/internal/n3/LexicalUnit.java b/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/internal/n3/LexicalUnit.java
index e1dfda2bb..502194b93 100644
--- a/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/internal/n3/LexicalUnit.java
+++ b/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/internal/n3/LexicalUnit.java
@@ -35,4 +35,6 @@ import java.io.IOException;
 /**
  * Represents a lexical unit inside a N3 document.
+ * 
+ * @author Thierry Boileau
  */
 public abstract class LexicalUnit {
@@ -55,5 +57,6 @@ public abstract class LexicalUnit {
      *            The parsing context.
      */
-    public LexicalUnit(RdfN3ParsingContentHandler contentHandler, Context context) {
+    public LexicalUnit(RdfN3ParsingContentHandler contentHandler,
+            Context context) {
         super();
         this.contentHandler = contentHandler;
diff --git a/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/internal/n3/ListToken.java b/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/internal/n3/ListToken.java
index 2f18fdce8..a5db88e39 100644
--- a/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/internal/n3/ListToken.java
+++ b/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/internal/n3/ListToken.java
@@ -39,112 +39,114 @@ import org.restlet.ext.rdf.internal.RdfConstants;
 
 /**
- * Represens a list of N3 tokens.
+ * Represents a list of N3 tokens.
+ * 
+ * @author Thierry Boileau
  */
 class ListToken extends LexicalUnit {
-	/** The list of contained tokens. */
-	List<LexicalUnit> lexicalUnits;
+    /** The list of contained tokens. */
+    List<LexicalUnit> lexicalUnits;
 
-	/**
-	 * Constructor with arguments.
-	 * 
-	 * @param contentHandler
-	 *            The document's parent handler.
-	 * @param context
-	 *            The parsing context.
-	 */
-	public ListToken(RdfN3ParsingContentHandler contentHandler, Context context)
-			throws IOException {
-		super(contentHandler, context);
-		lexicalUnits = new ArrayList<LexicalUnit>();
-		this.parse();
-	}
+    /**
+     * Constructor with arguments.
+     * 
+     * @param contentHandler
+     *            The document's parent handler.
+     * @param context
+     *            The parsing context.
+     */
+    public ListToken(RdfN3ParsingContentHandler contentHandler, Context context)
+            throws IOException {
+        super(contentHandler, context);
+        lexicalUnits = new ArrayList<LexicalUnit>();
+        this.parse();
+    }
 
-	@Override
-	public Object resolve() {
-		Reference currentBlankNode = (Reference) new BlankNodeToken(
-				RdfN3ParsingContentHandler.newBlankNodeId()).resolve();
-		for (LexicalUnit lexicalUnit : lexicalUnits) {
-			Object element = lexicalUnit.resolve();
+    @Override
+    public Object resolve() {
+        Reference currentBlankNode = (Reference) new BlankNodeToken(
+                RdfN3ParsingContentHandler.newBlankNodeId()).resolve();
+        for (LexicalUnit lexicalUnit : lexicalUnits) {
+            Object element = lexicalUnit.resolve();
 
-			if (element instanceof Reference) {
-				getContentHandler().link(currentBlankNode,
-						RdfConstants.LIST_FIRST, (Reference) element);
-			} else if (element instanceof String) {
-				getContentHandler().link(currentBlankNode,
-						RdfConstants.LIST_FIRST,
-						new Reference((String) element));
-			} else {
-				// TODO Error.
-			}
+            if (element instanceof Reference) {
+                getContentHandler().link(currentBlankNode,
+                        RdfConstants.LIST_FIRST, (Reference) element);
+            } else if (element instanceof String) {
+                getContentHandler().link(currentBlankNode,
+                        RdfConstants.LIST_FIRST,
+                        new Reference((String) element));
+            } else {
+                // TODO Error.
+            }
 
-			Reference restBlankNode = (Reference) new BlankNodeToken(
-					RdfN3ParsingContentHandler.newBlankNodeId()).resolve();
+            Reference restBlankNode = (Reference) new BlankNodeToken(
+                    RdfN3ParsingContentHandler.newBlankNodeId()).resolve();
 
-			getContentHandler().link(currentBlankNode, RdfConstants.LIST_REST,
-					restBlankNode);
-			currentBlankNode = restBlankNode;
-		}
-		getContentHandler().link(currentBlankNode, RdfConstants.LIST_REST,
-				RdfConstants.OBJECT_NIL);
+            getContentHandler().link(currentBlankNode, RdfConstants.LIST_REST,
+                    restBlankNode);
+            currentBlankNode = restBlankNode;
+        }
+        getContentHandler().link(currentBlankNode, RdfConstants.LIST_REST,
+                RdfConstants.OBJECT_NIL);
 
-		return currentBlankNode;
-	}
+        return currentBlankNode;
+    }
 
-	@Override
-	public String getValue() {
-		return lexicalUnits.toString();
-	}
+    @Override
+    public String getValue() {
+        return lexicalUnits.toString();
+    }
 
-	@Override
-	public void parse() throws IOException {
-		getContentHandler().step();
-		do {
-			getContentHandler().consumeWhiteSpaces();
-			switch (getContentHandler().getChar()) {
-			case '(':
-				lexicalUnits.add(new ListToken(getContentHandler(),
-						getContext()));
-				break;
-			case '<':
-				if (getContentHandler().step() == '=') {
-					lexicalUnits.add(new Token(""<=""));
-					getContentHandler().step();
-					getContentHandler().discard();
-				} else {
-					getContentHandler().stepBack();
-					lexicalUnits.add(new UriToken(getContentHandler(),
-							getContext()));
-				}
-				break;
-			case '_':
-				lexicalUnits.add(new BlankNodeToken(getContentHandler()
-						.parseToken()));
-				break;
-			case '""':
-				lexicalUnits.add(new StringToken(getContentHandler(),
-						getContext()));
-				break;
-			case '[':
-				lexicalUnits.add(new BlankNodeToken(getContentHandler(),
-						getContext()));
-				break;
-			case '{':
-				lexicalUnits.add(new FormulaToken(getContentHandler(),
-						getContext()));
-				break;
-			case ')':
-				break;
-			case RdfN3ParsingContentHandler.EOF:
-				break;
-			default:
-				lexicalUnits.add(new Token(getContentHandler(), getContext()));
-				break;
-			}
-		} while (getContentHandler().getChar() != RdfN3ParsingContentHandler.EOF
-				&& getContentHandler().getChar() != ')');
-		if (getContentHandler().getChar() == ')') {
-			// Set the cursor at the right of the list token.
-			getContentHandler().step();
-		}
-	}
+    @Override
+    public void parse() throws IOException {
+        getContentHandler().step();
+        do {
+            getContentHandler().consumeWhiteSpaces();
+            switch (getContentHandler().getChar()) {
+            case '(':
+                lexicalUnits.add(new ListToken(getContentHandler(),
+                        getContext()));
+                break;
+            case '<':
+                if (getContentHandler().step() == '=') {
+                    lexicalUnits.add(new Token(""<=""));
+                    getContentHandler().step();
+                    getContentHandler().discard();
+                } else {
+                    getContentHandler().stepBack();
+                    lexicalUnits.add(new UriToken(getContentHandler(),
+                            getContext()));
+                }
+                break;
+            case '_':
+                lexicalUnits.add(new BlankNodeToken(getContentHandler()
+                        .parseToken()));
+                break;
+            case '""':
+                lexicalUnits.add(new StringToken(getContentHandler(),
+                        getContext()));
+                break;
+            case '[':
+                lexicalUnits.add(new BlankNodeToken(getContentHandler(),
+                        getContext()));
+                break;
+            case '{':
+                lexicalUnits.add(new FormulaToken(getContentHandler(),
+                        getContext()));
+                break;
+            case ')':
+                break;
+            case RdfN3ParsingContentHandler.EOF:
+                break;
+            default:
+                lexicalUnits.add(new Token(getContentHandler(), getContext()));
+                break;
+            }
+        } while (getContentHandler().getChar() != RdfN3ParsingContentHandler.EOF
+                && getContentHandler().getChar() != ')');
+        if (getContentHandler().getChar() == ')') {
+            // Set the cursor at the right of the list token.
+            getContentHandler().step();
+        }
+    }
 }
\ No newline at end of file
diff --git a/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/internal/n3/RdfN3ParsingContentHandler.java b/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/internal/n3/RdfN3ParsingContentHandler.java
index b3eec7b86..197c9e838 100644
--- a/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/internal/n3/RdfN3ParsingContentHandler.java
+++ b/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/internal/n3/RdfN3ParsingContentHandler.java
@@ -47,658 +47,661 @@ import org.restlet.representation.Representation;
 /**
  * Handler of RDF content according to the N3 notation.
+ * 
+ * @author Thierry Boileau
  */
 public class RdfN3ParsingContentHandler extends GraphHandler {
-	/** Increment used to identify inner blank nodes. */
-	private static int blankNodeId = 0;
-
-	/** Size of the reading buffer. */
-	private static final int BUFFER_SIZE = 4096;
-
-	/** End of reading buffer marker. */
-	public static final int EOF = 0;
-
-	/**
-	 * Returns true if the given character is alphanumeric.
-	 * 
-	 * @param c
-	 *            The given character to check.
-	 * @return true if the given character is alphanumeric.
-	 */
-	public static boolean isAlphaNum(int c) {
-		return (c >= 'a' && c <= 'z') || (c >= 'A' && c <= 'Z')
-				|| (c >= '0' && c <= '9');
-	}
-
-	/**
-	 * Returns true if the given character is a delimiter.
-	 * 
-	 * @param c
-	 *            The given character to check.
-	 * @return true if the given character is a delimiter.
-	 */
-	public static boolean isDelimiter(int c) {
-		return isWhiteSpace(c) || c == '^' || c == '!' || c == '=' || c == '<'
-				|| c == '""' || c == '{' || c == '}' || c == '[' || c == ']'
-				|| c == '(' || c == ')' || c == '.' || c == ';' || c == ','
-				|| c == '@';
-	}
-
-	/**
-	 * Returns true if the given character is a whitespace.
-	 * 
-	 * @param c
-	 *            The given character to check.
-	 * @return true if the given character is a whitespace.
-	 */
-	public static boolean isWhiteSpace(int c) {
-		return c == ' ' || c == '\n' || c == '\r' || c == '\t';
-	}
-
-	/**
-	 * Returns the identifier of a new blank node.
-	 * 
-	 * @return The identifier of a new blank node.
-	 */
-	public static String newBlankNodeId() {
-		return ""#_bn"" + blankNodeId++;
-	}
-
-	/** Internal buffered reader. */
-	private BufferedReader br;
-
-	/** The reading buffer. */
-	private final char[] buffer;
-
-	/** The current context object. */
-	private Context context;
-
-	/** The set of links to update when parsing. */
-	private Graph linkSet;
-
-	/** The representation to read. */
-	private Representation rdfN3Representation;
-
-	/**
-	 * Index that discovers the end of the current token and the beginning of
-	 * the futur one.
-	 */
-	private int scoutIndex;
-
-	/** Start index of current lexical unit. */
-	private int startTokenIndex;
-
-	/**
-	 * Constructor.
-	 * 
-	 * @param linkSet
-	 *            The set of links to update during the parsing.
-	 * @param rdfN3Representation
-	 *            The representation to read.
-	 * @throws IOException
-	 */
-	public RdfN3ParsingContentHandler(Graph linkSet,
-			Representation rdfN3Representation) throws IOException {
-		super();
-		this.linkSet = linkSet;
-		this.rdfN3Representation = rdfN3Representation;
-
-		// Initialize the buffer in two parts
-		this.buffer = new char[(RdfN3ParsingContentHandler.BUFFER_SIZE + 1) * 2];
-		// Mark the upper index of each part.
-		this.buffer[RdfN3ParsingContentHandler.BUFFER_SIZE] = this.buffer[2 * RdfN3ParsingContentHandler.BUFFER_SIZE + 1] = EOF;
-		this.scoutIndex = 2 * RdfN3ParsingContentHandler.BUFFER_SIZE;
-		this.startTokenIndex = 0;
-
-		this.br = new BufferedReader(new InputStreamReader(
-				this.rdfN3Representation.getStream()));
-		this.context = new Context();
-		context.getKeywords().addAll(
-				Arrays.asList(""a"", ""is"", ""of"", ""this"", ""has""));
-		parse();
-	}
-
-	/**
-	 * Discard all read characters until the end of the statement is reached
-	 * (marked by a '.').
-	 * 
-	 * @throws IOException
-	 */
-	public void consumeStatement() throws IOException {
-		int c = getChar();
-		while (c != RdfN3ParsingContentHandler.EOF && c != '.') {
-			c = step();
-		}
-		if (getChar() == '.') {
-			// A further step at the right of the statement.
-			step();
-		}
-		discard();
-	}
-
-	/**
-	 * Discard all read characters. A call to {@link getCurrentToken} will
-	 * return a single character.
-	 * 
-	 * @throws IOException
-	 */
-	public void consumeWhiteSpaces() throws IOException {
-		while (RdfN3ParsingContentHandler.isWhiteSpace(getChar())) {
-			step();
-		}
-		discard();
-	}
-
-	/**
-	 * Discard all read characters. A call to {@link getCurrentToken} will
-	 * return a single character.
-	 */
-	public void discard() {
-		startTokenIndex = scoutIndex;
-	}
-
-	/**
-	 * Loops over the given list of lexical units and generates the adequat
-	 * calls to link* methods.
-	 * 
-	 * @see GraphHandler#link(Graph, Reference, Reference)
-	 * @see GraphHandler#link(Reference, Reference, Literal)
-	 * @see GraphHandler#link(Reference, Reference, Reference)
-	 * @param lexicalUnits
-	 *            The list of lexical units used to generate the links.
-	 */
-	public void generateLinks(List<LexicalUnit> lexicalUnits) {
-		Object currentSubject = null;
-		Reference currentPredicate = null;
-		Object currentObject = null;
-		int nbTokens = 0;
-		boolean swapSubjectObject = false;
-		for (int i = 0; i < lexicalUnits.size(); i++) {
-			LexicalUnit lexicalUnit = lexicalUnits.get(i);
-
-			nbTokens++;
-			switch (nbTokens) {
-			case 1:
-				if ("","".equals(lexicalUnit.getValue())) {
-					nbTokens++;
-				} else if (!"";"".equals(lexicalUnit.getValue())) {
-					currentSubject = lexicalUnit.resolve();
-				}
-				break;
-			case 2:
-				if (""is"".equalsIgnoreCase(lexicalUnit.getValue())) {
-					nbTokens--;
-					swapSubjectObject = true;
-				} else if (""has"".equalsIgnoreCase(lexicalUnit.getValue())) {
-					nbTokens--;
-				} else if (""="".equalsIgnoreCase(lexicalUnit.getValue())) {
-					currentPredicate = RdfConstants.PREDICATE_SAME;
-				} else if (""=>"".equalsIgnoreCase(lexicalUnit.getValue())) {
-					currentPredicate = RdfConstants.PREDICATE_IMPLIES;
-				} else if (""<="".equalsIgnoreCase(lexicalUnit.getValue())) {
-					swapSubjectObject = true;
-					currentPredicate = RdfConstants.PREDICATE_IMPLIES;
-				} else if (""a"".equalsIgnoreCase(lexicalUnit.getValue())) {
-					currentPredicate = RdfConstants.PREDICATE_TYPE;
-				} else if (""!"".equalsIgnoreCase(lexicalUnit.getValue())) {
-					currentObject = new BlankNodeToken(
-							RdfN3ParsingContentHandler.newBlankNodeId())
-							.resolve();
-					currentPredicate = getPredicate(lexicalUnits.get(++i));
-					this.link(currentSubject, currentPredicate, currentObject);
-					currentSubject = currentObject;
-					nbTokens = 1;
-				} else if (""^"".equalsIgnoreCase(lexicalUnit.getValue())) {
-					currentObject = currentSubject;
-					currentPredicate = getPredicate(lexicalUnits.get(++i));
-					currentSubject = new BlankNodeToken(
-							RdfN3ParsingContentHandler.newBlankNodeId())
-							.resolve();
-					this.link(currentSubject, currentPredicate, currentObject);
-					nbTokens = 1;
-				} else {
-					currentPredicate = getPredicate(lexicalUnit);
-				}
-				break;
-			case 3:
-				if (""of"".equalsIgnoreCase(lexicalUnit.getValue())) {
-					nbTokens--;
-				} else {
-					if (swapSubjectObject) {
-						currentObject = currentSubject;
-						currentSubject = lexicalUnit.resolve();
-					} else {
-						currentObject = lexicalUnit.resolve();
-					}
-					this.link(currentSubject, currentPredicate, currentObject);
-					nbTokens = 0;
-					swapSubjectObject = false;
-				}
-				break;
-			default:
-				break;
-			}
-		}
-	}
-
-	/**
-	 * Returns the current parsed character.
-	 * 
-	 * @return The current parsed character.
-	 */
-	public char getChar() {
-		return (char) buffer[scoutIndex];
-	}
-
-	/**
-	 * Returns the current token.
-	 * 
-	 * @return The current token.
-	 */
-	public String getCurrentToken() {
-		StringBuilder builder = new StringBuilder();
-		if (startTokenIndex <= scoutIndex) {
-			if (scoutIndex <= RdfN3ParsingContentHandler.BUFFER_SIZE) {
-				for (int i = startTokenIndex; i < scoutIndex; i++) {
-					builder.append((char) buffer[i]);
-				}
-			} else {
-				for (int i = startTokenIndex; i < RdfN3ParsingContentHandler.BUFFER_SIZE; i++) {
-					builder.append((char) buffer[i]);
-				}
-				for (int i = RdfN3ParsingContentHandler.BUFFER_SIZE + 1; i < scoutIndex; i++) {
-					builder.append((char) buffer[i]);
-				}
-			}
-		} else {
-			if (startTokenIndex <= RdfN3ParsingContentHandler.BUFFER_SIZE) {
-				for (int i = startTokenIndex; i < RdfN3ParsingContentHandler.BUFFER_SIZE; i++) {
-					builder.append((char) buffer[i]);
-				}
-				for (int i = RdfN3ParsingContentHandler.BUFFER_SIZE + 1; i < (2 * RdfN3ParsingContentHandler.BUFFER_SIZE + 1); i++) {
-					builder.append((char) buffer[i]);
-				}
-				for (int i = 0; i < scoutIndex; i++) {
-					builder.append((char) buffer[i]);
-				}
-			} else {
-				for (int i = startTokenIndex; i < (2 * RdfN3ParsingContentHandler.BUFFER_SIZE + 1); i++) {
-					builder.append((char) buffer[i]);
-				}
-				for (int i = 0; i < scoutIndex; i++) {
-					builder.append((char) buffer[i]);
-				}
-			}
-		}
-		// the current token is consumed.
-		startTokenIndex = scoutIndex;
-		return builder.toString();
-	}
-
-	/**
-	 * Returns the given lexical unit as a predicate.
-	 * 
-	 * @param lexicalUnit
-	 *            The lexical unit to get as a predicate.
-	 * @return A RDF URI reference of the predicate.
-	 */
-	private Reference getPredicate(LexicalUnit lexicalUnit) {
-		Reference result = null;
-		Object p = lexicalUnit.resolve();
-		if (p instanceof Reference) {
-			result = (Reference) p;
-		} else if (p instanceof String) {
-			result = new Reference((String) p);
-		}
-
-		return result;
-	}
-
-	@Override
-	public void link(Graph source, Reference typeRef, Literal target) {
-		this.linkSet.add(source, typeRef, target);
-	}
-
-	@Override
-	public void link(Graph source, Reference typeRef, Reference target) {
-		this.linkSet.add(source, typeRef, target);
-	}
-
-	/**
-	 * Callback method used when a link is parsed or written.
-	 * 
-	 * @param source
-	 *            The source or subject of the link.
-	 * @param typeRef
-	 *            The type reference of the link.
-	 * @param target
-	 *            The target or object of the link.
-	 */
-	private void link(Object source, Reference typeRef, Object target) {
-		if (source instanceof Reference) {
-			if (target instanceof Reference) {
-				link((Reference) source, typeRef, (Reference) target);
-			} else if (target instanceof Literal) {
-				link((Reference) source, typeRef, (Literal) target);
-			} else {
-				// Error?
-			}
-		} else if (source instanceof Graph) {
-			if (target instanceof Reference) {
-				link((Graph) source, typeRef, (Reference) target);
-			} else if (target instanceof Literal) {
-				link((Graph) source, typeRef, (Literal) target);
-			} else {
-				// Error?
-			}
-		}
-	}
-
-	@Override
-	public void link(Reference source, Reference typeRef, Literal target) {
-		this.linkSet.add(source, typeRef, target);
-	}
-
-	@Override
-	public void link(Reference source, Reference typeRef, Reference target) {
-		this.linkSet.add(source, typeRef, target);
-	}
-
-	/**
-	 * Parses the current representation.
-	 * 
-	 * @throws IOException
-	 */
-	private void parse() throws IOException {
-		// Init the reading.
-		step();
-		do {
-			consumeWhiteSpaces();
-			switch (getChar()) {
-			case '@':
-				parseDirective(this.context);
-				break;
-			case '#':
-				parseComment();
-				break;
-			case '.':
-				step();
-				break;
-			default:
-				parseStatement(this.context);
-				break;
-			}
-		} while (getChar() != RdfN3ParsingContentHandler.EOF);
-
-	}
-
-	/**
-	 * Parses a comment.
-	 * 
-	 * @throws IOException
-	 */
-	public void parseComment() throws IOException {
-		int c;
-		do {
-			c = step();
-		} while (c != RdfN3ParsingContentHandler.EOF && c != '\n' && c != '\r');
-		discard();
-	}
-
-	/**
-	 * Parse the current directive and update the context according to the kind
-	 * of directive (""base"", ""prefix"", etc).
-	 * 
-	 * @param context
-	 *            The context to update.
-	 * @throws IOException
-	 */
-	public void parseDirective(Context context) throws IOException {
-		// Remove the leading '@' character.
-		step();
-		discard();
-		String currentKeyword = parseToken();
-		if (""base"".equalsIgnoreCase(currentKeyword)) {
-			consumeWhiteSpaces();
-			String base = parseUri();
-			Reference ref = new Reference(base);
-			if (ref.isRelative()) {
-				context.getBase().addSegment(base);
-			} else {
-				context.setBase(ref);
-			}
-			consumeStatement();
-		} else if (""prefix"".equalsIgnoreCase(currentKeyword)) {
-			consumeWhiteSpaces();
-			String prefix = parseToken();
-			consumeWhiteSpaces();
-			String uri = parseUri();
-			context.getPrefixes().put(prefix, uri);
-			consumeStatement();
-		} else if (""keywords"".equalsIgnoreCase(currentKeyword)) {
-			consumeWhiteSpaces();
-			int c;
-			do {
-				c = step();
-			} while (c != RdfN3ParsingContentHandler.EOF && c != '.');
-			String strKeywords = getCurrentToken();
-			String[] keywords = strKeywords.split("","");
-			context.getKeywords().clear();
-			for (String keyword : keywords) {
-				context.getKeywords().add(keyword.trim());
-			}
-			consumeStatement();
-		} else {
-			// TODO @ForAll and @ForSome are not supported yet.
-			consumeStatement();
-		}
-	}
-
-	/**
-	 * Reads the current statement until its end, and parses it.
-	 * 
-	 * @param context
-	 *            The current context.
-	 * @throws IOException
-	 */
-	public void parseStatement(Context context) throws IOException {
-		List<LexicalUnit> lexicalUnits = new ArrayList<LexicalUnit>();
-		do {
-			consumeWhiteSpaces();
-			switch (getChar()) {
-			case '(':
-				lexicalUnits.add(new ListToken(this, context));
-				break;
-			case '<':
-				if (step() == '=') {
-					lexicalUnits.add(new Token(""<=""));
-					step();
-					discard();
-				} else {
-					stepBack();
-					lexicalUnits.add(new UriToken(this, context));
-				}
-				break;
-			case '_':
-				lexicalUnits.add(new BlankNodeToken(parseToken()));
-				break;
-			case '""':
-				lexicalUnits.add(new StringToken(this, context));
-				break;
-			case '[':
-				lexicalUnits.add(new BlankNodeToken(this, context));
-				break;
-			case '!':
-				lexicalUnits.add(new Token(""!""));
-				step();
-				discard();
-				break;
-			case '^':
-				lexicalUnits.add(new Token(""^""));
-				step();
-				discard();
-				break;
-			case '=':
-				if (step() == '>') {
-					lexicalUnits.add(new Token(""=>""));
-					step();
-					discard();
-				} else {
-					lexicalUnits.add(new Token(""=""));
-					discard();
-				}
-				break;
-			case '@':
-				// Remove the leading '@' character.
-				step();
-				discard();
-				lexicalUnits.add(new Token(this, context));
-				discard();
-				break;
-			case ';':
-				// TODO
-				step();
-				discard();
-				lexicalUnits.add(new Token("";""));
-				break;
-			case ',':
-				// TODO
-				step();
-				discard();
-				lexicalUnits.add(new Token("",""));
-				break;
-			case '{':
-				lexicalUnits.add(new FormulaToken(this, context));
-				break;
-			case '.':
-				break;
-			case RdfN3ParsingContentHandler.EOF:
-				break;
-			default:
-				lexicalUnits.add(new Token(this, context));
-				break;
-			}
-		} while (getChar() != RdfN3ParsingContentHandler.EOF
-				&& getChar() != '.' && getChar() != '}');
-
-		// Generate the links
-		generateLinks(lexicalUnits);
-	}
-
-	/**
-	 * Returns the value of the current token.
-	 * 
-	 * @return The value of the current token.
-	 * @throws IOException
-	 */
-	public String parseToken() throws IOException {
-		int c;
-		do {
-			c = step();
-		} while (c != RdfN3ParsingContentHandler.EOF && !isDelimiter(c));
-		String result = getCurrentToken();
-		return result;
-	}
-
-	/**
-	 * Returns the value of the current URI.
-	 * 
-	 * @return The value of the current URI.
-	 * @throws IOException
-	 */
-	public String parseUri() throws IOException {
-		StringBuilder builder = new StringBuilder();
-		// Suppose the current character is ""<"".
-		int c = step();
-		while (c != RdfN3ParsingContentHandler.EOF && c != '>') {
-			if (!isWhiteSpace(c)) {
-				// Discard white spaces.
-				builder.append((char) c);
-			}
-			c = step();
-		}
-		if (c == '>') {
-			// Set the cursor at the right of the uri.
-			step();
-		}
-		discard();
-
-		return builder.toString();
-	}
-
-	/**
-	 * Read a new character.
-	 * 
-	 * @return The new read character.
-	 * @throws IOException
-	 */
-	public int step() throws IOException {
-		scoutIndex++;
-		if (buffer[scoutIndex] == RdfN3ParsingContentHandler.EOF) {
-			if (scoutIndex == RdfN3ParsingContentHandler.BUFFER_SIZE) {
-				// Reached the end of the first part of the buffer, read into
-				// the second one.
-				scoutIndex++;
-				int len = this.br.read(buffer, 0,
-						RdfN3ParsingContentHandler.BUFFER_SIZE);
-				if (len == -1) {
-					// End of the stream reached
-					buffer[scoutIndex] = RdfN3ParsingContentHandler.EOF;
-				} else {
-					buffer[RdfN3ParsingContentHandler.BUFFER_SIZE + len + 1] = RdfN3ParsingContentHandler.EOF;
-				}
-			} else if (scoutIndex == (2 * RdfN3ParsingContentHandler.BUFFER_SIZE + 1)) {
-				scoutIndex = 0;
-				// Reached the end of the second part of the buffer, read into
-				// the first one.
-				int len = this.br.read(buffer, 0,
-						RdfN3ParsingContentHandler.BUFFER_SIZE);
-				if (len == -1) {
-					// End of the stream reached
-					buffer[scoutIndex] = RdfN3ParsingContentHandler.EOF;
-				} else {
-					buffer[len] = RdfN3ParsingContentHandler.EOF;
-				}
-			} else {
-				// Reached the end of the stream.
-			}
-		}
-
-		return buffer[scoutIndex];
-	}
-
-	/**
-	 * Steps forward.
-	 * 
-	 * @param n
-	 *            the number of steps to go forward.
-	 * @throws IOException
-	 */
-	public void step(int n) throws IOException {
-		for (int i = 0; i < n; i++) {
-			step();
-		}
-	}
-
-	/**
-	 * Steps back of one step.
-	 * 
-	 */
-	public void stepBack() {
-		stepBack(1);
-	}
-
-	/**
-	 * Steps back.
-	 * 
-	 * @param n
-	 *            the number of steps to go back.
-	 */
-	public void stepBack(int n) {
-		scoutIndex -= n;
-		if (scoutIndex < 0) {
-			scoutIndex = RdfN3ParsingContentHandler.BUFFER_SIZE * 2 + 1
-					- scoutIndex;
-		}
-	}
+
+    /** Increment used to identify inner blank nodes. */
+    private static int blankNodeId = 0;
+
+    /** Size of the reading buffer. */
+    private static final int BUFFER_SIZE = 4096;
+
+    /** End of reading buffer marker. */
+    public static final int EOF = 0;
+
+    /**
+     * Returns true if the given character is alphanumeric.
+     * 
+     * @param c
+     *            The given character to check.
+     * @return true if the given character is alphanumeric.
+     */
+    public static boolean isAlphaNum(int c) {
+        return (c >= 'a' && c <= 'z') || (c >= 'A' && c <= 'Z')
+                || (c >= '0' && c <= '9');
+    }
+
+    /**
+     * Returns true if the given character is a delimiter.
+     * 
+     * @param c
+     *            The given character to check.
+     * @return true if the given character is a delimiter.
+     */
+    public static boolean isDelimiter(int c) {
+        return isWhiteSpace(c) || c == '^' || c == '!' || c == '=' || c == '<'
+                || c == '""' || c == '{' || c == '}' || c == '[' || c == ']'
+                || c == '(' || c == ')' || c == '.' || c == ';' || c == ','
+                || c == '@';
+    }
+
+    /**
+     * Returns true if the given character is a whitespace.
+     * 
+     * @param c
+     *            The given character to check.
+     * @return true if the given character is a whitespace.
+     */
+    public static boolean isWhiteSpace(int c) {
+        return c == ' ' || c == '\n' || c == '\r' || c == '\t';
+    }
+
+    /**
+     * Returns the identifier of a new blank node.
+     * 
+     * @return The identifier of a new blank node.
+     */
+    public static String newBlankNodeId() {
+        return ""#_bn"" + blankNodeId++;
+    }
+
+    /** Internal buffered reader. */
+    private BufferedReader br;
+
+    /** The reading buffer. */
+    private final char[] buffer;
+
+    /** The current context object. */
+    private Context context;
+
+    /** The set of links to update when parsing. */
+    private Graph linkSet;
+
+    /** The representation to read. */
+    private Representation rdfN3Representation;
+
+    /**
+     * Index that discovers the end of the current token and the beginning of
+     * the futur one.
+     */
+    private int scoutIndex;
+
+    /** Start index of current lexical unit. */
+    private int startTokenIndex;
+
+    /**
+     * Constructor.
+     * 
+     * @param linkSet
+     *            The set of links to update during the parsing.
+     * @param rdfN3Representation
+     *            The representation to read.
+     * @throws IOException
+     */
+    public RdfN3ParsingContentHandler(Graph linkSet,
+            Representation rdfN3Representation) throws IOException {
+        super();
+        this.linkSet = linkSet;
+        this.rdfN3Representation = rdfN3Representation;
+
+        // Initialize the buffer in two parts
+        this.buffer = new char[(RdfN3ParsingContentHandler.BUFFER_SIZE + 1) * 2];
+        // Mark the upper index of each part.
+        this.buffer[RdfN3ParsingContentHandler.BUFFER_SIZE] = this.buffer[2 * RdfN3ParsingContentHandler.BUFFER_SIZE + 1] = EOF;
+        this.scoutIndex = 2 * RdfN3ParsingContentHandler.BUFFER_SIZE;
+        this.startTokenIndex = 0;
+
+        this.br = new BufferedReader(new InputStreamReader(
+                this.rdfN3Representation.getStream()));
+        this.context = new Context();
+        context.getKeywords().addAll(
+                Arrays.asList(""a"", ""is"", ""of"", ""this"", ""has""));
+        parse();
+    }
+
+    /**
+     * Discard all read characters until the end of the statement is reached
+     * (marked by a '.').
+     * 
+     * @throws IOException
+     */
+    public void consumeStatement() throws IOException {
+        int c = getChar();
+        while (c != RdfN3ParsingContentHandler.EOF && c != '.') {
+            c = step();
+        }
+        if (getChar() == '.') {
+            // A further step at the right of the statement.
+            step();
+        }
+        discard();
+    }
+
+    /**
+     * Discard all read characters. A call to {@link getCurrentToken} will
+     * return a single character.
+     * 
+     * @throws IOException
+     */
+    public void consumeWhiteSpaces() throws IOException {
+        while (RdfN3ParsingContentHandler.isWhiteSpace(getChar())) {
+            step();
+        }
+        discard();
+    }
+
+    /**
+     * Discard all read characters. A call to {@link getCurrentToken} will
+     * return a single character.
+     */
+    public void discard() {
+        startTokenIndex = scoutIndex;
+    }
+
+    /**
+     * Loops over the given list of lexical units and generates the adequat
+     * calls to link* methods.
+     * 
+     * @see GraphHandler#link(Graph, Reference, Reference)
+     * @see GraphHandler#link(Reference, Reference, Literal)
+     * @see GraphHandler#link(Reference, Reference, Reference)
+     * @param lexicalUnits
+     *            The list of lexical units used to generate the links.
+     */
+    public void generateLinks(List<LexicalUnit> lexicalUnits) {
+        Object currentSubject = null;
+        Reference currentPredicate = null;
+        Object currentObject = null;
+        int nbTokens = 0;
+        boolean swapSubjectObject = false;
+        for (int i = 0; i < lexicalUnits.size(); i++) {
+            LexicalUnit lexicalUnit = lexicalUnits.get(i);
+
+            nbTokens++;
+            switch (nbTokens) {
+            case 1:
+                if ("","".equals(lexicalUnit.getValue())) {
+                    nbTokens++;
+                } else if (!"";"".equals(lexicalUnit.getValue())) {
+                    currentSubject = lexicalUnit.resolve();
+                }
+                break;
+            case 2:
+                if (""is"".equalsIgnoreCase(lexicalUnit.getValue())) {
+                    nbTokens--;
+                    swapSubjectObject = true;
+                } else if (""has"".equalsIgnoreCase(lexicalUnit.getValue())) {
+                    nbTokens--;
+                } else if (""="".equalsIgnoreCase(lexicalUnit.getValue())) {
+                    currentPredicate = RdfConstants.PREDICATE_SAME;
+                } else if (""=>"".equalsIgnoreCase(lexicalUnit.getValue())) {
+                    currentPredicate = RdfConstants.PREDICATE_IMPLIES;
+                } else if (""<="".equalsIgnoreCase(lexicalUnit.getValue())) {
+                    swapSubjectObject = true;
+                    currentPredicate = RdfConstants.PREDICATE_IMPLIES;
+                } else if (""a"".equalsIgnoreCase(lexicalUnit.getValue())) {
+                    currentPredicate = RdfConstants.PREDICATE_TYPE;
+                } else if (""!"".equalsIgnoreCase(lexicalUnit.getValue())) {
+                    currentObject = new BlankNodeToken(
+                            RdfN3ParsingContentHandler.newBlankNodeId())
+                            .resolve();
+                    currentPredicate = getPredicate(lexicalUnits.get(++i));
+                    this.link(currentSubject, currentPredicate, currentObject);
+                    currentSubject = currentObject;
+                    nbTokens = 1;
+                } else if (""^"".equalsIgnoreCase(lexicalUnit.getValue())) {
+                    currentObject = currentSubject;
+                    currentPredicate = getPredicate(lexicalUnits.get(++i));
+                    currentSubject = new BlankNodeToken(
+                            RdfN3ParsingContentHandler.newBlankNodeId())
+                            .resolve();
+                    this.link(currentSubject, currentPredicate, currentObject);
+                    nbTokens = 1;
+                } else {
+                    currentPredicate = getPredicate(lexicalUnit);
+                }
+                break;
+            case 3:
+                if (""of"".equalsIgnoreCase(lexicalUnit.getValue())) {
+                    nbTokens--;
+                } else {
+                    if (swapSubjectObject) {
+                        currentObject = currentSubject;
+                        currentSubject = lexicalUnit.resolve();
+                    } else {
+                        currentObject = lexicalUnit.resolve();
+                    }
+                    this.link(currentSubject, currentPredicate, currentObject);
+                    nbTokens = 0;
+                    swapSubjectObject = false;
+                }
+                break;
+            default:
+                break;
+            }
+        }
+    }
+
+    /**
+     * Returns the current parsed character.
+     * 
+     * @return The current parsed character.
+     */
+    public char getChar() {
+        return (char) buffer[scoutIndex];
+    }
+
+    /**
+     * Returns the current token.
+     * 
+     * @return The current token.
+     */
+    public String getCurrentToken() {
+        StringBuilder builder = new StringBuilder();
+        if (startTokenIndex <= scoutIndex) {
+            if (scoutIndex <= RdfN3ParsingContentHandler.BUFFER_SIZE) {
+                for (int i = startTokenIndex; i < scoutIndex; i++) {
+                    builder.append((char) buffer[i]);
+                }
+            } else {
+                for (int i = startTokenIndex; i < RdfN3ParsingContentHandler.BUFFER_SIZE; i++) {
+                    builder.append((char) buffer[i]);
+                }
+                for (int i = RdfN3ParsingContentHandler.BUFFER_SIZE + 1; i < scoutIndex; i++) {
+                    builder.append((char) buffer[i]);
+                }
+            }
+        } else {
+            if (startTokenIndex <= RdfN3ParsingContentHandler.BUFFER_SIZE) {
+                for (int i = startTokenIndex; i < RdfN3ParsingContentHandler.BUFFER_SIZE; i++) {
+                    builder.append((char) buffer[i]);
+                }
+                for (int i = RdfN3ParsingContentHandler.BUFFER_SIZE + 1; i < (2 * RdfN3ParsingContentHandler.BUFFER_SIZE + 1); i++) {
+                    builder.append((char) buffer[i]);
+                }
+                for (int i = 0; i < scoutIndex; i++) {
+                    builder.append((char) buffer[i]);
+                }
+            } else {
+                for (int i = startTokenIndex; i < (2 * RdfN3ParsingContentHandler.BUFFER_SIZE + 1); i++) {
+                    builder.append((char) buffer[i]);
+                }
+                for (int i = 0; i < scoutIndex; i++) {
+                    builder.append((char) buffer[i]);
+                }
+            }
+        }
+        // the current token is consumed.
+        startTokenIndex = scoutIndex;
+        return builder.toString();
+    }
+
+    /**
+     * Returns the given lexical unit as a predicate.
+     * 
+     * @param lexicalUnit
+     *            The lexical unit to get as a predicate.
+     * @return A RDF URI reference of the predicate.
+     */
+    private Reference getPredicate(LexicalUnit lexicalUnit) {
+        Reference result = null;
+        Object p = lexicalUnit.resolve();
+        if (p instanceof Reference) {
+            result = (Reference) p;
+        } else if (p instanceof String) {
+            result = new Reference((String) p);
+        }
+
+        return result;
+    }
+
+    @Override
+    public void link(Graph source, Reference typeRef, Literal target) {
+        this.linkSet.add(source, typeRef, target);
+    }
+
+    @Override
+    public void link(Graph source, Reference typeRef, Reference target) {
+        this.linkSet.add(source, typeRef, target);
+    }
+
+    /**
+     * Callback method used when a link is parsed or written.
+     * 
+     * @param source
+     *            The source or subject of the link.
+     * @param typeRef
+     *            The type reference of the link.
+     * @param target
+     *            The target or object of the link.
+     */
+    private void link(Object source, Reference typeRef, Object target) {
+        if (source instanceof Reference) {
+            if (target instanceof Reference) {
+                link((Reference) source, typeRef, (Reference) target);
+            } else if (target instanceof Literal) {
+                link((Reference) source, typeRef, (Literal) target);
+            } else {
+                // Error?
+            }
+        } else if (source instanceof Graph) {
+            if (target instanceof Reference) {
+                link((Graph) source, typeRef, (Reference) target);
+            } else if (target instanceof Literal) {
+                link((Graph) source, typeRef, (Literal) target);
+            } else {
+                // Error?
+            }
+        }
+    }
+
+    @Override
+    public void link(Reference source, Reference typeRef, Literal target) {
+        this.linkSet.add(source, typeRef, target);
+    }
+
+    @Override
+    public void link(Reference source, Reference typeRef, Reference target) {
+        this.linkSet.add(source, typeRef, target);
+    }
+
+    /**
+     * Parses the current representation.
+     * 
+     * @throws IOException
+     */
+    private void parse() throws IOException {
+        // Init the reading.
+        step();
+        do {
+            consumeWhiteSpaces();
+            switch (getChar()) {
+            case '@':
+                parseDirective(this.context);
+                break;
+            case '#':
+                parseComment();
+                break;
+            case '.':
+                step();
+                break;
+            default:
+                parseStatement(this.context);
+                break;
+            }
+        } while (getChar() != RdfN3ParsingContentHandler.EOF);
+
+    }
+
+    /**
+     * Parses a comment.
+     * 
+     * @throws IOException
+     */
+    public void parseComment() throws IOException {
+        int c;
+        do {
+            c = step();
+        } while (c != RdfN3ParsingContentHandler.EOF && c != '\n' && c != '\r');
+        discard();
+    }
+
+    /**
+     * Parse the current directive and update the context according to the kind
+     * of directive (""base"", ""prefix"", etc).
+     * 
+     * @param context
+     *            The context to update.
+     * @throws IOException
+     */
+    public void parseDirective(Context context) throws IOException {
+        // Remove the leading '@' character.
+        step();
+        discard();
+        String currentKeyword = parseToken();
+        if (""base"".equalsIgnoreCase(currentKeyword)) {
+            consumeWhiteSpaces();
+            String base = parseUri();
+            Reference ref = new Reference(base);
+            if (ref.isRelative()) {
+                context.getBase().addSegment(base);
+            } else {
+                context.setBase(ref);
+            }
+            consumeStatement();
+        } else if (""prefix"".equalsIgnoreCase(currentKeyword)) {
+            consumeWhiteSpaces();
+            String prefix = parseToken();
+            consumeWhiteSpaces();
+            String uri = parseUri();
+            context.getPrefixes().put(prefix, uri);
+            consumeStatement();
+        } else if (""keywords"".equalsIgnoreCase(currentKeyword)) {
+            consumeWhiteSpaces();
+            int c;
+            do {
+                c = step();
+            } while (c != RdfN3ParsingContentHandler.EOF && c != '.');
+            String strKeywords = getCurrentToken();
+            String[] keywords = strKeywords.split("","");
+            context.getKeywords().clear();
+            for (String keyword : keywords) {
+                context.getKeywords().add(keyword.trim());
+            }
+            consumeStatement();
+        } else {
+            // TODO @ForAll and @ForSome are not supported yet.
+            consumeStatement();
+        }
+    }
+
+    /**
+     * Reads the current statement until its end, and parses it.
+     * 
+     * @param context
+     *            The current context.
+     * @throws IOException
+     */
+    public void parseStatement(Context context) throws IOException {
+        List<LexicalUnit> lexicalUnits = new ArrayList<LexicalUnit>();
+        do {
+            consumeWhiteSpaces();
+            switch (getChar()) {
+            case '(':
+                lexicalUnits.add(new ListToken(this, context));
+                break;
+            case '<':
+                if (step() == '=') {
+                    lexicalUnits.add(new Token(""<=""));
+                    step();
+                    discard();
+                } else {
+                    stepBack();
+                    lexicalUnits.add(new UriToken(this, context));
+                }
+                break;
+            case '_':
+                lexicalUnits.add(new BlankNodeToken(parseToken()));
+                break;
+            case '""':
+                lexicalUnits.add(new StringToken(this, context));
+                break;
+            case '[':
+                lexicalUnits.add(new BlankNodeToken(this, context));
+                break;
+            case '!':
+                lexicalUnits.add(new Token(""!""));
+                step();
+                discard();
+                break;
+            case '^':
+                lexicalUnits.add(new Token(""^""));
+                step();
+                discard();
+                break;
+            case '=':
+                if (step() == '>') {
+                    lexicalUnits.add(new Token(""=>""));
+                    step();
+                    discard();
+                } else {
+                    lexicalUnits.add(new Token(""=""));
+                    discard();
+                }
+                break;
+            case '@':
+                // Remove the leading '@' character.
+                step();
+                discard();
+                lexicalUnits.add(new Token(this, context));
+                discard();
+                break;
+            case ';':
+                // TODO
+                step();
+                discard();
+                lexicalUnits.add(new Token("";""));
+                break;
+            case ',':
+                // TODO
+                step();
+                discard();
+                lexicalUnits.add(new Token("",""));
+                break;
+            case '{':
+                lexicalUnits.add(new FormulaToken(this, context));
+                break;
+            case '.':
+                break;
+            case RdfN3ParsingContentHandler.EOF:
+                break;
+            default:
+                lexicalUnits.add(new Token(this, context));
+                break;
+            }
+        } while (getChar() != RdfN3ParsingContentHandler.EOF
+                && getChar() != '.' && getChar() != '}');
+
+        // Generate the links
+        generateLinks(lexicalUnits);
+    }
+
+    /**
+     * Returns the value of the current token.
+     * 
+     * @return The value of the current token.
+     * @throws IOException
+     */
+    public String parseToken() throws IOException {
+        int c;
+        do {
+            c = step();
+        } while (c != RdfN3ParsingContentHandler.EOF && !isDelimiter(c));
+        String result = getCurrentToken();
+        return result;
+    }
+
+    /**
+     * Returns the value of the current URI.
+     * 
+     * @return The value of the current URI.
+     * @throws IOException
+     */
+    public String parseUri() throws IOException {
+        StringBuilder builder = new StringBuilder();
+        // Suppose the current character is ""<"".
+        int c = step();
+        while (c != RdfN3ParsingContentHandler.EOF && c != '>') {
+            if (!isWhiteSpace(c)) {
+                // Discard white spaces.
+                builder.append((char) c);
+            }
+            c = step();
+        }
+        if (c == '>') {
+            // Set the cursor at the right of the uri.
+            step();
+        }
+        discard();
+
+        return builder.toString();
+    }
+
+    /**
+     * Read a new character.
+     * 
+     * @return The new read character.
+     * @throws IOException
+     */
+    public int step() throws IOException {
+        scoutIndex++;
+        if (buffer[scoutIndex] == RdfN3ParsingContentHandler.EOF) {
+            if (scoutIndex == RdfN3ParsingContentHandler.BUFFER_SIZE) {
+                // Reached the end of the first part of the buffer, read into
+                // the second one.
+                scoutIndex++;
+                int len = this.br.read(buffer, 0,
+                        RdfN3ParsingContentHandler.BUFFER_SIZE);
+                if (len == -1) {
+                    // End of the stream reached
+                    buffer[scoutIndex] = RdfN3ParsingContentHandler.EOF;
+                } else {
+                    buffer[RdfN3ParsingContentHandler.BUFFER_SIZE + len + 1] = RdfN3ParsingContentHandler.EOF;
+                }
+            } else if (scoutIndex == (2 * RdfN3ParsingContentHandler.BUFFER_SIZE + 1)) {
+                scoutIndex = 0;
+                // Reached the end of the second part of the buffer, read into
+                // the first one.
+                int len = this.br.read(buffer, 0,
+                        RdfN3ParsingContentHandler.BUFFER_SIZE);
+                if (len == -1) {
+                    // End of the stream reached
+                    buffer[scoutIndex] = RdfN3ParsingContentHandler.EOF;
+                } else {
+                    buffer[len] = RdfN3ParsingContentHandler.EOF;
+                }
+            } else {
+                // Reached the end of the stream.
+            }
+        }
+
+        return buffer[scoutIndex];
+    }
+
+    /**
+     * Steps forward.
+     * 
+     * @param n
+     *            the number of steps to go forward.
+     * @throws IOException
+     */
+    public void step(int n) throws IOException {
+        for (int i = 0; i < n; i++) {
+            step();
+        }
+    }
+
+    /**
+     * Steps back of one step.
+     * 
+     */
+    public void stepBack() {
+        stepBack(1);
+    }
+
+    /**
+     * Steps back.
+     * 
+     * @param n
+     *            the number of steps to go back.
+     */
+    public void stepBack(int n) {
+        scoutIndex -= n;
+        if (scoutIndex < 0) {
+            scoutIndex = RdfN3ParsingContentHandler.BUFFER_SIZE * 2 + 1
+                    - scoutIndex;
+        }
+    }
 
 }
diff --git a/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/internal/n3/RdfN3WritingContentHandler.java b/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/internal/n3/RdfN3WritingContentHandler.java
index b6db8b371..2ab77fb25 100644
--- a/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/internal/n3/RdfN3WritingContentHandler.java
+++ b/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/internal/n3/RdfN3WritingContentHandler.java
@@ -48,251 +48,253 @@ import org.restlet.ext.rdf.internal.RdfConstants;
 /**
  * Handler of RDF content according to the N3 notation.
+ * 
+ * @author Thierry Boileau
  */
 public class RdfN3WritingContentHandler extends GraphHandler {
 
-	/** Buffered writer. */
-	BufferedWriter bw;
+    /** Buffered writer. */
+    private BufferedWriter bw;
 
-	/** The current context object. */
-	private Context context;
+    /** The current context object. */
+    private Context context;
 
-	/** The preceding predicate used for factorization matter. */
-	private Reference precPredicate;
+    /** The preceding predicate used for factorization matter. */
+    private Reference precPredicate;
 
-	/** The preceding source used for factorization matter. */
-	private Reference precSource;
+    /** The preceding source used for factorization matter. */
+    private Reference precSource;
 
-	/** Indicates if the end of the statement is to be written. */
-	private boolean writeExtraDot;
+    /** Indicates if the end of the statement is to be written. */
+    private boolean writeExtraDot;
 
-	/**
-	 * Constructor.
-	 * 
-	 * @param linkSet
-	 *            The set of links to write to the output stream.
-	 * @param outputStream
-	 *            The output stream to write to.
-	 * @throws IOException
-	 * @throws IOException
-	 */
-	public RdfN3WritingContentHandler(Graph linkset, OutputStream outputStream)
-			throws IOException {
-		super();
-		this.bw = new BufferedWriter(new OutputStreamWriter(outputStream));
-		this.context = new Context();
-		Map<String, String> prefixes = context.getPrefixes();
-		prefixes.put(RdfConstants.RDF_SCHEMA.toString(), ""rdf"");
-		prefixes.put(RdfConstants.RDF_SYNTAX.toString(), ""rdfs"");
-		prefixes.put(""http://www.w3.org/2000/10/swap/grammar/bnf#"", ""cfg"");
-		prefixes.put(""http://www.w3.org/2000/10/swap/grammar/n3#"", ""n3"");
-		prefixes.put(""http://www.w3.org/2000/10/swap/list#"", ""list"");
-		prefixes.put(""http://www.w3.org/2000/10/swap/pim/doc#"", ""doc"");
-		prefixes.put(""http://www.w3.org/2002/07/owl#"", ""owl"");
-		prefixes.put(""http://www.w3.org/2000/10/swap/log#"", ""log"");
-		prefixes.put(""http://purl.org/dc/elements/1.1/"", ""dc"");
-		prefixes.put(""http://www.w3.org/2001/XMLSchema#"", ""type"");
+    /**
+     * Constructor.
+     * 
+     * @param linkSet
+     *            The set of links to write to the output stream.
+     * @param outputStream
+     *            The output stream to write to.
+     * @throws IOException
+     * @throws IOException
+     */
+    public RdfN3WritingContentHandler(Graph linkset, OutputStream outputStream)
+            throws IOException {
+        super();
+        this.bw = new BufferedWriter(new OutputStreamWriter(outputStream));
+        this.context = new Context();
+        Map<String, String> prefixes = context.getPrefixes();
+        prefixes.put(RdfConstants.RDF_SCHEMA.toString(), ""rdf"");
+        prefixes.put(RdfConstants.RDF_SYNTAX.toString(), ""rdfs"");
+        prefixes.put(""http://www.w3.org/2000/10/swap/grammar/bnf#"", ""cfg"");
+        prefixes.put(""http://www.w3.org/2000/10/swap/grammar/n3#"", ""n3"");
+        prefixes.put(""http://www.w3.org/2000/10/swap/list#"", ""list"");
+        prefixes.put(""http://www.w3.org/2000/10/swap/pim/doc#"", ""doc"");
+        prefixes.put(""http://www.w3.org/2002/07/owl#"", ""owl"");
+        prefixes.put(""http://www.w3.org/2000/10/swap/log#"", ""log"");
+        prefixes.put(""http://purl.org/dc/elements/1.1/"", ""dc"");
+        prefixes.put(""http://www.w3.org/2001/XMLSchema#"", ""type"");
 
-		for (Entry<String, String> entry : prefixes.entrySet()) {
-			this.bw.append(""@prefix "").append(entry.getValue()).append("": "")
-					.append(entry.getKey()).append("".\n"");
-		}
-		this.bw.append(""@keywords a, is, of, has.\n"");
+        for (Entry<String, String> entry : prefixes.entrySet()) {
+            this.bw.append(""@prefix "").append(entry.getValue()).append("": "")
+                    .append(entry.getKey()).append("".\n"");
+        }
+        this.bw.append(""@keywords a, is, of, has.\n"");
 
-		this.write(linkset);
-		this.bw.flush();
-	}
+        this.write(linkset);
+        this.bw.flush();
+    }
 
-	@Override
-	public void link(Graph source, Reference typeRef, Literal target) {
-		try {
-			this.bw.write(""{"");
-			write(source);
-			this.bw.write(""} "");
-			write(typeRef, this.context.getPrefixes());
-			this.bw.write("" "");
-			write(target);
-		} catch (IOException e) {
-			// TODO Auto-generated catch block
-		}
-	}
+    @Override
+    public void link(Graph source, Reference typeRef, Literal target) {
+        try {
+            this.bw.write(""{"");
+            write(source);
+            this.bw.write(""} "");
+            write(typeRef, this.context.getPrefixes());
+            this.bw.write("" "");
+            write(target);
+        } catch (IOException e) {
+            // TODO Auto-generated catch block
+        }
+    }
 
-	@Override
-	public void link(Graph source, Reference typeRef, Reference target) {
-		try {
-			this.bw.write(""{"");
-			write(source);
-			this.bw.write(""} "");
-			write(typeRef, this.context.getPrefixes());
-			this.bw.write("" "");
-			write(target, this.context.getPrefixes());
-		} catch (IOException e) {
-			// TODO Auto-generated catch block
-		}
-	}
+    @Override
+    public void link(Graph source, Reference typeRef, Reference target) {
+        try {
+            this.bw.write(""{"");
+            write(source);
+            this.bw.write(""} "");
+            write(typeRef, this.context.getPrefixes());
+            this.bw.write("" "");
+            write(target, this.context.getPrefixes());
+        } catch (IOException e) {
+            // TODO Auto-generated catch block
+        }
+    }
 
-	@Override
-	public void link(Reference source, Reference typeRef, Literal target) {
-		try {
-			if (source.equals(this.precSource)) {
-				if (typeRef.equals(this.precPredicate)) {
-					this.bw.write("", "");
-				} else {
-					this.bw.write(""; "");
-					write(typeRef, this.context.getPrefixes());
-					this.bw.write("" "");
-				}
-			} else {
-				write(source, this.context.getPrefixes());
-				this.bw.write("" "");
-				write(typeRef, this.context.getPrefixes());
-				this.bw.write("" "");
-			}
-			write(target);
-		} catch (IOException e) {
-			// TODO Auto-generated catch block
-		}
-	}
+    @Override
+    public void link(Reference source, Reference typeRef, Literal target) {
+        try {
+            if (source.equals(this.precSource)) {
+                if (typeRef.equals(this.precPredicate)) {
+                    this.bw.write("", "");
+                } else {
+                    this.bw.write(""; "");
+                    write(typeRef, this.context.getPrefixes());
+                    this.bw.write("" "");
+                }
+            } else {
+                write(source, this.context.getPrefixes());
+                this.bw.write("" "");
+                write(typeRef, this.context.getPrefixes());
+                this.bw.write("" "");
+            }
+            write(target);
+        } catch (IOException e) {
+            // TODO Auto-generated catch block
+        }
+    }
 
-	@Override
-	public void link(Reference source, Reference typeRef, Reference target) {
-		try {
-			if (source.equals(this.precSource)) {
-				this.writeExtraDot = false;
-				if (typeRef.equals(this.precPredicate)) {
-					this.bw.write("", "");
-				} else {
-					this.bw.write(""; "");
-					write(typeRef, this.context.getPrefixes());
-					this.bw.write("" "");
-				}
-			} else {
-				this.writeExtraDot = true;
-				write(source, this.context.getPrefixes());
-				this.bw.write("" "");
-				write(typeRef, this.context.getPrefixes());
-				this.bw.write("" "");
-			}
-			write(target, this.context.getPrefixes());
-		} catch (IOException e) {
-			// TODO Auto-generated catch block
-		}
-	}
+    @Override
+    public void link(Reference source, Reference typeRef, Reference target) {
+        try {
+            if (source.equals(this.precSource)) {
+                this.writeExtraDot = false;
+                if (typeRef.equals(this.precPredicate)) {
+                    this.bw.write("", "");
+                } else {
+                    this.bw.write(""; "");
+                    write(typeRef, this.context.getPrefixes());
+                    this.bw.write("" "");
+                }
+            } else {
+                this.writeExtraDot = true;
+                write(source, this.context.getPrefixes());
+                this.bw.write("" "");
+                write(typeRef, this.context.getPrefixes());
+                this.bw.write("" "");
+            }
+            write(target, this.context.getPrefixes());
+        } catch (IOException e) {
+            // TODO Auto-generated catch block
+        }
+    }
 
-	/**
-	 * Write the representation of the given graph of links.
-	 * 
-	 * @param linkset
-	 *            the given graph of links.
-	 * @throws IOException
-	 * @throws IOException
-	 */
-	private void write(Graph linkset) throws IOException {
-		for (Link link : linkset) {
-			if (link.hasReferenceSource()) {
-				if (!link.getSourceAsReference().equals(this.precSource)) {
-					this.bw.write("".\n"");
-					this.writeExtraDot = true;
-				}
-				if (link.hasReferenceTarget()) {
-					link(link.getSourceAsReference(), link.getTypeRef(), link
-							.getTargetAsReference());
-				} else if (link.hasLiteralTarget()) {
-					link(link.getSourceAsReference(), link.getTypeRef(), link
-							.getTargetAsLiteral());
-				} else if (link.hasLiteralTarget()) {
-					// TODO Hande source as link.
-				} else {
-					// Error?
-				}
-			} else if (link.hasGraphSource()) {
-				this.writeExtraDot = false;
-				if (link.hasReferenceTarget()) {
-					link(link.getSourceAsGraph(), link.getTypeRef(), link
-							.getTargetAsReference());
-				} else if (link.hasLiteralTarget()) {
-					link(link.getSourceAsGraph(), link.getTypeRef(), link
-							.getTargetAsLiteral());
-				} else if (link.hasLiteralTarget()) {
-					// TODO Hande source as link.
-				} else {
-					// Error?
-				}
-				this.bw.write("".\n"");
-			}
-			this.precSource = link.getSourceAsReference();
-			this.precPredicate = link.getTypeRef();
-		}
-		if (writeExtraDot) {
-			this.bw.write("".\n"");
-		}
-	}
+    /**
+     * Write the representation of the given graph of links.
+     * 
+     * @param linkset
+     *            the given graph of links.
+     * @throws IOException
+     * @throws IOException
+     */
+    private void write(Graph linkset) throws IOException {
+        for (Link link : linkset) {
+            if (link.hasReferenceSource()) {
+                if (!link.getSourceAsReference().equals(this.precSource)) {
+                    this.bw.write("".\n"");
+                    this.writeExtraDot = true;
+                }
+                if (link.hasReferenceTarget()) {
+                    link(link.getSourceAsReference(), link.getTypeRef(), link
+                            .getTargetAsReference());
+                } else if (link.hasLiteralTarget()) {
+                    link(link.getSourceAsReference(), link.getTypeRef(), link
+                            .getTargetAsLiteral());
+                } else if (link.hasLiteralTarget()) {
+                    // TODO Hande source as link.
+                } else {
+                    // Error?
+                }
+            } else if (link.hasGraphSource()) {
+                this.writeExtraDot = false;
+                if (link.hasReferenceTarget()) {
+                    link(link.getSourceAsGraph(), link.getTypeRef(), link
+                            .getTargetAsReference());
+                } else if (link.hasLiteralTarget()) {
+                    link(link.getSourceAsGraph(), link.getTypeRef(), link
+                            .getTargetAsLiteral());
+                } else if (link.hasLiteralTarget()) {
+                    // TODO Handle source as link.
+                } else {
+                    // Error?
+                }
+                this.bw.write("".\n"");
+            }
+            this.precSource = link.getSourceAsReference();
+            this.precPredicate = link.getTypeRef();
+        }
+        if (writeExtraDot) {
+            this.bw.write("".\n"");
+        }
+    }
 
-	/**
-	 * Writes the representation of a given reference to a byte stream.
-	 * 
-	 * @param outputStream
-	 *            The output stream.
-	 * @param reference
-	 *            The reference to write.
-	 * @param prefixes
-	 *            The map of known namespaces.
-	 * @throws IOException
-	 */
-	private void write(Literal literal) throws IOException {
-		// Write it as a string
-		this.bw.write(""\"""");
-		if (literal.getValue().contains(""\n"")) {
-			this.bw.write(""\"""");
-			this.bw.write(""\"""");
-			this.bw.write(literal.getValue());
-			this.bw.write(""\"""");
-			this.bw.write(""\"""");
-		} else {
-			this.bw.write(literal.getValue());
-		}
+    /**
+     * Writes the representation of a given reference to a byte stream.
+     * 
+     * @param outputStream
+     *            The output stream.
+     * @param reference
+     *            The reference to write.
+     * @param prefixes
+     *            The map of known namespaces.
+     * @throws IOException
+     */
+    private void write(Literal literal) throws IOException {
+        // Write it as a string
+        this.bw.write(""\"""");
+        if (literal.getValue().contains(""\n"")) {
+            this.bw.write(""\"""");
+            this.bw.write(""\"""");
+            this.bw.write(literal.getValue());
+            this.bw.write(""\"""");
+            this.bw.write(""\"""");
+        } else {
+            this.bw.write(literal.getValue());
+        }
 
-		this.bw.write(""\"""");
-		if (literal.getDatatypeRef() != null) {
-			this.bw.write(""^^"");
-			write(literal.getDatatypeRef(), context.getPrefixes());
-		}
-		if (literal.getLanguage() != null) {
-			this.bw.write(""@"");
-			this.bw.write(literal.getLanguage().toString());
-		}
-	}
+        this.bw.write(""\"""");
+        if (literal.getDatatypeRef() != null) {
+            this.bw.write(""^^"");
+            write(literal.getDatatypeRef(), context.getPrefixes());
+        }
+        if (literal.getLanguage() != null) {
+            this.bw.write(""@"");
+            this.bw.write(literal.getLanguage().toString());
+        }
+    }
 
-	/**
-	 * Writes the representation of a given reference.
-	 * 
-	 * @param reference
-	 *            The reference to write.
-	 * @param prefixes
-	 *            The map of known namespaces.
-	 * @throws IOException
-	 */
-	private void write(Reference reference, Map<String, String> prefixes)
-			throws IOException {
-		String uri = reference.toString();
-		if (LinkReference.isBlank(reference)) {
-			this.bw.write(uri);
-		} else {
-			boolean found = false;
-			for (Entry<String, String> entry : prefixes.entrySet()) {
-				if (uri.startsWith(entry.getKey())) {
-					found = true;
-					this.bw.append(entry.getValue());
-					this.bw.append("":"");
-					this.bw.append(uri.substring(entry.getKey().length()));
-					break;
-				}
-			}
-			if (!found) {
-				this.bw.append(""<"");
-				this.bw.append(uri);
-				this.bw.append("">"");
-			}
-		}
-	}
+    /**
+     * Writes the representation of a given reference.
+     * 
+     * @param reference
+     *            The reference to write.
+     * @param prefixes
+     *            The map of known namespaces.
+     * @throws IOException
+     */
+    private void write(Reference reference, Map<String, String> prefixes)
+            throws IOException {
+        String uri = reference.toString();
+        if (LinkReference.isBlank(reference)) {
+            this.bw.write(uri);
+        } else {
+            boolean found = false;
+            for (Entry<String, String> entry : prefixes.entrySet()) {
+                if (uri.startsWith(entry.getKey())) {
+                    found = true;
+                    this.bw.append(entry.getValue());
+                    this.bw.append("":"");
+                    this.bw.append(uri.substring(entry.getKey().length()));
+                    break;
+                }
+            }
+            if (!found) {
+                this.bw.append(""<"");
+                this.bw.append(uri);
+                this.bw.append("">"");
+            }
+        }
+    }
 
 }
diff --git a/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/internal/n3/StringToken.java b/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/internal/n3/StringToken.java
index ee99cf922..6922c42e0 100644
--- a/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/internal/n3/StringToken.java
+++ b/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/internal/n3/StringToken.java
@@ -39,4 +39,6 @@ import org.restlet.ext.rdf.Literal;
  * Represents a string of characters. This string could have a type and a
  * language.
+ * 
+ * @author Thierry Boileau
  */
 class StringToken extends LexicalUnit {
@@ -58,6 +60,6 @@ class StringToken extends LexicalUnit {
      *            The parsing context.
      */
-    public StringToken(RdfN3ParsingContentHandler contentHandler, Context context)
-            throws IOException {
+    public StringToken(RdfN3ParsingContentHandler contentHandler,
+            Context context) throws IOException {
         super(contentHandler, context);
         multiLines = false;
diff --git a/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/internal/n3/Token.java b/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/internal/n3/Token.java
index 08e63ff36..9d9eecfce 100644
--- a/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/internal/n3/Token.java
+++ b/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/internal/n3/Token.java
@@ -38,64 +38,66 @@ import org.restlet.ext.rdf.internal.RdfConstants;
 /**
  * Represents a still unidentified N3 token.
+ * 
+ * @author Thierry Boileau
  */
 class Token extends LexicalUnit {
 
-	/**
-	 * Constructor with arguments.
-	 * 
-	 * @param contentHandler
-	 *            The document's parent handler.
-	 * @param context
-	 *            The parsing context.
-	 */
-	public Token(RdfN3ParsingContentHandler contentHandler, Context context)
-			throws IOException {
-		super(contentHandler, context);
-		this.parse();
-	}
+    /**
+     * Constructor with arguments.
+     * 
+     * @param contentHandler
+     *            The document's parent handler.
+     * @param context
+     *            The parsing context.
+     */
+    public Token(RdfN3ParsingContentHandler contentHandler, Context context)
+            throws IOException {
+        super(contentHandler, context);
+        this.parse();
+    }
 
-	/**
-	 * Constructor with value.
-	 * 
-	 * @param value
-	 *            The value of the current lexical unit.
-	 */
-	public Token(String value) {
-		super(value);
-	}
+    /**
+     * Constructor with value.
+     * 
+     * @param value
+     *            The value of the current lexical unit.
+     */
+    public Token(String value) {
+        super(value);
+    }
 
-	@Override
-	public void parse() throws IOException {
-		int c;
-		do {
-			c = getContentHandler().step();
-		} while (c != RdfN3ParsingContentHandler.EOF
-				&& !RdfN3ParsingContentHandler.isDelimiter(c));
-		setValue(getContentHandler().getCurrentToken());
-	}
+    @Override
+    public void parse() throws IOException {
+        int c;
+        do {
+            c = getContentHandler().step();
+        } while (c != RdfN3ParsingContentHandler.EOF
+                && !RdfN3ParsingContentHandler.isDelimiter(c));
+        setValue(getContentHandler().getCurrentToken());
+    }
 
-	@Override
-	public Object resolve() {
-		Object result = null;
-		if (getContext().isQName(getValue())) {
-			result = (getContext() != null) ? getContext().resolve(getValue())
-					: getValue();
-		} else {
-			// Must be a literal
-			if (getValue().charAt(0) > '0' && getValue().charAt(0) < '9') {
-				if (getValue().contains(""."")) {
-					// Consider it as a float
-					result = new Literal(getValue(),
-							RdfConstants.XML_SCHEMA_TYPE_FLOAT);
-				} else {
-					// Consider it as an integer
-					result = new Literal(getValue(),
-							RdfConstants.XML_SCHEMA_TYPE_INTEGER);
-				}
-			} else {
-				// TODO What kind of literal?
-			}
-		}
-		return result;
-	}
+    @Override
+    public Object resolve() {
+        Object result = null;
+        if (getContext().isQName(getValue())) {
+            result = (getContext() != null) ? getContext().resolve(getValue())
+                    : getValue();
+        } else {
+            // Must be a literal
+            if (getValue().charAt(0) > '0' && getValue().charAt(0) < '9') {
+                if (getValue().contains(""."")) {
+                    // Consider it as a float
+                    result = new Literal(getValue(),
+                            RdfConstants.XML_SCHEMA_TYPE_FLOAT);
+                } else {
+                    // Consider it as an integer
+                    result = new Literal(getValue(),
+                            RdfConstants.XML_SCHEMA_TYPE_INTEGER);
+                }
+            } else {
+                // TODO What kind of literal?
+            }
+        }
+        return result;
+    }
 }
\ No newline at end of file
diff --git a/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/internal/n3/UriToken.java b/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/internal/n3/UriToken.java
index aab517028..ff5737d90 100644
--- a/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/internal/n3/UriToken.java
+++ b/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/internal/n3/UriToken.java
@@ -37,4 +37,6 @@ import org.restlet.data.Reference;
 /**
  * Represents a URI token inside a RDF N3 document.
+ * 
+ * @author Thierry Boileau
  */
 class UriToken extends LexicalUnit {
diff --git a/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/internal/xml/ContentReader.java b/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/internal/xml/ContentReader.java
new file mode 100644
index 000000000..0cfb97036
--- /dev/null
+++ b/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/internal/xml/ContentReader.java
@@ -0,0 +1,695 @@
+/**
+ * Copyright 2005-2009 Noelios Technologies.
+ * 
+ * The contents of this file are subject to the terms of one of the following
+ * open source licenses: LGPL 3.0 or LGPL 2.1 or CDDL 1.0 or EPL 1.0 (the
+ * ""Licenses""). You can select the license that you prefer but you may not use
+ * this file except in compliance with one of these Licenses.
+ * 
+ * You can obtain a copy of the LGPL 3.0 license at
+ * http://www.opensource.org/licenses/lgpl-3.0.html
+ * 
+ * You can obtain a copy of the LGPL 2.1 license at
+ * http://www.opensource.org/licenses/lgpl-2.1.php
+ * 
+ * You can obtain a copy of the CDDL 1.0 license at
+ * http://www.opensource.org/licenses/cddl1.php
+ * 
+ * You can obtain a copy of the EPL 1.0 license at
+ * http://www.opensource.org/licenses/eclipse-1.0.php
+ * 
+ * See the Licenses for the specific language governing permissions and
+ * limitations under the Licenses.
+ * 
+ * Alternatively, you can obtain a royalty free commercial license with less
+ * limitations, transferable or non-transferable, directly at
+ * http://www.noelios.com/products/restlet-engine
+ * 
+ * Restlet is a registered trademark of Noelios Technologies.
+ */
+
+package org.restlet.ext.rdf.internal.xml;
+
+import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+
+import org.restlet.data.Language;
+import org.restlet.data.Reference;
+import org.restlet.ext.rdf.GraphHandler;
+import org.restlet.ext.rdf.LinkReference;
+import org.restlet.ext.rdf.Literal;
+import org.restlet.ext.rdf.RdfRepresentation;
+import org.restlet.ext.rdf.internal.RdfConstants;
+import org.restlet.representation.Representation;
+import org.xml.sax.Attributes;
+import org.xml.sax.SAXException;
+import org.xml.sax.helpers.DefaultHandler;
+
+/**
+ * Content reader part.
+ * 
+ * @author Thierry Boileau
+ */
+class ContentReader extends DefaultHandler {
+    public enum State {
+        LITERAL, NONE, OBJECT, PREDICATE, SUBJECT
+    }
+
+    /** Increment used to identify inner blank nodes. */
+    private static int blankNodeId = 0;
+
+    /**
+     * Returns the identifier of a new blank node.
+     * 
+     * @return The identifier of a new blank node.
+     */
+    private static String newBlankNodeId() {
+        return ""#_bn"" + blankNodeId++;
+    }
+
+    /** The value of the ""base"" URI. */
+    private ScopedProperty<Reference> base;
+
+    /** Container for string content. */
+    private StringBuilder builder;
+
+    /** Indicates if the string content must be consumed. */
+    private boolean consumeContent;
+
+    /** Current data type. */
+    private String currentDataType;
+
+    /** Current language. */
+    private ScopedProperty<Language> language;
+
+    /** Current object. */
+    private Object currentObject;
+
+    /** Current predicate. */
+    private Reference currentPredicate;
+
+    /** The graph handler to call when a link is detected. */
+    private GraphHandler graphHandler;
+
+    /** Used to get the content of XMl literal. */
+    private int nodeDepth;
+
+    /** The list of known prefixes. */
+    private Map<String, String> prefixes;
+
+    /**
+     * True if {@link RdfRepresentation#RDF_SYNTAX} is the default namespace.
+     */
+    private boolean rdfDefaultNamespace;
+
+    /** Used when a statement must be reified. */
+    private Reference reifiedRef;
+
+    /** Heap of states. */
+    private List<ContentReader.State> states;
+
+    /** Heap of subjects. */
+    private List<Reference> subjects;
+
+    /**
+     * 
+     * 
+     * @param graphHandler
+     * 
+     */
+    /**
+     * Constructor.
+     * 
+     * @param graphHandler
+     *            The graph handler to call when a link is detected.
+     * @param representation
+     *            The input representation.
+     */
+    public ContentReader(GraphHandler graphHandler,
+            Representation representation) {
+        super();
+        this.graphHandler = graphHandler;
+        this.base = new ScopedProperty<Reference>();
+        this.language = new ScopedProperty<Language>();
+        if (representation.getIdentifier() != null) {
+            this.base.add(representation.getIdentifier().getTargetRef());
+            this.base.incrDepth();
+        }
+        if (representation.getLanguages().size() == 1) {
+            this.language.add(representation.getLanguages().get(1));
+            this.language.incrDepth();
+        }
+    }
+
+    @Override
+    public void characters(char[] ch, int start, int length)
+            throws SAXException {
+        if (consumeContent) {
+            builder.append(ch, start, length);
+        }
+    }
+
+    /**
+     * Returns true if the given qualified name is in the RDF namespace and is
+     * equal to the given local name.
+     * 
+     * @param localName
+     *            The local name to compare to.
+     * @param qName
+     *            The qualified name
+     */
+    private boolean checkRdfQName(String localName, String qName) {
+        boolean result = qName.equals(""rdf:"" + localName);
+        if (!result) {
+            int index = qName.indexOf("":"");
+            // The qualified name has no prefix.
+            result = rdfDefaultNamespace && (index == -1)
+                    && localName.equals(qName);
+        }
+
+        return result;
+    }
+
+    @Override
+    public void endDocument() throws SAXException {
+        this.builder = null;
+        this.currentObject = null;
+        this.currentPredicate = null;
+        this.graphHandler = null;
+        this.prefixes.clear();
+        this.prefixes = null;
+        this.states.clear();
+        this.states = null;
+        this.subjects.clear();
+        this.subjects = null;
+        this.nodeDepth = 0;
+    }
+
+    @Override
+    public void endElement(String uri, String localName, String name)
+            throws SAXException {
+        ContentReader.State state = popState();
+
+        if (state == State.SUBJECT) {
+            popSubject();
+        } else if (state == State.PREDICATE) {
+            if (this.consumeContent) {
+                link(getCurrentSubject(), this.currentPredicate, getLiteral(
+                        builder.toString(), null, this.language.getValue()));
+                this.consumeContent = false;
+            }
+        } else if (state == State.OBJECT) {
+        } else if (state == State.LITERAL) {
+            if (nodeDepth == 0) {
+                // End of the XML literal
+                link(getCurrentSubject(), this.currentPredicate, getLiteral(
+                        builder.toString(), this.currentDataType, this.language
+                                .getValue()));
+            } else {
+                // Still gleaning the content of an XML literal
+                // Glean the XML content
+                this.builder.append(""</"");
+                if (uri != null && !"""".equals(uri)) {
+                    this.builder.append(uri).append("":"");
+                }
+                this.builder.append(localName).append("">"");
+                nodeDepth--;
+                pushState(state);
+            }
+        }
+        this.base.decrDepth();
+        this.language.decrDepth();
+    }
+
+    @Override
+    public void endPrefixMapping(String prefix) throws SAXException {
+        this.prefixes.remove(prefix);
+    }
+
+    /**
+     * Returns the state at the top of the heap.
+     * 
+     * @return The state at the top of the heap.
+     */
+    private ContentReader.State getCurrentState() {
+        ContentReader.State result = null;
+        int size = this.states.size();
+
+        if (size > 0) {
+            result = this.states.get(size - 1);
+        }
+
+        return result;
+    }
+
+    /**
+     * Returns the subject at the top of the heap.
+     * 
+     * @return The subject at the top of the heap.
+     */
+    private Reference getCurrentSubject() {
+        Reference result = null;
+        int size = this.subjects.size();
+
+        if (size > 0) {
+            result = this.subjects.get(size - 1);
+        }
+
+        return result;
+    }
+
+    /**
+     * Returns a Literal object according to the given parameters.
+     * 
+     * @param value
+     *            The value of the literal.
+     * @param datatype
+     *            The datatype of the literal.
+     * @param language
+     *            The language of the literal.
+     * @return A Literal object
+     */
+    private Literal getLiteral(String value, String datatype, Language language) {
+        Literal literal = new Literal(value);
+        if (datatype != null) {
+            literal.setDatatypeRef(new Reference(datatype));
+        }
+        if (language != null) {
+            literal.setLanguage(language);
+        }
+        return literal;
+    }
+
+    /**
+     * A new statement has been detected with the current subject, predicate and
+     * object.
+     */
+    private void link() {
+        Reference currentSubject = getCurrentSubject();
+        if (currentSubject instanceof Reference) {
+            if (this.currentObject instanceof Reference) {
+                link(currentSubject, this.currentPredicate,
+                        (Reference) this.currentObject);
+            } else if (this.currentObject instanceof Literal) {
+                link(currentSubject, this.currentPredicate,
+                        (Literal) this.currentObject);
+            } else {
+                // TODO Error.
+            }
+        } else {
+            // TODO Error.
+        }
+    }
+
+    /**
+     * Creates a statement and reify it, if necessary.
+     * 
+     * @param subject
+     *            The subject of the statement.
+     * @param predicate
+     *            The predicate of the statement.
+     * @param object
+     *            The object of the statement.
+     */
+    private void link(Reference subject, Reference predicate, Literal object) {
+        this.graphHandler.link(subject, predicate, object);
+        if (this.reifiedRef != null) {
+            this.graphHandler.link(this.reifiedRef,
+                    RdfConstants.PREDICATE_SUBJECT, subject);
+            this.graphHandler.link(this.reifiedRef,
+                    RdfConstants.PREDICATE_PREDICATE, predicate);
+            this.graphHandler.link(this.reifiedRef,
+                    RdfConstants.PREDICATE_OBJECT, object);
+            this.graphHandler.link(reifiedRef, RdfConstants.PREDICATE_TYPE,
+                    RdfConstants.PREDICATE_STATEMENT);
+            this.reifiedRef = null;
+        }
+    }
+
+    /**
+     * Creates a statement and reify it, if necessary.
+     * 
+     * @param subject
+     *            The subject of the statement.
+     * @param predicate
+     *            The predicate of the statement.
+     * @param object
+     *            The object of the statement.
+     */
+    private void link(Reference subject, Reference predicate, Reference object) {
+        this.graphHandler.link(subject, predicate, object);
+
+        if (this.reifiedRef != null) {
+            this.graphHandler.link(this.reifiedRef,
+                    RdfConstants.PREDICATE_SUBJECT, subject);
+            this.graphHandler.link(this.reifiedRef,
+                    RdfConstants.PREDICATE_PREDICATE, predicate);
+            this.graphHandler.link(this.reifiedRef,
+                    RdfConstants.PREDICATE_OBJECT, object);
+            this.graphHandler.link(reifiedRef, RdfConstants.PREDICATE_TYPE,
+                    RdfConstants.PREDICATE_STATEMENT);
+            this.reifiedRef = null;
+        }
+    }
+
+    /**
+     * Returns the RDF URI of the given node represented by its namespace uri,
+     * local name, name, and attributes. It also generates the available
+     * statements, thanks to some shortcuts provided by the RDF XML syntax.
+     * 
+     * @param uri
+     * @param localName
+     * @param name
+     * @param attributes
+     * @return The RDF URI of the given node.
+     */
+    private Reference parseNode(String uri, String localName, String name,
+            Attributes attributes) {
+        Reference result = null;
+        // Stores the arcs
+        List<String[]> arcs = new ArrayList<String[]>();
+        boolean found = false;
+        if (attributes.getIndex(""xml:base"") != -1) {
+            this.base.add(new Reference(attributes.getValue(""xml:base"")));
+        }
+        // Get the RDF URI of this node
+        for (int i = 0; i < attributes.getLength(); i++) {
+            String qName = attributes.getQName(i);
+            if (checkRdfQName(""about"", qName)) {
+                found = true;
+                result = resolve(attributes.getValue(i), false);
+            } else if (checkRdfQName(""nodeID"", qName)) {
+                found = true;
+                result = LinkReference.createBlank(attributes.getValue(i));
+            } else if (checkRdfQName(""ID"", qName)) {
+                found = true;
+                result = resolve(attributes.getValue(i), true);
+            } else if (""xml:lang"".equals(qName)) {
+                this.language.add(Language.valueOf(attributes.getValue(i)));
+            } else if (""xml:base"".equals(qName)) {
+                // Already stored
+            } else {
+                if (!qName.startsWith(""xmlns"")) {
+                    String[] arc = { qName, attributes.getValue(i) };
+                    arcs.add(arc);
+                }
+            }
+        }
+        if (!found) {
+            // Blank node with no given ID
+            result = LinkReference.createBlank(ContentReader.newBlankNodeId());
+        }
+
+        // Create the available statements
+        if (!checkRdfQName(""Description"", name)) {
+            // Handle typed node
+            this.graphHandler.link(result, RdfConstants.PREDICATE_TYPE,
+                    resolve(uri, name));
+        }
+        for (String[] arc : arcs) {
+            this.graphHandler.link(result, resolve(null, arc[0]), getLiteral(
+                    arc[1], null, this.language.getValue()));
+        }
+
+        return result;
+    }
+
+    /**
+     * Returns the state at the top of the heap and removes it from the heap.
+     * 
+     * @return The state at the top of the heap.
+     */
+    private ContentReader.State popState() {
+        ContentReader.State result = null;
+        int size = this.states.size();
+
+        if (size > 0) {
+            result = this.states.remove(size - 1);
+        }
+
+        return result;
+    }
+
+    /**
+     * Returns the subject at the top of the heap and removes it from the heap.
+     * 
+     * @return The subject at the top of the heap.
+     */
+    private Reference popSubject() {
+        Reference result = null;
+        int size = this.subjects.size();
+
+        if (size > 0) {
+            result = this.subjects.remove(size - 1);
+        }
+
+        return result;
+    }
+
+    /**
+     * Adds a new state at the top of the heap.
+     * 
+     * @param state
+     *            The state to add.
+     */
+    private void pushState(ContentReader.State state) {
+        this.states.add(state);
+    }
+
+    /**
+     * Adds a new subject at the top of the heap.
+     * 
+     * @param subject
+     *            The subject to add.
+     */
+    private void pushSubject(Reference subject) {
+        this.subjects.add(subject);
+    }
+
+    /**
+     * Returns the absolute reference for a given value. If this value is not an
+     * absolute URI, then the base URI is used.
+     * 
+     * @param value
+     *            The value.
+     * @param fragment
+     *            True if the value is a fragment to add to the base reference.
+     * @return Returns the absolute reference for a given value.
+     */
+    private Reference resolve(String value, boolean fragment) {
+        Reference result = null;
+
+        if (fragment) {
+            result = new Reference(this.base.getValue());
+            result.setFragment(value);
+        } else {
+            result = new Reference(value);
+            if (result.isRelative()) {
+                result = new Reference(this.base.getValue(), value);
+            }
+        }
+        return result.getTargetRef();
+    }
+
+    /**
+     * Returns the absolute reference of a parsed element according to its URI,
+     * qualified name. In case the base URI is null or empty, then an attempt is
+     * made to look for the mapped URI according to the qName.
+     * 
+     * @param uri
+     *            The base URI.
+     * @param qName
+     *            The qualified name of the parsed element.
+     * @return Returns the absolute reference of a parsed element.
+     */
+    private Reference resolve(String uri, String qName) {
+        Reference result = null;
+
+        int index = qName.indexOf("":"");
+        String prefix = null;
+        String localName = null;
+        if (index != -1) {
+            prefix = qName.substring(0, index);
+            localName = qName.substring(index + 1);
+        } else {
+            localName = qName;
+            prefix = """";
+        }
+
+        if (uri != null && !"""".equals(uri)) {
+            if (!uri.endsWith(""#"") && !uri.endsWith(""/"")) {
+                result = new Reference(uri + ""/"" + localName);
+            } else {
+                result = new Reference(uri + localName);
+            }
+        } else {
+            String baseUri = this.prefixes.get(prefix);
+            if (baseUri != null) {
+                result = new Reference(baseUri + localName);
+            }
+        }
+
+        return (result == null) ? null : result.getTargetRef();
+    }
+
+    @Override
+    public void startDocument() throws SAXException {
+        this.prefixes = new HashMap<String, String>();
+        this.builder = new StringBuilder();
+        this.states = new ArrayList<ContentReader.State>();
+        this.subjects = new ArrayList<Reference>();
+        nodeDepth = 0;
+        pushState(State.NONE);
+    }
+
+    @Override
+    public void startElement(String uri, String localName, String name,
+            Attributes attributes) throws SAXException {
+        ContentReader.State state = getCurrentState();
+        this.base.incrDepth();
+        this.language.incrDepth();
+        if (!this.consumeContent && this.builder != null) {
+            this.builder = null;
+        }
+        if (state == State.NONE) {
+            if (checkRdfQName(""RDF"", name)) {
+                // Top element
+                String base = attributes.getValue(""xml:base"");
+                if (base != null) {
+                    this.base.add(new Reference(base));
+                }
+            } else {
+                // Parse the current subject
+                pushSubject(parseNode(uri, localName, name, attributes));
+                pushState(State.SUBJECT);
+            }
+        } else if (state == State.SUBJECT) {
+            // Parse the current predicate
+            List<String[]> arcs = new ArrayList<String[]>();
+            pushState(State.PREDICATE);
+            this.consumeContent = true;
+            Reference currentSubject = getCurrentSubject();
+            this.currentPredicate = resolve(uri, name);
+            Reference currentObject = null;
+            for (int i = 0; i < attributes.getLength(); i++) {
+                String qName = attributes.getQName(i);
+                if (checkRdfQName(""resource"", qName)) {
+                    this.consumeContent = false;
+                    currentObject = resolve(attributes.getValue(i), false);
+                    popState();
+                    pushState(State.OBJECT);
+                } else if (checkRdfQName(""datatype"", qName)) {
+                    // The object is a literal
+                    this.consumeContent = true;
+                    popState();
+                    pushState(State.LITERAL);
+                    this.currentDataType = attributes.getValue(i);
+                } else if (checkRdfQName(""parseType"", qName)) {
+                    String value = attributes.getValue(i);
+                    if (""Literal"".equals(value)) {
+                        this.consumeContent = true;
+                        // The object is an XML literal
+                        popState();
+                        pushState(State.LITERAL);
+                        this.currentDataType = RdfConstants.RDF_SYNTAX
+                                + ""XMLLiteral"";
+                        nodeDepth = 0;
+                    } else if (""Resource"".equals(value)) {
+                        this.consumeContent = false;
+                        // Create a new blank node
+                        currentObject = LinkReference.createBlank(ContentReader
+                                .newBlankNodeId());
+                        popState();
+                        pushState(State.SUBJECT);
+                        pushSubject(currentObject);
+                    } else {
+                        this.consumeContent = false;
+                        // Error
+                    }
+                } else if (checkRdfQName(""nodeID"", qName)) {
+                    this.consumeContent = false;
+                    currentObject = LinkReference.createBlank(attributes
+                            .getValue(i));
+                    popState();
+                    pushState(State.SUBJECT);
+                    pushSubject(currentObject);
+                } else if (checkRdfQName(""ID"", qName)) {
+                    // Reify the statement
+                    reifiedRef = resolve(attributes.getValue(i), true);
+                } else if (""xml:lang"".equals(qName)) {
+                    this.language.add(Language.valueOf(attributes.getValue(i)));
+                } else {
+                    if (!qName.startsWith(""xmlns"")) {
+                        // Add arcs.
+                        String[] arc = { qName, attributes.getValue(i) };
+                        arcs.add(arc);
+                    }
+                }
+            }
+            if (currentObject != null) {
+                link(currentSubject, this.currentPredicate, currentObject);
+            }
+
+            if (!arcs.isEmpty()) {
+                // Create arcs that starts from a blank node and ends to
+                // literal values. This blank node is the object of the
+                // current statement.
+
+                boolean found = false;
+                Reference blankNode = LinkReference.createBlank(ContentReader
+                        .newBlankNodeId());
+                for (String[] arc : arcs) {
+                    Reference pRef = resolve(null, arc[0]);
+                    // Silently remove unrecognized attributes
+                    if (pRef != null) {
+                        found = true;
+                        this.graphHandler.link(blankNode, pRef, new Literal(
+                                arc[1]));
+                    }
+                }
+                if (found) {
+                    link(currentSubject, this.currentPredicate, blankNode);
+                    popState();
+                    pushState(State.OBJECT);
+                }
+            }
+            if (this.consumeContent) {
+                builder = new StringBuilder();
+            }
+        } else if (state == State.PREDICATE) {
+            this.consumeContent = false;
+            // Parse the current object, create the current link
+            Reference object = parseNode(uri, localName, name, attributes);
+            this.currentObject = object;
+            link();
+            pushSubject(object);
+            pushState(State.SUBJECT);
+        } else if (state == State.OBJECT) {
+        } else if (state == State.LITERAL) {
+            // Glean the XML content
+            nodeDepth++;
+            this.builder.append(""<"");
+            if (uri != null && !"""".equals(uri)) {
+                this.builder.append(uri).append("":"");
+            }
+            this.builder.append(localName).append("">"");
+        }
+    }
+
+    @Override
+    public void startPrefixMapping(String prefix, String uri)
+            throws SAXException {
+        this.rdfDefaultNamespace = this.rdfDefaultNamespace
+                || ((prefix == null || """".equals(prefix)
+                        && RdfConstants.RDF_SYNTAX.toString(true, true).equals(
+                                uri)));
+
+        if (!uri.endsWith(""#"") && !uri.endsWith(""/"")) {
+            this.prefixes.put(prefix, uri + ""/"");
+        } else {
+            this.prefixes.put(prefix, uri);
+        }
+    }
+}
\ No newline at end of file
diff --git a/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/internal/xml/RdfXmlParsingContentHandler.java b/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/internal/xml/RdfXmlParsingContentHandler.java
index c5309f9bc..762979890 100644
--- a/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/internal/xml/RdfXmlParsingContentHandler.java
+++ b/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/internal/xml/RdfXmlParsingContentHandler.java
@@ -1,839 +1,120 @@
+/**
+ * Copyright 2005-2009 Noelios Technologies.
+ * 
+ * The contents of this file are subject to the terms of one of the following
+ * open source licenses: LGPL 3.0 or LGPL 2.1 or CDDL 1.0 or EPL 1.0 (the
+ * ""Licenses""). You can select the license that you prefer but you may not use
+ * this file except in compliance with one of these Licenses.
+ * 
+ * You can obtain a copy of the LGPL 3.0 license at
+ * http://www.opensource.org/licenses/lgpl-3.0.html
+ * 
+ * You can obtain a copy of the LGPL 2.1 license at
+ * http://www.opensource.org/licenses/lgpl-2.1.php
+ * 
+ * You can obtain a copy of the CDDL 1.0 license at
+ * http://www.opensource.org/licenses/cddl1.php
+ * 
+ * You can obtain a copy of the EPL 1.0 license at
+ * http://www.opensource.org/licenses/eclipse-1.0.php
+ * 
+ * See the Licenses for the specific language governing permissions and
+ * limitations under the Licenses.
+ * 
+ * Alternatively, you can obtain a royalty free commercial license with less
+ * limitations, transferable or non-transferable, directly at
+ * http://www.noelios.com/products/restlet-engine
+ * 
+ * Restlet is a registered trademark of Noelios Technologies.
+ */
+
 package org.restlet.ext.rdf.internal.xml;
 
 import java.io.IOException;
-import java.util.ArrayList;
-import java.util.HashMap;
-import java.util.List;
-import java.util.Map;
 
-import org.restlet.data.Language;
 import org.restlet.data.Reference;
 import org.restlet.ext.rdf.Graph;
 import org.restlet.ext.rdf.GraphHandler;
-import org.restlet.ext.rdf.LinkReference;
 import org.restlet.ext.rdf.Literal;
-import org.restlet.ext.rdf.RdfRepresentation;
-import org.restlet.ext.rdf.internal.RdfConstants;
 import org.restlet.representation.Representation;
 import org.restlet.representation.SaxRepresentation;
-import org.xml.sax.Attributes;
-import org.xml.sax.SAXException;
-import org.xml.sax.helpers.DefaultHandler;
 
+/**
+ * Handler of RDF content according to the RDF/XML format.
+ * 
+ * @author Thierry Boileau
+ */
 public class RdfXmlParsingContentHandler extends GraphHandler {
 
-	/**
-	 * Content reader part.
-	 */
-	private static class ContentReader extends DefaultHandler {
-		public enum State {
-			LITERAL, NONE, OBJECT, PREDICATE, SUBJECT
-		}
-
-		/** Increment used to identify inner blank nodes. */
-		private static int blankNodeId = 0;
-
-		/**
-		 * Returns the identifier of a new blank node.
-		 * 
-		 * @return The identifier of a new blank node.
-		 */
-		private static String newBlankNodeId() {
-			return ""#_bn"" + blankNodeId++;
-		}
-
-		/** The value of the ""base"" URI. */
-		private ScopedProperty<Reference> base;
-
-		/** Container for string content. */
-		private StringBuilder builder;
-
-		/** Indicates if the string content must be consumed. */
-		private boolean consumeContent;
-
-		/** Current data type. */
-		private String currentDataType;
-
-		/** Current language. */
-		private ScopedProperty<Language> language;
-
-		/** Current object. */
-		private Object currentObject;
-
-		/** Current predicate. */
-		private Reference currentPredicate;
-
-		/** The graph handler to call when a link is detected. */
-		private GraphHandler graphHandler;
-
-		/** Used to get the content of XMl literal. */
-		private int nodeDepth;
-
-		/** The list of known prefixes. */
-		private Map<String, String> prefixes;
-
-		/**
-		 * True if {@link RdfRepresentation#RDF_SYNTAX} is the default
-		 * namespace.
-		 */
-		private boolean rdfDefaultNamespace;
-
-		/** Used when a statement must be reified. */
-		private Reference reifiedRef;
-
-		/** Heap of states. */
-		private List<State> states;
-
-		/** Heap of subjects. */
-		private List<Reference> subjects;
-
-		/**
-		 * 
-		 * 
-		 * @param graphHandler
-		 * 
-		 */
-		/**
-		 * Constructor.
-		 * 
-		 * @param graphHandler
-		 *            The graph handler to call when a link is detected.
-		 * @param representation
-		 *            The input representation.
-		 */
-		public ContentReader(GraphHandler graphHandler,
-				Representation representation) {
-			super();
-			this.graphHandler = graphHandler;
-			this.base = new ScopedProperty<Reference>();
-			this.language = new ScopedProperty<Language>();
-			if (representation.getIdentifier() != null) {
-				this.base.add(representation.getIdentifier().getTargetRef());
-				this.base.incrDepth();
-			}
-			if (representation.getLanguages().size() == 1) {
-				this.language.add(representation.getLanguages().get(1));
-				this.language.incrDepth();
-			}
-		}
-
-		@Override
-		public void characters(char[] ch, int start, int length)
-				throws SAXException {
-			if (consumeContent) {
-				builder.append(ch, start, length);
-			}
-		}
-
-		/**
-		 * Returns true if the given qualified name is in the RDF namespace and
-		 * is equal to the given local name.
-		 * 
-		 * @param localName
-		 *            The local name to compare to.
-		 * @param qName
-		 *            The qualified name
-		 */
-		private boolean checkRdfQName(String localName, String qName) {
-			boolean result = qName.equals(""rdf:"" + localName);
-			if (!result) {
-				int index = qName.indexOf("":"");
-				// The qualified name has no prefix.
-				result = rdfDefaultNamespace && (index == -1)
-						&& localName.equals(qName);
-			}
-
-			return result;
-		}
-
-		@Override
-		public void endDocument() throws SAXException {
-			this.builder = null;
-			this.currentObject = null;
-			this.currentPredicate = null;
-			this.graphHandler = null;
-			this.prefixes.clear();
-			this.prefixes = null;
-			this.states.clear();
-			this.states = null;
-			this.subjects.clear();
-			this.subjects = null;
-			this.nodeDepth = 0;
-		}
-
-		@Override
-		public void endElement(String uri, String localName, String name)
-				throws SAXException {
-			State state = popState();
-
-			if (state == State.SUBJECT) {
-				popSubject();
-			} else if (state == State.PREDICATE) {
-				if (this.consumeContent) {
-					link(getCurrentSubject(), this.currentPredicate,
-							getLiteral(builder.toString(), null, this.language
-									.getValue()));
-					this.consumeContent = false;
-				}
-			} else if (state == State.OBJECT) {
-			} else if (state == State.LITERAL) {
-				if (nodeDepth == 0) {
-					// End of the XML literal
-					link(getCurrentSubject(), this.currentPredicate,
-							getLiteral(builder.toString(),
-									this.currentDataType, this.language
-											.getValue()));
-				} else {
-					// Still gleaning the content of an XML literal
-					// Glean the XML content
-					this.builder.append(""</"");
-					if (uri != null && !"""".equals(uri)) {
-						this.builder.append(uri).append("":"");
-					}
-					this.builder.append(localName).append("">"");
-					nodeDepth--;
-					pushState(state);
-				}
-			}
-			this.base.decrDepth();
-			this.language.decrDepth();
-		}
-
-		@Override
-		public void endPrefixMapping(String prefix) throws SAXException {
-			this.prefixes.remove(prefix);
-		}
-
-		/**
-		 * Returns the state at the top of the heap.
-		 * 
-		 * @return The state at the top of the heap.
-		 */
-		private State getCurrentState() {
-			State result = null;
-			int size = this.states.size();
-
-			if (size > 0) {
-				result = this.states.get(size - 1);
-			}
-
-			return result;
-		}
-
-		/**
-		 * Returns the subject at the top of the heap.
-		 * 
-		 * @return The subject at the top of the heap.
-		 */
-		private Reference getCurrentSubject() {
-			Reference result = null;
-			int size = this.subjects.size();
-
-			if (size > 0) {
-				result = this.subjects.get(size - 1);
-			}
-
-			return result;
-		}
-
-		/**
-		 * Returns a Literal object according to the given parameters.
-		 * 
-		 * @param value
-		 *            The value of the literal.
-		 * @param datatype
-		 *            The datatype of the literal.
-		 * @param language
-		 *            The language of the literal.
-		 * @return A Literal object
-		 */
-		private Literal getLiteral(String value, String datatype,
-				Language language) {
-			Literal literal = new Literal(value);
-			if (datatype != null) {
-				literal.setDatatypeRef(new Reference(datatype));
-			}
-			if (language != null) {
-				literal.setLanguage(language);
-			}
-			return literal;
-		}
-
-		/**
-		 * A new statement has been detected with the current subject, predicate
-		 * and object.
-		 */
-		private void link() {
-			Reference currentSubject = getCurrentSubject();
-			if (currentSubject instanceof Reference) {
-				if (this.currentObject instanceof Reference) {
-					link(currentSubject, this.currentPredicate,
-							(Reference) this.currentObject);
-				} else if (this.currentObject instanceof Literal) {
-					link(currentSubject, this.currentPredicate,
-							(Literal) this.currentObject);
-				} else {
-					// TODO Error.
-				}
-			} else {
-				// TODO Error.
-			}
-		}
-
-		/**
-		 * Creates a statement and reify it, if necessary.
-		 * 
-		 * @param subject
-		 *            The subject of the statement.
-		 * @param predicate
-		 *            The predicate of the statement.
-		 * @param object
-		 *            The object of the statement.
-		 */
-		private void link(Reference subject, Reference predicate, Literal object) {
-			this.graphHandler.link(subject, predicate, object);
-			if (this.reifiedRef != null) {
-				this.graphHandler.link(this.reifiedRef,
-						RdfConstants.PREDICATE_SUBJECT, subject);
-				this.graphHandler.link(this.reifiedRef,
-						RdfConstants.PREDICATE_PREDICATE, predicate);
-				this.graphHandler.link(this.reifiedRef,
-						RdfConstants.PREDICATE_OBJECT, object);
-				this.graphHandler.link(reifiedRef, RdfConstants.PREDICATE_TYPE,
-						RdfConstants.PREDICATE_STATEMENT);
-				this.reifiedRef = null;
-			}
-		}
-
-		/**
-		 * Creates a statement and reify it, if necessary.
-		 * 
-		 * @param subject
-		 *            The subject of the statement.
-		 * @param predicate
-		 *            The predicate of the statement.
-		 * @param object
-		 *            The object of the statement.
-		 */
-		private void link(Reference subject, Reference predicate,
-				Reference object) {
-			this.graphHandler.link(subject, predicate, object);
-
-			if (this.reifiedRef != null) {
-				this.graphHandler.link(this.reifiedRef,
-						RdfConstants.PREDICATE_SUBJECT, subject);
-				this.graphHandler.link(this.reifiedRef,
-						RdfConstants.PREDICATE_PREDICATE, predicate);
-				this.graphHandler.link(this.reifiedRef,
-						RdfConstants.PREDICATE_OBJECT, object);
-				this.graphHandler.link(reifiedRef, RdfConstants.PREDICATE_TYPE,
-						RdfConstants.PREDICATE_STATEMENT);
-				this.reifiedRef = null;
-			}
-		}
-
-		/**
-		 * Returns the RDF URI of the given node represented by its namespace
-		 * uri, local name, name, and attributes. It also generates the
-		 * available statements, thanks to some shortcuts provided by the RDF
-		 * XML syntax.
-		 * 
-		 * @param uri
-		 * @param localName
-		 * @param name
-		 * @param attributes
-		 * @return The RDF URI of the given node.
-		 */
-		private Reference parseNode(String uri, String localName, String name,
-				Attributes attributes) {
-			Reference result = null;
-			// Stores the arcs
-			List<String[]> arcs = new ArrayList<String[]>();
-			boolean found = false;
-			if (attributes.getIndex(""xml:base"") != -1) {
-				this.base.add(new Reference(attributes.getValue(""xml:base"")));
-			}
-			// Get the RDF URI of this node
-			for (int i = 0; i < attributes.getLength(); i++) {
-				String qName = attributes.getQName(i);
-				if (checkRdfQName(""about"", qName)) {
-					found = true;
-					result = resolve(attributes.getValue(i), false);
-				} else if (checkRdfQName(""nodeID"", qName)) {
-					found = true;
-					result = LinkReference.createBlank(attributes.getValue(i));
-				} else if (checkRdfQName(""ID"", qName)) {
-					found = true;
-					result = resolve(attributes.getValue(i), true);
-				} else if (""xml:lang"".equals(qName)) {
-					this.language.add(Language.valueOf(attributes.getValue(i)));
-				} else if (""xml:base"".equals(qName)) {
-					// Already stored
-				} else {
-					if (!qName.startsWith(""xmlns"")) {
-						String[] arc = { qName, attributes.getValue(i) };
-						arcs.add(arc);
-					}
-				}
-			}
-			if (!found) {
-				// Blank node with no given ID
-				result = LinkReference.createBlank(ContentReader
-						.newBlankNodeId());
-			}
-
-			// Create the available statements
-			if (!checkRdfQName(""Description"", name)) {
-				// Handle typed node
-				this.graphHandler.link(result, RdfConstants.PREDICATE_TYPE,
-						resolve(uri, name));
-			}
-			for (String[] arc : arcs) {
-				this.graphHandler.link(result, resolve(null, arc[0]),
-						getLiteral(arc[1], null, this.language.getValue()));
-			}
-
-			return result;
-		}
-
-		/**
-		 * Returns the state at the top of the heap and removes it from the
-		 * heap.
-		 * 
-		 * @return The state at the top of the heap.
-		 */
-		private State popState() {
-			State result = null;
-			int size = this.states.size();
-
-			if (size > 0) {
-				result = this.states.remove(size - 1);
-			}
-
-			return result;
-		}
-
-		/**
-		 * Returns the subject at the top of the heap and removes it from the
-		 * heap.
-		 * 
-		 * @return The subject at the top of the heap.
-		 */
-		private Reference popSubject() {
-			Reference result = null;
-			int size = this.subjects.size();
-
-			if (size > 0) {
-				result = this.subjects.remove(size - 1);
-			}
-
-			return result;
-		}
-
-		/**
-		 * Adds a new state at the top of the heap.
-		 * 
-		 * @param state
-		 *            The state to add.
-		 */
-		private void pushState(State state) {
-			this.states.add(state);
-		}
-
-		/**
-		 * Adds a new subject at the top of the heap.
-		 * 
-		 * @param subject
-		 *            The subject to add.
-		 */
-		private void pushSubject(Reference subject) {
-			this.subjects.add(subject);
-		}
-
-		/**
-		 * Returns the absolute reference for a given value. If this value is
-		 * not an absolute URI, then the base URI is used.
-		 * 
-		 * @param value
-		 *            The value.
-		 * @param fragment
-		 *            True if the value is a fragment to add to the base
-		 *            reference.
-		 * @return Returns the absolute reference for a given value.
-		 */
-		private Reference resolve(String value, boolean fragment) {
-			Reference result = null;
-
-			if (fragment) {
-				result = new Reference(this.base.getValue());
-				result.setFragment(value);
-			} else {
-				result = new Reference(value);
-				if (result.isRelative()) {
-					result = new Reference(this.base.getValue(), value);
-				}
-			}
-			return result.getTargetRef();
-		}
-
-		/**
-		 * Returns the absolute reference of a parsed element according to its
-		 * URI, qualified name. In case the base URI is null or empty, then an
-		 * attempt is made to look for the mapped URI according to the qName.
-		 * 
-		 * @param uri
-		 *            The base URI.
-		 * @param qName
-		 *            The qualified name of the parsed element.
-		 * @return Returns the absolute reference of a parsed element.
-		 */
-		private Reference resolve(String uri, String qName) {
-			Reference result = null;
-
-			int index = qName.indexOf("":"");
-			String prefix = null;
-			String localName = null;
-			if (index != -1) {
-				prefix = qName.substring(0, index);
-				localName = qName.substring(index + 1);
-			} else {
-				localName = qName;
-				prefix = """";
-			}
-
-			if (uri != null && !"""".equals(uri)) {
-				if (!uri.endsWith(""#"") && !uri.endsWith(""/"")) {
-					result = new Reference(uri + ""/"" + localName);
-				} else {
-					result = new Reference(uri + localName);
-				}
-			} else {
-				String baseUri = this.prefixes.get(prefix);
-				if (baseUri != null) {
-					result = new Reference(baseUri + localName);
-				}
-			}
-
-			return (result == null) ? null : result.getTargetRef();
-		}
-
-		@Override
-		public void startDocument() throws SAXException {
-			this.prefixes = new HashMap<String, String>();
-			this.builder = new StringBuilder();
-			this.states = new ArrayList<State>();
-			this.subjects = new ArrayList<Reference>();
-			nodeDepth = 0;
-			pushState(State.NONE);
-		}
-
-		@Override
-		public void startElement(String uri, String localName, String name,
-				Attributes attributes) throws SAXException {
-			State state = getCurrentState();
-			this.base.incrDepth();
-			this.language.incrDepth();
-			if (!this.consumeContent && this.builder != null) {
-				this.builder = null;
-			}
-			if (state == State.NONE) {
-				if (checkRdfQName(""RDF"", name)) {
-					// Top element
-					String base = attributes.getValue(""xml:base"");
-					if (base != null) {
-						this.base.add(new Reference(base));
-					}
-				} else {
-					// Parse the current subject
-					pushSubject(parseNode(uri, localName, name, attributes));
-					pushState(State.SUBJECT);
-				}
-			} else if (state == State.SUBJECT) {
-				// Parse the current predicate
-				List<String[]> arcs = new ArrayList<String[]>();
-				pushState(State.PREDICATE);
-				this.consumeContent = true;
-				Reference currentSubject = getCurrentSubject();
-				this.currentPredicate = resolve(uri, name);
-				Reference currentObject = null;
-				for (int i = 0; i < attributes.getLength(); i++) {
-					String qName = attributes.getQName(i);
-					if (checkRdfQName(""resource"", qName)) {
-						this.consumeContent = false;
-						currentObject = resolve(attributes.getValue(i), false);
-						popState();
-						pushState(State.OBJECT);
-					} else if (checkRdfQName(""datatype"", qName)) {
-						// The object is a literal
-						this.consumeContent = true;
-						popState();
-						pushState(State.LITERAL);
-						this.currentDataType = attributes.getValue(i);
-					} else if (checkRdfQName(""parseType"", qName)) {
-						String value = attributes.getValue(i);
-						if (""Literal"".equals(value)) {
-							this.consumeContent = true;
-							// The object is an XML literal
-							popState();
-							pushState(State.LITERAL);
-							this.currentDataType = RdfConstants.RDF_SYNTAX
-									+ ""XMLLiteral"";
-							nodeDepth = 0;
-						} else if (""Resource"".equals(value)) {
-							this.consumeContent = false;
-							// Create a new blank node
-							currentObject = LinkReference
-									.createBlank(ContentReader.newBlankNodeId());
-							popState();
-							pushState(State.SUBJECT);
-							pushSubject(currentObject);
-						} else {
-							this.consumeContent = false;
-							// Error
-						}
-					} else if (checkRdfQName(""nodeID"", qName)) {
-						this.consumeContent = false;
-						currentObject = LinkReference.createBlank(attributes
-								.getValue(i));
-						popState();
-						pushState(State.SUBJECT);
-						pushSubject(currentObject);
-					} else if (checkRdfQName(""ID"", qName)) {
-						// Reify the statement
-						reifiedRef = resolve(attributes.getValue(i), true);
-					} else if (""xml:lang"".equals(qName)) {
-						this.language.add(Language.valueOf(attributes
-								.getValue(i)));
-					} else {
-						if (!qName.startsWith(""xmlns"")) {
-							// Add arcs.
-							String[] arc = { qName, attributes.getValue(i) };
-							arcs.add(arc);
-						}
-					}
-				}
-				if (currentObject != null) {
-					link(currentSubject, this.currentPredicate, currentObject);
-				}
-
-				if (!arcs.isEmpty()) {
-					// Create arcs that starts from a blank node and ends to
-					// literal values. This blank node is the object of the
-					// current statement.
-
-					boolean found = false;
-					Reference blankNode = LinkReference
-							.createBlank(ContentReader.newBlankNodeId());
-					for (String[] arc : arcs) {
-						Reference pRef = resolve(null, arc[0]);
-						// Silently remove unrecognized attributes
-						if (pRef != null) {
-							found = true;
-							this.graphHandler.link(blankNode, pRef,
-									new Literal(arc[1]));
-						}
-					}
-					if (found) {
-						link(currentSubject, this.currentPredicate, blankNode);
-						popState();
-						pushState(State.OBJECT);
-					}
-				}
-				if (this.consumeContent) {
-					builder = new StringBuilder();
-				}
-			} else if (state == State.PREDICATE) {
-				this.consumeContent = false;
-				// Parse the current object, create the current link
-				Reference object = parseNode(uri, localName, name, attributes);
-				this.currentObject = object;
-				link();
-				pushSubject(object);
-				pushState(State.SUBJECT);
-			} else if (state == State.OBJECT) {
-			} else if (state == State.LITERAL) {
-				// Glean the XML content
-				nodeDepth++;
-				this.builder.append(""<"");
-				if (uri != null && !"""".equals(uri)) {
-					this.builder.append(uri).append("":"");
-				}
-				this.builder.append(localName).append("">"");
-			}
-		}
-
-		@Override
-		public void startPrefixMapping(String prefix, String uri)
-				throws SAXException {
-			this.rdfDefaultNamespace = this.rdfDefaultNamespace
-					|| ((prefix == null || """".equals(prefix)
-							&& RdfConstants.RDF_SYNTAX.toString(true, true)
-									.equals(uri)));
-
-			if (!uri.endsWith(""#"") && !uri.endsWith(""/"")) {
-				this.prefixes.put(prefix, uri + ""/"");
-			} else {
-				this.prefixes.put(prefix, uri);
-			}
-		}
-	}
-
-	/**
-	 * Used to handle properties that have a scope such as the base URI, the
-	 * xml:lang property.
-	 * 
-	 * @param <E>
-	 *            The type of the property.
-	 */
-	private static class ScopedProperty<E> {
-		private int[] depths;
-		private List<E> values;
-		private int size;
-
-		/**
-		 * Constructor.
-		 */
-		public ScopedProperty() {
-			super();
-			this.depths = new int[10];
-			this.values = new ArrayList<E>();
-			this.size = 0;
-		}
-
-		/**
-		 * Constructor.
-		 * 
-		 * @param value
-		 *            Value.
-		 */
-		public ScopedProperty(E value) {
-			this();
-			add(value);
-			incrDepth();
-		}
-
-		/**
-		 * Add a new value.
-		 * 
-		 * @param value
-		 *            The value to be added.
-		 */
-		public void add(E value) {
-			this.values.add(value);
-			if (this.size == this.depths.length) {
-				int[] temp = new int[2 * this.depths.length];
-				System.arraycopy(this.depths, 0, temp, 0, this.depths.length);
-				this.depths = temp;
-			}
-			this.size++;
-			this.depths[size - 1] = 0;
-		}
-
-		/**
-		 * Decrements the depth of the current value, and remove it if
-		 * necessary.
-		 */
-		public void decrDepth() {
-			if (this.size > 0) {
-				this.depths[size - 1]--;
-				if (this.depths[size - 1] < 0) {
-					this.size--;
-					this.values.remove(size);
-				}
-			}
-		}
-
-		/**
-		 * Returns the current value.
-		 * 
-		 * @return The current value.
-		 */
-		public E getValue() {
-			if (this.size > 0) {
-				return this.values.get(this.size - 1);
-			}
-			return null;
-		}
-
-		/**
-		 * Increments the depth of the current value.
-		 */
-		public void incrDepth() {
-			if (this.size > 0) {
-				this.depths[size - 1]++;
-			}
-		}
-	}
-
-	/** The set of links to update when parsing, or to read when writing. */
-	private Graph linkSet;
-
-	/** The representation to read. */
-	private SaxRepresentation rdfXmlRepresentation;
-
-	/**
-	 * Constructor.
-	 * 
-	 * @param linkSet
-	 *            The set of links to update during the parsing.
-	 * @param rdfXmlRepresentation
-	 *            The representation to read.
-	 * @throws IOException
-	 */
-	public RdfXmlParsingContentHandler(Graph linkSet,
-			Representation rdfXmlRepresentation) throws IOException {
-		super();
-		this.linkSet = linkSet;
-		if (rdfXmlRepresentation instanceof SaxRepresentation) {
-			this.rdfXmlRepresentation = (SaxRepresentation) rdfXmlRepresentation;
-		} else {
-			this.rdfXmlRepresentation = new SaxRepresentation(
-					rdfXmlRepresentation);
-			// Transmit the identifier used as a base for the resolution of
-			// relative URIs.
-			this.rdfXmlRepresentation.setIdentifier(rdfXmlRepresentation
-					.getIdentifier());
-		}
-
-		parse();
-	}
-
-	@Override
-	public void link(Graph source, Reference typeRef, Literal target) {
-		if (source != null && typeRef != null && target != null) {
-			this.linkSet.add(source, typeRef, target);
-		}
-	}
-
-	@Override
-	public void link(Graph source, Reference typeRef, Reference target) {
-		if (source != null && typeRef != null && target != null) {
-			this.linkSet.add(source, typeRef, target);
-		}
-	}
-
-	@Override
-	public void link(Reference source, Reference typeRef, Literal target) {
-		if (source != null && typeRef != null && target != null) {
-			this.linkSet.add(source, typeRef, target);
-		}
-	}
-
-	@Override
-	public void link(Reference source, Reference typeRef, Reference target) {
-		if (source != null && typeRef != null && target != null) {
-			this.linkSet.add(source, typeRef, target);
-		}
-	}
-
-	/**
-	 * Parses the current representation.
-	 * 
-	 * @throws IOException
-	 */
-	private void parse() throws IOException {
-		this.rdfXmlRepresentation.parse(new ContentReader(this,
-				rdfXmlRepresentation));
-	}
+    /** The set of links to update when parsing, or to read when writing. */
+    private Graph linkSet;
+
+    /** The representation to read. */
+    private SaxRepresentation rdfXmlRepresentation;
+
+    /**
+     * Constructor.
+     * 
+     * @param linkSet
+     *            The set of links to update during the parsing.
+     * @param rdfXmlRepresentation
+     *            The representation to read.
+     * @throws IOException
+     */
+    public RdfXmlParsingContentHandler(Graph linkSet,
+            Representation rdfXmlRepresentation) throws IOException {
+        super();
+        this.linkSet = linkSet;
+        if (rdfXmlRepresentation instanceof SaxRepresentation) {
+            this.rdfXmlRepresentation = (SaxRepresentation) rdfXmlRepresentation;
+        } else {
+            this.rdfXmlRepresentation = new SaxRepresentation(
+                    rdfXmlRepresentation);
+            // Transmit the identifier used as a base for the resolution of
+            // relative URIs.
+            this.rdfXmlRepresentation.setIdentifier(rdfXmlRepresentation
+                    .getIdentifier());
+        }
+
+        parse();
+    }
+
+    @Override
+    public void link(Graph source, Reference typeRef, Literal target) {
+        if (source != null && typeRef != null && target != null) {
+            this.linkSet.add(source, typeRef, target);
+        }
+    }
+
+    @Override
+    public void link(Graph source, Reference typeRef, Reference target) {
+        if (source != null && typeRef != null && target != null) {
+            this.linkSet.add(source, typeRef, target);
+        }
+    }
+
+    @Override
+    public void link(Reference source, Reference typeRef, Literal target) {
+        if (source != null && typeRef != null && target != null) {
+            this.linkSet.add(source, typeRef, target);
+        }
+    }
+
+    @Override
+    public void link(Reference source, Reference typeRef, Reference target) {
+        if (source != null && typeRef != null && target != null) {
+            this.linkSet.add(source, typeRef, target);
+        }
+    }
+
+    /**
+     * Parses the current representation.
+     * 
+     * @throws IOException
+     */
+    private void parse() throws IOException {
+        this.rdfXmlRepresentation.parse(new ContentReader(this,
+                rdfXmlRepresentation));
+    }
 
 }
diff --git a/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/internal/xml/RdfXmlWritingContentHandler.java b/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/internal/xml/RdfXmlWritingContentHandler.java
index fb7cb9629..98077b2dc 100644
--- a/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/internal/xml/RdfXmlWritingContentHandler.java
+++ b/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/internal/xml/RdfXmlWritingContentHandler.java
@@ -43,9 +43,11 @@ import org.restlet.ext.rdf.Literal;
 /**
  * Handler of RDF content according to the RDF XML syntax.
+ * 
+ * @author Thierry Boileau
  */
 public class RdfXmlWritingContentHandler extends GraphHandler {
 
     /** Buffered writer. */
-    // TODO plutt un XMLWriter?
+    // TODO better to use a XMLWriter?
     BufferedWriter bw;
 
diff --git a/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/internal/xml/ScopedProperty.java b/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/internal/xml/ScopedProperty.java
new file mode 100644
index 000000000..c6fe2bdad
--- /dev/null
+++ b/modules/org.restlet.ext.rdf/src/org/restlet/ext/rdf/internal/xml/ScopedProperty.java
@@ -0,0 +1,123 @@
+/**
+ * Copyright 2005-2009 Noelios Technologies.
+ * 
+ * The contents of this file are subject to the terms of one of the following
+ * open source licenses: LGPL 3.0 or LGPL 2.1 or CDDL 1.0 or EPL 1.0 (the
+ * ""Licenses""). You can select the license that you prefer but you may not use
+ * this file except in compliance with one of these Licenses.
+ * 
+ * You can obtain a copy of the LGPL 3.0 license at
+ * http://www.opensource.org/licenses/lgpl-3.0.html
+ * 
+ * You can obtain a copy of the LGPL 2.1 license at
+ * http://www.opensource.org/licenses/lgpl-2.1.php
+ * 
+ * You can obtain a copy of the CDDL 1.0 license at
+ * http://www.opensource.org/licenses/cddl1.php
+ * 
+ * You can obtain a copy of the EPL 1.0 license at
+ * http://www.opensource.org/licenses/eclipse-1.0.php
+ * 
+ * See the Licenses for the specific language governing permissions and
+ * limitations under the Licenses.
+ * 
+ * Alternatively, you can obtain a royalty free commercial license with less
+ * limitations, transferable or non-transferable, directly at
+ * http://www.noelios.com/products/restlet-engine
+ * 
+ * Restlet is a registered trademark of Noelios Technologies.
+ */
+
+package org.restlet.ext.rdf.internal.xml;
+
+import java.util.ArrayList;
+import java.util.List;
+
+/**
+ * Used to handle properties that have a scope such as the base URI, the
+ * xml:lang property.
+ * 
+ * @param <E>
+ *            The type of the property.
+ * @author Thierry Boileau
+ */
+class ScopedProperty<E> {
+    private int[] depths;
+
+    private List<E> values;
+
+    private int size;
+
+    /**
+     * Constructor.
+     */
+    public ScopedProperty() {
+        super();
+        this.depths = new int[10];
+        this.values = new ArrayList<E>();
+        this.size = 0;
+    }
+
+    /**
+     * Constructor.
+     * 
+     * @param value
+     *            Value.
+     */
+    public ScopedProperty(E value) {
+        this();
+        add(value);
+        incrDepth();
+    }
+
+    /**
+     * Add a new value.
+     * 
+     * @param value
+     *            The value to be added.
+     */
+    public void add(E value) {
+        this.values.add(value);
+        if (this.size == this.depths.length) {
+            int[] temp = new int[2 * this.depths.length];
+            System.arraycopy(this.depths, 0, temp, 0, this.depths.length);
+            this.depths = temp;
+        }
+        this.size++;
+        this.depths[size - 1] = 0;
+    }
+
+    /**
+     * Decrements the depth of the current value, and remove it if necessary.
+     */
+    public void decrDepth() {
+        if (this.size > 0) {
+            this.depths[size - 1]--;
+            if (this.depths[size - 1] < 0) {
+                this.size--;
+                this.values.remove(size);
+            }
+        }
+    }
+
+    /**
+     * Returns the current value.
+     * 
+     * @return The current value.
+     */
+    public E getValue() {
+        if (this.size > 0) {
+            return this.values.get(this.size - 1);
+        }
+        return null;
+    }
+
+    /**
+     * Increments the depth of the current value.
+     */
+    public void incrDepth() {
+        if (this.size > 0) {
+            this.depths[size - 1]++;
+        }
+    }
+}
\ No newline at end of file
", - Minor refactoring in RDF extension.--
1405,Java,012afd9ecc4659a2a86a1cd13a4af629bdcbc34a,,A,restlet,restlet-framework-java,"[4, 13, 14, 2, 5, 1, 0, 1, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/modules/com.noelios.restlet/src/com/noelios/restlet/application/RangeFilter.java b/modules/com.noelios.restlet/src/com/noelios/restlet/application/RangeFilter.java
index b6b167fb6..834e2b9ad 100644
--- a/modules/com.noelios.restlet/src/com/noelios/restlet/application/RangeFilter.java
+++ b/modules/com.noelios.restlet/src/com/noelios/restlet/application/RangeFilter.java
@@ -30,4 +30,5 @@ package com.noelios.restlet.application;
 import org.restlet.Context;
 import org.restlet.Filter;
+import org.restlet.data.Method;
 import org.restlet.data.Range;
 import org.restlet.data.Request;
@@ -36,4 +37,9 @@ import org.restlet.data.Status;
 import org.restlet.service.RangeService;
 
+/**
+ * Filter that is in charge to check the responses to requests for partial
+ * content.
+ * 
+ */
 public class RangeFilter extends Filter {
 
@@ -55,7 +61,19 @@ public class RangeFilter extends Filter {
                 Range requestedRange = request.getRanges().get(0);
                 if (!requestedRange.equals(response.getEntity().getRange())) {
+                    getLogger()
+                            .info(
+                                    ""The range of the response entity is not equals to the requested one."");
                     response.setEntity(new RangeRepresentation(response
                             .getEntity(), requestedRange));
                 }
+                if (Method.GET.equals(request.getMethod())
+                        && response.getStatus().isSuccess()
+                        && !Status.SUCCESS_PARTIAL_CONTENT.equals(response
+                                .getStatus())) {
+                    response.setStatus(Status.SUCCESS_PARTIAL_CONTENT);
+                    getLogger()
+                            .info(
+                                    ""The status of a response to a partial GET must be \""206 Partial content\""."");
+                }
             } else if (request.getRanges().size() > 1) {
                 // Return a server error as this isn't supported yet
diff --git a/modules/com.noelios.restlet/src/com/noelios/restlet/http/HttpClientCall.java b/modules/com.noelios.restlet/src/com/noelios/restlet/http/HttpClientCall.java
index 91be8fefb..b44a4bb9e 100644
--- a/modules/com.noelios.restlet/src/com/noelios/restlet/http/HttpClientCall.java
+++ b/modules/com.noelios.restlet/src/com/noelios/restlet/http/HttpClientCall.java
@@ -318,6 +318,5 @@ public abstract class HttpClientCall extends HttpCall {
                         .equals(Status.REDIRECTION_NOT_MODIFIED)
                 && !response.getStatus().equals(Status.SUCCESS_NO_CONTENT)
-                && !response.getStatus().equals(Status.SUCCESS_RESET_CONTENT)
-                && !response.getStatus().equals(Status.SUCCESS_PARTIAL_CONTENT)) {
+                && !response.getStatus().equals(Status.SUCCESS_RESET_CONTENT)) {
             // Make sure that an InputRepresentation will not be instantiated
             // while the stream is closed.
diff --git a/modules/com.noelios.restlet/src/com/noelios/restlet/http/HttpClientConverter.java b/modules/com.noelios.restlet/src/com/noelios/restlet/http/HttpClientConverter.java
index da99d022c..900278378 100644
--- a/modules/com.noelios.restlet/src/com/noelios/restlet/http/HttpClientConverter.java
+++ b/modules/com.noelios.restlet/src/com/noelios/restlet/http/HttpClientConverter.java
@@ -442,8 +442,4 @@ public class HttpClientConverter extends HttpConverter {
                     response.getEntity().release();
                     response.setEntity(null);
-                } else if (response.getStatus().equals(
-                        Status.SUCCESS_PARTIAL_CONTENT)) {
-                    response.getEntity().release();
-                    response.setEntity(null);
                 } else if (response.getStatus().equals(
                         Status.REDIRECTION_NOT_MODIFIED)) {
diff --git a/modules/com.noelios.restlet/src/com/noelios/restlet/http/HttpServerConverter.java b/modules/com.noelios.restlet/src/com/noelios/restlet/http/HttpServerConverter.java
index c9a055133..b378062fd 100644
--- a/modules/com.noelios.restlet/src/com/noelios/restlet/http/HttpServerConverter.java
+++ b/modules/com.noelios.restlet/src/com/noelios/restlet/http/HttpServerConverter.java
@@ -153,5 +153,4 @@ public class HttpServerConverter extends HttpConverter {
                                 .getDownloadName()));
             }
-            // TODO manage comparison with the requested ranges
             if (entity.getRange() != null) {
                 try {
@@ -347,15 +346,4 @@ public class HttpServerConverter extends HttpConverter {
                     response.setEntity(null);
                 }
-            } else if (response.getStatus().equals(
-                    Status.SUCCESS_PARTIAL_CONTENT)) {
-                if (response.getEntity() != null) {
-                    getLogger()
-                            .warning(
-                                    ""Responses with a 206 (Partial content) status aren't supported yet. Ignoring the entity for resource \""""
-                                            + response.getRequest()
-                                                    .getResourceRef() + ""."");
-                    response.setEntity(null);
-
-                }
             } else if (response.getStatus().equals(
                     Status.REDIRECTION_NOT_MODIFIED)) {
diff --git a/modules/org.restlet.test/src/org/restlet/test/RangeTestCase.java b/modules/org.restlet.test/src/org/restlet/test/RangeTestCase.java
index 65e05f347..84d43ee34 100644
--- a/modules/org.restlet.test/src/org/restlet/test/RangeTestCase.java
+++ b/modules/org.restlet.test/src/org/restlet/test/RangeTestCase.java
@@ -209,25 +209,25 @@ public class RangeTestCase extends TestCase {
         request.setRanges(Arrays.asList(new Range(0, 10)));
         response = client.handle(request);
-        assertEquals(Status.SUCCESS_OK, response.getStatus());
+        assertEquals(Status.SUCCESS_PARTIAL_CONTENT, response.getStatus());
         assertEquals(""1234567890"", response.getEntity().getText());
 
         request.setRanges(Arrays.asList(new Range(Range.INDEX_FIRST, 2)));
         response = client.handle(request);
-        assertEquals(Status.SUCCESS_OK, response.getStatus());
+        assertEquals(Status.SUCCESS_PARTIAL_CONTENT, response.getStatus());
         assertEquals(""12"", response.getEntity().getText());
 
         request.setRanges(Arrays.asList(new Range(2, 2)));
         response = client.handle(request);
-        assertEquals(Status.SUCCESS_OK, response.getStatus());
+        assertEquals(Status.SUCCESS_PARTIAL_CONTENT, response.getStatus());
         assertEquals(""34"", response.getEntity().getText());
 
         request.setRanges(Arrays.asList(new Range(2, 7)));
         response = client.handle(request);
-        assertEquals(Status.SUCCESS_OK, response.getStatus());
+        assertEquals(Status.SUCCESS_PARTIAL_CONTENT, response.getStatus());
         assertEquals(""3456789"", response.getEntity().getText());
 
         request.setRanges(Arrays.asList(new Range(Range.INDEX_LAST, 7)));
         response = client.handle(request);
-        assertEquals(Status.SUCCESS_OK, response.getStatus());
+        assertEquals(Status.SUCCESS_PARTIAL_CONTENT, response.getStatus());
         assertEquals(""4567890"", response.getEntity().getText());
     }
@@ -277,5 +277,5 @@ public class RangeTestCase extends TestCase {
         request.setMethod(Method.GET);
         response = client.handle(request);
-        assertEquals(Status.SUCCESS_OK, response.getStatus());
+        assertEquals(Status.SUCCESS_PARTIAL_CONTENT, response.getStatus());
         assertEquals(""0000000000"", response.getEntity().getText());
 
@@ -313,5 +313,5 @@ public class RangeTestCase extends TestCase {
         request.setMethod(Method.GET);
         response = client.handle(request);
-        assertEquals(Status.SUCCESS_OK, response.getStatus());
+        assertEquals(Status.SUCCESS_PARTIAL_CONTENT, response.getStatus());
         assertEquals(""888"", response.getEntity().getText());
 
@@ -332,5 +332,5 @@ public class RangeTestCase extends TestCase {
         request.setRanges(Arrays.asList(new Range(3, Range.SIZE_MAX)));
         response = client.handle(request);
-        assertEquals(Status.SUCCESS_OK, response.getStatus());
+        assertEquals(Status.SUCCESS_PARTIAL_CONTENT, response.getStatus());
         assertEquals(""20000998"", response.getEntity().getText());
 
",Added support of Ranges.--
1407,Java,e5ec49b123c4070355182f04397d8c8c347c9aff,,P,apache,hbase,"[2, 5, 0, 3, 0, 0, 0, 4, 116, 38, 8, 13, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/hbase-it/src/test/java/org/apache/hadoop/hbase/IntegrationTestRegionReplicaPerf.java b/hbase-it/src/test/java/org/apache/hadoop/hbase/IntegrationTestRegionReplicaPerf.java
index ca3a8f0e36..8ea27bfd55 100644
--- a/hbase-it/src/test/java/org/apache/hadoop/hbase/IntegrationTestRegionReplicaPerf.java
+++ b/hbase-it/src/test/java/org/apache/hadoop/hbase/IntegrationTestRegionReplicaPerf.java
@@ -33,5 +33,4 @@ import org.apache.hadoop.hbase.client.HBaseAdmin;
 import org.apache.hadoop.hbase.ipc.RpcClient;
 import org.apache.hadoop.hbase.regionserver.DisabledRegionSplitPolicy;
-import org.apache.hadoop.hbase.util.Pair;
 import org.apache.hadoop.mapreduce.Counters;
 import org.apache.hadoop.mapreduce.Job;
@@ -223,40 +222,4 @@ public class IntegrationTestRegionReplicaPerf extends IntegrationTestBase {
   }
 
-  /**
-   * Modify a table, synchronous. Waiting logic similar to that of {@code admin.rb#alter_status}.
-   */
-  private static void modifyTableSync(HBaseAdmin admin, HTableDescriptor desc) throws Exception {
-    admin.modifyTable(desc.getTableName(), desc);
-    Pair<Integer, Integer> status = new Pair<Integer, Integer>() {{
-      setFirst(0);
-      setSecond(0);
-    }};
-    for (int i = 0; status.getFirst() != 0 && i < 500; i++) { // wait up to 500 seconds
-      status = admin.getAlterStatus(desc.getTableName());
-      if (status.getSecond() != 0) {
-        LOG.debug(status.getSecond() - status.getFirst() + ""/"" + status.getSecond()
-          + "" regions updated."");
-        Thread.sleep(1 * 1000l);
-      } else {
-        LOG.debug(""All regions updated."");
-      }
-    }
-    if (status.getSecond() != 0) {
-      throw new Exception(""Failed to update replica count after 500 seconds."");
-    }
-  }
-
-  /**
-   * Set the number of Region replicas.
-   */
-  private static void setReplicas(HBaseAdmin admin, TableName table, int replicaCount)
-      throws Exception {
-    admin.disableTable(table);
-    HTableDescriptor desc = admin.getTableDescriptor(table);
-    desc.setRegionReplication(replicaCount);
-    modifyTableSync(admin, desc);
-    admin.enableTable(table);
-  }
-
   public void test() throws Exception {
     int maxIters = 3;
@@ -295,5 +258,5 @@ public class IntegrationTestRegionReplicaPerf extends IntegrationTestBase {
     cleanUpMonkey(""Altering table."");
     LOG.debug(""Altering "" + tableName + "" replica count to "" + replicaCount);
-    setReplicas(util.getHBaseAdmin(), tableName, replicaCount);
+    util.setReplicas(util.getHBaseAdmin(), tableName, replicaCount);
     setUpMonkey();
     startMonkey();
diff --git a/hbase-it/src/test/java/org/apache/hadoop/hbase/mapreduce/IntegrationTestBulkLoad.java b/hbase-it/src/test/java/org/apache/hadoop/hbase/mapreduce/IntegrationTestBulkLoad.java
index dd4415bf52..4112014bd2 100644
--- a/hbase-it/src/test/java/org/apache/hadoop/hbase/mapreduce/IntegrationTestBulkLoad.java
+++ b/hbase-it/src/test/java/org/apache/hadoop/hbase/mapreduce/IntegrationTestBulkLoad.java
@@ -19,6 +19,4 @@
 package org.apache.hadoop.hbase.mapreduce;
 
-import static org.junit.Assert.assertEquals;
-
 import java.io.DataInput;
 import java.io.DataOutput;
@@ -29,4 +27,5 @@ import java.util.Map;
 import java.util.Random;
 import java.util.Set;
+import java.util.concurrent.atomic.AtomicLong;
 
 import org.apache.commons.cli.CommandLine;
@@ -39,12 +38,23 @@ import org.apache.hadoop.hbase.Cell;
 import org.apache.hadoop.hbase.CellUtil;
 import org.apache.hadoop.hbase.HBaseConfiguration;
+import org.apache.hadoop.hbase.HBaseTestingUtility;
+import org.apache.hadoop.hbase.HTableDescriptor;
 import org.apache.hadoop.hbase.IntegrationTestBase;
 import org.apache.hadoop.hbase.IntegrationTestingUtility;
 import org.apache.hadoop.hbase.IntegrationTests;
 import org.apache.hadoop.hbase.KeyValue;
+import org.apache.hadoop.hbase.TableName;
+import org.apache.hadoop.hbase.client.Consistency;
+import org.apache.hadoop.hbase.client.HBaseAdmin;
 import org.apache.hadoop.hbase.client.HTable;
 import org.apache.hadoop.hbase.client.Result;
 import org.apache.hadoop.hbase.client.Scan;
+import org.apache.hadoop.hbase.coprocessor.BaseRegionObserver;
+import org.apache.hadoop.hbase.coprocessor.ObserverContext;
+import org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment;
 import org.apache.hadoop.hbase.io.ImmutableBytesWritable;
+import org.apache.hadoop.hbase.regionserver.InternalScanner;
+import org.apache.hadoop.hbase.regionserver.RegionScanner;
+import org.apache.hadoop.hbase.regionserver.StorefileRefresherChore;
 import org.apache.hadoop.hbase.util.Bytes;
 import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;
@@ -70,4 +80,7 @@ import org.junit.Test;
 import org.junit.experimental.categories.Category;
 
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertTrue;
+
 /**
  * Test Bulk Load and MR on a distributed cluster.
@@ -100,4 +113,6 @@ import org.junit.experimental.categories.Category;
  * The name of the table.
  *
+ * hbase.IntegrationTestBulkLoad.replicaCount
+ * How many region replicas to configure for the table under test.
  */
 @Category(IntegrationTests.class)
@@ -106,7 +121,7 @@ public class IntegrationTestBulkLoad extends IntegrationTestBase {
   private static final Log LOG = LogFactory.getLog(IntegrationTestBulkLoad.class);
 
-  private static byte[] CHAIN_FAM = Bytes.toBytes(""L"");
-  private static byte[] SORT_FAM  = Bytes.toBytes(""S"");
-  private static byte[] DATA_FAM  = Bytes.toBytes(""D"");
+  private static final byte[] CHAIN_FAM = Bytes.toBytes(""L"");
+  private static final byte[] SORT_FAM  = Bytes.toBytes(""S"");
+  private static final byte[] DATA_FAM  = Bytes.toBytes(""D"");
 
   private static String CHAIN_LENGTH_KEY = ""hbase.IntegrationTestBulkLoad.chainLength"";
@@ -124,7 +139,71 @@ public class IntegrationTestBulkLoad extends IntegrationTestBase {
   private static String TABLE_NAME = ""IntegrationTestBulkLoad"";
 
+  private static String NUM_REPLICA_COUNT_KEY = ""hbase.IntegrationTestBulkLoad.replicaCount"";
+  private static int NUM_REPLICA_COUNT_DEFAULT = 1;
+
+  private static final String OPT_LOAD = ""load"";
+  private static final String OPT_CHECK = ""check"";
+
+  private boolean load = false;
+  private boolean check = false;
+
+  public static class SlowMeCoproScanOperations extends BaseRegionObserver {
+    static final AtomicLong sleepTime = new AtomicLong(2000);
+    Random r = new Random();
+    AtomicLong countOfNext = new AtomicLong(0); 
+    AtomicLong countOfOpen = new AtomicLong(0); 
+    public SlowMeCoproScanOperations() {}
+    @Override
+    public RegionScanner preScannerOpen(final ObserverContext<RegionCoprocessorEnvironment> e,
+        final Scan scan, final RegionScanner s) throws IOException {
+      if (countOfOpen.incrementAndGet() % 4 == 0) { //slowdown openScanner randomly
+        slowdownCode(e);
+      }
+      return s;
+    }
+
+    @Override
+    public boolean preScannerNext(final ObserverContext<RegionCoprocessorEnvironment> e,
+        final InternalScanner s, final List<Result> results,
+        final int limit, final boolean hasMore) throws IOException {
+      //this will slow down a certain next operation if the conditions are met. The slowness
+      //will allow the call to go to a replica
+      if (countOfNext.incrementAndGet() % 4 == 0) {
+        slowdownCode(e);
+      }
+      return true;
+    }
+    protected void slowdownCode(final ObserverContext<RegionCoprocessorEnvironment> e) {
+      if (e.getEnvironment().getRegion().getRegionInfo().getReplicaId() == 0) {
+        try {
+          if (sleepTime.get() > 0) {
+            LOG.info(""Sleeping for "" + sleepTime.get() + "" ms"");
+            Thread.sleep(sleepTime.get());
+          }
+        } catch (InterruptedException e1) {
+          LOG.error(e1);
+        }
+      } 
+    }
+  }
+
+  /**
+   * Modify table {@code getTableName()} to carry {@link SlowMeCoproScanOperations}.
+   */
+  private void installSlowingCoproc() throws IOException, InterruptedException {
+    int replicaCount = conf.getInt(NUM_REPLICA_COUNT_KEY, NUM_REPLICA_COUNT_DEFAULT);
+    if (replicaCount == NUM_REPLICA_COUNT_DEFAULT) return;
+
+    TableName t = TableName.valueOf(getTablename());
+    HBaseAdmin admin = util.getHBaseAdmin();
+    HTableDescriptor desc = admin.getTableDescriptor(t);
+    desc.addCoprocessor(SlowMeCoproScanOperations.class.getName());
+    HBaseTestingUtility.modifyTableSync(admin, desc);
+  }
+
   @Test
   public void testBulkLoad() throws Exception {
     runLoad();
+    installSlowingCoproc();
     runCheck();
   }
@@ -146,5 +225,5 @@ public class IntegrationTestBulkLoad extends IntegrationTestBase {
   }
 
-  private void setupTable() throws IOException {
+  private void setupTable() throws IOException, InterruptedException {
     if (util.getHBaseAdmin().tableExists(getTablename())) {
       util.deleteTable(getTablename());
@@ -156,4 +235,10 @@ public class IntegrationTestBulkLoad extends IntegrationTestBase {
         getSplits(16)
     );
+
+    int replicaCount = conf.getInt(NUM_REPLICA_COUNT_KEY, NUM_REPLICA_COUNT_DEFAULT);
+    if (replicaCount == NUM_REPLICA_COUNT_DEFAULT) return;
+
+    TableName t = TableName.valueOf(getTablename());
+    HBaseTestingUtility.setReplicas(util.getHBaseAdmin(), t, replicaCount);
   }
 
@@ -557,6 +642,6 @@ public class IntegrationTestBulkLoad extends IntegrationTestBase {
 
     Job job = new Job(conf);
-
     job.setJarByClass(getClass());
+    job.setJobName(jobName);
 
     job.setPartitionerClass(NaturalKeyPartitioner.class);
@@ -564,14 +649,14 @@ public class IntegrationTestBulkLoad extends IntegrationTestBase {
     job.setSortComparatorClass(CompositeKeyComparator.class);
 
-    Scan s = new Scan();
-    s.addFamily(CHAIN_FAM);
-    s.addFamily(SORT_FAM);
-    s.setMaxVersions(1);
-    s.setCacheBlocks(false);
-    s.setBatch(1000);
+    Scan scan = new Scan();
+    scan.addFamily(CHAIN_FAM);
+    scan.addFamily(SORT_FAM);
+    scan.setMaxVersions(1);
+    scan.setCacheBlocks(false);
+    scan.setBatch(1000);
 
     TableMapReduceUtil.initTableMapperJob(
         Bytes.toBytes(getTablename()),
-        new Scan(),
+        scan,
         LinkedListCheckingMapper.class,
         LinkKey.class,
@@ -596,4 +681,8 @@ public class IntegrationTestBulkLoad extends IntegrationTestBase {
     util = getTestingUtil(getConf());
     util.initializeCluster(1);
+    int replicaCount = getConf().getInt(NUM_REPLICA_COUNT_KEY, NUM_REPLICA_COUNT_DEFAULT);
+    if (LOG.isDebugEnabled() && replicaCount != NUM_REPLICA_COUNT_DEFAULT) {
+      LOG.debug(""Region Replicas enabled: "" + replicaCount);
+    }
 
     // Scale this up on a real cluster
@@ -608,10 +697,4 @@ public class IntegrationTestBulkLoad extends IntegrationTestBase {
   }
 
-  private static final String OPT_LOAD = ""load"";
-  private static final String OPT_CHECK = ""check"";
-
-  private boolean load = false;
-  private boolean check = false;
-
   @Override
   protected void addOptions() {
@@ -633,4 +716,5 @@ public class IntegrationTestBulkLoad extends IntegrationTestBase {
       runLoad();
     } else if (check) {
+      installSlowingCoproc();
       runCheck();
     } else {
@@ -656,4 +740,3 @@ public class IntegrationTestBulkLoad extends IntegrationTestBase {
     System.exit(status);
   }
-
-}
\ No newline at end of file
+}
diff --git a/hbase-it/src/test/java/org/apache/hadoop/hbase/test/IntegrationTestTimeBoundedRequestsWithRegionReplicas.java b/hbase-it/src/test/java/org/apache/hadoop/hbase/test/IntegrationTestTimeBoundedRequestsWithRegionReplicas.java
index 66f31552d7..eb3bb706b0 100644
--- a/hbase-it/src/test/java/org/apache/hadoop/hbase/test/IntegrationTestTimeBoundedRequestsWithRegionReplicas.java
+++ b/hbase-it/src/test/java/org/apache/hadoop/hbase/test/IntegrationTestTimeBoundedRequestsWithRegionReplicas.java
@@ -235,4 +235,5 @@ public class IntegrationTestTimeBoundedRequestsWithRegionReplicas extends Integr
     protected long runTime;
     protected Thread timeoutThread;
+    protected AtomicLong staleReads = new AtomicLong();
 
     public TimeBoundedMultiThreadedReader(LoadTestDataGenerator dataGen, Configuration conf,
@@ -264,4 +265,5 @@ public class IntegrationTestTimeBoundedRequestsWithRegionReplicas extends Integr
     protected String progressInfo() {
       StringBuilder builder = new StringBuilder(super.progressInfo());
+      appendToStatus(builder, ""stale_reads"", staleReads.get());
       appendToStatus(builder, ""get_timeouts"", timedOutReads.get());
       return builder.toString();
@@ -328,4 +330,7 @@ public class IntegrationTestTimeBoundedRequestsWithRegionReplicas extends Integr
           throws IOException {
         super.verifyResultsAndUpdateMetrics(verify, gets, elapsedNano, results, table, isNullExpected);
+        for (Result r : results) {
+          if (r.isStale()) staleReads.incrementAndGet();
+        }
         // we actually do not timeout and cancel the reads after timeout. We just wait for the RPC
         // to complete, but if the request took longer than timeout, we treat that as error.
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableRecordReaderImpl.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableRecordReaderImpl.java
index 7eb7871d3a..e8e6e8bb73 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableRecordReaderImpl.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableRecordReaderImpl.java
@@ -66,4 +66,5 @@ public class TableRecordReaderImpl {
   private Method getCounter = null;
   private long numRestarts = 0;
+  private long numStale = 0;
   private long timestamp;
   private int rowcount;
@@ -204,4 +205,5 @@ public class TableRecordReaderImpl {
       try {
         value = this.scanner.next();
+        if (value != null && value.isStale()) numStale++;
         if (logScannerActivity) {
           rowcount ++;
@@ -231,4 +233,5 @@ public class TableRecordReaderImpl {
         }
         value = scanner.next();
+        if (value != null && value.isStale()) numStale++;
         numRestarts++;
       }
@@ -271,9 +274,9 @@ public class TableRecordReaderImpl {
     ScanMetrics scanMetrics = ProtobufUtil.toScanMetrics(serializedMetrics);
 
-    updateCounters(scanMetrics, numRestarts, getCounter, context);
+    updateCounters(scanMetrics, numRestarts, getCounter, context, numStale);
   }
 
   protected static void updateCounters(ScanMetrics scanMetrics, long numScannerRestarts,
-      Method getCounter, TaskAttemptContext context) {
+      Method getCounter, TaskAttemptContext context, long numStale) {
     // we can get access to counters only if hbase uses new mapreduce APIs
     if (getCounter == null) {
@@ -290,4 +293,6 @@ public class TableRecordReaderImpl {
       ((Counter) getCounter.invoke(context, HBASE_COUNTER_GROUP_NAME,
           ""NUM_SCANNER_RESTARTS"")).increment(numScannerRestarts);
+      ((Counter) getCounter.invoke(context, HBASE_COUNTER_GROUP_NAME,
+          ""NUM_SCAN_RESULTS_STALE"")).increment(numStale);
     } catch (Exception e) {
       LOG.debug(""can't update counter."" + StringUtils.stringifyException(e));
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableSnapshotInputFormat.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableSnapshotInputFormat.java
index f8d4d18059..8071c5648b 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableSnapshotInputFormat.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableSnapshotInputFormat.java
@@ -153,5 +153,5 @@ public class TableSnapshotInputFormat extends InputFormat<ImmutableBytesWritable
         ScanMetrics scanMetrics = delegate.getScanner().getScanMetrics();
         if (scanMetrics != null && context != null) {
-          TableRecordReaderImpl.updateCounters(scanMetrics, 0, getCounter, context);
+          TableRecordReaderImpl.updateCounters(scanMetrics, 0, getCounter, context, 0);
         }
       }
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java
index 79bda274d7..3b64b735de 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java
@@ -93,4 +93,5 @@ import org.apache.hadoop.hbase.util.JVMClusterUtil;
 import org.apache.hadoop.hbase.util.JVMClusterUtil.MasterThread;
 import org.apache.hadoop.hbase.util.JVMClusterUtil.RegionServerThread;
+import org.apache.hadoop.hbase.util.Pair;
 import org.apache.hadoop.hbase.util.RegionSplitter;
 import org.apache.hadoop.hbase.util.RetryCounter;
@@ -1464,4 +1465,42 @@ public class HBaseTestingUtility extends HBaseCommonTestingUtility {
   }
 
+  /**
+   * Modify a table, synchronous. Waiting logic similar to that of {@code admin.rb#alter_status}.
+   */
+  public static void modifyTableSync(HBaseAdmin admin, HTableDescriptor desc)
+      throws IOException, InterruptedException {
+    admin.modifyTable(desc.getTableName(), desc);
+    Pair<Integer, Integer> status = new Pair<Integer, Integer>() {{
+      setFirst(0);
+      setSecond(0);
+    }};
+    for (int i = 0; status.getFirst() != 0 && i < 500; i++) { // wait up to 500 seconds
+      status = admin.getAlterStatus(desc.getTableName());
+      if (status.getSecond() != 0) {
+        LOG.debug(status.getSecond() - status.getFirst() + ""/"" + status.getSecond()
+          + "" regions updated."");
+        Thread.sleep(1 * 1000l);
+      } else {
+        LOG.debug(""All regions updated."");
+        break;
+      }
+    }
+    if (status.getSecond() != 0) {
+      throw new IOException(""Failed to update replica count after 500 seconds."");
+    }
+  }
+
+  /**
+   * Set the number of Region replicas.
+   */
+  public static void setReplicas(HBaseAdmin admin, TableName table, int replicaCount)
+      throws IOException, InterruptedException {
+    admin.disableTable(table);
+    HTableDescriptor desc = admin.getTableDescriptor(table);
+    desc.setRegionReplication(replicaCount);
+    modifyTableSync(admin, desc);
+    admin.enableTable(table);
+  }
+
   /**
    * Drop an existing table
",HBASE-10818. Add integration test for bulkload- with replicas (Nick Dimiduk and Devaraj Das)--
1413,Java,b580f0706dc1dcded6d1a584c37a83dd1cb2ea2a,,C,restlet,restlet-framework-java,"[1, 0, 2, 0, 10, 4, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 4, 0, 0, 0, 0, 0, 0]","diff --git a/build/tmpl/text/changes.txt b/build/tmpl/text/changes.txt
index 9f9255ad3..44c46f7a7 100644
--- a/build/tmpl/text/changes.txt
+++ b/build/tmpl/text/changes.txt
@@ -12,4 +12,8 @@ Changes log
         Reported by Avi Flax and Rhett Sutphin.
     - Misc
+      - The simplified logging formatter (one line) is now available only in
+        the Java SE edition as it could cause troubles with Java EE container
+        and potentially GAE/Android as we reconfigure the default log manager
+        programmatically. Reported by Kristoffer Gronowski and Bo Xing.
 
 - 2.1 Milestone 3 (03/31/2011)
diff --git a/modules/org.restlet/src/org/restlet/engine/Engine.java b/modules/org.restlet/src/org/restlet/engine/Engine.java
index 0d0aba075..d3d0799f8 100644
--- a/modules/org.restlet/src/org/restlet/engine/Engine.java
+++ b/modules/org.restlet/src/org/restlet/engine/Engine.java
@@ -102,11 +102,13 @@ public class Engine {
     private static volatile Engine instance = null;
 
+    // [ifdef jse] member
     /** The org.restlet log level . */
     private static volatile boolean logConfigured = false;
 
-    // [ifndef gwt] member
+    // [ifdef jse] member
     /** The general log formatter. */
     private static volatile Class<? extends Formatter> logFormatter = org.restlet.engine.log.SimplestFormatter.class;
 
+    // [ifdef jse] member
     /** The general log level . */
     private static volatile Level logLevel = Level.INFO;
@@ -121,4 +123,5 @@ public class Engine {
     public static final String RELEASE_NUMBER = ""@release-type@@release-number@"";
 
+    // [ifdef jse] member
     /** The org.restlet log level . */
     private static volatile Level restletLogLevel;
@@ -149,9 +152,9 @@ public class Engine {
     }
 
+    // [ifdef jse] method
     /**
      * Updates the global log configuration of the JVM programmatically.
      */
     public static void configureLog() {
-        // [ifndef gwt]
         if ((System.getProperty(""java.util.logging.config.file"") == null)
                 && (System.getProperty(""java.util.logging.config.class"") == null)) {
@@ -189,11 +192,8 @@ public class Engine {
             } catch (Exception e) {
                 e.printStackTrace();
-            } finally {
-                logConfigured = true;
             }
         }
-        // [enddef]
-        // [ifdef gwt] instruction uncomment
-        // logConfigured = true;
+
+        logConfigured = true;
     }
 
@@ -223,5 +223,5 @@ public class Engine {
     }
 
-    // [ifndef gwt] method
+    // [ifdef jse] method
     /**
      * Returns the general log formatter.
@@ -285,4 +285,5 @@ public class Engine {
     }
 
+    // [ifdef jse] method
     /**
      * Returns the general log level.
@@ -306,4 +307,5 @@ public class Engine {
     }
 
+    // [ifdef jse] method
     /**
      * Returns the Restlet log level. For loggers with a name starting with
@@ -347,8 +349,9 @@ public class Engine {
      */
     public static synchronized Engine register(boolean discoverPlugins) {
+        // [ifdef jse]
         if (!logConfigured) {
             configureLog();
         }
-
+        // [enddef]
         Engine result = new Engine(discoverPlugins);
         org.restlet.engine.Engine.setInstance(result);
@@ -369,5 +372,5 @@ public class Engine {
     }
 
-    // [ifndef gwt] method
+    // [ifdef jse] method
     /**
      * Sets the general log formatter.
@@ -381,4 +384,5 @@ public class Engine {
     }
 
+    // [ifdef jse] method
     /**
      * Sets the general log level. Modifies the global JVM's {@link LogManager}.
@@ -392,4 +396,5 @@ public class Engine {
     }
 
+    // [ifdef jse] method
     /**
      * Sets the Restlet log level. For loggers with a name starting with
",      - The simplified logging formatter (one line)- is now available only in         the Java SE edition as it could cause- troubles with Java EE container         and potentially GAE/Android as we- reconfigure the default log manager         programmatically. Reported by- Kristoffer Gronowski and Bo Xing.--
1436,Java,8a07f772e2d36b759f4d5ab6f213fbb0869a1766,,C,orientechnologies,orientdb,"[1, 5, 0, 1, 0, 0, 0, 1, 16, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/object/src/main/java/com/orientechnologies/orient/object/enhancement/OObjectEntityEnhancer.java b/object/src/main/java/com/orientechnologies/orient/object/enhancement/OObjectEntityEnhancer.java
index f4e5e89df7..db4864a47d 100644
--- a/object/src/main/java/com/orientechnologies/orient/object/enhancement/OObjectEntityEnhancer.java
+++ b/object/src/main/java/com/orientechnologies/orient/object/enhancement/OObjectEntityEnhancer.java
@@ -50,280 +50,285 @@ import com.orientechnologies.orient.object.serialization.OObjectCustomSerializer
 public class OObjectEntityEnhancer {
 
-	private static final OObjectEntityEnhancer	instance							= new OObjectEntityEnhancer();
+  private static final OObjectEntityEnhancer instance              = new OObjectEntityEnhancer();
 
-	public static final String									ENHANCER_CLASS_PREFIX	= ""orientdb_"";
+  public static final String                 ENHANCER_CLASS_PREFIX = ""orientdb_"";
 
-	public OObjectEntityEnhancer() {
-	}
+  public OObjectEntityEnhancer() {
+  }
 
-	@SuppressWarnings(""unchecked"")
-	public <T> T getProxiedInstance(final String iClass, final OEntityManager entityManager, final ODocument doc, Object... iArgs) {
-		final Class<T> clazz = (Class<T>) entityManager.getEntityClass(iClass);
-		return getProxiedInstance(clazz, doc, iArgs);
-	}
+  @SuppressWarnings(""unchecked"")
+  public <T> T getProxiedInstance(final String iClass, final OEntityManager entityManager, final ODocument doc, Object... iArgs) {
+    final Class<T> clazz = (Class<T>) entityManager.getEntityClass(iClass);
+    return getProxiedInstance(clazz, doc, iArgs);
+  }
 
-	@SuppressWarnings(""unchecked"")
-	public <T> T getProxiedInstance(final String iClass, final Object iEnclosingInstance, final OEntityManager entityManager,
-			final ODocument doc, Object... iArgs) {
-		final Class<T> clazz = (Class<T>) entityManager.getEntityClass(iClass);
-		return getProxiedInstance(clazz, iEnclosingInstance, doc, iArgs);
-	}
+  @SuppressWarnings(""unchecked"")
+  public <T> T getProxiedInstance(final String iClass, final Object iEnclosingInstance, final OEntityManager entityManager,
+      final ODocument doc, Object... iArgs) {
+    final Class<T> clazz = (Class<T>) entityManager.getEntityClass(iClass);
+    return getProxiedInstance(clazz, iEnclosingInstance, doc, iArgs);
+  }
 
-	public <T> T getProxiedInstance(final Class<T> iClass, final ODocument doc, Object... iArgs) {
-		return getProxiedInstance(iClass, null, doc, iArgs);
-	}
+  public <T> T getProxiedInstance(final Class<T> iClass, final ODocument doc, Object... iArgs) {
+    return getProxiedInstance(iClass, null, doc, iArgs);
+  }
 
-	@SuppressWarnings(""unchecked"")
-	public <T> T getProxiedInstance(final Class<T> iClass, Object iEnclosingInstance, final ODocument doc, Object... iArgs) {
-		if (iClass == null) {
-			throw new OSerializationException(""Type "" + doc.getClassName()
-					+ "" cannot be serialized because is not part of registered entities. To fix this error register this class"");
-		}
-		final Class<T> c;
-		boolean isInnerClass = iClass.getEnclosingClass() != null;
-		if (Proxy.class.isAssignableFrom(iClass)) {
-			c = iClass;
-		} else {
-			ProxyFactory f = new ProxyFactory();
-			f.setSuperclass(iClass);
-			f.setFilter(new MethodFilter() {
-				public boolean isHandled(Method m) {
-					final String methodName = m.getName();
-					try {
-						return (isSetterMethod(methodName, m) || isGetterMethod(methodName, m) || methodName.equals(""equals"") || methodName
-								.equals(""hashCode""));
-					} catch (NoSuchFieldException nsfe) {
-						OLogManager.instance().warn(this, ""Error handling the method %s in class %s"", nsfe, m.getName(), iClass.getName());
-						return false;
-					} catch (SecurityException se) {
-						OLogManager.instance().warn(this, """", se, m.getName(), iClass.getName());
-						return false;
-					}
-				}
-			});
-			c = f.createClass();
-		}
-		MethodHandler mi = new OObjectProxyMethodHandler(doc);
-		try {
-			T newEntity;
-			if (iArgs != null && iArgs.length > 0) {
-				if (isInnerClass) {
-					if (iEnclosingInstance == null) {
-						iEnclosingInstance = iClass.getEnclosingClass().newInstance();
-					}
-					Object[] newArgs = new Object[iArgs.length + 1];
-					newArgs[0] = iEnclosingInstance;
-					for (int i = 0; i < iArgs.length; i++) {
-						newArgs[i + 1] = iArgs[i];
-					}
-					iArgs = newArgs;
-				}
-				Constructor<T> constructor = null;
-				for (Constructor<?> constr : c.getConstructors()) {
-					boolean found = true;
-					if (constr.getParameterTypes().length == iArgs.length) {
-						for (int i = 0; i < constr.getParameterTypes().length; i++) {
-							Class<?> parameterType = constr.getParameterTypes()[i];
-							if (parameterType.isPrimitive()) {
-								if (!isPrimitiveParameterCorrect(parameterType, iArgs[i])) {
-									found = false;
-									break;
-								}
-							} else if (iArgs[i] != null && !parameterType.isAssignableFrom(iArgs[i].getClass())) {
-								found = false;
-								break;
-							}
-						}
-					} else {
-						continue;
-					}
-					if (found) {
-						constructor = (Constructor<T>) constr;
-						break;
-					}
-				}
-				if (constructor != null) {
-					newEntity = (T) constructor.newInstance(iArgs);
-					initDocument(iClass, newEntity, doc, (ODatabaseObject) ODatabaseRecordThreadLocal.INSTANCE.get().getDatabaseOwner());
-				} else {
-					if (iEnclosingInstance != null)
-						newEntity = createInstanceNoParameters(c, iEnclosingInstance);
-					else
-						newEntity = createInstanceNoParameters(c, iClass);
-				}
-			} else {
-				if (iEnclosingInstance != null)
-					newEntity = createInstanceNoParameters(c, iEnclosingInstance);
-				else
-					newEntity = createInstanceNoParameters(c, iClass);
-			}
-			((Proxy) newEntity).setHandler(mi);
-			if (OObjectEntitySerializer.hasBoundedDocumentField(iClass))
-				OObjectEntitySerializer.setFieldValue(OObjectEntitySerializer.getBoundedDocumentField(iClass), newEntity, doc);
-			return newEntity;
-		} catch (InstantiationException ie) {
-			OLogManager.instance().error(this, ""Error creating proxied instance for class "" + iClass.getName(), ie);
-		} catch (IllegalAccessException iae) {
-			OLogManager.instance().error(this, ""Error creating proxied instance for class "" + iClass.getName(), iae);
-		} catch (IllegalArgumentException iae) {
-			OLogManager.instance().error(this, ""Error creating proxied instance for class "" + iClass.getName(), iae);
-		} catch (SecurityException se) {
-			OLogManager.instance().error(this, ""Error creating proxied instance for class "" + iClass.getName(), se);
-		} catch (InvocationTargetException ite) {
-			OLogManager.instance().error(this, ""Error creating proxied instance for class "" + iClass.getName(), ite);
-		} catch (NoSuchMethodException nsme) {
-			OLogManager.instance().error(this, ""Error creating proxied instance for class "" + iClass.getName(), nsme);
-		}
-		return null;
-	}
+  @SuppressWarnings(""unchecked"")
+  public <T> T getProxiedInstance(final Class<T> iClass, Object iEnclosingInstance, final ODocument doc, Object... iArgs) {
+    if (iClass == null) {
+      throw new OSerializationException(""Type "" + doc.getClassName()
+          + "" cannot be serialized because is not part of registered entities. To fix this error register this class"");
+    }
+    final Class<T> c;
+    boolean isInnerClass = iClass.getEnclosingClass() != null;
+    if (Proxy.class.isAssignableFrom(iClass)) {
+      c = iClass;
+    } else {
+      ProxyFactory f = new ProxyFactory();
+      f.setSuperclass(iClass);
+      f.setFilter(new MethodFilter() {
+        public boolean isHandled(Method m) {
+          final String methodName = m.getName();
+          try {
+            return (isSetterMethod(methodName, m) || isGetterMethod(methodName, m) || methodName.equals(""equals"") || methodName
+                .equals(""hashCode""));
+          } catch (NoSuchFieldException nsfe) {
+            OLogManager.instance().warn(this, ""Error handling the method %s in class %s"", nsfe, m.getName(), iClass.getName());
+            return false;
+          } catch (SecurityException se) {
+            OLogManager.instance().warn(this, """", se, m.getName(), iClass.getName());
+            return false;
+          }
+        }
+      });
+      c = f.createClass();
+    }
+    MethodHandler mi = new OObjectProxyMethodHandler(doc);
+    try {
+      T newEntity;
+      if (iArgs != null && iArgs.length > 0) {
+        if (isInnerClass) {
+          if (iEnclosingInstance == null) {
+            iEnclosingInstance = iClass.getEnclosingClass().newInstance();
+          }
+          Object[] newArgs = new Object[iArgs.length + 1];
+          newArgs[0] = iEnclosingInstance;
+          for (int i = 0; i < iArgs.length; i++) {
+            newArgs[i + 1] = iArgs[i];
+          }
+          iArgs = newArgs;
+        }
+        Constructor<T> constructor = null;
+        for (Constructor<?> constr : c.getConstructors()) {
+          boolean found = true;
+          if (constr.getParameterTypes().length == iArgs.length) {
+            for (int i = 0; i < constr.getParameterTypes().length; i++) {
+              Class<?> parameterType = constr.getParameterTypes()[i];
+              if (parameterType.isPrimitive()) {
+                if (!isPrimitiveParameterCorrect(parameterType, iArgs[i])) {
+                  found = false;
+                  break;
+                }
+              } else if (iArgs[i] != null && !parameterType.isAssignableFrom(iArgs[i].getClass())) {
+                found = false;
+                break;
+              }
+            }
+          } else {
+            continue;
+          }
+          if (found) {
+            constructor = (Constructor<T>) constr;
+            break;
+          }
+        }
+        if (constructor != null) {
+          newEntity = (T) constructor.newInstance(iArgs);
+          initDocument(iClass, newEntity, doc, (ODatabaseObject) ODatabaseRecordThreadLocal.INSTANCE.get().getDatabaseOwner());
+        } else {
+          if (iEnclosingInstance != null)
+            newEntity = createInstanceNoParameters(c, iEnclosingInstance);
+          else
+            newEntity = createInstanceNoParameters(c, iClass);
+        }
+      } else {
+        if (iEnclosingInstance != null)
+          newEntity = createInstanceNoParameters(c, iEnclosingInstance);
+        else
+          newEntity = createInstanceNoParameters(c, iClass);
+      }
+      ((Proxy) newEntity).setHandler(mi);
+      if (OObjectEntitySerializer.hasBoundedDocumentField(iClass))
+        OObjectEntitySerializer.setFieldValue(OObjectEntitySerializer.getBoundedDocumentField(iClass), newEntity, doc);
+      return newEntity;
+    } catch (InstantiationException ie) {
+      OLogManager.instance().error(this, ""Error creating proxied instance for class "" + iClass.getName(), ie);
+    } catch (IllegalAccessException iae) {
+      OLogManager.instance().error(this, ""Error creating proxied instance for class "" + iClass.getName(), iae);
+    } catch (IllegalArgumentException iae) {
+      OLogManager.instance().error(this, ""Error creating proxied instance for class "" + iClass.getName(), iae);
+    } catch (SecurityException se) {
+      OLogManager.instance().error(this, ""Error creating proxied instance for class "" + iClass.getName(), se);
+    } catch (InvocationTargetException ite) {
+      OLogManager.instance().error(this, ""Error creating proxied instance for class "" + iClass.getName(), ite);
+    } catch (NoSuchMethodException nsme) {
+      OLogManager.instance().error(this, ""Error creating proxied instance for class "" + iClass.getName(), nsme);
+    }
+    return null;
+  }
 
-	public static synchronized OObjectEntityEnhancer getInstance() {
-		return instance;
-	}
+  public static synchronized OObjectEntityEnhancer getInstance() {
+    return instance;
+  }
 
-	private boolean isSetterMethod(String fieldName, Method m) throws SecurityException, NoSuchFieldException {
-		if (!fieldName.startsWith(""set"") || !checkIfFirstCharAfterPrefixIsUpperCase(fieldName, ""set""))
-			return false;
-		if (m.getParameterTypes() != null && m.getParameterTypes().length != 1)
-			return false;
-		return !OObjectEntitySerializer.isTransientField(m.getDeclaringClass(), getFieldName(m));
-	}
+  private boolean isSetterMethod(String fieldName, Method m) throws SecurityException, NoSuchFieldException {
+    if (!fieldName.startsWith(""set"") || !checkIfFirstCharAfterPrefixIsUpperCase(fieldName, ""set""))
+      return false;
+    if (m.getParameterTypes() != null && m.getParameterTypes().length != 1)
+      return false;
+    return !OObjectEntitySerializer.isTransientField(m.getDeclaringClass(), getFieldName(m));
+  }
 
-	private boolean isGetterMethod(String fieldName, Method m) throws SecurityException, NoSuchFieldException {
-		int prefixLength;
-		if (fieldName.startsWith(""get"") && checkIfFirstCharAfterPrefixIsUpperCase(fieldName, ""get""))
-			prefixLength = ""get"".length();
-		else if (fieldName.startsWith(""is"") && checkIfFirstCharAfterPrefixIsUpperCase(fieldName, ""is""))
-			prefixLength = ""is"".length();
-		else
-			return false;
-		if (m.getParameterTypes() != null && m.getParameterTypes().length > 0)
-			return false;
-		if (fieldName.length() <= prefixLength)
-			return false;
-		return !OObjectEntitySerializer.isTransientField(m.getDeclaringClass(), getFieldName(m));
-	}
+  private boolean isGetterMethod(String fieldName, Method m) throws SecurityException, NoSuchFieldException {
+    int prefixLength;
+    if (fieldName.startsWith(""get"") && checkIfFirstCharAfterPrefixIsUpperCase(fieldName, ""get""))
+      prefixLength = ""get"".length();
+    else if (fieldName.startsWith(""is"") && checkIfFirstCharAfterPrefixIsUpperCase(fieldName, ""is""))
+      prefixLength = ""is"".length();
+    else
+      return false;
+    if (m.getParameterTypes() != null && m.getParameterTypes().length > 0)
+      return false;
+    if (fieldName.length() <= prefixLength)
+      return false;
+    return !OObjectEntitySerializer.isTransientField(m.getDeclaringClass(), getFieldName(m));
+  }
 
-	protected String getFieldName(Method m) {
-		if (m.getName().startsWith(""get""))
-			return getFieldName(m.getName(), ""get"");
-		else if (m.getName().startsWith(""set""))
-			return getFieldName(m.getName(), ""set"");
-		else
-			return getFieldName(m.getName(), ""is"");
-	}
+  protected String getFieldName(Method m) {
+    if (m.getName().startsWith(""get""))
+      return getFieldName(m.getName(), ""get"");
+    else if (m.getName().startsWith(""set""))
+      return getFieldName(m.getName(), ""set"");
+    else
+      return getFieldName(m.getName(), ""is"");
+  }
 
-	protected String getFieldName(String methodName, String prefix) {
-		StringBuffer fieldName = new StringBuffer();
-		fieldName.append(Character.toLowerCase(methodName.charAt(prefix.length())));
-		for (int i = (prefix.length() + 1); i < methodName.length(); i++) {
-			fieldName.append(methodName.charAt(i));
-		}
-		return fieldName.toString();
-	}
+  protected String getFieldName(String methodName, String prefix) {
+    StringBuffer fieldName = new StringBuffer();
+    fieldName.append(Character.toLowerCase(methodName.charAt(prefix.length())));
+    for (int i = (prefix.length() + 1); i < methodName.length(); i++) {
+      fieldName.append(methodName.charAt(i));
+    }
+    return fieldName.toString();
+  }
 
-	private boolean checkIfFirstCharAfterPrefixIsUpperCase(String methodName, String prefix) {
-		return methodName.length() > prefix.length() ? Character.isUpperCase(methodName.charAt(prefix.length())) : false;
-	}
+  private boolean checkIfFirstCharAfterPrefixIsUpperCase(String methodName, String prefix) {
+    return methodName.length() > prefix.length() ? Character.isUpperCase(methodName.charAt(prefix.length())) : false;
+  }
 
-	private boolean isPrimitiveParameterCorrect(Class<?> primitiveClass, Object parameterValue) {
-		if (parameterValue == null)
-			return false;
-		final Class<?> parameterClass = parameterValue.getClass();
-		if (Integer.TYPE.isAssignableFrom(primitiveClass))
-			return Integer.class.isAssignableFrom(parameterClass);
-		else if (Double.TYPE.isAssignableFrom(primitiveClass))
-			return Double.class.isAssignableFrom(parameterClass);
-		else if (Float.TYPE.isAssignableFrom(primitiveClass))
-			return Float.class.isAssignableFrom(parameterClass);
-		else if (Long.TYPE.isAssignableFrom(primitiveClass))
-			return Long.class.isAssignableFrom(parameterClass);
-		else if (Short.TYPE.isAssignableFrom(primitiveClass))
-			return Short.class.isAssignableFrom(parameterClass);
-		else if (Byte.TYPE.isAssignableFrom(primitiveClass))
-			return Byte.class.isAssignableFrom(parameterClass);
-		return false;
-	}
+  private boolean isPrimitiveParameterCorrect(Class<?> primitiveClass, Object parameterValue) {
+    if (parameterValue == null)
+      return false;
+    final Class<?> parameterClass = parameterValue.getClass();
+    if (Integer.TYPE.isAssignableFrom(primitiveClass))
+      return Integer.class.isAssignableFrom(parameterClass);
+    else if (Double.TYPE.isAssignableFrom(primitiveClass))
+      return Double.class.isAssignableFrom(parameterClass);
+    else if (Float.TYPE.isAssignableFrom(primitiveClass))
+      return Float.class.isAssignableFrom(parameterClass);
+    else if (Long.TYPE.isAssignableFrom(primitiveClass))
+      return Long.class.isAssignableFrom(parameterClass);
+    else if (Short.TYPE.isAssignableFrom(primitiveClass))
+      return Short.class.isAssignableFrom(parameterClass);
+    else if (Byte.TYPE.isAssignableFrom(primitiveClass))
+      return Byte.class.isAssignableFrom(parameterClass);
+    return false;
+  }
 
-	@SuppressWarnings({ ""rawtypes"", ""unchecked"" })
-	protected void initDocument(Class<?> iClass, Object iInstance, ODocument iDocument, ODatabaseObject db)
-			throws IllegalArgumentException, IllegalAccessException {
-		for (Class<?> currentClass = iClass; currentClass != Object.class;) {
-			for (Field f : currentClass.getDeclaredFields()) {
-				if (f.getName().equals(""this$0""))
-					continue;
-				if (!f.isAccessible()) {
-					f.setAccessible(true);
-				}
-				Object o = f.get(iInstance);
-				if (o != null) {
-					if (OObjectEntitySerializer.isSerializedType(f)) {
-						if (o instanceof List<?>) {
-							List<?> list = new ArrayList();
-							iDocument.field(f.getName(), list);
-							o = new OObjectCustomSerializerList(OObjectEntitySerializer.getSerializedType(f), iDocument, list, (List<?>) o);
-							f.set(iInstance, o);
-						} else if (o instanceof Set<?>) {
-							Set<?> set = new HashSet();
-							iDocument.field(f.getName(), set);
-							o = new OObjectCustomSerializerSet(OObjectEntitySerializer.getSerializedType(f), iDocument, set, (Set<?>) o);
-							f.set(iInstance, o);
-						} else if (o instanceof Map<?, ?>) {
-							Map<?, ?> map = new HashMap();
-							iDocument.field(f.getName(), map);
-							o = new OObjectCustomSerializerMap(OObjectEntitySerializer.getSerializedType(f), iDocument, map, (Map<?, ?>) o);
-							f.set(iInstance, o);
-						} else {
-							o = OObjectEntitySerializer.serializeFieldValue(o.getClass(), o);
-							iDocument.field(f.getName(), o);
-						}
-					} else {
-						iDocument.field(f.getName(), OObjectEntitySerializer.typeToStream(o, OType.getTypeByClass(f.getType()), db, iDocument));
-					}
-				}
-			}
-			currentClass = currentClass.getSuperclass();
-		}
-	}
+  @SuppressWarnings({ ""rawtypes"", ""unchecked"" })
+  protected void initDocument(Class<?> iClass, Object iInstance, ODocument iDocument, ODatabaseObject db)
+      throws IllegalArgumentException, IllegalAccessException {
+    for (Class<?> currentClass = iClass; currentClass != Object.class;) {
+      for (Field f : currentClass.getDeclaredFields()) {
+        if (f.getName().equals(""this$0""))
+          continue;
+        if (!f.isAccessible()) {
+          f.setAccessible(true);
+        }
+        Object o = f.get(iInstance);
+        if (o != null) {
+          if (OObjectEntitySerializer.isSerializedType(f)) {
+            if (o instanceof List<?>) {
+              List<?> list = new ArrayList();
+              iDocument.field(f.getName(), list);
+              o = new OObjectCustomSerializerList(OObjectEntitySerializer.getSerializedType(f), iDocument, list, (List<?>) o);
+              f.set(iInstance, o);
+            } else if (o instanceof Set<?>) {
+              Set<?> set = new HashSet();
+              iDocument.field(f.getName(), set);
+              o = new OObjectCustomSerializerSet(OObjectEntitySerializer.getSerializedType(f), iDocument, set, (Set<?>) o);
+              f.set(iInstance, o);
+            } else if (o instanceof Map<?, ?>) {
+              Map<?, ?> map = new HashMap();
+              iDocument.field(f.getName(), map);
+              o = new OObjectCustomSerializerMap(OObjectEntitySerializer.getSerializedType(f), iDocument, map, (Map<?, ?>) o);
+              f.set(iInstance, o);
+            } else {
+              o = OObjectEntitySerializer.serializeFieldValue(o.getClass(), o);
+              iDocument.field(f.getName(), o);
+            }
+          } else {
+            iDocument.field(f.getName(), OObjectEntitySerializer.typeToStream(o, OType.getTypeByClass(f.getType()), db, iDocument));
+          }
+        }
+      }
+      currentClass = currentClass.getSuperclass();
+    }
+  }
 
-	protected <T> T createInstanceNoParameters(Class<T> iProxiedClass, Class<?> iOriginalClass) throws SecurityException,
-			NoSuchMethodException, IllegalArgumentException, InstantiationException, IllegalAccessException, InvocationTargetException {
-		T instanceToReturn = null;
-		final Class<?> enclosingClass = iOriginalClass.getEnclosingClass();
+  protected <T> T createInstanceNoParameters(Class<T> iProxiedClass, Class<?> iOriginalClass) throws SecurityException,
+      NoSuchMethodException, IllegalArgumentException, InstantiationException, IllegalAccessException, InvocationTargetException {
+    T instanceToReturn = null;
+    final Class<?> enclosingClass = iOriginalClass.getEnclosingClass();
 
-		if (enclosingClass != null) {
-			Object instanceOfEnclosingClass = createInstanceNoParameters(enclosingClass, enclosingClass);
+    if (enclosingClass != null) {
+      Object instanceOfEnclosingClass = createInstanceNoParameters(enclosingClass, enclosingClass);
 
-			Constructor<T> ctor = iProxiedClass.getConstructor(enclosingClass);
+      Constructor<T> ctor = iProxiedClass.getConstructor(enclosingClass);
 
-			if (ctor != null) {
-				instanceToReturn = ctor.newInstance(instanceOfEnclosingClass);
-			}
-		} else {
-			instanceToReturn = iProxiedClass.newInstance();
-		}
+      if (ctor != null) {
+        instanceToReturn = ctor.newInstance(instanceOfEnclosingClass);
+      }
+    } else {
+      try {
+        instanceToReturn = iProxiedClass.newInstance();
+      } catch (InstantiationException e) {
+        OLogManager.instance().error(this, ""Cannot create an instance of the enclosing class '%s'"", iOriginalClass);
+        throw e;
+      }
+    }
 
-		return instanceToReturn;
+    return instanceToReturn;
 
-	}
+  }
 
-	protected <T> T createInstanceNoParameters(Class<T> iProxiedClass, Object iEnclosingInstance) throws SecurityException,
-			NoSuchMethodException, IllegalArgumentException, InstantiationException, IllegalAccessException, InvocationTargetException {
-		T instanceToReturn = null;
-		final Class<?> enclosingClass = iEnclosingInstance.getClass();
+  protected <T> T createInstanceNoParameters(Class<T> iProxiedClass, Object iEnclosingInstance) throws SecurityException,
+      NoSuchMethodException, IllegalArgumentException, InstantiationException, IllegalAccessException, InvocationTargetException {
+    T instanceToReturn = null;
+    final Class<?> enclosingClass = iEnclosingInstance.getClass();
 
-		if (enclosingClass != null) {
+    if (enclosingClass != null) {
 
-			Constructor<T> ctor = iProxiedClass.getConstructor(enclosingClass);
+      Constructor<T> ctor = iProxiedClass.getConstructor(enclosingClass);
 
-			if (ctor != null) {
-				instanceToReturn = ctor.newInstance(iEnclosingInstance);
-			}
-		} else {
-			instanceToReturn = iProxiedClass.newInstance();
-		}
+      if (ctor != null) {
+        instanceToReturn = ctor.newInstance(iEnclosingInstance);
+      }
+    } else {
+      instanceToReturn = iProxiedClass.newInstance();
+    }
 
-		return instanceToReturn;
+    return instanceToReturn;
 
-	}
+  }
 }
diff --git a/tests/src/test/java/com/orientechnologies/orient/test/database/auto/DictionaryTest.java b/tests/src/test/java/com/orientechnologies/orient/test/database/auto/DictionaryTest.java
index 441c66d4c9..e99182ebd6 100644
--- a/tests/src/test/java/com/orientechnologies/orient/test/database/auto/DictionaryTest.java
+++ b/tests/src/test/java/com/orientechnologies/orient/test/database/auto/DictionaryTest.java
@@ -26,5 +26,4 @@ import com.orientechnologies.orient.core.record.ORecord;
 import com.orientechnologies.orient.core.record.impl.ORecordFlat;
 import com.orientechnologies.orient.object.db.OObjectDatabaseTx;
-import com.orientechnologies.orient.object.enhancement.ExactEntity;
 
 @Test(groups = ""dictionary"")
@@ -32,4 +31,7 @@ public class DictionaryTest {
   private String url;
 
+  public DictionaryTest() {
+  }
+
   @Parameters(value = ""url"")
   public DictionaryTest(String iURL) {
@@ -130,12 +132,27 @@ public class DictionaryTest {
   }
 
+  public class ObjectDictionaryTest {
+    private String name;
+
+    public ObjectDictionaryTest() {
+    }
+
+    public String getName() {
+      return name;
+    }
+
+    public void setName(String name) {
+      this.name = name;
+    }
+  }
+
   @Test(dependsOnMethods = ""testDictionaryMassiveCreate"")
   public void testDictionaryWithPOJOs() throws IOException {
     OObjectDatabaseTx database = new OObjectDatabaseTx(url);
     database.open(""admin"", ""admin"");
-    database.getEntityManager().registerEntityClass(ExactEntity.class);
+    database.getEntityManager().registerEntityClass(ObjectDictionaryTest.class);
 
     Assert.assertNull(database.getDictionary().get(""testKey""));
-    database.getDictionary().put(""testKey"", new ExactEntity());
+    database.getDictionary().put(""testKey"", new ObjectDictionaryTest());
     Assert.assertNotNull(database.getDictionary().get(""testKey""));
 
",Fixed issue with inner class and Object Database- interface--
1439,Java,d9ed3ad870a70bbda3183148223ee519e45bde43,,C,orientechnologies,orientdb,"[21, 463, 71, 111, 23, 6, 15, 4, 3990, 2453, 397, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/core/src/main/java/com/orientechnologies/orient/core/index/OClassIndexManager.java b/core/src/main/java/com/orientechnologies/orient/core/index/OClassIndexManager.java
index e860fcefb6..2699f83591 100644
--- a/core/src/main/java/com/orientechnologies/orient/core/index/OClassIndexManager.java
+++ b/core/src/main/java/com/orientechnologies/orient/core/index/OClassIndexManager.java
@@ -30,4 +30,5 @@ import java.util.SortedSet;
 import java.util.TreeSet;
 
+import com.orientechnologies.common.collection.OCompositeKey;
 import com.orientechnologies.orient.core.db.record.OIdentifiable;
 import com.orientechnologies.orient.core.db.record.OMultiValueChangeEvent;
@@ -183,10 +184,5 @@ public class OClassIndexManager extends ODocumentHookAbstract {
       for (final OIndex<?> index : indexes) {
         final Object key = index.getDefinition().getDocumentValueToIndex(iRecord);
-        if (key instanceof Collection) {
-          for (final Object keyItem : (Collection<?>) key)
-            if (keyItem != null)
-              index.remove(keyItem, iRecord);
-        } else if (key != null)
-          index.remove(key, iRecord);
+        deleteIndexKey(index, iRecord, key);
       }
     }
@@ -205,7 +201,10 @@ public class OClassIndexManager extends ODocumentHookAbstract {
   }
 
-  private void processCompositeIndexUpdate(final OIndex<?> index, final Set<String> dirtyFields, final ODocument iRecord) {
-    final OIndexDefinition indexDefinition = index.getDefinition();
+  private static void processCompositeIndexUpdate(final OIndex<?> index, final Set<String> dirtyFields, final ODocument iRecord) {
+    final OCompositeIndexDefinition indexDefinition = (OCompositeIndexDefinition) index.getDefinition();
+
     final List<String> indexFields = indexDefinition.getFields();
+    final String multiValueField = indexDefinition.getMultiValueField();
+
     for (final String indexField : indexFields) {
       if (dirtyFields.contains(indexField)) {
@@ -213,20 +212,60 @@ public class OClassIndexManager extends ODocumentHookAbstract {
 
         for (final String field : indexFields) {
-          if (dirtyFields.contains(field)) {
-            origValues.add(iRecord.getOriginalValue(field));
-          } else {
-            origValues.add(iRecord.<Object> field(field));
-          }
+          if (!field.equals(multiValueField))
+            if (dirtyFields.contains(field)) {
+              origValues.add(iRecord.getOriginalValue(field));
+            } else {
+              origValues.add(iRecord.<Object> field(field));
+            }
         }
 
-        final Object origValue = indexDefinition.createValue(origValues);
-        final Object newValue = indexDefinition.getDocumentValueToIndex(iRecord);
+        if (multiValueField == null) {
+          final Object origValue = indexDefinition.createValue(origValues);
+          final Object newValue = indexDefinition.getDocumentValueToIndex(iRecord);
 
-        if (origValue != null) {
-          index.remove(origValue, iRecord);
-        }
+          if (origValue != null)
+            index.remove(origValue, iRecord);
 
-        if (newValue != null) {
-          index.put(newValue, iRecord.placeholder());
+          if (newValue != null)
+            index.put(newValue, iRecord.placeholder());
+        } else {
+          final OMultiValueChangeTimeLine<?, ?> multiValueChangeTimeLine = iRecord.getCollectionTimeLine(multiValueField);
+          if (multiValueChangeTimeLine == null) {
+            if (dirtyFields.contains(multiValueField))
+              origValues.add(indexDefinition.getMultiValueDefinitionIndex(), iRecord.getOriginalValue(multiValueField));
+            else
+              origValues.add(indexDefinition.getMultiValueDefinitionIndex(), iRecord.field(multiValueField));
+
+            final Object origValue = indexDefinition.createValue(origValues);
+            final Object newValue = indexDefinition.getDocumentValueToIndex(iRecord);
+
+            processIndexUpdateFieldAssignment(index, iRecord, origValue, newValue);
+          } else {
+            if (dirtyFields.size() == 1) {
+              final Map<OCompositeKey, Integer> keysToAdd = new HashMap<OCompositeKey, Integer>();
+              final Map<OCompositeKey, Integer> keysToRemove = new HashMap<OCompositeKey, Integer>();
+
+              for (OMultiValueChangeEvent<?, ?> changeEvent : multiValueChangeTimeLine.getMultiValueChangeEvents()) {
+                indexDefinition.processChangeEvent(changeEvent, keysToAdd, keysToRemove, origValues.toArray());
+              }
+
+              for (final Object keyToRemove : keysToRemove.keySet())
+                index.remove(keyToRemove, iRecord);
+
+              for (final Object keyToAdd : keysToAdd.keySet())
+                index.put(keyToAdd, iRecord.placeholder());
+            } else {
+              final OTrackedMultiValue fieldValue = iRecord.field(multiValueField);
+              final Object restoredMultiValue = fieldValue
+                  .returnOriginalState(multiValueChangeTimeLine.getMultiValueChangeEvents());
+
+              origValues.add(indexDefinition.getMultiValueDefinitionIndex(), restoredMultiValue);
+
+              final Object origValue = indexDefinition.createValue(origValues);
+              final Object newValue = indexDefinition.getDocumentValueToIndex(iRecord);
+
+              processIndexUpdateFieldAssignment(index, iRecord, origValue, newValue);
+            }
+          }
         }
         return;
@@ -235,5 +274,5 @@ public class OClassIndexManager extends ODocumentHookAbstract {
   }
 
-  private void processSingleIndexUpdate(final OIndex<?> index, final Set<String> dirtyFields, final ODocument iRecord) {
+  private static void processSingleIndexUpdate(final OIndex<?> index, final Set<String> dirtyFields, final ODocument iRecord) {
     final OIndexDefinition indexDefinition = index.getDefinition();
     final List<String> indexFields = indexDefinition.getFields();
@@ -266,46 +305,45 @@ public class OClassIndexManager extends ODocumentHookAbstract {
       final Object newValue = indexDefinition.getDocumentValueToIndex(iRecord);
 
-      if ((origValue instanceof Collection) && (newValue instanceof Collection)) {
-        final Set<Object> valuesToRemove = new HashSet<Object>((Collection<?>) origValue);
-        final Set<Object> valuesToAdd = new HashSet<Object>((Collection<?>) newValue);
+      processIndexUpdateFieldAssignment(index, iRecord, origValue, newValue);
+    }
+  }
 
-        valuesToRemove.removeAll((Collection<?>) newValue);
-        valuesToAdd.removeAll((Collection<?>) origValue);
+  private static void processIndexUpdateFieldAssignment(OIndex<?> index, ODocument iRecord, final Object origValue,
+      final Object newValue) {
+    if ((origValue instanceof Collection) && (newValue instanceof Collection)) {
+      final Set<Object> valuesToRemove = new HashSet<Object>((Collection<?>) origValue);
+      final Set<Object> valuesToAdd = new HashSet<Object>((Collection<?>) newValue);
 
-        for (final Object valueToRemove : valuesToRemove) {
-          if (valueToRemove != null) {
-            index.remove(valueToRemove, iRecord);
-          }
-        }
+      valuesToRemove.removeAll((Collection<?>) newValue);
+      valuesToAdd.removeAll((Collection<?>) origValue);
 
-        for (final Object valueToAdd : valuesToAdd) {
-          if (valueToAdd != null) {
-            index.put(valueToAdd, iRecord);
-          }
+      for (final Object valueToRemove : valuesToRemove) {
+        if (valueToRemove != null) {
+          index.remove(valueToRemove, iRecord);
         }
-      } else {
-        if (origValue instanceof Collection) {
-          for (final Object origValueItem : (Collection<?>) origValue) {
-            if (origValueItem != null) {
-              index.remove(origValueItem, iRecord);
-            }
-          }
-        } else if (origValue != null) {
-          index.remove(origValue, iRecord);
+      }
+
+      for (final Object valueToAdd : valuesToAdd) {
+        if (valueToAdd != null) {
+          index.put(valueToAdd, iRecord);
         }
+      }
+    } else {
+      deleteIndexKey(index, iRecord, origValue);
 
-        if (newValue instanceof Collection) {
-          for (final Object newValueItem : (Collection<?>) newValue) {
-            index.put(newValueItem, iRecord.placeholder());
-          }
-        } else if (newValue != null) {
-          index.put(newValue, iRecord.placeholder());
+      if (newValue instanceof Collection) {
+        for (final Object newValueItem : (Collection<?>) newValue) {
+          index.put(newValueItem, iRecord.placeholder());
         }
+      } else if (newValue != null) {
+        index.put(newValue, iRecord.placeholder());
       }
     }
   }
 
-  private boolean processCompositeIndexDelete(final OIndex<?> index, final Set<String> dirtyFields, final ODocument iRecord) {
-    final OIndexDefinition indexDefinition = index.getDefinition();
+  private static boolean processCompositeIndexDelete(final OIndex<?> index, final Set<String> dirtyFields, final ODocument iRecord) {
+    final OCompositeIndexDefinition indexDefinition = (OCompositeIndexDefinition) index.getDefinition();
+
+    final String multiValueField = indexDefinition.getMultiValueField();
 
     final List<String> indexFields = indexDefinition.getFields();
@@ -316,13 +354,25 @@ public class OClassIndexManager extends ODocumentHookAbstract {
 
         for (final String field : indexFields) {
-          if (dirtyFields.contains(field))
-            origValues.add(iRecord.getOriginalValue(field));
+          if (!field.equals(multiValueField))
+            if (dirtyFields.contains(field))
+              origValues.add(iRecord.getOriginalValue(field));
+            else
+              origValues.add(iRecord.<Object> field(field));
+        }
+
+        if (multiValueField != null) {
+          final OMultiValueChangeTimeLine<?, ?> multiValueChangeTimeLine = iRecord.getCollectionTimeLine(multiValueField);
+          if (multiValueChangeTimeLine != null) {
+            final OTrackedMultiValue fieldValue = iRecord.field(multiValueField);
+            final Object restoredMultiValue = fieldValue.returnOriginalState(multiValueChangeTimeLine.getMultiValueChangeEvents());
+            origValues.add(indexDefinition.getMultiValueDefinitionIndex(), restoredMultiValue);
+          } else if (dirtyFields.contains(multiValueField))
+            origValues.add(indexDefinition.getMultiValueDefinitionIndex(), iRecord.getOriginalValue(multiValueField));
           else
-            origValues.add(iRecord.<Object> field(field));
+            origValues.add(indexDefinition.getMultiValueDefinitionIndex(), iRecord.field(multiValueField));
         }
 
         final Object origValue = indexDefinition.createValue(origValues);
-        if (origValue != null)
-          index.remove(origValue, iRecord);
+        deleteIndexKey(index, iRecord, origValue);
 
         return true;
@@ -332,6 +382,17 @@ public class OClassIndexManager extends ODocumentHookAbstract {
   }
 
+  private static void deleteIndexKey(OIndex<?> index, ODocument iRecord, Object origValue) {
+    if (origValue instanceof Collection) {
+      for (final Object valueItem : (Collection<?>) origValue) {
+        if (valueItem != null)
+          index.remove(valueItem, iRecord);
+      }
+    } else if (origValue != null) {
+      index.remove(origValue, iRecord);
+    }
+  }
+
   @SuppressWarnings({ ""rawtypes"", ""unchecked"" })
-  private boolean processSingleIndexDelete(final OIndex<?> index, final Set<String> dirtyFields, final ODocument iRecord) {
+  private static boolean processSingleIndexDelete(final OIndex<?> index, final Set<String> dirtyFields, final ODocument iRecord) {
     final OIndexDefinition indexDefinition = index.getDefinition();
 
@@ -353,13 +414,5 @@ public class OClassIndexManager extends ODocumentHookAbstract {
         origValue = indexDefinition.createValue(iRecord.getOriginalValue(indexField));
 
-      if (origValue instanceof Collection) {
-        for (final Object valueItem : (Collection<?>) origValue) {
-          if (valueItem != null) {
-            index.remove(valueItem, iRecord);
-          }
-        }
-      } else if (origValue != null) {
-        index.remove(origValue, iRecord);
-      }
+      deleteIndexKey(index, iRecord, origValue);
       return true;
     }
@@ -367,5 +420,5 @@ public class OClassIndexManager extends ODocumentHookAbstract {
   }
 
-  private void checkIndexedPropertiesOnCreation(final ODocument iRecord) {
+  private static void checkIndexedPropertiesOnCreation(final ODocument iRecord) {
     final OClass cls = iRecord.getSchemaClass();
     if (cls == null)
@@ -387,5 +440,5 @@ public class OClassIndexManager extends ODocumentHookAbstract {
   }
 
-  private void acquireModificationLock(final ODocument iRecord) {
+  private static void acquireModificationLock(final ODocument iRecord) {
     final OClass cls = iRecord.getSchemaClass();
     if (cls == null)
@@ -407,5 +460,5 @@ public class OClassIndexManager extends ODocumentHookAbstract {
   }
 
-  private void releaseModificationLock(final ODocument iRecord) {
+  private static void releaseModificationLock(final ODocument iRecord) {
     final OClass cls = iRecord.getSchemaClass();
     if (cls == null)
@@ -418,5 +471,5 @@ public class OClassIndexManager extends ODocumentHookAbstract {
   }
 
-  private void checkIndexedPropertiesOnUpdate(final ODocument iRecord) {
+  private static void checkIndexedPropertiesOnUpdate(final ODocument iRecord) {
     final OClass cls = iRecord.getSchemaClass();
     if (cls == null)
@@ -449,5 +502,5 @@ public class OClassIndexManager extends ODocumentHookAbstract {
   }
 
-  private ODocument checkForLoading(final ODocument iRecord) {
+  private static ODocument checkForLoading(final ODocument iRecord) {
     if (iRecord.getInternalStatus() == ORecordElement.STATUS.NOT_LOADED) {
       try {
diff --git a/core/src/main/java/com/orientechnologies/orient/core/index/OCompositeIndexDefinition.java b/core/src/main/java/com/orientechnologies/orient/core/index/OCompositeIndexDefinition.java
index b70418b680..8bb1d48c22 100644
--- a/core/src/main/java/com/orientechnologies/orient/core/index/OCompositeIndexDefinition.java
+++ b/core/src/main/java/com/orientechnologies/orient/core/index/OCompositeIndexDefinition.java
@@ -19,10 +19,14 @@ import java.lang.reflect.InvocationTargetException;
 import java.util.ArrayList;
 import java.util.Arrays;
+import java.util.Collection;
 import java.util.Collections;
 import java.util.Iterator;
 import java.util.LinkedList;
 import java.util.List;
+import java.util.Map;
+import java.util.Set;
 
 import com.orientechnologies.common.collection.OCompositeKey;
+import com.orientechnologies.orient.core.db.record.OMultiValueChangeEvent;
 import com.orientechnologies.orient.core.db.record.ORecordElement;
 import com.orientechnologies.orient.core.metadata.schema.OType;
@@ -37,7 +41,8 @@ public class OCompositeIndexDefinition extends ODocumentWrapperNoClass implement
   private final List<OIndexDefinition> indexDefinitions;
   private String                       className;
+  private int                          multiValueDefinitionIndex = -1;
 
   public OCompositeIndexDefinition() {
-    indexDefinitions = new LinkedList<OIndexDefinition>();
+    indexDefinitions = new ArrayList<OIndexDefinition>(5);
   }
 
@@ -51,5 +56,5 @@ public class OCompositeIndexDefinition extends ODocumentWrapperNoClass implement
     super(new ODocument());
 
-    indexDefinitions = new LinkedList<OIndexDefinition>();
+    indexDefinitions = new ArrayList<OIndexDefinition>(5);
     className = iClassName;
   }
@@ -65,6 +70,16 @@ public class OCompositeIndexDefinition extends ODocumentWrapperNoClass implement
   public OCompositeIndexDefinition(final String iClassName, final List<? extends OIndexDefinition> iIndexes) {
     super(new ODocument());
-    indexDefinitions = new LinkedList<OIndexDefinition>();
-    indexDefinitions.addAll(iIndexes);
+
+    indexDefinitions = new ArrayList<OIndexDefinition>(5);
+    for (OIndexDefinition indexDefinition : iIndexes) {
+      indexDefinitions.add(indexDefinition);
+
+      if (indexDefinition instanceof OIndexDefinitionMultiValue)
+        if (multiValueDefinitionIndex == -1)
+          multiValueDefinitionIndex = indexDefinitions.size() - 1;
+        else
+          throw new OIndexException(""Composite key can not contain more than one collection item"");
+    }
+
     className = iClassName;
   }
@@ -85,4 +100,11 @@ public class OCompositeIndexDefinition extends ODocumentWrapperNoClass implement
   public void addIndex(final OIndexDefinition indexDefinition) {
     indexDefinitions.add(indexDefinition);
+    if (indexDefinition instanceof OIndexDefinitionMultiValue) {
+      if (multiValueDefinitionIndex == -1)
+        multiValueDefinitionIndex = indexDefinitions.size() - 1;
+      else
+        throw new OIndexException(""Composite key can not contain more than one collection item"");
+    }
+
   }
 
@@ -98,9 +120,24 @@ public class OCompositeIndexDefinition extends ODocumentWrapperNoClass implement
   }
 
+  /**
+   * {@inheritDoc}
+   */
+  public List<String> getFieldsToIndex() {
+    final List<String> fields = new LinkedList<String>();
+    for (final OIndexDefinition indexDefinition : indexDefinitions) {
+      fields.addAll(indexDefinition.getFieldsToIndex());
+    }
+    return Collections.unmodifiableList(fields);
+  }
+
   /**
    * {@inheritDoc}
    */
   public Object getDocumentValueToIndex(final ODocument iDocument) {
-    final OCompositeKey compositeKey = new OCompositeKey();
+    final List<OCompositeKey> compositeKeys = new ArrayList<OCompositeKey>(10);
+    final OCompositeKey firstKey = new OCompositeKey();
+    boolean containsCollection = false;
+
+    compositeKeys.add(firstKey);
 
     for (final OIndexDefinition indexDefinition : indexDefinitions) {
@@ -110,8 +147,22 @@ public class OCompositeIndexDefinition extends ODocumentWrapperNoClass implement
         return null;
 
-      compositeKey.addKey(result);
+      containsCollection = addKey(firstKey, compositeKeys, containsCollection, result);
     }
 
-    return compositeKey;
+    if (!containsCollection)
+      return firstKey;
+
+    return compositeKeys;
+  }
+
+  public int getMultiValueDefinitionIndex() {
+    return multiValueDefinitionIndex;
+  }
+
+  public String getMultiValueField() {
+    if (multiValueDefinitionIndex >= 0)
+      return indexDefinitions.get(multiValueDefinitionIndex).getFields().get(0);
+
+    return null;
   }
 
@@ -119,7 +170,12 @@ public class OCompositeIndexDefinition extends ODocumentWrapperNoClass implement
    * {@inheritDoc}
    */
-  public Comparable<?> createValue(final List<?> params) {
+  public Object createValue(final List<?> params) {
     int currentParamIndex = 0;
-    final OCompositeKey compositeKey = new OCompositeKey();
+    final OCompositeKey firstKey = new OCompositeKey();
+
+    final List<OCompositeKey> compositeKeys = new ArrayList<OCompositeKey>(10);
+    compositeKeys.add(firstKey);
+
+    boolean containsCollection = false;
 
     for (final OIndexDefinition indexDefinition : indexDefinitions) {
@@ -138,4 +194,47 @@ public class OCompositeIndexDefinition extends ODocumentWrapperNoClass implement
       final Object keyValue = indexDefinition.createValue(indexParams);
 
+      if (keyValue == null)
+        return null;
+
+      containsCollection = addKey(firstKey, compositeKeys, containsCollection, keyValue);
+    }
+
+    if (!containsCollection)
+      return firstKey;
+
+    return compositeKeys;
+  }
+
+  public OIndexDefinitionMultiValue getMultiValueDefinition() {
+    if (multiValueDefinitionIndex > -1)
+      return (OIndexDefinitionMultiValue) indexDefinitions.get(multiValueDefinitionIndex);
+
+    return null;
+  }
+
+  public OCompositeKey createSingleValue(final List<?> params) {
+    final OCompositeKey compositeKey = new OCompositeKey();
+    int currentParamIndex = 0;
+
+    for (final OIndexDefinition indexDefinition : indexDefinitions) {
+      if (currentParamIndex + 1 > params.size())
+        break;
+
+      final int endIndex;
+      if (currentParamIndex + indexDefinition.getParamCount() > params.size())
+        endIndex = params.size();
+      else
+        endIndex = currentParamIndex + indexDefinition.getParamCount();
+
+      final List<?> indexParams = params.subList(currentParamIndex, endIndex);
+      currentParamIndex += indexDefinition.getParamCount();
+
+      final Object keyValue;
+
+      if (indexDefinition instanceof OIndexDefinitionMultiValue)
+        keyValue = ((OIndexDefinitionMultiValue) indexDefinition).createSingleValue(indexParams.toArray());
+      else
+        keyValue = indexDefinition.createValue(indexParams);
+
       if (keyValue == null)
         return null;
@@ -147,11 +246,56 @@ public class OCompositeIndexDefinition extends ODocumentWrapperNoClass implement
   }
 
+  private static boolean addKey(OCompositeKey firstKey, List<OCompositeKey> compositeKeys, boolean containsCollection,
+      Object keyValue) {
+    if (keyValue instanceof Collection) {
+      final Collection<?> collectionKey = (Collection<?>) keyValue;
+      if (!containsCollection)
+        for (int i = 1; i < collectionKey.size(); i++) {
+          final OCompositeKey compositeKey = new OCompositeKey(firstKey.getKeys());
+          compositeKeys.add(compositeKey);
+        }
+      else
+        throw new OIndexException(""Composite key can not contain more than one collection item"");
+
+      int compositeIndex = 0;
+      for (final Object keyItem : collectionKey) {
+        final OCompositeKey compositeKey = compositeKeys.get(compositeIndex);
+        compositeKey.addKey(keyItem);
+
+        compositeIndex++;
+      }
+
+      containsCollection = true;
+    } else if (containsCollection)
+      for (final OCompositeKey compositeKey : compositeKeys)
+        compositeKey.addKey(keyValue);
+    else
+      firstKey.addKey(keyValue);
+
+    return containsCollection;
+  }
+
   /**
    * {@inheritDoc}
    */
-  public Comparable<?> createValue(final Object... params) {
+  public Object createValue(final Object... params) {
     return createValue(Arrays.asList(params));
   }
 
+  public void processChangeEvent(OMultiValueChangeEvent<?, ?> changeEvent, Map<OCompositeKey, Integer> keysToAdd,
+      Map<OCompositeKey, Integer> keysToRemove, Object... params) {
+
+    final OIndexDefinitionMultiValue indexDefinitionMultiValue = (OIndexDefinitionMultiValue) indexDefinitions
+        .get(multiValueDefinitionIndex);
+
+    final CompositeWrapperMap compositeWrapperKeysToAdd = new CompositeWrapperMap(keysToAdd, indexDefinitions, params,
+        multiValueDefinitionIndex);
+
+    final CompositeWrapperMap compositeWrapperKeysToRemove = new CompositeWrapperMap(keysToRemove, indexDefinitions, params,
+        multiValueDefinitionIndex);
+
+    indexDefinitionMultiValue.processChangeEvent(changeEvent, compositeWrapperKeysToAdd, compositeWrapperKeysToRemove);
+  }
+
   /**
    * {@inheritDoc}
@@ -236,5 +380,5 @@ public class OCompositeIndexDefinition extends ODocumentWrapperNoClass implement
     ddl.append(indexName).append("" on "").append(className).append("" ( "");
 
-    final Iterator<String> fieldIterator = getFields().iterator();
+    final Iterator<String> fieldIterator = getFieldsToIndex().iterator();
     if (fieldIterator.hasNext()) {
       ddl.append(fieldIterator.next());
@@ -245,12 +389,14 @@ public class OCompositeIndexDefinition extends ODocumentWrapperNoClass implement
     ddl.append("" ) "").append(indexType).append(' ');
 
-    boolean first = true;
-    for (OType oType : getTypes()) {
-      if (first)
-        first = false;
-      else
-        ddl.append("", "");
+    if (multiValueDefinitionIndex == -1) {
+      boolean first = true;
+      for (OType oType : getTypes()) {
+        if (first)
+          first = false;
+        else
+          ddl.append("", "");
 
-      ddl.append(oType.name());
+        ddl.append(oType.name());
+      }
     }
 
@@ -278,4 +424,7 @@ public class OCompositeIndexDefinition extends ODocumentWrapperNoClass implement
 
         indexDefinitions.add(indexDefinition);
+
+        if (indexDefinition instanceof OIndexDefinitionMultiValue)
+          multiValueDefinitionIndex = indexDefinitions.size() - 1;
       }
 
@@ -292,3 +441,84 @@ public class OCompositeIndexDefinition extends ODocumentWrapperNoClass implement
     }
   }
+
+  private static final class CompositeWrapperMap implements Map<Object, Integer> {
+    private final Map<OCompositeKey, Integer> underlying;
+    private final Object[]                    params;
+    private final List<OIndexDefinition>      indexDefinitions;
+    private final int                         multiValueIndex;
+
+    private CompositeWrapperMap(Map<OCompositeKey, Integer> underlying, List<OIndexDefinition> indexDefinitions, Object[] params,
+        int multiValueIndex) {
+      this.underlying = underlying;
+      this.params = params;
+      this.multiValueIndex = multiValueIndex;
+      this.indexDefinitions = indexDefinitions;
+    }
+
+    public int size() {
+      return underlying.size();
+    }
+
+    public boolean isEmpty() {
+      return underlying.isEmpty();
+    }
+
+    public boolean containsKey(Object key) {
+      final OCompositeKey compositeKey = convertToCompositeKey(key);
+
+      return underlying.containsKey(compositeKey);
+    }
+
+    public boolean containsValue(Object value) {
+      return underlying.containsValue(value);
+    }
+
+    public Integer get(Object key) {
+      return underlying.get(convertToCompositeKey(key));
+    }
+
+    public Integer put(Object key, Integer value) {
+      final OCompositeKey compositeKey = convertToCompositeKey(key);
+      return underlying.put(compositeKey, value);
+    }
+
+    public Integer remove(Object key) {
+      return underlying.remove(convertToCompositeKey(key));
+    }
+
+    public void putAll(Map<? extends Object, ? extends Integer> m) {
+      throw new UnsupportedOperationException(""Unsupported because of performance reasons"");
+    }
+
+    public void clear() {
+      underlying.clear();
+    }
+
+    public Set<Object> keySet() {
+      throw new UnsupportedOperationException(""Unsupported because of performance reasons"");
+    }
+
+    public Collection<Integer> values() {
+      return underlying.values();
+    }
+
+    public Set<Entry<Object, Integer>> entrySet() {
+      throw new UnsupportedOperationException();
+    }
+
+    private OCompositeKey convertToCompositeKey(Object key) {
+      final OCompositeKey compositeKey = new OCompositeKey();
+
+      int paramsIndex = 0;
+      for (int i = 0; i < indexDefinitions.size(); i++) {
+        final OIndexDefinition indexDefinition = indexDefinitions.get(i);
+        if (i != multiValueIndex) {
+          compositeKey.addKey(indexDefinition.createValue(params[paramsIndex]));
+          paramsIndex++;
+        } else
+          compositeKey.addKey(((OIndexDefinitionMultiValue) indexDefinition).createSingleValue(key));
+      }
+      return compositeKey;
+    }
+  }
 }
diff --git a/core/src/main/java/com/orientechnologies/orient/core/index/OIndexDefinition.java b/core/src/main/java/com/orientechnologies/orient/core/index/OIndexDefinition.java
index cfdfcbf1c0..79f183b550 100644
--- a/core/src/main/java/com/orientechnologies/orient/core/index/OIndexDefinition.java
+++ b/core/src/main/java/com/orientechnologies/orient/core/index/OIndexDefinition.java
@@ -31,85 +31,91 @@ import com.orientechnologies.orient.core.record.impl.ODocument;
  */
 public interface OIndexDefinition extends OIndexCallback {
-	/**
-	 * @return Names of fields which given index is used to calculate key value. Order of fields is important.
-	 */
-	public List<String> getFields();
+  /**
+   * @return Names of fields which given index is used to calculate key value. Order of fields is important.
+   */
+  public List<String> getFields();
 
-	/**
-	 * @return Name of the class which this index belongs to.
-	 */
-	public String getClassName();
+  /**
+   * @return Names of fields and their index modifiers (like ""by value"" for fields that hold <code>Map</code> values) which given
+   *         index is used to calculate key value. Order of fields is important.
+   */
+  public List<String> getFieldsToIndex();
 
-	/**
-	 * {@inheritDoc}
-	 */
-	public boolean equals(Object index);
+  /**
+   * @return Name of the class which this index belongs to.
+   */
+  public String getClassName();
 
-	/**
-	 * {@inheritDoc}
-	 */
-	public int hashCode();
+  /**
+   * {@inheritDoc}
+   */
+  public boolean equals(Object index);
 
-	/**
-	 * {@inheritDoc}
-	 */
-	public String toString();
+  /**
+   * {@inheritDoc}
+   */
+  public int hashCode();
 
-	/**
-	 * Calculates key value by passed in parameters.
-	 * 
-	 * If it is impossible to calculate key value by given parameters <code>null</code> will be returned.
-	 * 
-	 * @param params
-	 *          Parameters from which index key will be calculated.
-	 * 
-	 * @return Key value or null if calculation is impossible.
-	 */
-	public Object createValue(List<?> params);
+  /**
+   * {@inheritDoc}
+   */
+  public String toString();
 
-	/**
-	 * Calculates key value by passed in parameters.
-	 * 
-	 * If it is impossible to calculate key value by given parameters <code>null</code> will be returned.
-	 * 
-	 * 
-	 * @param params
-	 *          Parameters from which index key will be calculated.
-	 * 
-	 * @return Key value or null if calculation is impossible.
-	 */
-	public Object createValue(Object... params);
+  /**
+   * Calculates key value by passed in parameters.
+   * 
+   * If it is impossible to calculate key value by given parameters <code>null</code> will be returned.
+   * 
+   * @param params
+   *          Parameters from which index key will be calculated.
+   * 
+   * @return Key value or null if calculation is impossible.
+   */
+  public Object createValue(List<?> params);
 
-	/**
-	 * Returns amount of parameters that are used to calculate key value. It does not mean that all parameters should be supplied. It
-	 * only means that if you provide more parameters they will be ignored and will not participate in index key calculation.
-	 * 
-	 * @return Amount of that are used to calculate key value. Call result should be equals to {@code getTypes().length}.
-	 */
-	public int getParamCount();
+  /**
+   * Calculates key value by passed in parameters.
+   * 
+   * If it is impossible to calculate key value by given parameters <code>null</code> will be returned.
+   * 
+   * 
+   * @param params
+   *          Parameters from which index key will be calculated.
+   * 
+   * @return Key value or null if calculation is impossible.
+   */
+  public Object createValue(Object... params);
 
-	/**
-	 * Return types of values from which index key consist. In case of index that is built on single document property value single
-	 * array that contains property type will be returned. In case of composite indexes result will contain several key types.
-	 * 
-	 * @return Types of values from which index key consist.
-	 */
-	public OType[] getTypes();
+  /**
+   * Returns amount of parameters that are used to calculate key value. It does not mean that all parameters should be supplied. It
+   * only means that if you provide more parameters they will be ignored and will not participate in index key calculation.
+   * 
+   * @return Amount of that are used to calculate key value. Call result should be equals to {@code getTypes().length}.
+   */
+  public int getParamCount();
 
-	/**
-	 * Serializes internal index state to document.
-	 * 
-	 * @return Document that contains internal index state.
-	 */
-	public ODocument toStream();
+  /**
+   * Return types of values from which index key consist. In case of index that is built on single document property value single
+   * array that contains property type will be returned. In case of composite indexes result will contain several key types.
+   * 
+   * @return Types of values from which index key consist.
+   */
+  public OType[] getTypes();
 
-	/**
-	 * Deserialize internal index state from document.
-	 * 
-	 * @param document
-	 *          Serialized index presentation.
-	 */
-	public void fromStream(ODocument document);
+  /**
+   * Serializes internal index state to document.
+   * 
+   * @return Document that contains internal index state.
+   */
+  public ODocument toStream();
 
-	public String toCreateIndexDDL(String indexName, String indexType);
+  /**
+   * Deserialize internal index state from document.
+   * 
+   * @param document
+   *          Serialized index presentation.
+   */
+  public void fromStream(ODocument document);
+
+  public String toCreateIndexDDL(String indexName, String indexType);
 }
diff --git a/core/src/main/java/com/orientechnologies/orient/core/index/OIndexDefinitionFactory.java b/core/src/main/java/com/orientechnologies/orient/core/index/OIndexDefinitionFactory.java
index becbcbe6e2..854b9bb083 100644
--- a/core/src/main/java/com/orientechnologies/orient/core/index/OIndexDefinitionFactory.java
+++ b/core/src/main/java/com/orientechnologies/orient/core/index/OIndexDefinitionFactory.java
@@ -2,4 +2,5 @@ package com.orientechnologies.orient.core.index;
 
 import java.util.List;
+import java.util.regex.Pattern;
 
 import com.orientechnologies.orient.core.metadata.schema.OClass;
@@ -15,4 +16,6 @@ import com.orientechnologies.orient.core.metadata.schema.OType;
  */
 public class OIndexDefinitionFactory {
+  private static final Pattern FILED_NAME_PATTERN = Pattern.compile(""\\s+"");
+
   /**
    * Creates an instance of {@link OIndexDefinition} for automatic index.
@@ -44,5 +47,5 @@ public class OIndexDefinitionFactory {
    */
   public static String extractFieldName(final String fieldDefinition) {
-    String[] fieldNameParts = fieldDefinition.split(""\\s+"");
+    String[] fieldNameParts = FILED_NAME_PATTERN.split(fieldDefinition);
     if (fieldNameParts.length == 1)
       return fieldDefinition;
@@ -51,26 +54,17 @@ public class OIndexDefinitionFactory {
 
     throw new IllegalArgumentException(""Illegal field name format, should be '<property> [by key|value]' but was '""
-        + fieldDefinition + ""'"");
+        + fieldDefinition + '\'');
   }
 
   private static OIndexDefinition createMultipleFieldIndexDefinition(final OClass oClass, final List<String> fieldsToIndex,
       final List<OType> types) {
-    final OIndexDefinition indexDefinition;
     final String className = oClass.getName();
     final OCompositeIndexDefinition compositeIndex = new OCompositeIndexDefinition(className);
 
     for (int i = 0, fieldsToIndexSize = fieldsToIndex.size(); i < fieldsToIndexSize; i++) {
-      String fieldName = adjustFieldName(oClass, fieldsToIndex.get(i));
-      final OType propertyType = types.get(i);
-      if (propertyType.equals(OType.EMBEDDEDLIST) || propertyType.equals(OType.EMBEDDEDSET) || propertyType.equals(OType.LINKSET)
-          || propertyType.equals(OType.LINKLIST) || propertyType.equals(OType.EMBEDDEDMAP) || propertyType.equals(OType.LINKMAP))
-        throw new OIndexException(""Collections are not supported in composite indexes"");
-
-      final OPropertyIndexDefinition propertyIndex = new OPropertyIndexDefinition(className, fieldName, propertyType);
-      compositeIndex.addIndex(propertyIndex);
+      compositeIndex.addIndex(createSingleFieldIndexDefinition(oClass, fieldsToIndex.get(i), types.get(i)));
     }
 
-    indexDefinition = compositeIndex;
-    return indexDefinition;
+    return compositeIndex;
   }
 
@@ -136,5 +130,5 @@ public class OIndexDefinitionFactory {
 
   private static OPropertyMapIndexDefinition.INDEX_BY extractMapIndexSpecifier(final String fieldName) {
-    String[] fieldNameParts = fieldName.split(""\\s+"");
+    String[] fieldNameParts = FILED_NAME_PATTERN.split(fieldName);
     if (fieldNameParts.length == 1)
       return OPropertyMapIndexDefinition.INDEX_BY.KEY;
@@ -146,10 +140,10 @@ public class OIndexDefinitionFactory {
         } catch (IllegalArgumentException iae) {
           throw new IllegalArgumentException(""Illegal field name format, should be '<property> [by key|value]' but was '""
-              + fieldName + ""'"");
+              + fieldName + '\'');
         }
     }
 
     throw new IllegalArgumentException(""Illegal field name format, should be '<property> [by key|value]' but was '"" + fieldName
-        + ""'"");
+        + '\'');
   }
 
diff --git a/core/src/main/java/com/orientechnologies/orient/core/index/OIndexDefinitionMultiValue.java b/core/src/main/java/com/orientechnologies/orient/core/index/OIndexDefinitionMultiValue.java
index 6e93bc8181..b54c650516 100644
--- a/core/src/main/java/com/orientechnologies/orient/core/index/OIndexDefinitionMultiValue.java
+++ b/core/src/main/java/com/orientechnologies/orient/core/index/OIndexDefinitionMultiValue.java
@@ -20,29 +20,33 @@ import java.util.Map;
 import com.orientechnologies.orient.core.db.record.OMultiValueChangeEvent;
 
-	/**
-	 * Interface that indicates that index definition is based on collection of values but not on single value.
-	 *
-	 * @author <a href=""mailto:lomakin.andrey@gmail.com"">Andrey Lomakin</a>
-	 * @since 20.12.11
-	 */
-  public interface OIndexDefinitionMultiValue extends OIndexDefinition {
+/**
+ * Interface that indicates that index definition is based on collection of values but not on single value.
+ * 
+ * @author <a href=""mailto:lomakin.andrey@gmail.com"">Andrey Lomakin</a>
+ * @since 20.12.11
+ */
+public interface OIndexDefinitionMultiValue extends OIndexDefinition {
 
-	/**
-	 * Converts passed in value in the key of single index entry.
-	 *
-	 * @param param Value to convert.
-	 * @return Index key.
-	 */
-	public Object createSingleValue(final Object param);
+  /**
+   * Converts passed in value in the key of single index entry.
+   * 
+   * @param param
+   *          Value to convert.
+   * @return Index key.
+   */
+  public Object createSingleValue(final Object... param);
 
-	/**
-	 * Process event that contains operation on collection and extract values that should be added removed from index
-	 * to reflect collection changes in the given index.
-	 *
-	 * @param changeEvent   Event that describes operation that was performed on collection.
-	 * @param keysToAdd     Values that should be added to related index.
-	 * @param keysToRemove  Values that should be removed to related index.
-	 */
-	public void processChangeEvent(final OMultiValueChangeEvent<?,?> changeEvent, final Map<Object, Integer> keysToAdd,
-																	 final Map<Object, Integer> keysToRemove);
+  /**
+   * Process event that contains operation on collection and extract values that should be added removed from index to reflect
+   * collection changes in the given index.
+   * 
+   * @param changeEvent
+   *          Event that describes operation that was performed on collection.
+   * @param keysToAdd
+   *          Values that should be added to related index.
+   * @param keysToRemove
+   *          Values that should be removed to related index.
+   */
+  public void processChangeEvent(final OMultiValueChangeEvent<?, ?> changeEvent, final Map<Object, Integer> keysToAdd,
+      final Map<Object, Integer> keysToRemove);
 }
diff --git a/core/src/main/java/com/orientechnologies/orient/core/index/OPropertyIndexDefinition.java b/core/src/main/java/com/orientechnologies/orient/core/index/OPropertyIndexDefinition.java
index 2ceba63745..be35084b3b 100644
--- a/core/src/main/java/com/orientechnologies/orient/core/index/OPropertyIndexDefinition.java
+++ b/core/src/main/java/com/orientechnologies/orient/core/index/OPropertyIndexDefinition.java
@@ -56,4 +56,8 @@ public class OPropertyIndexDefinition extends ODocumentWrapperNoClass implements
   }
 
+  public List<String> getFieldsToIndex() {
+    return Collections.singletonList(field);
+  }
+
   public Object getDocumentValueToIndex(final ODocument iDocument) {
     if (OType.LINK.equals(keyType)) {
diff --git a/core/src/main/java/com/orientechnologies/orient/core/index/OPropertyListIndexDefinition.java b/core/src/main/java/com/orientechnologies/orient/core/index/OPropertyListIndexDefinition.java
index 83d4d5a955..23cdf4db71 100644
--- a/core/src/main/java/com/orientechnologies/orient/core/index/OPropertyListIndexDefinition.java
+++ b/core/src/main/java/com/orientechnologies/orient/core/index/OPropertyListIndexDefinition.java
@@ -34,67 +34,67 @@ import com.orientechnologies.orient.core.record.impl.ODocument;
 public class OPropertyListIndexDefinition extends OAbstractIndexDefinitionMultiValue implements OIndexDefinitionMultiValue {
 
-	public OPropertyListIndexDefinition(final String iClassName, final String iField, final OType iType) {
-		super(iClassName, iField, iType);
-	}
+  public OPropertyListIndexDefinition(final String iClassName, final String iField, final OType iType) {
+    super(iClassName, iField, iType);
+  }
 
-	public OPropertyListIndexDefinition() {
-	}
+  public OPropertyListIndexDefinition() {
+  }
 
-	@Override
-	public Object getDocumentValueToIndex(ODocument iDocument) {
-		return createValue(iDocument.field(field));
-	}
+  @Override
+  public Object getDocumentValueToIndex(ODocument iDocument) {
+    return createValue(iDocument.field(field));
+  }
 
-	@Override
-	public Object createValue(final List<?> params) {
-		if (!(params.get(0) instanceof Collection))
-			return null;
+  @Override
+  public Object createValue(final List<?> params) {
+    if (!(params.get(0) instanceof Collection))
+      return null;
 
-		final Collection<?> multiValueCollection = (Collection<?>) params.get(0);
-		final List<Object> values = new ArrayList<Object>(multiValueCollection.size());
-		for (final Object item : multiValueCollection) {
-			values.add(createSingleValue(item));
-		}
-		return values;
-	}
+    final Collection<?> multiValueCollection = (Collection<?>) params.get(0);
+    final List<Object> values = new ArrayList<Object>(multiValueCollection.size());
+    for (final Object item : multiValueCollection) {
+      values.add(createSingleValue(item));
+    }
+    return values;
+  }
 
-	@Override
-	public Object createValue(final Object... params) {
-		if (!(params[0] instanceof Collection)) {
-			return null;
-		}
+  @Override
+  public Object createValue(final Object... params) {
+    if (!(params[0] instanceof Collection)) {
+      return null;
+    }
 
-		final Collection<?> multiValueCollection = (Collection<?>) params[0];
-		final List<Object> values = new ArrayList<Object>(multiValueCollection.size());
-		for (final Object item : multiValueCollection) {
-			values.add(createSingleValue(item));
-		}
-		return values;
-	}
+    final Collection<?> multiValueCollection = (Collection<?>) params[0];
+    final List<Object> values = new ArrayList<Object>(multiValueCollection.size());
+    for (final Object item : multiValueCollection) {
+      values.add(createSingleValue(item));
+    }
+    return values;
+  }
 
-	public Object createSingleValue(final Object param) {
-		return OType.convert(param, keyType.getDefaultJavaType());
-	}
+  public Object createSingleValue(final Object... param) {
+    return OType.convert(param[0], keyType.getDefaultJavaType());
+  }
 
-	public void processChangeEvent(final OMultiValueChangeEvent<?, ?> changeEvent, final Map<Object, Integer> keysToAdd,
-			final Map<Object, Integer> keysToRemove) {
-		switch (changeEvent.getChangeType()) {
-		case ADD: {
-			processAdd(createSingleValue(changeEvent.getValue()), keysToAdd, keysToRemove);
-			break;
-		}
-		case REMOVE: {
-			processRemoval(createSingleValue(changeEvent.getOldValue()), keysToAdd, keysToRemove);
-			break;
-		}
-		case UPDATE: {
-			processRemoval(createSingleValue(changeEvent.getOldValue()), keysToAdd, keysToRemove);
-			processAdd(createSingleValue(changeEvent.getValue()), keysToAdd, keysToRemove);
-			break;
-		}
-		default:
-			throw new IllegalArgumentException(""Invalid change type : "" + changeEvent.getChangeType());
-		}
-	}
+  public void processChangeEvent(final OMultiValueChangeEvent<?, ?> changeEvent, final Map<Object, Integer> keysToAdd,
+      final Map<Object, Integer> keysToRemove) {
+    switch (changeEvent.getChangeType()) {
+    case ADD: {
+      processAdd(createSingleValue(changeEvent.getValue()), keysToAdd, keysToRemove);
+      break;
+    }
+    case REMOVE: {
+      processRemoval(createSingleValue(changeEvent.getOldValue()), keysToAdd, keysToRemove);
+      break;
+    }
+    case UPDATE: {
+      processRemoval(createSingleValue(changeEvent.getOldValue()), keysToAdd, keysToRemove);
+      processAdd(createSingleValue(changeEvent.getValue()), keysToAdd, keysToRemove);
+      break;
+    }
+    default:
+      throw new IllegalArgumentException(""Invalid change type : "" + changeEvent.getChangeType());
+    }
+  }
 
   @Override
diff --git a/core/src/main/java/com/orientechnologies/orient/core/index/OPropertyMapIndexDefinition.java b/core/src/main/java/com/orientechnologies/orient/core/index/OPropertyMapIndexDefinition.java
index 023b0fe2b5..976c87a21e 100644
--- a/core/src/main/java/com/orientechnologies/orient/core/index/OPropertyMapIndexDefinition.java
+++ b/core/src/main/java/com/orientechnologies/orient/core/index/OPropertyMapIndexDefinition.java
@@ -18,4 +18,5 @@ package com.orientechnologies.orient.core.index;
 import java.util.ArrayList;
 import java.util.Collection;
+import java.util.Collections;
 import java.util.List;
 import java.util.Map;
@@ -33,175 +34,182 @@ import com.orientechnologies.orient.core.record.impl.ODocument;
 public class OPropertyMapIndexDefinition extends OAbstractIndexDefinitionMultiValue implements OIndexDefinitionMultiValue {
 
-	/**
-	 * Indicates whether Map will be indexed using its keys or values.
-	 */
-	public static enum INDEX_BY {
-		KEY, VALUE
-	}
-
-	private INDEX_BY	indexBy	= INDEX_BY.KEY;
-
-	public OPropertyMapIndexDefinition() {
-	}
-
-	public OPropertyMapIndexDefinition(final String iClassName, final String iField, final OType iType, final INDEX_BY indexBy) {
-		super(iClassName, iField, iType);
-
-		if (indexBy == null)
-			throw new NullPointerException(""You have to provide way by which map entries should be mapped"");
-
-		this.indexBy = indexBy;
-	}
-
-	@Override
-	public Object getDocumentValueToIndex(ODocument iDocument) {
-		return createValue(iDocument.field(field));
-	}
-
-	@Override
-	public Object createValue(List<?> params) {
-		if (!(params.get(0) instanceof Map))
-			return null;
-
-		final Collection<?> mapParams = extractMapParams((Map<?, ?>) params.get(0));
-		final List<Object> result = new ArrayList<Object>(mapParams.size());
-		for (final Object mapParam : mapParams) {
-			result.add(createSingleValue(mapParam));
-		}
-
-		return result;
-	}
-
-	@Override
-	public Object createValue(Object... params) {
-		if (!(params[0] instanceof Map))
-			return null;
-
-		final Collection<?> mapParams = extractMapParams((Map<?, ?>) params[0]);
-
-		final List<Object> result = new ArrayList<Object>(mapParams.size());
-		for (final Object mapParam : mapParams) {
-			result.add(createSingleValue(mapParam));
-		}
-
-		return result;
-	}
-
-	public INDEX_BY getIndexBy() {
-		return indexBy;
-	}
-
-	@Override
-	protected void serializeToStream() {
-		super.serializeToStream();
-		document.field(""mapIndexBy"", indexBy.toString());
-	}
-
-	@Override
-	protected void serializeFromStream() {
-		super.serializeFromStream();
-		indexBy = INDEX_BY.valueOf(document.<String> field(""mapIndexBy""));
-	}
-
-	private Collection<?> extractMapParams(Map<?, ?> map) {
-		if (indexBy == INDEX_BY.KEY)
-			return map.keySet();
-
-		return map.values();
-	}
-
-	@Override
-	public boolean equals(Object o) {
-		if (this == o)
-			return true;
-		if (o == null || getClass() != o.getClass())
-			return false;
-		if (!super.equals(o))
-			return false;
-
-		OPropertyMapIndexDefinition that = (OPropertyMapIndexDefinition) o;
-
-		if (indexBy != that.indexBy)
-			return false;
-
-		return true;
-	}
-
-	public Object createSingleValue(final Object param) {
-		return OType.convert(param, keyType.getDefaultJavaType());
-	}
-
-	public void processChangeEvent(final OMultiValueChangeEvent<?, ?> changeEvent, final Map<Object, Integer> keysToAdd,
-			final Map<Object, Integer> keysToRemove) {
-		final boolean result;
-		if (indexBy.equals(INDEX_BY.KEY))
-			result = processKeyChangeEvent(changeEvent, keysToAdd, keysToRemove);
-		else
-			result = processValueChangeEvent(changeEvent, keysToAdd, keysToRemove);
-
-		if (!result)
-			throw new IllegalArgumentException(""Invalid change type :"" + changeEvent.getChangeType());
-	}
-
-	private boolean processKeyChangeEvent(final OMultiValueChangeEvent<?, ?> changeEvent, final Map<Object, Integer> keysToAdd,
-			final Map<Object, Integer> keysToRemove) {
-		switch (changeEvent.getChangeType()) {
-		case ADD:
-			processAdd(createSingleValue(changeEvent.getKey()), keysToAdd, keysToRemove);
-			return true;
-		case REMOVE:
-			processRemoval(createSingleValue(changeEvent.getKey()), keysToAdd, keysToRemove);
-			return true;
-		case UPDATE:
-			return true;
-		}
-		return false;
-	}
-
-	private boolean processValueChangeEvent(final OMultiValueChangeEvent<?, ?> changeEvent, final Map<Object, Integer> keysToAdd,
-			final Map<Object, Integer> keysToRemove) {
-		switch (changeEvent.getChangeType()) {
-		case ADD:
-			processAdd(createSingleValue(changeEvent.getValue()), keysToAdd, keysToRemove);
-			return true;
-		case REMOVE:
-			processRemoval(createSingleValue(changeEvent.getOldValue()), keysToAdd, keysToRemove);
-			return true;
-		case UPDATE:
-			processRemoval(createSingleValue(changeEvent.getOldValue()), keysToAdd, keysToRemove);
-			processAdd(createSingleValue(changeEvent.getValue()), keysToAdd, keysToRemove);
-			return true;
-		}
-		return false;
-	}
-
-	@Override
-	public int hashCode() {
-		int result = super.hashCode();
-		result = 31 * result + indexBy.hashCode();
-		return result;
-	}
-
-	@Override
-	public String toString() {
-		return ""OPropertyMapIndexDefinition{"" + ""indexBy="" + indexBy + ""} "" + super.toString();
-	}
-
-	@Override
-	public String toCreateIndexDDL(String indexName, String indexType) {
-		final StringBuilder ddl = new StringBuilder(""create index "");
-
-		ddl.append(indexName).append("" on "");
-		ddl.append(className).append("" ( "").append(field);
-
-		if (indexBy == INDEX_BY.KEY)
-			ddl.append("" by key"");
-		else
-			ddl.append("" by value"");
-
-		ddl.append("" ) "");
-		ddl.append(indexType);
-
-		return ddl.toString();
-	}
+  /**
+   * Indicates whether Map will be indexed using its keys or values.
+   */
+  public static enum INDEX_BY {
+    KEY, VALUE
+  }
+
+  private INDEX_BY indexBy = INDEX_BY.KEY;
+
+  public OPropertyMapIndexDefinition() {
+  }
+
+  public OPropertyMapIndexDefinition(final String iClassName, final String iField, final OType iType, final INDEX_BY indexBy) {
+    super(iClassName, iField, iType);
+
+    if (indexBy == null)
+      throw new NullPointerException(""You have to provide way by which map entries should be mapped"");
+
+    this.indexBy = indexBy;
+  }
+
+  @Override
+  public Object getDocumentValueToIndex(ODocument iDocument) {
+    return createValue(iDocument.field(field));
+  }
+
+  @Override
+  public Object createValue(List<?> params) {
+    if (!(params.get(0) instanceof Map))
+      return null;
+
+    final Collection<?> mapParams = extractMapParams((Map<?, ?>) params.get(0));
+    final List<Object> result = new ArrayList<Object>(mapParams.size());
+    for (final Object mapParam : mapParams) {
+      result.add(createSingleValue(mapParam));
+    }
+
+    return result;
+  }
+
+  @Override
+  public Object createValue(Object... params) {
+    if (!(params[0] instanceof Map))
+      return null;
+
+    final Collection<?> mapParams = extractMapParams((Map<?, ?>) params[0]);
+
+    final List<Object> result = new ArrayList<Object>(mapParams.size());
+    for (final Object mapParam : mapParams) {
+      result.add(createSingleValue(mapParam));
+    }
+
+    return result;
+  }
+
+  public INDEX_BY getIndexBy() {
+    return indexBy;
+  }
+
+  @Override
+  protected void serializeToStream() {
+    super.serializeToStream();
+    document.field(""mapIndexBy"", indexBy.toString());
+  }
+
+  @Override
+  protected void serializeFromStream() {
+    super.serializeFromStream();
+    indexBy = INDEX_BY.valueOf(document.<String> field(""mapIndexBy""));
+  }
+
+  private Collection<?> extractMapParams(Map<?, ?> map) {
+    if (indexBy == INDEX_BY.KEY)
+      return map.keySet();
+
+    return map.values();
+  }
+
+  @Override
+  public boolean equals(Object o) {
+    if (this == o)
+      return true;
+    if (o == null || getClass() != o.getClass())
+      return false;
+    if (!super.equals(o))
+      return false;
+
+    OPropertyMapIndexDefinition that = (OPropertyMapIndexDefinition) o;
+
+    if (indexBy != that.indexBy)
+      return false;
+
+    return true;
+  }
+
+  public Object createSingleValue(final Object... param) {
+    return OType.convert(param[0], keyType.getDefaultJavaType());
+  }
+
+  public void processChangeEvent(final OMultiValueChangeEvent<?, ?> changeEvent, final Map<Object, Integer> keysToAdd,
+      final Map<Object, Integer> keysToRemove) {
+    final boolean result;
+    if (indexBy.equals(INDEX_BY.KEY))
+      result = processKeyChangeEvent(changeEvent, keysToAdd, keysToRemove);
+    else
+      result = processValueChangeEvent(changeEvent, keysToAdd, keysToRemove);
+
+    if (!result)
+      throw new IllegalArgumentException(""Invalid change type :"" + changeEvent.getChangeType());
+  }
+
+  private boolean processKeyChangeEvent(final OMultiValueChangeEvent<?, ?> changeEvent, final Map<Object, Integer> keysToAdd,
+      final Map<Object, Integer> keysToRemove) {
+    switch (changeEvent.getChangeType()) {
+    case ADD:
+      processAdd(createSingleValue(changeEvent.getKey()), keysToAdd, keysToRemove);
+      return true;
+    case REMOVE:
+      processRemoval(createSingleValue(changeEvent.getKey()), keysToAdd, keysToRemove);
+      return true;
+    case UPDATE:
+      return true;
+    }
+    return false;
+  }
+
+  private boolean processValueChangeEvent(final OMultiValueChangeEvent<?, ?> changeEvent, final Map<Object, Integer> keysToAdd,
+      final Map<Object, Integer> keysToRemove) {
+    switch (changeEvent.getChangeType()) {
+    case ADD:
+      processAdd(createSingleValue(changeEvent.getValue()), keysToAdd, keysToRemove);
+      return true;
+    case REMOVE:
+      processRemoval(createSingleValue(changeEvent.getOldValue()), keysToAdd, keysToRemove);
+      return true;
+    case UPDATE:
+      processRemoval(createSingleValue(changeEvent.getOldValue()), keysToAdd, keysToRemove);
+      processAdd(createSingleValue(changeEvent.getValue()), keysToAdd, keysToRemove);
+      return true;
+    }
+    return false;
+  }
+
+  @Override
+  public List<String> getFieldsToIndex() {
+    if (indexBy == INDEX_BY.KEY)
+      return Collections.singletonList(field + "" by key"");
+    return Collections.singletonList(field + "" by value"");
+  }
+
+  @Override
+  public int hashCode() {
+    int result = super.hashCode();
+    result = 31 * result + indexBy.hashCode();
+    return result;
+  }
+
+  @Override
+  public String toString() {
+    return ""OPropertyMapIndexDefinition{"" + ""indexBy="" + indexBy + ""} "" + super.toString();
+  }
+
+  @Override
+  public String toCreateIndexDDL(String indexName, String indexType) {
+    final StringBuilder ddl = new StringBuilder(""create index "");
+
+    ddl.append(indexName).append("" on "");
+    ddl.append(className).append("" ( "").append(field);
+
+    if (indexBy == INDEX_BY.KEY)
+      ddl.append("" by key"");
+    else
+      ddl.append("" by value"");
+
+    ddl.append("" ) "");
+    ddl.append(indexType);
+
+    return ddl.toString();
+  }
 }
diff --git a/core/src/main/java/com/orientechnologies/orient/core/index/ORuntimeKeyIndexDefinition.java b/core/src/main/java/com/orientechnologies/orient/core/index/ORuntimeKeyIndexDefinition.java
index 270af80d81..ae6509a47f 100644
--- a/core/src/main/java/com/orientechnologies/orient/core/index/ORuntimeKeyIndexDefinition.java
+++ b/core/src/main/java/com/orientechnologies/orient/core/index/ORuntimeKeyIndexDefinition.java
@@ -54,4 +54,8 @@ public class ORuntimeKeyIndexDefinition<T> extends ODocumentWrapperNoClass imple
   }
 
+  public List<String> getFieldsToIndex() {
+    return Collections.emptyList();
+  }
+
   public String getClassName() {
     return null;
@@ -130,5 +134,5 @@ public class ORuntimeKeyIndexDefinition<T> extends ODocumentWrapperNoClass imple
   public String toCreateIndexDDL(final String indexName, final String indexType) {
     final StringBuilder ddl = new StringBuilder(""create index "");
-    ddl.append(indexName).append("" "").append(indexType).append("" "");
+    ddl.append(indexName).append(' ').append(indexType).append(' ');
     ddl.append(""runtime "").append(serializer.getId());
     return ddl.toString();
diff --git a/core/src/main/java/com/orientechnologies/orient/core/index/OSimpleKeyIndexDefinition.java b/core/src/main/java/com/orientechnologies/orient/core/index/OSimpleKeyIndexDefinition.java
index 3f17667999..d4452d6edb 100644
--- a/core/src/main/java/com/orientechnologies/orient/core/index/OSimpleKeyIndexDefinition.java
+++ b/core/src/main/java/com/orientechnologies/orient/core/index/OSimpleKeyIndexDefinition.java
@@ -13,130 +13,134 @@ import com.orientechnologies.orient.core.type.ODocumentWrapperNoClass;
 
 public class OSimpleKeyIndexDefinition extends ODocumentWrapperNoClass implements OIndexDefinition {
-	private OType[]	keyTypes;
-
-	public OSimpleKeyIndexDefinition(final OType... keyTypes) {
-		super(new ODocument());
-		this.keyTypes = keyTypes;
-	}
-
-	public OSimpleKeyIndexDefinition() {
-	}
-
-	public List<String> getFields() {
-		return Collections.emptyList();
-	}
-
-	public String getClassName() {
-		return null;
-	}
-
-	public Comparable<?> createValue(final List<?> params) {
-		return createValue(params != null ? params.toArray() : null);
-	}
-
-	public Comparable<?> createValue(final Object... params) {
-		if (params == null || params.length == 0)
-			return null;
-
-		if (keyTypes.length == 1)
-			return (Comparable<?>) OType.convert(params[0], keyTypes[0].getDefaultJavaType());
-
-		final OCompositeKey compositeKey = new OCompositeKey();
-
-		for (int i = 0; i < params.length; ++i) {
-			final Comparable<?> paramValue = (Comparable<?>) OType.convert(params[i], keyTypes[i].getDefaultJavaType());
-
-			if (paramValue == null)
-				return null;
-			compositeKey.addKey(paramValue);
-		}
-
-		return compositeKey;
-	}
-
-	public int getParamCount() {
-		return keyTypes.length;
-	}
-
-	public OType[] getTypes() {
-		return keyTypes;
-	}
-
-	@Override
-	public ODocument toStream() {
-		document.setInternalStatus(ORecordElement.STATUS.UNMARSHALLING);
-		try {
-
-			final List<String> keyTypeNames = new ArrayList<String>(keyTypes.length);
-
-			for (final OType keyType : keyTypes)
-				keyTypeNames.add(keyType.toString());
-
-			document.field(""keyTypes"", keyTypeNames, OType.EMBEDDEDLIST);
-			return document;
-		} finally {
-			document.setInternalStatus(ORecordElement.STATUS.LOADED);
-		}
-	}
-
-	@Override
-	protected void fromStream() {
-		final List<String> keyTypeNames = document.field(""keyTypes"");
-		keyTypes = new OType[keyTypeNames.size()];
-
-		int i = 0;
-		for (final String keyTypeName : keyTypeNames) {
-			keyTypes[i] = OType.valueOf(keyTypeName);
-			i++;
-		}
-	}
-
-	public Object getDocumentValueToIndex(final ODocument iDocument) {
-		throw new OIndexException(""This method is not supported in given index definition."");
-	}
-
-	@Override
-	public boolean equals(final Object o) {
-		if (this == o)
-			return true;
-		if (o == null || getClass() != o.getClass())
-			return false;
-
-		final OSimpleKeyIndexDefinition that = (OSimpleKeyIndexDefinition) o;
-		if (!Arrays.equals(keyTypes, that.keyTypes))
-			return false;
-
-		return true;
-	}
-
-	@Override
-	public int hashCode() {
-		int result = super.hashCode();
-		result = 31 * result + (keyTypes != null ? Arrays.hashCode(keyTypes) : 0);
-		return result;
-	}
-
-	@Override
-	public String toString() {
-		return ""OSimpleKeyIndexDefinition{"" + ""keyTypes="" + (keyTypes == null ? null : Arrays.asList(keyTypes)) + '}';
-	}
-
-	/**
-	 * {@inheritDoc}
-	 * 
-	 * @param indexName
-	 * @param indexType
-	 */
-	public String toCreateIndexDDL(final String indexName, final String indexType) {
-		final StringBuilder ddl = new StringBuilder(""create index "");
-		ddl.append(indexName).append("" "").append(indexType).append("" "");
-
-		if (keyTypes != null && keyTypes.length > 0) {
-			ddl.append(keyTypes[0].toString());
-			for (int i = 1; i < keyTypes.length; i++) {
-				ddl.append("", "").append(keyTypes[i].toString());
-			}
-		}
-		return ddl.toString();
-	}
+  private OType[] keyTypes;
+
+  public OSimpleKeyIndexDefinition(final OType... keyTypes) {
+    super(new ODocument());
+    this.keyTypes = keyTypes;
+  }
+
+  public OSimpleKeyIndexDefinition() {
+  }
+
+  public List<String> getFields() {
+    return Collections.emptyList();
+  }
+
+  public List<String> getFieldsToIndex() {
+    return Collections.emptyList();
+  }
+
+  public String getClassName() {
+    return null;
+  }
+
+  public Comparable<?> createValue(final List<?> params) {
+    return createValue(params != null ? params.toArray() : null);
+  }
+
+  public Comparable<?> createValue(final Object... params) {
+    if (params == null || params.length == 0)
+      return null;
+
+    if (keyTypes.length == 1)
+      return (Comparable<?>) OType.convert(params[0], keyTypes[0].getDefaultJavaType());
+
+    final OCompositeKey compositeKey = new OCompositeKey();
+
+    for (int i = 0; i < params.length; ++i) {
+      final Comparable<?> paramValue = (Comparable<?>) OType.convert(params[i], keyTypes[i].getDefaultJavaType());
+
+      if (paramValue == null)
+        return null;
+      compositeKey.addKey(paramValue);
+    }
+
+    return compositeKey;
+  }
+
+  public int getParamCount() {
+    return keyTypes.length;
+  }
+
+  public OType[] getTypes() {
+    return keyTypes;
+  }
+
+  @Override
+  public ODocument toStream() {
+    document.setInternalStatus(ORecordElement.STATUS.UNMARSHALLING);
+    try {
+
+      final List<String> keyTypeNames = new ArrayList<String>(keyTypes.length);
+
+      for (final OType keyType : keyTypes)
+        keyTypeNames.add(keyType.toString());
+
+      document.field(""keyTypes"", keyTypeNames, OType.EMBEDDEDLIST);
+      return document;
+    } finally {
+      document.setInternalStatus(ORecordElement.STATUS.LOADED);
+    }
+  }
+
+  @Override
+  protected void fromStream() {
+    final List<String> keyTypeNames = document.field(""keyTypes"");
+    keyTypes = new OType[keyTypeNames.size()];
+
+    int i = 0;
+    for (final String keyTypeName : keyTypeNames) {
+      keyTypes[i] = OType.valueOf(keyTypeName);
+      i++;
+    }
+  }
+
+  public Object getDocumentValueToIndex(final ODocument iDocument) {
+    throw new OIndexException(""This method is not supported in given index definition."");
+  }
+
+  @Override
+  public boolean equals(final Object o) {
+    if (this == o)
+      return true;
+    if (o == null || getClass() != o.getClass())
+      return false;
+
+    final OSimpleKeyIndexDefinition that = (OSimpleKeyIndexDefinition) o;
+    if (!Arrays.equals(keyTypes, that.keyTypes))
+      return false;
+
+    return true;
+  }
+
+  @Override
+  public int hashCode() {
+    int result = super.hashCode();
+    result = 31 * result + (keyTypes != null ? Arrays.hashCode(keyTypes) : 0);
+    return result;
+  }
+
+  @Override
+  public String toString() {
+    return ""OSimpleKeyIndexDefinition{"" + ""keyTypes="" + (keyTypes == null ? null : Arrays.asList(keyTypes)) + '}';
+  }
+
+  /**
+   * {@inheritDoc}
+   * 
+   * @param indexName
+   * @param indexType
+   */
+  public String toCreateIndexDDL(final String indexName, final String indexType) {
+    final StringBuilder ddl = new StringBuilder(""create index "");
+    ddl.append(indexName).append(' ').append(indexType).append(' ');
+
+    if (keyTypes != null && keyTypes.length > 0) {
+      ddl.append(keyTypes[0].toString());
+      for (int i = 1; i < keyTypes.length; i++) {
+        ddl.append("", "").append(keyTypes[i].toString());
+      }
+    }
+    return ddl.toString();
+  }
 }
diff --git a/core/src/main/java/com/orientechnologies/orient/core/sql/OCommandExecutorSQLSelect.java b/core/src/main/java/com/orientechnologies/orient/core/sql/OCommandExecutorSQLSelect.java
index 5b0b4b95d0..3377f29751 100644
--- a/core/src/main/java/com/orientechnologies/orient/core/sql/OCommandExecutorSQLSelect.java
+++ b/core/src/main/java/com/orientechnologies/orient/core/sql/OCommandExecutorSQLSelect.java
@@ -61,5 +61,4 @@ import com.orientechnologies.orient.core.sql.operator.OIndexReuseType;
 import com.orientechnologies.orient.core.sql.operator.OQueryOperator;
 import com.orientechnologies.orient.core.sql.operator.OQueryOperatorBetween;
-import com.orientechnologies.orient.core.sql.operator.OQueryOperatorEquals;
 import com.orientechnologies.orient.core.sql.operator.OQueryOperatorIn;
 import com.orientechnologies.orient.core.sql.operator.OQueryOperatorMajor;
@@ -383,9 +382,5 @@ public class OCommandExecutorSQLSelect extends OCommandExecutorSQLResultsetAbstr
 
       final List<OIndex<?>> involvedIndexes = getInvolvedIndexes(iSchemaClass, searchResult);
-      Collections.sort(involvedIndexes, new Comparator<OIndex>() {
-        public int compare(final OIndex indexOne, final OIndex indexTwo) {
-          return indexOne.getDefinition().getParamCount() - indexTwo.getDefinition().getParamCount();
-        }
-      });
+      Collections.sort(involvedIndexes, IndexComparator.INSTANCE);
 
       // go through all possible index for given set of fields.
@@ -396,5 +391,5 @@ public class OCommandExecutorSQLSelect extends OCommandExecutorSQLResultsetAbstr
         // we need to test that last field in query subset and field in index that has the same position
         // are equals.
-        if (!(operator instanceof OQueryOperatorEquals)) {
+        if (!OIndexSearchResult.isIndexEqualityOperator(operator)) {
           final String lastFiled = searchResult.lastField.getItemName(searchResult.lastField.getItemCount() - 1);
           final String relatedIndexField = indexDefinition.getFields().get(searchResult.fieldValuePairs.size());
@@ -424,5 +419,5 @@ public class OCommandExecutorSQLSelect extends OCommandExecutorSQLResultsetAbstr
   }
 
-  private List<OIndex<?>> getInvolvedIndexes(OClass iSchemaClass, OIndexSearchResult searchResultFields) {
+  private static List<OIndex<?>> getInvolvedIndexes(OClass iSchemaClass, OIndexSearchResult searchResultFields) {
     final Set<OIndex<?>> involvedIndexes = iSchemaClass.getInvolvedIndexes(searchResultFields.fields());
 
@@ -439,16 +434,19 @@ public class OCommandExecutorSQLSelect extends OCommandExecutorSQLResultsetAbstr
   }
 
-  private OIndexSearchResult analyzeQueryBranch(final OClass iSchemaClass, final OSQLFilterCondition iCondition,
+  private static OIndexSearchResult analyzeQueryBranch(final OClass iSchemaClass, OSQLFilterCondition iCondition,
       final List<OIndexSearchResult> iIndexSearchResults) {
     if (iCondition == null)
       return null;
 
-    final OQueryOperator operator = iCondition.getOperator();
-    if (operator == null)
+    OQueryOperator operator = iCondition.getOperator();
+
+    while (operator == null) {
       if (iCondition.getRight() == null && iCondition.getLeft() instanceof OSQLFilterCondition) {
-        return analyzeQueryBranch(iSchemaClass, (OSQLFilterCondition) iCondition.getLeft(), iIndexSearchResults);
+        iCondition = (OSQLFilterCondition) iCondition.getLeft();
+        operator = iCondition.getOperator();
       } else {
         return null;
       }
+    }
 
     final OIndexReuseType indexReuseType = operator.getIndexReuseType(iCondition.getLeft(), iCondition.getRight());
@@ -495,5 +493,5 @@ public class OCommandExecutorSQLSelect extends OCommandExecutorSQLResultsetAbstr
    * @return true if the property was indexed and found, otherwise false
    */
-  private OIndexSearchResult createIndexedProperty(final OSQLFilterCondition iCondition, final Object iItem) {
+  private static OIndexSearchResult createIndexedProperty(final OSQLFilterCondition iCondition, final Object iItem) {
     if (iItem == null || !(iItem instanceof OSQLFilterItemField))
       return null;
@@ -909,5 +907,5 @@ public class OCommandExecutorSQLSelect extends OCommandExecutorSQLResultsetAbstr
   }
 
-  private Object getIndexKey(final OIndexDefinition indexDefinition, Object value) {
+  private static Object getIndexKey(final OIndexDefinition indexDefinition, Object value) {
     if (indexDefinition instanceof OCompositeIndexDefinition) {
       if (value instanceof List) {
@@ -940,5 +938,5 @@ public class OCommandExecutorSQLSelect extends OCommandExecutorSQLResultsetAbstr
   }
 
-  private ODocument createIndexEntryAsDocument(final Object iKey, final OIdentifiable iValue) {
+  private static ODocument createIndexEntryAsDocument(final Object iKey, final OIdentifiable iValue) {
     final ODocument doc = new ODocument().setOrdered(true);
     doc.field(""key"", iKey);
@@ -969,5 +967,5 @@ public class OCommandExecutorSQLSelect extends OCommandExecutorSQLResultsetAbstr
   }
 
-  private boolean checkIndexExistence(OClass iSchemaClass, OIndexSearchResult result) {
+  private static boolean checkIndexExistence(OClass iSchemaClass, OIndexSearchResult result) {
     if (!iSchemaClass.areIndexed(result.fields())) {
       return false;
@@ -1025,3 +1023,11 @@ public class OCommandExecutorSQLSelect extends OCommandExecutorSQLResultsetAbstr
     return false;
   }
+
+  private static class IndexComparator implements Comparator<OIndex> {
+    private static final IndexComparator INSTANCE = new IndexComparator();
+
+    public int compare(final OIndex indexOne, final OIndex indexTwo) {
+      return indexOne.getDefinition().getParamCount() - indexTwo.getDefinition().getParamCount();
+    }
+  }
 }
diff --git a/core/src/main/java/com/orientechnologies/orient/core/sql/OIndexSearchResult.java b/core/src/main/java/com/orientechnologies/orient/core/sql/OIndexSearchResult.java
index e16a080705..30cbefc712 100644
--- a/core/src/main/java/com/orientechnologies/orient/core/sql/OIndexSearchResult.java
+++ b/core/src/main/java/com/orientechnologies/orient/core/sql/OIndexSearchResult.java
@@ -8,4 +8,7 @@ import java.util.Map;
 import com.orientechnologies.orient.core.sql.filter.OSQLFilterItemField;
 import com.orientechnologies.orient.core.sql.operator.OQueryOperator;
+import com.orientechnologies.orient.core.sql.operator.OQueryOperatorContains;
+import com.orientechnologies.orient.core.sql.operator.OQueryOperatorContainsKey;
+import com.orientechnologies.orient.core.sql.operator.OQueryOperatorContainsValue;
 import com.orientechnologies.orient.core.sql.operator.OQueryOperatorEquals;
 
@@ -22,63 +25,68 @@ import com.orientechnologies.orient.core.sql.operator.OQueryOperatorEquals;
  */
 public class OIndexSearchResult {
-	final Map<String, Object>							fieldValuePairs	= new HashMap<String, Object>();
-	final OQueryOperator									lastOperator;
-	final OSQLFilterItemField.FieldChain	lastField;
-	final Object													lastValue;
+  final Map<String, Object>            fieldValuePairs = new HashMap<String, Object>(8);
+  final OQueryOperator                 lastOperator;
+  final OSQLFilterItemField.FieldChain lastField;
+  final Object                         lastValue;
 
-	OIndexSearchResult(final OQueryOperator lastOperator, final OSQLFilterItemField.FieldChain field, final Object value) {
-		this.lastOperator = lastOperator;
-		lastField = field;
-		lastValue = value;
-	}
+  OIndexSearchResult(final OQueryOperator lastOperator, final OSQLFilterItemField.FieldChain field, final Object value) {
+    this.lastOperator = lastOperator;
+    lastField = field;
+    lastValue = value;
+  }
 
-	/**
-	 * Combines two queries subset into one. This operation will be valid only if {@link #canBeMerged(OIndexSearchResult)} method will
-	 * return <code>true</code> for the same passed in parameter.
-	 * 
-	 * @param searchResult
-	 *          Query subset to merge.
-	 * @return New instance that presents merged query.
-	 */
-	OIndexSearchResult merge(final OIndexSearchResult searchResult) {
-		final OQueryOperator operator;
-		final OIndexSearchResult result;
+  /**
+   * Combines two queries subset into one. This operation will be valid only if {@link #canBeMerged(OIndexSearchResult)} method will
+   * return <code>true</code> for the same passed in parameter.
+   * 
+   * @param searchResult
+   *          Query subset to merge.
+   * @return New instance that presents merged query.
+   */
+  OIndexSearchResult merge(final OIndexSearchResult searchResult) {
+    final OQueryOperator operator;
+    final OIndexSearchResult result;
 
-		if (searchResult.lastOperator instanceof OQueryOperatorEquals) {
-			result = new OIndexSearchResult(this.lastOperator, lastField, lastValue);
-			result.fieldValuePairs.putAll(searchResult.fieldValuePairs);
-			result.fieldValuePairs.putAll(fieldValuePairs);
-			result.fieldValuePairs.put(searchResult.lastField.getItemName(0), searchResult.lastValue);
-		} else {
-			operator = searchResult.lastOperator;
-			result = new OIndexSearchResult(operator, searchResult.lastField, searchResult.lastValue);
-			result.fieldValuePairs.putAll(searchResult.fieldValuePairs);
-			result.fieldValuePairs.putAll(fieldValuePairs);
-			result.fieldValuePairs.put(lastField.getItemName(0), lastValue);
-		}
-		return result;
-	}
+    if (searchResult.lastOperator instanceof OQueryOperatorEquals) {
+      result = new OIndexSearchResult(this.lastOperator, lastField, lastValue);
+      result.fieldValuePairs.putAll(searchResult.fieldValuePairs);
+      result.fieldValuePairs.putAll(fieldValuePairs);
+      result.fieldValuePairs.put(searchResult.lastField.getItemName(0), searchResult.lastValue);
+    } else {
+      operator = searchResult.lastOperator;
+      result = new OIndexSearchResult(operator, searchResult.lastField, searchResult.lastValue);
+      result.fieldValuePairs.putAll(searchResult.fieldValuePairs);
+      result.fieldValuePairs.putAll(fieldValuePairs);
+      result.fieldValuePairs.put(lastField.getItemName(0), lastValue);
+    }
+    return result;
+  }
 
-	/**
-	 * @param searchResult
-	 *          Query subset is going to be merged with given one.
-	 * @return <code>true</code> if two query subsets can be merged.
-	 */
-	boolean canBeMerged(final OIndexSearchResult searchResult) {
-		if (lastField.isLong() || searchResult.lastField.isLong()) {
-			return false;
-		}
-		return (lastOperator instanceof OQueryOperatorEquals) || (searchResult.lastOperator instanceof OQueryOperatorEquals);
-	}
+  /**
+   * @param searchResult
+   *          Query subset is going to be merged with given one.
+   * @return <code>true</code> if two query subsets can be merged.
+   */
+  boolean canBeMerged(final OIndexSearchResult searchResult) {
+    if (lastField.isLong() || searchResult.lastField.isLong()) {
+      return false;
+    }
+    return isIndexEqualityOperator(lastOperator) || isIndexEqualityOperator(searchResult.lastOperator);
+  }
 
-	List<String> fields() {
-		final List<String> result = new ArrayList<String>(fieldValuePairs.size() + 1);
-		result.addAll(fieldValuePairs.keySet());
-		result.add(lastField.getItemName(0));
-		return result;
-	}
+  List<String> fields() {
+    final List<String> result = new ArrayList<String>(fieldValuePairs.size() + 1);
+    result.addAll(fieldValuePairs.keySet());
+    result.add(lastField.getItemName(0));
+    return result;
+  }
 
-	int getFieldCount() {
-		return fieldValuePairs.size() + 1;
-	}
-}
\ No newline at end of file
+  int getFieldCount() {
+    return fieldValuePairs.size() + 1;
+  }
+
+  public static boolean isIndexEqualityOperator(OQueryOperator queryOperator) {
+    return queryOperator instanceof OQueryOperatorEquals || queryOperator instanceof OQueryOperatorContains
+        || queryOperator instanceof OQueryOperatorContainsKey || queryOperator instanceof OQueryOperatorContainsValue;
+  }
+}
diff --git a/core/src/main/java/com/orientechnologies/orient/core/sql/operator/OQueryOperatorBetween.java b/core/src/main/java/com/orientechnologies/orient/core/sql/operator/OQueryOperatorBetween.java
index 6d3a7c4089..57e8dbcb8e 100644
--- a/core/src/main/java/com/orientechnologies/orient/core/sql/operator/OQueryOperatorBetween.java
+++ b/core/src/main/java/com/orientechnologies/orient/core/sql/operator/OQueryOperatorBetween.java
@@ -27,4 +27,5 @@ import com.orientechnologies.orient.core.command.OCommandContext;
 import com.orientechnologies.orient.core.db.record.OIdentifiable;
 import com.orientechnologies.orient.core.id.ORID;
+import com.orientechnologies.orient.core.index.OCompositeIndexDefinition;
 import com.orientechnologies.orient.core.index.OIndex;
 import com.orientechnologies.orient.core.index.OIndexDefinition;
@@ -109,4 +110,6 @@ public class OQueryOperatorBetween extends OQueryOperatorEqualityNotNulls {
         result = index.getValuesBetween(keyOne, true, keyTwo, true);
     } else {
+      final OCompositeIndexDefinition compositeIndexDefinition = (OCompositeIndexDefinition) indexDefinition;
+
       final Object[] betweenKeys = (Object[]) keyParams.get(keyParams.size() - 1);
 
@@ -129,10 +132,10 @@ public class OQueryOperatorBetween extends OQueryOperatorEqualityNotNulls {
       betweenKeyTwoParams.add(betweenKeyTwo);
 
-      final Object keyOne = indexDefinition.createValue(betweenKeyOneParams);
+      final Object keyOne = compositeIndexDefinition.createSingleValue(betweenKeyOneParams);
 
       if (keyOne == null)
         return null;
 
-      final Object keyTwo = indexDefinition.createValue(betweenKeyTwoParams);
+      final Object keyTwo = compositeIndexDefinition.createSingleValue(betweenKeyTwoParams);
 
       if (keyTwo == null)
@@ -147,4 +150,6 @@ public class OQueryOperatorBetween extends OQueryOperatorEqualityNotNulls {
         OProfiler.getInstance().updateCounter(""Query.compositeIndexUsage"", 1);
         OProfiler.getInstance().updateCounter(""Query.compositeIndexUsage."" + indexDefinition.getParamCount(), 1);
+        OProfiler.getInstance().updateCounter(
+            ""Query.compositeIndexUsage."" + indexDefinition.getParamCount() + '.' + keyParams.size(), 1);
       }
     }
diff --git a/core/src/main/java/com/orientechnologies/orient/core/sql/operator/OQueryOperatorContains.java b/core/src/main/java/com/orientechnologies/orient/core/sql/operator/OQueryOperatorContains.java
index 0d4faf90b3..bdc7782e42 100644
--- a/core/src/main/java/com/orientechnologies/orient/core/sql/operator/OQueryOperatorContains.java
+++ b/core/src/main/java/com/orientechnologies/orient/core/sql/operator/OQueryOperatorContains.java
@@ -16,7 +16,15 @@
 package com.orientechnologies.orient.core.sql.operator;
 
+import java.util.Collection;
+import java.util.Collections;
+import java.util.Iterator;
+import java.util.List;
+import java.util.Map;
+
+import com.orientechnologies.common.profiler.OProfiler;
 import com.orientechnologies.orient.core.command.OCommandContext;
 import com.orientechnologies.orient.core.db.record.OIdentifiable;
 import com.orientechnologies.orient.core.id.ORID;
+import com.orientechnologies.orient.core.index.OCompositeIndexDefinition;
 import com.orientechnologies.orient.core.index.OIndex;
 import com.orientechnologies.orient.core.index.OIndexDefinition;
@@ -25,10 +33,4 @@ import com.orientechnologies.orient.core.index.OIndexInternal;
 import com.orientechnologies.orient.core.sql.filter.OSQLFilterCondition;
 
-import java.util.Collection;
-import java.util.Collections;
-import java.util.Iterator;
-import java.util.List;
-import java.util.Map;
-
 /**
  * CONTAINS operator.
@@ -136,9 +138,35 @@ public class OQueryOperatorContains extends OQueryOperatorEqualityNotNulls {
         return (Collection<OIdentifiable>) indexResult;
 
-			if(indexResult == null)
-				return Collections.emptyList();
-      return  Collections.singletonList((OIdentifiable) indexResult);
+      if (indexResult == null)
+        return Collections.emptyList();
+      return Collections.singletonList((OIdentifiable) indexResult);
+    } else {
+      // in case of composite keys several items can be returned in case of we perform search
+      // using part of composite key stored in index.
+
+      final OCompositeIndexDefinition compositeIndexDefinition = (OCompositeIndexDefinition) indexDefinition;
+
+      final Object keyOne = compositeIndexDefinition.createSingleValue(keyParams);
+
+      if (keyOne == null)
+        return null;
+
+      final Object keyTwo = compositeIndexDefinition.createSingleValue(keyParams);
+
+      final Collection<OIdentifiable> result;
+      if (fetchLimit > -1)
+        result = index.getValuesBetween(keyOne, true, keyTwo, true, fetchLimit);
+      else
+        result = index.getValuesBetween(keyOne, true, keyTwo, true);
+
+      if (OProfiler.getInstance().isRecording()) {
+        OProfiler.getInstance().updateCounter(""Query.compositeIndexUsage"", 1);
+        OProfiler.getInstance().updateCounter(""Query.compositeIndexUsage."" + indexDefinition.getParamCount(), 1);
+        OProfiler.getInstance().updateCounter(
+            ""Query.compositeIndexUsage."" + indexDefinition.getParamCount() + '.' + keyParams.size(), 1);
+      }
+
+      return result;
     }
-    return null;
   }
 
diff --git a/core/src/main/java/com/orientechnologies/orient/core/sql/operator/OQueryOperatorContainsKey.java b/core/src/main/java/com/orientechnologies/orient/core/sql/operator/OQueryOperatorContainsKey.java
index ce7891be5a..6f4f0b8f4f 100644
--- a/core/src/main/java/com/orientechnologies/orient/core/sql/operator/OQueryOperatorContainsKey.java
+++ b/core/src/main/java/com/orientechnologies/orient/core/sql/operator/OQueryOperatorContainsKey.java
@@ -16,7 +16,14 @@
 package com.orientechnologies.orient.core.sql.operator;
 
+import java.util.Collection;
+import java.util.Collections;
+import java.util.List;
+import java.util.Map;
+
+import com.orientechnologies.common.profiler.OProfiler;
 import com.orientechnologies.orient.core.command.OCommandContext;
 import com.orientechnologies.orient.core.db.record.OIdentifiable;
 import com.orientechnologies.orient.core.id.ORID;
+import com.orientechnologies.orient.core.index.OCompositeIndexDefinition;
 import com.orientechnologies.orient.core.index.OIndex;
 import com.orientechnologies.orient.core.index.OIndexDefinition;
@@ -26,9 +33,4 @@ import com.orientechnologies.orient.core.index.OPropertyMapIndexDefinition;
 import com.orientechnologies.orient.core.sql.filter.OSQLFilterCondition;
 
-import java.util.Collection;
-import java.util.Collections;
-import java.util.List;
-import java.util.Map;
-
 /**
  * CONTAINS KEY operator.
@@ -70,8 +72,4 @@ public class OQueryOperatorContainsKey extends OQueryOperatorEqualityNotNulls {
     final OIndexDefinition indexDefinition = index.getDefinition();
 
-    if (!((index.getDefinition() instanceof OPropertyMapIndexDefinition) && ((OPropertyMapIndexDefinition) index.getDefinition())
-        .getIndexBy() == OPropertyMapIndexDefinition.INDEX_BY.KEY))
-      return null;
-
     final OIndexInternal<?> internalIndex = index.getInternal();
     if (!internalIndex.canBeUsedInEqualityOperators())
@@ -79,9 +77,9 @@ public class OQueryOperatorContainsKey extends OQueryOperatorEqualityNotNulls {
 
     if (indexDefinition.getParamCount() == 1) {
-      final Object key;
-      if (indexDefinition instanceof OIndexDefinitionMultiValue)
-        key = ((OIndexDefinitionMultiValue) indexDefinition).createSingleValue(keyParams.get(0));
-      else
-        key = indexDefinition.createValue(keyParams);
+      if (!((indexDefinition instanceof OPropertyMapIndexDefinition) && ((OPropertyMapIndexDefinition) indexDefinition)
+          .getIndexBy() == OPropertyMapIndexDefinition.INDEX_BY.KEY))
+        return null;
+
+      final Object key = ((OIndexDefinitionMultiValue) indexDefinition).createSingleValue(keyParams.get(0));
 
       if (key == null)
@@ -92,10 +90,40 @@ public class OQueryOperatorContainsKey extends OQueryOperatorEqualityNotNulls {
         return (Collection<OIdentifiable>) indexResult;
 
-			if(indexResult == null)
-				return Collections.emptyList();
-			return  Collections.singletonList((OIdentifiable) indexResult);
-		}
+      if (indexResult == null)
+        return Collections.emptyList();
+      return Collections.singletonList((OIdentifiable) indexResult);
+    } else {
+      // in case of composite keys several items can be returned in case of we perform search
+      // using part of composite key stored in index.
 
-    return null;
+      final OCompositeIndexDefinition compositeIndexDefinition = (OCompositeIndexDefinition) indexDefinition;
+
+      if (!((compositeIndexDefinition.getMultiValueDefinition() instanceof OPropertyMapIndexDefinition) && ((OPropertyMapIndexDefinition) compositeIndexDefinition
+          .getMultiValueDefinition()).getIndexBy() == OPropertyMapIndexDefinition.INDEX_BY.KEY))
+        return null;
+
+      final Object keyOne = compositeIndexDefinition.createSingleValue(keyParams);
+
+      if (keyOne == null)
+        return null;
+
+      final Object keyTwo = compositeIndexDefinition.createSingleValue(keyParams);
+
+      final Collection<OIdentifiable> result;
+      if (fetchLimit > -1)
+        result = index.getValuesBetween(keyOne, true, keyTwo, true, fetchLimit);
+      else
+        result = index.getValuesBetween(keyOne, true, keyTwo, true);
+
+      if (OProfiler.getInstance().isRecording()) {
+        OProfiler.getInstance().updateCounter(""Query.compositeIndexUsage"", 1);
+        OProfiler.getInstance().updateCounter(""Query.compositeIndexUsage."" + indexDefinition.getParamCount(), 1);
+        OProfiler.getInstance().updateCounter(
+            ""Query.compositeIndexUsage."" + indexDefinition.getParamCount() + '.' + keyParams.size(), 1);
+      }
+
+      return result;
+
+    }
   }
 
diff --git a/core/src/main/java/com/orientechnologies/orient/core/sql/operator/OQueryOperatorContainsValue.java b/core/src/main/java/com/orientechnologies/orient/core/sql/operator/OQueryOperatorContainsValue.java
index 8295ed4123..95b6d0829d 100644
--- a/core/src/main/java/com/orientechnologies/orient/core/sql/operator/OQueryOperatorContainsValue.java
+++ b/core/src/main/java/com/orientechnologies/orient/core/sql/operator/OQueryOperatorContainsValue.java
@@ -16,5 +16,11 @@
 package com.orientechnologies.orient.core.sql.operator;
 
+import java.util.Collection;
+import java.util.Collections;
+import java.util.List;
+import java.util.Map;
+
 import com.orientechnologies.common.exception.OException;
+import com.orientechnologies.common.profiler.OProfiler;
 import com.orientechnologies.orient.core.command.OCommandContext;
 import com.orientechnologies.orient.core.db.record.OIdentifiable;
@@ -22,4 +28,5 @@ import com.orientechnologies.orient.core.db.record.ORecordElement;
 import com.orientechnologies.orient.core.exception.ORecordNotFoundException;
 import com.orientechnologies.orient.core.id.ORID;
+import com.orientechnologies.orient.core.index.OCompositeIndexDefinition;
 import com.orientechnologies.orient.core.index.OIndex;
 import com.orientechnologies.orient.core.index.OIndexDefinition;
@@ -31,9 +38,4 @@ import com.orientechnologies.orient.core.record.ORecordSchemaAware;
 import com.orientechnologies.orient.core.sql.filter.OSQLFilterCondition;
 
-import java.util.Collection;
-import java.util.Collections;
-import java.util.List;
-import java.util.Map;
-
 /**
  * CONTAINS KEY operator.
@@ -115,8 +117,4 @@ public class OQueryOperatorContainsValue extends OQueryOperatorEqualityNotNulls
     final OIndexDefinition indexDefinition = index.getDefinition();
 
-    if (!((index.getDefinition() instanceof OPropertyMapIndexDefinition) && ((OPropertyMapIndexDefinition) index.getDefinition())
-        .getIndexBy() == OPropertyMapIndexDefinition.INDEX_BY.VALUE))
-      return null;
-
     final OIndexInternal<?> internalIndex = index.getInternal();
     if (!internalIndex.canBeUsedInEqualityOperators())
@@ -124,9 +122,9 @@ public class OQueryOperatorContainsValue extends OQueryOperatorEqualityNotNulls
 
     if (indexDefinition.getParamCount() == 1) {
-      final Object key;
-      if (indexDefinition instanceof OIndexDefinitionMultiValue)
-        key = ((OIndexDefinitionMultiValue) indexDefinition).createSingleValue(keyParams.get(0));
-      else
-        key = indexDefinition.createValue(keyParams);
+      if (!((indexDefinition instanceof OPropertyMapIndexDefinition) && ((OPropertyMapIndexDefinition) indexDefinition)
+          .getIndexBy() == OPropertyMapIndexDefinition.INDEX_BY.VALUE))
+        return null;
+
+      final Object key = ((OIndexDefinitionMultiValue) indexDefinition).createSingleValue(keyParams.get(0));
 
       if (key == null)
@@ -137,9 +135,38 @@ public class OQueryOperatorContainsValue extends OQueryOperatorEqualityNotNulls
         return (Collection<OIdentifiable>) indexResult;
 
-			if(indexResult == null)
-				return Collections.emptyList();
-			return  Collections.singletonList((OIdentifiable) indexResult);
-		}
-    return null;
+      if (indexResult == null)
+        return Collections.emptyList();
+      return Collections.singletonList((OIdentifiable) indexResult);
+    } else {
+      // in case of composite keys several items can be returned in case of we perform search
+      // using part of composite key stored in index.
+      final OCompositeIndexDefinition compositeIndexDefinition = (OCompositeIndexDefinition) indexDefinition;
+
+      if (!((compositeIndexDefinition.getMultiValueDefinition() instanceof OPropertyMapIndexDefinition) && ((OPropertyMapIndexDefinition) compositeIndexDefinition
+          .getMultiValueDefinition()).getIndexBy() == OPropertyMapIndexDefinition.INDEX_BY.VALUE))
+        return null;
+
+      final Object keyOne = compositeIndexDefinition.createSingleValue(keyParams);
+
+      if (keyOne == null)
+        return null;
+
+      final Object keyTwo = compositeIndexDefinition.createSingleValue(keyParams);
+
+      final Collection<OIdentifiable> result;
+      if (fetchLimit > -1)
+        result = index.getValuesBetween(keyOne, true, keyTwo, true, fetchLimit);
+      else
+        result = index.getValuesBetween(keyOne, true, keyTwo, true);
+
+      if (OProfiler.getInstance().isRecording()) {
+        OProfiler.getInstance().updateCounter(""Query.compositeIndexUsage"", 1);
+        OProfiler.getInstance().updateCounter(""Query.compositeIndexUsage."" + indexDefinition.getParamCount(), 1);
+        OProfiler.getInstance().updateCounter(
+            ""Query.compositeIndexUsage."" + indexDefinition.getParamCount() + '.' + keyParams.size(), 1);
+      }
+
+      return result;
+    }
   }
 
diff --git a/core/src/main/java/com/orientechnologies/orient/core/sql/operator/OQueryOperatorEquals.java b/core/src/main/java/com/orientechnologies/orient/core/sql/operator/OQueryOperatorEquals.java
index d8ae966b95..b02cb692d8 100644
--- a/core/src/main/java/com/orientechnologies/orient/core/sql/operator/OQueryOperatorEquals.java
+++ b/core/src/main/java/com/orientechnologies/orient/core/sql/operator/OQueryOperatorEquals.java
@@ -16,8 +16,13 @@
 package com.orientechnologies.orient.core.sql.operator;
 
+import java.util.Collection;
+import java.util.Collections;
+import java.util.List;
+
 import com.orientechnologies.common.profiler.OProfiler;
 import com.orientechnologies.orient.core.command.OCommandContext;
 import com.orientechnologies.orient.core.db.record.OIdentifiable;
 import com.orientechnologies.orient.core.id.ORID;
+import com.orientechnologies.orient.core.index.OCompositeIndexDefinition;
 import com.orientechnologies.orient.core.index.OIndex;
 import com.orientechnologies.orient.core.index.OIndexDefinition;
@@ -32,8 +37,4 @@ import com.orientechnologies.orient.core.sql.filter.OSQLFilterItemField;
 import com.orientechnologies.orient.core.sql.filter.OSQLFilterItemParameter;
 
-import java.util.Collection;
-import java.util.Collections;
-import java.util.List;
-
 /**
  * EQUALS operator.
@@ -121,17 +122,19 @@ public class OQueryOperatorEquals extends OQueryOperatorEqualityNotNulls {
         return (Collection<OIdentifiable>) indexResult;
 
-			if(indexResult == null)
-				return Collections.emptyList();
-			return  Collections.singletonList((OIdentifiable) indexResult);
-		} else {
+      if (indexResult == null)
+        return Collections.emptyList();
+      return Collections.singletonList((OIdentifiable) indexResult);
+    } else {
       // in case of composite keys several items can be returned in case of we perform search
       // using part of composite key stored in index.
 
-      final Object keyOne = indexDefinition.createValue(keyParams);
+      final OCompositeIndexDefinition compositeIndexDefinition = (OCompositeIndexDefinition) indexDefinition;
+
+      final Object keyOne = compositeIndexDefinition.createSingleValue(keyParams);
 
       if (keyOne == null)
         return null;
 
-      final Object keyTwo = indexDefinition.createValue(keyParams);
+      final Object keyTwo = compositeIndexDefinition.createSingleValue(keyParams);
 
       final Collection<OIdentifiable> result;
@@ -144,4 +147,6 @@ public class OQueryOperatorEquals extends OQueryOperatorEqualityNotNulls {
         OProfiler.getInstance().updateCounter(""Query.compositeIndexUsage"", 1);
         OProfiler.getInstance().updateCounter(""Query.compositeIndexUsage."" + indexDefinition.getParamCount(), 1);
+        OProfiler.getInstance().updateCounter(
+            ""Query.compositeIndexUsage."" + indexDefinition.getParamCount() + '.' + keyParams.size(), 1);
       }
 
diff --git a/core/src/main/java/com/orientechnologies/orient/core/sql/operator/OQueryOperatorMajor.java b/core/src/main/java/com/orientechnologies/orient/core/sql/operator/OQueryOperatorMajor.java
index 0f258d3d68..0dcbbcccca 100644
--- a/core/src/main/java/com/orientechnologies/orient/core/sql/operator/OQueryOperatorMajor.java
+++ b/core/src/main/java/com/orientechnologies/orient/core/sql/operator/OQueryOperatorMajor.java
@@ -24,4 +24,5 @@ import com.orientechnologies.orient.core.db.record.OIdentifiable;
 import com.orientechnologies.orient.core.id.ORID;
 import com.orientechnologies.orient.core.id.ORecordId;
+import com.orientechnologies.orient.core.index.OCompositeIndexDefinition;
 import com.orientechnologies.orient.core.index.OIndex;
 import com.orientechnologies.orient.core.index.OIndexDefinition;
@@ -92,10 +93,12 @@ public class OQueryOperatorMajor extends OQueryOperatorEqualityNotNulls {
       // is the biggest composite key in the index that contains key with value field1=1.
 
-      final Object keyOne = indexDefinition.createValue(keyParams);
+      final OCompositeIndexDefinition compositeIndexDefinition = (OCompositeIndexDefinition) indexDefinition;
+
+      final Object keyOne = compositeIndexDefinition.createSingleValue(keyParams);
 
       if (keyOne == null)
         return null;
 
-      final Object keyTwo = indexDefinition.createValue(keyParams.subList(0, keyParams.size() - 1));
+      final Object keyTwo = compositeIndexDefinition.createSingleValue(keyParams.subList(0, keyParams.size() - 1));
 
       if (keyTwo == null)
@@ -110,4 +113,6 @@ public class OQueryOperatorMajor extends OQueryOperatorEqualityNotNulls {
         OProfiler.getInstance().updateCounter(""Query.compositeIndexUsage"", 1);
         OProfiler.getInstance().updateCounter(""Query.compositeIndexUsage."" + indexDefinition.getParamCount(), 1);
+        OProfiler.getInstance().updateCounter(
+            ""Query.compositeIndexUsage."" + indexDefinition.getParamCount() + '.' + keyParams.size(), 1);
       }
     }
diff --git a/core/src/main/java/com/orientechnologies/orient/core/sql/operator/OQueryOperatorMajorEquals.java b/core/src/main/java/com/orientechnologies/orient/core/sql/operator/OQueryOperatorMajorEquals.java
index 151e05c3b6..86aae9a5b8 100644
--- a/core/src/main/java/com/orientechnologies/orient/core/sql/operator/OQueryOperatorMajorEquals.java
+++ b/core/src/main/java/com/orientechnologies/orient/core/sql/operator/OQueryOperatorMajorEquals.java
@@ -23,4 +23,5 @@ import com.orientechnologies.orient.core.command.OCommandContext;
 import com.orientechnologies.orient.core.db.record.OIdentifiable;
 import com.orientechnologies.orient.core.id.ORID;
+import com.orientechnologies.orient.core.index.OCompositeIndexDefinition;
 import com.orientechnologies.orient.core.index.OIndex;
 import com.orientechnologies.orient.core.index.OIndexDefinition;
@@ -91,10 +92,12 @@ public class OQueryOperatorMajorEquals extends OQueryOperatorEqualityNotNulls {
       // is the biggest composite key in the index that contains key with value field1=1.
 
-      final Object keyOne = indexDefinition.createValue(keyParams);
+      final OCompositeIndexDefinition compositeIndexDefinition = (OCompositeIndexDefinition) indexDefinition;
+
+      final Object keyOne = compositeIndexDefinition.createSingleValue(keyParams);
 
       if (keyOne == null)
         return null;
 
-      final Object keyTwo = indexDefinition.createValue(keyParams.subList(0, keyParams.size() - 1));
+      final Object keyTwo = compositeIndexDefinition.createSingleValue(keyParams.subList(0, keyParams.size() - 1));
 
       if (keyTwo == null)
@@ -109,4 +112,6 @@ public class OQueryOperatorMajorEquals extends OQueryOperatorEqualityNotNulls {
         OProfiler.getInstance().updateCounter(""Query.compositeIndexUsage"", 1);
         OProfiler.getInstance().updateCounter(""Query.compositeIndexUsage."" + indexDefinition.getParamCount(), 1);
+        OProfiler.getInstance().updateCounter(
+            ""Query.compositeIndexUsage."" + indexDefinition.getParamCount() + '.' + keyParams.size(), 1);
       }
     }
diff --git a/core/src/main/java/com/orientechnologies/orient/core/sql/operator/OQueryOperatorMinor.java b/core/src/main/java/com/orientechnologies/orient/core/sql/operator/OQueryOperatorMinor.java
index 747a27f6b8..f67eae2896 100644
--- a/core/src/main/java/com/orientechnologies/orient/core/sql/operator/OQueryOperatorMinor.java
+++ b/core/src/main/java/com/orientechnologies/orient/core/sql/operator/OQueryOperatorMinor.java
@@ -23,4 +23,5 @@ import com.orientechnologies.orient.core.command.OCommandContext;
 import com.orientechnologies.orient.core.db.record.OIdentifiable;
 import com.orientechnologies.orient.core.id.ORID;
+import com.orientechnologies.orient.core.index.OCompositeIndexDefinition;
 import com.orientechnologies.orient.core.index.OIndex;
 import com.orientechnologies.orient.core.index.OIndexDefinition;
@@ -91,10 +92,12 @@ public class OQueryOperatorMinor extends OQueryOperatorEqualityNotNulls {
       // is the biggest composite key in the index that contains key with values field1=1 and field2=2.
 
-      final Object keyOne = indexDefinition.createValue(keyParams.subList(0, keyParams.size() - 1));
+      final OCompositeIndexDefinition compositeIndexDefinition = (OCompositeIndexDefinition) indexDefinition;
+
+      final Object keyOne = compositeIndexDefinition.createSingleValue(keyParams.subList(0, keyParams.size() - 1));
 
       if (keyOne == null)
         return null;
 
-      final Object keyTwo = indexDefinition.createValue(keyParams);
+      final Object keyTwo = compositeIndexDefinition.createSingleValue(keyParams);
 
       if (keyTwo == null)
@@ -109,4 +112,6 @@ public class OQueryOperatorMinor extends OQueryOperatorEqualityNotNulls {
         OProfiler.getInstance().updateCounter(""Query.compositeIndexUsage"", 1);
         OProfiler.getInstance().updateCounter(""Query.compositeIndexUsage."" + indexDefinition.getParamCount(), 1);
+        OProfiler.getInstance().updateCounter(
+            ""Query.compositeIndexUsage."" + indexDefinition.getParamCount() + '.' + keyParams.size(), 1);
       }
     }
diff --git a/core/src/main/java/com/orientechnologies/orient/core/sql/operator/OQueryOperatorMinorEquals.java b/core/src/main/java/com/orientechnologies/orient/core/sql/operator/OQueryOperatorMinorEquals.java
index d9bed3fc5f..80cb554f2c 100644
--- a/core/src/main/java/com/orientechnologies/orient/core/sql/operator/OQueryOperatorMinorEquals.java
+++ b/core/src/main/java/com/orientechnologies/orient/core/sql/operator/OQueryOperatorMinorEquals.java
@@ -23,4 +23,5 @@ import com.orientechnologies.orient.core.command.OCommandContext;
 import com.orientechnologies.orient.core.db.record.OIdentifiable;
 import com.orientechnologies.orient.core.id.ORID;
+import com.orientechnologies.orient.core.index.OCompositeIndexDefinition;
 import com.orientechnologies.orient.core.index.OIndex;
 import com.orientechnologies.orient.core.index.OIndexDefinition;
@@ -91,10 +92,12 @@ public class OQueryOperatorMinorEquals extends OQueryOperatorEqualityNotNulls {
       // is the biggest composite key in the index that contains key with value field1=1 and field2=2.
 
-      final Object keyOne = indexDefinition.createValue(keyParams.subList(0, keyParams.size() - 1));
+      final OCompositeIndexDefinition compositeIndexDefinition = (OCompositeIndexDefinition) indexDefinition;
+
+      final Object keyOne = compositeIndexDefinition.createSingleValue(keyParams.subList(0, keyParams.size() - 1));
 
       if (keyOne == null)
         return null;
 
-      final Object keyTwo = indexDefinition.createValue(keyParams);
+      final Object keyTwo = compositeIndexDefinition.createSingleValue(keyParams);
 
       if (keyTwo == null)
@@ -109,4 +112,6 @@ public class OQueryOperatorMinorEquals extends OQueryOperatorEqualityNotNulls {
         OProfiler.getInstance().updateCounter(""Query.compositeIndexUsage"", 1);
         OProfiler.getInstance().updateCounter(""Query.compositeIndexUsage."" + indexDefinition.getParamCount(), 1);
+        OProfiler.getInstance().updateCounter(
+            ""Query.compositeIndexUsage."" + indexDefinition.getParamCount() + '.' + keyParams.size(), 1);
       }
     }
diff --git a/core/src/test/java/com/orientechnologies/orient/core/index/OCompositeIndexDefinitionTest.java b/core/src/test/java/com/orientechnologies/orient/core/index/OCompositeIndexDefinitionTest.java
index dda2cae105..c9752799bb 100644
--- a/core/src/test/java/com/orientechnologies/orient/core/index/OCompositeIndexDefinitionTest.java
+++ b/core/src/test/java/com/orientechnologies/orient/core/index/OCompositeIndexDefinitionTest.java
@@ -1,6 +1,10 @@
 package com.orientechnologies.orient.core.index;
 
+import java.util.ArrayList;
 import java.util.Arrays;
+import java.util.Collection;
+import java.util.HashMap;
 import java.util.List;
+import java.util.Map;
 
 import org.testng.Assert;
@@ -9,5 +13,11 @@ import org.testng.annotations.Test;
 
 import com.orientechnologies.common.collection.OCompositeKey;
+import com.orientechnologies.common.exception.OException;
 import com.orientechnologies.orient.core.db.document.ODatabaseDocumentTx;
+import com.orientechnologies.orient.core.db.record.OMultiValueChangeEvent;
+import com.orientechnologies.orient.core.db.record.OMultiValueChangeListener;
+import com.orientechnologies.orient.core.db.record.OTrackedList;
+import com.orientechnologies.orient.core.db.record.OTrackedMap;
+import com.orientechnologies.orient.core.db.record.OTrackedSet;
 import com.orientechnologies.orient.core.metadata.schema.OType;
 import com.orientechnologies.orient.core.record.impl.ODocument;
@@ -37,12 +47,95 @@ public class OCompositeIndexDefinitionTest {
   @Test
   public void testCreateValueSuccessful() {
-    final Comparable<?> result = compositeIndex.createValue(Arrays.asList(""12"", ""test""));
+    final Object result = compositeIndex.createValue(Arrays.asList(""12"", ""test""));
 
     Assert.assertEquals(result, new OCompositeKey(Arrays.asList(12, ""test"")));
   }
 
+  @Test
+  public void testCreateMapValueSuccessful() {
+    final OCompositeIndexDefinition compositeIndexDefinition = new OCompositeIndexDefinition(""testCollectionClass"");
+
+    compositeIndexDefinition.addIndex(new OPropertyIndexDefinition(""testCollectionClass"", ""fOne"", OType.INTEGER));
+    compositeIndexDefinition.addIndex(new OPropertyMapIndexDefinition(""testCollectionClass"", ""fTwo"", OType.STRING,
+        OPropertyMapIndexDefinition.INDEX_BY.KEY));
+
+    final Map<String, String> stringMap = new HashMap<String, String>();
+    stringMap.put(""key1"", ""val1"");
+    stringMap.put(""key2"", ""val2"");
+
+    final Object result = compositeIndexDefinition.createValue(12, stringMap);
+
+    final Collection<OCompositeKey> collectionResult = (Collection<OCompositeKey>) result;
+
+    Assert.assertEquals(collectionResult.size(), 2);
+    Assert.assertTrue(collectionResult.contains(new OCompositeKey(12, ""key1"")));
+    Assert.assertTrue(collectionResult.contains(new OCompositeKey(12, ""key2"")));
+  }
+
+  @Test
+  public void testCreateCollectionValueSuccessfulOne() {
+    final OCompositeIndexDefinition compositeIndexDefinition = new OCompositeIndexDefinition(""testCollectionClass"");
+
+    compositeIndexDefinition.addIndex(new OPropertyIndexDefinition(""testCollectionClass"", ""fOne"", OType.INTEGER));
+    compositeIndexDefinition.addIndex(new OPropertyListIndexDefinition(""testCollectionClass"", ""fTwo"", OType.INTEGER));
+
+    final Object result = compositeIndexDefinition.createValue(12, Arrays.asList(1, 2));
+
+    final ArrayList<OCompositeKey> expectedResult = new ArrayList<OCompositeKey>();
+
+    expectedResult.add(new OCompositeKey(12, 1));
+    expectedResult.add(new OCompositeKey(12, 2));
+
+    Assert.assertEquals(result, expectedResult);
+  }
+
+  @Test
+  public void testCreateCollectionValueSuccessfulTwo() {
+    final OCompositeIndexDefinition compositeIndexDefinition = new OCompositeIndexDefinition(""testCollectionClass"");
+
+    compositeIndexDefinition.addIndex(new OPropertyListIndexDefinition(""testCollectionClass"", ""fTwo"", OType.INTEGER));
+    compositeIndexDefinition.addIndex(new OPropertyIndexDefinition(""testCollectionClass"", ""fOne"", OType.INTEGER));
+
+    final Object result = compositeIndexDefinition.createValue(Arrays.asList(Arrays.asList(1, 2), 12));
+
+    final ArrayList<OCompositeKey> expectedResult = new ArrayList<OCompositeKey>();
+
+    expectedResult.add(new OCompositeKey(1, 12));
+    expectedResult.add(new OCompositeKey(2, 12));
+
+    Assert.assertEquals(result, expectedResult);
+  }
+
+  @Test
+  public void testCreateCollectionValueSuccessfulThree() {
+    final OCompositeIndexDefinition compositeIndexDefinition = new OCompositeIndexDefinition(""testCollectionClass"");
+
+    compositeIndexDefinition.addIndex(new OPropertyIndexDefinition(""testCollectionClass"", ""fOne"", OType.INTEGER));
+    compositeIndexDefinition.addIndex(new OPropertyListIndexDefinition(""testCollectionClass"", ""fTwo"", OType.INTEGER));
+    compositeIndexDefinition.addIndex(new OPropertyIndexDefinition(""testCollectionClass"", ""fThree"", OType.STRING));
+
+    final Object result = compositeIndexDefinition.createValue(12, Arrays.asList(1, 2), ""test"");
+
+    final ArrayList<OCompositeKey> expectedResult = new ArrayList<OCompositeKey>();
+
+    expectedResult.add(new OCompositeKey(12, 1, ""test""));
+    expectedResult.add(new OCompositeKey(12, 2, ""test""));
+
+    Assert.assertEquals(result, expectedResult);
+  }
+
+  @Test(expectedExceptions = OIndexException.class)
+  public void testCreateCollectionValueTwoCollections() {
+    final OCompositeIndexDefinition compositeIndexDefinition = new OCompositeIndexDefinition(""testCollectionClass"");
+
+    compositeIndexDefinition.addIndex(new OPropertyListIndexDefinition(""testCollectionClass"", ""fTwo"", OType.INTEGER));
+    compositeIndexDefinition.addIndex(new OPropertyListIndexDefinition(""testCollectionClass"", ""fOne"", OType.INTEGER));
+
+    compositeIndexDefinition.createValue(Arrays.asList(1, 2), Arrays.asList(12));
+  }
+
   @Test
   public void testCreateValueWrongParam() {
-    final Comparable<?> result = compositeIndex.createValue(Arrays.asList(""1t2"", ""test""));
+    final Object result = compositeIndex.createValue(Arrays.asList(""1t2"", ""test""));
     Assert.assertNull(result);
   }
@@ -93,4 +186,111 @@ public class OCompositeIndexDefinitionTest {
   }
 
+  @Test
+  public void testDocumentToIndexMapValueSuccessful() {
+    final ODocument document = new ODocument();
+
+    final Map<String, String> stringMap = new HashMap<String, String>();
+    stringMap.put(""key1"", ""val1"");
+    stringMap.put(""key2"", ""val2"");
+
+    document.field(""fOne"", 12);
+    document.field(""fTwo"", stringMap);
+
+    final OCompositeIndexDefinition compositeIndexDefinition = new OCompositeIndexDefinition(""testCollectionClass"");
+
+    compositeIndexDefinition.addIndex(new OPropertyIndexDefinition(""testCollectionClass"", ""fOne"", OType.INTEGER));
+    compositeIndexDefinition.addIndex(new OPropertyMapIndexDefinition(""testCollectionClass"", ""fTwo"", OType.STRING,
+        OPropertyMapIndexDefinition.INDEX_BY.KEY));
+
+    final Object result = compositeIndexDefinition.getDocumentValueToIndex(document);
+    final Collection<OCompositeKey> collectionResult = (Collection<OCompositeKey>) result;
+
+    Assert.assertEquals(collectionResult.size(), 2);
+    Assert.assertTrue(collectionResult.contains(new OCompositeKey(12, ""key1"")));
+    Assert.assertTrue(collectionResult.contains(new OCompositeKey(12, ""key2"")));
+  }
+
+  @Test
+  public void testDocumentToIndexCollectionValueSuccessfulOne() {
+    final ODocument document = new ODocument();
+
+    document.field(""fOne"", 12);
+    document.field(""fTwo"", Arrays.asList(1, 2));
+
+    final OCompositeIndexDefinition compositeIndexDefinition = new OCompositeIndexDefinition(""testCollectionClass"");
+
+    compositeIndexDefinition.addIndex(new OPropertyIndexDefinition(""testCollectionClass"", ""fOne"", OType.INTEGER));
+    compositeIndexDefinition.addIndex(new OPropertyListIndexDefinition(""testCollectionClass"", ""fTwo"", OType.INTEGER));
+
+    final Object result = compositeIndexDefinition.getDocumentValueToIndex(document);
+
+    final ArrayList<OCompositeKey> expectedResult = new ArrayList<OCompositeKey>();
+
+    expectedResult.add(new OCompositeKey(12, 1));
+    expectedResult.add(new OCompositeKey(12, 2));
+
+    Assert.assertEquals(result, expectedResult);
+  }
+
+  @Test
+  public void testDocumentToIndexCollectionValueSuccessfulTwo() {
+    final ODocument document = new ODocument();
+
+    document.field(""fOne"", 12);
+    document.field(""fTwo"", Arrays.asList(1, 2));
+
+    final OCompositeIndexDefinition compositeIndexDefinition = new OCompositeIndexDefinition(""testCollectionClass"");
+
+    compositeIndexDefinition.addIndex(new OPropertyListIndexDefinition(""testCollectionClass"", ""fTwo"", OType.INTEGER));
+    compositeIndexDefinition.addIndex(new OPropertyIndexDefinition(""testCollectionClass"", ""fOne"", OType.INTEGER));
+
+    final Object result = compositeIndexDefinition.getDocumentValueToIndex(document);
+
+    final ArrayList<OCompositeKey> expectedResult = new ArrayList<OCompositeKey>();
+
+    expectedResult.add(new OCompositeKey(1, 12));
+    expectedResult.add(new OCompositeKey(2, 12));
+
+    Assert.assertEquals(result, expectedResult);
+  }
+
+  @Test
+  public void testDocumentToIndexCollectionValueSuccessfulThree() {
+    final ODocument document = new ODocument();
+
+    document.field(""fOne"", 12);
+    document.field(""fTwo"", Arrays.asList(1, 2));
+    document.field(""fThree"", ""test"");
+
+    final OCompositeIndexDefinition compositeIndexDefinition = new OCompositeIndexDefinition(""testCollectionClass"");
+
+    compositeIndexDefinition.addIndex(new OPropertyIndexDefinition(""testCollectionClass"", ""fOne"", OType.INTEGER));
+    compositeIndexDefinition.addIndex(new OPropertyListIndexDefinition(""testCollectionClass"", ""fTwo"", OType.INTEGER));
+    compositeIndexDefinition.addIndex(new OPropertyIndexDefinition(""testCollectionClass"", ""fThree"", OType.STRING));
+
+    final Object result = compositeIndexDefinition.getDocumentValueToIndex(document);
+
+    final ArrayList<OCompositeKey> expectedResult = new ArrayList<OCompositeKey>();
+
+    expectedResult.add(new OCompositeKey(12, 1, ""test""));
+    expectedResult.add(new OCompositeKey(12, 2, ""test""));
+
+    Assert.assertEquals(result, expectedResult);
+  }
+
+  @Test(expectedExceptions = OException.class)
+  public void testDocumentToIndexCollectionValueTwoCollections() {
+    final ODocument document = new ODocument();
+
+    document.field(""fOne"", Arrays.asList(12));
+    document.field(""fTwo"", Arrays.asList(1, 2));
+
+    final OCompositeIndexDefinition compositeIndexDefinition = new OCompositeIndexDefinition(""testCollectionClass"");
+
+    compositeIndexDefinition.addIndex(new OPropertyListIndexDefinition(""testCollectionClass"", ""fOne"", OType.INTEGER));
+    compositeIndexDefinition.addIndex(new OPropertyListIndexDefinition(""testCollectionClass"", ""fTwo"", OType.INTEGER));
+    compositeIndexDefinition.getDocumentValueToIndex(document);
+  }
+
   @Test
   public void testDocumentToIndexWrongField() {
@@ -180,4 +380,244 @@ public class OCompositeIndexDefinitionTest {
   }
 
+  public void testProcessChangeListEventsOne() {
+    final OCompositeIndexDefinition compositeIndexDefinition = new OCompositeIndexDefinition();
+
+    compositeIndexDefinition.addIndex(new OPropertyIndexDefinition(""testCollectionClass"", ""fOne"", OType.INTEGER));
+    compositeIndexDefinition.addIndex(new OPropertyListIndexDefinition(""testCollectionClass"", ""fTwo"", OType.STRING));
+    compositeIndexDefinition.addIndex(new OPropertyIndexDefinition(""testCollectionClass"", ""fThree"", OType.INTEGER));
+
+    final ODocument doc = new ODocument();
+    doc.unsetDirty();
+    Assert.assertFalse(doc.isDirty());
+
+    final OTrackedList<String> trackedList = new OTrackedList<String>(doc);
+    final List<OMultiValueChangeEvent<Integer, String>> firedEvents = new ArrayList<OMultiValueChangeEvent<Integer, String>>();
+
+    trackedList.addChangeListener(new OMultiValueChangeListener<Integer, String>() {
+      public void onAfterRecordChanged(final OMultiValueChangeEvent<Integer, String> event) {
+        firedEvents.add(event);
+      }
+    });
+
+    trackedList.add(""l1"");
+    trackedList.add(""l2"");
+    trackedList.add(""l3"");
+    trackedList.remove(""l2"");
+
+    Map<OCompositeKey, Integer> keysToAdd = new HashMap<OCompositeKey, Integer>();
+    Map<OCompositeKey, Integer> keysToRemove = new HashMap<OCompositeKey, Integer>();
+
+    for (OMultiValueChangeEvent<Integer, String> multiValueChangeEvent : firedEvents)
+      compositeIndexDefinition.processChangeEvent(multiValueChangeEvent, keysToAdd, keysToRemove, 2, 3);
+
+    Assert.assertEquals(keysToRemove.size(), 0);
+    Assert.assertEquals(keysToAdd.size(), 2);
+
+    Assert.assertTrue(keysToAdd.containsKey(new OCompositeKey(2, ""l1"", 3)));
+    Assert.assertTrue(keysToAdd.containsKey(new OCompositeKey(2, ""l3"", 3)));
+  }
+
+  public void testProcessChangeListEventsTwo() {
+    final OCompositeIndexDefinition compositeIndexDefinition = new OCompositeIndexDefinition();
+
+    compositeIndexDefinition.addIndex(new OPropertyIndexDefinition(""testCollectionClass"", ""fOne"", OType.INTEGER));
+    compositeIndexDefinition.addIndex(new OPropertyListIndexDefinition(""testCollectionClass"", ""fTwo"", OType.STRING));
+    compositeIndexDefinition.addIndex(new OPropertyIndexDefinition(""testCollectionClass"", ""fThree"", OType.INTEGER));
+
+    final ODocument doc = new ODocument();
+    doc.unsetDirty();
+    Assert.assertFalse(doc.isDirty());
+
+    final OTrackedList<String> trackedList = new OTrackedList<String>(doc);
+    final List<OMultiValueChangeEvent<Integer, String>> firedEvents = new ArrayList<OMultiValueChangeEvent<Integer, String>>();
+
+    trackedList.add(""l1"");
+    trackedList.add(""l2"");
+    trackedList.add(""l3"");
+    trackedList.remove(""l2"");
+
+    trackedList.addChangeListener(new OMultiValueChangeListener<Integer, String>() {
+      public void onAfterRecordChanged(final OMultiValueChangeEvent<Integer, String> event) {
+        firedEvents.add(event);
+      }
+    });
+
+    trackedList.add(""l4"");
+    trackedList.remove(""l1"");
+
+    Map<OCompositeKey, Integer> keysToAdd = new HashMap<OCompositeKey, Integer>();
+    Map<OCompositeKey, Integer> keysToRemove = new HashMap<OCompositeKey, Integer>();
+
+    for (OMultiValueChangeEvent<Integer, String> multiValueChangeEvent : firedEvents)
+      compositeIndexDefinition.processChangeEvent(multiValueChangeEvent, keysToAdd, keysToRemove, 2, 3);
+
+    Assert.assertEquals(keysToRemove.size(), 1);
+    Assert.assertEquals(keysToAdd.size(), 1);
+
+    Assert.assertTrue(keysToAdd.containsKey(new OCompositeKey(2, ""l4"", 3)));
+    Assert.assertTrue(keysToRemove.containsKey(new OCompositeKey(2, ""l1"", 3)));
+  }
+
+  public void testProcessChangeSetEventsOne() {
+    final OCompositeIndexDefinition compositeIndexDefinition = new OCompositeIndexDefinition();
+
+    compositeIndexDefinition.addIndex(new OPropertyIndexDefinition(""testCollectionClass"", ""fOne"", OType.INTEGER));
+    compositeIndexDefinition.addIndex(new OPropertyListIndexDefinition(""testCollectionClass"", ""fTwo"", OType.STRING));
+    compositeIndexDefinition.addIndex(new OPropertyIndexDefinition(""testCollectionClass"", ""fThree"", OType.INTEGER));
+
+    final ODocument doc = new ODocument();
+    doc.unsetDirty();
+    Assert.assertFalse(doc.isDirty());
+
+    final OTrackedSet<String> trackedSet = new OTrackedSet<String>(doc);
+    final List<OMultiValueChangeEvent<String, String>> firedEvents = new ArrayList<OMultiValueChangeEvent<String, String>>();
+
+    trackedSet.addChangeListener(new OMultiValueChangeListener<String, String>() {
+      public void onAfterRecordChanged(final OMultiValueChangeEvent<String, String> event) {
+        firedEvents.add(event);
+      }
+    });
+
+    trackedSet.add(""l1"");
+    trackedSet.add(""l2"");
+    trackedSet.add(""l3"");
+    trackedSet.remove(""l2"");
+
+    Map<OCompositeKey, Integer> keysToAdd = new HashMap<OCompositeKey, Integer>();
+    Map<OCompositeKey, Integer> keysToRemove = new HashMap<OCompositeKey, Integer>();
+
+    for (OMultiValueChangeEvent<String, String> multiValueChangeEvent : firedEvents)
+      compositeIndexDefinition.processChangeEvent(multiValueChangeEvent, keysToAdd, keysToRemove, 2, 3);
+
+    Assert.assertEquals(keysToRemove.size(), 0);
+    Assert.assertEquals(keysToAdd.size(), 2);
+
+    Assert.assertTrue(keysToAdd.containsKey(new OCompositeKey(2, ""l1"", 3)));
+    Assert.assertTrue(keysToAdd.containsKey(new OCompositeKey(2, ""l3"", 3)));
+  }
+
+  public void testProcessChangeSetEventsTwo() {
+    final OCompositeIndexDefinition compositeIndexDefinition = new OCompositeIndexDefinition();
+
+    compositeIndexDefinition.addIndex(new OPropertyIndexDefinition(""testCollectionClass"", ""fOne"", OType.INTEGER));
+    compositeIndexDefinition.addIndex(new OPropertyListIndexDefinition(""testCollectionClass"", ""fTwo"", OType.STRING));
+    compositeIndexDefinition.addIndex(new OPropertyIndexDefinition(""testCollectionClass"", ""fThree"", OType.INTEGER));
+
+    final ODocument doc = new ODocument();
+    doc.unsetDirty();
+    Assert.assertFalse(doc.isDirty());
+
+    final OTrackedSet<String> trackedMap = new OTrackedSet<String>(doc);
+    final List<OMultiValueChangeEvent<String, String>> firedEvents = new ArrayList<OMultiValueChangeEvent<String, String>>();
+
+    trackedMap.add(""l1"");
+    trackedMap.add(""l2"");
+    trackedMap.add(""l3"");
+    trackedMap.remove(""l2"");
+
+    trackedMap.addChangeListener(new OMultiValueChangeListener<String, String>() {
+      public void onAfterRecordChanged(final OMultiValueChangeEvent<String, String> event) {
+        firedEvents.add(event);
+      }
+    });
+
+    trackedMap.add(""l4"");
+    trackedMap.remove(""l1"");
+
+    Map<OCompositeKey, Integer> keysToAdd = new HashMap<OCompositeKey, Integer>();
+    Map<OCompositeKey, Integer> keysToRemove = new HashMap<OCompositeKey, Integer>();
+
+    for (OMultiValueChangeEvent<String, String> multiValueChangeEvent : firedEvents)
+      compositeIndexDefinition.processChangeEvent(multiValueChangeEvent, keysToAdd, keysToRemove, 2, 3);
+
+    Assert.assertEquals(keysToRemove.size(), 1);
+    Assert.assertEquals(keysToAdd.size(), 1);
+
+    Assert.assertTrue(keysToAdd.containsKey(new OCompositeKey(2, ""l4"", 3)));
+    Assert.assertTrue(keysToRemove.containsKey(new OCompositeKey(2, ""l1"", 3)));
+  }
+
+  public void testProcessChangeKeyMapEventsOne() {
+    final OCompositeIndexDefinition compositeIndexDefinition = new OCompositeIndexDefinition();
+
+    compositeIndexDefinition.addIndex(new OPropertyIndexDefinition(""testCollectionClass"", ""fOne"", OType.INTEGER));
+    compositeIndexDefinition.addIndex(new OPropertyMapIndexDefinition(""testCollectionClass"", ""fTwo"", OType.STRING,
+        OPropertyMapIndexDefinition.INDEX_BY.KEY));
+    compositeIndexDefinition.addIndex(new OPropertyIndexDefinition(""testCollectionClass"", ""fThree"", OType.INTEGER));
+
+    final ODocument doc = new ODocument();
+    doc.unsetDirty();
+    Assert.assertFalse(doc.isDirty());
+
+    final OTrackedMap<String> trackedMap = new OTrackedMap<String>(doc);
+    final List<OMultiValueChangeEvent<Object, String>> firedEvents = new ArrayList<OMultiValueChangeEvent<Object, String>>();
+
+    trackedMap.addChangeListener(new OMultiValueChangeListener<Object, String>() {
+      public void onAfterRecordChanged(final OMultiValueChangeEvent<Object, String> event) {
+        firedEvents.add(event);
+      }
+    });
+
+    trackedMap.put(""k1"", ""v1"");
+    trackedMap.put(""k2"", ""v2"");
+    trackedMap.put(""k3"", ""v3"");
+    trackedMap.remove(""k2"");
+
+    Map<OCompositeKey, Integer> keysToAdd = new HashMap<OCompositeKey, Integer>();
+    Map<OCompositeKey, Integer> keysToRemove = new HashMap<OCompositeKey, Integer>();
+
+    for (OMultiValueChangeEvent<Object, String> multiValueChangeEvent : firedEvents)
+      compositeIndexDefinition.processChangeEvent(multiValueChangeEvent, keysToAdd, keysToRemove, 2, 3);
+
+    Assert.assertEquals(keysToRemove.size(), 0);
+    Assert.assertEquals(keysToAdd.size(), 2);
+
+    Assert.assertTrue(keysToAdd.containsKey(new OCompositeKey(2, ""k1"", 3)));
+    Assert.assertTrue(keysToAdd.containsKey(new OCompositeKey(2, ""k3"", 3)));
+  }
+
+  public void testProcessChangeKeyMapEventsTwo() {
+    final OCompositeIndexDefinition compositeIndexDefinition = new OCompositeIndexDefinition();
+
+    compositeIndexDefinition.addIndex(new OPropertyIndexDefinition(""testCollectionClass"", ""fOne"", OType.INTEGER));
+    compositeIndexDefinition.addIndex(new OPropertyMapIndexDefinition(""testCollectionClass"", ""fTwo"", OType.STRING,
+        OPropertyMapIndexDefinition.INDEX_BY.KEY));
+    compositeIndexDefinition.addIndex(new OPropertyIndexDefinition(""testCollectionClass"", ""fThree"", OType.INTEGER));
+
+    final ODocument doc = new ODocument();
+    doc.unsetDirty();
+    Assert.assertFalse(doc.isDirty());
+
+    final OTrackedMap<String> trackedMap = new OTrackedMap<String>(doc);
+
+    trackedMap.put(""k1"", ""v1"");
+    trackedMap.put(""k2"", ""v2"");
+    trackedMap.put(""k3"", ""v3"");
+    trackedMap.remove(""k2"");
+
+    final List<OMultiValueChangeEvent<Object, String>> firedEvents = new ArrayList<OMultiValueChangeEvent<Object, String>>();
+
+    trackedMap.addChangeListener(new OMultiValueChangeListener<Object, String>() {
+      public void onAfterRecordChanged(final OMultiValueChangeEvent<Object, String> event) {
+        firedEvents.add(event);
+      }
+    });
+
+    trackedMap.put(""k4"", ""v4"");
+    trackedMap.remove(""k1"");
+
+    Map<OCompositeKey, Integer> keysToAdd = new HashMap<OCompositeKey, Integer>();
+    Map<OCompositeKey, Integer> keysToRemove = new HashMap<OCompositeKey, Integer>();
+
+    for (OMultiValueChangeEvent<Object, String> multiValueChangeEvent : firedEvents)
+      compositeIndexDefinition.processChangeEvent(multiValueChangeEvent, keysToAdd, keysToRemove, 2, 3);
+
+    Assert.assertEquals(keysToRemove.size(), 1);
+    Assert.assertEquals(keysToAdd.size(), 1);
+
+    Assert.assertTrue(keysToAdd.containsKey(new OCompositeKey(2, ""k4"", 3)));
+    Assert.assertTrue(keysToRemove.containsKey(new OCompositeKey(2, ""k1"", 3)));
+  }
+
   @Test
   public void testClassName() {
diff --git a/tests/src/test/java/com/orientechnologies/orient/test/database/auto/ClassIndexManagerTest.java b/tests/src/test/java/com/orientechnologies/orient/test/database/auto/ClassIndexManagerTest.java
index f6a09dfbf0..4cf2f5fa93 100644
--- a/tests/src/test/java/com/orientechnologies/orient/test/database/auto/ClassIndexManagerTest.java
+++ b/tests/src/test/java/com/orientechnologies/orient/test/database/auto/ClassIndexManagerTest.java
@@ -2,4 +2,5 @@ package com.orientechnologies.orient.test.database.auto;
 
 import java.util.ArrayList;
+import java.util.Arrays;
 import java.util.Collection;
 import java.util.HashMap;
@@ -17,4 +18,5 @@ import org.testng.annotations.Parameters;
 import org.testng.annotations.Test;
 
+import com.orientechnologies.common.collection.OCompositeKey;
 import com.orientechnologies.orient.core.db.document.ODatabaseDocumentTx;
 import com.orientechnologies.orient.core.index.OIndex;
@@ -30,838 +32,1274 @@ import com.orientechnologies.orient.core.sql.OCommandSQL;
 @Test(groups = { ""index"" })
 public class ClassIndexManagerTest {
-	private final ODatabaseDocumentTx	database;
-
-	@Parameters(value = ""url"")
-	public ClassIndexManagerTest(final String iURL) {
-		database = new ODatabaseDocumentTx(iURL);
-	}
-
-	@BeforeClass
-	public void beforeClass() {
-		if (database.isClosed())
-			database.open(""admin"", ""admin"");
-
-		final OSchema schema = database.getMetadata().getSchema();
-		final OClass superClass = schema.createClass(""classIndexManagerTestSuperClass"");
-		final OProperty propertyZero = superClass.createProperty(""prop0"", OType.STRING);
-		propertyZero.createIndex(OClass.INDEX_TYPE.UNIQUE);
-
-		final OClass oClass = schema.createClass(""classIndexManagerTestClass"", superClass);
-		final OProperty propOne = oClass.createProperty(""prop1"", OType.STRING);
-		propOne.createIndex(OClass.INDEX_TYPE.UNIQUE);
-
-		final OProperty propTwo = oClass.createProperty(""prop2"", OType.INTEGER);
-		propTwo.createIndex(OClass.INDEX_TYPE.NOTUNIQUE);
-
-		oClass.createProperty(""prop3"", OType.BOOLEAN);
-
-		final OProperty propFour = oClass.createProperty(""prop4"", OType.EMBEDDEDLIST, OType.STRING);
-		propFour.createIndex(OClass.INDEX_TYPE.NOTUNIQUE);
-
-		oClass.createProperty(""prop5"", OType.EMBEDDEDMAP, OType.STRING);
-		oClass.createIndex(""classIndexManagerTestIndexByKey"", OClass.INDEX_TYPE.NOTUNIQUE, ""prop5"");
-		oClass.createIndex(""classIndexManagerTestIndexByValue"", OClass.INDEX_TYPE.NOTUNIQUE, ""prop5 by value"");
-
-		final OProperty propSix = oClass.createProperty(""prop6"", OType.EMBEDDEDSET, OType.STRING);
-		propSix.createIndex(OClass.INDEX_TYPE.NOTUNIQUE);
-
-		oClass.createIndex(""classIndexManagerComposite"", OClass.INDEX_TYPE.UNIQUE, ""prop1"", ""prop2"");
-
-		final OClass oClassTwo = schema.createClass(""classIndexManagerTestClassTwo"");
-		oClassTwo.createProperty(""prop1"", OType.STRING);
-		oClassTwo.createProperty(""prop2"", OType.INTEGER);
-
-		schema.save();
-
-		database.close();
-	}
-
-	@BeforeMethod
-	public void beforeMethod() {
-		if (database.isClosed())
-			database.open(""admin"", ""admin"");
-	}
-
-	@AfterMethod
-	public void afterMethod() {
-		database.command(new OCommandSQL(""delete from classIndexManagerTestClass"")).execute();
-		database.command(new OCommandSQL(""delete from classIndexManagerTestClassTwo"")).execute();
-		database.command(new OCommandSQL(""delete from classIndexManagerTestSuperClass"")).execute();
-		database.close();
-	}
-
-	@AfterClass
-	public void afterClass() {
-		if (database.isClosed())
-			database.open(""admin"", ""admin"");
-		database.command(new OCommandSQL(""drop class classIndexManagerTestClass"")).execute();
-		database.command(new OCommandSQL(""drop class classIndexManagerTestClassTwo"")).execute();
-		database.command(new OCommandSQL(""drop class classIndexManagerTestSuperClass"")).execute();
-		database.getMetadata().getSchema().reload();
-		database.getLevel2Cache().clear();
-		database.close();
-	}
-
-	public void testPropertiesCheckUniqueIndexDubKeysCreate() {
-		final ODocument docOne = new ODocument(""classIndexManagerTestClass"");
-		final ODocument docTwo = new ODocument(""classIndexManagerTestClass"");
-
-		docOne.field(""prop1"", ""a"");
-		docOne.save();
-
-		boolean exceptionThrown = false;
-		try {
-			docTwo.field(""prop1"", ""a"");
-			docTwo.save();
-		} catch (OIndexException e) {
-			exceptionThrown = true;
-		}
-		Assert.assertTrue(exceptionThrown);
-	}
-
-	public void testPropertiesCheckUniqueIndexDubKeyIsNullCreate() {
-		final ODocument docOne = new ODocument(""classIndexManagerTestClass"");
-		final ODocument docTwo = new ODocument(""classIndexManagerTestClass"");
-
-		docOne.field(""prop1"", ""a"");
-		docOne.save();
-
-  	docTwo.field(""prop1"", (String)null);
-		docTwo.save();
-	}
-
-	public void testPropertiesCheckUniqueIndexDubKeyIsNullCreateInTx() {
-		final ODocument docOne = new ODocument(""classIndexManagerTestClass"");
-		final ODocument docTwo = new ODocument(""classIndexManagerTestClass"");
-
-		database.begin();
-		docOne.field(""prop1"", ""a"");
-		docOne.save();
-
-		docTwo.field(""prop1"", (String)null);
-		docTwo.save();
-		database.commit();
-	}
-
-	public void testPropertiesCheckUniqueIndexInParentDubKeysCreate() {
-		final ODocument docOne = new ODocument(""classIndexManagerTestClass"");
-		final ODocument docTwo = new ODocument(""classIndexManagerTestClass"");
-
-		docOne.field(""prop0"", ""a"");
-		docOne.save();
-
-		boolean exceptionThrown = false;
-		try {
-			docTwo.field(""prop0"", ""a"");
-			docTwo.save();
-		} catch (OIndexException e) {
-			exceptionThrown = true;
-		}
-		Assert.assertTrue(exceptionThrown);
-	}
-
-	public void testPropertiesCheckUniqueIndexDubKeysUpdate() {
-		final ODocument docOne = new ODocument(""classIndexManagerTestClass"");
-		final ODocument docTwo = new ODocument(""classIndexManagerTestClass"");
-
-		boolean exceptionThrown = false;
-		docOne.field(""prop1"", ""a"");
-		docOne.save();
-
-		docTwo.field(""prop1"", ""b"");
-		docTwo.save();
-
-		try {
-			docTwo.field(""prop1"", ""a"");
-			docTwo.save();
-		} catch (OIndexException e) {
-			exceptionThrown = true;
-		}
-		Assert.assertTrue(exceptionThrown);
-	}
-
-	public void testPropertiesCheckUniqueIndexDubKeyIsNullUpdate() {
-		final ODocument docOne = new ODocument(""classIndexManagerTestClass"");
-		final ODocument docTwo = new ODocument(""classIndexManagerTestClass"");
-
-		docOne.field(""prop1"", ""a"");
-		docOne.save();
-
-		docTwo.field(""prop1"", ""b"");
-		docTwo.save();
-
-		docTwo.field(""prop1"", (String)null);
-		docTwo.save();
-	}
-
-	public void testPropertiesCheckUniqueIndexDubKeyIsNullUpdateInTX() {
-		final ODocument docOne = new ODocument(""classIndexManagerTestClass"");
-		final ODocument docTwo = new ODocument(""classIndexManagerTestClass"");
-
-		database.begin();
-		docOne.field(""prop1"", ""a"");
-		docOne.save();
-
-		docTwo.field(""prop1"", ""b"");
-		docTwo.save();
-
-		docTwo.field(""prop1"", (String)null);
-		docTwo.save();
-		database.commit();
-	}
-
-	public void testPropertiesCheckNonUniqueIndexDubKeys() {
-		final ODocument docOne = new ODocument(""classIndexManagerTestClass"");
-		docOne.field(""prop2"", 1);
-		docOne.save();
-
-		final ODocument docTwo = new ODocument(""classIndexManagerTestClass"");
-		docTwo.field(""prop2"", 1);
-		docTwo.save();
-	}
-
-	public void testPropertiesCheckUniqueNullKeys() {
-		final ODocument docOne = new ODocument(""classIndexManagerTestClass"");
-		docOne.field(""prop3"", ""a"");
-		docOne.save();
-
-		final ODocument docTwo = new ODocument(""classIndexManagerTestClass"");
-		docTwo.field(""prop3"", ""a"");
-		docTwo.save();
-	}
-
-	public void testCreateDocumentWithoutClass() {
-		final Collection<? extends OIndex<?>> beforeIndexes = database.getMetadata().getIndexManager().getIndexes();
-		final Map<String, Long> indexSizeMap = new HashMap<String, Long>();
-
-		for (final OIndex<?> index : beforeIndexes)
-			indexSizeMap.put(index.getName(), index.getSize());
-
-		final ODocument docOne = new ODocument();
-		docOne.field(""prop1"", ""a"");
-		docOne.save();
-
-		final ODocument docTwo = new ODocument();
-		docTwo.field(""prop1"", ""a"");
-		docTwo.save();
-
-		final Collection<? extends OIndex<?>> afterIndexes = database.getMetadata().getIndexManager().getIndexes();
-		for (final OIndex<?> index : afterIndexes)
-			Assert.assertEquals(index.getSize(), indexSizeMap.get(index.getName()).longValue());
-	}
-
-	public void testUpdateDocumentWithoutClass() {
-		final Collection<? extends OIndex<?>> beforeIndexes = database.getMetadata().getIndexManager().getIndexes();
-		final Map<String, Long> indexSizeMap = new HashMap<String, Long>();
-
-		for (final OIndex<?> index : beforeIndexes)
-			indexSizeMap.put(index.getName(), index.getSize());
-
-		final ODocument docOne = new ODocument();
-		docOne.field(""prop1"", ""a"");
-		docOne.save();
-
-		final ODocument docTwo = new ODocument();
-		docTwo.field(""prop1"", ""b"");
-		docTwo.save();
+  private final ODatabaseDocumentTx database;
+
+  @Parameters(value = ""url"")
+  public ClassIndexManagerTest(final String iURL) {
+    database = new ODatabaseDocumentTx(iURL);
+  }
+
+  @BeforeClass
+  public void beforeClass() {
+    if (database.isClosed())
+      database.open(""admin"", ""admin"");
+
+    final OSchema schema = database.getMetadata().getSchema();
+    final OClass superClass = schema.createClass(""classIndexManagerTestSuperClass"");
+    final OProperty propertyZero = superClass.createProperty(""prop0"", OType.STRING);
+    propertyZero.createIndex(OClass.INDEX_TYPE.UNIQUE);
+
+    final OClass oClass = schema.createClass(""classIndexManagerTestClass"", superClass);
+    final OProperty propOne = oClass.createProperty(""prop1"", OType.STRING);
+    propOne.createIndex(OClass.INDEX_TYPE.UNIQUE);
+
+    final OProperty propTwo = oClass.createProperty(""prop2"", OType.INTEGER);
+    propTwo.createIndex(OClass.INDEX_TYPE.NOTUNIQUE);
+
+    oClass.createProperty(""prop3"", OType.BOOLEAN);
+
+    final OProperty propFour = oClass.createProperty(""prop4"", OType.EMBEDDEDLIST, OType.STRING);
+    propFour.createIndex(OClass.INDEX_TYPE.NOTUNIQUE);
+
+    oClass.createProperty(""prop5"", OType.EMBEDDEDMAP, OType.STRING);
+    oClass.createIndex(""classIndexManagerTestIndexByKey"", OClass.INDEX_TYPE.NOTUNIQUE, ""prop5"");
+    oClass.createIndex(""classIndexManagerTestIndexByValue"", OClass.INDEX_TYPE.NOTUNIQUE, ""prop5 by value"");
+
+    final OProperty propSix = oClass.createProperty(""prop6"", OType.EMBEDDEDSET, OType.STRING);
+    propSix.createIndex(OClass.INDEX_TYPE.NOTUNIQUE);
+
+    oClass.createIndex(""classIndexManagerComposite"", OClass.INDEX_TYPE.UNIQUE, ""prop1"", ""prop2"");
+
+    final OClass oClassTwo = schema.createClass(""classIndexManagerTestClassTwo"");
+    oClassTwo.createProperty(""prop1"", OType.STRING);
+    oClassTwo.createProperty(""prop2"", OType.INTEGER);
+
+    final OClass compositeCollectionClass = schema.createClass(""classIndexManagerTestCompositeCollectionClass"");
+    compositeCollectionClass.createProperty(""prop1"", OType.STRING);
+    compositeCollectionClass.createProperty(""prop2"", OType.EMBEDDEDLIST, OType.INTEGER);
+
+    compositeCollectionClass
+        .createIndex(""classIndexManagerTestIndexValueAndCollection"", OClass.INDEX_TYPE.UNIQUE, ""prop1"", ""prop2"");
+
+    schema.save();
+
+    database.close();
+  }
+
+  @BeforeMethod
+  public void beforeMethod() {
+    if (database.isClosed())
+      database.open(""admin"", ""admin"");
+  }
+
+  @AfterMethod
+  public void afterMethod() {
+    database.command(new OCommandSQL(""delete from classIndexManagerTestClass"")).execute();
+    database.command(new OCommandSQL(""delete from classIndexManagerTestClassTwo"")).execute();
+    database.command(new OCommandSQL(""delete from classIndexManagerTestSuperClass"")).execute();
+    database.close();
+  }
+
+  @AfterClass
+  public void afterClass() {
+    if (database.isClosed())
+      database.open(""admin"", ""admin"");
+    database.command(new OCommandSQL(""drop class classIndexManagerTestClass"")).execute();
+    database.command(new OCommandSQL(""drop class classIndexManagerTestClassTwo"")).execute();
+    database.command(new OCommandSQL(""drop class classIndexManagerTestSuperClass"")).execute();
+    database.getMetadata().getSchema().reload();
+    database.getLevel2Cache().clear();
+    database.close();
+  }
+
+  public void testPropertiesCheckUniqueIndexDubKeysCreate() {
+    final ODocument docOne = new ODocument(""classIndexManagerTestClass"");
+    final ODocument docTwo = new ODocument(""classIndexManagerTestClass"");
+
+    docOne.field(""prop1"", ""a"");
+    docOne.save();
+
+    boolean exceptionThrown = false;
+    try {
+      docTwo.field(""prop1"", ""a"");
+      docTwo.save();
+    } catch (OIndexException e) {
+      exceptionThrown = true;
+    }
+    Assert.assertTrue(exceptionThrown);
+  }
+
+  public void testPropertiesCheckUniqueIndexDubKeyIsNullCreate() {
+    final ODocument docOne = new ODocument(""classIndexManagerTestClass"");
+    final ODocument docTwo = new ODocument(""classIndexManagerTestClass"");
+
+    docOne.field(""prop1"", ""a"");
+    docOne.save();
+
+    docTwo.field(""prop1"", (String) null);
+    docTwo.save();
+  }
+
+  public void testPropertiesCheckUniqueIndexDubKeyIsNullCreateInTx() {
+    final ODocument docOne = new ODocument(""classIndexManagerTestClass"");
+    final ODocument docTwo = new ODocument(""classIndexManagerTestClass"");
+
+    database.begin();
+    docOne.field(""prop1"", ""a"");
+    docOne.save();
+
+    docTwo.field(""prop1"", (String) null);
+    docTwo.save();
+    database.commit();
+  }
+
+  public void testPropertiesCheckUniqueIndexInParentDubKeysCreate() {
+    final ODocument docOne = new ODocument(""classIndexManagerTestClass"");
+    final ODocument docTwo = new ODocument(""classIndexManagerTestClass"");
+
+    docOne.field(""prop0"", ""a"");
+    docOne.save();
+
+    boolean exceptionThrown = false;
+    try {
+      docTwo.field(""prop0"", ""a"");
+      docTwo.save();
+    } catch (OIndexException e) {
+      exceptionThrown = true;
+    }
+    Assert.assertTrue(exceptionThrown);
+  }
+
+  public void testPropertiesCheckUniqueIndexDubKeysUpdate() {
+    final ODocument docOne = new ODocument(""classIndexManagerTestClass"");
+    final ODocument docTwo = new ODocument(""classIndexManagerTestClass"");
+
+    boolean exceptionThrown = false;
+    docOne.field(""prop1"", ""a"");
+    docOne.save();
+
+    docTwo.field(""prop1"", ""b"");
+    docTwo.save();
+
+    try {
+      docTwo.field(""prop1"", ""a"");
+      docTwo.save();
+    } catch (OIndexException e) {
+      exceptionThrown = true;
+    }
+    Assert.assertTrue(exceptionThrown);
+  }
+
+  public void testPropertiesCheckUniqueIndexDubKeyIsNullUpdate() {
+    final ODocument docOne = new ODocument(""classIndexManagerTestClass"");
+    final ODocument docTwo = new ODocument(""classIndexManagerTestClass"");
+
+    docOne.field(""prop1"", ""a"");
+    docOne.save();
+
+    docTwo.field(""prop1"", ""b"");
+    docTwo.save();
+
+    docTwo.field(""prop1"", (String) null);
+    docTwo.save();
+  }
+
+  public void testPropertiesCheckUniqueIndexDubKeyIsNullUpdateInTX() {
+    final ODocument docOne = new ODocument(""classIndexManagerTestClass"");
+    final ODocument docTwo = new ODocument(""classIndexManagerTestClass"");
+
+    database.begin();
+    docOne.field(""prop1"", ""a"");
+    docOne.save();
+
+    docTwo.field(""prop1"", ""b"");
+    docTwo.save();
+
+    docTwo.field(""prop1"", (String) null);
+    docTwo.save();
+    database.commit();
+  }
+
+  public void testPropertiesCheckNonUniqueIndexDubKeys() {
+    final ODocument docOne = new ODocument(""classIndexManagerTestClass"");
+    docOne.field(""prop2"", 1);
+    docOne.save();
+
+    final ODocument docTwo = new ODocument(""classIndexManagerTestClass"");
+    docTwo.field(""prop2"", 1);
+    docTwo.save();
+  }
+
+  public void testPropertiesCheckUniqueNullKeys() {
+    final ODocument docOne = new ODocument(""classIndexManagerTestClass"");
+    docOne.field(""prop3"", ""a"");
+    docOne.save();
+
+    final ODocument docTwo = new ODocument(""classIndexManagerTestClass"");
+    docTwo.field(""prop3"", ""a"");
+    docTwo.save();
+  }
+
+  public void testCreateDocumentWithoutClass() {
+    final Collection<? extends OIndex<?>> beforeIndexes = database.getMetadata().getIndexManager().getIndexes();
+    final Map<String, Long> indexSizeMap = new HashMap<String, Long>();
+
+    for (final OIndex<?> index : beforeIndexes)
+      indexSizeMap.put(index.getName(), index.getSize());
+
+    final ODocument docOne = new ODocument();
+    docOne.field(""prop1"", ""a"");
+    docOne.save();
+
+    final ODocument docTwo = new ODocument();
+    docTwo.field(""prop1"", ""a"");
+    docTwo.save();
+
+    final Collection<? extends OIndex<?>> afterIndexes = database.getMetadata().getIndexManager().getIndexes();
+    for (final OIndex<?> index : afterIndexes)
+      Assert.assertEquals(index.getSize(), indexSizeMap.get(index.getName()).longValue());
+  }
+
+  public void testUpdateDocumentWithoutClass() {
+    final Collection<? extends OIndex<?>> beforeIndexes = database.getMetadata().getIndexManager().getIndexes();
+    final Map<String, Long> indexSizeMap = new HashMap<String, Long>();
+
+    for (final OIndex<?> index : beforeIndexes)
+      indexSizeMap.put(index.getName(), index.getSize());
+
+    final ODocument docOne = new ODocument();
+    docOne.field(""prop1"", ""a"");
+    docOne.save();
+
+    final ODocument docTwo = new ODocument();
+    docTwo.field(""prop1"", ""b"");
+    docTwo.save();
 
-		docOne.field(""prop1"", ""a"");
-		docOne.save();
+    docOne.field(""prop1"", ""a"");
+    docOne.save();
 
-		final Collection<? extends OIndex<?>> afterIndexes = database.getMetadata().getIndexManager().getIndexes();
-		for (final OIndex<?> index : afterIndexes)
-			Assert.assertEquals(index.getSize(), indexSizeMap.get(index.getName()).longValue());
-	}
+    final Collection<? extends OIndex<?>> afterIndexes = database.getMetadata().getIndexManager().getIndexes();
+    for (final OIndex<?> index : afterIndexes)
+      Assert.assertEquals(index.getSize(), indexSizeMap.get(index.getName()).longValue());
+  }
 
-	public void testDeleteDocumentWithoutClass() {
-		final ODocument docOne = new ODocument();
-		docOne.field(""prop1"", ""a"");
-		docOne.save();
+  public void testDeleteDocumentWithoutClass() {
+    final ODocument docOne = new ODocument();
+    docOne.field(""prop1"", ""a"");
+    docOne.save();
 
-		docOne.delete();
-	}
+    docOne.delete();
+  }
 
-	public void testDeleteModifiedDocumentWithoutClass() {
-		final ODocument docOne = new ODocument();
-		docOne.field(""prop1"", ""a"");
-		docOne.save();
+  public void testDeleteModifiedDocumentWithoutClass() {
+    final ODocument docOne = new ODocument();
+    docOne.field(""prop1"", ""a"");
+    docOne.save();
 
-		docOne.field(""prop1"", ""b"");
+    docOne.field(""prop1"", ""b"");
 
-		docOne.delete();
-	}
-
-	public void testDocumentUpdateWithoutDirtyFields() {
-		final ODocument docOne = new ODocument(""classIndexManagerTestClass"");
-		docOne.field(""prop1"", ""a"");
-		docOne.save();
+    docOne.delete();
+  }
+
+  public void testDocumentUpdateWithoutDirtyFields() {
+    final ODocument docOne = new ODocument(""classIndexManagerTestClass"");
+    docOne.field(""prop1"", ""a"");
+    docOne.save();
 
-		docOne.setDirty();
-		docOne.save();
-	}
+    docOne.setDirty();
+    docOne.save();
+  }
 
-	public void testCreateDocumentIndexRecordAdded() {
-		final ODocument doc = new ODocument(""classIndexManagerTestClass"");
-		doc.field(""prop0"", ""x"");
-		doc.field(""prop1"", ""a"");
-		doc.field(""prop2"", 1);
-
-		doc.save();
+  public void testCreateDocumentIndexRecordAdded() {
+    final ODocument doc = new ODocument(""classIndexManagerTestClass"");
+    doc.field(""prop0"", ""x"");
+    doc.field(""prop1"", ""a"");
+    doc.field(""prop2"", 1);
+
+    doc.save();
 
-		final OSchema schema = database.getMetadata().getSchema();
-		final OClass oClass = schema.getClass(""classIndexManagerTestClass"");
-		final OClass oSuperClass = schema.getClass(""classIndexManagerTestSuperClass"");
+    final OSchema schema = database.getMetadata().getSchema();
+    final OClass oClass = schema.getClass(""classIndexManagerTestClass"");
+    final OClass oSuperClass = schema.getClass(""classIndexManagerTestSuperClass"");
 
-		final OIndex<?> propOneIndex = oClass.getClassIndex(""classIndexManagerTestClass.prop1"");
-		Assert.assertNotNull(propOneIndex.get(""a""));
-		Assert.assertEquals(propOneIndex.getSize(), 1);
+    final OIndex<?> propOneIndex = oClass.getClassIndex(""classIndexManagerTestClass.prop1"");
+    Assert.assertNotNull(propOneIndex.get(""a""));
+    Assert.assertEquals(propOneIndex.getSize(), 1);
 
-		final OIndex<?> compositeIndex = oClass.getClassIndex(""classIndexManagerComposite"");
+    final OIndex<?> compositeIndex = oClass.getClassIndex(""classIndexManagerComposite"");
 
-		final OIndexDefinition compositeIndexDefinition = compositeIndex.getDefinition();
-		Assert.assertNotNull(compositeIndex.get(compositeIndexDefinition.createValue(""a"", 1)));
-		Assert.assertEquals(compositeIndex.getSize(), 1);
+    final OIndexDefinition compositeIndexDefinition = compositeIndex.getDefinition();
+    Assert.assertNotNull(compositeIndex.get(compositeIndexDefinition.createValue(""a"", 1)));
+    Assert.assertEquals(compositeIndex.getSize(), 1);
 
-		final OIndex<?> propZeroIndex = oSuperClass.getClassIndex(""classIndexManagerTestSuperClass.prop0"");
-		Assert.assertNotNull(propZeroIndex.get(""x""));
-		Assert.assertEquals(propZeroIndex.getSize(), 1);
-	}
+    final OIndex<?> propZeroIndex = oSuperClass.getClassIndex(""classIndexManagerTestSuperClass.prop0"");
+    Assert.assertNotNull(propZeroIndex.get(""x""));
+    Assert.assertEquals(propZeroIndex.getSize(), 1);
+  }
 
-	public void testUpdateDocumentIndexRecordRemoved() {
-		final ODocument doc = new ODocument(""classIndexManagerTestClass"");
-		doc.field(""prop0"", ""x"");
-		doc.field(""prop1"", ""a"");
-		doc.field(""prop2"", 1);
+  public void testUpdateDocumentIndexRecordRemoved() {
+    final ODocument doc = new ODocument(""classIndexManagerTestClass"");
+    doc.field(""prop0"", ""x"");
+    doc.field(""prop1"", ""a"");
+    doc.field(""prop2"", 1);
 
-		doc.save();
+    doc.save();
 
-		final OSchema schema = database.getMetadata().getSchema();
-		final OClass oSuperClass = schema.getClass(""classIndexManagerTestSuperClass"");
-		final OClass oClass = schema.getClass(""classIndexManagerTestClass"");
+    final OSchema schema = database.getMetadata().getSchema();
+    final OClass oSuperClass = schema.getClass(""classIndexManagerTestSuperClass"");
+    final OClass oClass = schema.getClass(""classIndexManagerTestClass"");
 
-		final OIndex<?> propOneIndex = oClass.getClassIndex(""classIndexManagerTestClass.prop1"");
-		final OIndex<?> compositeIndex = oClass.getClassIndex(""classIndexManagerComposite"");
-		final OIndex<?> propZeroIndex = oSuperClass.getClassIndex(""classIndexManagerTestSuperClass.prop0"");
+    final OIndex<?> propOneIndex = oClass.getClassIndex(""classIndexManagerTestClass.prop1"");
+    final OIndex<?> compositeIndex = oClass.getClassIndex(""classIndexManagerComposite"");
+    final OIndex<?> propZeroIndex = oSuperClass.getClassIndex(""classIndexManagerTestSuperClass.prop0"");
 
-		Assert.assertEquals(propOneIndex.getSize(), 1);
-		Assert.assertEquals(compositeIndex.getSize(), 1);
-		Assert.assertEquals(propZeroIndex.getSize(), 1);
+    Assert.assertEquals(propOneIndex.getSize(), 1);
+    Assert.assertEquals(compositeIndex.getSize(), 1);
+    Assert.assertEquals(propZeroIndex.getSize(), 1);
 
-		doc.removeField(""prop2"");
-		doc.removeField(""prop0"");
-		doc.save();
+    doc.removeField(""prop2"");
+    doc.removeField(""prop0"");
+    doc.save();
 
-		Assert.assertEquals(propOneIndex.getSize(), 1);
-		Assert.assertEquals(compositeIndex.getSize(), 0);
-		Assert.assertEquals(propZeroIndex.getSize(), 0);
-	}
+    Assert.assertEquals(propOneIndex.getSize(), 1);
+    Assert.assertEquals(compositeIndex.getSize(), 0);
+    Assert.assertEquals(propZeroIndex.getSize(), 0);
+  }
 
-	public void testUpdateDocumentNullKeyIndexRecordRemoved() {
-		final ODocument doc = new ODocument(""classIndexManagerTestClass"");
+  public void testUpdateDocumentNullKeyIndexRecordRemoved() {
+    final ODocument doc = new ODocument(""classIndexManagerTestClass"");
 
-		doc.field(""prop0"", ""x"");
-		doc.field(""prop1"", ""a"");
-		doc.field(""prop2"", 1);
+    doc.field(""prop0"", ""x"");
+    doc.field(""prop1"", ""a"");
+    doc.field(""prop2"", 1);
 
-		doc.save();
+    doc.save();
 
-		final OSchema schema = database.getMetadata().getSchema();
-		final OClass oSuperClass = schema.getClass(""classIndexManagerTestSuperClass"");
-		final OClass oClass = schema.getClass(""classIndexManagerTestClass"");
+    final OSchema schema = database.getMetadata().getSchema();
+    final OClass oSuperClass = schema.getClass(""classIndexManagerTestSuperClass"");
+    final OClass oClass = schema.getClass(""classIndexManagerTestClass"");
 
-		final OIndex<?> propOneIndex = oClass.getClassIndex(""classIndexManagerTestClass.prop1"");
-		final OIndex<?> compositeIndex = oClass.getClassIndex(""classIndexManagerComposite"");
-		final OIndex<?> propZeroIndex = oSuperClass.getClassIndex(""classIndexManagerTestSuperClass.prop0"");
+    final OIndex<?> propOneIndex = oClass.getClassIndex(""classIndexManagerTestClass.prop1"");
+    final OIndex<?> compositeIndex = oClass.getClassIndex(""classIndexManagerComposite"");
+    final OIndex<?> propZeroIndex = oSuperClass.getClassIndex(""classIndexManagerTestSuperClass.prop0"");
 
-		Assert.assertEquals(propOneIndex.getSize(), 1);
-		Assert.assertEquals(compositeIndex.getSize(), 1);
-		Assert.assertEquals(propZeroIndex.getSize(), 1);
+    Assert.assertEquals(propOneIndex.getSize(), 1);
+    Assert.assertEquals(compositeIndex.getSize(), 1);
+    Assert.assertEquals(propZeroIndex.getSize(), 1);
 
-		doc.field(""prop2"", (Object) null);
-		doc.field(""prop0"", (Object) null);
-		doc.save();
+    doc.field(""prop2"", (Object) null);
+    doc.field(""prop0"", (Object) null);
+    doc.save();
 
-		Assert.assertEquals(propOneIndex.getSize(), 1);
-		Assert.assertEquals(compositeIndex.getSize(), 0);
-		Assert.assertEquals(propZeroIndex.getSize(), 0);
-	}
+    Assert.assertEquals(propOneIndex.getSize(), 1);
+    Assert.assertEquals(compositeIndex.getSize(), 0);
+    Assert.assertEquals(propZeroIndex.getSize(), 0);
+  }
 
-	public void testUpdateDocumentIndexRecordUpdated() {
-		final ODocument doc = new ODocument(""classIndexManagerTestClass"");
-		doc.field(""prop0"", ""x"");
-		doc.field(""prop1"", ""a"");
-		doc.field(""prop2"", 1);
+  public void testUpdateDocumentIndexRecordUpdated() {
+    final ODocument doc = new ODocument(""classIndexManagerTestClass"");
+    doc.field(""prop0"", ""x"");
+    doc.field(""prop1"", ""a"");
+    doc.field(""prop2"", 1);
 
-		doc.save();
+    doc.save();
 
-		final OSchema schema = database.getMetadata().getSchema();
-		final OClass oSuperClass = schema.getClass(""classIndexManagerTestSuperClass"");
-		final OClass oClass = schema.getClass(""classIndexManagerTestClass"");
+    final OSchema schema = database.getMetadata().getSchema();
+    final OClass oSuperClass = schema.getClass(""classIndexManagerTestSuperClass"");
+    final OClass oClass = schema.getClass(""classIndexManagerTestClass"");
 
-		final OIndex<?> propZeroIndex = oSuperClass.getClassIndex(""classIndexManagerTestSuperClass.prop0"");
-		final OIndex<?> propOneIndex = oClass.getClassIndex(""classIndexManagerTestClass.prop1"");
-		final OIndex<?> compositeIndex = oClass.getClassIndex(""classIndexManagerComposite"");
-		final OIndexDefinition compositeIndexDefinition = compositeIndex.getDefinition();
+    final OIndex<?> propZeroIndex = oSuperClass.getClassIndex(""classIndexManagerTestSuperClass.prop0"");
+    final OIndex<?> propOneIndex = oClass.getClassIndex(""classIndexManagerTestClass.prop1"");
+    final OIndex<?> compositeIndex = oClass.getClassIndex(""classIndexManagerComposite"");
+    final OIndexDefinition compositeIndexDefinition = compositeIndex.getDefinition();
 
-		Assert.assertEquals(propOneIndex.getSize(), 1);
-		Assert.assertEquals(compositeIndex.getSize(), 1);
-		Assert.assertEquals(propZeroIndex.getSize(), 1);
+    Assert.assertEquals(propOneIndex.getSize(), 1);
+    Assert.assertEquals(compositeIndex.getSize(), 1);
+    Assert.assertEquals(propZeroIndex.getSize(), 1);
 
-		doc.field(""prop2"", 2);
-		doc.field(""prop0"", ""y"");
-		doc.save();
+    doc.field(""prop2"", 2);
+    doc.field(""prop0"", ""y"");
+    doc.save();
 
-		Assert.assertEquals(propOneIndex.getSize(), 1);
-		Assert.assertEquals(compositeIndex.getSize(), 1);
-		Assert.assertEquals(propZeroIndex.getSize(), 1);
+    Assert.assertEquals(propOneIndex.getSize(), 1);
+    Assert.assertEquals(compositeIndex.getSize(), 1);
+    Assert.assertEquals(propZeroIndex.getSize(), 1);
 
-		Assert.assertNotNull(propZeroIndex.get(""y""));
-		Assert.assertNotNull(propOneIndex.get(""a""));
-		Assert.assertNotNull(compositeIndex.get(compositeIndexDefinition.createValue(""a"", 2)));
-	}
+    Assert.assertNotNull(propZeroIndex.get(""y""));
+    Assert.assertNotNull(propOneIndex.get(""a""));
+    Assert.assertNotNull(compositeIndex.get(compositeIndexDefinition.createValue(""a"", 2)));
+  }
 
-	public void testUpdateDocumentIndexRecordUpdatedFromNullField() {
-		final ODocument doc = new ODocument(""classIndexManagerTestClass"");
-		doc.field(""prop1"", ""a"");
-		doc.field(""prop2"", (Object) null);
+  public void testUpdateDocumentIndexRecordUpdatedFromNullField() {
+    final ODocument doc = new ODocument(""classIndexManagerTestClass"");
+    doc.field(""prop1"", ""a"");
+    doc.field(""prop2"", (Object) null);
 
-		doc.save();
+    doc.save();
 
-		final OSchema schema = database.getMetadata().getSchema();
-		final OClass oClass = schema.getClass(""classIndexManagerTestClass"");
+    final OSchema schema = database.getMetadata().getSchema();
+    final OClass oClass = schema.getClass(""classIndexManagerTestClass"");
 
-		final OIndex<?> propOneIndex = oClass.getClassIndex(""classIndexManagerTestClass.prop1"");
-		final OIndex<?> compositeIndex = oClass.getClassIndex(""classIndexManagerComposite"");
-		final OIndexDefinition compositeIndexDefinition = compositeIndex.getDefinition();
+    final OIndex<?> propOneIndex = oClass.getClassIndex(""classIndexManagerTestClass.prop1"");
+    final OIndex<?> compositeIndex = oClass.getClassIndex(""classIndexManagerComposite"");
+    final OIndexDefinition compositeIndexDefinition = compositeIndex.getDefinition();
 
-		Assert.assertEquals(propOneIndex.getSize(), 1);
-		Assert.assertEquals(compositeIndex.getSize(), 0);
+    Assert.assertEquals(propOneIndex.getSize(), 1);
+    Assert.assertEquals(compositeIndex.getSize(), 0);
 
-		doc.field(""prop2"", 2);
-		doc.save();
+    doc.field(""prop2"", 2);
+    doc.save();
 
-		Assert.assertEquals(propOneIndex.getSize(), 1);
-		Assert.assertEquals(compositeIndex.getSize(), 1);
+    Assert.assertEquals(propOneIndex.getSize(), 1);
+    Assert.assertEquals(compositeIndex.getSize(), 1);
 
-		Assert.assertNotNull(propOneIndex.get(""a""));
-		Assert.assertNotNull(compositeIndex.get(compositeIndexDefinition.createValue(""a"", 2)));
-	}
+    Assert.assertNotNull(propOneIndex.get(""a""));
+    Assert.assertNotNull(compositeIndex.get(compositeIndexDefinition.createValue(""a"", 2)));
+  }
 
-	public void testListUpdate() {
-		final OSchema schema = database.getMetadata().getSchema();
-		final OClass oClass = schema.getClass(""classIndexManagerTestClass"");
+  public void testListUpdate() {
+    final OSchema schema = database.getMetadata().getSchema();
+    final OClass oClass = schema.getClass(""classIndexManagerTestClass"");
 
-		final OIndex<?> propFourIndex = oClass.getClassIndex(""classIndexManagerTestClass.prop4"");
+    final OIndex<?> propFourIndex = oClass.getClassIndex(""classIndexManagerTestClass.prop4"");
 
-		Assert.assertEquals(propFourIndex.getSize(), 0);
+    Assert.assertEquals(propFourIndex.getSize(), 0);
 
-		final ODocument doc = new ODocument(""classIndexManagerTestClass"");
+    final ODocument doc = new ODocument(""classIndexManagerTestClass"");
 
-		final List<String> listProperty = new ArrayList<String>();
-		listProperty.add(""value1"");
-		listProperty.add(""value2"");
+    final List<String> listProperty = new ArrayList<String>();
+    listProperty.add(""value1"");
+    listProperty.add(""value2"");
 
-		doc.field(""prop4"", listProperty);
-		doc.save();
+    doc.field(""prop4"", listProperty);
+    doc.save();
 
-		Assert.assertEquals(propFourIndex.getSize(), 2);
-		Assert.assertNotNull(propFourIndex.get(""value1""));
-		Assert.assertNotNull(propFourIndex.get(""value2""));
+    Assert.assertEquals(propFourIndex.getSize(), 2);
+    Assert.assertNotNull(propFourIndex.get(""value1""));
+    Assert.assertNotNull(propFourIndex.get(""value2""));
 
-		List<String> trackedList = doc.field(""prop4"");
-		trackedList.set(0, ""value3"");
+    List<String> trackedList = doc.field(""prop4"");
+    trackedList.set(0, ""value3"");
 
-		trackedList.add(""value4"");
-		trackedList.add(""value4"");
-		trackedList.add(""value4"");
-		trackedList.remove(""value4"");
-		trackedList.remove(""value2"");
-		trackedList.add(""value5"");
+    trackedList.add(""value4"");
+    trackedList.add(""value4"");
+    trackedList.add(""value4"");
+    trackedList.remove(""value4"");
+    trackedList.remove(""value2"");
+    trackedList.add(""value5"");
 
-		doc.save();
+    doc.save();
 
-		Assert.assertEquals(propFourIndex.getSize(), 3);
-		Assert.assertNotNull(propFourIndex.get(""value3""));
-		Assert.assertNotNull(propFourIndex.get(""value4""));
-		Assert.assertNotNull(propFourIndex.get(""value5""));
-	}
+    Assert.assertEquals(propFourIndex.getSize(), 3);
+    Assert.assertNotNull(propFourIndex.get(""value3""));
+    Assert.assertNotNull(propFourIndex.get(""value4""));
+    Assert.assertNotNull(propFourIndex.get(""value5""));
+  }
 
+  public void testMapUpdate() {
+    final OSchema schema = database.getMetadata().getSchema();
+    final OClass oClass = schema.getClass(""classIndexManagerTestClass"");
 
-	public void testMapUpdate() {
-		final OSchema schema = database.getMetadata().getSchema();
-		final OClass oClass = schema.getClass(""classIndexManagerTestClass"");
+    final OIndex<?> propFiveIndexKey = oClass.getClassIndex(""classIndexManagerTestIndexByKey"");
+    final OIndex<?> propFiveIndexValue = oClass.getClassIndex(""classIndexManagerTestIndexByValue"");
 
-		final OIndex<?> propFiveIndexKey = oClass.getClassIndex(""classIndexManagerTestIndexByKey"");
-		final OIndex<?> propFiveIndexValue = oClass.getClassIndex(""classIndexManagerTestIndexByValue"");
+    Assert.assertEquals(propFiveIndexKey.getSize(), 0);
 
-		Assert.assertEquals(propFiveIndexKey.getSize(), 0);
+    final ODocument doc = new ODocument(""classIndexManagerTestClass"");
 
-		final ODocument doc = new ODocument(""classIndexManagerTestClass"");
+    final Map<String, String> mapProperty = new HashMap<String, String>();
+    mapProperty.put(""key1"", ""value1"");
+    mapProperty.put(""key2"", ""value2"");
 
-		final Map<String, String> mapProperty = new HashMap<String, String>();
-		mapProperty.put(""key1"", ""value1"");
-		mapProperty.put(""key2"", ""value2"");
+    doc.field(""prop5"", mapProperty);
+    doc.save();
 
-		doc.field(""prop5"", mapProperty);
-		doc.save();
+    Assert.assertEquals(propFiveIndexKey.getSize(), 2);
+    Assert.assertNotNull(propFiveIndexKey.get(""key1""));
+    Assert.assertNotNull(propFiveIndexKey.get(""key2""));
 
-		Assert.assertEquals(propFiveIndexKey.getSize(), 2);
-		Assert.assertNotNull(propFiveIndexKey.get(""key1""));
-		Assert.assertNotNull(propFiveIndexKey.get(""key2""));
+    Map<String, String> trackedMap = doc.field(""prop5"");
+    trackedMap.put(""key3"", ""value3"");
+    trackedMap.put(""key4"", ""value4"");
+    trackedMap.remove(""key1"");
+    trackedMap.put(""key1"", ""value5"");
+    trackedMap.remove(""key2"");
+    trackedMap.put(""key6"", ""value6"");
+    trackedMap.put(""key7"", ""value6"");
+    trackedMap.put(""key8"", ""value6"");
+    trackedMap.put(""key4"", ""value7"");
 
-		Map<String, String> trackedMap = doc.field(""prop5"");
-		trackedMap.put(""key3"", ""value3"");
-		trackedMap.put(""key4"", ""value4"");
-		trackedMap.remove(""key1"");
-		trackedMap.put(""key1"", ""value5"");
-		trackedMap.remove(""key2"");
-		trackedMap.put(""key6"", ""value6"");
-		trackedMap.put(""key7"", ""value6"");
-		trackedMap.put(""key8"", ""value6"");
-		trackedMap.put(""key4"", ""value7"");
+    trackedMap.remove(""key8"");
 
-		trackedMap.remove(""key8"");
+    doc.save();
 
+    Assert.assertEquals(propFiveIndexKey.getSize(), 5);
+    Assert.assertNotNull(propFiveIndexKey.get(""key1""));
+    Assert.assertNotNull(propFiveIndexKey.get(""key3""));
+    Assert.assertNotNull(propFiveIndexKey.get(""key4""));
+    Assert.assertNotNull(propFiveIndexKey.get(""key6""));
+    Assert.assertNotNull(propFiveIndexKey.get(""key7""));
 
-		doc.save();
+    Assert.assertEquals(propFiveIndexValue.getSize(), 4);
+    Assert.assertNotNull(propFiveIndexValue.get(""value5""));
+    Assert.assertNotNull(propFiveIndexValue.get(""value3""));
+    Assert.assertNotNull(propFiveIndexValue.get(""value7""));
+    Assert.assertNotNull(propFiveIndexValue.get(""value6""));
 
-		Assert.assertEquals(propFiveIndexKey.getSize(), 5);
-		Assert.assertNotNull(propFiveIndexKey.get(""key1""));
-		Assert.assertNotNull(propFiveIndexKey.get(""key3""));
-		Assert.assertNotNull(propFiveIndexKey.get(""key4""));
-		Assert.assertNotNull(propFiveIndexKey.get(""key6""));
-		Assert.assertNotNull(propFiveIndexKey.get(""key7""));
+  }
 
-		Assert.assertEquals(propFiveIndexValue.getSize(), 4);
-		Assert.assertNotNull(propFiveIndexValue.get(""value5""));
-		Assert.assertNotNull(propFiveIndexValue.get(""value3""));
-		Assert.assertNotNull(propFiveIndexValue.get(""value7""));
-		Assert.assertNotNull(propFiveIndexValue.get(""value6""));
+  public void testSetUpdate() {
+    final OSchema schema = database.getMetadata().getSchema();
+    final OClass oClass = schema.getClass(""classIndexManagerTestClass"");
 
-	}
+    final OIndex<?> propSixIndex = oClass.getClassIndex(""classIndexManagerTestClass.prop6"");
 
-	public void testSetUpdate() {
-		final OSchema schema = database.getMetadata().getSchema();
-		final OClass oClass = schema.getClass(""classIndexManagerTestClass"");
+    Assert.assertEquals(propSixIndex.getSize(), 0);
 
-		final OIndex<?> propSixIndex = oClass.getClassIndex(""classIndexManagerTestClass.prop6"");
+    final ODocument doc = new ODocument(""classIndexManagerTestClass"");
 
-		Assert.assertEquals(propSixIndex.getSize(), 0);
+    final Set<String> setProperty = new HashSet<String>();
+    setProperty.add(""value1"");
+    setProperty.add(""value2"");
 
-		final ODocument doc = new ODocument(""classIndexManagerTestClass"");
+    doc.field(""prop6"", setProperty);
+    doc.save();
 
-		final Set<String> setProperty = new HashSet<String>();
-		setProperty.add(""value1"");
-		setProperty.add(""value2"");
+    Assert.assertEquals(propSixIndex.getSize(), 2);
+    Assert.assertNotNull(propSixIndex.get(""value1""));
+    Assert.assertNotNull(propSixIndex.get(""value2""));
 
-		doc.field(""prop6"", setProperty);
-		doc.save();
+    Set<String> trackedSet = doc.field(""prop6"");
 
-		Assert.assertEquals(propSixIndex.getSize(), 2);
-		Assert.assertNotNull(propSixIndex.get(""value1""));
-		Assert.assertNotNull(propSixIndex.get(""value2""));
+    trackedSet.add(""value4"");
+    trackedSet.add(""value4"");
+    trackedSet.add(""value4"");
+    trackedSet.remove(""value4"");
+    trackedSet.remove(""value2"");
+    trackedSet.add(""value5"");
 
-		Set<String> trackedSet = doc.field(""prop6"");
+    doc.save();
 
-		trackedSet.add(""value4"");
-		trackedSet.add(""value4"");
-		trackedSet.add(""value4"");
-		trackedSet.remove(""value4"");
-		trackedSet.remove(""value2"");
-		trackedSet.add(""value5"");
+    Assert.assertEquals(propSixIndex.getSize(), 2);
+    Assert.assertNotNull(propSixIndex.get(""value1""));
+    Assert.assertNotNull(propSixIndex.get(""value5""));
+  }
 
-		doc.save();
+  public void testListDelete() {
+    final OSchema schema = database.getMetadata().getSchema();
+    final OClass oClass = schema.getClass(""classIndexManagerTestClass"");
 
-		Assert.assertEquals(propSixIndex.getSize(), 2);
-		Assert.assertNotNull(propSixIndex.get(""value1""));
-		Assert.assertNotNull(propSixIndex.get(""value5""));
-	}
+    final OIndex<?> propFourIndex = oClass.getClassIndex(""classIndexManagerTestClass.prop4"");
 
-	public void testListDelete() {
-		final OSchema schema = database.getMetadata().getSchema();
-		final OClass oClass = schema.getClass(""classIndexManagerTestClass"");
+    Assert.assertEquals(propFourIndex.getSize(), 0);
 
-		final OIndex<?> propFourIndex = oClass.getClassIndex(""classIndexManagerTestClass.prop4"");
+    final ODocument doc = new ODocument(""classIndexManagerTestClass"");
 
-		Assert.assertEquals(propFourIndex.getSize(), 0);
+    final List<String> listProperty = new ArrayList<String>();
+    listProperty.add(""value1"");
+    listProperty.add(""value2"");
 
-		final ODocument doc = new ODocument(""classIndexManagerTestClass"");
+    doc.field(""prop4"", listProperty);
+    doc.save();
 
-		final List<String> listProperty = new ArrayList<String>();
-		listProperty.add(""value1"");
-		listProperty.add(""value2"");
+    Assert.assertEquals(propFourIndex.getSize(), 2);
+    Assert.assertNotNull(propFourIndex.get(""value1""));
+    Assert.assertNotNull(propFourIndex.get(""value2""));
 
-		doc.field(""prop4"", listProperty);
-		doc.save();
+    List<String> trackedList = doc.field(""prop4"");
+    trackedList.set(0, ""value3"");
 
-		Assert.assertEquals(propFourIndex.getSize(), 2);
-		Assert.assertNotNull(propFourIndex.get(""value1""));
-		Assert.assertNotNull(propFourIndex.get(""value2""));
+    trackedList.add(""value4"");
+    trackedList.add(""value4"");
+    trackedList.add(""value4"");
+    trackedList.remove(""value4"");
+    trackedList.remove(""value2"");
+    trackedList.add(""value5"");
 
-		List<String> trackedList = doc.field(""prop4"");
-		trackedList.set(0, ""value3"");
+    doc.save();
 
-		trackedList.add(""value4"");
-		trackedList.add(""value4"");
-		trackedList.add(""value4"");
-		trackedList.remove(""value4"");
-		trackedList.remove(""value2"");
-		trackedList.add(""value5"");
+    Assert.assertEquals(propFourIndex.getSize(), 3);
+    Assert.assertNotNull(propFourIndex.get(""value3""));
+    Assert.assertNotNull(propFourIndex.get(""value4""));
+    Assert.assertNotNull(propFourIndex.get(""value5""));
 
-		doc.save();
+    trackedList = doc.field(""prop4"");
+    trackedList.remove(""value3"");
+    trackedList.remove(""value4"");
+    trackedList.add(""value8"");
 
-		Assert.assertEquals(propFourIndex.getSize(), 3);
-		Assert.assertNotNull(propFourIndex.get(""value3""));
-		Assert.assertNotNull(propFourIndex.get(""value4""));
-		Assert.assertNotNull(propFourIndex.get(""value5""));
+    doc.delete();
 
-		trackedList = doc.field(""prop4"");
-		trackedList.remove(""value3"");
-		trackedList.remove(""value4"");
-		trackedList.add(""value8"");
+    Assert.assertEquals(propFourIndex.getSize(), 0);
+  }
 
-		doc.delete();
+  public void testMapDelete() {
+    final OSchema schema = database.getMetadata().getSchema();
+    final OClass oClass = schema.getClass(""classIndexManagerTestClass"");
 
-		Assert.assertEquals(propFourIndex.getSize(), 0);
-	}
+    final OIndex<?> propFiveIndexKey = oClass.getClassIndex(""classIndexManagerTestIndexByKey"");
+    final OIndex<?> propFiveIndexValue = oClass.getClassIndex(""classIndexManagerTestIndexByValue"");
 
+    Assert.assertEquals(propFiveIndexKey.getSize(), 0);
 
-	public void testMapDelete() {
-		final OSchema schema = database.getMetadata().getSchema();
-		final OClass oClass = schema.getClass(""classIndexManagerTestClass"");
+    final ODocument doc = new ODocument(""classIndexManagerTestClass"");
 
-		final OIndex<?> propFiveIndexKey = oClass.getClassIndex(""classIndexManagerTestIndexByKey"");
-		final OIndex<?> propFiveIndexValue = oClass.getClassIndex(""classIndexManagerTestIndexByValue"");
+    final Map<String, String> mapProperty = new HashMap<String, String>();
+    mapProperty.put(""key1"", ""value1"");
+    mapProperty.put(""key2"", ""value2"");
 
-		Assert.assertEquals(propFiveIndexKey.getSize(), 0);
+    doc.field(""prop5"", mapProperty);
+    doc.save();
 
-		final ODocument doc = new ODocument(""classIndexManagerTestClass"");
+    Assert.assertEquals(propFiveIndexKey.getSize(), 2);
+    Assert.assertNotNull(propFiveIndexKey.get(""key1""));
+    Assert.assertNotNull(propFiveIndexKey.get(""key2""));
 
-		final Map<String, String> mapProperty = new HashMap<String, String>();
-		mapProperty.put(""key1"", ""value1"");
-		mapProperty.put(""key2"", ""value2"");
+    Map<String, String> trackedMap = doc.field(""prop5"");
+    trackedMap.put(""key3"", ""value3"");
+    trackedMap.put(""key4"", ""value4"");
+    trackedMap.remove(""key1"");
+    trackedMap.put(""key1"", ""value5"");
+    trackedMap.remove(""key2"");
+    trackedMap.put(""key6"", ""value6"");
+    trackedMap.put(""key7"", ""value6"");
+    trackedMap.put(""key8"", ""value6"");
+    trackedMap.put(""key4"", ""value7"");
 
-		doc.field(""prop5"", mapProperty);
-		doc.save();
+    trackedMap.remove(""key8"");
 
-		Assert.assertEquals(propFiveIndexKey.getSize(), 2);
-		Assert.assertNotNull(propFiveIndexKey.get(""key1""));
-		Assert.assertNotNull(propFiveIndexKey.get(""key2""));
+    doc.save();
 
-		Map<String, String> trackedMap = doc.field(""prop5"");
-		trackedMap.put(""key3"", ""value3"");
-		trackedMap.put(""key4"", ""value4"");
-		trackedMap.remove(""key1"");
-		trackedMap.put(""key1"", ""value5"");
-		trackedMap.remove(""key2"");
-		trackedMap.put(""key6"", ""value6"");
-		trackedMap.put(""key7"", ""value6"");
-		trackedMap.put(""key8"", ""value6"");
-		trackedMap.put(""key4"", ""value7"");
+    Assert.assertEquals(propFiveIndexKey.getSize(), 5);
+    Assert.assertNotNull(propFiveIndexKey.get(""key1""));
+    Assert.assertNotNull(propFiveIndexKey.get(""key3""));
+    Assert.assertNotNull(propFiveIndexKey.get(""key4""));
+    Assert.assertNotNull(propFiveIndexKey.get(""key6""));
+    Assert.assertNotNull(propFiveIndexKey.get(""key7""));
 
-		trackedMap.remove(""key8"");
+    Assert.assertEquals(propFiveIndexValue.getSize(), 4);
+    Assert.assertNotNull(propFiveIndexValue.get(""value5""));
+    Assert.assertNotNull(propFiveIndexValue.get(""value3""));
+    Assert.assertNotNull(propFiveIndexValue.get(""value7""));
+    Assert.assertNotNull(propFiveIndexValue.get(""value6""));
 
+    trackedMap = doc.field(""prop5"");
 
-		doc.save();
+    trackedMap.remove(""key1"");
+    trackedMap.remove(""key3"");
+    trackedMap.remove(""key4"");
+    trackedMap.put(""key6"", ""value10"");
+    trackedMap.put(""key11"", ""value11"");
 
-		Assert.assertEquals(propFiveIndexKey.getSize(), 5);
-		Assert.assertNotNull(propFiveIndexKey.get(""key1""));
-		Assert.assertNotNull(propFiveIndexKey.get(""key3""));
-		Assert.assertNotNull(propFiveIndexKey.get(""key4""));
-		Assert.assertNotNull(propFiveIndexKey.get(""key6""));
-		Assert.assertNotNull(propFiveIndexKey.get(""key7""));
+    doc.delete();
 
-		Assert.assertEquals(propFiveIndexValue.getSize(), 4);
-		Assert.assertNotNull(propFiveIndexValue.get(""value5""));
-		Assert.assertNotNull(propFiveIndexValue.get(""value3""));
-		Assert.assertNotNull(propFiveIndexValue.get(""value7""));
-		Assert.assertNotNull(propFiveIndexValue.get(""value6""));
+    Assert.assertEquals(propFiveIndexKey.getSize(), 0);
+    Assert.assertEquals(propFiveIndexValue.getSize(), 0);
+  }
 
-		trackedMap = doc.field(""prop5"");
+  public void testSetDelete() {
+    final OSchema schema = database.getMetadata().getSchema();
+    final OClass oClass = schema.getClass(""classIndexManagerTestClass"");
 
-		trackedMap.remove(""key1"");
-		trackedMap.remove(""key3"");
-		trackedMap.remove(""key4"");
-		trackedMap.put(""key6"", ""value10"");
-		trackedMap.put(""key11"", ""value11"");
+    final OIndex<?> propSixIndex = oClass.getClassIndex(""classIndexManagerTestClass.prop6"");
 
-		doc.delete();
+    Assert.assertEquals(propSixIndex.getSize(), 0);
 
-		Assert.assertEquals(propFiveIndexKey.getSize(), 0);
-		Assert.assertEquals(propFiveIndexValue.getSize(), 0);
-	}
+    final ODocument doc = new ODocument(""classIndexManagerTestClass"");
 
-	public void testSetDelete() {
-		final OSchema schema = database.getMetadata().getSchema();
-		final OClass oClass = schema.getClass(""classIndexManagerTestClass"");
+    final Set<String> setProperty = new HashSet<String>();
+    setProperty.add(""value1"");
+    setProperty.add(""value2"");
 
-		final OIndex<?> propSixIndex = oClass.getClassIndex(""classIndexManagerTestClass.prop6"");
+    doc.field(""prop6"", setProperty);
+    doc.save();
 
-		Assert.assertEquals(propSixIndex.getSize(), 0);
+    Assert.assertEquals(propSixIndex.getSize(), 2);
+    Assert.assertNotNull(propSixIndex.get(""value1""));
+    Assert.assertNotNull(propSixIndex.get(""value2""));
 
-		final ODocument doc = new ODocument(""classIndexManagerTestClass"");
+    Set<String> trackedSet = doc.field(""prop6"");
 
-		final Set<String> setProperty = new HashSet<String>();
-		setProperty.add(""value1"");
-		setProperty.add(""value2"");
+    trackedSet.add(""value4"");
+    trackedSet.add(""value4"");
+    trackedSet.add(""value4"");
+    trackedSet.remove(""value4"");
+    trackedSet.remove(""value2"");
+    trackedSet.add(""value5"");
 
-		doc.field(""prop6"", setProperty);
-		doc.save();
+    doc.save();
 
-		Assert.assertEquals(propSixIndex.getSize(), 2);
-		Assert.assertNotNull(propSixIndex.get(""value1""));
-		Assert.assertNotNull(propSixIndex.get(""value2""));
+    Assert.assertEquals(propSixIndex.getSize(), 2);
+    Assert.assertNotNull(propSixIndex.get(""value1""));
+    Assert.assertNotNull(propSixIndex.get(""value5""));
 
-		Set<String> trackedSet = doc.field(""prop6"");
+    trackedSet = doc.field(""prop6"");
+    trackedSet.remove(""value1"");
+    trackedSet.add(""value6"");
 
-		trackedSet.add(""value4"");
-		trackedSet.add(""value4"");
-		trackedSet.add(""value4"");
-		trackedSet.remove(""value4"");
-		trackedSet.remove(""value2"");
-		trackedSet.add(""value5"");
+    doc.delete();
 
-		doc.save();
+    Assert.assertEquals(propSixIndex.getSize(), 0);
+  }
 
-		Assert.assertEquals(propSixIndex.getSize(), 2);
-		Assert.assertNotNull(propSixIndex.get(""value1""));
-		Assert.assertNotNull(propSixIndex.get(""value5""));
+  public void testDeleteDocumentIndexRecordDeleted() {
+    final ODocument doc = new ODocument(""classIndexManagerTestClass"");
+    doc.field(""prop0"", ""x"");
+    doc.field(""prop1"", ""a"");
+    doc.field(""prop2"", 1);
 
-		trackedSet = doc.field(""prop6"");
-		trackedSet.remove(""value1"");
-		trackedSet.add(""value6"");
+    doc.save();
 
-		doc.delete();
+    final OSchema schema = database.getMetadata().getSchema();
+    final OClass oSuperClass = schema.getClass(""classIndexManagerTestSuperClass"");
+    final OClass oClass = schema.getClass(""classIndexManagerTestClass"");
 
-		Assert.assertEquals(propSixIndex.getSize(), 0);
-	}
+    final OIndex<?> propZeroIndex = oSuperClass.getClassIndex(""classIndexManagerTestSuperClass.prop0"");
+    final OIndex<?> propOneIndex = oClass.getClassIndex(""classIndexManagerTestClass.prop1"");
+    final OIndex<?> compositeIndex = oClass.getClassIndex(""classIndexManagerComposite"");
 
+    Assert.assertEquals(propZeroIndex.getSize(), 1);
+    Assert.assertEquals(propOneIndex.getSize(), 1);
+    Assert.assertEquals(compositeIndex.getSize(), 1);
 
-	public void testDeleteDocumentIndexRecordDeleted() {
-		final ODocument doc = new ODocument(""classIndexManagerTestClass"");
-		doc.field(""prop0"", ""x"");
-		doc.field(""prop1"", ""a"");
-		doc.field(""prop2"", 1);
+    doc.delete();
 
-		doc.save();
+    Assert.assertEquals(propZeroIndex.getSize(), 0);
+    Assert.assertEquals(propOneIndex.getSize(), 0);
+    Assert.assertEquals(compositeIndex.getSize(), 0);
+  }
 
-		final OSchema schema = database.getMetadata().getSchema();
-		final OClass oSuperClass = schema.getClass(""classIndexManagerTestSuperClass"");
-		final OClass oClass = schema.getClass(""classIndexManagerTestClass"");
+  public void testDeleteUpdatedDocumentIndexRecordDeleted() {
+    final ODocument doc = new ODocument(""classIndexManagerTestClass"");
+    doc.field(""prop0"", ""x"");
+    doc.field(""prop1"", ""a"");
+    doc.field(""prop2"", 1);
 
-		final OIndex<?> propZeroIndex = oSuperClass.getClassIndex(""classIndexManagerTestSuperClass.prop0"");
-		final OIndex<?> propOneIndex = oClass.getClassIndex(""classIndexManagerTestClass.prop1"");
-		final OIndex<?> compositeIndex = oClass.getClassIndex(""classIndexManagerComposite"");
+    doc.save();
 
-		Assert.assertEquals(propZeroIndex.getSize(), 1);
-		Assert.assertEquals(propOneIndex.getSize(), 1);
-		Assert.assertEquals(compositeIndex.getSize(), 1);
+    final OSchema schema = database.getMetadata().getSchema();
+    final OClass oSuperClass = schema.getClass(""classIndexManagerTestSuperClass"");
+    final OClass oClass = schema.getClass(""classIndexManagerTestClass"");
 
-		doc.delete();
+    final OIndex<?> propOneIndex = oClass.getClassIndex(""classIndexManagerTestClass.prop1"");
+    final OIndex<?> compositeIndex = oClass.getClassIndex(""classIndexManagerComposite"");
 
-		Assert.assertEquals(propZeroIndex.getSize(), 0);
-		Assert.assertEquals(propOneIndex.getSize(), 0);
-		Assert.assertEquals(compositeIndex.getSize(), 0);
-	}
+    final OIndex<?> propZeroIndex = oSuperClass.getClassIndex(""classIndexManagerTestSuperClass.prop0"");
+    Assert.assertEquals(propZeroIndex.getSize(), 1);
+    Assert.assertEquals(propOneIndex.getSize(), 1);
+    Assert.assertEquals(compositeIndex.getSize(), 1);
 
-	public void testDeleteUpdatedDocumentIndexRecordDeleted() {
-		final ODocument doc = new ODocument(""classIndexManagerTestClass"");
-		doc.field(""prop0"", ""x"");
-		doc.field(""prop1"", ""a"");
-		doc.field(""prop2"", 1);
+    doc.field(""prop2"", 2);
+    doc.field(""prop0"", ""y"");
 
-		doc.save();
+    doc.delete();
 
-		final OSchema schema = database.getMetadata().getSchema();
-		final OClass oSuperClass = schema.getClass(""classIndexManagerTestSuperClass"");
-		final OClass oClass = schema.getClass(""classIndexManagerTestClass"");
+    Assert.assertEquals(propZeroIndex.getSize(), 0);
+    Assert.assertEquals(propOneIndex.getSize(), 0);
+    Assert.assertEquals(compositeIndex.getSize(), 0);
+  }
 
-		final OIndex<?> propOneIndex = oClass.getClassIndex(""classIndexManagerTestClass.prop1"");
-		final OIndex<?> compositeIndex = oClass.getClassIndex(""classIndexManagerComposite"");
+  public void testDeleteUpdatedDocumentNullFieldIndexRecordDeleted() {
+    final ODocument doc = new ODocument(""classIndexManagerTestClass"");
+    doc.field(""prop1"", ""a"");
+    doc.field(""prop2"", (Object) null);
 
-		final OIndex<?> propZeroIndex = oSuperClass.getClassIndex(""classIndexManagerTestSuperClass.prop0"");
-		Assert.assertEquals(propZeroIndex.getSize(), 1);
-		Assert.assertEquals(propOneIndex.getSize(), 1);
-		Assert.assertEquals(compositeIndex.getSize(), 1);
+    doc.save();
 
-		doc.field(""prop2"", 2);
-		doc.field(""prop0"", ""y"");
+    final OSchema schema = database.getMetadata().getSchema();
+    final OClass oClass = schema.getClass(""classIndexManagerTestClass"");
 
-		doc.delete();
+    final OIndex<?> propOneIndex = oClass.getClassIndex(""classIndexManagerTestClass.prop1"");
+    final OIndex<?> compositeIndex = oClass.getClassIndex(""classIndexManagerComposite"");
 
-		Assert.assertEquals(propZeroIndex.getSize(), 0);
-		Assert.assertEquals(propOneIndex.getSize(), 0);
-		Assert.assertEquals(compositeIndex.getSize(), 0);
-	}
+    Assert.assertEquals(propOneIndex.getSize(), 1);
+    Assert.assertEquals(compositeIndex.getSize(), 0);
 
-	public void testDeleteUpdatedDocumentNullFieldIndexRecordDeleted() {
-		final ODocument doc = new ODocument(""classIndexManagerTestClass"");
-		doc.field(""prop1"", ""a"");
-		doc.field(""prop2"", (Object) null);
+    doc.delete();
 
-		doc.save();
+    Assert.assertEquals(propOneIndex.getSize(), 0);
+    Assert.assertEquals(compositeIndex.getSize(), 0);
+  }
 
-		final OSchema schema = database.getMetadata().getSchema();
-		final OClass oClass = schema.getClass(""classIndexManagerTestClass"");
+  public void testDeleteUpdatedDocumentOrigNullFieldIndexRecordDeleted() {
+    final ODocument doc = new ODocument(""classIndexManagerTestClass"");
+    doc.field(""prop1"", ""a"");
+    doc.field(""prop2"", (Object) null);
 
-		final OIndex<?> propOneIndex = oClass.getClassIndex(""classIndexManagerTestClass.prop1"");
-		final OIndex<?> compositeIndex = oClass.getClassIndex(""classIndexManagerComposite"");
+    doc.save();
 
-		Assert.assertEquals(propOneIndex.getSize(), 1);
-		Assert.assertEquals(compositeIndex.getSize(), 0);
+    final OSchema schema = database.getMetadata().getSchema();
+    final OClass oClass = schema.getClass(""classIndexManagerTestClass"");
 
-		doc.delete();
+    final OIndex<?> propOneIndex = oClass.getClassIndex(""classIndexManagerTestClass.prop1"");
+    final OIndex<?> compositeIndex = oClass.getClassIndex(""classIndexManagerComposite"");
 
-		Assert.assertEquals(propOneIndex.getSize(), 0);
-		Assert.assertEquals(compositeIndex.getSize(), 0);
-	}
+    Assert.assertEquals(propOneIndex.getSize(), 1);
+    Assert.assertEquals(compositeIndex.getSize(), 0);
 
-	public void testDeleteUpdatedDocumentOrigNullFieldIndexRecordDeleted() {
-		final ODocument doc = new ODocument(""classIndexManagerTestClass"");
-		doc.field(""prop1"", ""a"");
-		doc.field(""prop2"", (Object) null);
+    doc.field(""prop2"", 2);
 
-		doc.save();
+    doc.delete();
 
-		final OSchema schema = database.getMetadata().getSchema();
-		final OClass oClass = schema.getClass(""classIndexManagerTestClass"");
+    Assert.assertEquals(propOneIndex.getSize(), 0);
+    Assert.assertEquals(compositeIndex.getSize(), 0);
+  }
 
-		final OIndex<?> propOneIndex = oClass.getClassIndex(""classIndexManagerTestClass.prop1"");
-		final OIndex<?> compositeIndex = oClass.getClassIndex(""classIndexManagerComposite"");
+  public void testNoClassIndexesUpdate() {
+    final ODocument doc = new ODocument(""classIndexManagerTestClassTwo"");
+    doc.field(""prop1"", ""a"");
+    doc.save();
 
-		Assert.assertEquals(propOneIndex.getSize(), 1);
-		Assert.assertEquals(compositeIndex.getSize(), 0);
+    doc.field(""prop1"", ""b"");
+    doc.save();
 
-		doc.field(""prop2"", 2);
+    final OSchema schema = database.getMetadata().getSchema();
+    final OClass oClass = schema.getClass(""classIndexManagerTestClass"");
 
-		doc.delete();
+    final Collection<OIndex<?>> indexes = oClass.getIndexes();
+    for (final OIndex<?> index : indexes) {
+      Assert.assertEquals(index.getSize(), 0);
+    }
+  }
 
-		Assert.assertEquals(propOneIndex.getSize(), 0);
-		Assert.assertEquals(compositeIndex.getSize(), 0);
-	}
+  public void testNoClassIndexesDelete() {
+    final ODocument doc = new ODocument(""classIndexManagerTestClassTwo"");
+    doc.field(""prop1"", ""a"");
+    doc.save();
 
-	public void testNoClassIndexesUpdate() {
-		final ODocument doc = new ODocument(""classIndexManagerTestClassTwo"");
-		doc.field(""prop1"", ""a"");
-		doc.save();
+    doc.delete();
+  }
 
-		doc.field(""prop1"", ""b"");
-		doc.save();
+  public void testCollectionCompositeCreation() {
+    final ODocument doc = new ODocument(""classIndexManagerTestCompositeCollectionClass"");
 
-		final OSchema schema = database.getMetadata().getSchema();
-		final OClass oClass = schema.getClass(""classIndexManagerTestClass"");
+    doc.field(""prop1"", ""test1"");
+    doc.field(""prop2"", Arrays.asList(1, 2));
 
-		final Collection<OIndex<?>> indexes = oClass.getIndexes();
-		for (final OIndex<?> index : indexes) {
-			Assert.assertEquals(index.getSize(), 0);
-		}
-	}
+    doc.save();
 
-	public void testNoClassIndexesDelete() {
-		final ODocument doc = new ODocument(""classIndexManagerTestClassTwo"");
-		doc.field(""prop1"", ""a"");
-		doc.save();
+    final OIndex<?> index = database.getMetadata().getIndexManager().getIndex(""classIndexManagerTestIndexValueAndCollection"");
+    Assert.assertEquals(index.getSize(), 2);
+
+    Assert.assertEquals(index.get(new OCompositeKey(""test1"", 1)), doc.getIdentity());
+    Assert.assertEquals(index.get(new OCompositeKey(""test1"", 2)), doc.getIdentity());
+
+    doc.delete();
+
+    Assert.assertEquals(index.getSize(), 0);
+  }
+
+  public void testCollectionCompositeNullSimpleFieldCreation() {
+    final ODocument doc = new ODocument(""classIndexManagerTestCompositeCollectionClass"");
+
+    doc.field(""prop1"", (Object) null);
+    doc.field(""prop2"", Arrays.asList(1, 2));
+
+    doc.save();
+
+    final OIndex<?> index = database.getMetadata().getIndexManager().getIndex(""classIndexManagerTestIndexValueAndCollection"");
+    Assert.assertEquals(index.getSize(), 0);
+
+    doc.delete();
+  }
+
+  public void testCollectionCompositeNullCollectionFieldCreation() {
+    final ODocument doc = new ODocument(""classIndexManagerTestCompositeCollectionClass"");
+
+    doc.field(""prop1"", ""test1"");
+    doc.field(""prop2"", (Object) null);
+
+    doc.save();
+
+    final OIndex<?> index = database.getMetadata().getIndexManager().getIndex(""classIndexManagerTestIndexValueAndCollection"");
+    Assert.assertEquals(index.getSize(), 0);
+
+    doc.delete();
+  }
+
+  public void testCollectionCompositeUpdateSimpleField() {
+    final ODocument doc = new ODocument(""classIndexManagerTestCompositeCollectionClass"");
+
+    doc.field(""prop1"", ""test1"");
+    doc.field(""prop2"", Arrays.asList(1, 2));
+
+    doc.save();
+
+    final OIndex<?> index = database.getMetadata().getIndexManager().getIndex(""classIndexManagerTestIndexValueAndCollection"");
+    Assert.assertEquals(index.getSize(), 2);
+
+    doc.field(""prop1"", ""test2"");
+
+    doc.save();
+
+    Assert.assertEquals(index.get(new OCompositeKey(""test2"", 1)), doc.getIdentity());
+    Assert.assertEquals(index.get(new OCompositeKey(""test2"", 2)), doc.getIdentity());
+
+    Assert.assertEquals(index.getSize(), 2);
+
+    doc.delete();
+
+    Assert.assertEquals(index.getSize(), 0);
+  }
+
+  public void testCollectionCompositeUpdateCollectionWasAssigned() {
+    final ODocument doc = new ODocument(""classIndexManagerTestCompositeCollectionClass"");
+
+    doc.field(""prop1"", ""test1"");
+    doc.field(""prop2"", Arrays.asList(1, 2));
+
+    doc.save();
+
+    final OIndex<?> index = database.getMetadata().getIndexManager().getIndex(""classIndexManagerTestIndexValueAndCollection"");
+    Assert.assertEquals(index.getSize(), 2);
+
+    doc.field(""prop2"", Arrays.asList(1, 3));
+
+    doc.save();
+
+    Assert.assertEquals(index.get(new OCompositeKey(""test1"", 1)), doc.getIdentity());
+    Assert.assertEquals(index.get(new OCompositeKey(""test1"", 3)), doc.getIdentity());
+
+    Assert.assertEquals(index.getSize(), 2);
+
+    doc.delete();
+
+    Assert.assertEquals(index.getSize(), 0);
+  }
+
+  public void testCollectionCompositeUpdateCollectionWasChanged() {
+    final ODocument doc = new ODocument(""classIndexManagerTestCompositeCollectionClass"");
+
+    doc.field(""prop1"", ""test1"");
+    doc.field(""prop2"", Arrays.asList(1, 2));
+
+    doc.save();
+
+    final OIndex<?> index = database.getMetadata().getIndexManager().getIndex(""classIndexManagerTestIndexValueAndCollection"");
+    Assert.assertEquals(index.getSize(), 2);
+
+    List<Integer> docList = doc.field(""prop2"");
+    docList.add(3);
+    docList.add(4);
+    docList.add(5);
+
+    docList.remove(0);
+
+    doc.save();
+
+    Assert.assertEquals(index.get(new OCompositeKey(""test1"", 2)), doc.getIdentity());
+    Assert.assertEquals(index.get(new OCompositeKey(""test1"", 3)), doc.getIdentity());
+    Assert.assertEquals(index.get(new OCompositeKey(""test1"", 4)), doc.getIdentity());
+    Assert.assertEquals(index.get(new OCompositeKey(""test1"", 5)), doc.getIdentity());
+
+    Assert.assertEquals(index.getSize(), 4);
+
+    doc.delete();
+
+    Assert.assertEquals(index.getSize(), 0);
+  }
+
+  public void testCollectionCompositeUpdateCollectionWasChangedSimpleFieldWasAssigned() {
+    final ODocument doc = new ODocument(""classIndexManagerTestCompositeCollectionClass"");
+
+    doc.field(""prop1"", ""test1"");
+    doc.field(""prop2"", Arrays.asList(1, 2));
+
+    doc.save();
+
+    final OIndex<?> index = database.getMetadata().getIndexManager().getIndex(""classIndexManagerTestIndexValueAndCollection"");
+    Assert.assertEquals(index.getSize(), 2);
+
+    List<Integer> docList = doc.field(""prop2"");
+    docList.add(3);
+    docList.add(4);
+    docList.add(5);
+
+    docList.remove(0);
+
+    doc.field(""prop1"", ""test2"");
+
+    doc.save();
+
+    Assert.assertEquals(index.getSize(), 4);
+
+    Assert.assertEquals(index.get(new OCompositeKey(""test2"", 2)), doc.getIdentity());
+    Assert.assertEquals(index.get(new OCompositeKey(""test2"", 3)), doc.getIdentity());
+    Assert.assertEquals(index.get(new OCompositeKey(""test2"", 4)), doc.getIdentity());
+    Assert.assertEquals(index.get(new OCompositeKey(""test2"", 5)), doc.getIdentity());
+
+    doc.delete();
+
+    Assert.assertEquals(index.getSize(), 0);
+  }
+
+  public void testCollectionCompositeUpdateSimpleFieldNull() {
+    final ODocument doc = new ODocument(""classIndexManagerTestCompositeCollectionClass"");
+
+    doc.field(""prop1"", ""test1"");
+    doc.field(""prop2"", Arrays.asList(1, 2));
+
+    doc.save();
+
+    final OIndex<?> index = database.getMetadata().getIndexManager().getIndex(""classIndexManagerTestIndexValueAndCollection"");
+    Assert.assertEquals(index.getSize(), 2);
+
+    doc.field(""prop1"", (Object) null);
+
+    doc.save();
+
+    Assert.assertEquals(index.getSize(), 0);
+
+    doc.delete();
+
+    Assert.assertEquals(index.getSize(), 0);
+  }
+
+  public void testCollectionCompositeUpdateCollectionWasAssignedNull() {
+    final ODocument doc = new ODocument(""classIndexManagerTestCompositeCollectionClass"");
+
+    doc.field(""prop1"", ""test1"");
+    doc.field(""prop2"", Arrays.asList(1, 2));
+
+    doc.save();
+
+    final OIndex<?> index = database.getMetadata().getIndexManager().getIndex(""classIndexManagerTestIndexValueAndCollection"");
+    Assert.assertEquals(index.getSize(), 2);
+
+    doc.field(""prop2"", (Object) null);
+
+    doc.save();
+
+    Assert.assertEquals(index.getSize(), 0);
+
+    doc.delete();
+
+    Assert.assertEquals(index.getSize(), 0);
+  }
+
+  public void testCollectionCompositeUpdateBothAssignedNull() {
+    final ODocument doc = new ODocument(""classIndexManagerTestCompositeCollectionClass"");
+
+    doc.field(""prop1"", ""test1"");
+    doc.field(""prop2"", Arrays.asList(1, 2));
+
+    doc.save();
+
+    final OIndex<?> index = database.getMetadata().getIndexManager().getIndex(""classIndexManagerTestIndexValueAndCollection"");
+    Assert.assertEquals(index.getSize(), 2);
+
+    doc.field(""prop2"", (Object) null);
+    doc.field(""prop1"", (Object) null);
+
+    doc.save();
+
+    Assert.assertEquals(index.getSize(), 0);
+
+    doc.delete();
+
+    Assert.assertEquals(index.getSize(), 0);
+  }
+
+  public void testCollectionCompositeUpdateCollectionWasChangedSimpleFieldWasAssignedNull() {
+    final ODocument doc = new ODocument(""classIndexManagerTestCompositeCollectionClass"");
+
+    doc.field(""prop1"", ""test1"");
+    doc.field(""prop2"", Arrays.asList(1, 2));
+
+    doc.save();
+
+    final OIndex<?> index = database.getMetadata().getIndexManager().getIndex(""classIndexManagerTestIndexValueAndCollection"");
+    Assert.assertEquals(index.getSize(), 2);
+
+    List<Integer> docList = doc.field(""prop2"");
+    docList.add(3);
+    docList.add(4);
+    docList.add(5);
+
+    docList.remove(0);
+
+    doc.field(""prop1"", (Object) null);
+
+    doc.save();
+
+    Assert.assertEquals(index.getSize(), 0);
+
+    doc.delete();
+
+    Assert.assertEquals(index.getSize(), 0);
+  }
+
+  public void testCollectionCompositeDeleteSimpleFieldAssigend() {
+    final ODocument doc = new ODocument(""classIndexManagerTestCompositeCollectionClass"");
+
+    doc.field(""prop1"", ""test1"");
+    doc.field(""prop2"", Arrays.asList(1, 2));
+
+    doc.save();
+
+    final OIndex<?> index = database.getMetadata().getIndexManager().getIndex(""classIndexManagerTestIndexValueAndCollection"");
+    Assert.assertEquals(index.getSize(), 2);
+
+    doc.field(""prop1"", ""test2"");
+    doc.delete();
+
+    Assert.assertEquals(index.getSize(), 0);
+  }
+
+  public void testCollectionCompositeDeleteCollectionFieldAssigend() {
+    final ODocument doc = new ODocument(""classIndexManagerTestCompositeCollectionClass"");
+
+    doc.field(""prop1"", ""test1"");
+    doc.field(""prop2"", Arrays.asList(1, 2));
+
+    doc.save();
+
+    final OIndex<?> index = database.getMetadata().getIndexManager().getIndex(""classIndexManagerTestIndexValueAndCollection"");
+    Assert.assertEquals(index.getSize(), 2);
+
+    doc.field(""prop2"", Arrays.asList(1, 3));
+    doc.delete();
+
+    Assert.assertEquals(index.getSize(), 0);
+  }
+
+  public void testCollectionCompositeDeleteCollectionFieldChanged() {
+    final ODocument doc = new ODocument(""classIndexManagerTestCompositeCollectionClass"");
+
+    doc.field(""prop1"", ""test1"");
+    doc.field(""prop2"", Arrays.asList(1, 2));
+
+    doc.save();
+
+    final OIndex<?> index = database.getMetadata().getIndexManager().getIndex(""classIndexManagerTestIndexValueAndCollection"");
+    Assert.assertEquals(index.getSize(), 2);
+
+    List<Integer> docList = doc.field(""prop2"");
+    docList.add(3);
+    docList.add(4);
+
+    docList.remove(1);
+
+    doc.delete();
+
+    Assert.assertEquals(index.getSize(), 0);
+  }
+
+  public void testCollectionCompositeDeleteBothCollectionSimpleFieldChanged() {
+    final ODocument doc = new ODocument(""classIndexManagerTestCompositeCollectionClass"");
+
+    doc.field(""prop1"", ""test1"");
+    doc.field(""prop2"", Arrays.asList(1, 2));
+
+    doc.save();
+
+    final OIndex<?> index = database.getMetadata().getIndexManager().getIndex(""classIndexManagerTestIndexValueAndCollection"");
+    Assert.assertEquals(index.getSize(), 2);
+
+    List<Integer> docList = doc.field(""prop2"");
+    docList.add(3);
+    docList.add(4);
+
+    docList.remove(1);
+
+    doc.field(""prop1"", ""test2"");
+
+    doc.delete();
+
+    Assert.assertEquals(index.getSize(), 0);
+  }
+
+  public void testCollectionCompositeDeleteBothCollectionSimpleFieldAssigend() {
+    final ODocument doc = new ODocument(""classIndexManagerTestCompositeCollectionClass"");
+
+    doc.field(""prop1"", ""test1"");
+    doc.field(""prop2"", Arrays.asList(1, 2));
+
+    doc.save();
+
+    final OIndex<?> index = database.getMetadata().getIndexManager().getIndex(""classIndexManagerTestIndexValueAndCollection"");
+    Assert.assertEquals(index.getSize(), 2);
+
+    doc.field(""prop2"", Arrays.asList(1, 3));
+    doc.field(""prop1"", ""test2"");
+    doc.delete();
+
+    Assert.assertEquals(index.getSize(), 0);
+  }
+
+  public void testCollectionCompositeDeleteSimpleFieldNull() {
+    final ODocument doc = new ODocument(""classIndexManagerTestCompositeCollectionClass"");
+
+    doc.field(""prop1"", ""test1"");
+    doc.field(""prop2"", Arrays.asList(1, 2));
+
+    doc.save();
+
+    final OIndex<?> index = database.getMetadata().getIndexManager().getIndex(""classIndexManagerTestIndexValueAndCollection"");
+    Assert.assertEquals(index.getSize(), 2);
+
+    doc.field(""prop1"", (Object) null);
+    doc.delete();
+
+    Assert.assertEquals(index.getSize(), 0);
+  }
+
+  public void testCollectionCompositeDeleteCollectionFieldNull() {
+    final ODocument doc = new ODocument(""classIndexManagerTestCompositeCollectionClass"");
+
+    doc.field(""prop1"", ""test1"");
+    doc.field(""prop2"", Arrays.asList(1, 2));
+
+    doc.save();
+
+    final OIndex<?> index = database.getMetadata().getIndexManager().getIndex(""classIndexManagerTestIndexValueAndCollection"");
+    Assert.assertEquals(index.getSize(), 2);
+
+    doc.field(""prop2"", (Object) null);
+    doc.delete();
+
+    Assert.assertEquals(index.getSize(), 0);
+  }
+
+  public void testCollectionCompositeDeleteBothSimpleCollectionFieldNull() {
+    final ODocument doc = new ODocument(""classIndexManagerTestCompositeCollectionClass"");
+
+    doc.field(""prop1"", ""test1"");
+    doc.field(""prop2"", Arrays.asList(1, 2));
+
+    doc.save();
+
+    final OIndex<?> index = database.getMetadata().getIndexManager().getIndex(""classIndexManagerTestIndexValueAndCollection"");
+    Assert.assertEquals(index.getSize(), 2);
+
+    doc.field(""prop2"", (Object) null);
+    doc.field(""prop1"", (Object) null);
+    doc.delete();
+
+    Assert.assertEquals(index.getSize(), 0);
+  }
+
+  public void testCollectionCompositeDeleteCollectionFieldChangedSimpleFieldNull() {
+    final ODocument doc = new ODocument(""classIndexManagerTestCompositeCollectionClass"");
+
+    doc.field(""prop1"", ""test1"");
+    doc.field(""prop2"", Arrays.asList(1, 2));
+
+    doc.save();
+
+    final OIndex<?> index = database.getMetadata().getIndexManager().getIndex(""classIndexManagerTestIndexValueAndCollection"");
+    Assert.assertEquals(index.getSize(), 2);
+
+    List<Integer> docList = doc.field(""prop2"");
+    docList.add(3);
+    docList.add(4);
+
+    docList.remove(1);
+
+    doc.field(""prop1"", (Object) null);
+
+    doc.delete();
+
+    Assert.assertEquals(index.getSize(), 0);
+  }
 
-		doc.delete();
-	}
 }
diff --git a/tests/src/test/java/com/orientechnologies/orient/test/database/auto/ClassIndexTest.java b/tests/src/test/java/com/orientechnologies/orient/test/database/auto/ClassIndexTest.java
index 95ddf4feb9..49edf9e838 100644
--- a/tests/src/test/java/com/orientechnologies/orient/test/database/auto/ClassIndexTest.java
+++ b/tests/src/test/java/com/orientechnologies/orient/test/database/auto/ClassIndexTest.java
@@ -1,12 +1,9 @@
 package com.orientechnologies.orient.test.database.auto;
 
-import com.orientechnologies.common.listener.OProgressListener;
-import com.orientechnologies.orient.core.db.document.ODatabaseDocumentTx;
-import com.orientechnologies.orient.core.index.*;
-import com.orientechnologies.orient.core.metadata.schema.OClass;
-import com.orientechnologies.orient.core.metadata.schema.OSchema;
-import com.orientechnologies.orient.core.metadata.schema.OType;
-import com.orientechnologies.orient.core.sql.OCommandSQL;
-import org.testng.annotations.*;
+import static org.testng.Assert.assertEquals;
+import static org.testng.Assert.assertFalse;
+import static org.testng.Assert.assertNull;
+import static org.testng.Assert.assertTrue;
+import static org.testng.Assert.fail;
 
 import java.util.Arrays;
@@ -16,46 +13,75 @@ import java.util.Set;
 import java.util.concurrent.atomic.AtomicInteger;
 
-import static org.testng.Assert.*;
-import static org.testng.Assert.assertEquals;
+import org.testng.annotations.AfterClass;
+import org.testng.annotations.AfterMethod;
+import org.testng.annotations.BeforeClass;
+import org.testng.annotations.BeforeMethod;
+import org.testng.annotations.Parameters;
+import org.testng.annotations.Test;
 
-@Test(groups = {""index""})
-public class ClassIndexTest
-{
+import com.orientechnologies.common.listener.OProgressListener;
+import com.orientechnologies.orient.core.db.document.ODatabaseDocumentTx;
+import com.orientechnologies.orient.core.index.OCompositeIndexDefinition;
+import com.orientechnologies.orient.core.index.OIndex;
+import com.orientechnologies.orient.core.index.OIndexDefinition;
+import com.orientechnologies.orient.core.index.OIndexException;
+import com.orientechnologies.orient.core.index.OPropertyIndexDefinition;
+import com.orientechnologies.orient.core.index.OPropertyListIndexDefinition;
+import com.orientechnologies.orient.core.index.OPropertyMapIndexDefinition;
+import com.orientechnologies.orient.core.metadata.schema.OClass;
+import com.orientechnologies.orient.core.metadata.schema.OSchema;
+import com.orientechnologies.orient.core.metadata.schema.OType;
+import com.orientechnologies.orient.core.sql.OCommandSQL;
+
+@Test(groups = { ""index"" })
+public class ClassIndexTest {
   private final ODatabaseDocumentTx database;
-  private OClass oClass;
-  private OClass oSuperClass;
+  private OClass                    oClass;
+  private OClass                    oSuperClass;
 
   @Parameters(value = ""url"")
-  public ClassIndexTest( final String iURL )
-  {
-    database = new ODatabaseDocumentTx( iURL );
+  public ClassIndexTest(final String iURL) {
+    database = new ODatabaseDocumentTx(iURL);
   }
 
   @BeforeClass
-  public void beforeClass()
-  {
-    if ( database.isClosed() ) {
-      database.open( ""admin"", ""admin"" );
+  public void beforeClass() {
+    if (database.isClosed()) {
+      database.open(""admin"", ""admin"");
     }
 
     final OSchema schema = database.getMetadata().getSchema();
 
-    oClass = schema.createClass( ""ClassIndexTestClass"" );
-    oSuperClass = schema.createClass( ""ClassIndexTestSuperClass"" );
+    oClass = schema.createClass(""ClassIndexTestClass"");
+    oSuperClass = schema.createClass(""ClassIndexTestSuperClass"");
+
+    oClass.createProperty(""fOne"", OType.INTEGER);
+    oClass.createProperty(""fTwo"", OType.STRING);
+    oClass.createProperty(""fThree"", OType.BOOLEAN);
+    oClass.createProperty(""fFour"", OType.INTEGER);
+
+    oClass.createProperty(""fSix"", OType.STRING);
+    oClass.createProperty(""fSeven"", OType.STRING);
+
+    oClass.createProperty(""fEight"", OType.INTEGER);
+    oClass.createProperty(""fTen"", OType.INTEGER);
+    oClass.createProperty(""fEleven"", OType.INTEGER);
+    oClass.createProperty(""fTwelve"", OType.INTEGER);
+    oClass.createProperty(""fThirteen"", OType.INTEGER);
+    oClass.createProperty(""fFourteen"", OType.INTEGER);
+    oClass.createProperty(""fFifteen"", OType.INTEGER);
 
+    oClass.createProperty(""fEmbeddedMap"", OType.EMBEDDEDMAP, OType.INTEGER);
+    oClass.createProperty(""fEmbeddedMapWithoutLinkedType"", OType.EMBEDDEDMAP);
+    oClass.createProperty(""fLinkMap"", OType.LINKMAP);
 
-    oClass.createProperty( ""fOne"", OType.INTEGER );
-    oClass.createProperty( ""fTwo"", OType.STRING );
-    oClass.createProperty( ""fThree"", OType.BOOLEAN );
-    oClass.createProperty( ""fFour"", OType.INTEGER );
+    oClass.createProperty(""fLinkList"", OType.LINKLIST);
+    oClass.createProperty(""fEmbeddedList"", OType.EMBEDDEDLIST, OType.INTEGER);
 
-    oClass.createProperty( ""fSix"", OType.STRING );
-    oClass.createProperty( ""fSeven"", OType.STRING );
-    oClass.createProperty( ""fEmbeddedMap"", OType.EMBEDDEDMAP, OType.INTEGER );
-    oClass.createProperty( ""fEmbeddedMapWithoutLinkedType"", OType.EMBEDDEDMAP );
-    oClass.createProperty( ""fLinkMap"", OType.LINKMAP );
+    oClass.createProperty(""fEmbeddedSet"", OType.EMBEDDEDSET, OType.INTEGER);
+    oClass.createProperty(""fLinkSet"", OType.LINKSET);
 
-    oSuperClass.createProperty( ""fNine"", OType.INTEGER );
-    oClass.setSuperClass( oSuperClass );
+    oSuperClass.createProperty(""fNine"", OType.INTEGER);
+    oClass.setSuperClass(oSuperClass);
 
     schema.save();
@@ -64,32 +90,29 @@ public class ClassIndexTest
 
   @BeforeMethod
-  public void beforeMethod()
-  {
-    database.open( ""admin"", ""admin"" );
+  public void beforeMethod() {
+    database.open(""admin"", ""admin"");
   }
 
   @AfterMethod
-  public void afterMethod()
-  {
+  public void afterMethod() {
     database.close();
   }
 
   @AfterClass
-  public void afterClass()
-  {
-    if ( database.isClosed() ) {
-      database.open( ""admin"", ""admin"" );
+  public void afterClass() {
+    if (database.isClosed()) {
+      database.open(""admin"", ""admin"");
     }
 
-    database.command( new OCommandSQL( ""delete from ClassIndexTestClass"" ) ).execute();
-    database.command( new OCommandSQL( ""delete from ClassIndexTestSuperClass"" ) ).execute();
-    database.command( new OCommandSQL( ""delete from ClassIndexInTest"" ) ).execute();
+    database.command(new OCommandSQL(""delete from ClassIndexTestClass"")).execute();
+    database.command(new OCommandSQL(""delete from ClassIndexTestSuperClass"")).execute();
+    database.command(new OCommandSQL(""delete from ClassIndexInTest"")).execute();
 
-    database.command( new OCommandSQL( ""drop class ClassIndexInTest"" ) ).execute();
-    database.command( new OCommandSQL( ""drop class ClassIndexTestClass"" ) ).execute();
+    database.command(new OCommandSQL(""drop class ClassIndexInTest"")).execute();
+    database.command(new OCommandSQL(""drop class ClassIndexTestClass"")).execute();
 
     database.getMetadata().getSchema().reload();
 
-    database.command( new OCommandSQL( ""drop class ClassIndexTestSuperClass"" ) ).execute();
+    database.command(new OCommandSQL(""drop class ClassIndexTestSuperClass"")).execute();
 
     database.getMetadata().getSchema().reload();
@@ -100,951 +123,1127 @@ public class ClassIndexTest
 
   @Test
-  public void testCreateOnePropertyIndexTest()
-  {
-    final OIndex result = oClass.createIndex( ""ClassIndexTestPropertyOne"", OClass.INDEX_TYPE.UNIQUE, ""fOne"" );
+  public void testCreateOnePropertyIndexTest() {
+    final OIndex result = oClass.createIndex(""ClassIndexTestPropertyOne"", OClass.INDEX_TYPE.UNIQUE, ""fOne"");
 
-    assertEquals( result.getName(), ""ClassIndexTestPropertyOne"" );
-    assertEquals( oClass.getClassIndex( ""ClassIndexTestPropertyOne"" ).getName(), result.getName() );
-    assertEquals(
-      database.getMetadata().getIndexManager().getClassIndex( ""ClassIndexTestClass"", ""ClassIndexTestPropertyOne"" ).getName(),
-      result.getName() );
+    assertEquals(result.getName(), ""ClassIndexTestPropertyOne"");
+    assertEquals(oClass.getClassIndex(""ClassIndexTestPropertyOne"").getName(), result.getName());
+    assertEquals(database.getMetadata().getIndexManager().getClassIndex(""ClassIndexTestClass"", ""ClassIndexTestPropertyOne"")
+        .getName(), result.getName());
 
   }
 
-	@Test
-	public void testCreateOnePropertyIndexInvalidName()
-	{
-		try {
-			oClass.createIndex( ""ClassIndex:TestPropertyOne"", OClass.INDEX_TYPE.UNIQUE, ""fOne"" );
-			fail();
-		} catch (Exception e) {
-			if(e.getCause() != null)
-				e = (Exception)e.getCause();
+  @Test
+  public void testCreateOnePropertyIndexInvalidName() {
+    try {
+      oClass.createIndex(""ClassIndex:TestPropertyOne"", OClass.INDEX_TYPE.UNIQUE, ""fOne"");
+      fail();
+    } catch (Exception e) {
+      if (e.getCause() != null)
+        e = (Exception) e.getCause();
 
-			assertTrue(e instanceof IllegalArgumentException);
-		}
-	}
+      assertTrue(e instanceof IllegalArgumentException);
+    }
+  }
 
-	@Test
-  public void createCompositeIndexTestWithoutListener()
-  {
-    final OIndex result = oClass.createIndex( ""ClassIndexTestCompositeOne"", OClass.INDEX_TYPE.UNIQUE, ""fOne"", ""fTwo"" );
+  @Test
+  public void createCompositeIndexTestWithoutListener() {
+    final OIndex result = oClass.createIndex(""ClassIndexTestCompositeOne"", OClass.INDEX_TYPE.UNIQUE, ""fOne"", ""fTwo"");
 
-    assertEquals( result.getName(), ""ClassIndexTestCompositeOne"" );
-    assertEquals( oClass.getClassIndex( ""ClassIndexTestCompositeOne"" ).getName(), result.getName() );
-    assertEquals( database.getMetadata().getIndexManager().getClassIndex( ""ClassIndexTestClass"", ""ClassIndexTestCompositeOne"" ).getName(),
-      result.getName() );
+    assertEquals(result.getName(), ""ClassIndexTestCompositeOne"");
+    assertEquals(oClass.getClassIndex(""ClassIndexTestCompositeOne"").getName(), result.getName());
+    assertEquals(database.getMetadata().getIndexManager().getClassIndex(""ClassIndexTestClass"", ""ClassIndexTestCompositeOne"")
+        .getName(), result.getName());
   }
 
   @Test
-  public void createCompositeIndexTestWithListener()
-  {
-    final AtomicInteger atomicInteger = new AtomicInteger( 0 );
-    final OProgressListener progressListener = new OProgressListener()
-    {
-      public void onBegin( final Object iTask, final long iTotal )
-      {
+  public void createCompositeIndexTestWithListener() {
+    final AtomicInteger atomicInteger = new AtomicInteger(0);
+    final OProgressListener progressListener = new OProgressListener() {
+      public void onBegin(final Object iTask, final long iTotal) {
         atomicInteger.incrementAndGet();
       }
 
-      public boolean onProgress( final Object iTask, final long iCounter, final float iPercent )
-      {
+      public boolean onProgress(final Object iTask, final long iCounter, final float iPercent) {
         return true;
       }
 
-      public void onCompletition( final Object iTask, final boolean iSucceed )
-      {
+      public void onCompletition(final Object iTask, final boolean iSucceed) {
         atomicInteger.incrementAndGet();
       }
     };
 
-    final OIndex result = oClass.createIndex( ""ClassIndexTestCompositeTwo"", OClass.INDEX_TYPE.UNIQUE,
-      progressListener, ""fOne"", ""fTwo"", ""fThree"" );
+    final OIndex result = oClass.createIndex(""ClassIndexTestCompositeTwo"", OClass.INDEX_TYPE.UNIQUE, progressListener, ""fOne"",
+        ""fTwo"", ""fThree"");
+
+    assertEquals(result.getName(), ""ClassIndexTestCompositeTwo"");
+    assertEquals(oClass.getClassIndex(""ClassIndexTestCompositeTwo"").getName(), result.getName());
+    assertEquals(database.getMetadata().getIndexManager().getClassIndex(""ClassIndexTestClass"", ""ClassIndexTestCompositeTwo"")
+        .getName(), result.getName());
+    assertEquals(atomicInteger.get(), 2);
+  }
+
+  @Test
+  public void testCreateOnePropertyEmbeddedMapIndex() {
+    final OIndex result = oClass.createIndex(""ClassIndexTestPropertyEmbeddedMap"", OClass.INDEX_TYPE.UNIQUE, ""fEmbeddedMap"");
+
+    assertEquals(result.getName(), ""ClassIndexTestPropertyEmbeddedMap"");
+    assertEquals(oClass.getClassIndex(""ClassIndexTestPropertyEmbeddedMap"").getName(), result.getName());
+    assertEquals(database.getMetadata().getIndexManager().getClassIndex(""ClassIndexTestClass"", ""ClassIndexTestPropertyEmbeddedMap"")
+        .getName(), result.getName());
+
+    final OIndexDefinition indexDefinition = result.getDefinition();
+
+    assertTrue(indexDefinition instanceof OPropertyMapIndexDefinition);
+    assertEquals(indexDefinition.getFields().get(0), ""fEmbeddedMap"");
+    assertEquals(indexDefinition.getTypes()[0], OType.STRING);
+    assertEquals(((OPropertyMapIndexDefinition) indexDefinition).getIndexBy(), OPropertyMapIndexDefinition.INDEX_BY.KEY);
+  }
+
+  @Test
+  public void testCreateCompositeEmbeddedMapIndex() {
+    final OIndex result = oClass.createIndex(""ClassIndexTestCompositeEmbeddedMap"", OClass.INDEX_TYPE.UNIQUE, ""fFifteen"",
+        ""fEmbeddedMap"");
+
+    assertEquals(result.getName(), ""ClassIndexTestCompositeEmbeddedMap"");
+    assertEquals(oClass.getClassIndex(""ClassIndexTestCompositeEmbeddedMap"").getName(), result.getName());
+    assertEquals(database.getMetadata().getIndexManager()
+        .getClassIndex(""ClassIndexTestClass"", ""ClassIndexTestCompositeEmbeddedMap"").getName(), result.getName());
 
-    assertEquals( result.getName(), ""ClassIndexTestCompositeTwo"" );
-    assertEquals( oClass.getClassIndex( ""ClassIndexTestCompositeTwo"" ).getName(), result.getName() );
-    assertEquals( database.getMetadata().getIndexManager().getClassIndex( ""ClassIndexTestClass"", ""ClassIndexTestCompositeTwo"" ).getName(),
-      result.getName() );
-    assertEquals( atomicInteger.get(), 2 );
+    final OIndexDefinition indexDefinition = result.getDefinition();
+
+    assertTrue(indexDefinition instanceof OCompositeIndexDefinition);
+    assertEquals(indexDefinition.getFields().toArray(), new String[] { ""fFifteen"", ""fEmbeddedMap"" });
+
+    assertEquals(indexDefinition.getTypes(), new OType[] { OType.INTEGER, OType.STRING });
+    assertEquals(indexDefinition.getParamCount(), 2);
   }
 
   @Test
-  public void testCreateOnePropertyEmbeddedMapIndex()
-  {
-    final OIndex result = oClass.createIndex( ""ClassIndexTestPropertyEmbeddedMap"", OClass.INDEX_TYPE.UNIQUE, ""fEmbeddedMap"" );
+  public void testCreateCompositeEmbeddedMapByKeyIndex() {
+    final OIndex result = oClass.createIndex(""ClassIndexTestCompositeEmbeddedMapByKey"", OClass.INDEX_TYPE.UNIQUE, ""fEight"",
+        ""fEmbeddedMap"");
 
-    assertEquals( result.getName(), ""ClassIndexTestPropertyEmbeddedMap"" );
-    assertEquals( oClass.getClassIndex( ""ClassIndexTestPropertyEmbeddedMap"" ).getName(), result.getName() );
+    assertEquals(result.getName(), ""ClassIndexTestCompositeEmbeddedMapByKey"");
+    assertEquals(oClass.getClassIndex(""ClassIndexTestCompositeEmbeddedMapByKey"").getName(), result.getName());
     assertEquals(
-      database.getMetadata().getIndexManager().getClassIndex( ""ClassIndexTestClass"", ""ClassIndexTestPropertyEmbeddedMap"" ).getName(),
-      result.getName() );
+        database.getMetadata().getIndexManager().getClassIndex(""ClassIndexTestClass"", ""ClassIndexTestCompositeEmbeddedMapByKey"")
+            .getName(), result.getName());
 
     final OIndexDefinition indexDefinition = result.getDefinition();
 
-    assertTrue( indexDefinition instanceof OPropertyMapIndexDefinition );
-    assertEquals( indexDefinition.getFields().get( 0 ), ""fEmbeddedMap"" );
-    assertEquals( indexDefinition.getTypes()[0], OType.STRING );
-    assertEquals(((OPropertyMapIndexDefinition)indexDefinition).getIndexBy(), OPropertyMapIndexDefinition.INDEX_BY.KEY );
+    assertTrue(indexDefinition instanceof OCompositeIndexDefinition);
+    assertEquals(indexDefinition.getFields().toArray(), new String[] { ""fEight"", ""fEmbeddedMap"" });
+
+    assertEquals(indexDefinition.getTypes(), new OType[] { OType.INTEGER, OType.STRING });
+    assertEquals(indexDefinition.getParamCount(), 2);
   }
 
   @Test
-  public void testCreateOnePropertyLinkedMapIndex()
-  {
-    final OIndex result = oClass.createIndex( ""ClassIndexTestPropertyLinkedMap"", OClass.INDEX_TYPE.UNIQUE, ""fLinkMap"" );
+  public void testCreateCompositeEmbeddedMapByValueIndex() {
+    final OIndex result = oClass.createIndex(""ClassIndexTestCompositeEmbeddedMapByValue"", OClass.INDEX_TYPE.UNIQUE, ""fTen"",
+        ""fEmbeddedMap by value"");
 
-    assertEquals( result.getName(), ""ClassIndexTestPropertyLinkedMap"" );
-    assertEquals( oClass.getClassIndex( ""ClassIndexTestPropertyLinkedMap"" ).getName(), result.getName() );
+    assertEquals(result.getName(), ""ClassIndexTestCompositeEmbeddedMapByValue"");
+    assertEquals(oClass.getClassIndex(""ClassIndexTestCompositeEmbeddedMapByValue"").getName(), result.getName());
     assertEquals(
-      database.getMetadata().getIndexManager().getClassIndex( ""ClassIndexTestClass"", ""ClassIndexTestPropertyLinkedMap"" ).getName(),
-      result.getName() );
+        database.getMetadata().getIndexManager().getClassIndex(""ClassIndexTestClass"", ""ClassIndexTestCompositeEmbeddedMapByValue"")
+            .getName(), result.getName());
 
     final OIndexDefinition indexDefinition = result.getDefinition();
 
-    assertTrue( indexDefinition instanceof OPropertyMapIndexDefinition );
-    assertEquals( indexDefinition.getFields().get( 0 ), ""fLinkMap"" );
-    assertEquals( indexDefinition.getTypes()[0], OType.STRING );
-    assertEquals(((OPropertyMapIndexDefinition)indexDefinition).getIndexBy(), OPropertyMapIndexDefinition.INDEX_BY.KEY );
+    assertTrue(indexDefinition instanceof OCompositeIndexDefinition);
+    assertEquals(indexDefinition.getFields().toArray(), new String[] { ""fTen"", ""fEmbeddedMap"" });
+
+    assertEquals(indexDefinition.getTypes(), new OType[] { OType.INTEGER, OType.INTEGER });
+    assertEquals(indexDefinition.getParamCount(), 2);
   }
 
   @Test
-  public void testCreateOnePropertyLinkMapByKeyIndex()
-  {
-    final OIndex result = oClass.createIndex( ""ClassIndexTestPropertyLinkedMap"", OClass.INDEX_TYPE.UNIQUE, ""fLinkMap by key"" );
+  public void testCreateCompositeLinkMapByValueIndex() {
+    final OIndex result = oClass.createIndex(""ClassIndexTestCompositeLinkMapByValue"", OClass.INDEX_TYPE.UNIQUE, ""fEleven"",
+        ""fLinkMap by value"");
 
-    assertEquals( result.getName(), ""ClassIndexTestPropertyLinkedMap"" );
-    assertEquals( oClass.getClassIndex( ""ClassIndexTestPropertyLinkedMap"" ).getName(), result.getName() );
+    assertEquals(result.getName(), ""ClassIndexTestCompositeLinkMapByValue"");
+    assertEquals(oClass.getClassIndex(""ClassIndexTestCompositeLinkMapByValue"").getName(), result.getName());
     assertEquals(
-      database.getMetadata().getIndexManager().getClassIndex( ""ClassIndexTestClass"", ""ClassIndexTestPropertyLinkedMap"" ).getName(),
-      result.getName() );
+        database.getMetadata().getIndexManager().getClassIndex(""ClassIndexTestClass"", ""ClassIndexTestCompositeLinkMapByValue"")
+            .getName(), result.getName());
 
     final OIndexDefinition indexDefinition = result.getDefinition();
 
-    assertTrue( indexDefinition instanceof OPropertyMapIndexDefinition );
-    assertEquals( indexDefinition.getFields().get( 0 ), ""fLinkMap"" );
-    assertEquals( indexDefinition.getTypes()[0], OType.STRING );
-    assertEquals(((OPropertyMapIndexDefinition)indexDefinition).getIndexBy(), OPropertyMapIndexDefinition.INDEX_BY.KEY );
+    assertTrue(indexDefinition instanceof OCompositeIndexDefinition);
+    assertEquals(indexDefinition.getFields().toArray(), new String[] { ""fEleven"", ""fLinkMap"" });
+
+    assertEquals(indexDefinition.getTypes(), new OType[] { OType.INTEGER, OType.LINK });
+    assertEquals(indexDefinition.getParamCount(), 2);
+  }
+
+  @Test
+  public void testCreateCompositeEmbeddedSetIndex() {
+    final OIndex result = oClass.createIndex(""ClassIndexTestCompositeEmbeddedSet"", OClass.INDEX_TYPE.UNIQUE, ""fTwelve"",
+        ""fEmbeddedSet"");
+
+    assertEquals(result.getName(), ""ClassIndexTestCompositeEmbeddedSet"");
+    assertEquals(oClass.getClassIndex(""ClassIndexTestCompositeEmbeddedSet"").getName(), result.getName());
+    assertEquals(database.getMetadata().getIndexManager()
+        .getClassIndex(""ClassIndexTestClass"", ""ClassIndexTestCompositeEmbeddedSet"").getName(), result.getName());
+
+    final OIndexDefinition indexDefinition = result.getDefinition();
+
+    assertTrue(indexDefinition instanceof OCompositeIndexDefinition);
+    assertEquals(indexDefinition.getFields().toArray(), new String[] { ""fTwelve"", ""fEmbeddedSet"" });
+
+    assertEquals(indexDefinition.getTypes(), new OType[] { OType.INTEGER, OType.INTEGER });
+    assertEquals(indexDefinition.getParamCount(), 2);
+  }
+
+  @Test(expectedExceptions = OIndexException.class)
+  public void testCreateCompositeLinkSetIndex() {
+    oClass.createIndex(""ClassIndexTestCompositeLinkSet"", OClass.INDEX_TYPE.UNIQUE, ""fTwelve"", ""fLinkSet"");
   }
 
   @Test
-  public void testCreateOnePropertyLinkMapByValueIndex()
-  {
-    final OIndex result = oClass.createIndex( ""ClassIndexTestPropertyLinkedMap"", OClass.INDEX_TYPE.UNIQUE, ""fLinkMap by value"" );
+  public void testCreateCompositeEmbeddedListIndex() {
+    final OIndex result = oClass.createIndex(""ClassIndexTestCompositeEmbeddedList"", OClass.INDEX_TYPE.UNIQUE, ""fThirteen"",
+        ""fEmbeddedList"");
 
-    assertEquals( result.getName(), ""ClassIndexTestPropertyLinkedMap"" );
-    assertEquals( oClass.getClassIndex( ""ClassIndexTestPropertyLinkedMap"" ).getName(), result.getName() );
+    assertEquals(result.getName(), ""ClassIndexTestCompositeEmbeddedList"");
+    assertEquals(oClass.getClassIndex(""ClassIndexTestCompositeEmbeddedList"").getName(), result.getName());
     assertEquals(
-      database.getMetadata().getIndexManager().getClassIndex( ""ClassIndexTestClass"", ""ClassIndexTestPropertyLinkedMap"" ).getName(),
-      result.getName() );
+        database.getMetadata().getIndexManager().getClassIndex(""ClassIndexTestClass"", ""ClassIndexTestCompositeEmbeddedList"")
+            .getName(), result.getName());
 
     final OIndexDefinition indexDefinition = result.getDefinition();
 
-    assertTrue( indexDefinition instanceof OPropertyMapIndexDefinition );
-    assertEquals( indexDefinition.getFields().get( 0 ), ""fLinkMap"" );
-    assertEquals( indexDefinition.getTypes()[0], OType.LINK );
-    assertEquals(((OPropertyMapIndexDefinition)indexDefinition).getIndexBy(), OPropertyMapIndexDefinition.INDEX_BY.VALUE );
+    assertTrue(indexDefinition instanceof OCompositeIndexDefinition);
+    assertEquals(indexDefinition.getFields().toArray(), new String[] { ""fThirteen"", ""fEmbeddedList"" });
+
+    assertEquals(indexDefinition.getTypes(), new OType[] { OType.INTEGER, OType.INTEGER });
+    assertEquals(indexDefinition.getParamCount(), 2);
   }
 
+  @Test
+  public void testCreateCompositeLinkListIndex() {
+    final OIndex result = oClass.createIndex(""ClassIndexTestCompositeLinkList"", OClass.INDEX_TYPE.UNIQUE, ""fFourteen"", ""fLinkList"");
+
+    assertEquals(result.getName(), ""ClassIndexTestCompositeLinkList"");
+    assertEquals(oClass.getClassIndex(""ClassIndexTestCompositeLinkList"").getName(), result.getName());
+    assertEquals(database.getMetadata().getIndexManager().getClassIndex(""ClassIndexTestClass"", ""ClassIndexTestCompositeLinkList"")
+        .getName(), result.getName());
+
+    final OIndexDefinition indexDefinition = result.getDefinition();
+
+    assertTrue(indexDefinition instanceof OCompositeIndexDefinition);
+    assertEquals(indexDefinition.getFields().toArray(), new String[] { ""fFourteen"", ""fLinkList"" });
+
+    assertEquals(indexDefinition.getTypes(), new OType[] { OType.INTEGER, OType.LINK });
+    assertEquals(indexDefinition.getParamCount(), 2);
+  }
 
   @Test
-  public void testCreateOnePropertyByKeyEmbeddedMapIndex()
-  {
-    final OIndex result = oClass.createIndex( ""ClassIndexTestPropertyByKeyEmbeddedMap"", OClass.INDEX_TYPE.UNIQUE, ""fEmbeddedMap by key"" );
+  public void testCreateOnePropertyLinkedMapIndex() {
+    final OIndex result = oClass.createIndex(""ClassIndexTestPropertyLinkedMap"", OClass.INDEX_TYPE.UNIQUE, ""fLinkMap"");
+
+    assertEquals(result.getName(), ""ClassIndexTestPropertyLinkedMap"");
+    assertEquals(oClass.getClassIndex(""ClassIndexTestPropertyLinkedMap"").getName(), result.getName());
+    assertEquals(database.getMetadata().getIndexManager().getClassIndex(""ClassIndexTestClass"", ""ClassIndexTestPropertyLinkedMap"")
+        .getName(), result.getName());
+
+    final OIndexDefinition indexDefinition = result.getDefinition();
 
-    assertEquals( result.getName(), ""ClassIndexTestPropertyByKeyEmbeddedMap"" );
-    assertEquals( oClass.getClassIndex( ""ClassIndexTestPropertyByKeyEmbeddedMap"" ).getName(), result.getName() );
+    assertTrue(indexDefinition instanceof OPropertyMapIndexDefinition);
+    assertEquals(indexDefinition.getFields().get(0), ""fLinkMap"");
+    assertEquals(indexDefinition.getTypes()[0], OType.STRING);
+    assertEquals(((OPropertyMapIndexDefinition) indexDefinition).getIndexBy(), OPropertyMapIndexDefinition.INDEX_BY.KEY);
+  }
+
+  @Test
+  public void testCreateOnePropertyLinkMapByKeyIndex() {
+    final OIndex result = oClass.createIndex(""ClassIndexTestPropertyLinkedMapByKey"", OClass.INDEX_TYPE.UNIQUE, ""fLinkMap by key"");
+
+    assertEquals(result.getName(), ""ClassIndexTestPropertyLinkedMapByKey"");
+    assertEquals(oClass.getClassIndex(""ClassIndexTestPropertyLinkedMapByKey"").getName(), result.getName());
     assertEquals(
-      database.getMetadata().getIndexManager().getClassIndex( ""ClassIndexTestClass"", ""ClassIndexTestPropertyByKeyEmbeddedMap"" ).getName(),
-      result.getName() );
+        database.getMetadata().getIndexManager().getClassIndex(""ClassIndexTestClass"", ""ClassIndexTestPropertyLinkedMapByKey"")
+            .getName(), result.getName());
 
     final OIndexDefinition indexDefinition = result.getDefinition();
 
-    assertTrue( indexDefinition instanceof OPropertyMapIndexDefinition );
-    assertEquals( indexDefinition.getFields().get( 0 ), ""fEmbeddedMap"" );
-    assertEquals( indexDefinition.getTypes()[0], OType.STRING );
-    assertEquals(((OPropertyMapIndexDefinition)indexDefinition).getIndexBy(), OPropertyMapIndexDefinition.INDEX_BY.KEY );
+    assertTrue(indexDefinition instanceof OPropertyMapIndexDefinition);
+    assertEquals(indexDefinition.getFields().get(0), ""fLinkMap"");
+    assertEquals(indexDefinition.getTypes()[0], OType.STRING);
+    assertEquals(((OPropertyMapIndexDefinition) indexDefinition).getIndexBy(), OPropertyMapIndexDefinition.INDEX_BY.KEY);
   }
 
   @Test
-  public void testCreateOnePropertyByValueEmbeddedMapIndex()
-  {
-    final OIndex result = oClass.createIndex( ""ClassIndexTestPropertyByValueEmbeddedMap"", OClass.INDEX_TYPE.UNIQUE, ""fEmbeddedMap by value"" );
+  public void testCreateOnePropertyLinkMapByValueIndex() {
+    final OIndex result = oClass.createIndex(""ClassIndexTestPropertyLinkedMapByValue"", OClass.INDEX_TYPE.UNIQUE,
+        ""fLinkMap by value"");
 
-    assertEquals( result.getName(), ""ClassIndexTestPropertyByValueEmbeddedMap"" );
-    assertEquals( oClass.getClassIndex( ""ClassIndexTestPropertyByValueEmbeddedMap"" ).getName(), result.getName() );
+    assertEquals(result.getName(), ""ClassIndexTestPropertyLinkedMapByValue"");
+    assertEquals(oClass.getClassIndex(""ClassIndexTestPropertyLinkedMapByValue"").getName(), result.getName());
     assertEquals(
-      database.getMetadata().getIndexManager().getClassIndex( ""ClassIndexTestClass"", ""ClassIndexTestPropertyByValueEmbeddedMap"" ).getName(),
-      result.getName() );
+        database.getMetadata().getIndexManager().getClassIndex(""ClassIndexTestClass"", ""ClassIndexTestPropertyLinkedMapByValue"")
+            .getName(), result.getName());
 
     final OIndexDefinition indexDefinition = result.getDefinition();
 
-    assertTrue( indexDefinition instanceof OPropertyMapIndexDefinition );
-    assertEquals( indexDefinition.getFields().get( 0 ), ""fEmbeddedMap"" );
-    assertEquals( indexDefinition.getTypes()[0], OType.INTEGER );
-    assertEquals(((OPropertyMapIndexDefinition)indexDefinition).getIndexBy(), OPropertyMapIndexDefinition.INDEX_BY.VALUE );
+    assertTrue(indexDefinition instanceof OPropertyMapIndexDefinition);
+    assertEquals(indexDefinition.getFields().get(0), ""fLinkMap"");
+    assertEquals(indexDefinition.getTypes()[0], OType.LINK);
+    assertEquals(((OPropertyMapIndexDefinition) indexDefinition).getIndexBy(), OPropertyMapIndexDefinition.INDEX_BY.VALUE);
   }
 
   @Test
-  public void testCreateOnePropertyWrongSpecifierEmbeddedMapIndexOne()
-  {
+  public void testCreateOnePropertyByKeyEmbeddedMapIndex() {
+    final OIndex result = oClass.createIndex(""ClassIndexTestPropertyByKeyEmbeddedMap"", OClass.INDEX_TYPE.UNIQUE,
+        ""fEmbeddedMap by key"");
+
+    assertEquals(result.getName(), ""ClassIndexTestPropertyByKeyEmbeddedMap"");
+    assertEquals(oClass.getClassIndex(""ClassIndexTestPropertyByKeyEmbeddedMap"").getName(), result.getName());
+    assertEquals(
+        database.getMetadata().getIndexManager().getClassIndex(""ClassIndexTestClass"", ""ClassIndexTestPropertyByKeyEmbeddedMap"")
+            .getName(), result.getName());
+
+    final OIndexDefinition indexDefinition = result.getDefinition();
+
+    assertTrue(indexDefinition instanceof OPropertyMapIndexDefinition);
+    assertEquals(indexDefinition.getFields().get(0), ""fEmbeddedMap"");
+    assertEquals(indexDefinition.getTypes()[0], OType.STRING);
+    assertEquals(((OPropertyMapIndexDefinition) indexDefinition).getIndexBy(), OPropertyMapIndexDefinition.INDEX_BY.KEY);
+  }
+
+  @Test
+  public void testCreateOnePropertyByValueEmbeddedMapIndex() {
+    final OIndex result = oClass.createIndex(""ClassIndexTestPropertyByValueEmbeddedMap"", OClass.INDEX_TYPE.UNIQUE,
+        ""fEmbeddedMap by value"");
+
+    assertEquals(result.getName(), ""ClassIndexTestPropertyByValueEmbeddedMap"");
+    assertEquals(oClass.getClassIndex(""ClassIndexTestPropertyByValueEmbeddedMap"").getName(), result.getName());
+    assertEquals(
+        database.getMetadata().getIndexManager().getClassIndex(""ClassIndexTestClass"", ""ClassIndexTestPropertyByValueEmbeddedMap"")
+            .getName(), result.getName());
+
+    final OIndexDefinition indexDefinition = result.getDefinition();
+
+    assertTrue(indexDefinition instanceof OPropertyMapIndexDefinition);
+    assertEquals(indexDefinition.getFields().get(0), ""fEmbeddedMap"");
+    assertEquals(indexDefinition.getTypes()[0], OType.INTEGER);
+    assertEquals(((OPropertyMapIndexDefinition) indexDefinition).getIndexBy(), OPropertyMapIndexDefinition.INDEX_BY.VALUE);
+  }
+
+  @Test
+  public void testCreateOnePropertyWrongSpecifierEmbeddedMapIndexOne() {
     boolean exceptionIsThrown = false;
     try {
-      oClass.createIndex( ""ClassIndexTestPropertyWrongSpecifierEmbeddedMap"", OClass.INDEX_TYPE.UNIQUE, ""fEmbeddedMap by ttt"" );
-    } catch( IllegalArgumentException e ) {
+      oClass.createIndex(""ClassIndexTestPropertyWrongSpecifierEmbeddedMap"", OClass.INDEX_TYPE.UNIQUE, ""fEmbeddedMap by ttt"");
+    } catch (IllegalArgumentException e) {
       exceptionIsThrown = true;
-      assertEquals(e.getMessage(), ""Illegal field name format, should be '<property> [by key|value]' but was 'fEmbeddedMap by ttt'"" );
+      assertEquals(e.getMessage(), ""Illegal field name format, should be '<property> [by key|value]' but was 'fEmbeddedMap by ttt'"");
     }
 
-    assertTrue( exceptionIsThrown );
-    assertNull( oClass.getClassIndex( ""ClassIndexTestPropertyWrongSpecifierEmbeddedMap"" ));
+    assertTrue(exceptionIsThrown);
+    assertNull(oClass.getClassIndex(""ClassIndexTestPropertyWrongSpecifierEmbeddedMap""));
   }
 
   @Test
-  public void testCreateOnePropertyWrongSpecifierEmbeddedMapIndexTwo()
-  {
+  public void testCreateOnePropertyWrongSpecifierEmbeddedMapIndexTwo() {
     boolean exceptionIsThrown = false;
     try {
-      oClass.createIndex( ""ClassIndexTestPropertyWrongSpecifierEmbeddedMap"", OClass.INDEX_TYPE.UNIQUE, ""fEmbeddedMap b value"" );
-    } catch( IllegalArgumentException e ) {
+      oClass.createIndex(""ClassIndexTestPropertyWrongSpecifierEmbeddedMap"", OClass.INDEX_TYPE.UNIQUE, ""fEmbeddedMap b value"");
+    } catch (IllegalArgumentException e) {
       exceptionIsThrown = true;
-      assertEquals(e.getMessage(), ""Illegal field name format, should be '<property> [by key|value]' but was 'fEmbeddedMap b value'"" );
+      assertEquals(e.getMessage(),
+          ""Illegal field name format, should be '<property> [by key|value]' but was 'fEmbeddedMap b value'"");
     }
 
-    assertTrue( exceptionIsThrown );
-    assertNull( oClass.getClassIndex( ""ClassIndexTestPropertyWrongSpecifierEmbeddedMap"" ));
+    assertTrue(exceptionIsThrown);
+    assertNull(oClass.getClassIndex(""ClassIndexTestPropertyWrongSpecifierEmbeddedMap""));
   }
 
   @Test
-  public void testCreateOnePropertyWrongSpecifierEmbeddedMapIndexThree()
-  {
+  public void testCreateOnePropertyWrongSpecifierEmbeddedMapIndexThree() {
     boolean exceptionIsThrown = false;
     try {
-      oClass.createIndex( ""ClassIndexTestPropertyWrongSpecifierEmbeddedMap"", OClass.INDEX_TYPE.UNIQUE, ""fEmbeddedMap by value t"" );
-    } catch( IllegalArgumentException e ) {
+      oClass.createIndex(""ClassIndexTestPropertyWrongSpecifierEmbeddedMap"", OClass.INDEX_TYPE.UNIQUE, ""fEmbeddedMap by value t"");
+    } catch (IllegalArgumentException e) {
       exceptionIsThrown = true;
-      assertEquals(e.getMessage(), ""Illegal field name format, should be '<property> [by key|value]' but was 'fEmbeddedMap by value t'"" );
+      assertEquals(e.getMessage(),
+          ""Illegal field name format, should be '<property> [by key|value]' but was 'fEmbeddedMap by value t'"");
     }
 
-    assertTrue( exceptionIsThrown );
-    assertNull( oClass.getClassIndex( ""ClassIndexTestPropertyWrongSpecifierEmbeddedMap"" ));
-  }
-
-  @Test(dependsOnMethods = {
-    ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
-    ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
-    ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
-    ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex""
-  })
-  public void testAreIndexedOneProperty()
-  {
-    final boolean result = oClass.areIndexed( Arrays.asList( ""fOne"" ) );
-
-    assertTrue( result );
-  }
-
-  @Test(dependsOnMethods = {
-    ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
-    ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
-    ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
-    ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex""
-  })
-  public void testAreIndexedDoesNotContainProperty()
-  {
-    final boolean result = oClass.areIndexed( Arrays.asList( ""fSix"" ) );
-
-    assertFalse( result );
-  }
-
-  @Test(dependsOnMethods = {
-    ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
-    ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
-    ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
-    ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex""
-  })
-  public void testAreIndexedTwoProperties()
-  {
-    final boolean result = oClass.areIndexed( Arrays.asList( ""fTwo"", ""fOne"" ) );
-
-    assertTrue( result );
-  }
-
-  @Test(dependsOnMethods = {
-    ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
-    ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
-    ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
-    ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex""
-  })
-  public void testAreIndexedThreeProperties()
-  {
-    final boolean result = oClass.areIndexed( Arrays.asList( ""fTwo"", ""fOne"", ""fThree"" ) );
-
-    assertTrue( result );
-  }
-
-
-  @Test(dependsOnMethods = {
-    ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
-    ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
-    ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
-    ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex""
-  })
-  public void testAreIndexedPropertiesNotFirst()
-  {
-    final boolean result = oClass.areIndexed( Arrays.asList( ""fTwo"", ""fTree"" ) );
-
-    assertFalse( result );
-  }
-
-  @Test(dependsOnMethods = {
-    ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
-    ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
-    ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
-    ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex""
-  })
-  public void testAreIndexedPropertiesMoreThanNeeded()
-  {
-    final boolean result = oClass.areIndexed( Arrays.asList( ""fTwo"", ""fOne"", ""fThee"", ""fFour"" ) );
-
-    assertFalse( result );
-  }
-
-  @Test(dependsOnMethods = {
-    ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
-    ""testCreateOnePropertyIndexTest"", ""createParentPropertyIndex"", ""testCreateOnePropertyEmbeddedMapIndex"",
-    ""testCreateOnePropertyByKeyEmbeddedMapIndex"", ""testCreateOnePropertyByValueEmbeddedMapIndex"",
-    ""testCreateOnePropertyLinkedMapIndex"", ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex""
-  })
-  public void testAreIndexedParentProperty()
-  {
-    final boolean result = oClass.areIndexed( Arrays.asList( ""fNine"" ) );
-
-    assertTrue( result );
-  }
-
-  @Test(dependsOnMethods = {
-    ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
-    ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex""
-    , ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
-    ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex""
-  })
-  public void testAreIndexedParentChildProperty()
-  {
-    final boolean result = oClass.areIndexed( Arrays.asList( ""fOne, fNine"" ) );
-
-    assertFalse( result );
-  }
-
-  @Test(dependsOnMethods = {
-    ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
-    ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
-    ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
-    ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex""
-  })
-  public void testAreIndexedOnePropertyArrayParams()
-  {
-    final boolean result = oClass.areIndexed( ""fOne"" );
-
-    assertTrue( result );
-  }
-
-  @Test(dependsOnMethods = {
-    ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
-    ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
-    ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
-    ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex""
-  })
-  public void testAreIndexedDoesNotContainPropertyArrayParams()
-  {
-    final boolean result = oClass.areIndexed( ""fSix"" );
-
-    assertFalse( result );
-  }
-
-  @Test(dependsOnMethods = {
-    ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
-    ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
-    ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
-    ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex""
-  })
-  public void testAreIndexedTwoPropertiesArrayParams()
-  {
-    final boolean result = oClass.areIndexed( ""fTwo"", ""fOne"" );
-
-    assertTrue( result );
-  }
-
-  @Test(dependsOnMethods = {
-    ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
-    ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
-    ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
-    ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex""
-  })
-  public void testAreIndexedThreePropertiesArrayParams()
-  {
-    final boolean result = oClass.areIndexed( ""fTwo"", ""fOne"", ""fThree"" );
-
-    assertTrue( result );
-  }
-
-
-  @Test(dependsOnMethods = {
-    ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
-    ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
-    ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
-    ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex""
-  })
-  public void testAreIndexedPropertiesNotFirstArrayParams()
-  {
-    final boolean result = oClass.areIndexed( ""fTwo"", ""fTree"" );
-
-    assertFalse( result );
-  }
-
-  @Test(dependsOnMethods = {
-    ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
-    ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
-    ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
-    ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex""
-  })
-  public void testAreIndexedPropertiesMoreThanNeededArrayParams()
-  {
-    final boolean result = oClass.areIndexed( ""fTwo"", ""fOne"", ""fThee"", ""fFour"" );
-
-    assertFalse( result );
-  }
-
-  @Test(dependsOnMethods = {
-    ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
-    ""testCreateOnePropertyIndexTest"", ""createParentPropertyIndex"", ""testCreateOnePropertyEmbeddedMapIndex"",
-    ""testCreateOnePropertyByKeyEmbeddedMapIndex"", ""testCreateOnePropertyByValueEmbeddedMapIndex"",
-    ""testCreateOnePropertyLinkedMapIndex"", ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex""
-  })
-  public void testAreIndexedParentPropertyArrayParams()
-  {
-    final boolean result = oClass.areIndexed( ""fNine"" );
-
-    assertTrue( result );
-  }
-
-  @Test(dependsOnMethods = {
-    ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
-    ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
-    ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
-    ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex""
-  })
-  public void testAreIndexedParentChildPropertyArrayParams()
-  {
-    final boolean result = oClass.areIndexed( ""fOne, fNine"" );
-
-    assertFalse( result );
-  }
-
-  @Test(dependsOnMethods = {
-    ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
-    ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
-    ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
-    ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex""
-  })
-  public void testGetClassInvolvedIndexesOnePropertyArrayParams()
-  {
-    final Set<OIndex<?>> result = oClass.getClassInvolvedIndexes( ""fOne"" );
-
-    assertEquals( result.size(), 3 );
-
-    assertTrue( containsIndex( result, ""ClassIndexTestPropertyOne"" ) );
-    assertTrue( containsIndex( result, ""ClassIndexTestCompositeOne"" ) );
-    assertTrue( containsIndex( result, ""ClassIndexTestCompositeTwo"" ) );
-  }
-
-  @Test(dependsOnMethods = {
-    ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
-    ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
-    ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
-    ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex""
-  })
-  public void testGetClassInvolvedIndexesTwoPropertiesArrayParams()
-  {
-    final Set<OIndex<?>> result = oClass.getClassInvolvedIndexes( ""fTwo"", ""fOne"" );
-    assertEquals( result.size(), 2 );
-
-    assertTrue( containsIndex( result, ""ClassIndexTestCompositeOne"" ) );
-    assertTrue( containsIndex( result, ""ClassIndexTestCompositeTwo"" ) );
-  }
-
-  @Test(dependsOnMethods = {
-    ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
-    ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
-    ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
-    ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex""
-  })
-  public void testGetClassInvolvedIndexesThreePropertiesArrayParams()
-  {
-    final Set<OIndex<?>> result = oClass.getClassInvolvedIndexes( ""fTwo"", ""fOne"", ""fThree"" );
-
-    assertEquals( result.size(), 1 );
-    assertEquals( result.iterator().next().getName(), ""ClassIndexTestCompositeTwo"" );
-  }
-
-
-  @Test(dependsOnMethods = {
-    ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
-    ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
-    ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
-    ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex""
-  })
-  public void testGetClassInvolvedIndexesNotInvolvedPropertiesArrayParams()
-  {
-    final Set<OIndex<?>> result = oClass.getClassInvolvedIndexes( ""fTwo"", ""fFour"" );
-
-    assertEquals( result.size(), 0 );
-  }
-
-  @Test(dependsOnMethods = {
-    ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
-    ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
-    ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
-    ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex""
-  })
-  public void testGetClassInvolvedIndexesPropertiesMorThanNeededArrayParams()
-  {
-    final Set<OIndex<?>> result = oClass.getClassInvolvedIndexes( ""fTwo"", ""fOne"", ""fThee"", ""fFour"" );
-
-    assertEquals( result.size(), 0 );
-  }
-
-  @Test(dependsOnMethods = {
-    ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
-    ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
-    ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
-    ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex""
-  })
-  public void testGetInvolvedIndexesPropertiesMorThanNeeded()
-  {
-    final Set<OIndex<?>> result = oClass.getClassInvolvedIndexes( Arrays.asList( ""fTwo"", ""fOne"", ""fThee"", ""fFour"" ) );
-
-    assertEquals( result.size(), 0 );
-  }
-
-  @Test(dependsOnMethods = {
-    ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
-    ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
-    ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
-    ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex""
-  })
-  public void testGetClassInvolvedIndexesOneProperty()
-  {
-    final Set<OIndex<?>> result = oClass.getClassInvolvedIndexes( Arrays.asList( ""fOne"" ) );
-
-    assertEquals( result.size(), 3 );
-
-    assertTrue( containsIndex( result, ""ClassIndexTestPropertyOne"" ) );
-    assertTrue( containsIndex( result, ""ClassIndexTestCompositeOne"" ) );
-    assertTrue( containsIndex( result, ""ClassIndexTestCompositeTwo"" ) );
-  }
-
-  @Test(dependsOnMethods = {
-    ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
-    ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
-    ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
-    ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex""
-  })
-  public void testGetClassInvolvedIndexesTwoProperties()
-  {
-    final Set<OIndex<?>> result = oClass.getClassInvolvedIndexes( Arrays.asList( ""fTwo"", ""fOne"" ) );
-    assertEquals( result.size(), 2 );
-
-    assertTrue( containsIndex( result, ""ClassIndexTestCompositeOne"" ) );
-    assertTrue( containsIndex( result, ""ClassIndexTestCompositeTwo"" ) );
-  }
-
-  @Test(dependsOnMethods = {
-    ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
-    ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
-    ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
-    ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex""
-  })
-  public void testGetClassInvolvedIndexesThreeProperties()
-  {
-    final Set<OIndex<?>> result = oClass.getClassInvolvedIndexes( Arrays.asList( ""fTwo"", ""fOne"", ""fThree"" ) );
-
-    assertEquals( result.size(), 1 );
-    assertEquals( result.iterator().next().getName(), ""ClassIndexTestCompositeTwo"" );
-  }
-
-  @Test(dependsOnMethods = {
-    ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
-    ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
-    ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
-    ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex""
-  })
-  public void testGetClassInvolvedIndexesNotInvolvedProperties()
-  {
-    final Set<OIndex<?>> result = oClass.getClassInvolvedIndexes( Arrays.asList( ""fTwo"", ""fFour"" ) );
-
-    assertEquals( result.size(), 0 );
-  }
-
-  @Test(dependsOnMethods = {
-    ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
-    ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
-    ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
-    ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex""
-  })
-  public void testGetClassInvolvedIndexesPropertiesMorThanNeeded()
-  {
-    final Set<OIndex<?>> result = oClass.getClassInvolvedIndexes( Arrays.asList( ""fTwo"", ""fOne"", ""fThee"", ""fFour"" ) );
-
-    assertEquals( result.size(), 0 );
-  }
-
-  @Test(dependsOnMethods = {
-    ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
-    ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
-    ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
-    ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex""
-  })
-  public void testGetInvolvedIndexesOnePropertyArrayParams()
-  {
-    final Set<OIndex<?>> result = oClass.getInvolvedIndexes( ""fOne"" );
-
-    assertEquals( result.size(), 3 );
-
-    assertTrue( containsIndex( result, ""ClassIndexTestPropertyOne"" ) );
-    assertTrue( containsIndex( result, ""ClassIndexTestCompositeOne"" ) );
-    assertTrue( containsIndex( result, ""ClassIndexTestCompositeTwo"" ) );
-  }
-
-  @Test(dependsOnMethods = {
-    ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
-    ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
-    ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
-    ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex""
-  })
-  public void testGetInvolvedIndexesTwoPropertiesArrayParams()
-  {
-    final Set<OIndex<?>> result = oClass.getInvolvedIndexes( ""fTwo"", ""fOne"" );
-    assertEquals( result.size(), 2 );
-
-    assertTrue( containsIndex( result, ""ClassIndexTestCompositeOne"" ) );
-    assertTrue( containsIndex( result, ""ClassIndexTestCompositeTwo"" ) );
-  }
-
-  @Test(dependsOnMethods = {
-    ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
-    ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
-    ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
-    ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex""
-  })
-  public void testGetInvolvedIndexesThreePropertiesArrayParams()
-  {
-    final Set<OIndex<?>> result = oClass.getInvolvedIndexes( ""fTwo"", ""fOne"", ""fThree"" );
-
-    assertEquals( result.size(), 1 );
-    assertEquals( result.iterator().next().getName(), ""ClassIndexTestCompositeTwo"" );
-  }
-
-
-  @Test(dependsOnMethods = {
-    ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
-    ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
-    ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
-    ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex""
-  })
-  public void testGetInvolvedIndexesNotInvolvedPropertiesArrayParams()
-  {
-    final Set<OIndex<?>> result = oClass.getInvolvedIndexes( ""fTwo"", ""fFour"" );
-
-    assertEquals( result.size(), 0 );
-  }
-
-  @Test(dependsOnMethods = {
-    ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
-    ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
-    ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
-    ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex""
-  })
-  public void testGetParentInvolvedIndexesArrayParams()
-  {
-    final Set<OIndex<?>> result = oClass.getInvolvedIndexes( ""fNine"" );
-
-    assertEquals( result.size(), 1 );
-    assertEquals( result.iterator().next().getName(), ""ClassIndexTestParentPropertyNine"" );
-  }
-
-  @Test(dependsOnMethods = {
-    ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
-    ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
-    ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
-    ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex""
-  })
-  public void testGetParentChildInvolvedIndexesArrayParams()
-  {
-    final Set<OIndex<?>> result = oClass.getInvolvedIndexes( ""fOne"", ""fNine"" );
-
-    assertEquals( result.size(), 0 );
-  }
-
-  @Test(dependsOnMethods = {
-    ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
-    ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
-    ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
-    ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex""
-  })
-  public void testGetInvolvedIndexesOneProperty()
-  {
-    final Set<OIndex<?>> result = oClass.getInvolvedIndexes( Arrays.asList( ""fOne"" ) );
-
-    assertEquals( result.size(), 3 );
-
-    assertTrue( containsIndex( result, ""ClassIndexTestPropertyOne"" ) );
-    assertTrue( containsIndex( result, ""ClassIndexTestCompositeOne"" ) );
-    assertTrue( containsIndex( result, ""ClassIndexTestCompositeTwo"" ) );
-  }
-
-  @Test(dependsOnMethods = {
-    ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
-    ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
-    ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
-    ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex""
-  })
-  public void testGetInvolvedIndexesTwoProperties()
-  {
-    final Set<OIndex<?>> result = oClass.getInvolvedIndexes( Arrays.asList( ""fTwo"", ""fOne"" ) );
-    assertEquals( result.size(), 2 );
-
-    assertTrue( containsIndex( result, ""ClassIndexTestCompositeOne"" ) );
-    assertTrue( containsIndex( result, ""ClassIndexTestCompositeTwo"" ) );
-  }
-
-  @Test(dependsOnMethods = {
-    ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
-    ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
-    ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
-    ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex""
-  })
-  public void testGetInvolvedIndexesThreeProperties()
-  {
-    final Set<OIndex<?>> result = oClass.getInvolvedIndexes( Arrays.asList( ""fTwo"", ""fOne"", ""fThree"" ) );
-
-    assertEquals( result.size(), 1 );
-    assertEquals( result.iterator().next().getName(), ""ClassIndexTestCompositeTwo"" );
-  }
-
-
-  @Test(dependsOnMethods = {
-    ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
-    ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
-    ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
-    ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex""
-  })
-  public void testGetInvolvedIndexesNotInvolvedProperties()
-  {
-    final Set<OIndex<?>> result = oClass.getInvolvedIndexes( Arrays.asList( ""fTwo"", ""fFour"" ) );
-
-    assertEquals( result.size(), 0 );
-  }
-
-  @Test(dependsOnMethods = {
-    ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
-    ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
-    ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
-    ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex""
-  })
-  public void testGetParentInvolvedIndexes()
-  {
-    final Set<OIndex<?>> result = oClass.getInvolvedIndexes( Arrays.asList( ""fNine"" ) );
-
-    assertEquals( result.size(), 1 );
-    assertEquals( result.iterator().next().getName(), ""ClassIndexTestParentPropertyNine"" );
-  }
-
-  @Test(dependsOnMethods = {
-    ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
-    ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
-    ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
-    ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex""
-  })
-  public void testGetParentChildInvolvedIndexes()
-  {
-    final Set<OIndex<?>> result = oClass.getInvolvedIndexes( Arrays.asList( ""fOne"", ""fNine"" ) );
-
-    assertEquals( result.size(), 0 );
-  }
-
-  @Test(dependsOnMethods = {
-    ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
-    ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
-    ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
-    ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex""
-  })
-  public void testGetClassIndexes()
-  {
-    final Set<OIndex<?>> indexes = oClass.getClassIndexes();
-    final Set<OIndexDefinition> expectedIndexDefinitions = new HashSet<OIndexDefinition>();
+    assertTrue(exceptionIsThrown);
+    assertNull(oClass.getClassIndex(""ClassIndexTestPropertyWrongSpecifierEmbeddedMap""));
+  }
+
+  @Test(dependsOnMethods = { ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
+      ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
+      ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
+      ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex"", ""testCreateCompositeEmbeddedMapIndex"",
+      ""testCreateCompositeEmbeddedMapByKeyIndex"", ""testCreateCompositeEmbeddedMapByValueIndex"",
+      ""testCreateCompositeLinkMapByValueIndex"", ""testCreateCompositeEmbeddedSetIndex"", ""testCreateCompositeEmbeddedListIndex"" })
+  public void testAreIndexedOneProperty() {
+    final boolean result = oClass.areIndexed(Arrays.asList(""fOne""));
 
-    final OCompositeIndexDefinition compositeIndexOne = new OCompositeIndexDefinition( ""ClassIndexTestClass"" );
+    assertTrue(result);
+  }
+
+  @Test(dependsOnMethods = { ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
+      ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
+      ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
+      ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex"", ""testCreateCompositeEmbeddedMapIndex"",
+      ""testCreateCompositeEmbeddedMapIndex"", ""testCreateCompositeEmbeddedMapByKeyIndex"",
+      ""testCreateCompositeEmbeddedMapByValueIndex"", ""testCreateCompositeLinkMapByValueIndex"",
+      ""testCreateCompositeEmbeddedSetIndex"", ""testCreateCompositeEmbeddedListIndex"" })
+  public void testAreIndexedEightProperty() {
+    final boolean result = oClass.areIndexed(Arrays.asList(""fEight""));
+    assertTrue(result);
+  }
+
+  @Test(dependsOnMethods = { ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
+      ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
+      ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
+      ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex"", ""testCreateCompositeEmbeddedMapIndex"",
+      ""testCreateCompositeEmbeddedMapByKeyIndex"", ""testCreateCompositeEmbeddedMapByKeyIndex"",
+      ""testCreateCompositeEmbeddedMapByValueIndex"", ""testCreateCompositeLinkMapByValueIndex"",
+      ""testCreateCompositeEmbeddedSetIndex"", ""testCreateCompositeEmbeddedListIndex"" })
+  public void testAreIndexedEightPropertyEmbeddedMap() {
+    final boolean result = oClass.areIndexed(Arrays.asList(""fEmbeddedMap"", ""fEight""));
+    assertTrue(result);
+  }
+
+  @Test(dependsOnMethods = { ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
+      ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
+      ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
+      ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex"", ""testCreateCompositeEmbeddedMapIndex"",
+      ""testCreateCompositeEmbeddedMapByKeyIndex"", ""testCreateCompositeEmbeddedMapByValueIndex"",
+      ""testCreateCompositeLinkMapByValueIndex"", ""testCreateCompositeEmbeddedSetIndex"", ""testCreateCompositeEmbeddedListIndex"" })
+  public void testAreIndexedDoesNotContainProperty() {
+    final boolean result = oClass.areIndexed(Arrays.asList(""fSix""));
 
-    compositeIndexOne.addIndex( new OPropertyIndexDefinition( ""ClassIndexTestClass"", ""fOne"", OType.INTEGER ) );
-    compositeIndexOne.addIndex( new OPropertyIndexDefinition( ""ClassIndexTestClass"", ""fTwo"", OType.STRING ) );
-    expectedIndexDefinitions.add( compositeIndexOne );
+    assertFalse(result);
+  }
+
+  @Test(dependsOnMethods = { ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
+      ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
+      ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
+      ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex"", ""testCreateCompositeEmbeddedMapIndex"",
+      ""testCreateCompositeEmbeddedMapByKeyIndex"", ""testCreateCompositeEmbeddedMapByValueIndex"",
+      ""testCreateCompositeLinkMapByValueIndex"", ""testCreateCompositeEmbeddedSetIndex"", ""testCreateCompositeEmbeddedListIndex"" })
+  public void testAreIndexedTwoProperties() {
+    final boolean result = oClass.areIndexed(Arrays.asList(""fTwo"", ""fOne""));
 
-    final OCompositeIndexDefinition compositeIndexTwo = new OCompositeIndexDefinition( ""ClassIndexTestClass"" );
+    assertTrue(result);
+  }
+
+  @Test(dependsOnMethods = { ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
+      ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
+      ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
+      ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex"", ""testCreateCompositeEmbeddedMapIndex"",
+      ""testCreateCompositeEmbeddedMapByKeyIndex"", ""testCreateCompositeEmbeddedMapByValueIndex"",
+      ""testCreateCompositeLinkMapByValueIndex"", ""testCreateCompositeEmbeddedSetIndex"", ""testCreateCompositeEmbeddedListIndex"" })
+  public void testAreIndexedThreeProperties() {
+    final boolean result = oClass.areIndexed(Arrays.asList(""fTwo"", ""fOne"", ""fThree""));
 
-    compositeIndexTwo.addIndex( new OPropertyIndexDefinition( ""ClassIndexTestClass"", ""fOne"", OType.INTEGER ) );
-    compositeIndexTwo.addIndex( new OPropertyIndexDefinition( ""ClassIndexTestClass"", ""fTwo"", OType.STRING ) );
-    compositeIndexTwo.addIndex( new OPropertyIndexDefinition( ""ClassIndexTestClass"", ""fThree"", OType.BOOLEAN ) );
-    expectedIndexDefinitions.add( compositeIndexTwo );
+    assertTrue(result);
+  }
+
+  @Test(dependsOnMethods = { ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
+      ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
+      ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
+      ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex"", ""testCreateCompositeEmbeddedMapIndex"",
+      ""testCreateCompositeEmbeddedMapByKeyIndex"", ""testCreateCompositeEmbeddedMapByValueIndex"",
+      ""testCreateCompositeLinkMapByValueIndex"", ""testCreateCompositeEmbeddedSetIndex"", ""testCreateCompositeEmbeddedListIndex"" })
+  public void testAreIndexedPropertiesNotFirst() {
+    final boolean result = oClass.areIndexed(Arrays.asList(""fTwo"", ""fTree""));
 
-    final OPropertyIndexDefinition propertyIndex = new OPropertyIndexDefinition( ""ClassIndexTestClass"", ""fOne"", OType.INTEGER );
-    expectedIndexDefinitions.add( propertyIndex );
+    assertFalse(result);
+  }
+
+  @Test(dependsOnMethods = { ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
+      ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
+      ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
+      ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex"", ""testCreateCompositeEmbeddedMapIndex"",
+      ""testCreateCompositeEmbeddedMapByKeyIndex"", ""testCreateCompositeEmbeddedMapByValueIndex"",
+      ""testCreateCompositeLinkMapByValueIndex"", ""testCreateCompositeEmbeddedSetIndex"", ""testCreateCompositeEmbeddedListIndex"" })
+  public void testAreIndexedPropertiesMoreThanNeeded() {
+    final boolean result = oClass.areIndexed(Arrays.asList(""fTwo"", ""fOne"", ""fThee"", ""fFour""));
 
-    final OPropertyMapIndexDefinition propertyMapIndexDefinition = new OPropertyMapIndexDefinition( ""ClassIndexTestClass"", ""fEmbeddedMap"", OType.STRING,
-      OPropertyMapIndexDefinition.INDEX_BY.KEY );
-    expectedIndexDefinitions.add( propertyMapIndexDefinition );
-
-    final OPropertyMapIndexDefinition propertyMapByValueIndexDefinition = new OPropertyMapIndexDefinition( ""ClassIndexTestClass"", ""fEmbeddedMap"", OType.INTEGER,
-      OPropertyMapIndexDefinition.INDEX_BY.VALUE );
-    expectedIndexDefinitions.add( propertyMapByValueIndexDefinition );
-
-    final OPropertyMapIndexDefinition propertyLinkMapByKeyIndexDefinition = new OPropertyMapIndexDefinition( ""ClassIndexTestClass"", ""fLinkMap"", OType.STRING,
-      OPropertyMapIndexDefinition.INDEX_BY.KEY );
-    expectedIndexDefinitions.add( propertyLinkMapByKeyIndexDefinition );
-
-    final OPropertyMapIndexDefinition propertyLinkMapByValueIndexDefinition = new OPropertyMapIndexDefinition( ""ClassIndexTestClass"", ""fLinkMap"", OType.LINK,
-      OPropertyMapIndexDefinition.INDEX_BY.VALUE );
-    expectedIndexDefinitions.add( propertyLinkMapByValueIndexDefinition );
-
-    assertEquals( indexes.size(), 7);
-
-    for( final OIndex index : indexes ) {
-      assertTrue( expectedIndexDefinitions.contains( index.getDefinition() ) );
-    }
+    assertFalse(result);
+  }
+
+  @Test(dependsOnMethods = { ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
+      ""testCreateOnePropertyIndexTest"", ""createParentPropertyIndex"", ""testCreateOnePropertyEmbeddedMapIndex"",
+      ""testCreateOnePropertyByKeyEmbeddedMapIndex"", ""testCreateOnePropertyByValueEmbeddedMapIndex"",
+      ""testCreateOnePropertyLinkedMapIndex"", ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex"",
+      ""testCreateCompositeEmbeddedMapIndex"", ""testCreateCompositeEmbeddedMapByKeyIndex"",
+      ""testCreateCompositeEmbeddedMapByValueIndex"", ""testCreateCompositeLinkMapByValueIndex"",
+      ""testCreateCompositeEmbeddedSetIndex"", ""testCreateCompositeEmbeddedListIndex"" })
+  public void testAreIndexedParentProperty() {
+    final boolean result = oClass.areIndexed(Arrays.asList(""fNine""));
+
+    assertTrue(result);
+  }
+
+  @Test(dependsOnMethods = { ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
+      ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
+      ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
+      ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex"", ""testCreateCompositeEmbeddedMapIndex"",
+      ""testCreateCompositeEmbeddedMapByKeyIndex"", ""testCreateCompositeEmbeddedMapByValueIndex"",
+      ""testCreateCompositeLinkMapByValueIndex"", ""testCreateCompositeEmbeddedSetIndex"", ""testCreateCompositeEmbeddedListIndex"" })
+  public void testAreIndexedParentChildProperty() {
+    final boolean result = oClass.areIndexed(Arrays.asList(""fOne, fNine""));
+
+    assertFalse(result);
+  }
+
+  @Test(dependsOnMethods = { ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
+      ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
+      ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
+      ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex"", ""testCreateCompositeEmbeddedMapIndex"",
+      ""testCreateCompositeEmbeddedMapByKeyIndex"", ""testCreateCompositeEmbeddedMapByValueIndex"",
+      ""testCreateCompositeLinkMapByValueIndex"", ""testCreateCompositeEmbeddedSetIndex"", ""testCreateCompositeEmbeddedListIndex"" })
+  public void testAreIndexedOnePropertyArrayParams() {
+    final boolean result = oClass.areIndexed(""fOne"");
+
+    assertTrue(result);
+  }
 
+  @Test(dependsOnMethods = { ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
+      ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
+      ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
+      ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex"", ""testCreateCompositeEmbeddedMapIndex"",
+      ""testCreateCompositeEmbeddedMapByKeyIndex"", ""testCreateCompositeEmbeddedMapByValueIndex"",
+      ""testCreateCompositeLinkMapByValueIndex"", ""testCreateCompositeEmbeddedSetIndex"", ""testCreateCompositeEmbeddedListIndex"" })
+  public void testAreIndexedDoesNotContainPropertyArrayParams() {
+    final boolean result = oClass.areIndexed(""fSix"");
+
+    assertFalse(result);
   }
 
-  @Test(dependsOnMethods = {
-    ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
-    ""testCreateOnePropertyIndexTest"", ""createParentPropertyIndex"", ""testCreateOnePropertyEmbeddedMapIndex"",
-    ""testCreateOnePropertyByKeyEmbeddedMapIndex"", ""testCreateOnePropertyByValueEmbeddedMapIndex"",
-    ""testCreateOnePropertyLinkedMapIndex"", ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex""
-  })
-  public void testGetIndexes()
-  {
-    final Set<OIndex<?>> indexes = oClass.getIndexes();
-    final Set<OIndexDefinition> expectedIndexDefinitions = new HashSet<OIndexDefinition>();
-
-    final OCompositeIndexDefinition compositeIndexOne = new OCompositeIndexDefinition( ""ClassIndexTestClass"" );
-
-    compositeIndexOne.addIndex( new OPropertyIndexDefinition( ""ClassIndexTestClass"", ""fOne"", OType.INTEGER ) );
-    compositeIndexOne.addIndex( new OPropertyIndexDefinition( ""ClassIndexTestClass"", ""fTwo"", OType.STRING ) );
-    expectedIndexDefinitions.add( compositeIndexOne );
+  @Test(dependsOnMethods = { ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
+      ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
+      ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
+      ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex"", ""testCreateCompositeEmbeddedMapIndex"",
+      ""testCreateCompositeEmbeddedMapByKeyIndex"", ""testCreateCompositeEmbeddedMapByValueIndex"",
+      ""testCreateCompositeLinkMapByValueIndex"", ""testCreateCompositeEmbeddedSetIndex"", ""testCreateCompositeEmbeddedListIndex"" })
+  public void testAreIndexedTwoPropertiesArrayParams() {
+    final boolean result = oClass.areIndexed(""fTwo"", ""fOne"");
+
+    assertTrue(result);
+  }
 
-    final OCompositeIndexDefinition compositeIndexTwo = new OCompositeIndexDefinition( ""ClassIndexTestClass"" );
+  @Test(dependsOnMethods = { ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
+      ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
+      ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
+      ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex"", ""testCreateCompositeEmbeddedMapIndex"",
+      ""testCreateCompositeEmbeddedMapByKeyIndex"", ""testCreateCompositeEmbeddedMapByValueIndex"",
+      ""testCreateCompositeLinkMapByValueIndex"", ""testCreateCompositeEmbeddedSetIndex"", ""testCreateCompositeEmbeddedListIndex"" })
+  public void testAreIndexedThreePropertiesArrayParams() {
+    final boolean result = oClass.areIndexed(""fTwo"", ""fOne"", ""fThree"");
+
+    assertTrue(result);
+  }
+
+  @Test(dependsOnMethods = { ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
+      ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
+      ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
+      ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex"", ""testCreateCompositeEmbeddedMapIndex"",
+      ""testCreateCompositeEmbeddedMapByKeyIndex"", ""testCreateCompositeEmbeddedMapByValueIndex"",
+      ""testCreateCompositeLinkMapByValueIndex"", ""testCreateCompositeEmbeddedSetIndex"", ""testCreateCompositeEmbeddedListIndex"" })
+  public void testAreIndexedPropertiesNotFirstArrayParams() {
+    final boolean result = oClass.areIndexed(""fTwo"", ""fTree"");
+
+    assertFalse(result);
+  }
+
+  @Test(dependsOnMethods = { ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
+      ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
+      ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
+      ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex"", ""testCreateCompositeEmbeddedMapIndex"",
+      ""testCreateCompositeEmbeddedMapByKeyIndex"", ""testCreateCompositeEmbeddedMapByValueIndex"",
+      ""testCreateCompositeLinkMapByValueIndex"", ""testCreateCompositeEmbeddedSetIndex"", ""testCreateCompositeEmbeddedListIndex"" })
+  public void testAreIndexedPropertiesMoreThanNeededArrayParams() {
+    final boolean result = oClass.areIndexed(""fTwo"", ""fOne"", ""fThee"", ""fFour"");
+
+    assertFalse(result);
+  }
+
+  @Test(dependsOnMethods = { ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
+      ""testCreateOnePropertyIndexTest"", ""createParentPropertyIndex"", ""testCreateOnePropertyEmbeddedMapIndex"",
+      ""testCreateOnePropertyByKeyEmbeddedMapIndex"", ""testCreateOnePropertyByValueEmbeddedMapIndex"",
+      ""testCreateOnePropertyLinkedMapIndex"", ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex"",
+      ""testCreateCompositeEmbeddedMapIndex"", ""testCreateCompositeEmbeddedMapByKeyIndex"",
+      ""testCreateCompositeEmbeddedMapByValueIndex"", ""testCreateCompositeLinkMapByValueIndex"",
+      ""testCreateCompositeEmbeddedSetIndex"", ""testCreateCompositeEmbeddedListIndex"" })
+  public void testAreIndexedParentPropertyArrayParams() {
+    final boolean result = oClass.areIndexed(""fNine"");
+
+    assertTrue(result);
+  }
 
-    compositeIndexTwo.addIndex( new OPropertyIndexDefinition( ""ClassIndexTestClass"", ""fOne"", OType.INTEGER ) );
-    compositeIndexTwo.addIndex( new OPropertyIndexDefinition( ""ClassIndexTestClass"", ""fTwo"", OType.STRING ) );
-    compositeIndexTwo.addIndex( new OPropertyIndexDefinition( ""ClassIndexTestClass"", ""fThree"", OType.BOOLEAN ) );
-    expectedIndexDefinitions.add( compositeIndexTwo );
+  @Test(dependsOnMethods = { ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
+      ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
+      ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
+      ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex"", ""testCreateCompositeEmbeddedMapIndex"",
+      ""testCreateCompositeEmbeddedMapByKeyIndex"", ""testCreateCompositeEmbeddedMapByValueIndex"",
+      ""testCreateCompositeLinkMapByValueIndex"", ""testCreateCompositeEmbeddedSetIndex"", ""testCreateCompositeEmbeddedListIndex"" })
+  public void testAreIndexedParentChildPropertyArrayParams() {
+    final boolean result = oClass.areIndexed(""fOne, fNine"");
 
-    final OPropertyIndexDefinition propertyIndex = new OPropertyIndexDefinition( ""ClassIndexTestClass"", ""fOne"", OType.INTEGER );
-    expectedIndexDefinitions.add( propertyIndex );
+    assertFalse(result);
+  }
 
-    final OPropertyIndexDefinition parentPropertyIndex = new OPropertyIndexDefinition( ""ClassIndexTestSuperClass"", ""fNine"", OType.INTEGER );
-    expectedIndexDefinitions.add( parentPropertyIndex );
+  @Test(dependsOnMethods = { ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
+      ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
+      ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
+      ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex"", ""testCreateCompositeEmbeddedMapIndex"",
+      ""testCreateCompositeEmbeddedMapByKeyIndex"", ""testCreateCompositeEmbeddedMapByValueIndex"",
+      ""testCreateCompositeLinkMapByValueIndex"", ""testCreateCompositeEmbeddedSetIndex"", ""testCreateCompositeEmbeddedListIndex"" })
+  public void testGetClassInvolvedIndexesOnePropertyArrayParams() {
+    final Set<OIndex<?>> result = oClass.getClassInvolvedIndexes(""fOne"");
 
-    final OPropertyMapIndexDefinition propertyMapIndexDefinition = new OPropertyMapIndexDefinition( ""ClassIndexTestClass"", ""fEmbeddedMap"", OType.STRING,
-      OPropertyMapIndexDefinition.INDEX_BY.KEY );
-    expectedIndexDefinitions.add( propertyMapIndexDefinition );
+    assertEquals(result.size(), 3);
 
-    final OPropertyMapIndexDefinition propertyMapByValueIndexDefinition = new OPropertyMapIndexDefinition( ""ClassIndexTestClass"", ""fEmbeddedMap"", OType.INTEGER,
-      OPropertyMapIndexDefinition.INDEX_BY.VALUE );
-    expectedIndexDefinitions.add( propertyMapByValueIndexDefinition );
+    assertTrue(containsIndex(result, ""ClassIndexTestPropertyOne""));
+    assertTrue(containsIndex(result, ""ClassIndexTestCompositeOne""));
+    assertTrue(containsIndex(result, ""ClassIndexTestCompositeTwo""));
+  }
+
+  @Test(dependsOnMethods = { ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
+      ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
+      ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
+      ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex"", ""testCreateCompositeEmbeddedMapIndex"",
+      ""testCreateCompositeEmbeddedMapByKeyIndex"", ""testCreateCompositeEmbeddedMapByValueIndex"",
+      ""testCreateCompositeLinkMapByValueIndex"", ""testCreateCompositeEmbeddedSetIndex"", ""testCreateCompositeEmbeddedListIndex"" })
+  public void testGetClassInvolvedIndexesTwoPropertiesArrayParams() {
+    final Set<OIndex<?>> result = oClass.getClassInvolvedIndexes(""fTwo"", ""fOne"");
+    assertEquals(result.size(), 2);
+
+    assertTrue(containsIndex(result, ""ClassIndexTestCompositeOne""));
+    assertTrue(containsIndex(result, ""ClassIndexTestCompositeTwo""));
+  }
+
+  @Test(dependsOnMethods = { ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
+      ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
+      ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
+      ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex"", ""testCreateCompositeEmbeddedMapIndex"",
+      ""testCreateCompositeEmbeddedMapByKeyIndex"", ""testCreateCompositeEmbeddedMapByValueIndex"",
+      ""testCreateCompositeLinkMapByValueIndex"", ""testCreateCompositeEmbeddedSetIndex"", ""testCreateCompositeEmbeddedListIndex"" })
+  public void testGetClassInvolvedIndexesThreePropertiesArrayParams() {
+    final Set<OIndex<?>> result = oClass.getClassInvolvedIndexes(""fTwo"", ""fOne"", ""fThree"");
+
+    assertEquals(result.size(), 1);
+    assertEquals(result.iterator().next().getName(), ""ClassIndexTestCompositeTwo"");
+  }
+
+  @Test(dependsOnMethods = { ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
+      ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
+      ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
+      ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex"", ""testCreateCompositeEmbeddedMapIndex"",
+      ""testCreateCompositeEmbeddedMapByKeyIndex"", ""testCreateCompositeEmbeddedMapByValueIndex"",
+      ""testCreateCompositeLinkMapByValueIndex"", ""testCreateCompositeEmbeddedSetIndex"", ""testCreateCompositeEmbeddedListIndex"" })
+  public void testGetClassInvolvedIndexesNotInvolvedPropertiesArrayParams() {
+    final Set<OIndex<?>> result = oClass.getClassInvolvedIndexes(""fTwo"", ""fFour"");
+
+    assertEquals(result.size(), 0);
+  }
+
+  @Test(dependsOnMethods = { ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
+      ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
+      ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
+      ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex"", ""testCreateCompositeEmbeddedMapIndex"",
+      ""testCreateCompositeEmbeddedMapByKeyIndex"", ""testCreateCompositeEmbeddedMapByValueIndex"",
+      ""testCreateCompositeLinkMapByValueIndex"", ""testCreateCompositeEmbeddedSetIndex"", ""testCreateCompositeEmbeddedListIndex"" })
+  public void testGetClassInvolvedIndexesPropertiesMorThanNeededArrayParams() {
+    final Set<OIndex<?>> result = oClass.getClassInvolvedIndexes(""fTwo"", ""fOne"", ""fThee"", ""fFour"");
+
+    assertEquals(result.size(), 0);
+  }
+
+  @Test(dependsOnMethods = { ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
+      ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
+      ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
+      ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex"", ""testCreateCompositeEmbeddedMapIndex"",
+      ""testCreateCompositeEmbeddedMapByKeyIndex"", ""testCreateCompositeEmbeddedMapByValueIndex"",
+      ""testCreateCompositeLinkMapByValueIndex"", ""testCreateCompositeEmbeddedSetIndex"", ""testCreateCompositeEmbeddedListIndex"" })
+  public void testGetInvolvedIndexesPropertiesMorThanNeeded() {
+    final Set<OIndex<?>> result = oClass.getClassInvolvedIndexes(Arrays.asList(""fTwo"", ""fOne"", ""fThee"", ""fFour""));
+
+    assertEquals(result.size(), 0);
+  }
+
+  @Test(dependsOnMethods = { ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
+      ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
+      ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
+      ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex"", ""testCreateCompositeEmbeddedMapIndex"",
+      ""testCreateCompositeEmbeddedMapByKeyIndex"", ""testCreateCompositeEmbeddedMapByValueIndex"",
+      ""testCreateCompositeLinkMapByValueIndex"", ""testCreateCompositeEmbeddedSetIndex"", ""testCreateCompositeEmbeddedListIndex"" })
+  public void testGetClassInvolvedIndexesOneProperty() {
+    final Set<OIndex<?>> result = oClass.getClassInvolvedIndexes(Arrays.asList(""fOne""));
+
+    assertEquals(result.size(), 3);
+
+    assertTrue(containsIndex(result, ""ClassIndexTestPropertyOne""));
+    assertTrue(containsIndex(result, ""ClassIndexTestCompositeOne""));
+    assertTrue(containsIndex(result, ""ClassIndexTestCompositeTwo""));
+  }
+
+  @Test(dependsOnMethods = { ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
+      ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
+      ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
+      ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex"", ""testCreateCompositeEmbeddedMapIndex"",
+      ""testCreateCompositeEmbeddedMapByKeyIndex"", ""testCreateCompositeEmbeddedMapByValueIndex"",
+      ""testCreateCompositeLinkMapByValueIndex"", ""testCreateCompositeEmbeddedSetIndex"", ""testCreateCompositeEmbeddedListIndex"" })
+  public void testGetClassInvolvedIndexesTwoProperties() {
+    final Set<OIndex<?>> result = oClass.getClassInvolvedIndexes(Arrays.asList(""fTwo"", ""fOne""));
+    assertEquals(result.size(), 2);
+
+    assertTrue(containsIndex(result, ""ClassIndexTestCompositeOne""));
+    assertTrue(containsIndex(result, ""ClassIndexTestCompositeTwo""));
+  }
+
+  @Test(dependsOnMethods = { ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
+      ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
+      ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
+      ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex"", ""testCreateCompositeEmbeddedMapIndex"",
+      ""testCreateCompositeEmbeddedMapByKeyIndex"", ""testCreateCompositeEmbeddedMapByValueIndex"",
+      ""testCreateCompositeLinkMapByValueIndex"", ""testCreateCompositeEmbeddedSetIndex"", ""testCreateCompositeEmbeddedListIndex"" })
+  public void testGetClassInvolvedIndexesThreeProperties() {
+    final Set<OIndex<?>> result = oClass.getClassInvolvedIndexes(Arrays.asList(""fTwo"", ""fOne"", ""fThree""));
+
+    assertEquals(result.size(), 1);
+    assertEquals(result.iterator().next().getName(), ""ClassIndexTestCompositeTwo"");
+  }
+
+  @Test(dependsOnMethods = { ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
+      ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
+      ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
+      ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex"", ""testCreateCompositeEmbeddedMapIndex"",
+      ""testCreateCompositeEmbeddedMapByKeyIndex"", ""testCreateCompositeEmbeddedMapByValueIndex"",
+      ""testCreateCompositeLinkMapByValueIndex"", ""testCreateCompositeEmbeddedSetIndex"", ""testCreateCompositeEmbeddedListIndex"" })
+  public void testGetClassInvolvedIndexesNotInvolvedProperties() {
+    final Set<OIndex<?>> result = oClass.getClassInvolvedIndexes(Arrays.asList(""fTwo"", ""fFour""));
+
+    assertEquals(result.size(), 0);
+  }
+
+  @Test(dependsOnMethods = { ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
+      ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
+      ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
+      ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex"", ""testCreateCompositeEmbeddedMapIndex"",
+      ""testCreateCompositeEmbeddedMapByKeyIndex"", ""testCreateCompositeEmbeddedMapByValueIndex"",
+      ""testCreateCompositeLinkMapByValueIndex"", ""testCreateCompositeEmbeddedSetIndex"", ""testCreateCompositeEmbeddedListIndex"" })
+  public void testGetClassInvolvedIndexesPropertiesMorThanNeeded() {
+    final Set<OIndex<?>> result = oClass.getClassInvolvedIndexes(Arrays.asList(""fTwo"", ""fOne"", ""fThee"", ""fFour""));
+
+    assertEquals(result.size(), 0);
+  }
+
+  @Test(dependsOnMethods = { ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
+      ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
+      ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
+      ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex"", ""testCreateCompositeEmbeddedMapIndex"",
+      ""testCreateCompositeEmbeddedMapByKeyIndex"", ""testCreateCompositeEmbeddedMapByValueIndex"",
+      ""testCreateCompositeLinkMapByValueIndex"", ""testCreateCompositeEmbeddedSetIndex"", ""testCreateCompositeEmbeddedListIndex"" })
+  public void testGetInvolvedIndexesOnePropertyArrayParams() {
+    final Set<OIndex<?>> result = oClass.getInvolvedIndexes(""fOne"");
+
+    assertEquals(result.size(), 3);
+
+    assertTrue(containsIndex(result, ""ClassIndexTestPropertyOne""));
+    assertTrue(containsIndex(result, ""ClassIndexTestCompositeOne""));
+    assertTrue(containsIndex(result, ""ClassIndexTestCompositeTwo""));
+  }
+
+  @Test(dependsOnMethods = { ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
+      ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
+      ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
+      ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex"", ""testCreateCompositeEmbeddedMapIndex"",
+      ""testCreateCompositeEmbeddedMapByKeyIndex"", ""testCreateCompositeEmbeddedMapByValueIndex"",
+      ""testCreateCompositeLinkMapByValueIndex"", ""testCreateCompositeEmbeddedSetIndex"", ""testCreateCompositeEmbeddedListIndex"" })
+  public void testGetInvolvedIndexesTwoPropertiesArrayParams() {
+    final Set<OIndex<?>> result = oClass.getInvolvedIndexes(""fTwo"", ""fOne"");
+    assertEquals(result.size(), 2);
+
+    assertTrue(containsIndex(result, ""ClassIndexTestCompositeOne""));
+    assertTrue(containsIndex(result, ""ClassIndexTestCompositeTwo""));
+  }
+
+  @Test(dependsOnMethods = { ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
+      ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
+      ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
+      ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex"", ""testCreateCompositeEmbeddedMapIndex"",
+      ""testCreateCompositeEmbeddedMapByKeyIndex"", ""testCreateCompositeEmbeddedMapByValueIndex"",
+      ""testCreateCompositeLinkMapByValueIndex"", ""testCreateCompositeEmbeddedSetIndex"", ""testCreateCompositeEmbeddedListIndex"" })
+  public void testGetInvolvedIndexesThreePropertiesArrayParams() {
+    final Set<OIndex<?>> result = oClass.getInvolvedIndexes(""fTwo"", ""fOne"", ""fThree"");
+
+    assertEquals(result.size(), 1);
+    assertEquals(result.iterator().next().getName(), ""ClassIndexTestCompositeTwo"");
+  }
+
+  @Test(dependsOnMethods = { ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
+      ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
+      ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
+      ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex"", ""testCreateCompositeEmbeddedMapIndex"",
+      ""testCreateCompositeEmbeddedMapByKeyIndex"", ""testCreateCompositeEmbeddedMapByValueIndex"",
+      ""testCreateCompositeLinkMapByValueIndex"", ""testCreateCompositeEmbeddedSetIndex"", ""testCreateCompositeEmbeddedListIndex"" })
+  public void testGetInvolvedIndexesNotInvolvedPropertiesArrayParams() {
+    final Set<OIndex<?>> result = oClass.getInvolvedIndexes(""fTwo"", ""fFour"");
+
+    assertEquals(result.size(), 0);
+  }
+
+  @Test(dependsOnMethods = { ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
+      ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
+      ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
+      ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex"", ""testCreateCompositeEmbeddedMapIndex"",
+      ""testCreateCompositeEmbeddedMapByKeyIndex"", ""testCreateCompositeEmbeddedMapByValueIndex"",
+      ""testCreateCompositeLinkMapByValueIndex"", ""testCreateCompositeEmbeddedSetIndex"", ""testCreateCompositeEmbeddedListIndex"" })
+  public void testGetParentInvolvedIndexesArrayParams() {
+    final Set<OIndex<?>> result = oClass.getInvolvedIndexes(""fNine"");
+
+    assertEquals(result.size(), 1);
+    assertEquals(result.iterator().next().getName(), ""ClassIndexTestParentPropertyNine"");
+  }
+
+  @Test(dependsOnMethods = { ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
+      ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
+      ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
+      ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex"", ""testCreateCompositeEmbeddedMapIndex"",
+      ""testCreateCompositeEmbeddedMapByKeyIndex"", ""testCreateCompositeEmbeddedMapByValueIndex"",
+      ""testCreateCompositeLinkMapByValueIndex"", ""testCreateCompositeEmbeddedSetIndex"", ""testCreateCompositeEmbeddedListIndex"" })
+  public void testGetParentChildInvolvedIndexesArrayParams() {
+    final Set<OIndex<?>> result = oClass.getInvolvedIndexes(""fOne"", ""fNine"");
+
+    assertEquals(result.size(), 0);
+  }
+
+  @Test(dependsOnMethods = { ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
+      ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
+      ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
+      ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex"", ""testCreateCompositeEmbeddedMapIndex"",
+      ""testCreateCompositeEmbeddedMapByKeyIndex"", ""testCreateCompositeEmbeddedMapByValueIndex"",
+      ""testCreateCompositeLinkMapByValueIndex"", ""testCreateCompositeEmbeddedSetIndex"", ""testCreateCompositeEmbeddedListIndex"" })
+  public void testGetInvolvedIndexesOneProperty() {
+    final Set<OIndex<?>> result = oClass.getInvolvedIndexes(Arrays.asList(""fOne""));
+
+    assertEquals(result.size(), 3);
+
+    assertTrue(containsIndex(result, ""ClassIndexTestPropertyOne""));
+    assertTrue(containsIndex(result, ""ClassIndexTestCompositeOne""));
+    assertTrue(containsIndex(result, ""ClassIndexTestCompositeTwo""));
+  }
+
+  @Test(dependsOnMethods = { ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
+      ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
+      ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
+      ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex"", ""testCreateCompositeEmbeddedMapIndex"",
+      ""testCreateCompositeEmbeddedMapByKeyIndex"", ""testCreateCompositeEmbeddedMapByValueIndex"",
+      ""testCreateCompositeLinkMapByValueIndex"", ""testCreateCompositeEmbeddedSetIndex"", ""testCreateCompositeEmbeddedListIndex"" })
+  public void testGetInvolvedIndexesTwoProperties() {
+    final Set<OIndex<?>> result = oClass.getInvolvedIndexes(Arrays.asList(""fTwo"", ""fOne""));
+    assertEquals(result.size(), 2);
+
+    assertTrue(containsIndex(result, ""ClassIndexTestCompositeOne""));
+    assertTrue(containsIndex(result, ""ClassIndexTestCompositeTwo""));
+  }
+
+  @Test(dependsOnMethods = { ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
+      ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
+      ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
+      ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex"", ""testCreateCompositeEmbeddedMapIndex"",
+      ""testCreateCompositeEmbeddedMapByKeyIndex"", ""testCreateCompositeEmbeddedMapByValueIndex"",
+      ""testCreateCompositeLinkMapByValueIndex"", ""testCreateCompositeEmbeddedSetIndex"", ""testCreateCompositeEmbeddedListIndex"" })
+  public void testGetInvolvedIndexesThreeProperties() {
+    final Set<OIndex<?>> result = oClass.getInvolvedIndexes(Arrays.asList(""fTwo"", ""fOne"", ""fThree""));
+
+    assertEquals(result.size(), 1);
+    assertEquals(result.iterator().next().getName(), ""ClassIndexTestCompositeTwo"");
+  }
+
+  @Test(dependsOnMethods = { ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
+      ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
+      ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
+      ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex"", ""testCreateCompositeEmbeddedMapIndex"",
+      ""testCreateCompositeEmbeddedMapByKeyIndex"", ""testCreateCompositeEmbeddedMapByValueIndex"",
+      ""testCreateCompositeLinkMapByValueIndex"", ""testCreateCompositeEmbeddedSetIndex"", ""testCreateCompositeEmbeddedListIndex"" })
+  public void testGetInvolvedIndexesNotInvolvedProperties() {
+    final Set<OIndex<?>> result = oClass.getInvolvedIndexes(Arrays.asList(""fTwo"", ""fFour""));
+
+    assertEquals(result.size(), 0);
+  }
+
+  @Test(dependsOnMethods = { ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
+      ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
+      ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
+      ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex"", ""testCreateCompositeEmbeddedMapIndex"",
+      ""testCreateCompositeEmbeddedMapByKeyIndex"", ""testCreateCompositeEmbeddedMapByValueIndex"",
+      ""testCreateCompositeLinkMapByValueIndex"", ""testCreateCompositeEmbeddedSetIndex"", ""testCreateCompositeEmbeddedListIndex"" })
+  public void testGetParentInvolvedIndexes() {
+    final Set<OIndex<?>> result = oClass.getInvolvedIndexes(Arrays.asList(""fNine""));
+
+    assertEquals(result.size(), 1);
+    assertEquals(result.iterator().next().getName(), ""ClassIndexTestParentPropertyNine"");
+  }
+
+  @Test(dependsOnMethods = { ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
+      ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
+      ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
+      ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex"", ""testCreateCompositeEmbeddedMapIndex"",
+      ""testCreateCompositeEmbeddedMapByKeyIndex"", ""testCreateCompositeEmbeddedMapByValueIndex"",
+      ""testCreateCompositeLinkMapByValueIndex"", ""testCreateCompositeEmbeddedSetIndex"", ""testCreateCompositeEmbeddedListIndex"" })
+  public void testGetParentChildInvolvedIndexes() {
+    final Set<OIndex<?>> result = oClass.getInvolvedIndexes(Arrays.asList(""fOne"", ""fNine""));
+
+    assertEquals(result.size(), 0);
+  }
+
+  @Test(dependsOnMethods = { ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
+      ""testCreateOnePropertyIndexTest"", ""testCreateOnePropertyEmbeddedMapIndex"", ""testCreateOnePropertyByKeyEmbeddedMapIndex"",
+      ""testCreateOnePropertyByValueEmbeddedMapIndex"", ""testCreateOnePropertyLinkedMapIndex"",
+      ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex"", ""testCreateCompositeEmbeddedMapIndex"",
+      ""testCreateCompositeEmbeddedMapByKeyIndex"", ""testCreateCompositeEmbeddedMapByValueIndex"",
+      ""testCreateCompositeLinkMapByValueIndex"", ""testCreateCompositeEmbeddedSetIndex"", ""testCreateCompositeEmbeddedListIndex"" })
+  public void testGetClassIndexes() {
+    final Set<OIndex<?>> indexes = oClass.getClassIndexes();
+    final Set<OIndexDefinition> expectedIndexDefinitions = new HashSet<OIndexDefinition>();
 
-    final OPropertyMapIndexDefinition propertyLinkMapByKeyIndexDefinition = new OPropertyMapIndexDefinition( ""ClassIndexTestClass"", ""fLinkMap"", OType.STRING,
-      OPropertyMapIndexDefinition.INDEX_BY.KEY );
-    expectedIndexDefinitions.add( propertyLinkMapByKeyIndexDefinition );
+    final OCompositeIndexDefinition compositeIndexOne = new OCompositeIndexDefinition(""ClassIndexTestClass"");
+
+    compositeIndexOne.addIndex(new OPropertyIndexDefinition(""ClassIndexTestClass"", ""fOne"", OType.INTEGER));
+    compositeIndexOne.addIndex(new OPropertyIndexDefinition(""ClassIndexTestClass"", ""fTwo"", OType.STRING));
+    expectedIndexDefinitions.add(compositeIndexOne);
+
+    final OCompositeIndexDefinition compositeIndexTwo = new OCompositeIndexDefinition(""ClassIndexTestClass"");
+
+    compositeIndexTwo.addIndex(new OPropertyIndexDefinition(""ClassIndexTestClass"", ""fOne"", OType.INTEGER));
+    compositeIndexTwo.addIndex(new OPropertyIndexDefinition(""ClassIndexTestClass"", ""fTwo"", OType.STRING));
+    compositeIndexTwo.addIndex(new OPropertyIndexDefinition(""ClassIndexTestClass"", ""fThree"", OType.BOOLEAN));
+    expectedIndexDefinitions.add(compositeIndexTwo);
+
+    final OCompositeIndexDefinition compositeIndexThree = new OCompositeIndexDefinition(""ClassIndexTestClass"");
+    compositeIndexThree.addIndex(new OPropertyIndexDefinition(""ClassIndexTestClass"", ""fEight"", OType.INTEGER));
+    compositeIndexThree.addIndex(new OPropertyMapIndexDefinition(""ClassIndexTestClass"", ""fEmbeddedMap"", OType.STRING,
+        OPropertyMapIndexDefinition.INDEX_BY.KEY));
+    expectedIndexDefinitions.add(compositeIndexThree);
+
+    final OCompositeIndexDefinition compositeIndexFour = new OCompositeIndexDefinition(""ClassIndexTestClass"");
+    compositeIndexFour.addIndex(new OPropertyIndexDefinition(""ClassIndexTestClass"", ""fTen"", OType.INTEGER));
+    compositeIndexFour.addIndex(new OPropertyMapIndexDefinition(""ClassIndexTestClass"", ""fEmbeddedMap"", OType.INTEGER,
+        OPropertyMapIndexDefinition.INDEX_BY.VALUE));
+    expectedIndexDefinitions.add(compositeIndexFour);
+
+    final OCompositeIndexDefinition compositeIndexFive = new OCompositeIndexDefinition(""ClassIndexTestClass"");
+    compositeIndexFive.addIndex(new OPropertyIndexDefinition(""ClassIndexTestClass"", ""fEleven"", OType.INTEGER));
+    compositeIndexFive.addIndex(new OPropertyMapIndexDefinition(""ClassIndexTestClass"", ""fLinkMap"", OType.LINK,
+        OPropertyMapIndexDefinition.INDEX_BY.VALUE));
+    expectedIndexDefinitions.add(compositeIndexFive);
+
+    final OCompositeIndexDefinition compositeIndexSix = new OCompositeIndexDefinition(""ClassIndexTestClass"");
+    compositeIndexSix.addIndex(new OPropertyIndexDefinition(""ClassIndexTestClass"", ""fTwelve"", OType.INTEGER));
+    compositeIndexSix.addIndex(new OPropertyListIndexDefinition(""ClassIndexTestClass"", ""fEmbeddedSet"", OType.INTEGER));
+    expectedIndexDefinitions.add(compositeIndexSix);
+
+    final OCompositeIndexDefinition compositeIndexSeven = new OCompositeIndexDefinition(""ClassIndexTestClass"");
+    compositeIndexSeven.addIndex(new OPropertyIndexDefinition(""ClassIndexTestClass"", ""fThirteen"", OType.INTEGER));
+    compositeIndexSeven.addIndex(new OPropertyListIndexDefinition(""ClassIndexTestClass"", ""fEmbeddedList"", OType.INTEGER));
+    expectedIndexDefinitions.add(compositeIndexSeven);
+
+    final OCompositeIndexDefinition compositeIndexEight = new OCompositeIndexDefinition(""ClassIndexTestClass"");
+    compositeIndexEight.addIndex(new OPropertyIndexDefinition(""ClassIndexTestClass"", ""fFourteen"", OType.INTEGER));
+    compositeIndexEight.addIndex(new OPropertyListIndexDefinition(""ClassIndexTestClass"", ""fEmbeddedList"", OType.LINK));
+    expectedIndexDefinitions.add(compositeIndexEight);
+
+    final OCompositeIndexDefinition compositeIndexNine = new OCompositeIndexDefinition(""ClassIndexTestClass"");
+    compositeIndexNine.addIndex(new OPropertyIndexDefinition(""ClassIndexTestClass"", ""fFifteen"", OType.INTEGER));
+    compositeIndexNine.addIndex(new OPropertyMapIndexDefinition(""ClassIndexTestClass"", ""fEmbeddedMap"", OType.STRING,
+        OPropertyMapIndexDefinition.INDEX_BY.KEY));
+    expectedIndexDefinitions.add(compositeIndexNine);
+
+    final OPropertyIndexDefinition propertyIndex = new OPropertyIndexDefinition(""ClassIndexTestClass"", ""fOne"", OType.INTEGER);
+    expectedIndexDefinitions.add(propertyIndex);
+
+    final OPropertyMapIndexDefinition propertyMapIndexDefinition = new OPropertyMapIndexDefinition(""ClassIndexTestClass"",
+        ""fEmbeddedMap"", OType.STRING, OPropertyMapIndexDefinition.INDEX_BY.KEY);
+    expectedIndexDefinitions.add(propertyMapIndexDefinition);
+
+    final OPropertyMapIndexDefinition propertyMapByValueIndexDefinition = new OPropertyMapIndexDefinition(""ClassIndexTestClass"",
+        ""fEmbeddedMap"", OType.INTEGER, OPropertyMapIndexDefinition.INDEX_BY.VALUE);
+    expectedIndexDefinitions.add(propertyMapByValueIndexDefinition);
+
+    final OPropertyMapIndexDefinition propertyLinkMapByKeyIndexDefinition = new OPropertyMapIndexDefinition(""ClassIndexTestClass"",
+        ""fLinkMap"", OType.STRING, OPropertyMapIndexDefinition.INDEX_BY.KEY);
+    expectedIndexDefinitions.add(propertyLinkMapByKeyIndexDefinition);
+
+    final OPropertyMapIndexDefinition propertyLinkMapByValueIndexDefinition = new OPropertyMapIndexDefinition(
+        ""ClassIndexTestClass"", ""fLinkMap"", OType.LINK, OPropertyMapIndexDefinition.INDEX_BY.VALUE);
+    expectedIndexDefinitions.add(propertyLinkMapByValueIndexDefinition);
+
+    assertEquals(indexes.size(), 15);
+
+    for (final OIndex index : indexes) {
+      assertTrue(expectedIndexDefinitions.contains(index.getDefinition()));
+    }
 
-    final OPropertyMapIndexDefinition propertyLinkMapByValueIndexDefinition = new OPropertyMapIndexDefinition( ""ClassIndexTestClass"", ""fLinkMap"", OType.LINK,
-      OPropertyMapIndexDefinition.INDEX_BY.VALUE );
-    expectedIndexDefinitions.add( propertyLinkMapByValueIndexDefinition );
+  }
 
-    assertEquals( indexes.size(), 8 );
+  @Test(dependsOnMethods = { ""createCompositeIndexTestWithListener"", ""createCompositeIndexTestWithoutListener"",
+      ""testCreateOnePropertyIndexTest"", ""createParentPropertyIndex"", ""testCreateOnePropertyEmbeddedMapIndex"",
+      ""testCreateOnePropertyByKeyEmbeddedMapIndex"", ""testCreateOnePropertyByValueEmbeddedMapIndex"",
+      ""testCreateOnePropertyLinkedMapIndex"", ""testCreateOnePropertyLinkMapByKeyIndex"", ""testCreateOnePropertyLinkMapByValueIndex"",
+      ""testCreateCompositeEmbeddedMapIndex"", ""testCreateCompositeEmbeddedMapByKeyIndex"",
+      ""testCreateCompositeEmbeddedMapByValueIndex"", ""testCreateCompositeLinkMapByValueIndex"",
+      ""testCreateCompositeEmbeddedSetIndex"", ""testCreateCompositeEmbeddedListIndex"" })
+  public void testGetIndexes() {
+    final Set<OIndex<?>> indexes = oClass.getIndexes();
+    final Set<OIndexDefinition> expectedIndexDefinitions = new HashSet<OIndexDefinition>();
 
-    for( final OIndex index : indexes ) {
-      assertTrue( expectedIndexDefinitions.contains( index.getDefinition() ) );
+    final OCompositeIndexDefinition compositeIndexOne = new OCompositeIndexDefinition(""ClassIndexTestClass"");
+
+    compositeIndexOne.addIndex(new OPropertyIndexDefinition(""ClassIndexTestClass"", ""fOne"", OType.INTEGER));
+    compositeIndexOne.addIndex(new OPropertyIndexDefinition(""ClassIndexTestClass"", ""fTwo"", OType.STRING));
+    expectedIndexDefinitions.add(compositeIndexOne);
+
+    final OCompositeIndexDefinition compositeIndexTwo = new OCompositeIndexDefinition(""ClassIndexTestClass"");
+
+    compositeIndexTwo.addIndex(new OPropertyIndexDefinition(""ClassIndexTestClass"", ""fOne"", OType.INTEGER));
+    compositeIndexTwo.addIndex(new OPropertyIndexDefinition(""ClassIndexTestClass"", ""fTwo"", OType.STRING));
+    compositeIndexTwo.addIndex(new OPropertyIndexDefinition(""ClassIndexTestClass"", ""fThree"", OType.BOOLEAN));
+    expectedIndexDefinitions.add(compositeIndexTwo);
+
+    final OCompositeIndexDefinition compositeIndexThree = new OCompositeIndexDefinition(""ClassIndexTestClass"");
+    compositeIndexThree.addIndex(new OPropertyIndexDefinition(""ClassIndexTestClass"", ""fEight"", OType.INTEGER));
+    compositeIndexThree.addIndex(new OPropertyMapIndexDefinition(""ClassIndexTestClass"", ""fEmbeddedMap"", OType.STRING,
+        OPropertyMapIndexDefinition.INDEX_BY.KEY));
+    expectedIndexDefinitions.add(compositeIndexThree);
+
+    final OCompositeIndexDefinition compositeIndexFour = new OCompositeIndexDefinition(""ClassIndexTestClass"");
+    compositeIndexFour.addIndex(new OPropertyIndexDefinition(""ClassIndexTestClass"", ""fTen"", OType.INTEGER));
+    compositeIndexFour.addIndex(new OPropertyMapIndexDefinition(""ClassIndexTestClass"", ""fEmbeddedMap"", OType.INTEGER,
+        OPropertyMapIndexDefinition.INDEX_BY.VALUE));
+    expectedIndexDefinitions.add(compositeIndexFour);
+
+    final OCompositeIndexDefinition compositeIndexFive = new OCompositeIndexDefinition(""ClassIndexTestClass"");
+    compositeIndexFive.addIndex(new OPropertyIndexDefinition(""ClassIndexTestClass"", ""fEleven"", OType.INTEGER));
+    compositeIndexFive.addIndex(new OPropertyMapIndexDefinition(""ClassIndexTestClass"", ""fLinkMap"", OType.LINK,
+        OPropertyMapIndexDefinition.INDEX_BY.VALUE));
+    expectedIndexDefinitions.add(compositeIndexFive);
+
+    final OCompositeIndexDefinition compositeIndexSix = new OCompositeIndexDefinition(""ClassIndexTestClass"");
+    compositeIndexSix.addIndex(new OPropertyIndexDefinition(""ClassIndexTestClass"", ""fTwelve"", OType.INTEGER));
+    compositeIndexSix.addIndex(new OPropertyListIndexDefinition(""ClassIndexTestClass"", ""fEmbeddedSet"", OType.INTEGER));
+    expectedIndexDefinitions.add(compositeIndexSix);
+
+    final OCompositeIndexDefinition compositeIndexSeven = new OCompositeIndexDefinition(""ClassIndexTestClass"");
+    compositeIndexSeven.addIndex(new OPropertyIndexDefinition(""ClassIndexTestClass"", ""fThirteen"", OType.INTEGER));
+    compositeIndexSeven.addIndex(new OPropertyListIndexDefinition(""ClassIndexTestClass"", ""fEmbeddedList"", OType.INTEGER));
+    expectedIndexDefinitions.add(compositeIndexSeven);
+
+    final OCompositeIndexDefinition compositeIndexEight = new OCompositeIndexDefinition(""ClassIndexTestClass"");
+    compositeIndexEight.addIndex(new OPropertyIndexDefinition(""ClassIndexTestClass"", ""fFourteen"", OType.INTEGER));
+    compositeIndexEight.addIndex(new OPropertyListIndexDefinition(""ClassIndexTestClass"", ""fEmbeddedList"", OType.LINK));
+    expectedIndexDefinitions.add(compositeIndexEight);
+
+    final OCompositeIndexDefinition compositeIndexNine = new OCompositeIndexDefinition(""ClassIndexTestClass"");
+    compositeIndexNine.addIndex(new OPropertyIndexDefinition(""ClassIndexTestClass"", ""fFifteen"", OType.INTEGER));
+    compositeIndexNine.addIndex(new OPropertyMapIndexDefinition(""ClassIndexTestClass"", ""fEmbeddedMap"", OType.STRING,
+        OPropertyMapIndexDefinition.INDEX_BY.KEY));
+    expectedIndexDefinitions.add(compositeIndexNine);
+
+    final OPropertyIndexDefinition propertyIndex = new OPropertyIndexDefinition(""ClassIndexTestClass"", ""fOne"", OType.INTEGER);
+    expectedIndexDefinitions.add(propertyIndex);
+
+    final OPropertyIndexDefinition parentPropertyIndex = new OPropertyIndexDefinition(""ClassIndexTestSuperClass"", ""fNine"",
+        OType.INTEGER);
+    expectedIndexDefinitions.add(parentPropertyIndex);
+
+    final OPropertyMapIndexDefinition propertyMapIndexDefinition = new OPropertyMapIndexDefinition(""ClassIndexTestClass"",
+        ""fEmbeddedMap"", OType.STRING, OPropertyMapIndexDefinition.INDEX_BY.KEY);
+    expectedIndexDefinitions.add(propertyMapIndexDefinition);
+
+    final OPropertyMapIndexDefinition propertyMapByValueIndexDefinition = new OPropertyMapIndexDefinition(""ClassIndexTestClass"",
+        ""fEmbeddedMap"", OType.INTEGER, OPropertyMapIndexDefinition.INDEX_BY.VALUE);
+    expectedIndexDefinitions.add(propertyMapByValueIndexDefinition);
+
+    final OPropertyMapIndexDefinition propertyLinkMapByKeyIndexDefinition = new OPropertyMapIndexDefinition(""ClassIndexTestClass"",
+        ""fLinkMap"", OType.STRING, OPropertyMapIndexDefinition.INDEX_BY.KEY);
+    expectedIndexDefinitions.add(propertyLinkMapByKeyIndexDefinition);
+
+    final OPropertyMapIndexDefinition propertyLinkMapByValueIndexDefinition = new OPropertyMapIndexDefinition(
+        ""ClassIndexTestClass"", ""fLinkMap"", OType.LINK, OPropertyMapIndexDefinition.INDEX_BY.VALUE);
+    expectedIndexDefinitions.add(propertyLinkMapByValueIndexDefinition);
+
+    assertEquals(indexes.size(), 16);
+
+    for (final OIndex index : indexes) {
+      assertTrue(expectedIndexDefinitions.contains(index.getDefinition()));
     }
   }
 
   @Test
-  public void testGetIndexesWithoutParent()
-  {
-
-    final OClass inClass = database.getMetadata().getSchema().createClass( ""ClassIndexInTest"" );
-    inClass.createProperty( ""fOne"", OType.INTEGER );
+  public void testGetIndexesWithoutParent() {
+    final OClass inClass = database.getMetadata().getSchema().createClass(""ClassIndexInTest"");
+    inClass.createProperty(""fOne"", OType.INTEGER);
 
-    final OIndex result = inClass.createIndex( ""ClassIndexTestPropertyOne"", OClass.INDEX_TYPE.UNIQUE, ""fOne"" );
+    final OIndex result = inClass.createIndex(""ClassIndexTestPropertyOne"", OClass.INDEX_TYPE.UNIQUE, ""fOne"");
 
-    assertEquals( result.getName(), ""ClassIndexTestPropertyOne"" );
-    assertEquals( inClass.getClassIndex( ""ClassIndexTestPropertyOne"" ).getName(), result.getName() );
+    assertEquals(result.getName(), ""ClassIndexTestPropertyOne"");
+    assertEquals(inClass.getClassIndex(""ClassIndexTestPropertyOne"").getName(), result.getName());
 
     final Set<OIndex<?>> indexes = inClass.getIndexes();
-    final OPropertyIndexDefinition propertyIndexDefinition = new OPropertyIndexDefinition( ""ClassIndexInTest"", ""fOne"", OType.INTEGER );
+    final OPropertyIndexDefinition propertyIndexDefinition = new OPropertyIndexDefinition(""ClassIndexInTest"", ""fOne"", OType.INTEGER);
 
-    assertEquals( indexes.size(), 1 );
+    assertEquals(indexes.size(), 1);
 
-    assertTrue( indexes.iterator().next().getDefinition().equals( propertyIndexDefinition ) );
+    assertTrue(indexes.iterator().next().getDefinition().equals(propertyIndexDefinition));
   }
 
   @Test(expectedExceptions = OIndexException.class)
-  public void testCreateIndexEmptyFields()
-  {
-    oClass.createIndex( ""ClassIndexTestCompositeEmpty"", OClass.INDEX_TYPE.UNIQUE );
+  public void testCreateIndexEmptyFields() {
+    oClass.createIndex(""ClassIndexTestCompositeEmpty"", OClass.INDEX_TYPE.UNIQUE);
   }
 
   @Test(expectedExceptions = OIndexException.class)
-  public void testCreateIndexAbsentFields()
-  {
-    oClass.createIndex( ""ClassIndexTestCompositeFieldAbsent"", OClass.INDEX_TYPE.UNIQUE, ""fFive"" );
+  public void testCreateIndexAbsentFields() {
+    oClass.createIndex(""ClassIndexTestCompositeFieldAbsent"", OClass.INDEX_TYPE.UNIQUE, ""fFive"");
   }
 
   @Test(expectedExceptions = OIndexException.class)
-  public void testCreateProxyIndex()
-  {
-    oClass.createIndex( ""ClassIndexTestProxyIndex"", OClass.INDEX_TYPE.PROXY, ""fOne"" );
+  public void testCreateProxyIndex() {
+    oClass.createIndex(""ClassIndexTestProxyIndex"", OClass.INDEX_TYPE.PROXY, ""fOne"");
   }
 
   @Test(expectedExceptions = OIndexException.class)
-  public void testCreateFullTextIndexTwoProperties()
-  {
-    oClass.createIndex( ""ClassIndexTestFulltextIndex"", OClass.INDEX_TYPE.FULLTEXT, ""fSix"", ""fSeven"" );
+  public void testCreateFullTextIndexTwoProperties() {
+    oClass.createIndex(""ClassIndexTestFulltextIndex"", OClass.INDEX_TYPE.FULLTEXT, ""fSix"", ""fSeven"");
   }
 
   @Test
-  public void testCreateFullTextIndexOneProperty()
-  {
-    final OIndex<?> result = oClass.createIndex( ""ClassIndexTestFulltextIndex"", OClass.INDEX_TYPE.FULLTEXT, ""fSix"" );
+  public void testCreateFullTextIndexOneProperty() {
+    final OIndex<?> result = oClass.createIndex(""ClassIndexTestFulltextIndex"", OClass.INDEX_TYPE.FULLTEXT, ""fSix"");
 
-    assertEquals( result.getName(), ""ClassIndexTestFulltextIndex"" );
-    assertEquals( oClass.getClassIndex( ""ClassIndexTestFulltextIndex"" ).getName(), result.getName() );
-    assertEquals( result.getType(), OClass.INDEX_TYPE.FULLTEXT.toString() );
+    assertEquals(result.getName(), ""ClassIndexTestFulltextIndex"");
+    assertEquals(oClass.getClassIndex(""ClassIndexTestFulltextIndex"").getName(), result.getName());
+    assertEquals(result.getType(), OClass.INDEX_TYPE.FULLTEXT.toString());
   }
 
   @Test
-  public void testCreateDictionaryIndex()
-  {
-    final OIndex<?> result = oClass.createIndex( ""ClassIndexTestDictionaryIndex"", OClass.INDEX_TYPE.DICTIONARY, ""fOne"" );
+  public void testCreateDictionaryIndex() {
+    final OIndex<?> result = oClass.createIndex(""ClassIndexTestDictionaryIndex"", OClass.INDEX_TYPE.DICTIONARY, ""fOne"");
 
-    assertEquals( result.getName(), ""ClassIndexTestDictionaryIndex"" );
-    assertEquals( oClass.getClassIndex( ""ClassIndexTestDictionaryIndex"" ).getName(), result.getName() );
-    assertEquals( result.getType(), OClass.INDEX_TYPE.DICTIONARY.toString() );
+    assertEquals(result.getName(), ""ClassIndexTestDictionaryIndex"");
+    assertEquals(oClass.getClassIndex(""ClassIndexTestDictionaryIndex"").getName(), result.getName());
+    assertEquals(result.getType(), OClass.INDEX_TYPE.DICTIONARY.toString());
   }
 
   @Test
-  public void testCreateNotUniqueIndex()
-  {
-    final OIndex<?> result = oClass.createIndex( ""ClassIndexTestNotUniqueIndex"", OClass.INDEX_TYPE.NOTUNIQUE, ""fOne"" );
+  public void testCreateNotUniqueIndex() {
+    final OIndex<?> result = oClass.createIndex(""ClassIndexTestNotUniqueIndex"", OClass.INDEX_TYPE.NOTUNIQUE, ""fOne"");
 
-    assertEquals( result.getName(), ""ClassIndexTestNotUniqueIndex"" );
-    assertEquals( oClass.getClassIndex( ""ClassIndexTestNotUniqueIndex"" ).getName(), result.getName() );
-    assertEquals( result.getType(), OClass.INDEX_TYPE.NOTUNIQUE.toString() );
+    assertEquals(result.getName(), ""ClassIndexTestNotUniqueIndex"");
+    assertEquals(oClass.getClassIndex(""ClassIndexTestNotUniqueIndex"").getName(), result.getName());
+    assertEquals(result.getType(), OClass.INDEX_TYPE.NOTUNIQUE.toString());
   }
 
@@ -1052,24 +1251,23 @@ public class ClassIndexTest
   public void testCreateMapWithoutLinkedType() {
     try {
-      oClass.createIndex( ""ClassIndexMapWithoutLinkedTypeIndex"", OClass.INDEX_TYPE.NOTUNIQUE, ""fEmbeddedMapWithoutLinkedType by value"" );
+      oClass.createIndex(""ClassIndexMapWithoutLinkedTypeIndex"", OClass.INDEX_TYPE.NOTUNIQUE,
+          ""fEmbeddedMapWithoutLinkedType by value"");
       fail();
     } catch (OIndexException e) {
-      assertEquals(e.getMessage(), ""Linked type was not provided. "" +
-              ""You should provide linked type for embedded collections that are going to be indexed."");
+      assertEquals(e.getMessage(), ""Linked type was not provided. ""
+          + ""You should provide linked type for embedded collections that are going to be indexed."");
     }
   }
-  
-  public void createParentPropertyIndex()
-  {
-    final OIndex result = oSuperClass.createIndex( ""ClassIndexTestParentPropertyNine"", OClass.INDEX_TYPE.UNIQUE, ""fNine"" );
 
-    assertEquals( result.getName(), ""ClassIndexTestParentPropertyNine"" );
-    assertEquals( oSuperClass.getClassIndex( ""ClassIndexTestParentPropertyNine"" ).getName(), result.getName() );
+  public void createParentPropertyIndex() {
+    final OIndex result = oSuperClass.createIndex(""ClassIndexTestParentPropertyNine"", OClass.INDEX_TYPE.UNIQUE, ""fNine"");
+
+    assertEquals(result.getName(), ""ClassIndexTestParentPropertyNine"");
+    assertEquals(oSuperClass.getClassIndex(""ClassIndexTestParentPropertyNine"").getName(), result.getName());
   }
 
-  private boolean containsIndex( final Collection<? extends OIndex> classIndexes, final String indexName )
-  {
-    for( final OIndex index : classIndexes ) {
-      if ( index.getName().equals( indexName ) ) {
+  private boolean containsIndex(final Collection<? extends OIndex> classIndexes, final String indexName) {
+    for (final OIndex index : classIndexes) {
+      if (index.getName().equals(indexName)) {
         return true;
       }
@@ -1079,11 +1277,10 @@ public class ClassIndexTest
 
   @Test
-  public void testDropProperty() throws Exception
-  {
-    oClass.createProperty( ""fFive"", OType.INTEGER );
+  public void testDropProperty() throws Exception {
+    oClass.createProperty(""fFive"", OType.INTEGER);
 
-    oClass.dropProperty( ""fFive"" );
+    oClass.dropProperty(""fFive"");
 
-    assertNull( oClass.getProperty( ""fFive"" ) );
+    assertNull(oClass.getProperty(""fFive""));
   }
 }
diff --git a/tests/src/test/java/com/orientechnologies/orient/test/database/auto/SQLSelectIndexReuseTest.java b/tests/src/test/java/com/orientechnologies/orient/test/database/auto/SQLSelectIndexReuseTest.java
index 6bb66684a7..c514c25cf6 100644
--- a/tests/src/test/java/com/orientechnologies/orient/test/database/auto/SQLSelectIndexReuseTest.java
+++ b/tests/src/test/java/com/orientechnologies/orient/test/database/auto/SQLSelectIndexReuseTest.java
@@ -3,6 +3,8 @@ package com.orientechnologies.orient.test.database.auto;
 import java.util.ArrayList;
 import java.util.HashMap;
+import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
+import java.util.Set;
 
 import org.testng.Assert;
@@ -19,2013 +21,2415 @@ import com.orientechnologies.orient.core.sql.OCommandSQL;
 import com.orientechnologies.orient.core.sql.query.OSQLSynchQuery;
 
-@Test(groups = {""index""})
+@Test(groups = { ""index"" })
 public class SQLSelectIndexReuseTest extends AbstractIndexReuseTest {
-	@Parameters(value = ""url"")
-	public SQLSelectIndexReuseTest(final String iURL) {
-		super(iURL);
-	}
-
-	@BeforeClass
-	public void beforeClass() throws Exception {
-		if (database.isClosed()) {
-			database.open(""admin"", ""admin"");
-		}
-
-		final OSchema schema = database.getMetadata().getSchema();
-		final OClass oClass = schema.createClass(""sqlSelectIndexReuseTestClass"");
-
-		oClass.createProperty(""prop1"", OType.INTEGER);
-		oClass.createProperty(""prop2"", OType.INTEGER);
-		oClass.createProperty(""prop3"", OType.INTEGER);
-		oClass.createProperty(""prop4"", OType.INTEGER);
-		oClass.createProperty(""prop5"", OType.INTEGER);
-		oClass.createProperty(""prop6"", OType.INTEGER);
-		oClass.createProperty(""prop7"", OType.STRING);
-		oClass.createProperty(""fEmbeddedMap"", OType.EMBEDDEDMAP, OType.INTEGER);
-		oClass.createProperty(""fLinkMap"", OType.LINKMAP);
-		oClass.createProperty(""fEmbeddedList"", OType.EMBEDDEDLIST, OType.INTEGER);
-		oClass.createProperty(""fLinkList"", OType.LINKLIST);
-
-		oClass.createIndex(""indexone"", OClass.INDEX_TYPE.UNIQUE, ""prop1"", ""prop2"");
-		oClass.createIndex(""indextwo"", OClass.INDEX_TYPE.UNIQUE, ""prop3"");
-		oClass.createIndex(""indexthree"", OClass.INDEX_TYPE.NOTUNIQUE, ""prop1"", ""prop2"", ""prop4"");
-		oClass.createIndex(""indexfour"", OClass.INDEX_TYPE.NOTUNIQUE, ""prop4"", ""prop1"", ""prop3"");
-		oClass.createIndex(""indexfive"", OClass.INDEX_TYPE.NOTUNIQUE, ""prop6"", ""prop1"", ""prop3"");
-		oClass.createIndex(""indexsix"", OClass.INDEX_TYPE.FULLTEXT, ""prop7"");
-		oClass.createIndex(""sqlSelectIndexReuseTestEmbeddedMapByKey"", OClass.INDEX_TYPE.NOTUNIQUE, ""fEmbeddedMap"");
-		oClass.createIndex(""sqlSelectIndexReuseTestEmbeddedMapByValue"", OClass.INDEX_TYPE.NOTUNIQUE, ""fEmbeddedMap by value"");
-		oClass.createIndex(""sqlSelectIndexReuseTestEmbeddedList"", OClass.INDEX_TYPE.NOTUNIQUE, ""fEmbeddedList"");
-
-		schema.save();
-
-		final String fullTextIndexStrings[] = {""Alice : What is the use of a book, without pictures or conversations?"",
-						""Rabbit : Oh my ears and whiskers, how late it's getting!"",
-						""Alice : If it had grown up, it would have made a dreadfully ugly child; but it makes rather a handsome pig, I think"",
-						""The Cat : We're all mad here."", ""The Hatter : Why is a raven like a writing desk?"",
-						""The Hatter : Twinkle, twinkle, little bat! How I wonder what you're at."", ""The Queen : Off with her head!"",
-						""The Duchess : Tut, tut, child! Everything's got a moral, if only you can find it."",
-						""The Duchess : Take care of the sense, and the sounds will take care of themselves."",
-						""The King : Begin at the beginning and go on till you come to the end: then stop.""};
-
-		for (int i = 0; i < 10; i++) {
-			final Map<String, Integer> embeddedMap = new HashMap<String, Integer>();
-
-			embeddedMap.put(""key"" + (i * 10 + 1), i * 10 + 1);
-			embeddedMap.put(""key"" + (i * 10 + 2), i * 10 + 2);
-			embeddedMap.put(""key"" + (i * 10 + 3), i * 10 + 3);
-			embeddedMap.put(""key"" + (i * 10 + 4), i * 10 + 1);
-
-			final List<Integer> embeddedList = new ArrayList<Integer>(3);
-			embeddedList.add(i * 3);
-			embeddedList.add(i * 3 + 1);
-			embeddedList.add(i * 3 + 2);
-
-			for (int j = 0; j < 10; j++) {
-				final ODocument document = new ODocument(""sqlSelectIndexReuseTestClass"");
-				document.field(""prop1"", i);
-				document.field(""prop2"", j);
-				document.field(""prop3"", i * 10 + j);
-
-				document.field(""prop4"", i);
-				document.field(""prop5"", i);
-
-				document.field(""prop6"", j);
-
-				document.field(""prop7"", fullTextIndexStrings[i]);
-
-				document.field(""fEmbeddedMap"", embeddedMap);
-
-				document.field(""fEmbeddedList"", embeddedList);
-
-				document.save();
-			}
-		}
-		database.close();
-	}
-
-	@AfterClass
-	public void afterClass() throws Exception {
-		if (database.isClosed()) {
-			database.open(""admin"", ""admin"");
-		}
-
-		database.command(new OCommandSQL(""drop class sqlSelectIndexReuseTestClass"")).execute();
-		database.getMetadata().getSchema().reload();
-		database.getLevel2Cache().clear();
-
-		database.close();
-	}
-
-	@Test
-	public void testCompositeSearchEquals() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-		long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
-		long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
-
-		if (oldIndexUsage == -1) {
-			oldIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage == -1) {
-			oldCompositeIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage2 == -1) {
-			oldCompositeIndexUsage2 = 0;
-		}
-
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1 = 1 and prop2 = 2"")).execute();
-
-		Assert.assertEquals(result.size(), 1);
-
-		final ODocument document = result.get(0);
-		Assert.assertEquals(document.<Integer>field(""prop1"").intValue(), 1);
-		Assert.assertEquals(document.<Integer>field(""prop2"").intValue(), 2);
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
-	}
-
-	@Test
-	public void testCompositeSearchHasChainOperatorsEquals() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1.asInteger() = 1 and prop2 = 2""))
-						.execute();
-
-		Assert.assertEquals(result.size(), 1);
-
-		final ODocument document = result.get(0);
-		Assert.assertEquals(document.<Integer>field(""prop1"").intValue(), 1);
-		Assert.assertEquals(document.<Integer>field(""prop2"").intValue(), 2);
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage);
-	}
-
-	@Test
-	public void testCompositeSearchEqualsOneField() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-		long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
-		long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
-
-		if (oldIndexUsage == -1) {
-			oldIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage == -1) {
-			oldCompositeIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage2 == -1) {
-			oldCompositeIndexUsage2 = 0;
-		}
-
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1 = 1"")).execute();
-
-		Assert.assertEquals(result.size(), 10);
-
-		for (int i = 0; i < 10; i++) {
-			final ODocument document = new ODocument();
-			document.field(""prop1"", 1);
-			document.field(""prop2"", i);
-
-			Assert.assertEquals(containsDocument(result, document), 1);
-		}
-
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
-	}
-
-	@Test
-	public void testNoCompositeSearchEquals() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop2 = 1"")).execute();
-
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage);
-		Assert.assertEquals(result.size(), 10);
-
-		for (int i = 0; i < 10; i++) {
-			final ODocument document = new ODocument();
-			document.field(""prop1"", i);
-			document.field(""prop2"", 1);
-
-			Assert.assertEquals(containsDocument(result, document), 1);
-		}
-	}
-
-	@Test
-	public void testCompositeSearchEqualsWithArgs() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-		long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
-		long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
-
-		if (oldIndexUsage == -1) {
-			oldIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage == -1) {
-			oldCompositeIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage2 == -1) {
-			oldCompositeIndexUsage2 = 0;
-		}
-
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1 = ? and prop2 = ?"")).execute(1, 2);
-
-		Assert.assertEquals(result.size(), 1);
-
-		final ODocument document = result.get(0);
-		Assert.assertEquals(document.<Integer>field(""prop1"").intValue(), 1);
-		Assert.assertEquals(document.<Integer>field(""prop2"").intValue(), 2);
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
-	}
-
-	@Test
-	public void testCompositeSearchEqualsOneFieldWithArgs() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-		long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
-		long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
-
-		if (oldIndexUsage == -1) {
-			oldIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage == -1) {
-			oldCompositeIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage2 == -1) {
-			oldCompositeIndexUsage2 = 0;
-		}
-
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1 = ?"")).execute(1);
-
-		Assert.assertEquals(result.size(), 10);
-
-		for (int i = 0; i < 10; i++) {
-			final ODocument document = new ODocument();
-			document.field(""prop1"", 1);
-			document.field(""prop2"", i);
-
-			Assert.assertEquals(containsDocument(result, document), 1);
-		}
-
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
-	}
-
-	@Test
-	public void testNoCompositeSearchEqualsWithArgs() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop2 = ?"")).execute(1);
-
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage);
-		Assert.assertEquals(result.size(), 10);
-
-		for (int i = 0; i < 10; i++) {
-			final ODocument document = new ODocument();
-			document.field(""prop1"", i);
-			document.field(""prop2"", 1);
-
-			Assert.assertEquals(containsDocument(result, document), 1);
-		}
-	}
-
-	@Test
-	public void testCompositeSearchGT() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-		long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
-		long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
-
-		if (oldIndexUsage == -1) {
-			oldIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage == -1) {
-			oldCompositeIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage2 == -1) {
-			oldCompositeIndexUsage2 = 0;
-		}
-
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1 = 1 and prop2 > 2"")).execute();
-
-		Assert.assertEquals(result.size(), 7);
-
-		for (int i = 3; i < 10; i++) {
-			final ODocument document = new ODocument();
-			document.field(""prop1"", 1);
-			document.field(""prop2"", i);
-
-			Assert.assertEquals(containsDocument(result, document), 1);
-		}
-
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
-	}
-
-	@Test
-	public void testCompositeSearchGTOneField() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-		long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
-		long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
-
-		if (oldIndexUsage == -1) {
-			oldIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage == -1) {
-			oldCompositeIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage2 == -1) {
-			oldCompositeIndexUsage2 = 0;
-		}
-
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1 > 7"")).execute();
-
-		Assert.assertEquals(result.size(), 20);
-
-		for (int i = 8; i < 10; i++) {
-			for (int j = 0; j < 10; j++) {
-				final ODocument document = new ODocument();
-				document.field(""prop1"", i);
-				document.field(""prop2"", j);
-
-				Assert.assertEquals(containsDocument(result, document), 1);
-			}
-		}
-
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
-	}
-
-	@Test
-	public void testCompositeSearchGTOneFieldNoSearch() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop2 > 7"")).execute();
-
-		Assert.assertEquals(result.size(), 20);
-
-		for (int i = 8; i < 10; i++) {
-			for (int j = 0; j < 10; j++) {
-				final ODocument document = new ODocument();
-				document.field(""prop1"", j);
-				document.field(""prop2"", i);
-
-				Assert.assertEquals(containsDocument(result, document), 1);
-			}
-		}
-
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage);
-	}
-
-	@Test
-	public void testCompositeSearchGTWithArgs() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-		long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
-		long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
-
-		if (oldIndexUsage == -1) {
-			oldIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage == -1) {
-			oldCompositeIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage2 == -1) {
-			oldCompositeIndexUsage2 = 0;
-		}
-
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1 = ? and prop2 > ?"")).execute(1, 2);
-
-		Assert.assertEquals(result.size(), 7);
-
-		for (int i = 3; i < 10; i++) {
-			final ODocument document = new ODocument();
-			document.field(""prop1"", 1);
-			document.field(""prop2"", i);
-
-			Assert.assertEquals(containsDocument(result, document), 1);
-		}
-
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
-	}
-
-	@Test
-	public void testCompositeSearchGTOneFieldWithArgs() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-		long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
-		long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
-
-		if (oldIndexUsage == -1) {
-			oldIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage == -1) {
-			oldCompositeIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage2 == -1) {
-			oldCompositeIndexUsage2 = 0;
-		}
-
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1 > ?"")).execute(7);
-
-		Assert.assertEquals(result.size(), 20);
-
-		for (int i = 8; i < 10; i++) {
-			for (int j = 0; j < 10; j++) {
-				final ODocument document = new ODocument();
-				document.field(""prop1"", i);
-				document.field(""prop2"", j);
-
-				Assert.assertEquals(containsDocument(result, document), 1);
-			}
-		}
-
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
-	}
-
-	@Test
-	public void testCompositeSearchGTOneFieldNoSearchWithArgs() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop2 > ?"")).execute(7);
-
-		Assert.assertEquals(result.size(), 20);
-
-		for (int i = 8; i < 10; i++) {
-			for (int j = 0; j < 10; j++) {
-				final ODocument document = new ODocument();
-				document.field(""prop1"", j);
-				document.field(""prop2"", i);
-
-				Assert.assertEquals(containsDocument(result, document), 1);
-			}
-		}
-
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage);
-	}
-
-	@Test
-	public void testCompositeSearchGTQ() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-		long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
-		long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
-
-		if (oldIndexUsage == -1) {
-			oldIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage == -1) {
-			oldCompositeIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage2 == -1) {
-			oldCompositeIndexUsage2 = 0;
-		}
-
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1 = 1 and prop2 >= 2"")).execute();
-
-		Assert.assertEquals(result.size(), 8);
-
-		for (int i = 2; i < 10; i++) {
-			final ODocument document = new ODocument();
-			document.field(""prop1"", 1);
-			document.field(""prop2"", i);
-
-			Assert.assertEquals(containsDocument(result, document), 1);
-		}
-
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
-	}
-
-	@Test
-	public void testCompositeSearchGTQOneField() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-		long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
-		long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
-
-		if (oldIndexUsage == -1) {
-			oldIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage == -1) {
-			oldCompositeIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage2 == -1) {
-			oldCompositeIndexUsage2 = 0;
-		}
-
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1 >= 7"")).execute();
-
-		Assert.assertEquals(result.size(), 30);
-
-		for (int i = 7; i < 10; i++) {
-			for (int j = 0; j < 10; j++) {
-				final ODocument document = new ODocument();
-				document.field(""prop1"", i);
-				document.field(""prop2"", j);
-
-				Assert.assertEquals(containsDocument(result, document), 1);
-			}
-		}
-
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
-	}
-
-	@Test
-	public void testCompositeSearchGTQOneFieldNoSearch() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop2 >= 7"")).execute();
-
-		Assert.assertEquals(result.size(), 30);
-
-		for (int i = 7; i < 10; i++) {
-			for (int j = 0; j < 10; j++) {
-				final ODocument document = new ODocument();
-				document.field(""prop1"", j);
-				document.field(""prop2"", i);
-
-				Assert.assertEquals(containsDocument(result, document), 1);
-			}
-		}
-
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage);
-	}
-
-	@Test
-	public void testCompositeSearchGTQWithArgs() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-		long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
-		long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
-
-		if (oldIndexUsage == -1) {
-			oldIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage == -1) {
-			oldCompositeIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage2 == -1) {
-			oldCompositeIndexUsage2 = 0;
-		}
-
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1 = ? and prop2 >= ?"")).execute(1, 2);
-
-		Assert.assertEquals(result.size(), 8);
-
-		for (int i = 2; i < 10; i++) {
-			final ODocument document = new ODocument();
-			document.field(""prop1"", 1);
-			document.field(""prop2"", i);
-
-			Assert.assertEquals(containsDocument(result, document), 1);
-		}
-
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
-	}
-
-	@Test
-	public void testCompositeSearchGTQOneFieldWithArgs() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-		long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
-		long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
-
-		if (oldIndexUsage == -1) {
-			oldIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage == -1) {
-			oldCompositeIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage2 == -1) {
-			oldCompositeIndexUsage2 = 0;
-		}
-
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1 >= ?"")).execute(7);
-
-		Assert.assertEquals(result.size(), 30);
-
-		for (int i = 7; i < 10; i++) {
-			for (int j = 0; j < 10; j++) {
-				final ODocument document = new ODocument();
-				document.field(""prop1"", i);
-				document.field(""prop2"", j);
-
-				Assert.assertEquals(containsDocument(result, document), 1);
-			}
-		}
-
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
-	}
-
-	@Test
-	public void testCompositeSearchGTQOneFieldNoSearchWithArgs() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop2 >= ?"")).execute(7);
-
-		Assert.assertEquals(result.size(), 30);
-
-		for (int i = 7; i < 10; i++) {
-			for (int j = 0; j < 10; j++) {
-				final ODocument document = new ODocument();
-				document.field(""prop1"", j);
-				document.field(""prop2"", i);
-
-				Assert.assertEquals(containsDocument(result, document), 1);
-			}
-		}
-
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage);
-	}
-
-	@Test
-	public void testCompositeSearchLTQ() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-		long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
-		long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
-
-		if (oldIndexUsage == -1) {
-			oldIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage == -1) {
-			oldCompositeIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage2 == -1) {
-			oldCompositeIndexUsage2 = 0;
-		}
-
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1 = 1 and prop2 <= 2"")).execute();
-
-		Assert.assertEquals(result.size(), 3);
-
-		for (int i = 0; i <= 2; i++) {
-			final ODocument document = new ODocument();
-			document.field(""prop1"", 1);
-			document.field(""prop2"", i);
-
-			Assert.assertEquals(containsDocument(result, document), 1);
-		}
-
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
-
-	}
-
-	@Test
-	public void testCompositeSearchLTQOneField() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-		long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
-		long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
-
-		if (oldIndexUsage == -1) {
-			oldIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage == -1) {
-			oldCompositeIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage2 == -1) {
-			oldCompositeIndexUsage2 = 0;
-		}
-
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1 <= 7"")).execute();
-
-		Assert.assertEquals(result.size(), 80);
-
-		for (int i = 0; i <= 7; i++) {
-			for (int j = 0; j < 10; j++) {
-				final ODocument document = new ODocument();
-				document.field(""prop1"", i);
-				document.field(""prop2"", j);
-
-				Assert.assertEquals(containsDocument(result, document), 1);
-			}
-		}
-
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
-	}
-
-	@Test
-	public void testCompositeSearchLTQOneFieldNoSearch() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop2 <= 7"")).execute();
-
-		Assert.assertEquals(result.size(), 80);
-
-		for (int i = 0; i <= 7; i++) {
-			for (int j = 0; j < 10; j++) {
-				final ODocument document = new ODocument();
-				document.field(""prop1"", j);
-				document.field(""prop2"", i);
-
-				Assert.assertEquals(containsDocument(result, document), 1);
-			}
-		}
-
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage);
-	}
-
-	@Test
-	public void testCompositeSearchLTQWithArgs() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-		long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
-		long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
-
-		if (oldIndexUsage == -1) {
-			oldIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage == -1) {
-			oldCompositeIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage2 == -1) {
-			oldCompositeIndexUsage2 = 0;
-		}
-
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1 = ? and prop2 <= ?"")).execute(1, 2);
-
-		Assert.assertEquals(result.size(), 3);
-
-		for (int i = 0; i <= 2; i++) {
-			final ODocument document = new ODocument();
-			document.field(""prop1"", 1);
-			document.field(""prop2"", i);
-
-			Assert.assertEquals(containsDocument(result, document), 1);
-		}
-
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
-	}
-
-	@Test
-	public void testCompositeSearchLTQOneFieldWithArgs() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-		long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
-		long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
-
-		if (oldIndexUsage == -1) {
-			oldIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage == -1) {
-			oldCompositeIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage2 == -1) {
-			oldCompositeIndexUsage2 = 0;
-		}
-
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1 <= ?"")).execute(7);
-
-		Assert.assertEquals(result.size(), 80);
-
-		for (int i = 0; i <= 7; i++) {
-			for (int j = 0; j < 10; j++) {
-				final ODocument document = new ODocument();
-				document.field(""prop1"", i);
-				document.field(""prop2"", j);
-
-				Assert.assertEquals(containsDocument(result, document), 1);
-			}
-		}
-
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
-	}
-
-	@Test
-	public void testCompositeSearchLTQOneFieldNoSearchWithArgs() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop2 <= ?"")).execute(7);
-
-		Assert.assertEquals(result.size(), 80);
-
-		for (int i = 0; i <= 7; i++) {
-			for (int j = 0; j < 10; j++) {
-				final ODocument document = new ODocument();
-				document.field(""prop1"", j);
-				document.field(""prop2"", i);
-
-				Assert.assertEquals(containsDocument(result, document), 1);
-			}
-		}
-
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage);
-	}
-
-	@Test
-	public void testCompositeSearchLT() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-		long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
-		long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
-
-		if (oldIndexUsage == -1) {
-			oldIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage == -1) {
-			oldCompositeIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage2 == -1) {
-			oldCompositeIndexUsage2 = 0;
-		}
-
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1 = 1 and prop2 < 2"")).execute();
-
-		Assert.assertEquals(result.size(), 2);
-
-		for (int i = 0; i < 2; i++) {
-			final ODocument document = new ODocument();
-			document.field(""prop1"", 1);
-			document.field(""prop2"", i);
-
-			Assert.assertEquals(containsDocument(result, document), 1);
-		}
-
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
-	}
-
-	@Test
-	public void testCompositeSearchLTOneField() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-		long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
-		long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
-
-		if (oldIndexUsage == -1) {
-			oldIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage == -1) {
-			oldCompositeIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage2 == -1) {
-			oldCompositeIndexUsage2 = 0;
-		}
-
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1 < 7"")).execute();
-
-		Assert.assertEquals(result.size(), 70);
-
-		for (int i = 0; i < 7; i++) {
-			for (int j = 0; j < 10; j++) {
-				final ODocument document = new ODocument();
-				document.field(""prop1"", i);
-				document.field(""prop2"", j);
-
-				Assert.assertEquals(containsDocument(result, document), 1);
-			}
-		}
-
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
-	}
-
-	@Test
-	public void testCompositeSearchLTOneFieldNoSearch() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop2 < 7"")).execute();
-
-		Assert.assertEquals(result.size(), 70);
-
-		for (int i = 0; i < 7; i++) {
-			for (int j = 0; j < 10; j++) {
-				final ODocument document = new ODocument();
-				document.field(""prop1"", j);
-				document.field(""prop2"", i);
-
-				Assert.assertEquals(containsDocument(result, document), 1);
-			}
-		}
-
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage);
-	}
-
-	@Test
-	public void testCompositeSearchLTWithArgs() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-		long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
-		long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
-
-		if (oldIndexUsage == -1) {
-			oldIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage == -1) {
-			oldCompositeIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage2 == -1) {
-			oldCompositeIndexUsage2 = 0;
-		}
-
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1 = ? and prop2 < ?"")).execute(1, 2);
-
-		Assert.assertEquals(result.size(), 2);
-
-		for (int i = 0; i < 2; i++) {
-			final ODocument document = new ODocument();
-			document.field(""prop1"", 1);
-			document.field(""prop2"", i);
-
-			Assert.assertEquals(containsDocument(result, document), 1);
-		}
-
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
-	}
-
-	@Test
-	public void testCompositeSearchLTOneFieldWithArgs() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-		long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
-		long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
-
-		if (oldIndexUsage == -1) {
-			oldIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage == -1) {
-			oldCompositeIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage2 == -1) {
-			oldCompositeIndexUsage2 = 0;
-		}
-
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1 < ?"")).execute(7);
-
-		Assert.assertEquals(result.size(), 70);
-
-		for (int i = 0; i < 7; i++) {
-			for (int j = 0; j < 10; j++) {
-				final ODocument document = new ODocument();
-				document.field(""prop1"", i);
-				document.field(""prop2"", j);
-
-				Assert.assertEquals(containsDocument(result, document), 1);
-			}
-		}
-
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
-	}
-
-	@Test
-	public void testCompositeSearchLTOneFieldNoSearchWithArgs() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop2 < ?"")).execute(7);
-
-		Assert.assertEquals(result.size(), 70);
-
-		for (int i = 0; i < 7; i++) {
-			for (int j = 0; j < 10; j++) {
-				final ODocument document = new ODocument();
-				document.field(""prop1"", j);
-				document.field(""prop2"", i);
-
-				Assert.assertEquals(containsDocument(result, document), 1);
-			}
-		}
-
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage);
-	}
-
-	@Test
-	public void testCompositeSearchBetween() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-		long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
-		long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
-
-		if (oldIndexUsage == -1) {
-			oldIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage == -1) {
-			oldCompositeIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage2 == -1) {
-			oldCompositeIndexUsage2 = 0;
-		}
-
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1 = 1 and prop2 between 1 and 3""))
-						.execute();
-
-		Assert.assertEquals(result.size(), 3);
-
-		for (int i = 1; i <= 3; i++) {
-			final ODocument document = new ODocument();
-			document.field(""prop1"", 1);
-			document.field(""prop2"", i);
-
-			Assert.assertEquals(containsDocument(result, document), 1);
-		}
-
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
-	}
-
-	@Test
-	public void testCompositeSearchBetweenOneField() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-		long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
-		long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
-
-		if (oldIndexUsage == -1) {
-			oldIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage == -1) {
-			oldCompositeIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage2 == -1) {
-			oldCompositeIndexUsage2 = 0;
-		}
-
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1 between 1 and 3"")).execute();
-
-		Assert.assertEquals(result.size(), 30);
-
-		for (int i = 1; i <= 3; i++) {
-			for (int j = 0; j < 10; j++) {
-				final ODocument document = new ODocument();
-				document.field(""prop1"", i);
-				document.field(""prop2"", j);
-
-				Assert.assertEquals(containsDocument(result, document), 1);
-			}
-		}
-
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
-	}
-
-	@Test
-	public void testCompositeSearchBetweenOneFieldNoSearch() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop2 between 1 and 3"")).execute();
-
-		Assert.assertEquals(result.size(), 30);
-
-		for (int i = 1; i <= 3; i++) {
-			for (int j = 0; j < 10; j++) {
-				final ODocument document = new ODocument();
-				document.field(""prop1"", j);
-				document.field(""prop2"", i);
-
-				Assert.assertEquals(containsDocument(result, document), 1);
-			}
-		}
-
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage);
-	}
-
-	@Test
-	public void testCompositeSearchBetweenWithArgs() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-		long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
-		long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
-
-		if (oldIndexUsage == -1) {
-			oldIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage == -1) {
-			oldCompositeIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage2 == -1) {
-			oldCompositeIndexUsage2 = 0;
-		}
-
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1 = 1 and prop2 between ? and ?""))
-						.execute(1, 3);
-
-		Assert.assertEquals(result.size(), 3);
-
-		for (int i = 1; i <= 3; i++) {
-			final ODocument document = new ODocument();
-			document.field(""prop1"", 1);
-			document.field(""prop2"", i);
-
-			Assert.assertEquals(containsDocument(result, document), 1);
-		}
-
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
-	}
-
-	@Test
-	public void testCompositeSearchBetweenOneFieldWithArgs() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-		long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
-		long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
-
-		if (oldIndexUsage == -1) {
-			oldIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage == -1) {
-			oldCompositeIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage2 == -1) {
-			oldCompositeIndexUsage2 = 0;
-		}
-
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1 between ? and ?"")).execute(1, 3);
-
-		Assert.assertEquals(result.size(), 30);
-
-		for (int i = 1; i <= 3; i++) {
-			for (int j = 0; j < 10; j++) {
-				final ODocument document = new ODocument();
-				document.field(""prop1"", i);
-				document.field(""prop2"", j);
-
-				Assert.assertEquals(containsDocument(result, document), 1);
-			}
-		}
-
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
-	}
-
-	@Test
-	public void testCompositeSearchBetweenOneFieldNoSearchWithArgs() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop2 between ? and ?"")).execute(1, 3);
-
-		Assert.assertEquals(result.size(), 30);
-
-		for (int i = 1; i <= 3; i++) {
-			for (int j = 0; j < 10; j++) {
-				final ODocument document = new ODocument();
-				document.field(""prop1"", j);
-				document.field(""prop2"", i);
-
-				Assert.assertEquals(containsDocument(result, document), 1);
-			}
-		}
-
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage);
-	}
-
-	@Test
-	public void testSingleSearchEquals() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-		long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
-
-		if (oldIndexUsage == -1) {
-			oldIndexUsage = 0;
-		}
-
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop3 = 1"")).execute();
-
-		Assert.assertEquals(result.size(), 1);
-
-		final ODocument document = result.get(0);
-		Assert.assertEquals(document.<Integer>field(""prop3"").intValue(), 1);
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage);
-	}
-
-	@Test
-	public void testSingleSearchEqualsWithArgs() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-		long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
-
-		if (oldIndexUsage == -1) {
-			oldIndexUsage = 0;
-		}
-
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop3 = ?"")).execute(1);
-
-		Assert.assertEquals(result.size(), 1);
-
-		final ODocument document = result.get(0);
-		Assert.assertEquals(document.<Integer>field(""prop3"").intValue(), 1);
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage);
-	}
-
-	@Test
-	public void testSingleSearchGT() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-		long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
-
-		if (oldIndexUsage == -1) {
-			oldIndexUsage = 0;
-		}
-
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop3 > 90"")).execute();
+  @Parameters(value = ""url"")
+  public SQLSelectIndexReuseTest(final String iURL) {
+    super(iURL);
+  }
 
-		Assert.assertEquals(result.size(), 9);
+  @BeforeClass
+  public void beforeClass() throws Exception {
+    if (database.isClosed()) {
+      database.open(""admin"", ""admin"");
+    }
 
-		for (int i = 91; i < 100; i++) {
-			final ODocument document = new ODocument();
-			document.field(""prop3"", i);
-			Assert.assertEquals(containsDocument(result, document), 1);
-		}
+    final OSchema schema = database.getMetadata().getSchema();
+    final OClass oClass = schema.createClass(""sqlSelectIndexReuseTestClass"");
 
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage);
-	}
-
-	@Test
-	public void testSingleSearchGTWithArgs() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-		long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
+    oClass.createProperty(""prop1"", OType.INTEGER);
+    oClass.createProperty(""prop2"", OType.INTEGER);
+    oClass.createProperty(""prop3"", OType.INTEGER);
+    oClass.createProperty(""prop4"", OType.INTEGER);
+    oClass.createProperty(""prop5"", OType.INTEGER);
+    oClass.createProperty(""prop6"", OType.INTEGER);
+    oClass.createProperty(""prop7"", OType.STRING);
+    oClass.createProperty(""prop8"", OType.INTEGER);
+    oClass.createProperty(""prop9"", OType.INTEGER);
+
+    oClass.createProperty(""fEmbeddedMap"", OType.EMBEDDEDMAP, OType.INTEGER);
+    oClass.createProperty(""fEmbeddedMapTwo"", OType.EMBEDDEDMAP, OType.INTEGER);
 
-		if (oldIndexUsage == -1) {
-			oldIndexUsage = 0;
-		}
+    oClass.createProperty(""fLinkMap"", OType.LINKMAP);
 
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop3 > ?"")).execute(90);
+    oClass.createProperty(""fEmbeddedList"", OType.EMBEDDEDLIST, OType.INTEGER);
+    oClass.createProperty(""fEmbeddedListTwo"", OType.EMBEDDEDLIST, OType.INTEGER);
 
-		Assert.assertEquals(result.size(), 9);
+    oClass.createProperty(""fLinkList"", OType.LINKLIST);
 
-		for (int i = 91; i < 100; i++) {
-			final ODocument document = new ODocument();
-			document.field(""prop3"", i);
-			Assert.assertEquals(containsDocument(result, document), 1);
-		}
+    oClass.createProperty(""fEmbeddedSet"", OType.EMBEDDEDSET, OType.INTEGER);
+    oClass.createProperty(""fEmbeddedSetTwo"", OType.EMBEDDEDSET, OType.INTEGER);
+
+    oClass.createIndex(""indexone"", OClass.INDEX_TYPE.UNIQUE, ""prop1"", ""prop2"");
+    oClass.createIndex(""indextwo"", OClass.INDEX_TYPE.UNIQUE, ""prop3"");
+    oClass.createIndex(""indexthree"", OClass.INDEX_TYPE.NOTUNIQUE, ""prop1"", ""prop2"", ""prop4"");
+    oClass.createIndex(""indexfour"", OClass.INDEX_TYPE.NOTUNIQUE, ""prop4"", ""prop1"", ""prop3"");
+    oClass.createIndex(""indexfive"", OClass.INDEX_TYPE.NOTUNIQUE, ""prop6"", ""prop1"", ""prop3"");
+    oClass.createIndex(""indexsix"", OClass.INDEX_TYPE.FULLTEXT, ""prop7"");
+
+    oClass.createIndex(""sqlSelectIndexReuseTestEmbeddedMapByKey"", OClass.INDEX_TYPE.NOTUNIQUE, ""fEmbeddedMap"");
+    oClass.createIndex(""sqlSelectIndexReuseTestEmbeddedMapByValue"", OClass.INDEX_TYPE.NOTUNIQUE, ""fEmbeddedMap by value"");
+    oClass.createIndex(""sqlSelectIndexReuseTestEmbeddedList"", OClass.INDEX_TYPE.NOTUNIQUE, ""fEmbeddedList"");
+
+    oClass.createIndex(""sqlSelectIndexReuseTestEmbeddedMapByKeyProp8"", OClass.INDEX_TYPE.NOTUNIQUE, ""fEmbeddedMapTwo"", ""prop8"");
+    oClass.createIndex(""sqlSelectIndexReuseTestEmbeddedMapByValueProp8"", OClass.INDEX_TYPE.NOTUNIQUE, ""fEmbeddedMapTwo by value"",
+        ""prop8"");
+
+    oClass.createIndex(""sqlSelectIndexReuseTestEmbeddedSetProp8"", OClass.INDEX_TYPE.NOTUNIQUE, ""fEmbeddedSetTwo"", ""prop8"");
+    oClass.createIndex(""sqlSelectIndexReuseTestProp9EmbeddedSetProp8"", OClass.INDEX_TYPE.NOTUNIQUE, ""prop9"", ""fEmbeddedSetTwo"",
+        ""prop8"");
+
+    oClass.createIndex(""sqlSelectIndexReuseTestEmbeddedListTwoProp8"", OClass.INDEX_TYPE.NOTUNIQUE, ""fEmbeddedListTwo"", ""prop8"");
+
+    schema.save();
+
+    final String fullTextIndexStrings[] = { ""Alice : What is the use of a book, without pictures or conversations?"",
+        ""Rabbit : Oh my ears and whiskers, how late it's getting!"",
+        ""Alice : If it had grown up, it would have made a dreadfully ugly child; but it makes rather a handsome pig, I think"",
+        ""The Cat : We're all mad here."", ""The Hatter : Why is a raven like a writing desk?"",
+        ""The Hatter : Twinkle, twinkle, little bat! How I wonder what you're at."", ""The Queen : Off with her head!"",
+        ""The Duchess : Tut, tut, child! Everything's got a moral, if only you can find it."",
+        ""The Duchess : Take care of the sense, and the sounds will take care of themselves."",
+        ""The King : Begin at the beginning and go on till you come to the end: then stop."" };
+
+    for (int i = 0; i < 10; i++) {
+      final Map<String, Integer> embeddedMap = new HashMap<String, Integer>();
+
+      embeddedMap.put(""key"" + (i * 10 + 1), i * 10 + 1);
+      embeddedMap.put(""key"" + (i * 10 + 2), i * 10 + 2);
+      embeddedMap.put(""key"" + (i * 10 + 3), i * 10 + 3);
+      embeddedMap.put(""key"" + (i * 10 + 4), i * 10 + 1);
+
+      final List<Integer> embeddedList = new ArrayList<Integer>(3);
+      embeddedList.add(i * 3);
+      embeddedList.add(i * 3 + 1);
+      embeddedList.add(i * 3 + 2);
+
+      final Set<Integer> embeddedSet = new HashSet<Integer>();
+      embeddedSet.add(i * 10);
+      embeddedSet.add(i * 10 + 1);
+      embeddedSet.add(i * 10 + 2);
+
+      for (int j = 0; j < 10; j++) {
+        final ODocument document = new ODocument(""sqlSelectIndexReuseTestClass"");
+        document.field(""prop1"", i);
+        document.field(""prop2"", j);
+        document.field(""prop3"", i * 10 + j);
+
+        document.field(""prop4"", i);
+        document.field(""prop5"", i);
+
+        document.field(""prop6"", j);
+
+        document.field(""prop7"", fullTextIndexStrings[i]);
+
+        document.field(""prop8"", j);
+
+        document.field(""prop9"", j % 2);
+
+        document.field(""fEmbeddedMap"", embeddedMap);
+        document.field(""fEmbeddedMapTwo"", embeddedMap);
+
+        document.field(""fEmbeddedList"", embeddedList);
+        document.field(""fEmbeddedListTwo"", embeddedList);
+
+        document.field(""fEmbeddedSet"", embeddedSet);
+        document.field(""fEmbeddedSetTwo"", embeddedSet);
+
+        document.save();
+      }
+    }
+    database.close();
+  }
+
+  @AfterClass
+  public void afterClass() throws Exception {
+    if (database.isClosed()) {
+      database.open(""admin"", ""admin"");
+    }
+
+    database.command(new OCommandSQL(""drop class sqlSelectIndexReuseTestClass"")).execute();
+    database.getMetadata().getSchema().reload();
+    database.getLevel2Cache().clear();
+
+    database.close();
+  }
+
+  @Test
+  public void testCompositeSearchEquals() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+    long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
+    long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
+
+    if (oldIndexUsage == -1) {
+      oldIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage == -1) {
+      oldCompositeIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage2 == -1) {
+      oldCompositeIndexUsage2 = 0;
+    }
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1 = 1 and prop2 = 2"")).execute();
+
+    Assert.assertEquals(result.size(), 1);
+
+    final ODocument document = result.get(0);
+    Assert.assertEquals(document.<Integer> field(""prop1"").intValue(), 1);
+    Assert.assertEquals(document.<Integer> field(""prop2"").intValue(), 2);
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
+  }
+
+  @Test
+  public void testCompositeSearchHasChainOperatorsEquals() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1.asInteger() = 1 and prop2 = 2""))
+        .execute();
+
+    Assert.assertEquals(result.size(), 1);
+
+    final ODocument document = result.get(0);
+    Assert.assertEquals(document.<Integer> field(""prop1"").intValue(), 1);
+    Assert.assertEquals(document.<Integer> field(""prop2"").intValue(), 2);
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage);
+  }
+
+  @Test
+  public void testCompositeSearchEqualsOneField() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+    long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
+    long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
+    long oldCompositeIndexUsage21 = profiler.getCounter(""Query.compositeIndexUsage.2.1"");
+
+    if (oldIndexUsage == -1) {
+      oldIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage == -1) {
+      oldCompositeIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage2 == -1)
+      oldCompositeIndexUsage2 = 0;
+
+    if (oldCompositeIndexUsage21 == -1)
+      oldCompositeIndexUsage2 = 0;
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1 = 1"")).execute();
+
+    Assert.assertEquals(result.size(), 10);
+
+    for (int i = 0; i < 10; i++) {
+      final ODocument document = new ODocument();
+      document.field(""prop1"", 1);
+      document.field(""prop2"", i);
+
+      Assert.assertEquals(containsDocument(result, document), 1);
+    }
+
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2.1""), oldCompositeIndexUsage21 + 1);
+  }
+
+  @Test
+  public void testCompositeSearchEqualsOneFieldMapIndexByKey() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+    long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
+    long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
+    long oldCompositeIndexUsage21 = profiler.getCounter(""Query.compositeIndexUsage.2.1"");
+
+    if (oldIndexUsage == -1) {
+      oldIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage == -1) {
+      oldCompositeIndexUsage = 0;
+    }
+
+    if (oldCompositeIndexUsage2 == -1)
+      oldCompositeIndexUsage2 = 0;
+
+    if (oldCompositeIndexUsage21 == -1)
+      oldCompositeIndexUsage21 = 0;
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where fEmbeddedMapTwo containsKey 'key11'""))
+        .execute();
+
+    Assert.assertEquals(result.size(), 10);
+
+    final Map<String, Integer> embeddedMap = new HashMap<String, Integer>();
+
+    embeddedMap.put(""key11"", 11);
+    embeddedMap.put(""key12"", 12);
+    embeddedMap.put(""key13"", 13);
+    embeddedMap.put(""key14"", 11);
+
+    for (int i = 0; i < 10; i++) {
+      final ODocument document = new ODocument();
+      document.field(""prop8"", 1);
+      document.field(""fEmbeddedMapTwo"", embeddedMap);
+
+      Assert.assertEquals(containsDocument(result, document), 1);
+    }
+
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2.1""), oldCompositeIndexUsage21 + 1);
+  }
+
+  @Test
+  public void testCompositeSearchEqualsMapIndexByKey() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+    long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
+    long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
+    long oldCompositeIndexUsage22 = profiler.getCounter(""Query.compositeIndexUsage.2.2"");
+
+    if (oldIndexUsage == -1) {
+      oldIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage == -1) {
+      oldCompositeIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage2 == -1) {
+      oldCompositeIndexUsage2 = 0;
+    }
+
+    if (oldCompositeIndexUsage22 == -1)
+      oldCompositeIndexUsage22 = 0;
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass ""
+            + ""where prop8 = 1 and fEmbeddedMapTwo containsKey 'key11'"")).execute();
+
+    final Map<String, Integer> embeddedMap = new HashMap<String, Integer>();
+
+    embeddedMap.put(""key11"", 11);
+    embeddedMap.put(""key12"", 12);
+    embeddedMap.put(""key13"", 13);
+    embeddedMap.put(""key14"", 11);
+
+    Assert.assertEquals(result.size(), 1);
+
+    final ODocument document = new ODocument();
+    document.field(""prop8"", 1);
+    document.field(""fEmbeddedMap"", embeddedMap);
+
+    Assert.assertEquals(containsDocument(result, document), 1);
+
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2.2""), oldCompositeIndexUsage22 + 1);
+  }
+
+  @Test
+  public void testCompositeSearchEqualsOneFieldMapIndexByValue() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+    long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
+    long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
+    long oldCompositeIndexUsage21 = profiler.getCounter(""Query.compositeIndexUsage.2.1"");
+
+    if (oldIndexUsage == -1) {
+      oldIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage == -1) {
+      oldCompositeIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage2 == -1) {
+      oldCompositeIndexUsage2 = 0;
+    }
+    if (oldCompositeIndexUsage21 == -1) {
+      oldCompositeIndexUsage21 = 0;
+    }
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass "" + ""where fEmbeddedMapTwo containsValue 22""))
+        .execute();
+
+    final Map<String, Integer> embeddedMap = new HashMap<String, Integer>();
+
+    embeddedMap.put(""key21"", 21);
+    embeddedMap.put(""key22"", 22);
+    embeddedMap.put(""key23"", 23);
+    embeddedMap.put(""key24"", 21);
+
+    Assert.assertEquals(result.size(), 10);
+
+    for (int i = 0; i < 10; i++) {
+      final ODocument document = new ODocument();
+      document.field(""prop8"", i);
+      document.field(""fEmbeddedMapTwo"", embeddedMap);
+
+      Assert.assertEquals(containsDocument(result, document), 1);
+    }
+
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2.1""), oldCompositeIndexUsage21 + 1);
+  }
+
+  @Test
+  public void testCompositeSearchEqualsMapIndexByValue() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+    long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
+    long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
+    long oldCompositeIndexUsage22 = profiler.getCounter(""Query.compositeIndexUsage.2.2"");
+
+    if (oldIndexUsage == -1) {
+      oldIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage == -1) {
+      oldCompositeIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage2 == -1) {
+      oldCompositeIndexUsage2 = 0;
+    }
+    if (oldCompositeIndexUsage22 == -1)
+      oldCompositeIndexUsage22 = 0;
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass ""
+            + ""where prop8 = 1 and fEmbeddedMapTwo containsValue 22"")).execute();
+
+    final Map<String, Integer> embeddedMap = new HashMap<String, Integer>();
+
+    embeddedMap.put(""key21"", 21);
+    embeddedMap.put(""key22"", 22);
+    embeddedMap.put(""key23"", 23);
+    embeddedMap.put(""key24"", 21);
+
+    Assert.assertEquals(result.size(), 1);
+
+    final ODocument document = new ODocument();
+    document.field(""prop8"", 1);
+    document.field(""fEmbeddedMap"", embeddedMap);
+
+    Assert.assertEquals(containsDocument(result, document), 1);
+
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2.2""), oldCompositeIndexUsage22 + 1);
+  }
+
+  @Test
+  public void testCompositeSearchEqualsEmbeddedSetIndex() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+    long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
+    long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
+    long oldCompositeIndexUsage22 = profiler.getCounter(""Query.compositeIndexUsage.2.2"");
+
+    if (oldIndexUsage == -1) {
+      oldIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage == -1) {
+      oldCompositeIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage2 == -1) {
+      oldCompositeIndexUsage2 = 0;
+    }
+
+    if (oldCompositeIndexUsage22 == -1)
+      oldCompositeIndexUsage22 = 0;
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass ""
+            + ""where prop8 = 1 and fEmbeddedSetTwo contains 12"")).execute();
+
+    final Set<Integer> embeddedSet = new HashSet<Integer>();
+    embeddedSet.add(10);
+    embeddedSet.add(11);
+    embeddedSet.add(12);
+
+    Assert.assertEquals(result.size(), 1);
+
+    final ODocument document = new ODocument();
+    document.field(""prop8"", 1);
+    document.field(""fEmbeddedSet"", embeddedSet);
+
+    Assert.assertEquals(containsDocument(result, document), 1);
+
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2.2""), oldCompositeIndexUsage22 + 1);
+  }
+
+  @Test
+  public void testCompositeSearchEqualsEmbeddedSetInMiddleIndex() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+    long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
+    long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
+    long oldCompositeIndexUsage3 = profiler.getCounter(""Query.compositeIndexUsage.3"");
+    long oldCompositeIndexUsage33 = profiler.getCounter(""Query.compositeIndexUsage.3.3"");
+
+    if (oldIndexUsage == -1) {
+      oldIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage == -1) {
+      oldCompositeIndexUsage = 0;
+    }
+
+    if (oldCompositeIndexUsage2 == -1) {
+      oldCompositeIndexUsage2 = 0;
+    }
+
+    if (oldCompositeIndexUsage3 == -1)
+      oldCompositeIndexUsage3 = 0;
+
+    if (oldCompositeIndexUsage33 == -1)
+      oldCompositeIndexUsage33 = 0;
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass ""
+            + ""where prop9 = 0 and fEmbeddedSetTwo contains 92 and prop8 > 2"")).execute();
+
+    final Set<Integer> embeddedSet = new HashSet<Integer>(3);
+    embeddedSet.add(90);
+    embeddedSet.add(91);
+    embeddedSet.add(92);
+
+    Assert.assertEquals(result.size(), 3);
+
+    for (int i = 0; i < 3; i++) {
+      final ODocument document = new ODocument();
+      document.field(""prop8"", i * 2 + 4);
+      document.field(""prop9"", 0);
+      document.field(""fEmbeddedSet"", embeddedSet);
+
+      Assert.assertEquals(containsDocument(result, document), 1);
+    }
+
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.3""), oldCompositeIndexUsage3 + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.3.3""), oldCompositeIndexUsage33 + 1);
+  }
+
+  @Test
+  public void testCompositeSearchEqualsOneFieldEmbeddedListIndex() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+    long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
+    long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
+    long oldCompositeIndexUsage21 = profiler.getCounter(""Query.compositeIndexUsage.2.1"");
+
+    if (oldIndexUsage == -1) {
+      oldIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage == -1) {
+      oldCompositeIndexUsage = 0;
+    }
+
+    if (oldCompositeIndexUsage2 == -1)
+      oldCompositeIndexUsage2 = 0;
+
+    if (oldCompositeIndexUsage21 == -1)
+      oldCompositeIndexUsage21 = 0;
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where fEmbeddedListTwo contains 4"")).execute();
+
+    Assert.assertEquals(result.size(), 10);
+
+    final List<Integer> embeddedList = new ArrayList<Integer>(3);
+    embeddedList.add(3);
+    embeddedList.add(4);
+    embeddedList.add(5);
+
+    for (int i = 0; i < 10; i++) {
+      final ODocument document = new ODocument();
+      document.field(""prop8"", i);
+      document.field(""fEmbeddedListTwo"", embeddedList);
+
+      Assert.assertEquals(containsDocument(result, document), 1);
+    }
+
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2.1""), oldCompositeIndexUsage21 + 1);
+  }
+
+  @Test
+  public void testCompositeSearchEqualsEmbeddedListIndex() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+    long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
+    long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
+    long oldCompositeIndexUsage22 = profiler.getCounter(""Query.compositeIndexUsage.2.2"");
+
+    if (oldIndexUsage == -1) {
+      oldIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage == -1) {
+      oldCompositeIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage2 == -1) {
+      oldCompositeIndexUsage2 = 0;
+    }
+    if (oldCompositeIndexUsage22 == -1)
+      oldCompositeIndexUsage22 = 0;
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where""
+            + "" prop8 = 1 and fEmbeddedListTwo contains 4"")).execute();
+
+    Assert.assertEquals(result.size(), 1);
+
+    final List<Integer> embeddedList = new ArrayList<Integer>(3);
+    embeddedList.add(3);
+    embeddedList.add(4);
+    embeddedList.add(5);
+
+    final ODocument document = new ODocument();
+    document.field(""prop8"", 1);
+    document.field(""fEmbeddedListTwo"", embeddedList);
+
+    Assert.assertEquals(containsDocument(result, document), 1);
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2.2""), oldCompositeIndexUsage22 + 1);
+  }
+
+  @Test
+  public void testNoCompositeSearchEquals() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop2 = 1"")).execute();
+
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage);
+    Assert.assertEquals(result.size(), 10);
+
+    for (int i = 0; i < 10; i++) {
+      final ODocument document = new ODocument();
+      document.field(""prop1"", i);
+      document.field(""prop2"", 1);
+
+      Assert.assertEquals(containsDocument(result, document), 1);
+    }
+  }
+
+  @Test
+  public void testCompositeSearchEqualsWithArgs() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+    long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
+    long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
+
+    if (oldIndexUsage == -1) {
+      oldIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage == -1) {
+      oldCompositeIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage2 == -1) {
+      oldCompositeIndexUsage2 = 0;
+    }
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1 = ? and prop2 = ?"")).execute(1, 2);
+
+    Assert.assertEquals(result.size(), 1);
+
+    final ODocument document = result.get(0);
+    Assert.assertEquals(document.<Integer> field(""prop1"").intValue(), 1);
+    Assert.assertEquals(document.<Integer> field(""prop2"").intValue(), 2);
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
+  }
+
+  @Test
+  public void testCompositeSearchEqualsOneFieldWithArgs() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+    long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
+    long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
+
+    if (oldIndexUsage == -1) {
+      oldIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage == -1) {
+      oldCompositeIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage2 == -1) {
+      oldCompositeIndexUsage2 = 0;
+    }
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1 = ?"")).execute(1);
+
+    Assert.assertEquals(result.size(), 10);
+
+    for (int i = 0; i < 10; i++) {
+      final ODocument document = new ODocument();
+      document.field(""prop1"", 1);
+      document.field(""prop2"", i);
+
+      Assert.assertEquals(containsDocument(result, document), 1);
+    }
+
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
+  }
+
+  @Test
+  public void testNoCompositeSearchEqualsWithArgs() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop2 = ?"")).execute(1);
+
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage);
+    Assert.assertEquals(result.size(), 10);
+
+    for (int i = 0; i < 10; i++) {
+      final ODocument document = new ODocument();
+      document.field(""prop1"", i);
+      document.field(""prop2"", 1);
+
+      Assert.assertEquals(containsDocument(result, document), 1);
+    }
+  }
+
+  @Test
+  public void testCompositeSearchGT() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+    long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
+    long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
+
+    if (oldIndexUsage == -1) {
+      oldIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage == -1) {
+      oldCompositeIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage2 == -1) {
+      oldCompositeIndexUsage2 = 0;
+    }
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1 = 1 and prop2 > 2"")).execute();
+
+    Assert.assertEquals(result.size(), 7);
+
+    for (int i = 3; i < 10; i++) {
+      final ODocument document = new ODocument();
+      document.field(""prop1"", 1);
+      document.field(""prop2"", i);
+
+      Assert.assertEquals(containsDocument(result, document), 1);
+    }
+
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
+  }
+
+  @Test
+  public void testCompositeSearchGTOneField() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+    long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
+    long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
+
+    if (oldIndexUsage == -1) {
+      oldIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage == -1) {
+      oldCompositeIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage2 == -1) {
+      oldCompositeIndexUsage2 = 0;
+    }
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1 > 7"")).execute();
+
+    Assert.assertEquals(result.size(), 20);
+
+    for (int i = 8; i < 10; i++) {
+      for (int j = 0; j < 10; j++) {
+        final ODocument document = new ODocument();
+        document.field(""prop1"", i);
+        document.field(""prop2"", j);
+
+        Assert.assertEquals(containsDocument(result, document), 1);
+      }
+    }
+
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
+  }
+
+  @Test
+  public void testCompositeSearchGTOneFieldNoSearch() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop2 > 7"")).execute();
+
+    Assert.assertEquals(result.size(), 20);
+
+    for (int i = 8; i < 10; i++) {
+      for (int j = 0; j < 10; j++) {
+        final ODocument document = new ODocument();
+        document.field(""prop1"", j);
+        document.field(""prop2"", i);
+
+        Assert.assertEquals(containsDocument(result, document), 1);
+      }
+    }
+
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage);
+  }
+
+  @Test
+  public void testCompositeSearchGTWithArgs() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+    long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
+    long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
+
+    if (oldIndexUsage == -1) {
+      oldIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage == -1) {
+      oldCompositeIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage2 == -1) {
+      oldCompositeIndexUsage2 = 0;
+    }
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1 = ? and prop2 > ?"")).execute(1, 2);
+
+    Assert.assertEquals(result.size(), 7);
+
+    for (int i = 3; i < 10; i++) {
+      final ODocument document = new ODocument();
+      document.field(""prop1"", 1);
+      document.field(""prop2"", i);
+
+      Assert.assertEquals(containsDocument(result, document), 1);
+    }
+
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
+  }
+
+  @Test
+  public void testCompositeSearchGTOneFieldWithArgs() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+    long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
+    long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
+
+    if (oldIndexUsage == -1) {
+      oldIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage == -1) {
+      oldCompositeIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage2 == -1) {
+      oldCompositeIndexUsage2 = 0;
+    }
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1 > ?"")).execute(7);
+
+    Assert.assertEquals(result.size(), 20);
+
+    for (int i = 8; i < 10; i++) {
+      for (int j = 0; j < 10; j++) {
+        final ODocument document = new ODocument();
+        document.field(""prop1"", i);
+        document.field(""prop2"", j);
+
+        Assert.assertEquals(containsDocument(result, document), 1);
+      }
+    }
+
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
+  }
+
+  @Test
+  public void testCompositeSearchGTOneFieldNoSearchWithArgs() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop2 > ?"")).execute(7);
+
+    Assert.assertEquals(result.size(), 20);
+
+    for (int i = 8; i < 10; i++) {
+      for (int j = 0; j < 10; j++) {
+        final ODocument document = new ODocument();
+        document.field(""prop1"", j);
+        document.field(""prop2"", i);
+
+        Assert.assertEquals(containsDocument(result, document), 1);
+      }
+    }
+
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage);
+  }
+
+  @Test
+  public void testCompositeSearchGTQ() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+    long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
+    long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
+
+    if (oldIndexUsage == -1) {
+      oldIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage == -1) {
+      oldCompositeIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage2 == -1) {
+      oldCompositeIndexUsage2 = 0;
+    }
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1 = 1 and prop2 >= 2"")).execute();
+
+    Assert.assertEquals(result.size(), 8);
+
+    for (int i = 2; i < 10; i++) {
+      final ODocument document = new ODocument();
+      document.field(""prop1"", 1);
+      document.field(""prop2"", i);
+
+      Assert.assertEquals(containsDocument(result, document), 1);
+    }
+
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
+  }
+
+  @Test
+  public void testCompositeSearchGTQOneField() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+    long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
+    long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
+
+    if (oldIndexUsage == -1) {
+      oldIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage == -1) {
+      oldCompositeIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage2 == -1) {
+      oldCompositeIndexUsage2 = 0;
+    }
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1 >= 7"")).execute();
+
+    Assert.assertEquals(result.size(), 30);
+
+    for (int i = 7; i < 10; i++) {
+      for (int j = 0; j < 10; j++) {
+        final ODocument document = new ODocument();
+        document.field(""prop1"", i);
+        document.field(""prop2"", j);
+
+        Assert.assertEquals(containsDocument(result, document), 1);
+      }
+    }
+
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
+  }
+
+  @Test
+  public void testCompositeSearchGTQOneFieldNoSearch() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop2 >= 7"")).execute();
+
+    Assert.assertEquals(result.size(), 30);
+
+    for (int i = 7; i < 10; i++) {
+      for (int j = 0; j < 10; j++) {
+        final ODocument document = new ODocument();
+        document.field(""prop1"", j);
+        document.field(""prop2"", i);
+
+        Assert.assertEquals(containsDocument(result, document), 1);
+      }
+    }
+
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage);
+  }
+
+  @Test
+  public void testCompositeSearchGTQWithArgs() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+    long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
+    long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
+
+    if (oldIndexUsage == -1) {
+      oldIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage == -1) {
+      oldCompositeIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage2 == -1) {
+      oldCompositeIndexUsage2 = 0;
+    }
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1 = ? and prop2 >= ?"")).execute(1, 2);
+
+    Assert.assertEquals(result.size(), 8);
+
+    for (int i = 2; i < 10; i++) {
+      final ODocument document = new ODocument();
+      document.field(""prop1"", 1);
+      document.field(""prop2"", i);
+
+      Assert.assertEquals(containsDocument(result, document), 1);
+    }
+
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
+  }
+
+  @Test
+  public void testCompositeSearchGTQOneFieldWithArgs() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+    long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
+    long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
+
+    if (oldIndexUsage == -1) {
+      oldIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage == -1) {
+      oldCompositeIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage2 == -1) {
+      oldCompositeIndexUsage2 = 0;
+    }
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1 >= ?"")).execute(7);
+
+    Assert.assertEquals(result.size(), 30);
+
+    for (int i = 7; i < 10; i++) {
+      for (int j = 0; j < 10; j++) {
+        final ODocument document = new ODocument();
+        document.field(""prop1"", i);
+        document.field(""prop2"", j);
+
+        Assert.assertEquals(containsDocument(result, document), 1);
+      }
+    }
+
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
+  }
+
+  @Test
+  public void testCompositeSearchGTQOneFieldNoSearchWithArgs() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop2 >= ?"")).execute(7);
+
+    Assert.assertEquals(result.size(), 30);
+
+    for (int i = 7; i < 10; i++) {
+      for (int j = 0; j < 10; j++) {
+        final ODocument document = new ODocument();
+        document.field(""prop1"", j);
+        document.field(""prop2"", i);
+
+        Assert.assertEquals(containsDocument(result, document), 1);
+      }
+    }
+
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage);
+  }
+
+  @Test
+  public void testCompositeSearchLTQ() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+    long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
+    long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
+
+    if (oldIndexUsage == -1) {
+      oldIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage == -1) {
+      oldCompositeIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage2 == -1) {
+      oldCompositeIndexUsage2 = 0;
+    }
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1 = 1 and prop2 <= 2"")).execute();
+
+    Assert.assertEquals(result.size(), 3);
+
+    for (int i = 0; i <= 2; i++) {
+      final ODocument document = new ODocument();
+      document.field(""prop1"", 1);
+      document.field(""prop2"", i);
+
+      Assert.assertEquals(containsDocument(result, document), 1);
+    }
+
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
+
+  }
+
+  @Test
+  public void testCompositeSearchLTQOneField() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+    long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
+    long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
+
+    if (oldIndexUsage == -1) {
+      oldIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage == -1) {
+      oldCompositeIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage2 == -1) {
+      oldCompositeIndexUsage2 = 0;
+    }
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1 <= 7"")).execute();
+
+    Assert.assertEquals(result.size(), 80);
+
+    for (int i = 0; i <= 7; i++) {
+      for (int j = 0; j < 10; j++) {
+        final ODocument document = new ODocument();
+        document.field(""prop1"", i);
+        document.field(""prop2"", j);
+
+        Assert.assertEquals(containsDocument(result, document), 1);
+      }
+    }
+
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
+  }
+
+  @Test
+  public void testCompositeSearchLTQOneFieldNoSearch() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop2 <= 7"")).execute();
+
+    Assert.assertEquals(result.size(), 80);
+
+    for (int i = 0; i <= 7; i++) {
+      for (int j = 0; j < 10; j++) {
+        final ODocument document = new ODocument();
+        document.field(""prop1"", j);
+        document.field(""prop2"", i);
+
+        Assert.assertEquals(containsDocument(result, document), 1);
+      }
+    }
+
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage);
+  }
+
+  @Test
+  public void testCompositeSearchLTQWithArgs() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+    long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
+    long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
+
+    if (oldIndexUsage == -1) {
+      oldIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage == -1) {
+      oldCompositeIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage2 == -1) {
+      oldCompositeIndexUsage2 = 0;
+    }
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1 = ? and prop2 <= ?"")).execute(1, 2);
+
+    Assert.assertEquals(result.size(), 3);
+
+    for (int i = 0; i <= 2; i++) {
+      final ODocument document = new ODocument();
+      document.field(""prop1"", 1);
+      document.field(""prop2"", i);
+
+      Assert.assertEquals(containsDocument(result, document), 1);
+    }
+
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
+  }
+
+  @Test
+  public void testCompositeSearchLTQOneFieldWithArgs() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+    long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
+    long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
+
+    if (oldIndexUsage == -1) {
+      oldIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage == -1) {
+      oldCompositeIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage2 == -1) {
+      oldCompositeIndexUsage2 = 0;
+    }
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1 <= ?"")).execute(7);
+
+    Assert.assertEquals(result.size(), 80);
+
+    for (int i = 0; i <= 7; i++) {
+      for (int j = 0; j < 10; j++) {
+        final ODocument document = new ODocument();
+        document.field(""prop1"", i);
+        document.field(""prop2"", j);
+
+        Assert.assertEquals(containsDocument(result, document), 1);
+      }
+    }
+
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
+  }
+
+  @Test
+  public void testCompositeSearchLTQOneFieldNoSearchWithArgs() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop2 <= ?"")).execute(7);
+
+    Assert.assertEquals(result.size(), 80);
+
+    for (int i = 0; i <= 7; i++) {
+      for (int j = 0; j < 10; j++) {
+        final ODocument document = new ODocument();
+        document.field(""prop1"", j);
+        document.field(""prop2"", i);
+
+        Assert.assertEquals(containsDocument(result, document), 1);
+      }
+    }
+
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage);
+  }
+
+  @Test
+  public void testCompositeSearchLT() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+    long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
+    long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
+
+    if (oldIndexUsage == -1) {
+      oldIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage == -1) {
+      oldCompositeIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage2 == -1) {
+      oldCompositeIndexUsage2 = 0;
+    }
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1 = 1 and prop2 < 2"")).execute();
+
+    Assert.assertEquals(result.size(), 2);
+
+    for (int i = 0; i < 2; i++) {
+      final ODocument document = new ODocument();
+      document.field(""prop1"", 1);
+      document.field(""prop2"", i);
+
+      Assert.assertEquals(containsDocument(result, document), 1);
+    }
+
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
+  }
+
+  @Test
+  public void testCompositeSearchLTOneField() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+    long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
+    long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
+
+    if (oldIndexUsage == -1) {
+      oldIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage == -1) {
+      oldCompositeIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage2 == -1) {
+      oldCompositeIndexUsage2 = 0;
+    }
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1 < 7"")).execute();
+
+    Assert.assertEquals(result.size(), 70);
+
+    for (int i = 0; i < 7; i++) {
+      for (int j = 0; j < 10; j++) {
+        final ODocument document = new ODocument();
+        document.field(""prop1"", i);
+        document.field(""prop2"", j);
+
+        Assert.assertEquals(containsDocument(result, document), 1);
+      }
+    }
+
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
+  }
+
+  @Test
+  public void testCompositeSearchLTOneFieldNoSearch() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop2 < 7"")).execute();
+
+    Assert.assertEquals(result.size(), 70);
+
+    for (int i = 0; i < 7; i++) {
+      for (int j = 0; j < 10; j++) {
+        final ODocument document = new ODocument();
+        document.field(""prop1"", j);
+        document.field(""prop2"", i);
+
+        Assert.assertEquals(containsDocument(result, document), 1);
+      }
+    }
+
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage);
+  }
+
+  @Test
+  public void testCompositeSearchLTWithArgs() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+    long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
+    long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
+
+    if (oldIndexUsage == -1) {
+      oldIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage == -1) {
+      oldCompositeIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage2 == -1) {
+      oldCompositeIndexUsage2 = 0;
+    }
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1 = ? and prop2 < ?"")).execute(1, 2);
+
+    Assert.assertEquals(result.size(), 2);
+
+    for (int i = 0; i < 2; i++) {
+      final ODocument document = new ODocument();
+      document.field(""prop1"", 1);
+      document.field(""prop2"", i);
+
+      Assert.assertEquals(containsDocument(result, document), 1);
+    }
+
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
+  }
+
+  @Test
+  public void testCompositeSearchLTOneFieldWithArgs() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+    long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
+    long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
+
+    if (oldIndexUsage == -1) {
+      oldIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage == -1) {
+      oldCompositeIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage2 == -1) {
+      oldCompositeIndexUsage2 = 0;
+    }
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1 < ?"")).execute(7);
+
+    Assert.assertEquals(result.size(), 70);
+
+    for (int i = 0; i < 7; i++) {
+      for (int j = 0; j < 10; j++) {
+        final ODocument document = new ODocument();
+        document.field(""prop1"", i);
+        document.field(""prop2"", j);
+
+        Assert.assertEquals(containsDocument(result, document), 1);
+      }
+    }
+
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
+  }
+
+  @Test
+  public void testCompositeSearchLTOneFieldNoSearchWithArgs() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop2 < ?"")).execute(7);
+
+    Assert.assertEquals(result.size(), 70);
+
+    for (int i = 0; i < 7; i++) {
+      for (int j = 0; j < 10; j++) {
+        final ODocument document = new ODocument();
+        document.field(""prop1"", j);
+        document.field(""prop2"", i);
+
+        Assert.assertEquals(containsDocument(result, document), 1);
+      }
+    }
+
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage);
+  }
+
+  @Test
+  public void testCompositeSearchBetween() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+    long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
+    long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
+
+    if (oldIndexUsage == -1) {
+      oldIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage == -1) {
+      oldCompositeIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage2 == -1) {
+      oldCompositeIndexUsage2 = 0;
+    }
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1 = 1 and prop2 between 1 and 3""))
+        .execute();
+
+    Assert.assertEquals(result.size(), 3);
+
+    for (int i = 1; i <= 3; i++) {
+      final ODocument document = new ODocument();
+      document.field(""prop1"", 1);
+      document.field(""prop2"", i);
+
+      Assert.assertEquals(containsDocument(result, document), 1);
+    }
+
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
+  }
+
+  @Test
+  public void testCompositeSearchBetweenOneField() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+    long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
+    long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
+
+    if (oldIndexUsage == -1) {
+      oldIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage == -1) {
+      oldCompositeIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage2 == -1) {
+      oldCompositeIndexUsage2 = 0;
+    }
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1 between 1 and 3"")).execute();
+
+    Assert.assertEquals(result.size(), 30);
+
+    for (int i = 1; i <= 3; i++) {
+      for (int j = 0; j < 10; j++) {
+        final ODocument document = new ODocument();
+        document.field(""prop1"", i);
+        document.field(""prop2"", j);
+
+        Assert.assertEquals(containsDocument(result, document), 1);
+      }
+    }
+
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
+  }
+
+  @Test
+  public void testCompositeSearchBetweenOneFieldNoSearch() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop2 between 1 and 3"")).execute();
+
+    Assert.assertEquals(result.size(), 30);
+
+    for (int i = 1; i <= 3; i++) {
+      for (int j = 0; j < 10; j++) {
+        final ODocument document = new ODocument();
+        document.field(""prop1"", j);
+        document.field(""prop2"", i);
+
+        Assert.assertEquals(containsDocument(result, document), 1);
+      }
+    }
+
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage);
+  }
+
+  @Test
+  public void testCompositeSearchBetweenWithArgs() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+    long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
+    long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
+
+    if (oldIndexUsage == -1) {
+      oldIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage == -1) {
+      oldCompositeIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage2 == -1) {
+      oldCompositeIndexUsage2 = 0;
+    }
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1 = 1 and prop2 between ? and ?""))
+        .execute(1, 3);
+
+    Assert.assertEquals(result.size(), 3);
+
+    for (int i = 1; i <= 3; i++) {
+      final ODocument document = new ODocument();
+      document.field(""prop1"", 1);
+      document.field(""prop2"", i);
+
+      Assert.assertEquals(containsDocument(result, document), 1);
+    }
+
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
+  }
+
+  @Test
+  public void testCompositeSearchBetweenOneFieldWithArgs() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+    long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
+    long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
+
+    if (oldIndexUsage == -1) {
+      oldIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage == -1) {
+      oldCompositeIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage2 == -1) {
+      oldCompositeIndexUsage2 = 0;
+    }
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1 between ? and ?"")).execute(1, 3);
+
+    Assert.assertEquals(result.size(), 30);
+
+    for (int i = 1; i <= 3; i++) {
+      for (int j = 0; j < 10; j++) {
+        final ODocument document = new ODocument();
+        document.field(""prop1"", i);
+        document.field(""prop2"", j);
+
+        Assert.assertEquals(containsDocument(result, document), 1);
+      }
+    }
+
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
+  }
+
+  @Test
+  public void testCompositeSearchBetweenOneFieldNoSearchWithArgs() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop2 between ? and ?"")).execute(1, 3);
+
+    Assert.assertEquals(result.size(), 30);
+
+    for (int i = 1; i <= 3; i++) {
+      for (int j = 0; j < 10; j++) {
+        final ODocument document = new ODocument();
+        document.field(""prop1"", j);
+        document.field(""prop2"", i);
+
+        Assert.assertEquals(containsDocument(result, document), 1);
+      }
+    }
+
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage);
+  }
+
+  @Test
+  public void testSingleSearchEquals() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+    long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
+
+    if (oldIndexUsage == -1) {
+      oldIndexUsage = 0;
+    }
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop3 = 1"")).execute();
+
+    Assert.assertEquals(result.size(), 1);
+
+    final ODocument document = result.get(0);
+    Assert.assertEquals(document.<Integer> field(""prop3"").intValue(), 1);
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage);
+  }
+
+  @Test
+  public void testSingleSearchEqualsWithArgs() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+    long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
+
+    if (oldIndexUsage == -1) {
+      oldIndexUsage = 0;
+    }
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop3 = ?"")).execute(1);
+
+    Assert.assertEquals(result.size(), 1);
+
+    final ODocument document = result.get(0);
+    Assert.assertEquals(document.<Integer> field(""prop3"").intValue(), 1);
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage);
+  }
+
+  @Test
+  public void testSingleSearchGT() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+    long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
+
+    if (oldIndexUsage == -1) {
+      oldIndexUsage = 0;
+    }
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop3 > 90"")).execute();
 
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage);
-	}
-
-	@Test
-	public void testSingleSearchGTQ() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-		long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
+    Assert.assertEquals(result.size(), 9);
 
-		if (oldIndexUsage == -1) {
-			oldIndexUsage = 0;
-		}
+    for (int i = 91; i < 100; i++) {
+      final ODocument document = new ODocument();
+      document.field(""prop3"", i);
+      Assert.assertEquals(containsDocument(result, document), 1);
+    }
 
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop3 >= 90"")).execute();
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage);
+  }
+
+  @Test
+  public void testSingleSearchGTWithArgs() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+    long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
 
-		Assert.assertEquals(result.size(), 10);
+    if (oldIndexUsage == -1) {
+      oldIndexUsage = 0;
+    }
 
-		for (int i = 90; i < 100; i++) {
-			final ODocument document = new ODocument();
-			document.field(""prop3"", i);
-			Assert.assertEquals(containsDocument(result, document), 1);
-		}
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop3 > ?"")).execute(90);
 
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage);
-	}
+    Assert.assertEquals(result.size(), 9);
 
-	@Test
-	public void testSingleSearchGTQWithArgs() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-		long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
+    for (int i = 91; i < 100; i++) {
+      final ODocument document = new ODocument();
+      document.field(""prop3"", i);
+      Assert.assertEquals(containsDocument(result, document), 1);
+    }
 
-		if (oldIndexUsage == -1) {
-			oldIndexUsage = 0;
-		}
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage);
+  }
+
+  @Test
+  public void testSingleSearchGTQ() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+    long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
 
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop3 >= ?"")).execute(90);
+    if (oldIndexUsage == -1) {
+      oldIndexUsage = 0;
+    }
 
-		Assert.assertEquals(result.size(), 10);
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop3 >= 90"")).execute();
 
-		for (int i = 90; i < 100; i++) {
-			final ODocument document = new ODocument();
-			document.field(""prop3"", i);
-			Assert.assertEquals(containsDocument(result, document), 1);
-		}
+    Assert.assertEquals(result.size(), 10);
 
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage);
-	}
-
-	@Test
-	public void testSingleSearchLTQ() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-		long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
+    for (int i = 90; i < 100; i++) {
+      final ODocument document = new ODocument();
+      document.field(""prop3"", i);
+      Assert.assertEquals(containsDocument(result, document), 1);
+    }
 
-		if (oldIndexUsage == -1) {
-			oldIndexUsage = 0;
-		}
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage);
+  }
 
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop3 <= 10"")).execute();
+  @Test
+  public void testSingleSearchGTQWithArgs() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+    long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
 
-		Assert.assertEquals(result.size(), 11);
+    if (oldIndexUsage == -1) {
+      oldIndexUsage = 0;
+    }
 
-		for (int i = 0; i <= 10; i++) {
-			final ODocument document = new ODocument();
-			document.field(""prop3"", i);
-			Assert.assertEquals(containsDocument(result, document), 1);
-		}
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop3 >= ?"")).execute(90);
 
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage);
-	}
+    Assert.assertEquals(result.size(), 10);
 
-	@Test
-	public void testSingleSearchLTQWithArgs() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-		long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
+    for (int i = 90; i < 100; i++) {
+      final ODocument document = new ODocument();
+      document.field(""prop3"", i);
+      Assert.assertEquals(containsDocument(result, document), 1);
+    }
 
-		if (oldIndexUsage == -1) {
-			oldIndexUsage = 0;
-		}
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage);
+  }
+
+  @Test
+  public void testSingleSearchLTQ() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+    long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
 
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop3 <= ?"")).execute(10);
+    if (oldIndexUsage == -1) {
+      oldIndexUsage = 0;
+    }
 
-		Assert.assertEquals(result.size(), 11);
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop3 <= 10"")).execute();
 
-		for (int i = 0; i <= 10; i++) {
-			final ODocument document = new ODocument();
-			document.field(""prop3"", i);
-			Assert.assertEquals(containsDocument(result, document), 1);
-		}
+    Assert.assertEquals(result.size(), 11);
 
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage);
-	}
+    for (int i = 0; i <= 10; i++) {
+      final ODocument document = new ODocument();
+      document.field(""prop3"", i);
+      Assert.assertEquals(containsDocument(result, document), 1);
+    }
 
-	@Test
-	public void testSingleSearchLT() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-		long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage);
+  }
 
-		if (oldIndexUsage == -1) {
-			oldIndexUsage = 0;
-		}
+  @Test
+  public void testSingleSearchLTQWithArgs() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+    long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
 
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop3 < 10"")).execute();
+    if (oldIndexUsage == -1) {
+      oldIndexUsage = 0;
+    }
 
-		Assert.assertEquals(result.size(), 10);
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop3 <= ?"")).execute(10);
 
-		for (int i = 0; i < 10; i++) {
-			final ODocument document = new ODocument();
-			document.field(""prop3"", i);
-			Assert.assertEquals(containsDocument(result, document), 1);
-		}
+    Assert.assertEquals(result.size(), 11);
 
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage);
-	}
+    for (int i = 0; i <= 10; i++) {
+      final ODocument document = new ODocument();
+      document.field(""prop3"", i);
+      Assert.assertEquals(containsDocument(result, document), 1);
+    }
 
-	@Test
-	public void testSingleSearchLTWithArgs() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-		long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage);
+  }
 
-		if (oldIndexUsage == -1) {
-			oldIndexUsage = 0;
-		}
+  @Test
+  public void testSingleSearchLT() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+    long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
 
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop3 < ?"")).execute(10);
+    if (oldIndexUsage == -1) {
+      oldIndexUsage = 0;
+    }
 
-		Assert.assertEquals(result.size(), 10);
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop3 < 10"")).execute();
 
-		for (int i = 0; i < 10; i++) {
-			final ODocument document = new ODocument();
-			document.field(""prop3"", i);
-			Assert.assertEquals(containsDocument(result, document), 1);
-		}
+    Assert.assertEquals(result.size(), 10);
 
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage);
-	}
+    for (int i = 0; i < 10; i++) {
+      final ODocument document = new ODocument();
+      document.field(""prop3"", i);
+      Assert.assertEquals(containsDocument(result, document), 1);
+    }
 
-	@Test
-	public void testSingleSearchBetween() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-		long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
-
-		if (oldIndexUsage == -1) {
-			oldIndexUsage = 0;
-		}
-
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop3 between 1 and 10"")).execute();
-
-		Assert.assertEquals(result.size(), 10);
-
-		for (int i = 1; i <= 10; i++) {
-			final ODocument document = new ODocument();
-			document.field(""prop3"", i);
-			Assert.assertEquals(containsDocument(result, document), 1);
-		}
-
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage);
-	}
-
-	@Test
-	public void testSingleSearchBetweenWithArgs() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-		long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
-
-		if (oldIndexUsage == -1) {
-			oldIndexUsage = 0;
-		}
-
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop3 between ? and ?"")).execute(1, 10);
-
-		Assert.assertEquals(result.size(), 10);
-
-		for (int i = 1; i <= 10; i++) {
-			final ODocument document = new ODocument();
-			document.field(""prop3"", i);
-			Assert.assertEquals(containsDocument(result, document), 1);
-		}
-
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage);
-	}
-
-	@Test
-	public void testSingleSearchIN() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-		long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
-
-		if (oldIndexUsage == -1) {
-			oldIndexUsage = 0;
-		}
-
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop3 in [0, 5, 10]"")).execute();
-
-		Assert.assertEquals(result.size(), 3);
-
-		for (int i = 0; i <= 10; i += 5) {
-			final ODocument document = new ODocument();
-			document.field(""prop3"", i);
-			Assert.assertEquals(containsDocument(result, document), 1);
-		}
-
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage);
-	}
-
-	@Test
-	public void testSingleSearchINWithArgs() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-		long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
-
-		if (oldIndexUsage == -1) {
-			oldIndexUsage = 0;
-		}
-
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop3 in [?, ?, ?]"")).execute(0, 5, 10);
-
-		Assert.assertEquals(result.size(), 3);
-
-		for (int i = 0; i <= 10; i += 5) {
-			final ODocument document = new ODocument();
-			document.field(""prop3"", i);
-			Assert.assertEquals(containsDocument(result, document), 1);
-		}
-
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage);
-	}
-
-	@Test
-	public void testMostSpecificOnesProcessedFirst() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-		long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
-		long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
-
-		if (oldIndexUsage == -1) {
-			oldIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage == -1) {
-			oldCompositeIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage2 == -1) {
-			oldCompositeIndexUsage2 = 0;
-		}
-
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1 = 1 and prop2 = 1 and prop3 = 11""))
-						.execute();
-
-		Assert.assertEquals(result.size(), 1);
-
-		final ODocument document = result.get(0);
-		Assert.assertEquals(document.<Integer>field(""prop1"").intValue(), 1);
-		Assert.assertEquals(document.<Integer>field(""prop2"").intValue(), 1);
-		Assert.assertEquals(document.<Integer>field(""prop3"").intValue(), 11);
-
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
-	}
-
-	@Test
-	public void testTripleSearch() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-		long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
-		long oldCompositeIndexUsage3 = profiler.getCounter(""Query.compositeIndexUsage.3"");
-
-		if (oldIndexUsage == -1) {
-			oldIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage == -1) {
-			oldCompositeIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage3 == -1) {
-			oldCompositeIndexUsage3 = 0;
-		}
-
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1 = 1 and prop2 = 1 and prop4 >= 1""))
-						.execute();
-
-		Assert.assertEquals(result.size(), 1);
-
-		final ODocument document = result.get(0);
-		Assert.assertEquals(document.<Integer>field(""prop1"").intValue(), 1);
-		Assert.assertEquals(document.<Integer>field(""prop2"").intValue(), 1);
-		Assert.assertEquals(document.<Integer>field(""prop4"").intValue(), 1);
-
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.3""), oldCompositeIndexUsage3 + 1);
-	}
-
-	@Test
-	public void testTripleSearchLastFieldNotInIndexFirstCase() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-		long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
-		long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
-
-		if (oldIndexUsage == -1) {
-			oldIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage == -1) {
-			oldCompositeIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage2 == -1) {
-			oldCompositeIndexUsage2 = 0;
-		}
-
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1 = 1 and prop2 = 1 and prop5 >= 1""))
-						.execute();
-
-		Assert.assertEquals(result.size(), 1);
-
-		final ODocument document = result.get(0);
-		Assert.assertEquals(document.<Integer>field(""prop1"").intValue(), 1);
-		Assert.assertEquals(document.<Integer>field(""prop2"").intValue(), 1);
-		Assert.assertEquals(document.<Integer>field(""prop5"").intValue(), 1);
-
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
-	}
-
-	@Test
-	public void testTripleSearchLastFieldNotInIndexSecondCase() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-		long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
-		long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
-
-		if (oldIndexUsage == -1) {
-			oldIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage == -1) {
-			oldCompositeIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage2 == -1) {
-			oldCompositeIndexUsage2 = 0;
-		}
-
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1 = 1 and prop4 >= 1"")).execute();
-
-		Assert.assertEquals(result.size(), 10);
-
-		for (int i = 0; i < 10; i++) {
-			final ODocument document = new ODocument();
-			document.field(""prop1"", 1);
-			document.field(""prop2"", i);
-			document.field(""prop4"", 1);
-
-			Assert.assertEquals(containsDocument(result, document), 1);
-		}
-
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
-	}
-
-	@Test
-	public void testTripleSearchLastFieldInIndex() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-		long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
-		long oldCompositeIndexUsage3 = profiler.getCounter(""Query.compositeIndexUsage.3"");
-
-		if (oldIndexUsage == -1) {
-			oldIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage == -1) {
-			oldCompositeIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage3 == -1) {
-			oldCompositeIndexUsage3 = 0;
-		}
-
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1 = 1 and prop4 = 1"")).execute();
-
-		Assert.assertEquals(result.size(), 10);
-
-		for (int i = 0; i < 10; i++) {
-			final ODocument document = new ODocument();
-			document.field(""prop1"", 1);
-			document.field(""prop2"", i);
-			document.field(""prop4"", 1);
-
-			Assert.assertEquals(containsDocument(result, document), 1);
-		}
-
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.3""), oldCompositeIndexUsage3 + 1);
-	}
-
-	@Test
-	public void testTripleSearchLastFieldsCanNotBeMerged() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-		long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
-		long oldCompositeIndexUsage3 = profiler.getCounter(""Query.compositeIndexUsage.3"");
-
-		if (oldIndexUsage == -1) {
-			oldIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage == -1) {
-			oldCompositeIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage3 == -1) {
-			oldCompositeIndexUsage3 = 0;
-		}
-
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop6 <= 1 and prop4 < 1"")).execute();
-
-		Assert.assertEquals(result.size(), 2);
-
-		for (int i = 0; i < 2; i++) {
-			final ODocument document = new ODocument();
-			document.field(""prop6"", i);
-			document.field(""prop4"", 0);
-
-			Assert.assertEquals(containsDocument(result, document), 1);
-		}
-
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.3""), oldCompositeIndexUsage3 + 1);
-	}
-
-	@Test
-	public void testFullTextIndex() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-		long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
-
-		if (oldIndexUsage == -1) {
-			oldIndexUsage = 0;
-		}
-
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop7 containstext 'Alice' "")).execute();
-
-		Assert.assertEquals(result.size(), 20);
-
-		final ODocument docOne = new ODocument();
-		docOne.field(""prop7"", ""Alice : What is the use of a book, without pictures or conversations?"");
-		Assert.assertEquals(containsDocument(result, docOne), 10);
-
-		final ODocument docTwo = new ODocument();
-		docTwo.field(""prop7"",
-						""Alice : If it had grown up, it would have made a dreadfully ugly child; but it makes rather a handsome pig, I think"");
-		Assert.assertEquals(containsDocument(result, docTwo), 10);
-
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage);
-	}
-
-	@Test
-	public void testLastFieldNotCompatibleOperator() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-		long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
-		long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
-
-		if (oldIndexUsage == -1) {
-			oldIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage == -1) {
-			oldCompositeIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage2 == -1) {
-			oldCompositeIndexUsage2 = 0;
-		}
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage);
+  }
 
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1 = 1 and prop2 + 1 = 3"")).execute();
+  @Test
+  public void testSingleSearchLTWithArgs() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+    long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
 
-		Assert.assertEquals(result.size(), 1);
+    if (oldIndexUsage == -1) {
+      oldIndexUsage = 0;
+    }
 
-		final ODocument document = result.get(0);
-		Assert.assertEquals(document.<Integer>field(""prop1"").intValue(), 1);
-		Assert.assertEquals(document.<Integer>field(""prop2"").intValue(), 2);
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
-	}
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop3 < ?"")).execute(10);
 
-	@Test
-	public void testEmbeddedMapByKeyIndexReuse() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-		long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
-		long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
+    Assert.assertEquals(result.size(), 10);
 
-		if (oldIndexUsage == -1) {
-			oldIndexUsage = 0;
-		}
+    for (int i = 0; i < 10; i++) {
+      final ODocument document = new ODocument();
+      document.field(""prop3"", i);
+      Assert.assertEquals(containsDocument(result, document), 1);
+    }
 
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where fEmbeddedMap containskey 'key12'""))
-						.execute();
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage);
+  }
 
-		Assert.assertEquals(result.size(), 10);
+  @Test
+  public void testSingleSearchBetween() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+    long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
+
+    if (oldIndexUsage == -1) {
+      oldIndexUsage = 0;
+    }
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop3 between 1 and 10"")).execute();
+
+    Assert.assertEquals(result.size(), 10);
+
+    for (int i = 1; i <= 10; i++) {
+      final ODocument document = new ODocument();
+      document.field(""prop3"", i);
+      Assert.assertEquals(containsDocument(result, document), 1);
+    }
+
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage);
+  }
+
+  @Test
+  public void testSingleSearchBetweenWithArgs() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+    long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
+
+    if (oldIndexUsage == -1) {
+      oldIndexUsage = 0;
+    }
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop3 between ? and ?"")).execute(1, 10);
+
+    Assert.assertEquals(result.size(), 10);
+
+    for (int i = 1; i <= 10; i++) {
+      final ODocument document = new ODocument();
+      document.field(""prop3"", i);
+      Assert.assertEquals(containsDocument(result, document), 1);
+    }
+
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage);
+  }
+
+  @Test
+  public void testSingleSearchIN() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+    long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
+
+    if (oldIndexUsage == -1) {
+      oldIndexUsage = 0;
+    }
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop3 in [0, 5, 10]"")).execute();
+
+    Assert.assertEquals(result.size(), 3);
+
+    for (int i = 0; i <= 10; i += 5) {
+      final ODocument document = new ODocument();
+      document.field(""prop3"", i);
+      Assert.assertEquals(containsDocument(result, document), 1);
+    }
+
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage);
+  }
+
+  @Test
+  public void testSingleSearchINWithArgs() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+    long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
+
+    if (oldIndexUsage == -1) {
+      oldIndexUsage = 0;
+    }
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop3 in [?, ?, ?]"")).execute(0, 5, 10);
+
+    Assert.assertEquals(result.size(), 3);
+
+    for (int i = 0; i <= 10; i += 5) {
+      final ODocument document = new ODocument();
+      document.field(""prop3"", i);
+      Assert.assertEquals(containsDocument(result, document), 1);
+    }
+
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage);
+  }
+
+  @Test
+  public void testMostSpecificOnesProcessedFirst() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+    long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
+    long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
+
+    if (oldIndexUsage == -1) {
+      oldIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage == -1) {
+      oldCompositeIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage2 == -1) {
+      oldCompositeIndexUsage2 = 0;
+    }
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1 = 1 and prop2 = 1 and prop3 = 11""))
+        .execute();
+
+    Assert.assertEquals(result.size(), 1);
+
+    final ODocument document = result.get(0);
+    Assert.assertEquals(document.<Integer> field(""prop1"").intValue(), 1);
+    Assert.assertEquals(document.<Integer> field(""prop2"").intValue(), 1);
+    Assert.assertEquals(document.<Integer> field(""prop3"").intValue(), 11);
+
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
+  }
+
+  @Test
+  public void testTripleSearch() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+    long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
+    long oldCompositeIndexUsage3 = profiler.getCounter(""Query.compositeIndexUsage.3"");
+
+    if (oldIndexUsage == -1) {
+      oldIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage == -1) {
+      oldCompositeIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage3 == -1) {
+      oldCompositeIndexUsage3 = 0;
+    }
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1 = 1 and prop2 = 1 and prop4 >= 1""))
+        .execute();
+
+    Assert.assertEquals(result.size(), 1);
+
+    final ODocument document = result.get(0);
+    Assert.assertEquals(document.<Integer> field(""prop1"").intValue(), 1);
+    Assert.assertEquals(document.<Integer> field(""prop2"").intValue(), 1);
+    Assert.assertEquals(document.<Integer> field(""prop4"").intValue(), 1);
+
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.3""), oldCompositeIndexUsage3 + 1);
+  }
+
+  @Test
+  public void testTripleSearchLastFieldNotInIndexFirstCase() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+    long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
+    long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
+
+    if (oldIndexUsage == -1) {
+      oldIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage == -1) {
+      oldCompositeIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage2 == -1) {
+      oldCompositeIndexUsage2 = 0;
+    }
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1 = 1 and prop2 = 1 and prop5 >= 1""))
+        .execute();
+
+    Assert.assertEquals(result.size(), 1);
+
+    final ODocument document = result.get(0);
+    Assert.assertEquals(document.<Integer> field(""prop1"").intValue(), 1);
+    Assert.assertEquals(document.<Integer> field(""prop2"").intValue(), 1);
+    Assert.assertEquals(document.<Integer> field(""prop5"").intValue(), 1);
+
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
+  }
+
+  @Test
+  public void testTripleSearchLastFieldNotInIndexSecondCase() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+    long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
+    long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
+
+    if (oldIndexUsage == -1) {
+      oldIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage == -1) {
+      oldCompositeIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage2 == -1) {
+      oldCompositeIndexUsage2 = 0;
+    }
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1 = 1 and prop4 >= 1"")).execute();
+
+    Assert.assertEquals(result.size(), 10);
+
+    for (int i = 0; i < 10; i++) {
+      final ODocument document = new ODocument();
+      document.field(""prop1"", 1);
+      document.field(""prop2"", i);
+      document.field(""prop4"", 1);
+
+      Assert.assertEquals(containsDocument(result, document), 1);
+    }
+
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
+  }
+
+  @Test
+  public void testTripleSearchLastFieldInIndex() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+    long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
+    long oldCompositeIndexUsage3 = profiler.getCounter(""Query.compositeIndexUsage.3"");
+
+    if (oldIndexUsage == -1) {
+      oldIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage == -1) {
+      oldCompositeIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage3 == -1) {
+      oldCompositeIndexUsage3 = 0;
+    }
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1 = 1 and prop4 = 1"")).execute();
+
+    Assert.assertEquals(result.size(), 10);
+
+    for (int i = 0; i < 10; i++) {
+      final ODocument document = new ODocument();
+      document.field(""prop1"", 1);
+      document.field(""prop2"", i);
+      document.field(""prop4"", 1);
+
+      Assert.assertEquals(containsDocument(result, document), 1);
+    }
+
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.3""), oldCompositeIndexUsage3 + 1);
+  }
+
+  @Test
+  public void testTripleSearchLastFieldsCanNotBeMerged() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+    long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
+    long oldCompositeIndexUsage3 = profiler.getCounter(""Query.compositeIndexUsage.3"");
+
+    if (oldIndexUsage == -1) {
+      oldIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage == -1) {
+      oldCompositeIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage3 == -1) {
+      oldCompositeIndexUsage3 = 0;
+    }
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop6 <= 1 and prop4 < 1"")).execute();
+
+    Assert.assertEquals(result.size(), 2);
+
+    for (int i = 0; i < 2; i++) {
+      final ODocument document = new ODocument();
+      document.field(""prop6"", i);
+      document.field(""prop4"", 0);
+
+      Assert.assertEquals(containsDocument(result, document), 1);
+    }
+
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.3""), oldCompositeIndexUsage3 + 1);
+  }
+
+  @Test
+  public void testFullTextIndex() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+    long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
+
+    if (oldIndexUsage == -1) {
+      oldIndexUsage = 0;
+    }
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop7 containstext 'Alice' "")).execute();
+
+    Assert.assertEquals(result.size(), 20);
+
+    final ODocument docOne = new ODocument();
+    docOne.field(""prop7"", ""Alice : What is the use of a book, without pictures or conversations?"");
+    Assert.assertEquals(containsDocument(result, docOne), 10);
+
+    final ODocument docTwo = new ODocument();
+    docTwo.field(""prop7"",
+        ""Alice : If it had grown up, it would have made a dreadfully ugly child; but it makes rather a handsome pig, I think"");
+    Assert.assertEquals(containsDocument(result, docTwo), 10);
+
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage);
+  }
+
+  @Test
+  public void testLastFieldNotCompatibleOperator() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+    long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
+    long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
+
+    if (oldIndexUsage == -1) {
+      oldIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage == -1) {
+      oldCompositeIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage2 == -1) {
+      oldCompositeIndexUsage2 = 0;
+    }
 
-		final ODocument document = new ODocument();
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1 = 1 and prop2 + 1 = 3"")).execute();
 
-		final Map<String, Integer> embeddedMap = new HashMap<String, Integer>();
+    Assert.assertEquals(result.size(), 1);
 
-		embeddedMap.put(""key11"", 11);
-		embeddedMap.put(""key12"", 12);
-		embeddedMap.put(""key13"", 13);
-		embeddedMap.put(""key14"", 11);
+    final ODocument document = result.get(0);
+    Assert.assertEquals(document.<Integer> field(""prop1"").intValue(), 1);
+    Assert.assertEquals(document.<Integer> field(""prop2"").intValue(), 2);
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
+  }
 
-		document.field(""fEmbeddedMap"", embeddedMap);
+  @Test
+  public void testEmbeddedMapByKeyIndexReuse() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+    long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
+    long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
 
-		Assert.assertEquals(containsDocument(result, document), 10);
+    if (oldIndexUsage == -1) {
+      oldIndexUsage = 0;
+    }
 
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2);
-	}
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where fEmbeddedMap containskey 'key12'""))
+        .execute();
 
-	@Test
-	public void testEmbeddedMapBySpecificKeyIndexReuse() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-		long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
-		long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
+    Assert.assertEquals(result.size(), 10);
 
-		if (oldIndexUsage == -1) {
-			oldIndexUsage = 0;
-		}
+    final ODocument document = new ODocument();
 
-		final List<ODocument> result = database
-						.command(
-										new OSQLSynchQuery<ODocument>(
-														""select * from sqlSelectIndexReuseTestClass where ( fEmbeddedMap containskey 'key12' ) and ( fEmbeddedMap['key12'] = 12 )""))
-						.execute();
+    final Map<String, Integer> embeddedMap = new HashMap<String, Integer>();
 
-		Assert.assertEquals(result.size(), 10);
+    embeddedMap.put(""key11"", 11);
+    embeddedMap.put(""key12"", 12);
+    embeddedMap.put(""key13"", 13);
+    embeddedMap.put(""key14"", 11);
 
-		final ODocument document = new ODocument();
+    document.field(""fEmbeddedMap"", embeddedMap);
 
-		final Map<String, Integer> embeddedMap = new HashMap<String, Integer>();
+    Assert.assertEquals(containsDocument(result, document), 10);
 
-		embeddedMap.put(""key11"", 11);
-		embeddedMap.put(""key12"", 12);
-		embeddedMap.put(""key13"", 13);
-		embeddedMap.put(""key14"", 11);
-
-		document.field(""fEmbeddedMap"", embeddedMap);
-
-		Assert.assertEquals(containsDocument(result, document), 10);
-
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2);
-	}
-
-	@Test
-	public void testEmbeddedMapByValueIndexReuse() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-		long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
-		long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2);
+  }
 
-		if (oldIndexUsage == -1) {
-			oldIndexUsage = 0;
-		}
+  @Test
+  public void testEmbeddedMapBySpecificKeyIndexReuse() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+    long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
+    long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
 
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where fEmbeddedMap containsvalue 11"")).execute();
+    if (oldIndexUsage == -1) {
+      oldIndexUsage = 0;
+    }
 
-		Assert.assertEquals(result.size(), 10);
+    final List<ODocument> result = database
+        .command(
+            new OSQLSynchQuery<ODocument>(
+                ""select * from sqlSelectIndexReuseTestClass where ( fEmbeddedMap containskey 'key12' ) and ( fEmbeddedMap['key12'] = 12 )""))
+        .execute();
 
-		final ODocument document = new ODocument();
+    Assert.assertEquals(result.size(), 10);
 
-		final Map<String, Integer> embeddedMap = new HashMap<String, Integer>();
+    final ODocument document = new ODocument();
 
-		embeddedMap.put(""key11"", 11);
-		embeddedMap.put(""key12"", 12);
-		embeddedMap.put(""key13"", 13);
-		embeddedMap.put(""key14"", 11);
-
-		document.field(""fEmbeddedMap"", embeddedMap);
-
-		Assert.assertEquals(containsDocument(result, document), 10);
-
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2);
-	}
-
-	@Test
-	public void testEmbeddedListIndexReuse() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-		long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
-		long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
-
-		if (oldIndexUsage == -1) {
-			oldIndexUsage = 0;
-		}
-
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where fEmbeddedList contains 7"")).execute();
-
-		final List<Integer> embeddedList = new ArrayList<Integer>(3);
-		embeddedList.add(6);
-		embeddedList.add(7);
-		embeddedList.add(8);
-
-		final ODocument document = new ODocument();
-		document.field(""fEmbeddedList"", embeddedList);
-
-		Assert.assertEquals(containsDocument(result, document), 10);
-
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2);
-	}
-
-	@Test
-	public void testNotIndexOperatorFirstCase() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-		long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
-		long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
-
-		if (oldIndexUsage == -1) {
-			oldIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage == -1) {
-			oldCompositeIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage2 == -1) {
-			oldCompositeIndexUsage2 = 0;
-		}
-
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(
-										""select * from sqlSelectIndexReuseTestClass where prop1 = 1 and prop2  = 2 and ( prop4 = 3 or prop4 = 1 )"")).execute();
-
-		Assert.assertEquals(result.size(), 1);
-
-		final ODocument document = result.get(0);
-		Assert.assertEquals(document.<Integer>field(""prop1"").intValue(), 1);
-		Assert.assertEquals(document.<Integer>field(""prop2"").intValue(), 2);
-		Assert.assertEquals(document.<Integer>field(""prop4"").intValue(), 1);
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
-	}
-
-	@Test
-	public void testNotIndexOperatorSecondCase() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-
-		final List<ODocument> result = database.command(
-						new OSQLSynchQuery<ODocument>(
-										""select * from sqlSelectIndexReuseTestClass where ( prop1 = 1 and prop2 = 2 ) or ( prop4  = 1 and prop6 = 2 )""))
-						.execute();
-
-		Assert.assertEquals(result.size(), 1);
-
-		final ODocument document = result.get(0);
-		Assert.assertEquals(document.<Integer>field(""prop1"").intValue(), 1);
-		Assert.assertEquals(document.<Integer>field(""prop2"").intValue(), 2);
-		Assert.assertEquals(document.<Integer>field(""prop4"").intValue(), 1);
-		Assert.assertEquals(document.<Integer>field(""prop6"").intValue(), 2);
-
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage);
-	}
-
-	private int containsDocument(final List<ODocument> docList, final ODocument document) {
-		int count = 0;
-		for (final ODocument docItem : docList) {
-			boolean containsAllFields = true;
-			for (final String fieldName : document.fieldNames()) {
-				if (!document.<Object>field(fieldName).equals(docItem.<Object>field(fieldName))) {
-					containsAllFields = false;
-					break;
-				}
-			}
-			if (containsAllFields) {
-				count++;
-			}
-		}
-		return count;
-	}
-
-	@Test
-	public void testCompositeIndexEmptyResult() {
-		long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
-		long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
-		long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
-
-		if (oldIndexUsage == -1) {
-			oldIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage == -1) {
-			oldCompositeIndexUsage = 0;
-		}
-		if (oldCompositeIndexUsage2 == -1) {
-			oldCompositeIndexUsage2 = 0;
-		}
-
-		final List<ODocument> result = database.command(
-				new OSQLSynchQuery<ODocument>(
-						""select * from sqlSelectIndexReuseTestClass where prop1 = 1777 and prop2  = 2777"")).execute();
-
-		Assert.assertEquals(result.size(), 0);
-
-		Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
-		Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
-	}
+    final Map<String, Integer> embeddedMap = new HashMap<String, Integer>();
+
+    embeddedMap.put(""key11"", 11);
+    embeddedMap.put(""key12"", 12);
+    embeddedMap.put(""key13"", 13);
+    embeddedMap.put(""key14"", 11);
+
+    document.field(""fEmbeddedMap"", embeddedMap);
+
+    Assert.assertEquals(containsDocument(result, document), 10);
+
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2);
+  }
+
+  @Test
+  public void testEmbeddedMapByValueIndexReuse() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+    long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
+    long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
+
+    if (oldIndexUsage == -1) {
+      oldIndexUsage = 0;
+    }
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where fEmbeddedMap containsvalue 11"")).execute();
+
+    Assert.assertEquals(result.size(), 10);
+
+    final ODocument document = new ODocument();
+
+    final Map<String, Integer> embeddedMap = new HashMap<String, Integer>();
+
+    embeddedMap.put(""key11"", 11);
+    embeddedMap.put(""key12"", 12);
+    embeddedMap.put(""key13"", 13);
+    embeddedMap.put(""key14"", 11);
+
+    document.field(""fEmbeddedMap"", embeddedMap);
+
+    Assert.assertEquals(containsDocument(result, document), 10);
+
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2);
+  }
+
+  @Test
+  public void testEmbeddedListIndexReuse() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+    long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
+    long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
+
+    if (oldIndexUsage == -1) {
+      oldIndexUsage = 0;
+    }
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where fEmbeddedList contains 7"")).execute();
+
+    final List<Integer> embeddedList = new ArrayList<Integer>(3);
+    embeddedList.add(6);
+    embeddedList.add(7);
+    embeddedList.add(8);
+
+    final ODocument document = new ODocument();
+    document.field(""fEmbeddedList"", embeddedList);
+
+    Assert.assertEquals(containsDocument(result, document), 10);
+
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2);
+  }
+
+  @Test
+  public void testNotIndexOperatorFirstCase() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+    long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
+    long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
+
+    if (oldIndexUsage == -1) {
+      oldIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage == -1) {
+      oldCompositeIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage2 == -1) {
+      oldCompositeIndexUsage2 = 0;
+    }
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(
+            ""select * from sqlSelectIndexReuseTestClass where prop1 = 1 and prop2  = 2 and ( prop4 = 3 or prop4 = 1 )"")).execute();
+
+    Assert.assertEquals(result.size(), 1);
+
+    final ODocument document = result.get(0);
+    Assert.assertEquals(document.<Integer> field(""prop1"").intValue(), 1);
+    Assert.assertEquals(document.<Integer> field(""prop2"").intValue(), 2);
+    Assert.assertEquals(document.<Integer> field(""prop4"").intValue(), 1);
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
+  }
+
+  @Test
+  public void testNotIndexOperatorSecondCase() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(
+            ""select * from sqlSelectIndexReuseTestClass where ( prop1 = 1 and prop2 = 2 ) or ( prop4  = 1 and prop6 = 2 )""))
+        .execute();
+
+    Assert.assertEquals(result.size(), 1);
+
+    final ODocument document = result.get(0);
+    Assert.assertEquals(document.<Integer> field(""prop1"").intValue(), 1);
+    Assert.assertEquals(document.<Integer> field(""prop2"").intValue(), 2);
+    Assert.assertEquals(document.<Integer> field(""prop4"").intValue(), 1);
+    Assert.assertEquals(document.<Integer> field(""prop6"").intValue(), 2);
+
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage);
+  }
+
+  private int containsDocument(final List<ODocument> docList, final ODocument document) {
+    int count = 0;
+    for (final ODocument docItem : docList) {
+      boolean containsAllFields = true;
+      for (final String fieldName : document.fieldNames()) {
+        if (!document.<Object> field(fieldName).equals(docItem.<Object> field(fieldName))) {
+          containsAllFields = false;
+          break;
+        }
+      }
+      if (containsAllFields) {
+        count++;
+      }
+    }
+    return count;
+  }
+
+  @Test
+  public void testCompositeIndexEmptyResult() {
+    long oldIndexUsage = profiler.getCounter(""Query.indexUsage"");
+    long oldCompositeIndexUsage = profiler.getCounter(""Query.compositeIndexUsage"");
+    long oldCompositeIndexUsage2 = profiler.getCounter(""Query.compositeIndexUsage.2"");
+
+    if (oldIndexUsage == -1) {
+      oldIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage == -1) {
+      oldCompositeIndexUsage = 0;
+    }
+    if (oldCompositeIndexUsage2 == -1) {
+      oldCompositeIndexUsage2 = 0;
+    }
+
+    final List<ODocument> result = database.command(
+        new OSQLSynchQuery<ODocument>(""select * from sqlSelectIndexReuseTestClass where prop1 = 1777 and prop2  = 2777"")).execute();
+
+    Assert.assertEquals(result.size(), 0);
+
+    Assert.assertEquals(profiler.getCounter(""Query.indexUsage""), oldIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage""), oldCompositeIndexUsage + 1);
+    Assert.assertEquals(profiler.getCounter(""Query.compositeIndexUsage.2""), oldCompositeIndexUsage2 + 1);
+  }
 }
",Issue 762 was fixed.--
1453,Java,359a2756e623e605aaf29a1f3c7181666fae775c,,P,orientechnologies,orientdb,"[3, 6, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/core/src/main/java/com/orientechnologies/orient/core/db/ODatabaseWrapperAbstract.java b/core/src/main/java/com/orientechnologies/orient/core/db/ODatabaseWrapperAbstract.java
index b2f87de61a..1793a65f43 100644
--- a/core/src/main/java/com/orientechnologies/orient/core/db/ODatabaseWrapperAbstract.java
+++ b/core/src/main/java/com/orientechnologies/orient/core/db/ODatabaseWrapperAbstract.java
@@ -307,5 +307,5 @@ public abstract class ODatabaseWrapperAbstract<DB extends ODatabase> implements
   }
 
-  public <V> V callInLock(Callable<V> iCallable, boolean iExclusiveLock) {
+  public <V> V callInLock(final Callable<V> iCallable, final boolean iExclusiveLock) {
     return getStorage().callInLock(iCallable, iExclusiveLock);
   }
diff --git a/core/src/main/java/com/orientechnologies/orient/core/storage/impl/local/OClusterLocalLHPEPS.java b/core/src/main/java/com/orientechnologies/orient/core/storage/impl/local/OClusterLocalLHPEPS.java
index e310b14a2d..bcdc773873 100644
--- a/core/src/main/java/com/orientechnologies/orient/core/storage/impl/local/OClusterLocalLHPEPS.java
+++ b/core/src/main/java/com/orientechnologies/orient/core/storage/impl/local/OClusterLocalLHPEPS.java
@@ -349,5 +349,5 @@ public class OClusterLocalLHPEPS extends OSharedResourceAdaptive implements OClu
   public void truncate() throws IOException {
     storage.checkForClusterPermissions(getName());
-    
+
     acquireExclusiveLock();
     try {
@@ -452,4 +452,9 @@ public class OClusterLocalLHPEPS extends OSharedResourceAdaptive implements OClu
   }
 
+  @Override
+  public String toString() {
+    return name;
+  }
+
   public OPhysicalPosition getPhysicalPosition(OPhysicalPosition iPPosition) throws IOException {
     acquireSharedLock();
diff --git a/core/src/main/java/com/orientechnologies/orient/core/storage/impl/local/OStorageLocal.java b/core/src/main/java/com/orientechnologies/orient/core/storage/impl/local/OStorageLocal.java
index a9f44d8614..3998de6139 100644
--- a/core/src/main/java/com/orientechnologies/orient/core/storage/impl/local/OStorageLocal.java
+++ b/core/src/main/java/com/orientechnologies/orient/core/storage/impl/local/OStorageLocal.java
@@ -1452,8 +1452,11 @@ public class OStorageLocal extends OStorageEmbedded {
     OCluster cluster = clusterMap.get(iConfig.getName());
 
-    if (cluster != null) {
-      if (cluster instanceof OClusterLocal)
+    if (cluster instanceof OClusterLocal && iConfig instanceof OStoragePhysicalClusterLHPEPSConfiguration)
+      clusterMap.remove(iConfig.getName());
+    else if (cluster != null) {
+      if (cluster instanceof OClusterLocal) {
         // ALREADY CONFIGURED, JUST OVERWRITE CONFIG
         ((OClusterLocal) cluster).configure(this, iConfig);
+      }
       return -1;
     }
",Improved automatic backup management of errors--
1457,Java,393b67f7a03d76698375be3350ff9282661fbf21,,C,JetBrains,intellij-community,"[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/java/java-tests/testSrc/com/intellij/codeInsight/completion/MethodChainsCompletionTest.java b/java/java-tests/testSrc/com/intellij/codeInsight/completion/MethodChainsCompletionTest.java
index 320c63cad8d5..49c1c33c1057 100644
--- a/java/java-tests/testSrc/com/intellij/codeInsight/completion/MethodChainsCompletionTest.java
+++ b/java/java-tests/testSrc/com/intellij/codeInsight/completion/MethodChainsCompletionTest.java
@@ -110,5 +110,5 @@ public class MethodChainsCompletionTest extends AbstractCompilerAwareTest {
   }
 
-  public void testInnerClasses() {
+  public void _testInnerClasses() {
     assertAdvisorLookupElementEquals(""j.getEntry"", 0, 8, 1, 0, assertOneElement(doCompletion()));
   }
",tests repaired--
1459,Java,2947b932624e4931333c08cfd9c111628bbd25e9,,C,orientechnologies,orientdb,"[4, 5, 3, 3, 0, 0, 0, 3, 1, 0, 2, 0, 0, 0, 122, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/client/src/main/java/com/orientechnologies/orient/client/remote/OStorageRemote.java b/client/src/main/java/com/orientechnologies/orient/client/remote/OStorageRemote.java
index 2cd9c5df88..b75e598d20 100644
--- a/client/src/main/java/com/orientechnologies/orient/client/remote/OStorageRemote.java
+++ b/client/src/main/java/com/orientechnologies/orient/client/remote/OStorageRemote.java
@@ -50,5 +50,4 @@ import com.orientechnologies.orient.core.serialization.OSerializableStream;
 import com.orientechnologies.orient.core.serialization.serializer.stream.OStreamSerializerAnyRuntime;
 import com.orientechnologies.orient.core.serialization.serializer.stream.OStreamSerializerAnyStreamable;
-import com.orientechnologies.orient.core.sql.query.OSQLQuery;
 import com.orientechnologies.orient.core.storage.OCluster;
 import com.orientechnologies.orient.core.storage.ORawBuffer;
@@ -360,5 +359,5 @@ public class OStorageRemote extends OStorageAbstract {
 
 			try {
-				final OSQLQuery<?> aquery = (OSQLQuery<?>) iCommand;
+				final OCommandRequestText aquery = (OCommandRequestText) iCommand;
 
 				final boolean asynch = iCommand instanceof OCommandRequestAsynch;
@@ -515,8 +514,9 @@ public class OStorageRemote extends OStorageAbstract {
 				if (OClusterLocal.TYPE.equals(iClusterType)) {
 					// FIEL PATH + START SIZE
-					network.writeString((String) iArguments[0]).writeInt((Integer) iArguments[1]);
+					network.writeString(iArguments.length > 0 ? (String) iArguments[0] : """").writeInt(
+							iArguments.length > 0 ? (Integer) iArguments[1] : -1);
 				} else {
 					// PHY CLUSTER ID
-					network.writeInt((Integer) iArguments[0]);
+					network.writeInt(iArguments.length > 0 ? (Integer) iArguments[0] : -1);
 				}
 
diff --git a/core/src/main/java/com/orientechnologies/orient/core/command/OCommandRequestInternal.java b/core/src/main/java/com/orientechnologies/orient/core/command/OCommandRequestInternal.java
index da68922264..b7f1b7b6e3 100644
--- a/core/src/main/java/com/orientechnologies/orient/core/command/OCommandRequestInternal.java
+++ b/core/src/main/java/com/orientechnologies/orient/core/command/OCommandRequestInternal.java
@@ -31,4 +31,6 @@ public interface OCommandRequestInternal extends OCommandRequest, OSerializableS
 	public OCommandRequestInternal setDatabase(final ODatabaseRecord<?> iDatabase);
 
+	public OCommandResultListener getResultListener();
+
 	public void setResultListener(OCommandResultListener iListener);
 }
diff --git a/core/src/main/java/com/orientechnologies/orient/core/db/record/ODatabaseRecordAbstract.java b/core/src/main/java/com/orientechnologies/orient/core/db/record/ODatabaseRecordAbstract.java
index 8dd54bcedb..0c11593b38 100644
--- a/core/src/main/java/com/orientechnologies/orient/core/db/record/ODatabaseRecordAbstract.java
+++ b/core/src/main/java/com/orientechnologies/orient/core/db/record/ODatabaseRecordAbstract.java
@@ -102,12 +102,12 @@ public abstract class ODatabaseRecordAbstract<REC extends ORecordInternal<?>> ex
 			dictionary.load();
 
-			if (getStorage() instanceof OStorageLocal) {
-				user = getMetadata().getSecurity().getUser(iUserName);
-				if (user == null)
-					throw new OSecurityAccessException(this.getName(), ""User '"" + iUserName + ""' was not found in database: "" + getName());
+			user = getMetadata().getSecurity().getUser(iUserName);
+			if (user == null)
+				throw new OSecurityAccessException(this.getName(), ""User '"" + iUserName + ""' was not found in database: "" + getName());
 
-				if (user.getAccountStatus() != STATUSES.ACTIVE)
-					throw new OSecurityAccessException(this.getName(), ""User '"" + iUserName + ""' is not active"");
+			if (user.getAccountStatus() != STATUSES.ACTIVE)
+				throw new OSecurityAccessException(this.getName(), ""User '"" + iUserName + ""' is not active"");
 
+			if (getStorage() instanceof OStorageLocal) {
 				if (!user.checkPassword(iUserPassword)) {
 					// WAIT A BIT TO AVOID BRUTE FORCE
@@ -115,7 +115,7 @@ public abstract class ODatabaseRecordAbstract<REC extends ORecordInternal<?>> ex
 					throw new OSecurityAccessException(this.getName(), ""Password not valid for user: "" + iUserName);
 				}
-
-				checkSecurity(ODatabaseSecurityResources.DATABASE, ORole.PERMISSION_READ);
 			}
+
+			checkSecurity(ODatabaseSecurityResources.DATABASE, ORole.PERMISSION_READ);
 		} catch (Exception e) {
 			close();
diff --git a/server/src/main/java/com/orientechnologies/orient/server/network/protocol/binary/ONetworkProtocolBinary.java b/server/src/main/java/com/orientechnologies/orient/server/network/protocol/binary/ONetworkProtocolBinary.java
index 567b9385f8..3043000094 100644
--- a/server/src/main/java/com/orientechnologies/orient/server/network/protocol/binary/ONetworkProtocolBinary.java
+++ b/server/src/main/java/com/orientechnologies/orient/server/network/protocol/binary/ONetworkProtocolBinary.java
@@ -283,4 +283,6 @@ public class ONetworkProtocolBinary extends ONetworkProtocol {
 				underlyingDatabase.delete(channel.readShort(), channel.readLong(), channel.readInt());
 				sendOk();
+
+				channel.writeByte((byte) '1');
 				break;
 
diff --git a/tests/src/test/java/com/orientechnologies/orient/test/database/auto/SQLUpdateTest.java b/tests/src/test/java/com/orientechnologies/orient/test/database/auto/SQLUpdateTest.java
index 90db9b1c38..e810cd4d25 100644
--- a/tests/src/test/java/com/orientechnologies/orient/test/database/auto/SQLUpdateTest.java
+++ b/tests/src/test/java/com/orientechnologies/orient/test/database/auto/SQLUpdateTest.java
@@ -38,7 +38,8 @@ public class SQLUpdateTest {
 
 		Integer records = (Integer) database.command(
-				new OCommandSQL(""update Profile set salary = 120.30, location = -3:2, salary_cloned = salary where surname = 'Obama'"")).execute();
+				new OCommandSQL(""update Profile set salary = 120.30, location = -3:2, salary_cloned = salary where surname = 'Obama'""))
+				.execute();
 
-		Assert.assertTrue(records == 3);
+		Assert.assertEquals(records.intValue(), 3);
 
 		database.close();
diff --git a/tests/src/test/java/com/orientechnologies/orient/test/database/auto/local-test-db-from-scratch.xml b/tests/src/test/java/com/orientechnologies/orient/test/database/auto/local-test-db-from-scratch.xml
new file mode 100644
index 0000000000..fbc3ac6d05
--- /dev/null
+++ b/tests/src/test/java/com/orientechnologies/orient/test/database/auto/local-test-db-from-scratch.xml
@@ -0,0 +1,119 @@
+<!DOCTYPE suite SYSTEM ""http://beust.com/testng/testng-1.0.dtd"">
+<suite name=""Test Suite Example"" verbose=""1"" parallel=""false"">
+	<!-- <parameter name=""url"" value=""remote:localhost/demo"" /> -->
+
+	<!-- -->
+	<parameter name=""url""
+		value=""local:../../releases/0.9.19/db/databases/demo/demo"" />
+
+
+	<test name=""Setup"">
+		<parameter name=""path"" value=""../../releases/0.9.19/db/databases/demo"" />
+		<classes>
+			<class
+				name=""com.orientechnologies.orient.test.database.base.DeleteDirectory"" />
+		</classes>
+	</test>
+
+	<test name=""DbCreation"">
+		<classes>
+			<class
+				name=""com.orientechnologies.orient.test.database.auto.DbCreationTest"" />
+		</classes>
+	</test>
+	<test name=""Schema"">
+		<classes>
+			<class name=""com.orientechnologies.orient.test.database.auto.SchemaTest"" />
+		</classes>
+	</test>
+	<test name=""Security"">
+		<classes>
+			<class name=""com.orientechnologies.orient.test.database.auto.SecurityTest"" />
+		</classes>
+	</test>
+	<test name=""Hook"">
+		<classes>
+			<class name=""com.orientechnologies.orient.test.database.auto.HookTest"" />
+		</classes>
+	</test>
+	<test name=""Population"">
+		<classes>
+			<class
+				name=""com.orientechnologies.orient.test.database.auto.CRUDFlatPhysicalTest"" />
+			<class
+				name=""com.orientechnologies.orient.test.database.auto.CRUDColumnPhysicalTest"" />
+			<class
+				name=""com.orientechnologies.orient.test.database.auto.CRUDDocumentLogicalTest"" />
+			<class
+				name=""com.orientechnologies.orient.test.database.auto.CRUDDocumentPhysicalTest"" />
+			<class
+				name=""com.orientechnologies.orient.test.database.auto.CRUDObjectPhysicalTest"" />
+			<class
+				name=""com.orientechnologies.orient.test.database.auto.CRUDObjectInheritanceTest"" />
+			<class
+				name=""com.orientechnologies.orient.test.database.auto.CRUDFlatPhysicalTest"" />
+			<class
+				name=""com.orientechnologies.orient.test.database.auto.CRUDDocumentValidationTest"" />
+			<class
+				name=""com.orientechnologies.orient.test.database.auto.ObjectTreeTest"" />
+		</classes>
+	</test>
+	<test name=""Tx"">
+		<classes>
+			<class
+				name=""com.orientechnologies.orient.test.database.auto.TransactionAtomicTest"" />
+			<class
+				name=""com.orientechnologies.orient.test.database.auto.TransactionOptimisticTest"" />
+			<class
+				name=""com.orientechnologies.orient.test.database.auto.TransactionConsistencyTest"" />
+		</classes>
+	</test>
+	<test name=""Index"">
+		<classes>
+			<class name=""com.orientechnologies.orient.test.database.auto.IndexTest"" />
+		</classes>
+	</test>
+	<test name=""Dictionary"">
+		<classes>
+			<class
+				name=""com.orientechnologies.orient.test.database.auto.DictionaryTest"" />
+		</classes>
+	</test>
+	<test name=""Query"">
+		<classes>
+			<class
+				name=""com.orientechnologies.orient.test.database.auto.NativeQueryTest"" />
+			<class
+				name=""com.orientechnologies.orient.test.database.auto.WrongQueryTest"" />
+		</classes>
+	</test>
+	<test name=""sql-select"">
+		<classes>
+			<class
+				name=""com.orientechnologies.orient.test.database.auto.SQLSelectTest"" />
+		</classes>
+	</test>
+	<test name=""sql-insert"">
+		<classes>
+			<class
+				name=""com.orientechnologies.orient.test.database.auto.SQLInsertTest"" />
+		</classes>
+	</test>
+	<test name=""sql-update"">
+		<classes>
+			<class
+				name=""com.orientechnologies.orient.test.database.auto.SQLUpdateTest"" />
+		</classes>
+	</test>
+	<test name=""sql-delete"">
+		<classes>
+			<class
+				name=""com.orientechnologies.orient.test.database.auto.SQLDeleteTest"" />
+		</classes>
+	</test>
+	<test name=""End"">
+		<classes>
+			<class name=""com.orientechnologies.orient.test.database.auto.DbClosedTest"" />
+		</classes>
+	</test>
+</suite>
\ No newline at end of file
diff --git a/tests/src/test/java/com/orientechnologies/orient/test/database/auto/remote-test-db-from-scratch.xml b/tests/src/test/java/com/orientechnologies/orient/test/database/auto/remote-test-db-from-scratch.xml
index b57ffa92a5..71181d0856 100644
--- a/tests/src/test/java/com/orientechnologies/orient/test/database/auto/remote-test-db-from-scratch.xml
+++ b/tests/src/test/java/com/orientechnologies/orient/test/database/auto/remote-test-db-from-scratch.xml
@@ -1,11 +1,12 @@
 <!DOCTYPE suite SYSTEM ""http://beust.com/testng/testng-1.0.dtd"">
 <suite name=""Test Suite Example"" verbose=""1"" parallel=""false"">
-    <!--
+    <!--  -->
     <parameter name=""url"" value=""remote:localhost/demo"" />
-    -->
     
-    <!--   -->
-    <parameter name=""url"" value=""local:../../releases/0.9.19/db/databases/demo/demo""/>
     
+    <!--  
+    <parameter name=""url"" value=""local:../../releases/0.9.19/db/databases/demo/demo""/>
+     -->
+     
     <test name=""Setup"">
         <parameter name=""path"" value=""../../releases/0.9.19/db/databases/demo""/>
",Fixed some errors in remote calls.--
1461,Java,3b73c810de961f01ab2dd27710c7e17a0490e208,,A,orientechnologies,orientdb,"[7, 4, 1, 12, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/client/src/main/java/com/orientechnologies/orient/client/remote/OStorageRemote.java b/client/src/main/java/com/orientechnologies/orient/client/remote/OStorageRemote.java
index ffe771f4c5..ab7c460ee9 100644
--- a/client/src/main/java/com/orientechnologies/orient/client/remote/OStorageRemote.java
+++ b/client/src/main/java/com/orientechnologies/orient/client/remote/OStorageRemote.java
@@ -1248,10 +1248,9 @@ public class OStorageRemote extends OStorageAbstract {
 
 		if (record instanceof ORecordSchemaAware<?>)
-			((ORecordSchemaAware<?>) record).fill(iDatabase, classId, network.readShort(), network.readLong(), network.readInt());
+			((ORecordSchemaAware<?>) record).fill(iDatabase, classId, network.readShort(), network.readLong(), network.readInt(),
+					network.readBytes());
 		else
 			// DISCARD CLASS ID
-			record.fill(iDatabase, network.readShort(), network.readLong(), network.readInt());
-
-		record.fromStream(network.readBytes());
+			record.fill(iDatabase, network.readShort(), network.readLong(), network.readInt(), network.readBytes());
 
 		return record;
diff --git a/core/src/main/java/com/orientechnologies/orient/core/db/record/ODatabaseRecordAbstract.java b/core/src/main/java/com/orientechnologies/orient/core/db/record/ODatabaseRecordAbstract.java
index 1de1700b8f..f6fb23cf75 100644
--- a/core/src/main/java/com/orientechnologies/orient/core/db/record/ODatabaseRecordAbstract.java
+++ b/core/src/main/java/com/orientechnologies/orient/core/db/record/ODatabaseRecordAbstract.java
@@ -393,10 +393,10 @@ public abstract class ODatabaseRecordAbstract extends ODatabaseWrapperAbstract<O
 				currDb = (ODatabaseRecord) databaseOwner;
 
-			iRecord.fill(currDb, iClusterId, iPosition, recordBuffer.version);
+			iRecord.fill(currDb, iClusterId, iPosition, recordBuffer.version, recordBuffer.buffer);
 			iRecord.fromStream(recordBuffer.buffer);
 			iRecord.setStatus(STATUS.LOADED);
 
 			callbackHooks(TYPE.AFTER_READ, iRecord);
-			
+
 			if (!iIgnoreCache) {
 				getCache().pushRecord(iRecord);
@@ -483,5 +483,5 @@ public abstract class ODatabaseRecordAbstract extends ODatabaseWrapperAbstract<O
 			if (isNew) {
 				// UPDATE INFORMATION: CLUSTER ID+POSITION
-				iRecord.fill(iRecord.getDatabase(), clusterId, result, 0);
+				iRecord.fill(iRecord.getDatabase(), clusterId, result, 0, stream);
 				iRecord.setStatus(STATUS.LOADED);
 				if (stream != null && stream.length > 0)
@@ -492,5 +492,5 @@ public abstract class ODatabaseRecordAbstract extends ODatabaseWrapperAbstract<O
 			} else {
 				// UPDATE INFORMATION: VERSION
-				iRecord.fill(iRecord.getDatabase(), clusterId, rid.getClusterPosition(), (int) result);
+				iRecord.fill(iRecord.getDatabase(), clusterId, rid.getClusterPosition(), (int) result, stream);
 				iRecord.setStatus(STATUS.LOADED);
 				if (stream != null && stream.length > 0)
diff --git a/core/src/main/java/com/orientechnologies/orient/core/record/ORecordAbstract.java b/core/src/main/java/com/orientechnologies/orient/core/record/ORecordAbstract.java
index 63e751e6f3..0d1a92b3b3 100644
--- a/core/src/main/java/com/orientechnologies/orient/core/record/ORecordAbstract.java
+++ b/core/src/main/java/com/orientechnologies/orient/core/record/ORecordAbstract.java
@@ -51,8 +51,12 @@ public abstract class ORecordAbstract<T> implements ORecord<T>, ORecordInternal<
 	}
 
-	public ORecordAbstract<?> fill(final ODatabaseRecord iDatabase, final int iClusterId, final long iPosition, final int iVersion) {
+	public ORecordAbstract<?> fill(final ODatabaseRecord iDatabase, final int iClusterId, final long iPosition, final int iVersion,
+			final byte[] iBuffer) {
 		_database = iDatabase;
 		setIdentity(iClusterId, iPosition);
 		_version = iVersion;
+		_status = STATUS.LOADED;
+		_source = iBuffer;
+
 		return this;
 	}
@@ -243,5 +247,5 @@ public abstract class ORecordAbstract<T> implements ORecord<T>, ORecordInternal<
 
 			// GET CONTENT
-			//fromStream(toStream());
+			// fromStream(toStream());
 
 			return this;
diff --git a/core/src/main/java/com/orientechnologies/orient/core/record/ORecordInternal.java b/core/src/main/java/com/orientechnologies/orient/core/record/ORecordInternal.java
index 8d090da853..70f869c3c5 100644
--- a/core/src/main/java/com/orientechnologies/orient/core/record/ORecordInternal.java
+++ b/core/src/main/java/com/orientechnologies/orient/core/record/ORecordInternal.java
@@ -24,5 +24,5 @@ import com.orientechnologies.orient.core.serialization.OSerializableStream;
  */
 public interface ORecordInternal<T> extends ORecord<T>, OSerializableStream {
-	public ORecordAbstract<?> fill(ODatabaseRecord iDatabase, int iClusterId, long iPosition, int iVersion);
+	public ORecordAbstract<?> fill(ODatabaseRecord iDatabase, int iClusterId, long iPosition, int iVersion, byte[] iBuffer);
 
 	public ORecordAbstract<?> setIdentity(int iClusterId, long iClusterPosition);
diff --git a/core/src/main/java/com/orientechnologies/orient/core/record/ORecordSchemaAware.java b/core/src/main/java/com/orientechnologies/orient/core/record/ORecordSchemaAware.java
index baf0b55558..02f13d261f 100644
--- a/core/src/main/java/com/orientechnologies/orient/core/record/ORecordSchemaAware.java
+++ b/core/src/main/java/com/orientechnologies/orient/core/record/ORecordSchemaAware.java
@@ -52,4 +52,5 @@ public interface ORecordSchemaAware<T> extends ORecordInternal<T> {
 	public void validate() throws OValidationException;
 
-	public ORecordSchemaAware<T> fill(ODatabaseRecord iDatabase, int iClassId, int iClusterId, long iPosition, int iVersion);
+	public ORecordSchemaAware<T> fill(ODatabaseRecord iDatabase, int iClassId, int iClusterId, long iPosition, int iVersion,
+			byte[] iBuffer);
 }
diff --git a/core/src/main/java/com/orientechnologies/orient/core/record/ORecordSchemaAwareAbstract.java b/core/src/main/java/com/orientechnologies/orient/core/record/ORecordSchemaAwareAbstract.java
index a3501a6b7d..01802a8bbc 100644
--- a/core/src/main/java/com/orientechnologies/orient/core/record/ORecordSchemaAwareAbstract.java
+++ b/core/src/main/java/com/orientechnologies/orient/core/record/ORecordSchemaAwareAbstract.java
@@ -41,6 +41,6 @@ public abstract class ORecordSchemaAwareAbstract<T> extends ORecordAbstract<T> i
 
 	public ORecordSchemaAwareAbstract<T> fill(final ODatabaseRecord iDatabase, final int iClassId, final int iClusterId,
-			final long iPosition, final int iVersion) {
-		super.fill(iDatabase, iClusterId, iPosition, iVersion);
+			final long iPosition, final int iVersion, final byte[] iBuffer) {
+		super.fill(iDatabase, iClusterId, iPosition, iVersion, iBuffer);
 		setClass(_database.getMetadata().getSchema().getClassById(iClassId));
 		return this;
diff --git a/server/src/main/java/com/orientechnologies/orient/server/tx/OTransactionRecordProxy.java b/server/src/main/java/com/orientechnologies/orient/server/tx/OTransactionRecordProxy.java
index 6bc891752e..5e2855ec9b 100644
--- a/server/src/main/java/com/orientechnologies/orient/server/tx/OTransactionRecordProxy.java
+++ b/server/src/main/java/com/orientechnologies/orient/server/tx/OTransactionRecordProxy.java
@@ -168,5 +168,6 @@ public class OTransactionRecordProxy implements ORecordInternal<byte[]> {
 
 	@Override
-	public ORecordAbstract<?> fill(final ODatabaseRecord iDatabase, final int iClusterId, final long iPosition, final int iVersion) {
+	public ORecordAbstract<?> fill(final ODatabaseRecord iDatabase, final int iClusterId, final long iPosition, final int iVersion,
+			final byte[] iBuffer) {
 		return null;
 	}
",Started support for server-side triggers--
1462,Java,48053b56631374d50fc9075e39fea70da419a5c8,,A,orientechnologies,orientdb,"[1, 39, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/core/src/main/java/com/orientechnologies/orient/core/serialization/serializer/record/binary/ORecordSerializerBinaryV0.java b/core/src/main/java/com/orientechnologies/orient/core/serialization/serializer/record/binary/ORecordSerializerBinaryV0.java
index ba347d5bf4..90d03f9984 100644
--- a/core/src/main/java/com/orientechnologies/orient/core/serialization/serializer/record/binary/ORecordSerializerBinaryV0.java
+++ b/core/src/main/java/com/orientechnologies/orient/core/serialization/serializer/record/binary/ORecordSerializerBinaryV0.java
@@ -23,8 +23,10 @@ import com.orientechnologies.orient.core.db.record.OTrackedMap;
 import com.orientechnologies.orient.core.db.record.OTrackedSet;
 import com.orientechnologies.orient.core.db.record.ridbag.ORidBag;
+import com.orientechnologies.orient.core.exception.ODatabaseException;
 import com.orientechnologies.orient.core.id.OClusterPositionLong;
 import com.orientechnologies.orient.core.id.ORID;
 import com.orientechnologies.orient.core.id.ORecordId;
 import com.orientechnologies.orient.core.metadata.schema.OClass;
+import com.orientechnologies.orient.core.metadata.schema.OGlobalProperty;
 import com.orientechnologies.orient.core.metadata.schema.OProperty;
 import com.orientechnologies.orient.core.metadata.schema.OType;
@@ -53,13 +55,36 @@ public class ORecordSerializerBinaryV0 implements ODocumentSerializer {
     int last = 0;
     String field;
-    while ((field = readString(bytes)).length() != 0) {
+    while (true) {
+      OGlobalProperty prop = null;
+      final int len = OVarIntSerializer.readAsInteger(bytes);
+      if (len == 0)
+        break;
+      else if (len > 0) {
+        final String res = new String(bytes.bytes, bytes.offset, len, utf8);
+        bytes.skip(len);
+        field = res;
+      } else {
+        ODatabaseRecord db = document.getDatabase();
+        if (db == null || db.isClosed())
+          throw new ODatabaseException(""Impossible deserialize the document no database present"");
+        prop = db.getMetadata().getSchema().getGlobalPropertyById((len * -1) - 1);
+        field = prop.getName();
+      }
+
       if (document.containsField(field)) {
         // SKIP FIELD
-        bytes.skip(OIntegerSerializer.INT_SIZE + 1);
+        if (prop != null && prop.getType() != OType.ANY)
+          bytes.skip(OIntegerSerializer.INT_SIZE);
+        else
+          bytes.skip(OIntegerSerializer.INT_SIZE + 1);
         continue;
       }
 
       final int valuePos = readInteger(bytes);
-      final OType type = readOType(bytes);
+      final OType type;
+      if (prop != null && prop.getType() != OType.ANY)
+        type = prop.getType();
+      else
+        type = readOType(bytes);
 
       if (valuePos != 0) {
@@ -90,9 +115,19 @@ public class ORecordSerializerBinaryV0 implements ODocumentSerializer {
       writeEmptyString(bytes);
     int[] pos = new int[document.fields()];
+    OProperty[] properties = new OProperty[document.fields()];
     int i = 0;
     Entry<String, ?> values[] = new Entry[document.fields()];
     for (Entry<String, Object> entry : document) {
-      writeString(bytes, entry.getKey());
-      pos[i] = bytes.alloc(OIntegerSerializer.INT_SIZE + 1);
+      properties[i] = getSchemaProperty(document, entry.getKey());
+      if (properties[i] != null) {
+        OVarIntSerializer.write(bytes, (properties[i].getId() + 1) * -1);
+        if (properties[i].getType() != OType.ANY)
+          pos[i] = bytes.alloc(OIntegerSerializer.INT_SIZE);
+        else
+          pos[i] = bytes.alloc(OIntegerSerializer.INT_SIZE + 1);
+      } else {
+        writeString(bytes, entry.getKey());
+        pos[i] = bytes.alloc(OIntegerSerializer.INT_SIZE + 1);
+      }
       values[i] = entry;
       i++;
@@ -110,5 +145,6 @@ public class ORecordSerializerBinaryV0 implements ODocumentSerializer {
         pointer = writeSingleValue(bytes, value, type, getLinkedType(document, type, values[i].getKey()));
         OIntegerSerializer.INSTANCE.serialize(pointer, bytes.bytes, pos[i]);
-        writeOType(bytes, (pos[i] + OIntegerSerializer.INT_SIZE), type);
+        if (properties[i] == null || properties[i].getType() == OType.ANY)
+          writeOType(bytes, (pos[i] + OIntegerSerializer.INT_SIZE), type);
       }
     }
@@ -540,4 +576,11 @@ public class ORecordSerializerBinaryV0 implements ODocumentSerializer {
   }
 
+  private OProperty getSchemaProperty(ODocument document, String key) {
+    OClass clazz = document.getSchemaClass();
+    if (clazz != null)
+      return clazz.getProperty(key);
+    return null;
+  }
+
   private OType getFieldType(ODocument document, String key, Object fieldValue) {
     OType type = document.fieldType(key);
",implemented integration of globla property with- binary serialization--
1470,Java,9d3a1f0f0f6f7c1781e7f6b5785e23db6eb5703a,,C,JetBrains,intellij-community,"[1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/platform/lang-impl/src/com/intellij/codeInsight/editorActions/moveUpDown/BaseMoveHandler.java b/platform/lang-impl/src/com/intellij/codeInsight/editorActions/moveUpDown/BaseMoveHandler.java
index 7670facb22ba..6c8cbefcecf7 100644
--- a/platform/lang-impl/src/com/intellij/codeInsight/editorActions/moveUpDown/BaseMoveHandler.java
+++ b/platform/lang-impl/src/com/intellij/codeInsight/editorActions/moveUpDown/BaseMoveHandler.java
@@ -66,5 +66,5 @@ public abstract class BaseMoveHandler extends EditorWriteActionHandler {
     if (range.startLine == 0 && !isDown) return false;
 
-    return range.endLine < maxLine || !isDown;
+    return range.endLine <= maxLine || !isDown;
   }
 
",move statement should be enabled when moving to- the end of file--
1486,Java,8456536126f631d665ffd715dca9ae981588632e,,C,JetBrains,intellij-community,"[3, 6, 8, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/platform/lang-impl/src/com/intellij/codeInsight/lookup/impl/CompletionExtender.java b/platform/lang-impl/src/com/intellij/codeInsight/lookup/impl/CompletionExtender.java
index 9b27fb7ef9fa..9fffaf934164 100644
--- a/platform/lang-impl/src/com/intellij/codeInsight/lookup/impl/CompletionExtender.java
+++ b/platform/lang-impl/src/com/intellij/codeInsight/lookup/impl/CompletionExtender.java
@@ -65,6 +65,5 @@ public class CompletionExtender extends LightweightHint {
 
   private static JComponent createComponent(LookupElement element, LookupImpl lookup) {
-    final LookupCellRenderer renderer = new LookupCellRenderer(lookup);
-    renderer.setFullSize(true);
+    final LookupCellRenderer renderer = ((LookupCellRenderer)lookup.getList().getCellRenderer()).createExtenderRenderer();
     final JComponent component = (JComponent)renderer.getListCellRendererComponent(lookup.getList(), element,
                                                                                    lookup.getList().getSelectedIndex(),
diff --git a/platform/lang-impl/src/com/intellij/codeInsight/lookup/impl/LookupCellRenderer.java b/platform/lang-impl/src/com/intellij/codeInsight/lookup/impl/LookupCellRenderer.java
index c1381a570048..0a5e258a0c14 100644
--- a/platform/lang-impl/src/com/intellij/codeInsight/lookup/impl/LookupCellRenderer.java
+++ b/platform/lang-impl/src/com/intellij/codeInsight/lookup/impl/LookupCellRenderer.java
@@ -63,6 +63,4 @@ public class LookupCellRenderer implements ListCellRenderer {
   private static final Color EMPTY_ITEM_FOREGROUND_COLOR = FOREGROUND_COLOR;
 
-  private static final int MAX_LENGTH = 70;
-
   private final LookupImpl myLookup;
 
@@ -72,10 +70,11 @@ public class LookupCellRenderer implements ListCellRenderer {
   private final JPanel myPanel;
 
-  public static final Color PREFERRED_BACKGROUND_COLOR = new Color(220, 245, 220);
   private static final String ELLIPSIS = ""\u2026"";
-  private boolean myFullSize;
+  private final boolean myFullSize;
   private int myMaxWidth = -1;
 
-  public LookupCellRenderer(LookupImpl lookup) {
+  public LookupCellRenderer(LookupImpl lookup, boolean fullSize) {
+    myFullSize = fullSize;
+
     EditorColorsScheme scheme = lookup.getEditor().getColorsScheme();
     myNormalFont = scheme.getFont(EditorFontType.PLAIN);
@@ -122,5 +121,5 @@ public class LookupCellRenderer implements ListCellRenderer {
     final LookupElement item = (LookupElement)value;
     final Color foreground = isSelected ? SELECTED_FOREGROUND_COLOR : FOREGROUND_COLOR;
-    final Color background = getItemBackground(list, index, isSelected);
+    final Color background = isSelected ? SELECTED_BACKGROUND_COLOR : BACKGROUND_COLOR;
 
     int allowedWidth = list.getWidth() - AFTER_TAIL - AFTER_TYPE - getIconIndent();
@@ -161,8 +160,4 @@ public class LookupCellRenderer implements ListCellRenderer {
   }
 
-  private Color getItemBackground(JList list, int index, boolean isSelected) {
-    return isSelected ? SELECTED_BACKGROUND_COLOR : BACKGROUND_COLOR;
-  }
-
   private void setTailTextLabel(boolean isSelected, LookupElementPresentation presentation, Color foreground, int allowedWidth) {
     final Color fg = getTailTextColor(isSelected, presentation, foreground);
@@ -183,8 +178,4 @@ public class LookupCellRenderer implements ListCellRenderer {
   }
 
-  public void setFullSize(boolean fullSize) {
-    myFullSize = fullSize;
-  }
-
   private static String trimLabelText(@Nullable String text, int maxWidth, FontMetrics metrics) {
     if (text == null || StringUtil.isEmpty(text)) {
@@ -336,4 +327,10 @@ public class LookupCellRenderer implements ListCellRenderer {
   }
 
+  public LookupCellRenderer createExtenderRenderer() {
+    LookupCellRenderer renderer = new LookupCellRenderer(myLookup, true);
+    renderer.myEmptyIcon = myEmptyIcon;
+    return renderer;
+  }
+
   public int getIconIndent() {
     return myNameComponent.getIconTextGap() + myEmptyIcon.getIconWidth();
diff --git a/platform/lang-impl/src/com/intellij/codeInsight/lookup/impl/LookupImpl.java b/platform/lang-impl/src/com/intellij/codeInsight/lookup/impl/LookupImpl.java
index 9534a81cf2b4..c4ce0492a960 100644
--- a/platform/lang-impl/src/com/intellij/codeInsight/lookup/impl/LookupImpl.java
+++ b/platform/lang-impl/src/com/intellij/codeInsight/lookup/impl/LookupImpl.java
@@ -162,5 +162,5 @@ public class LookupImpl extends LightweightHint implements LookupEx, Disposable
 
     myIconPanel.setVisible(false);
-    myCellRenderer = new LookupCellRenderer(this);
+    myCellRenderer = new LookupCellRenderer(this, false);
     myList.setCellRenderer(myCellRenderer);
 
",correctly-sized icon in completion extender--
1487,Java,b792e33fdb52d83b0ce13bf2eaa98c0242bce157,,A,JetBrains,intellij-community,"[2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/EDIDE/src/ru/compscicenter/edide/StudyTaskManager.java b/EDIDE/src/ru/compscicenter/edide/StudyTaskManager.java
index b8d72745c911..4335b5b1a4f0 100644
--- a/EDIDE/src/ru/compscicenter/edide/StudyTaskManager.java
+++ b/EDIDE/src/ru/compscicenter/edide/StudyTaskManager.java
@@ -116,4 +116,5 @@ public class StudyTaskManager implements ProjectComponent, PersistentStateCompon
               addShortcut(PrevWindowAction.SHORTCUT, PrevWindowAction.ACTION_ID);
               addShortcut(ShowHintAction.SHORTCUT, ShowHintAction.ACTION_ID);
+              addShortcut(NextWindowAction.SHORTCUT2, NextWindowAction.ACTION_ID);
             }
           }
diff --git a/EDIDE/src/ru/compscicenter/edide/actions/NextWindowAction.java b/EDIDE/src/ru/compscicenter/edide/actions/NextWindowAction.java
index 1053f1be54ed..7f91b90ec5cb 100644
--- a/EDIDE/src/ru/compscicenter/edide/actions/NextWindowAction.java
+++ b/EDIDE/src/ru/compscicenter/edide/actions/NextWindowAction.java
@@ -20,4 +20,5 @@ public class NextWindowAction extends DumbAwareAction {
   public static final String ACTION_ID = ""NextWindow"";
   public static final String SHORTCUT = ""ctrl pressed PERIOD"";
+  public static final String SHORTCUT2 = ""ctrl pressed ENTER"";
 
   public void actionPerformed(AnActionEvent e) {
",added additional shortcut--
1495,Java,ebece5174a5ab834576c0f981682b78f7a6efe25,,A,apache,camel,"[2, 27, 1, 26, 16, 0, 2, 2, 36, 0, 0, 22, 0, 0, 40, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/camel-core/src/main/java/org/apache/camel/processor/idempotent/FileIdempotentRepository.java b/camel-core/src/main/java/org/apache/camel/processor/idempotent/FileIdempotentRepository.java
index 776c5e3debf..d56f6c290bf 100644
--- a/camel-core/src/main/java/org/apache/camel/processor/idempotent/FileIdempotentRepository.java
+++ b/camel-core/src/main/java/org/apache/camel/processor/idempotent/FileIdempotentRepository.java
@@ -22,4 +22,5 @@ import java.io.IOException;
 import java.util.Map;
 import java.util.Scanner;
+import java.util.concurrent.atomic.AtomicBoolean;
 
 import org.apache.camel.spi.IdempotentRepository;
@@ -41,11 +42,16 @@ public class FileIdempotentRepository implements IdempotentRepository<String> {
     private static final String STORE_DELIMITER = ""\n"";
     private Map<String, Object> cache;
-    private File store;
-    private long maxStoreSize = 1024 * 1000L; // 1mb store file
+    private File fileStore;
+    private long maxFileStoreSize = 1024 * 1000L; // 1mb store file
+    private AtomicBoolean init = new AtomicBoolean();
 
-    public FileIdempotentRepository(final File store, final Map<String, Object> set) {
-        this.store = store;
+    public FileIdempotentRepository() {
+        // default use a 1st level cache 
+        this.cache = new LRUCache<String, Object>(1000);
+    }
+
+    public FileIdempotentRepository(File fileStore, Map<String, Object> set) {
+        this.fileStore = fileStore;
         this.cache = set;
-        loadStore();
     }
 
@@ -54,8 +60,8 @@ public class FileIdempotentRepository implements IdempotentRepository<String> {
      * as 1st level cache with a default of 1000 entries in the cache.
      *
-     * @param store  the file store
+     * @param fileStore  the file store
      */
-    public static IdempotentRepository fileIdempotentRepository(File store) {
-        return fileIdempotentRepository(store, 1000);
+    public static IdempotentRepository fileIdempotentRepository(File fileStore) {
+        return fileIdempotentRepository(fileStore, 1000);
     }
 
@@ -64,9 +70,23 @@ public class FileIdempotentRepository implements IdempotentRepository<String> {
      * as 1st level cache.
      *
-     * @param store  the file store
+     * @param fileStore  the file store
      * @param cacheSize  the cache size
      */
-    public static IdempotentRepository fileIdempotentRepository(File store, int cacheSize) {
-        return fileIdempotentRepository(store, new LRUCache<String, Object>(cacheSize));
+    public static IdempotentRepository fileIdempotentRepository(File fileStore, int cacheSize) {
+        return fileIdempotentRepository(fileStore, new LRUCache<String, Object>(cacheSize));
+    }
+
+    /**
+     * Creates a new file based repository using a {@link org.apache.camel.util.LRUCache}
+     * as 1st level cache.
+     *
+     * @param fileStore  the file store
+     * @param cacheSize  the cache size
+     * @param maxFileStoreSize  the max size in bytes for the filestore file 
+     */
+    public static IdempotentRepository fileIdempotentRepository(File fileStore, int cacheSize, long maxFileStoreSize) {
+        FileIdempotentRepository repository = new FileIdempotentRepository(fileStore, new LRUCache<String, Object>(cacheSize));
+        repository.setMaxFileStoreSize(maxFileStoreSize);
+        return repository;
     }
 
@@ -87,9 +107,14 @@ public class FileIdempotentRepository implements IdempotentRepository<String> {
     public boolean add(String messageId) {
         synchronized (cache) {
+            // init store if not loaded before
+            if (init.compareAndSet(false, true)) {
+                loadStore();
+            }
+
             if (cache.containsKey(messageId)) {
                 return false;
             } else {
                 cache.put(messageId, messageId);
-                if (store.length() < maxStoreSize) {
+                if (fileStore.length() < maxFileStoreSize) {
                     // just append to store
                     appendToStore(messageId);
@@ -106,14 +131,18 @@ public class FileIdempotentRepository implements IdempotentRepository<String> {
     public boolean contains(String key) {
         synchronized (cache) {
+            // init store if not loaded before
+            if (init.compareAndSet(false, true)) {
+                loadStore();
+            }
             return cache.containsKey(key);
         }
     }
 
-    public File getStore() {
-        return store;
+    public File getFileStore() {
+        return fileStore;
     }
 
-    public void setStore(File store) {
-        this.store = store;
+    public void setFileStore(File fileStore) {
+        this.fileStore = fileStore;
     }
 
@@ -126,6 +155,6 @@ public class FileIdempotentRepository implements IdempotentRepository<String> {
     }
 
-    public long getMaxStoreSize() {
-        return maxStoreSize;
+    public long getMaxFileStoreSize() {
+        return maxFileStoreSize;
     }
 
@@ -135,6 +164,16 @@ public class FileIdempotentRepository implements IdempotentRepository<String> {
      * The default is 1mb.
      */
-    public void setMaxStoreSize(long maxStoreSize) {
-        this.maxStoreSize = maxStoreSize;
+    public void setMaxFileStoreSize(long maxFileStoreSize) {
+        this.maxFileStoreSize = maxFileStoreSize;
+    }
+
+    /**
+     * Sets the cache size
+     */
+    public void setCacheSize(int size) {
+        if (cache != null) {
+            cache.clear();
+        }
+        cache = new LRUCache<String, Object>(size);
     }
 
@@ -146,9 +185,14 @@ public class FileIdempotentRepository implements IdempotentRepository<String> {
     protected void appendToStore(final String messageId) {
         if (LOG.isDebugEnabled()) {
-            LOG.debug(""Appending "" + messageId + "" to idempotent filestore: "" + store);
+            LOG.debug(""Appending "" + messageId + "" to idempotent filestore: "" + fileStore);
         }
         FileOutputStream fos = null;
         try {
-            fos = new FileOutputStream(store, true);
+            // create store if missing
+            if (!fileStore.exists()) {
+                fileStore.createNewFile();
+            }
+            // append to store
+            fos = new FileOutputStream(fileStore, true);
             fos.write(messageId.getBytes());
             fos.write(STORE_DELIMITER.getBytes());
@@ -166,9 +210,9 @@ public class FileIdempotentRepository implements IdempotentRepository<String> {
     protected void trunkStore() {
         if (LOG.isDebugEnabled()) {
-            LOG.debug(""Trunking idempotent filestore: "" + store);
+            LOG.debug(""Trunking idempotent filestore: "" + fileStore);
         }
         FileOutputStream fos = null;
         try {
-            fos = new FileOutputStream(store);
+            fos = new FileOutputStream(fileStore);
             for (String key : cache.keySet()) {
                 fos.write(key.getBytes());
@@ -187,8 +231,8 @@ public class FileIdempotentRepository implements IdempotentRepository<String> {
     protected void loadStore() {
         if (LOG.isTraceEnabled()) {
-            LOG.trace(""Loading to 1st level cache from idempotent filestore: "" + store);
+            LOG.trace(""Loading to 1st level cache from idempotent filestore: "" + fileStore);
         }
 
-        if (!store.exists()) {
+        if (!fileStore.exists()) {
             return;
         }
@@ -197,5 +241,5 @@ public class FileIdempotentRepository implements IdempotentRepository<String> {
         Scanner scanner = null;
         try {
-            scanner = new Scanner(store);
+            scanner = new Scanner(fileStore);
             scanner.useDelimiter(STORE_DELIMITER);
             while (scanner.hasNextLine()) {
@@ -212,5 +256,5 @@ public class FileIdempotentRepository implements IdempotentRepository<String> {
 
         if (LOG.isDebugEnabled()) {
-            LOG.debug(""Loaded "" + cache.size() + "" to the 1st level cache from idempotent filestore: "" + store);
+            LOG.debug(""Loaded "" + cache.size() + "" to the 1st level cache from idempotent filestore: "" + fileStore);
         }
     }
diff --git a/camel-core/src/main/java/org/apache/camel/processor/idempotent/MemoryIdempotentRepository.java b/camel-core/src/main/java/org/apache/camel/processor/idempotent/MemoryIdempotentRepository.java
index ae22aca8bb7..700f0edb87f 100644
--- a/camel-core/src/main/java/org/apache/camel/processor/idempotent/MemoryIdempotentRepository.java
+++ b/camel-core/src/main/java/org/apache/camel/processor/idempotent/MemoryIdempotentRepository.java
@@ -34,4 +34,8 @@ public class MemoryIdempotentRepository implements IdempotentRepository<String>
     private Map<String, Object> cache;
 
+    public MemoryIdempotentRepository() {
+        this.cache = new LRUCache<String, Object>(1000);
+    }
+
     public MemoryIdempotentRepository(Map<String, Object> set) {
         this.cache = set;
@@ -43,5 +47,5 @@ public class MemoryIdempotentRepository implements IdempotentRepository<String>
      */
     public static IdempotentRepository memoryIdempotentRepository() {
-        return memoryIdempotentRepository(1000);
+        return new MemoryIdempotentRepository();
     }
 
diff --git a/components/camel-spring/src/test/java/org/apache/camel/spring/processor/idempotent/FileConsumerIdempotentTest.java b/components/camel-spring/src/test/java/org/apache/camel/spring/processor/idempotent/FileConsumerIdempotentTest.java
new file mode 100644
index 00000000000..46c038f1f74
--- /dev/null
+++ b/components/camel-spring/src/test/java/org/apache/camel/spring/processor/idempotent/FileConsumerIdempotentTest.java
@@ -0,0 +1,77 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.camel.spring.processor.idempotent;
+
+import java.io.File;
+
+import org.apache.camel.CamelContext;
+import org.apache.camel.ContextTestSupport;
+import org.apache.camel.component.file.FileComponent;
+import org.apache.camel.component.mock.MockEndpoint;
+import org.apache.camel.spi.IdempotentRepository;
+import static org.apache.camel.spring.processor.SpringTestHelper.createSpringCamelContext;
+
+public class FileConsumerIdempotentTest extends ContextTestSupport {
+
+    private IdempotentRepository repo;
+
+    protected CamelContext createCamelContext() throws Exception {
+        return createSpringCamelContext(this, ""org/apache/camel/spring/processor/idempotent/fileConsumerIdempotentTest.xml"");
+    }
+
+    @Override
+    protected void setUp() throws Exception {
+        deleteDirectory(""target/fileidempotent"");
+
+        super.setUp();
+        repo = context.getRegistry().lookup(""fileStore"", IdempotentRepository.class);
+    }
+
+
+    public void testIdempotent() throws Exception {
+        assertFalse(repo.contains(""report.txt""));
+
+        // send a file
+        template.sendBodyAndHeader(""file://target/fileidempotent/"", ""Hello World"", FileComponent.HEADER_FILE_NAME, ""report.txt"");
+
+        // consume the file the first time
+        MockEndpoint mock = getMockEndpoint(""mock:result"");
+        mock.expectedMessageCount(1);
+
+        assertMockEndpointsSatisfied();
+
+        // reset mock and set new expectations
+        mock.reset();
+        mock.expectedMessageCount(0);
+
+        // move file back
+        File file = new File(""target/fileidempotent/done/report.txt"");
+        File renamed = new File(""target/fileidempotent/report.txt"");
+        file = file.getAbsoluteFile();
+        file.renameTo(renamed.getAbsoluteFile());
+
+        // sleep to let the consumer try to poll the file
+        Thread.sleep(2000);
+
+        // should NOT consume the file again, let 2 secs pass to let the consumer try to consume it but it should not
+        assertMockEndpointsSatisfied();
+
+        assertTrue(repo.contains(""report.txt""));
+    }
+
+}
+
diff --git a/components/camel-spring/src/test/resources/org/apache/camel/spring/processor/idempotent/fileConsumerIdempotentTest.xml b/components/camel-spring/src/test/resources/org/apache/camel/spring/processor/idempotent/fileConsumerIdempotentTest.xml
new file mode 100644
index 00000000000..8714d14db6b
--- /dev/null
+++ b/components/camel-spring/src/test/resources/org/apache/camel/spring/processor/idempotent/fileConsumerIdempotentTest.xml
@@ -0,0 +1,44 @@
+<?xml version=""1.0"" encoding=""UTF-8""?>
+<!--
+    Licensed to the Apache Software Foundation (ASF) under one or more
+    contributor license agreements.  See the NOTICE file distributed with
+    this work for additional information regarding copyright ownership.
+    The ASF licenses this file to You under the Apache License, Version 2.0
+    (the ""License""); you may not use this file except in compliance with
+    the License.  You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+    Unless required by applicable law or agreed to in writing, software
+    distributed under the License is distributed on an ""AS IS"" BASIS,
+    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+    See the License for the specific language governing permissions and
+    limitations under the License.
+-->
+<beans xmlns=""http://www.springframework.org/schema/beans""
+       xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+       xsi:schemaLocation=""
+       http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-2.5.xsd
+       http://activemq.apache.org/camel/schema/spring http://activemq.apache.org/camel/schema/spring/camel-spring.xsd
+    "">
+
+    <!-- START SNIPPET: example -->
+    <!-- this is our file based idempotent store configured to use the .filestore.dat as file -->
+    <bean id=""fileStore"" class=""org.apache.camel.processor.idempotent.FileIdempotentRepository"">
+        <!-- the filename for the store -->
+        <property name=""fileStore"" value=""target/fileidempotent/.filestore.dat""/>
+        <!-- the max filesize in bytes for the file. Camel will trunk and flush the cache
+             if the file gets bigger -->
+        <property name=""maxFileStoreSize"" value=""512000""/>
+        <!-- the number of elements in our store -->
+        <property name=""cacheSize"" value=""250""/>
+    </bean>
+
+    <camelContext id=""camel"" xmlns=""http://activemq.apache.org/camel/schema/spring"">
+        <route>
+            <from uri=""file://target/fileidempotent/?idempotent=true&amp;idempotentRepositoryRef=fileStore&amp;moveNamePrefix=done/""/>
+            <to uri=""mock:result""/>
+        </route>
+    </camelContext>
+    <!-- END SNIPPET: example -->
+</beans>
",CAMEL-1099: Added FileIdempotentRepositry--git-svn-id: https://svn.apache.org/repos/asf/activemq/camel/trunk@723291 13f79535-47bb-0310-9956-ffa450edef68-
1503,Java,37a9214ecf57b5c85c866a90a5e1a52cc3092e8e,,A,JetBrains,intellij-community,"[1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/platform/platform-api/src/com/intellij/openapi/roots/impl/FileIndexImplUtil.java b/platform/platform-api/src/com/intellij/openapi/roots/impl/FileIndexImplUtil.java
index 94c2485a5f38..c922e2388dfb 100644
--- a/platform/platform-api/src/com/intellij/openapi/roots/impl/FileIndexImplUtil.java
+++ b/platform/platform-api/src/com/intellij/openapi/roots/impl/FileIndexImplUtil.java
@@ -34,5 +34,5 @@ public class FileIndexImplUtil {
         @Override
         public boolean visitFile(VirtualFile file) {
-          if (!file.isValid() || !filter.accept(file)) return true;
+          if (!file.isValid() || !filter.accept(file)) return false;
 
           if (!iterator.processFile(file)) throw new StopItException();
",symlink support in vfs & SOE protection--
1504,Java,90a5181501cbcf506c34a7870220f6f9a18b30df,,P,apache,hadoop,"[16, 166, 797, 93, 17, 69, 18, 4, 9, 16, 12, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 1, 0, 4, 8]","diff --git a/hadoop-mapreduce-project/CHANGES.txt b/hadoop-mapreduce-project/CHANGES.txt
index c27e0a96292..135aba975b9 100644
--- a/hadoop-mapreduce-project/CHANGES.txt
+++ b/hadoop-mapreduce-project/CHANGES.txt
@@ -264,4 +264,7 @@ Release 0.23.0 - Unreleased
     mahadev)
 
+    MAPREDUCE-2899. Replace major parts of ApplicationSubmissionContext with a 
+    ContainerLaunchContext (Arun Murthy via mahadev)
+
   OPTIMIZATIONS
 
diff --git a/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskAttemptImpl.java b/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskAttemptImpl.java
index 3d4dcb5ed0e..17cef5a26a6 100644
--- a/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskAttemptImpl.java
+++ b/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskAttemptImpl.java
@@ -580,11 +580,10 @@ private ContainerLaunchContext createContainerLaunchContext() {
       // //////////// End of JobConf setup
 
-      
       // Setup DistributedCache
-      setupDistributedCache(remoteFS, conf, localResources, environment);
+      MRApps.setupDistributedCache(conf, localResources, environment);
 
       // Set local-resources and environment
       container.setLocalResources(localResources);
-      container.setEnv(environment);
+      container.setEnvironment(environment);
       
       // Setup up tokens
@@ -619,5 +618,5 @@ private ContainerLaunchContext createContainerLaunchContext() {
       container.setServiceData(serviceData);
 
-      MRApps.addToClassPath(container.getEnv(), getInitialClasspath());
+      MRApps.addToClassPath(container.getEnvironment(), getInitialClasspath());
     } catch (IOException e) {
       throw new YarnException(e);
@@ -646,5 +645,5 @@ private ContainerLaunchContext createContainerLaunchContext() {
         workDir.toString(), containerLogDir, childTmpDir, jvmID));
 
-    MapReduceChildJVM.setVMEnv(container.getEnv(), classPaths,
+    MapReduceChildJVM.setVMEnv(container.getEnvironment(), classPaths,
         workDir.toString(), containerLogDir, nmLdLibraryPath, remoteTask,
         localizedApplicationTokensFile);
@@ -657,114 +656,4 @@ private ContainerLaunchContext createContainerLaunchContext() {
   }
 
-  private static long[] parseTimeStamps(String[] strs) {
-    if (null == strs) {
-      return null;
-    }
-    long[] result = new long[strs.length];
-    for(int i=0; i < strs.length; ++i) {
-      result[i] = Long.parseLong(strs[i]);
-    }
-    return result;
-  }
-
-  private void setupDistributedCache(FileSystem remoteFS, 
-      Configuration conf, 
-      Map<String, LocalResource> localResources,
-      Map<String, String> env) 
-  throws IOException {
-    
-    // Cache archives
-    parseDistributedCacheArtifacts(remoteFS, localResources, env, 
-        LocalResourceType.ARCHIVE, 
-        DistributedCache.getCacheArchives(conf), 
-        parseTimeStamps(DistributedCache.getArchiveTimestamps(conf)), 
-        getFileSizes(conf, MRJobConfig.CACHE_ARCHIVES_SIZES), 
-        DistributedCache.getArchiveVisibilities(conf), 
-        DistributedCache.getArchiveClassPaths(conf));
-    
-    // Cache files
-    parseDistributedCacheArtifacts(remoteFS, 
-        localResources, env, 
-        LocalResourceType.FILE, 
-        DistributedCache.getCacheFiles(conf),
-        parseTimeStamps(DistributedCache.getFileTimestamps(conf)),
-        getFileSizes(conf, MRJobConfig.CACHE_FILES_SIZES),
-        DistributedCache.getFileVisibilities(conf),
-        DistributedCache.getFileClassPaths(conf));
-  }
-
-  // TODO - Move this to MR!
-  // Use TaskDistributedCacheManager.CacheFiles.makeCacheFiles(URI[], 
-  // long[], boolean[], Path[], FileType)
-  private void parseDistributedCacheArtifacts(
-      FileSystem remoteFS, 
-      Map<String, LocalResource> localResources,
-      Map<String, String> env,
-      LocalResourceType type,
-      URI[] uris, long[] timestamps, long[] sizes, boolean visibilities[], 
-      Path[] pathsToPutOnClasspath) throws IOException {
-
-    if (uris != null) {
-      // Sanity check
-      if ((uris.length != timestamps.length) || (uris.length != sizes.length) ||
-          (uris.length != visibilities.length)) {
-        throw new IllegalArgumentException(""Invalid specification for "" +
-        		""distributed-cache artifacts of type "" + type + "" :"" +
-        		"" #uris="" + uris.length +
-        		"" #timestamps="" + timestamps.length +
-        		"" #visibilities="" + visibilities.length
-        		);
-      }
-      
-      Map<String, Path> classPaths = new HashMap<String, Path>();
-      if (pathsToPutOnClasspath != null) {
-        for (Path p : pathsToPutOnClasspath) {
-          p = remoteFS.resolvePath(p.makeQualified(remoteFS.getUri(),
-              remoteFS.getWorkingDirectory()));
-          classPaths.put(p.toUri().getPath().toString(), p);
-        }
-      }
-      for (int i = 0; i < uris.length; ++i) {
-        URI u = uris[i];
-        Path p = new Path(u);
-        p = remoteFS.resolvePath(p.makeQualified(remoteFS.getUri(),
-            remoteFS.getWorkingDirectory()));
-        // Add URI fragment or just the filename
-        Path name = new Path((null == u.getFragment())
-          ? p.getName()
-          : u.getFragment());
-        if (name.isAbsolute()) {
-          throw new IllegalArgumentException(""Resource name must be relative"");
-        }
-        String linkName = name.toUri().getPath();
-        localResources.put(
-            linkName,
-            BuilderUtils.newLocalResource(
-                p.toUri(), type, 
-                visibilities[i]
-                  ? LocalResourceVisibility.PUBLIC
-                  : LocalResourceVisibility.PRIVATE,
-                sizes[i], timestamps[i])
-        );
-        if (classPaths.containsKey(u.getPath())) {
-          MRApps.addToClassPath(env, linkName);
-        }
-      }
-    }
-  }
-  
-  // TODO - Move this to MR!
-  private static long[] getFileSizes(Configuration conf, String key) {
-    String[] strs = conf.getStrings(key);
-    if (strs == null) {
-      return null;
-    }
-    long[] result = new long[strs.length];
-    for(int i=0; i < strs.length; ++i) {
-      result[i] = Long.parseLong(strs[i]);
-    }
-    return result;
-  }
-  
   @Override
   public ContainerId getAssignedContainerID() {
diff --git a/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common/src/main/java/org/apache/hadoop/mapreduce/v2/util/MRApps.java b/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common/src/main/java/org/apache/hadoop/mapreduce/v2/util/MRApps.java
index 5dfa1dcfe46..68499497ac3 100644
--- a/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common/src/main/java/org/apache/hadoop/mapreduce/v2/util/MRApps.java
+++ b/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common/src/main/java/org/apache/hadoop/mapreduce/v2/util/MRApps.java
@@ -26,12 +26,18 @@
 import java.io.InputStream;
 import java.io.InputStreamReader;
+import java.net.URI;
 import java.util.Arrays;
+import java.util.HashMap;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 
+import org.apache.hadoop.classification.InterfaceAudience.Private;
+import org.apache.hadoop.classification.InterfaceStability.Unstable;
 import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.fs.FileSystem;
 import org.apache.hadoop.fs.Path;
 import org.apache.hadoop.mapreduce.MRJobConfig;
+import org.apache.hadoop.mapreduce.filecache.DistributedCache;
 import org.apache.hadoop.mapreduce.v2.MRConstants;
 import org.apache.hadoop.mapreduce.v2.api.records.JobId;
@@ -43,10 +49,16 @@
 import org.apache.hadoop.yarn.YarnException;
 import org.apache.hadoop.yarn.api.records.ApplicationId;
+import org.apache.hadoop.yarn.api.records.LocalResource;
+import org.apache.hadoop.yarn.api.records.LocalResourceType;
+import org.apache.hadoop.yarn.api.records.LocalResourceVisibility;
 import org.apache.hadoop.yarn.factory.providers.RecordFactoryProvider;
 import org.apache.hadoop.yarn.util.Apps;
+import org.apache.hadoop.yarn.util.BuilderUtils;
 
 /**
  * Helper class for MR applications
  */
+@Private
+@Unstable
 public class MRApps extends Apps {
   public static final String JOB = ""job"";
@@ -233,3 +245,120 @@ public static String getJobFile(Configuration conf, String user,
     return jobFile.toString();
   }
+  
+
+
+  private static long[] parseTimeStamps(String[] strs) {
+    if (null == strs) {
+      return null;
+    }
+    long[] result = new long[strs.length];
+    for(int i=0; i < strs.length; ++i) {
+      result[i] = Long.parseLong(strs[i]);
+    }
+    return result;
+  }
+
+  public static void setupDistributedCache( 
+      Configuration conf, 
+      Map<String, LocalResource> localResources,
+      Map<String, String> env) 
+  throws IOException {
+    
+    // Cache archives
+    parseDistributedCacheArtifacts(conf, localResources, env, 
+        LocalResourceType.ARCHIVE, 
+        DistributedCache.getCacheArchives(conf), 
+        parseTimeStamps(DistributedCache.getArchiveTimestamps(conf)), 
+        getFileSizes(conf, MRJobConfig.CACHE_ARCHIVES_SIZES), 
+        DistributedCache.getArchiveVisibilities(conf), 
+        DistributedCache.getArchiveClassPaths(conf));
+    
+    // Cache files
+    parseDistributedCacheArtifacts(conf, 
+        localResources, env, 
+        LocalResourceType.FILE, 
+        DistributedCache.getCacheFiles(conf),
+        parseTimeStamps(DistributedCache.getFileTimestamps(conf)),
+        getFileSizes(conf, MRJobConfig.CACHE_FILES_SIZES),
+        DistributedCache.getFileVisibilities(conf),
+        DistributedCache.getFileClassPaths(conf));
+  }
+
+  // TODO - Move this to MR!
+  // Use TaskDistributedCacheManager.CacheFiles.makeCacheFiles(URI[], 
+  // long[], boolean[], Path[], FileType)
+  private static void parseDistributedCacheArtifacts(
+      Configuration conf,
+      Map<String, LocalResource> localResources,
+      Map<String, String> env,
+      LocalResourceType type,
+      URI[] uris, long[] timestamps, long[] sizes, boolean visibilities[], 
+      Path[] pathsToPutOnClasspath) throws IOException {
+
+    if (uris != null) {
+      // Sanity check
+      if ((uris.length != timestamps.length) || (uris.length != sizes.length) ||
+          (uris.length != visibilities.length)) {
+        throw new IllegalArgumentException(""Invalid specification for "" +
+            ""distributed-cache artifacts of type "" + type + "" :"" +
+            "" #uris="" + uris.length +
+            "" #timestamps="" + timestamps.length +
+            "" #visibilities="" + visibilities.length
+            );
+      }
+      
+      Map<String, Path> classPaths = new HashMap<String, Path>();
+      if (pathsToPutOnClasspath != null) {
+        for (Path p : pathsToPutOnClasspath) {
+          FileSystem remoteFS = p.getFileSystem(conf);
+          p = remoteFS.resolvePath(p.makeQualified(remoteFS.getUri(),
+              remoteFS.getWorkingDirectory()));
+          classPaths.put(p.toUri().getPath().toString(), p);
+        }
+      }
+      for (int i = 0; i < uris.length; ++i) {
+        URI u = uris[i];
+        Path p = new Path(u);
+        FileSystem remoteFS = p.getFileSystem(conf);
+        p = remoteFS.resolvePath(p.makeQualified(remoteFS.getUri(),
+            remoteFS.getWorkingDirectory()));
+        // Add URI fragment or just the filename
+        Path name = new Path((null == u.getFragment())
+          ? p.getName()
+          : u.getFragment());
+        if (name.isAbsolute()) {
+          throw new IllegalArgumentException(""Resource name must be relative"");
+        }
+        String linkName = name.toUri().getPath();
+        localResources.put(
+            linkName,
+            BuilderUtils.newLocalResource(
+                p.toUri(), type, 
+                visibilities[i]
+                  ? LocalResourceVisibility.PUBLIC
+                  : LocalResourceVisibility.PRIVATE,
+                sizes[i], timestamps[i])
+        );
+        if (classPaths.containsKey(u.getPath())) {
+          MRApps.addToClassPath(env, linkName);
+        }
+      }
+    }
+  }
+  
+  // TODO - Move this to MR!
+  private static long[] getFileSizes(Configuration conf, String key) {
+    String[] strs = conf.getStrings(key);
+    if (strs == null) {
+      return null;
+    }
+    long[] result = new long[strs.length];
+    for(int i=0; i < strs.length; ++i) {
+      result[i] = Long.parseLong(strs[i]);
+    }
+    return result;
+  }
+  
+
+
 }
diff --git a/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java b/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java
index fa167a0acf1..37516460103 100644
--- a/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java
+++ b/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java
@@ -20,5 +20,4 @@
 
 import java.io.IOException;
-import java.net.URI;
 import java.nio.ByteBuffer;
 import java.util.ArrayList;
@@ -34,5 +33,4 @@
 import org.apache.hadoop.fs.FileContext;
 import org.apache.hadoop.fs.FileStatus;
-import org.apache.hadoop.fs.FileSystem;
 import org.apache.hadoop.fs.Path;
 import org.apache.hadoop.fs.UnsupportedFileSystemException;
@@ -56,5 +54,4 @@
 import org.apache.hadoop.mapreduce.TaskType;
 import org.apache.hadoop.mapreduce.TypeConverter;
-import org.apache.hadoop.mapreduce.filecache.DistributedCache;
 import org.apache.hadoop.mapreduce.protocol.ClientProtocol;
 import org.apache.hadoop.mapreduce.security.token.delegation.DelegationTokenIdentifier;
@@ -73,4 +70,5 @@
 import org.apache.hadoop.yarn.api.records.ApplicationState;
 import org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext;
+import org.apache.hadoop.yarn.api.records.ContainerLaunchContext;
 import org.apache.hadoop.yarn.api.records.LocalResource;
 import org.apache.hadoop.yarn.api.records.LocalResourceType;
@@ -238,5 +236,4 @@ public JobStatus submitJob(JobID jobId, String jobSubmitDir, Credentials ts)
     ApplicationSubmissionContext appContext = 
       createApplicationSubmissionContext(conf, jobSubmitDir, ts);
-    setupDistributedCache(conf, appContext);
     
     // XXX Remove
@@ -274,14 +271,16 @@ public ApplicationSubmissionContext createApplicationSubmissionContext(
       Configuration jobConf,
       String jobSubmitDir, Credentials ts) throws IOException {
-    ApplicationSubmissionContext appContext =
-        recordFactory.newRecordInstance(ApplicationSubmissionContext.class);
     ApplicationId applicationId = resMgrDelegate.getApplicationId();
-    appContext.setApplicationId(applicationId);
+    
+    // Setup resource requirements
     Resource capability = recordFactory.newRecordInstance(Resource.class);
     capability.setMemory(conf.getInt(MRJobConfig.MR_AM_VMEM_MB,
         MRJobConfig.DEFAULT_MR_AM_VMEM_MB));
     LOG.info(""AppMaster capability = "" + capability);
-    appContext.setMasterCapability(capability);
 
+    // Setup LocalResources
+    Map<String, LocalResource> localResources =
+        new HashMap<String, LocalResource>();
+    
     Path jobConfPath = new Path(jobSubmitDir, MRConstants.JOB_CONF_FILE);
     
@@ -293,12 +292,9 @@ public ApplicationSubmissionContext createApplicationSubmissionContext(
         + yarnUrlForJobSubmitDir);
 
-    appContext.setResource(MRConstants.JOB_SUBMIT_DIR,
-        yarnUrlForJobSubmitDir);
-
-    appContext.setResourceTodo(MRConstants.JOB_CONF_FILE,
+    localResources.put(MRConstants.JOB_CONF_FILE,
         createApplicationResource(defaultFileContext,
             jobConfPath));
     if (jobConf.get(MRJobConfig.JAR) != null) {
-      appContext.setResourceTodo(MRConstants.JOB_JAR,
+      localResources.put(MRConstants.JOB_JAR,
           createApplicationResource(defaultFileContext,
               new Path(jobSubmitDir, MRConstants.JOB_JAR)));
@@ -313,28 +309,19 @@ public ApplicationSubmissionContext createApplicationSubmissionContext(
     for (String s : new String[] { ""job.split"", ""job.splitmetainfo"",
         MRConstants.APPLICATION_TOKENS_FILE }) {
-      appContext.setResourceTodo(
+      localResources.put(
           MRConstants.JOB_SUBMIT_DIR + ""/"" + s,
-          createApplicationResource(defaultFileContext, new Path(jobSubmitDir, s)));
+          createApplicationResource(defaultFileContext, 
+              new Path(jobSubmitDir, s)));
     }
-
-    // TODO: Only if security is on.
-    List<String> fsTokens = new ArrayList<String>();
-    for (Token<? extends TokenIdentifier> token : ts.getAllTokens()) {
-      fsTokens.add(token.encodeToUrlString());
-    }
-    
-    // TODO - Remove this!
-    appContext.addAllFsTokens(fsTokens);
-    DataOutputBuffer dob = new DataOutputBuffer();
-    ts.writeTokenStorageToStream(dob);
-    appContext.setFsTokensTodo(ByteBuffer.wrap(dob.getData(), 0, dob.getLength()));
-
-    // Add queue information
-    appContext.setQueue(jobConf.get(JobContext.QUEUE_NAME, JobConf.DEFAULT_QUEUE_NAME));
-    
-    // Add job name
-    appContext.setApplicationName(jobConf.get(JobContext.JOB_NAME, ""N/A""));
     
-    // Add the command line
+    // Setup security tokens
+    ByteBuffer securityTokens = null;
+    if (UserGroupInformation.isSecurityEnabled()) {
+      DataOutputBuffer dob = new DataOutputBuffer();
+      ts.writeTokenStorageToStream(dob);
+      securityTokens = ByteBuffer.wrap(dob.getData(), 0, dob.getLength());
+    }
+
+    // Setup the command to run the AM
     String javaHome = ""$JAVA_HOME"";
     Vector<CharSequence> vargs = new Vector<CharSequence>(8);
@@ -347,11 +334,4 @@ public ApplicationSubmissionContext createApplicationSubmissionContext(
         MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS));
 
-    // Add { job jar, MR app jar } to classpath.
-    Map<String, String> environment = new HashMap<String, String>();
-    MRApps.setInitialClasspath(environment);
-    MRApps.addToClassPath(environment, MRConstants.JOB_JAR);
-    MRApps.addToClassPath(environment,
-        MRConstants.YARN_MAPREDUCE_APP_JAR_PATH);
-    appContext.addAllEnvironment(environment);
     vargs.add(""org.apache.hadoop.mapreduce.v2.app.MRAppMaster"");
     vargs.add(String.valueOf(applicationId.getClusterTimestamp()));
@@ -371,138 +351,41 @@ public ApplicationSubmissionContext createApplicationSubmissionContext(
     LOG.info(""Command to launch container for ApplicationMaster is : ""
         + mergedCommand);
+    
+    // Setup the environment - Add { job jar, MR app jar } to classpath.
+    Map<String, String> environment = new HashMap<String, String>();
+    MRApps.setInitialClasspath(environment);
+    MRApps.addToClassPath(environment, MRConstants.JOB_JAR);
+    MRApps.addToClassPath(environment,
+        MRConstants.YARN_MAPREDUCE_APP_JAR_PATH);
 
-    appContext.addAllCommands(vargsFinal);
-    // TODO: RM should get this from RPC.
-    appContext.setUser(UserGroupInformation.getCurrentUser().getShortUserName());
-    return appContext;
-  }
+    // Parse distributed cache
+    MRApps.setupDistributedCache(jobConf, localResources, environment);
 
-  /**
-   *    * TODO: Copied for now from TaskAttemptImpl.java ... fixme
-   * @param strs
-   * @return
-   */
-  private static long[] parseTimeStamps(String[] strs) {
-    if (null == strs) {
-      return null;
-    }
-    long[] result = new long[strs.length];
-    for(int i=0; i < strs.length; ++i) {
-      result[i] = Long.parseLong(strs[i]);
-    }
-    return result;
-  }
+    // Setup ContainerLaunchContext for AM container
+    ContainerLaunchContext amContainer =
+        recordFactory.newRecordInstance(ContainerLaunchContext.class);
+    amContainer.setResource(capability);             // Resource (mem) required
+    amContainer.setLocalResources(localResources);   // Local resources
+    amContainer.setEnvironment(environment);         // Environment
+    amContainer.setCommands(vargsFinal);             // Command for AM
+    amContainer.setContainerTokens(securityTokens);  // Security tokens
 
-  /**
-   * TODO: Copied for now from TaskAttemptImpl.java ... fixme
-   * 
-   * TODO: This is currently needed in YarnRunner as user code like setupJob,
-   * cleanupJob may need access to dist-cache. Once we separate distcache for
-   * maps, reduces, setup etc, this can include only a subset of artificats.
-   * This is also needed for uberAM case where we run everything inside AM.
-   */
-  private void setupDistributedCache(Configuration conf, 
-      ApplicationSubmissionContext container) throws IOException {
-    
-    // Cache archives
-    parseDistributedCacheArtifacts(conf, container, LocalResourceType.ARCHIVE, 
-        DistributedCache.getCacheArchives(conf), 
-        parseTimeStamps(DistributedCache.getArchiveTimestamps(conf)), 
-        getFileSizes(conf, MRJobConfig.CACHE_ARCHIVES_SIZES), 
-        DistributedCache.getArchiveVisibilities(conf), 
-        DistributedCache.getArchiveClassPaths(conf));
-    
-    // Cache files
-    parseDistributedCacheArtifacts(conf, container, LocalResourceType.FILE, 
-        DistributedCache.getCacheFiles(conf),
-        parseTimeStamps(DistributedCache.getFileTimestamps(conf)),
-        getFileSizes(conf, MRJobConfig.CACHE_FILES_SIZES),
-        DistributedCache.getFileVisibilities(conf),
-        DistributedCache.getFileClassPaths(conf));
-  }
-
-  // TODO - Move this to MR!
-  // Use TaskDistributedCacheManager.CacheFiles.makeCacheFiles(URI[], long[], boolean[], Path[], FileType)
-  private void parseDistributedCacheArtifacts(Configuration conf,
-      ApplicationSubmissionContext container, LocalResourceType type,
-      URI[] uris, long[] timestamps, long[] sizes, boolean visibilities[], 
-      Path[] pathsToPutOnClasspath) throws IOException {
-
-    if (uris != null) {
-      // Sanity check
-      if ((uris.length != timestamps.length) || (uris.length != sizes.length) ||
-          (uris.length != visibilities.length)) {
-        throw new IllegalArgumentException(""Invalid specification for "" +
-            ""distributed-cache artifacts of type "" + type + "" :"" +
-            "" #uris="" + uris.length +
-            "" #timestamps="" + timestamps.length +
-            "" #visibilities="" + visibilities.length
-            );
-      }
-      
-      Map<String, Path> classPaths = new HashMap<String, Path>();
-      if (pathsToPutOnClasspath != null) {
-        for (Path p : pathsToPutOnClasspath) {
-          FileSystem fs = p.getFileSystem(conf);
-          p = p.makeQualified(fs.getUri(), fs.getWorkingDirectory());
-          classPaths.put(p.toUri().getPath().toString(), p);
-        }
-      }
-      for (int i = 0; i < uris.length; ++i) {
-        URI u = uris[i];
-        Path p = new Path(u);
-        FileSystem fs = p.getFileSystem(conf);
-        p = fs.resolvePath(
-            p.makeQualified(fs.getUri(), fs.getWorkingDirectory()));
-        // Add URI fragment or just the filename
-        Path name = new Path((null == u.getFragment())
-          ? p.getName()
-          : u.getFragment());
-        if (name.isAbsolute()) {
-          throw new IllegalArgumentException(""Resource name must be relative"");
-        }
-        String linkName = name.toUri().getPath();
-        container.setResourceTodo(
-            linkName,
-            createLocalResource(
-                p.toUri(), type, 
-                visibilities[i]
-                  ? LocalResourceVisibility.PUBLIC
-                  : LocalResourceVisibility.PRIVATE,
-                sizes[i], timestamps[i])
-        );
-        if (classPaths.containsKey(u.getPath())) {
-          Map<String, String> environment = container.getAllEnvironment();
-          MRApps.addToClassPath(environment, linkName);
-        }
-      }
-    }
-  }
+    // Set up the ApplicationSubmissionContext
+    ApplicationSubmissionContext appContext =
+        recordFactory.newRecordInstance(ApplicationSubmissionContext.class);
+    appContext.setApplicationId(applicationId);                // ApplicationId
+    appContext.setUser(                                        // User name
+        UserGroupInformation.getCurrentUser().getShortUserName());
+    appContext.setQueue(                                       // Queue name
+        jobConf.get(JobContext.QUEUE_NAME,     
+        YarnConfiguration.DEFAULT_QUEUE_NAME));
+    appContext.setApplicationName(                             // Job name
+        jobConf.get(JobContext.JOB_NAME, 
+        YarnConfiguration.DEFAULT_APPLICATION_NAME));              
+    appContext.setAMContainerSpec(amContainer);         // AM Container 
 
-  // TODO - Move this to MR!
-  private static long[] getFileSizes(Configuration conf, String key) {
-    String[] strs = conf.getStrings(key);
-    if (strs == null) {
-      return null;
-    }
-    long[] result = new long[strs.length];
-    for(int i=0; i < strs.length; ++i) {
-      result[i] = Long.parseLong(strs[i]);
-    }
-    return result;
-  }
-  
-  private LocalResource createLocalResource(URI uri, 
-      LocalResourceType type, LocalResourceVisibility visibility, 
-      long size, long timestamp) throws IOException {
-    LocalResource resource = RecordFactoryProvider.getRecordFactory(null).newRecordInstance(LocalResource.class);
-    resource.setResource(ConverterUtils.getYarnUrlFromURI(uri));
-    resource.setType(type);
-    resource.setVisibility(visibility);
-    resource.setSize(size);
-    resource.setTimestamp(timestamp);
-    return resource;
+    return appContext;
   }
-  
+
   @Override
   public void setJobPriority(JobID arg0, String arg1) throws IOException,
diff --git a/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/api/records/ApplicationSubmissionContext.java b/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/api/records/ApplicationSubmissionContext.java
index 46511ca0d27..0f1243fd9fb 100644
--- a/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/api/records/ApplicationSubmissionContext.java
+++ b/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/api/records/ApplicationSubmissionContext.java
@@ -19,12 +19,6 @@
 package org.apache.hadoop.yarn.api.records;
 
-import java.nio.ByteBuffer;
-import java.util.List;
-import java.util.Map;
-
-import org.apache.hadoop.classification.InterfaceAudience.Private;
 import org.apache.hadoop.classification.InterfaceAudience.Public;
 import org.apache.hadoop.classification.InterfaceStability.Stable;
-import org.apache.hadoop.classification.InterfaceStability.Unstable;
 import org.apache.hadoop.yarn.api.ClientRMProtocol;
 
@@ -37,24 +31,15 @@
  *   <ul>
  *     <li>{@link ApplicationId} of the application.</li>
- *     <li>
- *       {@link Resource} necessary to run the <code>ApplicationMaster</code>.
- *     </li>
  *     <li>Application user.</li>
  *     <li>Application name.</li>
  *     <li>{@link Priority} of the application.</li>
- *     <li>Security tokens (if security is enabled).</li>
- *     <li>
- *       {@link LocalResource} necessary for running the 
- *       <code>ApplicationMaster</code> container such
- *       as binaries, jar, shared-objects, side-files etc. 
- *     </li>
  *     <li>
- *       Environment variables for the launched <code>ApplicationMaster</code> 
- *       process.
+ *       {@link ContainerLaunchContext} of the container in which the 
+ *       <code>ApplicationMaster</code> is executed.
  *     </li>
- *     <li>Command to launch the <code>ApplicationMaster</code>.</li>
  *   </ul>
  * </p>
  * 
+ * @see ContainerLaunchContext
  * @see ClientRMProtocol#submitApplication(org.apache.hadoop.yarn.api.protocolrecords.SubmitApplicationRequest)
  */
@@ -144,197 +129,24 @@
   
   /**
-   * Get the <code>Resource</code> required to run the 
-   * <code>ApplicationMaster</code>.
-   * @return <code>Resource</code> required to run the 
-   *         <code>ApplicationMaster</code>
-   */
-  @Public
-  @Stable
-  public Resource getMasterCapability();
-  
-  /**
-   * Set <code>Resource</code> required to run the 
-   * <code>ApplicationMaster</code>.
-   * @param masterCapability <code>Resource</code> required to run the 
-   *                         <code>ApplicationMaster</code>
-   */
-  @Public
-  @Stable
-  public void setMasterCapability(Resource masterCapability);
-  
-  @Private
-  @Unstable
-  public Map<String, URL> getAllResources();
-  
-  @Private
-  @Unstable
-  public URL getResource(String key);
-  
-  @Private
-  @Unstable
-  public void addAllResources(Map<String, URL> resources);
-
-  @Private
-  @Unstable
-  public void setResource(String key, URL url);
-
-  @Private
-  @Unstable
-  public void removeResource(String key);
-
-  @Private
-  @Unstable
-  public void clearResources();
-
-  /**
-   * Get all the <code>LocalResource</code> required to run the 
-   * <code>ApplicationMaster</code>.
-   * @return <code>LocalResource</code> required to run the 
-   *         <code>ApplicationMaster</code>
-   */
-  @Public
-  @Stable
-  public Map<String, LocalResource> getAllResourcesTodo();
-  
-  @Private
-  @Unstable
-  public LocalResource getResourceTodo(String key);
-  
-  /**
-   * Add all the <code>LocalResource</code> required to run the 
-   * <code>ApplicationMaster</code>.
-   * @param resources all <code>LocalResource</code> required to run the 
-   *                      <code>ApplicationMaster</code>
-   */
-  @Public
-  @Stable
-  public void addAllResourcesTodo(Map<String, LocalResource> resources);
-
-  @Private
-  @Unstable
-  public void setResourceTodo(String key, LocalResource localResource);
-
-  @Private
-  @Unstable
-  public void removeResourceTodo(String key);
-
-  @Private
-  @Unstable
-  public void clearResourcesTodo();
-
-  @Private
-  @Unstable
-  public List<String> getFsTokenList();
-  
-  @Private
-  @Unstable
-  public String getFsToken(int index);
-  
-  @Private
-  @Unstable
-  public int getFsTokenCount();
-  
-  @Private
-  @Unstable
-  public void addAllFsTokens(List<String> fsTokens);
-
-  @Private
-  @Unstable
-  public void addFsToken(String fsToken);
-
-  @Private
-  @Unstable
-  public void removeFsToken(int index);
-
-  @Private
-  @Unstable
-  public void clearFsTokens();
-
-  /**
-   * Get <em>file-system tokens</em> for the <code>ApplicationMaster</code>.
-   * @return file-system tokens for the <code>ApplicationMaster</code>
-   */
-  @Public
-  @Stable
-  public ByteBuffer getFsTokensTodo();
-  
-  /**
-   * Set <em>file-system tokens</em> for the <code>ApplicationMaster</code>.
-   * @param fsTokens file-system tokens for the <code>ApplicationMaster</code>
+   * Get the <code>ContainerLaunchContext</code> to describe the 
+   * <code>Container</code> with which the <code>ApplicationMaster</code> is
+   * launched.
+   * @return <code>ContainerLaunchContext</code> for the 
+   *         <code>ApplicationMaster</code> container
    */
   @Public
   @Stable
-  public void setFsTokensTodo(ByteBuffer fsTokens);
-
-  /**
-   * Get the <em>environment variables</em> for the 
-   * <code>ApplicationMaster</code>.
-   * @return environment variables for the <code>ApplicationMaster</code>
-   */
-  @Public
-  @Stable
-  public Map<String, String> getAllEnvironment();
-  
-  @Private
-  @Unstable
-  public String getEnvironment(String key);
+  public ContainerLaunchContext getAMContainerSpec();
   
   /**
-   * Add all of the <em>environment variables</em> for the 
-   * <code>ApplicationMaster</code>.
-   * @param environment environment variables for the 
-   *                    <code>ApplicationMaster</code>
+   * Set the <code>ContainerLaunchContext</code> to describe the 
+   * <code>Container</code> with which the <code>ApplicationMaster</code> is
+   * launched.
+   * @param amContainer <code>ContainerLaunchContext</code> for the 
+   *                    <code>ApplicationMaster</code> container
    */
   @Public
   @Stable
-  public void addAllEnvironment(Map<String, String> environment);
+  public void setAMContainerSpec(ContainerLaunchContext amContainer);
 
-  @Private
-  @Unstable
-  public void setEnvironment(String key, String env);
-
-  @Private
-  @Unstable
-  public void removeEnvironment(String key);
-
-  @Private
-  @Unstable
-  public void clearEnvironment();
-
-  /**
-   * Get the <em>commands</em> to launch the <code>ApplicationMaster</code>.
-   * @return commands to launch the <code>ApplicationMaster</code>
-   */
-  @Public
-  @Stable
-  public List<String> getCommandList();
-  
-  @Private
-  @Unstable
-  public String getCommand(int index);
-  
-  @Private
-  @Unstable
-  public int getCommandCount();
-  
-  /**
-   * Add all of the <em>commands</em> to launch the 
-   * <code>ApplicationMaster</code>.
-   * @param commands commands to launch the <code>ApplicationMaster</code>
-   */
-  @Public
-  @Stable
-  public void addAllCommands(List<String> commands);
-  
-  @Private
-  @Unstable
-  public void addCommand(String command);
-  
-  @Private
-  @Unstable
-  public void removeCommand(int index);
-  
-  @Private
-  @Unstable
-  public void clearCommands();
 }
\ No newline at end of file
diff --git a/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/api/records/ContainerLaunchContext.java b/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/api/records/ContainerLaunchContext.java
index 0339df9af1f..52452b54e11 100644
--- a/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/api/records/ContainerLaunchContext.java
+++ b/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/api/records/ContainerLaunchContext.java
@@ -157,5 +157,5 @@
   @Public
   @Stable
-  Map<String, String> getEnv();
+  Map<String, String> getEnvironment();
     
   /**
@@ -165,5 +165,5 @@
   @Public
   @Stable
-  void setEnv(Map<String, String> environment);
+  void setEnvironment(Map<String, String> environment);
 
   /**
diff --git a/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/api/records/impl/pb/ApplicationSubmissionContextPBImpl.java b/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/api/records/impl/pb/ApplicationSubmissionContextPBImpl.java
index 2b4841888a7..1f8b5c24b1f 100644
--- a/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/api/records/impl/pb/ApplicationSubmissionContextPBImpl.java
+++ b/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/api/records/impl/pb/ApplicationSubmissionContextPBImpl.java
@@ -19,48 +19,26 @@
 package org.apache.hadoop.yarn.api.records.impl.pb;
 
-
-import java.nio.ByteBuffer;
-import java.util.ArrayList;
-import java.util.HashMap;
-import java.util.Iterator;
-import java.util.List;
-import java.util.Map;
-
 import org.apache.hadoop.yarn.api.records.ApplicationId;
 import org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext;
-import org.apache.hadoop.yarn.api.records.LocalResource;
+import org.apache.hadoop.yarn.api.records.ContainerLaunchContext;
 import org.apache.hadoop.yarn.api.records.Priority;
 import org.apache.hadoop.yarn.api.records.ProtoBase;
-import org.apache.hadoop.yarn.api.records.Resource;
-import org.apache.hadoop.yarn.api.records.URL;
 import org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto;
 import org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto;
 import org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProtoOrBuilder;
-import org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto;
+import org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto;
 import org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto;
-import org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto;
-import org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto;
-import org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto;
-import org.apache.hadoop.yarn.proto.YarnProtos.StringURLMapProto;
-import org.apache.hadoop.yarn.proto.YarnProtos.URLProto;
-
-
     
-public class ApplicationSubmissionContextPBImpl extends ProtoBase<ApplicationSubmissionContextProto> implements ApplicationSubmissionContext {
-  ApplicationSubmissionContextProto proto = ApplicationSubmissionContextProto.getDefaultInstance();
+public class ApplicationSubmissionContextPBImpl 
+extends ProtoBase<ApplicationSubmissionContextProto> 
+implements ApplicationSubmissionContext {
+  ApplicationSubmissionContextProto proto = 
+      ApplicationSubmissionContextProto.getDefaultInstance();
   ApplicationSubmissionContextProto.Builder builder = null;
   boolean viaProto = false;
   
   private ApplicationId applicationId = null;
-  private Resource masterCapability = null;
-  private Map<String, URL> resources = null;
-  private Map<String, LocalResource> resourcesTodo = null;
-  private List<String> fsTokenList = null;
-  private ByteBuffer fsTokenTodo = null;
-  private Map<String, String> environment = null;
-  private List<String> commandList = null;
   private Priority priority = null;
-  
-  
+  private ContainerLaunchContext amContainer = null;
   
   public ApplicationSubmissionContextPBImpl() {
@@ -68,5 +46,6 @@ public ApplicationSubmissionContextPBImpl() {
   }
 
-  public ApplicationSubmissionContextPBImpl(ApplicationSubmissionContextProto proto) {
+  public ApplicationSubmissionContextPBImpl(
+      ApplicationSubmissionContextProto proto) {
     this.proto = proto;
     viaProto = true;
@@ -84,28 +63,10 @@ private void mergeLocalToBuilder() {
       builder.setApplicationId(convertToProtoFormat(this.applicationId));
     }
-    if (this.masterCapability != null) {
-      builder.setMasterCapability(convertToProtoFormat(this.masterCapability));
-    }
-    if (this.resources != null) {
-      addResourcesToProto();
-    }
-    if (this.resourcesTodo != null) {
-      addResourcesTodoToProto();
-    }
-    if (this.fsTokenList != null) {
-      addFsTokenListToProto();
-    }
-    if (this.fsTokenTodo != null) {
-      builder.setFsTokensTodo(convertToProtoFormat(this.fsTokenTodo));
-    }
-    if (this.environment != null) {
-      addEnvironmentToProto();
-    }
-    if (this.commandList != null) {
-      addCommandsToProto();
-    }
     if (this.priority != null) {
       builder.setPriority(convertToProtoFormat(this.priority));
     }
+    if (this.amContainer != null) {
+      builder.setAmContainerSpec(convertToProtoFormat(this.amContainer));
+    }
   }
 
@@ -146,4 +107,5 @@ public void setPriority(Priority priority) {
     this.priority = priority;
   }
+  
   @Override
   public ApplicationId getApplicationId() {
@@ -166,4 +128,5 @@ public void setApplicationId(ApplicationId applicationId) {
     this.applicationId = applicationId;
   }
+  
   @Override
   public String getApplicationName() {
@@ -184,401 +147,5 @@ public void setApplicationName(String applicationName) {
     builder.setApplicationName((applicationName));
   }
-  @Override
-  public Resource getMasterCapability() {
-    ApplicationSubmissionContextProtoOrBuilder p = viaProto ? proto : builder;
-    if (this.masterCapability != null) {
-      return masterCapability;
-    } // Else via proto
-    if (!p.hasMasterCapability()) {
-      return null;
-    }
-    masterCapability = convertFromProtoFormat(p.getMasterCapability());
-    return this.masterCapability;
-  }
-
-  @Override
-  public void setMasterCapability(Resource masterCapability) {
-    maybeInitBuilder();
-    if (masterCapability == null)
-      builder.clearMasterCapability();
-    this.masterCapability = masterCapability;
-  }
-  @Override
-  public Map<String, URL> getAllResources() {
-    initResources();
-    return this.resources;
-  }
-  @Override
-  public URL getResource(String key) {
-    initResources();
-    return this.resources.get(key);
-  }
-  
-  private void initResources() {
-    if (this.resources != null) {
-      return;
-    }
-    ApplicationSubmissionContextProtoOrBuilder p = viaProto ? proto : builder;
-    List<StringURLMapProto> mapAsList = p.getResourcesList();
-    this.resources = new HashMap<String, URL>();
-    
-    for (StringURLMapProto c : mapAsList) {
-      this.resources.put(c.getKey(), convertFromProtoFormat(c.getValue()));
-    }
-  }
-  
-  @Override
-  public void addAllResources(final Map<String, URL> resources) {
-    if (resources == null)
-      return;
-    initResources();
-    this.resources.putAll(resources);
-  }
-  
-  private void addResourcesToProto() {
-    maybeInitBuilder();
-    builder.clearResources();
-    if (this.resources == null)
-      return;
-    Iterable<StringURLMapProto> iterable = new Iterable<StringURLMapProto>() {
-      
-      @Override
-      public Iterator<StringURLMapProto> iterator() {
-        return new Iterator<StringURLMapProto>() {
-          
-          Iterator<String> keyIter = resources.keySet().iterator();
-          
-          @Override
-          public void remove() {
-            throw new UnsupportedOperationException();
-          }
-          
-          @Override
-          public StringURLMapProto next() {
-            String key = keyIter.next();
-            return StringURLMapProto.newBuilder().setKey(key).setValue(convertToProtoFormat(resources.get(key))).build();
-          }
-          
-          @Override
-          public boolean hasNext() {
-            return keyIter.hasNext();
-          }
-        };
-      }
-    };
-    builder.addAllResources(iterable);
-  }
-  @Override
-  public void setResource(String key, URL val) {
-    initResources();
-    this.resources.put(key, val);
-  }
-  @Override
-  public void removeResource(String key) {
-    initResources();
-    this.resources.remove(key);
-  }
-  @Override
-  public void clearResources() {
-    initResources();
-    this.resources.clear();
-  }
-  @Override
-  public Map<String, LocalResource> getAllResourcesTodo() {
-    initResourcesTodo();
-    return this.resourcesTodo;
-  }
-  @Override
-  public LocalResource getResourceTodo(String key) {
-    initResourcesTodo();
-    return this.resourcesTodo.get(key);
-  }
-  
-  private void initResourcesTodo() {
-    if (this.resourcesTodo != null) {
-      return;
-    }
-    ApplicationSubmissionContextProtoOrBuilder p = viaProto ? proto : builder;
-    List<StringLocalResourceMapProto> mapAsList = p.getResourcesTodoList();
-    this.resourcesTodo = new HashMap<String, LocalResource>();
-    
-    for (StringLocalResourceMapProto c : mapAsList) {
-      this.resourcesTodo.put(c.getKey(), convertFromProtoFormat(c.getValue()));
-    }
-  }
-  
-  @Override
-  public void addAllResourcesTodo(final Map<String, LocalResource> resourcesTodo) {
-    if (resourcesTodo == null) 
-      return;
-    initResourcesTodo();
-    this.resourcesTodo.putAll(resourcesTodo);
-  }
-  
-  private void addResourcesTodoToProto() {
-    maybeInitBuilder();
-    builder.clearResourcesTodo();
-    if (resourcesTodo == null)
-      return;
-    Iterable<StringLocalResourceMapProto> iterable = new Iterable<StringLocalResourceMapProto>() {
-      
-      @Override
-      public Iterator<StringLocalResourceMapProto> iterator() {
-        return new Iterator<StringLocalResourceMapProto>() {
-          
-          Iterator<String> keyIter = resourcesTodo.keySet().iterator();
-          
-          @Override
-          public void remove() {
-            throw new UnsupportedOperationException();
-          }
-          
-          @Override
-          public StringLocalResourceMapProto next() {
-            String key = keyIter.next();
-            return StringLocalResourceMapProto.newBuilder().setKey(key).setValue(convertToProtoFormat(resourcesTodo.get(key))).build();
-          }
-          
-          @Override
-          public boolean hasNext() {
-            return keyIter.hasNext();
-          }
-        };
-      }
-    };
-    builder.addAllResourcesTodo(iterable);
-  }
-  @Override
-  public void setResourceTodo(String key, LocalResource val) {
-    initResourcesTodo();
-    this.resourcesTodo.put(key, val);
-  }
-  @Override
-  public void removeResourceTodo(String key) {
-    initResourcesTodo();
-    this.resourcesTodo.remove(key);
-  }
-  @Override
-  public void clearResourcesTodo() {
-    initResourcesTodo();
-    this.resourcesTodo.clear();
-  }
-  @Override
-  public List<String> getFsTokenList() {
-    initFsTokenList();
-    return this.fsTokenList;
-  }
-  @Override
-  public String getFsToken(int index) {
-    initFsTokenList();
-    return this.fsTokenList.get(index);
-  }
-  @Override
-  public int getFsTokenCount() {
-    initFsTokenList();
-    return this.fsTokenList.size();
-  }
-  
-  private void initFsTokenList() {
-    if (this.fsTokenList != null) {
-      return;
-    }
-    ApplicationSubmissionContextProtoOrBuilder p = viaProto ? proto : builder;
-    List<String> list = p.getFsTokensList();
-    this.fsTokenList = new ArrayList<String>();
-
-    for (String c : list) {
-      this.fsTokenList.add(c);
-    }
-  }
-  
-  @Override
-  public void addAllFsTokens(final List<String> fsTokens) {
-    if (fsTokens == null) 
-      return;
-    initFsTokenList();
-    this.fsTokenList.addAll(fsTokens);
-  }
-  
-  private void addFsTokenListToProto() {
-    maybeInitBuilder();
-    builder.clearFsTokens();
-    builder.addAllFsTokens(this.fsTokenList);
-  }
-
-  @Override
-  public void addFsToken(String fsTokens) {
-    initFsTokenList();
-    this.fsTokenList.add(fsTokens);
-  }
-  @Override
-  public void removeFsToken(int index) {
-    initFsTokenList();
-    this.fsTokenList.remove(index);
-  }
-  @Override
-  public void clearFsTokens() {
-    initFsTokenList();
-    this.fsTokenList.clear();
-  }
-  @Override
-  public ByteBuffer getFsTokensTodo() {
-    ApplicationSubmissionContextProtoOrBuilder p = viaProto ? proto : builder;
-    if (this.fsTokenTodo != null) {
-      return this.fsTokenTodo;
-    }
-    if (!p.hasFsTokensTodo()) {
-      return null;
-    }
-    this.fsTokenTodo = convertFromProtoFormat(p.getFsTokensTodo());
-    return this.fsTokenTodo;
-  }
 
-  @Override
-  public void setFsTokensTodo(ByteBuffer fsTokensTodo) {
-    maybeInitBuilder();
-    if (fsTokensTodo == null) 
-      builder.clearFsTokensTodo();
-    this.fsTokenTodo = fsTokensTodo;
-  }
-  @Override
-  public Map<String, String> getAllEnvironment() {
-    initEnvironment();
-    return this.environment;
-  }
-  @Override
-  public String getEnvironment(String key) {
-    initEnvironment();
-    return this.environment.get(key);
-  }
-  
-  private void initEnvironment() {
-    if (this.environment != null) {
-      return;
-    }
-    ApplicationSubmissionContextProtoOrBuilder p = viaProto ? proto : builder;
-    List<StringStringMapProto> mapAsList = p.getEnvironmentList();
-    this.environment = new HashMap<String, String>();
-    
-    for (StringStringMapProto c : mapAsList) {
-      this.environment.put(c.getKey(), c.getValue());
-    }
-  }
-  
-  @Override
-  public void addAllEnvironment(Map<String, String> environment) {
-    if (environment == null)
-      return;
-    initEnvironment();
-    this.environment.putAll(environment);
-  }
-  
-  private void addEnvironmentToProto() {
-    maybeInitBuilder();
-    builder.clearEnvironment();
-    if (environment == null)
-      return;
-    Iterable<StringStringMapProto> iterable = new Iterable<StringStringMapProto>() {
-      
-      @Override
-      public Iterator<StringStringMapProto> iterator() {
-        return new Iterator<StringStringMapProto>() {
-          
-          Iterator<String> keyIter = environment.keySet().iterator();
-          
-          @Override
-          public void remove() {
-            throw new UnsupportedOperationException();
-          }
-          
-          @Override
-          public StringStringMapProto next() {
-            String key = keyIter.next();
-            return StringStringMapProto.newBuilder().setKey(key).setValue((environment.get(key))).build();
-          }
-          
-          @Override
-          public boolean hasNext() {
-            return keyIter.hasNext();
-          }
-        };
-      }
-    };
-    builder.addAllEnvironment(iterable);
-  }
-  @Override
-  public void setEnvironment(String key, String val) {
-    initEnvironment();
-    this.environment.put(key, val);
-  }
-  @Override
-  public void removeEnvironment(String key) {
-    initEnvironment();
-    this.environment.remove(key);
-  }
-  @Override
-  public void clearEnvironment() {
-    initEnvironment();
-    this.environment.clear();
-  }
-  @Override
-  public List<String> getCommandList() {
-    initCommandList();
-    return this.commandList;
-  }
-  @Override
-  public String getCommand(int index) {
-    initCommandList();
-    return this.commandList.get(index);
-  }
-  @Override
-  public int getCommandCount() {
-    initCommandList();
-    return this.commandList.size();
-  }
-  
-  private void initCommandList() {
-    if (this.commandList != null) {
-      return;
-    }
-    ApplicationSubmissionContextProtoOrBuilder p = viaProto ? proto : builder;
-    List<String> list = p.getCommandList();
-    this.commandList = new ArrayList<String>();
-
-    for (String c : list) {
-      this.commandList.add(c);
-    }
-  }
-  
-  @Override
-  public void addAllCommands(final List<String> command) {
-    if (command == null)
-      return;
-    initCommandList();
-    this.commandList.addAll(command);
-  }
-  
-  private void addCommandsToProto() {
-    maybeInitBuilder();
-    builder.clearCommand();
-    if (this.commandList == null) 
-      return;
-    builder.addAllCommand(this.commandList);
-  }
-  @Override
-  public void addCommand(String command) {
-    initCommandList();
-    this.commandList.add(command);
-  }
-  @Override
-  public void removeCommand(int index) {
-    initCommandList();
-    this.commandList.remove(index);
-  }
-  @Override
-  public void clearCommands() {
-    initCommandList();
-    this.commandList.clear();
-  }
   @Override
   public String getQueue() {
@@ -599,4 +166,5 @@ public void setQueue(String queue) {
     builder.setQueue((queue));
   }
+  
   @Override
   public String getUser() {
@@ -618,4 +186,26 @@ public void setUser(String user) {
   }
 
+  @Override
+  public ContainerLaunchContext getAMContainerSpec() {
+    ApplicationSubmissionContextProtoOrBuilder p = viaProto ? proto : builder;
+    if (this.amContainer != null) {
+      return amContainer;
+    } // Else via proto
+    if (!p.hasAmContainerSpec()) {
+      return null;
+    }
+    amContainer = convertFromProtoFormat(p.getAmContainerSpec());
+    return amContainer;
+  }
+
+  @Override
+  public void setAMContainerSpec(ContainerLaunchContext amContainer) {
+    maybeInitBuilder();
+    if (amContainer == null) {
+      builder.clearAmContainerSpec();
+    }
+    this.amContainer = amContainer;
+  }
+
   private PriorityPBImpl convertFromProtoFormat(PriorityProto p) {
     return new PriorityPBImpl(p);
@@ -634,27 +224,11 @@ private ApplicationIdProto convertToProtoFormat(ApplicationId t) {
   }
 
-  private ResourcePBImpl convertFromProtoFormat(ResourceProto p) {
-    return new ResourcePBImpl(p);
-  }
-
-  private ResourceProto convertToProtoFormat(Resource t) {
-    return ((ResourcePBImpl)t).getProto();
-  }
-
-  private URLPBImpl convertFromProtoFormat(URLProto p) {
-    return new URLPBImpl(p);
+  private ContainerLaunchContextPBImpl convertFromProtoFormat(
+      ContainerLaunchContextProto p) {
+    return new ContainerLaunchContextPBImpl(p);
   }
 
-  private URLProto convertToProtoFormat(URL t) {
-    return ((URLPBImpl)t).getProto();
+  private ContainerLaunchContextProto convertToProtoFormat(ContainerLaunchContext t) {
+    return ((ContainerLaunchContextPBImpl)t).getProto();
   }
-
-  private LocalResourcePBImpl convertFromProtoFormat(LocalResourceProto p) {
-    return new LocalResourcePBImpl(p);
-  }
-
-  private LocalResourceProto convertToProtoFormat(LocalResource t) {
-    return ((LocalResourcePBImpl)t).getProto();
-  }
-
 }  
diff --git a/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/api/records/impl/pb/ContainerLaunchContextPBImpl.java b/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/api/records/impl/pb/ContainerLaunchContextPBImpl.java
index 0696d8327bd..de292ad98e0 100644
--- a/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/api/records/impl/pb/ContainerLaunchContextPBImpl.java
+++ b/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/api/records/impl/pb/ContainerLaunchContextPBImpl.java
@@ -40,6 +40,4 @@
 import org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto;
 
-
-    
 public class ContainerLaunchContextPBImpl 
 extends ProtoBase<ContainerLaunchContextProto> 
@@ -55,8 +53,7 @@
   private ByteBuffer containerTokens = null;
   private Map<String, ByteBuffer> serviceData = null;
-  private Map<String, String> env = null;
+  private Map<String, String> environment = null;
   private List<String> commands = null;
   
-  
   public ContainerLaunchContextPBImpl() {
     builder = ContainerLaunchContextProto.newBuilder();
@@ -95,5 +92,5 @@ private void mergeLocalToBuilder() {
       addServiceDataToProto();
     }
-    if (this.env != null) {
+    if (this.environment != null) {
       addEnvToProto();
     }
@@ -365,35 +362,35 @@ public boolean hasNext() {
   
   @Override
-  public Map<String, String> getEnv() {
+  public Map<String, String> getEnvironment() {
     initEnv();
-    return this.env;
+    return this.environment;
   }
   
   private void initEnv() {
-    if (this.env != null) {
+    if (this.environment != null) {
       return;
     }
     ContainerLaunchContextProtoOrBuilder p = viaProto ? proto : builder;
-    List<StringStringMapProto> list = p.getEnvList();
-    this.env = new HashMap<String, String>();
+    List<StringStringMapProto> list = p.getEnvironmentList();
+    this.environment = new HashMap<String, String>();
 
     for (StringStringMapProto c : list) {
-      this.env.put(c.getKey(), c.getValue());
+      this.environment.put(c.getKey(), c.getValue());
     }
   }
   
   @Override
-  public void setEnv(final Map<String, String> env) {
+  public void setEnvironment(final Map<String, String> env) {
     if (env == null)
       return;
     initEnv();
-    this.env.clear();
-    this.env.putAll(env);
+    this.environment.clear();
+    this.environment.putAll(env);
   }
   
   private void addEnvToProto() {
     maybeInitBuilder();
-    builder.clearEnv();
-    if (env == null)
+    builder.clearEnvironment();
+    if (environment == null)
       return;
     Iterable<StringStringMapProto> iterable = 
@@ -404,5 +401,5 @@ private void addEnvToProto() {
         return new Iterator<StringStringMapProto>() {
           
-          Iterator<String> keyIter = env.keySet().iterator();
+          Iterator<String> keyIter = environment.keySet().iterator();
           
           @Override
@@ -415,5 +412,5 @@ public StringStringMapProto next() {
             String key = keyIter.next();
             return StringStringMapProto.newBuilder().setKey(key).setValue(
-                (env.get(key))).build();
+                (environment.get(key))).build();
           }
           
@@ -425,5 +422,5 @@ public boolean hasNext() {
       }
     };
-    builder.addAllEnv(iterable);
+    builder.addAllEnvironment(iterable);
   }
 
diff --git a/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-api/src/main/proto/yarn_protos.proto b/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-api/src/main/proto/yarn_protos.proto
index 61e3d1f5b94..cdcd1a747b8 100644
--- a/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-api/src/main/proto/yarn_protos.proto
+++ b/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-api/src/main/proto/yarn_protos.proto
@@ -189,15 +189,9 @@ message AMResponseProto {
 message ApplicationSubmissionContextProto {
   optional ApplicationIdProto application_id = 1;
-  optional string application_name = 2;
-  optional ResourceProto master_capability = 3;
-  repeated StringURLMapProto resources = 4;
-  repeated StringLocalResourceMapProto resources_todo = 5;
-  repeated string fs_tokens = 6;
-  optional bytes fs_tokens_todo = 7;
-  repeated StringStringMapProto environment = 8;
-  repeated string command = 9;
-  optional string queue = 10;
-  optional PriorityProto priority = 11;
-  optional string user = 12;
+  optional string application_name = 2 [default = ""N/A""];
+  optional string user = 3; 
+  optional string queue = 4 [default = ""default""];
+  optional PriorityProto priority = 5;
+  optional ContainerLaunchContextProto am_container_spec = 6;
 }
 
@@ -243,5 +237,5 @@ message ContainerLaunchContextProto {
   optional bytes container_tokens = 5;
   repeated StringBytesMapProto service_data = 6;
-  repeated StringStringMapProto env = 7;
+  repeated StringStringMapProto environment = 7;
   repeated string command = 8;
 }
diff --git a/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/conf/YarnConfiguration.java b/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/conf/YarnConfiguration.java
index 2169ee3e908..ba23134170f 100644
--- a/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/conf/YarnConfiguration.java
+++ b/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/conf/YarnConfiguration.java
@@ -220,4 +220,10 @@
   public static final int DEFAULT_RM_MAX_COMPLETED_APPLICATIONS = 10000;
   
+  /** Default application name */
+  public static final String DEFAULT_APPLICATION_NAME = ""N/A"";
+
+  /** Default queue name */
+  public static final String DEFAULT_QUEUE_NAME = ""default"";
+  
   ////////////////////////////////
   // Node Manager Configs
diff --git a/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/launcher/ContainerLaunch.java b/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/launcher/ContainerLaunch.java
index 1a34247c306..497460d3e7d 100644
--- a/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/launcher/ContainerLaunch.java
+++ b/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/launcher/ContainerLaunch.java
@@ -90,5 +90,5 @@ public Integer call() {
     String containerIdStr = ConverterUtils.toString(container.getContainerID());
     final String user = launchContext.getUser();
-    final Map<String,String> env = launchContext.getEnv();
+    final Map<String,String> env = launchContext.getEnvironment();
     final List<String> command = launchContext.getCommands();
     int ret = -1;
@@ -110,5 +110,5 @@ public Integer call() {
       launchContext.setCommands(newCmds);
 
-      Map<String, String> envs = launchContext.getEnv();
+      Map<String, String> envs = launchContext.getEnvironment();
       Map<String, String> newEnvs = new HashMap<String, String>(envs.size());
       for (Entry<String, String> entry : envs.entrySet()) {
@@ -119,5 +119,5 @@ public Integer call() {
                 containerLogDir.toUri().getPath()));
       }
-      launchContext.setEnv(newEnvs);
+      launchContext.setEnvironment(newEnvs);
       // /////////////////////////// End of variable expansion
 
diff --git a/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ClientRMService.java b/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ClientRMService.java
index 593d6525a68..a31bef8af9d 100644
--- a/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ClientRMService.java
+++ b/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ClientRMService.java
@@ -72,5 +72,4 @@
 import org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEvent;
 import org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType;
-import org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.AMLivelinessMonitor;
 import org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNode;
 import org.apache.hadoop.yarn.server.resourcemanager.scheduler.YarnScheduler;
@@ -91,5 +90,4 @@
   final private YarnScheduler scheduler;
   final private RMContext rmContext;
-  private final AMLivelinessMonitor amLivelinessMonitor;
   private final RMAppManager rmAppManager;
 
@@ -107,5 +105,4 @@ public ClientRMService(RMContext rmContext, YarnScheduler scheduler,
     this.scheduler = scheduler;
     this.rmContext = rmContext;
-    this.amLivelinessMonitor = rmContext.getAMLivelinessMonitor();
     this.rmAppManager = rmAppManager;
   }
@@ -196,13 +193,16 @@ public SubmitApplicationResponse submitApplication(
     ApplicationSubmissionContext submissionContext = request
         .getApplicationSubmissionContext();
-    ApplicationId applicationId = null;
-    String user = null;
+    ApplicationId applicationId = submissionContext.getApplicationId();
+    String user = submissionContext.getUser();
     try {
       user = UserGroupInformation.getCurrentUser().getShortUserName();
-      applicationId = submissionContext.getApplicationId();
       if (rmContext.getRMApps().get(applicationId) != null) {
         throw new IOException(""Application with id "" + applicationId
             + "" is already present! Cannot add a duplicate!"");
       }
+      
+      // Safety 
+      submissionContext.setUser(user);
+      
       // This needs to be synchronous as the client can query 
       // immediately following the submission to get the application status.
@@ -227,4 +227,5 @@ public SubmitApplicationResponse submitApplication(
   }
 
+  @SuppressWarnings(""unchecked"")
   @Override
   public FinishApplicationResponse finishApplication(
diff --git a/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/RMAppManager.java b/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/RMAppManager.java
index 9a86dfd4579..d0cd0a7ff86 100644
--- a/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/RMAppManager.java
+++ b/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/RMAppManager.java
@@ -211,5 +211,7 @@ protected synchronized void checkAppNumCompletedLimit() {
   }
 
-  protected synchronized void submitApplication(ApplicationSubmissionContext submissionContext) {
+  @SuppressWarnings(""unchecked"")
+  protected synchronized void submitApplication(
+      ApplicationSubmissionContext submissionContext) {
     ApplicationId applicationId = submissionContext.getApplicationId();
     RMApp application = null;
@@ -225,25 +227,35 @@ protected synchronized void submitApplication(ApplicationSubmissionContext submi
         LOG.debug(""Sending client token as "" + clientTokenStr);
       }
-      submissionContext.setQueue(submissionContext.getQueue() == null
-          ? ""default"" : submissionContext.getQueue());
-      submissionContext.setApplicationName(submissionContext
-          .getApplicationName() == null ? ""N/A"" : submissionContext
-          .getApplicationName());
+      
+      // Sanity checks
+      if (submissionContext.getQueue() == null) {
+        submissionContext.setQueue(YarnConfiguration.DEFAULT_QUEUE_NAME);
+      }
+      if (submissionContext.getApplicationName() == null) {
+        submissionContext.setApplicationName(
+            YarnConfiguration.DEFAULT_APPLICATION_NAME);
+      }
+
+      // Store application for recovery
       ApplicationStore appStore = rmContext.getApplicationsStore()
           .createApplicationStore(submissionContext.getApplicationId(),
           submissionContext);
+      
+      // Create RMApp
       application = new RMAppImpl(applicationId, rmContext,
           this.conf, submissionContext.getApplicationName(), user,
           submissionContext.getQueue(), submissionContext, clientTokenStr,
-          appStore, rmContext.getAMLivelinessMonitor(), this.scheduler,
+          appStore, this.scheduler,
           this.masterService);
 
-      if (rmContext.getRMApps().putIfAbsent(applicationId, application) != null) {
+      if (rmContext.getRMApps().putIfAbsent(applicationId, application) != 
+          null) {
         LOG.info(""Application with id "" + applicationId + 
             "" is already present! Cannot add a duplicate!"");
-        // don't send event through dispatcher as it will be handled by app already
-        // present with this id.
+        // don't send event through dispatcher as it will be handled by app 
+        // already present with this id.
         application.handle(new RMAppRejectedEvent(applicationId,
-            ""Application with this id is already present! Cannot add a duplicate!""));
+            ""Application with this id is already present! "" +
+            ""Cannot add a duplicate!""));
       } else {
         this.rmContext.getDispatcher().getEventHandler().handle(
diff --git a/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/RMAppManagerSubmitEvent.java b/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/RMAppManagerSubmitEvent.java
index 99b3d77fd4b..495e7844280 100644
--- a/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/RMAppManagerSubmitEvent.java
+++ b/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/RMAppManagerSubmitEvent.java
@@ -19,5 +19,4 @@
 package org.apache.hadoop.yarn.server.resourcemanager;
 
-import org.apache.hadoop.yarn.api.records.ApplicationId;
 import org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext;
 
diff --git a/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/amlauncher/AMLauncher.java b/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/amlauncher/AMLauncher.java
index 1a10993bb08..b394faa85d2 100644
--- a/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/amlauncher/AMLauncher.java
+++ b/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/amlauncher/AMLauncher.java
@@ -24,5 +24,4 @@
 import java.security.PrivilegedAction;
 import java.util.ArrayList;
-import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
@@ -121,5 +120,6 @@ private void launch() throws IOException {
     ContainerLaunchContext launchContext =
         createAMContainerLaunchContext(applicationContext, masterContainerID);
-    StartContainerRequest request = recordFactory.newRecordInstance(StartContainerRequest.class);
+    StartContainerRequest request = 
+        recordFactory.newRecordInstance(StartContainerRequest.class);
     request.setContainerLaunchContext(launchContext);
     containerMgrProxy.startContainer(request);
@@ -131,5 +131,6 @@ private void cleanup() throws IOException {
     connect();
     ContainerId containerId = application.getMasterContainer().getId();
-    StopContainerRequest stopRequest = recordFactory.newRecordInstance(StopContainerRequest.class);
+    StopContainerRequest stopRequest = 
+        recordFactory.newRecordInstance(StopContainerRequest.class);
     stopRequest.setContainerId(containerId);
     containerMgrProxy.stopContainer(stopRequest);
@@ -146,5 +147,5 @@ private ContainerManager getContainerMgrProxy(
 
     UserGroupInformation currentUser =
-        UserGroupInformation.createRemoteUser(""TODO""); // TODO
+        UserGroupInformation.createRemoteUser(""yarn""); // TODO
     if (UserGroupInformation.isSecurityEnabled()) {
       ContainerToken containerToken = container.getContainerToken();
@@ -171,6 +172,6 @@ private ContainerLaunchContext createAMContainerLaunchContext(
 
     // Construct the actual Container
-    ContainerLaunchContext container = recordFactory.newRecordInstance(ContainerLaunchContext.class);
-    container.setCommands(applicationMasterContext.getCommandList());
+    ContainerLaunchContext container = 
+        applicationMasterContext.getAMContainerSpec();
     StringBuilder mergedCommand = new StringBuilder();
     String failCount = Integer.toString(application.getAppAttemptId()
@@ -190,23 +191,17 @@ private ContainerLaunchContext createAMContainerLaunchContext(
     LOG.info(""Command to launch container "" + 
         containerID + "" : "" + mergedCommand);
-    Map<String, String> environment = 
-        applicationMasterContext.getAllEnvironment();
-    environment.putAll(setupTokensInEnv(applicationMasterContext));
-    container.setEnv(environment);
-
-    // Construct the actual Container
+    
+    // Finalize the container
     container.setContainerId(containerID);
     container.setUser(applicationMasterContext.getUser());
-    container.setResource(applicationMasterContext.getMasterCapability());
-    container.setLocalResources(applicationMasterContext.getAllResourcesTodo());
-    container.setContainerTokens(applicationMasterContext.getFsTokensTodo());
+    setupTokensAndEnv(container);
+    
     return container;
   }
 
-  private Map<String, String> setupTokensInEnv(
-      ApplicationSubmissionContext asc)
+  private void setupTokensAndEnv(
+      ContainerLaunchContext container)
       throws IOException {
-    Map<String, String> env =
-      new HashMap<String, String>();
+    Map<String, String> environment = container.getEnvironment();
     if (UserGroupInformation.isSecurityEnabled()) {
       // TODO: Security enabled/disabled info should come from RM.
@@ -215,7 +210,7 @@ private ContainerLaunchContext createAMContainerLaunchContext(
 
       DataInputByteBuffer dibb = new DataInputByteBuffer();
-      if (asc.getFsTokensTodo() != null) {
+      if (container.getContainerTokens() != null) {
         // TODO: Don't do this kind of checks everywhere.
-        dibb.reset(asc.getFsTokensTodo());
+        dibb.reset(container.getContainerTokens());
         credentials.readTokenStorageStream(dibb);
       }
@@ -237,5 +232,6 @@ private ContainerLaunchContext createAMContainerLaunchContext(
       String appMasterTokenEncoded = token.encodeToUrlString();
       LOG.debug(""Putting appMaster token in env : "" + appMasterTokenEncoded);
-      env.put(ApplicationConstants.APPLICATION_MASTER_TOKEN_ENV_NAME,
+      environment.put(
+          ApplicationConstants.APPLICATION_MASTER_TOKEN_ENV_NAME,
           appMasterTokenEncoded);
 
@@ -244,5 +240,6 @@ private ContainerLaunchContext createAMContainerLaunchContext(
       DataOutputBuffer dob = new DataOutputBuffer();
       credentials.writeTokenStorageToStream(dob);
-      asc.setFsTokensTodo(ByteBuffer.wrap(dob.getData(), 0, dob.getLength()));
+      container.setContainerTokens(
+          ByteBuffer.wrap(dob.getData(), 0, dob.getLength()));
 
       ApplicationTokenIdentifier identifier = new ApplicationTokenIdentifier(
@@ -253,7 +250,8 @@ private ContainerLaunchContext createAMContainerLaunchContext(
           Base64.encodeBase64URLSafeString(clientSecretKey.getEncoded());
       LOG.debug(""The encoded client secret-key to be put in env : "" + encoded);
-      env.put(ApplicationConstants.APPLICATION_CLIENT_SECRET_ENV_NAME, encoded);
+      environment.put(
+          ApplicationConstants.APPLICATION_CLIENT_SECRET_ENV_NAME, 
+          encoded);
     }
-    return env;
   }
   
diff --git a/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/rmapp/RMAppImpl.java b/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/rmapp/RMAppImpl.java
index 015c76163e4..65ee9945e29 100644
--- a/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/rmapp/RMAppImpl.java
+++ b/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/rmapp/RMAppImpl.java
@@ -87,5 +87,4 @@
   private long startTime;
   private long finishTime;
-  private AMLivelinessMonitor amLivelinessMonitor;
   private RMAppAttempt currentAttempt;
 
@@ -164,5 +163,5 @@ public RMAppImpl(ApplicationId applicationId, RMContext rmContext,
       Configuration config, String name, String user, String queue,
       ApplicationSubmissionContext submissionContext, String clientTokenStr,
-      ApplicationStore appStore, AMLivelinessMonitor amLivelinessMonitor,
+      ApplicationStore appStore, 
       YarnScheduler scheduler, ApplicationMasterService masterService) {
 
@@ -177,5 +176,4 @@ public RMAppImpl(ApplicationId applicationId, RMContext rmContext,
     this.clientTokenStr = clientTokenStr;
     this.appStore = appStore;
-    this.amLivelinessMonitor = amLivelinessMonitor;
     this.scheduler = scheduler;
     this.masterService = masterService;
@@ -381,4 +379,5 @@ public void handle(RMAppEvent event) {
   }
 
+  @SuppressWarnings(""unchecked"")
   private void createNewAttempt() {
     ApplicationAttemptId appAttemptId = Records
@@ -435,4 +434,5 @@ public void transition(RMAppImpl app, RMAppEvent event) {
     }
 
+    @SuppressWarnings(""unchecked"")
     public void transition(RMAppImpl app, RMAppEvent event) {
       Set<NodeId> nodes = getNodesOnWhichAttemptRan(app);
diff --git a/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/rmapp/attempt/RMAppAttemptImpl.java b/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/rmapp/attempt/RMAppAttemptImpl.java
index 6daff1d88e7..12eca4d82f3 100644
--- a/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/rmapp/attempt/RMAppAttemptImpl.java
+++ b/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/rmapp/attempt/RMAppAttemptImpl.java
@@ -85,4 +85,5 @@
 
   private final RMContext rmContext;
+  @SuppressWarnings(""rawtypes"")
   private final EventHandler eventHandler;
   private final YarnScheduler scheduler;
@@ -460,5 +461,5 @@ public void transition(RMAppAttemptImpl appAttempt,
       ResourceRequest request = BuilderUtils.newResourceRequest(
           AM_CONTAINER_PRIORITY, ""*"", appAttempt.submissionContext
-              .getMasterCapability(), 1);
+              .getAMContainerSpec().getResource(), 1);
       LOG.debug(""About to request resources for AM of ""
           + appAttempt.applicationAttemptId + "" required "" + request);
diff --git a/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/webapp/AppsBlock.java b/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/webapp/AppsBlock.java
index 94649923cb3..afdec298a1d 100644
--- a/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/webapp/AppsBlock.java
+++ b/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/webapp/AppsBlock.java
@@ -24,5 +24,4 @@
 
 import org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMApp;
-import org.apache.hadoop.yarn.util.Apps;
 import org.apache.hadoop.yarn.webapp.hamlet.Hamlet;
 import org.apache.hadoop.yarn.webapp.hamlet.Hamlet.TABLE;
@@ -60,5 +59,6 @@
       String trackingUrl = app.getTrackingUrl();
       String ui = trackingUrl == null || trackingUrl.isEmpty() ? ""UNASSIGNED"" :
-          (app.getFinishTime() == 0 ? ""ApplicationMaster"" : ""JobHistory"");
+          (app.getFinishTime() == 0 ? 
+              ""ApplicationMaster URL"" : ""JobHistory URL"");
       String percent = String.format(""%.1f"", app.getProgress() * 100);
       tbody.
diff --git a/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/MockRM.java b/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/MockRM.java
index 901948fab70..4be27399672 100644
--- a/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/MockRM.java
+++ b/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/MockRM.java
@@ -30,4 +30,5 @@
 import org.apache.hadoop.yarn.api.records.ApplicationId;
 import org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext;
+import org.apache.hadoop.yarn.api.records.ContainerLaunchContext;
 import org.apache.hadoop.yarn.api.records.Resource;
 import org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEvent;
@@ -82,11 +83,15 @@ public RMApp submitApp(int masterMemory) throws Exception {
     
     SubmitApplicationRequest req = Records.newRecord(SubmitApplicationRequest.class);
-    ApplicationSubmissionContext sub = Records.newRecord(ApplicationSubmissionContext.class);
+    ApplicationSubmissionContext sub = 
+        Records.newRecord(ApplicationSubmissionContext.class);
     sub.setApplicationId(appId);
     sub.setApplicationName("""");
     sub.setUser("""");
+    ContainerLaunchContext clc = 
+        Records.newRecord(ContainerLaunchContext.class);
     Resource capability = Records.newRecord(Resource.class);
     capability.setMemory(masterMemory);
-    sub.setMasterCapability(capability);
+    clc.setResource(capability);
+    sub.setAMContainerSpec(clc);
     req.setApplicationSubmissionContext(sub);
     
diff --git a/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/TestAppManager.java b/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/TestAppManager.java
index bd66a6337f1..afdeb161775 100644
--- a/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/TestAppManager.java
+++ b/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/TestAppManager.java
@@ -19,17 +19,10 @@
 package org.apache.hadoop.yarn.server.resourcemanager;
 
-import static org.mockito.Mockito.*;
 
-import java.util.ArrayList;
 import java.util.List;
-import java.util.LinkedList;
-import java.util.Map;
 import java.util.concurrent.ConcurrentMap;
 
-
 import junit.framework.Assert;
 
-import org.apache.commons.logging.Log;
-import org.apache.commons.logging.LogFactory;
 import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.yarn.conf.YarnConfiguration;
@@ -45,5 +38,4 @@
 import org.apache.hadoop.yarn.security.client.ClientToAMSecretManager;
 import org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService;
-import org.apache.hadoop.yarn.server.resourcemanager.ResourceManager;
 import org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEvent;
 import org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType;
@@ -64,6 +56,4 @@
 import org.apache.hadoop.yarn.service.Service;
 
-import org.junit.After;
-import org.junit.Before;
 import org.junit.Test;
 import com.google.common.collect.Maps;
@@ -76,5 +66,4 @@
 
 public class TestAppManager{
-  private static final Log LOG = LogFactory.getLog(TestAppManager.class);
   private static RMAppEventType appEventType = RMAppEventType.KILL; 
 
@@ -118,8 +107,6 @@ public static RMContext mockRMContext(int n, long time) {
       EventHandler<RMAppManagerEvent> {
 
-    private final RMContext rmContext;
 
-    public TestAppManagerDispatcher(RMContext rmContext) {
-      this.rmContext = rmContext;
+    public TestAppManagerDispatcher() {
     }
 
@@ -133,13 +120,9 @@ public void handle(RMAppManagerEvent event) {
       EventHandler<RMAppEvent> {
 
-    private final RMContext rmContext;
-
-    public TestDispatcher(RMContext rmContext) {
-      this.rmContext = rmContext;
+    public TestDispatcher() {
     }
 
     @Override
     public void handle(RMAppEvent event) {
-      ApplicationId appID = event.getApplicationId();
       //RMApp rmApp = this.rmContext.getRMApps().get(appID);
       setAppEventType(event.getType());
@@ -179,5 +162,6 @@ public void setCompletedAppsMax(int max) {
       super.setCompletedAppsMax(max);
     }
-    public void submitApplication(ApplicationSubmissionContext submissionContext) {
+    public void submitApplication(
+        ApplicationSubmissionContext submissionContext) {
       super.submitApplication(submissionContext);
     }
@@ -337,6 +321,7 @@ public void testRMAppRetireZeroSetting() throws Exception {
 
   protected void setupDispatcher(RMContext rmContext, Configuration conf) {
-    TestDispatcher testDispatcher = new TestDispatcher(rmContext);
-    TestAppManagerDispatcher testAppManagerDispatcher = new TestAppManagerDispatcher(rmContext);
+    TestDispatcher testDispatcher = new TestDispatcher();
+    TestAppManagerDispatcher testAppManagerDispatcher = 
+        new TestAppManagerDispatcher();
     rmContext.getDispatcher().register(RMAppEventType.class, testDispatcher);
     rmContext.getDispatcher().register(RMAppManagerEventType.class, testAppManagerDispatcher);
@@ -360,5 +345,6 @@ public void testRMAppSubmit() throws Exception {
     ApplicationId appID = MockApps.newAppID(1);
     RecordFactory recordFactory = RecordFactoryProvider.getRecordFactory(null);
-    ApplicationSubmissionContext context = recordFactory.newRecordInstance(ApplicationSubmissionContext.class);
+    ApplicationSubmissionContext context = 
+        recordFactory.newRecordInstance(ApplicationSubmissionContext.class);
     context.setApplicationId(appID);
     setupDispatcher(rmContext, conf);
@@ -368,6 +354,10 @@ public void testRMAppSubmit() throws Exception {
     Assert.assertNotNull(""app is null"", app);
     Assert.assertEquals(""app id doesn't match"", appID, app.getApplicationId());
-    Assert.assertEquals(""app name doesn't match"", ""N/A"", app.getName());
-    Assert.assertEquals(""app queue doesn't match"", ""default"", app.getQueue());
+    Assert.assertEquals(""app name doesn't match"", 
+        YarnConfiguration.DEFAULT_APPLICATION_NAME, 
+        app.getName());
+    Assert.assertEquals(""app queue doesn't match"", 
+        YarnConfiguration.DEFAULT_QUEUE_NAME, 
+        app.getQueue());
     Assert.assertEquals(""app state doesn't match"", RMAppState.NEW, app.getState());
     Assert.assertNotNull(""app store is null"", app.getApplicationStore());
diff --git a/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/rmapp/TestRMAppTransitions.java b/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/rmapp/TestRMAppTransitions.java
index 56bac772099..56b3f4b18af 100644
--- a/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/rmapp/TestRMAppTransitions.java
+++ b/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/rmapp/TestRMAppTransitions.java
@@ -129,5 +129,5 @@ protected RMApp createNewTestApp() {
           conf, name, user,
           queue, submissionContext, clientTokenStr,
-          appStore, rmContext.getAMLivelinessMonitor(), scheduler,
+          appStore, scheduler,
           masterService);
 
diff --git a/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-tests/src/test/java/org/apache/hadoop/yarn/server/TestContainerTokenSecretManager.java b/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-tests/src/test/java/org/apache/hadoop/yarn/server/TestContainerTokenSecretManager.java
index 32148982774..989f3483d91 100644
--- a/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-tests/src/test/java/org/apache/hadoop/yarn/server/TestContainerTokenSecretManager.java
+++ b/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-tests/src/test/java/org/apache/hadoop/yarn/server/TestContainerTokenSecretManager.java
@@ -28,4 +28,6 @@
 import java.security.PrivilegedAction;
 import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.Collections;
 import java.util.List;
 
@@ -55,8 +57,8 @@
 import org.apache.hadoop.yarn.api.records.ApplicationAttemptId;
 import org.apache.hadoop.yarn.api.records.ApplicationId;
-import org.apache.hadoop.yarn.api.records.ApplicationMaster;
 import org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext;
 import org.apache.hadoop.yarn.api.records.Container;
 import org.apache.hadoop.yarn.api.records.ContainerId;
+import org.apache.hadoop.yarn.api.records.ContainerLaunchContext;
 import org.apache.hadoop.yarn.api.records.ContainerToken;
 import org.apache.hadoop.yarn.api.records.LocalResource;
@@ -78,4 +80,5 @@
 import org.apache.hadoop.yarn.security.SchedulerSecurityInfo;
 import org.apache.hadoop.yarn.server.resourcemanager.ResourceManager;
+import org.apache.hadoop.yarn.server.resourcemanager.resource.Resources;
 import org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMApp;
 import org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttempt;
@@ -138,13 +141,9 @@ public void test() throws IOException, InterruptedException {
         recordFactory.newRecordInstance(ApplicationSubmissionContext.class);
     appSubmissionContext.setApplicationId(appID);
-    appSubmissionContext.setMasterCapability(recordFactory
-        .newRecordInstance(Resource.class));
-    appSubmissionContext.getMasterCapability().setMemory(1024);
-//    appSubmissionContext.resources = new HashMap<String, URL>();
+    ContainerLaunchContext amContainer =
+        recordFactory.newRecordInstance(ContainerLaunchContext.class);
+    amContainer.setResource(Resources.createResource(1024));
+    amContainer.setCommands(Arrays.asList(""sleep"", ""100""));
     appSubmissionContext.setUser(""testUser"");
-//    appSubmissionContext.environment = new HashMap<String, String>();
-//    appSubmissionContext.command = new ArrayList<String>();
-    appSubmissionContext.addCommand(""sleep"");
-    appSubmissionContext.addCommand(""100"");
 
     // TODO: Use a resource to work around bugs. Today NM doesn't create local
@@ -163,8 +162,9 @@ public void test() throws IOException, InterruptedException {
     rsrc.setType(LocalResourceType.FILE);
     rsrc.setVisibility(LocalResourceVisibility.PRIVATE);
-    appSubmissionContext.setResourceTodo(""testFile"", rsrc);
+    amContainer.setLocalResources(Collections.singletonMap(""testFile"", rsrc));
     SubmitApplicationRequest submitRequest = recordFactory
         .newRecordInstance(SubmitApplicationRequest.class);
     submitRequest.setApplicationSubmissionContext(appSubmissionContext);
+    appSubmissionContext.setAMContainerSpec(amContainer);
     resourceManager.getClientRMService().submitApplication(submitRequest);
 
",MAPREDUCE-2899. Replace major parts of- ApplicationSubmissionContext with a ContainerLaunchContext (Arun Murthy via- mahadev) - Merging r1170459 from trunk--git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/branch-0.23@1170460 13f79535-47bb-0310-9956-ffa450edef68-
1509,Java,9a40de8e6c1974d4ae187b181055ecd4b1cc93da,,C,apache,camel,"[0, 0, 0, 0, 0, 0, 0, 3, 2, 39, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/components/camel-jcr/src/test/java/org/apache/camel/component/jcr/JcrAuthTestBase.java b/components/camel-jcr/src/test/java/org/apache/camel/component/jcr/JcrAuthTestBase.java
index 737ee4a2438..4dc522016fb 100644
--- a/components/camel-jcr/src/test/java/org/apache/camel/component/jcr/JcrAuthTestBase.java
+++ b/components/camel-jcr/src/test/java/org/apache/camel/component/jcr/JcrAuthTestBase.java
@@ -18,6 +18,4 @@ package org.apache.camel.component.jcr;
 
 import java.io.File;
-import java.io.IOException;
-
 import javax.jcr.Repository;
 import javax.jcr.SimpleCredentials;
@@ -31,5 +29,4 @@ import org.apache.jackrabbit.api.security.user.UserManager;
 import org.apache.jackrabbit.core.SessionImpl;
 import org.apache.jackrabbit.core.TransientRepository;
-import org.apache.jackrabbit.core.fs.local.FileUtil;
 import org.apache.jackrabbit.core.security.authorization.JackrabbitAccessControlList;
 import org.junit.Before;
@@ -50,12 +47,9 @@ public abstract class JcrAuthTestBase extends CamelTestSupport {
     private Repository repository;
 
-    private void clean() throws IOException {
-        File[] files = {new File(""target/repository_with_auth""),
-                        new File(""derby.log"") };
-        for (File file : files) {
-            if (file.exists()) {
-                FileUtil.delete(file);
-            }
-        }
+    @Override
+    @Before
+    public void setUp() throws Exception {
+        deleteDirectory(""target/repository"");
+        super.setUp();
     }
 
@@ -107,10 +101,3 @@ public abstract class JcrAuthTestBase extends CamelTestSupport {
     }
 
-    @Override
-    @Before
-    public void setUp() throws Exception {
-        clean();
-        super.setUp();
-    }
-
 }
\ No newline at end of file
diff --git a/components/camel-jcr/src/test/java/org/apache/camel/component/jcr/JcrNodePathCreationTest.java b/components/camel-jcr/src/test/java/org/apache/camel/component/jcr/JcrNodePathCreationTest.java
index bf0e7c3a235..6aaef382279 100644
--- a/components/camel-jcr/src/test/java/org/apache/camel/component/jcr/JcrNodePathCreationTest.java
+++ b/components/camel-jcr/src/test/java/org/apache/camel/component/jcr/JcrNodePathCreationTest.java
@@ -17,7 +17,4 @@
 package org.apache.camel.component.jcr;
 
-import java.io.File;
-import java.io.IOException;
-
 import javax.jcr.Node;
 import javax.jcr.Repository;
@@ -30,5 +27,4 @@ import org.apache.camel.builder.RouteBuilder;
 import org.apache.camel.test.junit4.CamelTestSupport;
 import org.apache.jackrabbit.core.TransientRepository;
-import org.apache.jackrabbit.core.fs.local.FileUtil;
 import org.junit.Before;
 import org.junit.Test;
@@ -41,18 +37,8 @@ public class JcrNodePathCreationTest extends CamelTestSupport {
     @Before
     public void setUp() throws Exception {
-        clean();
+        deleteDirectory(""target/repository"");
         super.setUp();
     }
 
-    private void clean() throws IOException {
-        File[] files = {new File(""target/repository""), new File(""target/repository.xml""),
-                        new File(""derby.log"")};
-        for (File file : files) {
-            if (file.exists()) {
-                FileUtil.delete(file);
-            }
-        }
-    }
-    
     @Test
     public void testJcrNodePathCreation() throws Exception {
diff --git a/components/camel-jcr/src/test/java/org/apache/camel/component/jcr/JcrRouteTest.java b/components/camel-jcr/src/test/java/org/apache/camel/component/jcr/JcrRouteTest.java
index ac2d197973c..fdfb35948af 100644
--- a/components/camel-jcr/src/test/java/org/apache/camel/component/jcr/JcrRouteTest.java
+++ b/components/camel-jcr/src/test/java/org/apache/camel/component/jcr/JcrRouteTest.java
@@ -17,7 +17,4 @@
 package org.apache.camel.component.jcr;
 
-import java.io.File;
-import java.io.IOException;
-
 import javax.jcr.Node;
 import javax.jcr.Repository;
@@ -30,5 +27,4 @@ import org.apache.camel.builder.RouteBuilder;
 import org.apache.camel.test.junit4.CamelTestSupport;
 import org.apache.jackrabbit.core.TransientRepository;
-import org.apache.jackrabbit.core.fs.local.FileUtil;
 import org.junit.Before;
 import org.junit.Test;
@@ -41,18 +37,8 @@ public class JcrRouteTest extends CamelTestSupport {
     @Before
     public void setUp() throws Exception {
-        clean();
+        deleteDirectory(""target/repository"");
         super.setUp();
     }
 
-    private void clean() throws IOException {
-        File[] files = {new File(""target/repository""), new File(""target/repository.xml""),
-                        new File(""derby.log"")};
-        for (File file : files) {
-            if (file.exists()) {
-                FileUtil.delete(file);
-            }
-        }
-    }
-
     @Test
     public void testJcrRoute() throws Exception {
",Fixed unit test having problem on Windows- deleting files for cleanup.--git-svn-id: https://svn.apache.org/repos/asf/camel/trunk@888416 13f79535-47bb-0310-9956-ffa450edef68-
1518,Java,fdc7205adae52d9e2d928d06faacf9cc9f216b55,,C,apache,camel,"[3, 8, 3, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/components/camel-http4/src/main/java/org/apache/camel/component/http4/HttpComponent.java b/components/camel-http4/src/main/java/org/apache/camel/component/http4/HttpComponent.java
index f6431545bdb..d90a257edda 100644
--- a/components/camel-http4/src/main/java/org/apache/camel/component/http4/HttpComponent.java
+++ b/components/camel-http4/src/main/java/org/apache/camel/component/http4/HttpComponent.java
@@ -23,4 +23,5 @@ import java.util.Map;
 import org.apache.camel.Endpoint;
 import org.apache.camel.ResolveEndpointFailedException;
+import org.apache.camel.component.http4.helper.HttpHelper;
 import org.apache.camel.impl.HeaderFilterStrategyComponent;
 import org.apache.camel.util.CastUtils;
@@ -183,5 +184,5 @@ public class HttpComponent extends HeaderFilterStrategyComponent {
         }
         
-        boolean secure = isSecureConnection(uri);
+        boolean secure = HttpHelper.isSecureConnection(uri);
 
         // create the configurer to use for this endpoint
@@ -302,8 +303,4 @@ public class HttpComponent extends HeaderFilterStrategyComponent {
     }
 
-    private boolean isSecureConnection(String uri) {
-        return uri.startsWith(""https"");
-    }
-
     @Override
     protected boolean useIntrospectionOnEndpoint() {
diff --git a/components/camel-http4/src/main/java/org/apache/camel/component/http4/HttpEndpoint.java b/components/camel-http4/src/main/java/org/apache/camel/component/http4/HttpEndpoint.java
index 4ba78fba70a..c0a87d5da7e 100644
--- a/components/camel-http4/src/main/java/org/apache/camel/component/http4/HttpEndpoint.java
+++ b/components/camel-http4/src/main/java/org/apache/camel/component/http4/HttpEndpoint.java
@@ -22,4 +22,5 @@ import java.net.URISyntaxException;
 import org.apache.camel.PollingConsumer;
 import org.apache.camel.Producer;
+import org.apache.camel.component.http4.helper.HttpHelper;
 import org.apache.camel.impl.DefaultPollingEndpoint;
 import org.apache.camel.spi.HeaderFilterStrategy;
@@ -118,4 +119,8 @@ public class HttpEndpoint extends DefaultPollingEndpoint implements HeaderFilter
             int port = Integer.parseInt(getCamelContext().getProperties().get(""http.proxyPort""));
             String scheme = getCamelContext().getProperties().get(""http.proxyScheme"");
+            // fallback and use either http4 or https4 depending on secure
+            if (scheme == null) {
+                scheme = HttpHelper.isSecureConnection(getEndpointUri()) ? ""https4"" : ""http4"";
+            }
 
             LOG.debug(""CamelContext properties http.proxyHost, http.proxyPort, and http.proxyScheme detected. Using http proxy host: {} port: {} scheme: {}"", new Object[]{host, port, scheme});
diff --git a/components/camel-http4/src/main/java/org/apache/camel/component/http4/helper/HttpHelper.java b/components/camel-http4/src/main/java/org/apache/camel/component/http4/helper/HttpHelper.java
index 0da9eca33d4..775d25a36b9 100644
--- a/components/camel-http4/src/main/java/org/apache/camel/component/http4/helper/HttpHelper.java
+++ b/components/camel-http4/src/main/java/org/apache/camel/component/http4/helper/HttpHelper.java
@@ -266,5 +266,9 @@ public final class HttpHelper {
         }
         return new HttpVersion(major, minor);
+    }
 
+    public static boolean isSecureConnection(String uri) {
+        return uri.startsWith(""https"");
     }
+
 }
",CAMEL-4176: Fixed fallback to use http4 or http4s- for proxy scheme when configured as property on CamelContext properties.--git-svn-id: https://svn.apache.org/repos/asf/camel/trunk@1144310 13f79535-47bb-0310-9956-ffa450edef68-
1528,Java,a4873a43416cb322957863fd3c34795a3808f7ac,,A,apache,hadoop,"[0, 0, 0, 0, 0, 0, 0, 2, 175, 0, 0, 66, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]","diff --git a/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt b/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
index 62e45162a1e..c85adc18b1e 100644
--- a/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
+++ b/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
@@ -69,4 +69,6 @@ Release 2.0.0 - UNRELEASED
     (harsh via szetszwo)
 
+    HDFS-3167. CLI-based driver for MiniDFSCluster. (Henry Robinson via atm)
+
   IMPROVEMENTS
 
diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/test/HdfsTestDriver.java b/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/test/HdfsTestDriver.java
index 709a5012bfb..cdcf618c80d 100644
--- a/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/test/HdfsTestDriver.java
+++ b/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/test/HdfsTestDriver.java
@@ -37,5 +37,7 @@ public HdfsTestDriver(ProgramDriver pgd) {
     try {
       pgd.addClass(""dfsthroughput"", BenchmarkThroughput.class, 
-      ""measure hdfs throughput"");
+          ""measure hdfs throughput"");
+      pgd.addClass(""minidfscluster"", MiniDFSClusterManager.class, 
+          ""Run a single-process mini DFS cluster"");
     } catch(Throwable e) {
       e.printStackTrace();
diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/test/MiniDFSClusterManager.java b/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/test/MiniDFSClusterManager.java
new file mode 100644
index 00000000000..4622b4cd5c5
--- /dev/null
+++ b/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/test/MiniDFSClusterManager.java
@@ -0,0 +1,259 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.test;
+
+import java.io.File;
+import java.io.FileNotFoundException;
+import java.io.FileOutputStream;
+import java.io.FileWriter;
+import java.io.IOException;
+import java.util.Map;
+import java.util.TreeMap;
+
+import org.apache.commons.cli.CommandLine;
+import org.apache.commons.cli.CommandLineParser;
+import org.apache.commons.cli.GnuParser;
+import org.apache.commons.cli.HelpFormatter;
+import org.apache.commons.cli.OptionBuilder;
+import org.apache.commons.cli.Options;
+import org.apache.commons.cli.ParseException;
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.hdfs.HdfsConfiguration;
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.hdfs.MiniDFSCluster;
+import org.apache.hadoop.hdfs.server.common.HdfsServerConstants.StartupOption;
+import org.mortbay.util.ajax.JSON;
+
+/**
+ * This class drives the creation of a mini-cluster on the local machine. By
+ * default, a MiniDFSCluster is spawned on the first available ports that are
+ * found.
+ * 
+ * A series of command line flags controls the startup cluster options.
+ * 
+ * This class can dump a Hadoop configuration and some basic metadata (in JSON)
+ * into a textfile.
+ * 
+ * To shutdown the cluster, kill the process.
+ * 
+ * To run this from the command line, do the following (replacing the jar
+ * version as appropriate):
+ * 
+ * $HADOOP_HOME/bin/hadoop jar $HADOOP_HOME/share/hadoop/hdfs/hadoop-hdfs-0.24.0-SNAPSHOT-tests.jar org.apache.hadoop.test.MiniDFSClusterManager -options...
+ */
+public class MiniDFSClusterManager {
+  private static final Log LOG =
+    LogFactory.getLog(MiniDFSClusterManager.class);
+
+  private MiniDFSCluster dfs;
+  private String writeDetails;
+  private int numDataNodes;
+  private int nameNodePort;
+  private StartupOption dfsOpts;
+  private String writeConfig;
+  private Configuration conf;
+  
+  private static final long SLEEP_INTERVAL_MS = 1000 * 60;
+
+  /**
+   * Creates configuration options object.
+   */
+  @SuppressWarnings(""static-access"")
+  private Options makeOptions() {
+    Options options = new Options();
+    options
+        .addOption(""datanodes"", true, ""How many datanodes to start (default 1)"")
+        .addOption(""format"", false, ""Format the DFS (default false)"")
+        .addOption(""cmdport"", true,
+            ""Which port to listen on for commands (default 0--we choose)"")
+        .addOption(""nnport"", true, ""NameNode port (default 0--we choose)"")
+        .addOption(""namenode"", true, ""URL of the namenode (default ""
+            + ""is either the DFS cluster or a temporary dir)"")     
+        .addOption(OptionBuilder
+            .hasArgs()
+            .withArgName(""property=value"")
+            .withDescription(""Options to pass into configuration object"")
+            .create(""D""))
+        .addOption(OptionBuilder
+            .hasArg()
+            .withArgName(""path"")
+            .withDescription(""Save configuration to this XML file."")
+            .create(""writeConfig""))
+         .addOption(OptionBuilder
+            .hasArg()
+            .withArgName(""path"")
+            .withDescription(""Write basic information to this JSON file."")
+            .create(""writeDetails""))
+        .addOption(OptionBuilder.withDescription(""Prints option help."")
+            .create(""help""));
+    return options;
+  }
+
+  /**
+   * Main entry-point.
+   */
+  public void run(String[] args) throws IOException {
+    if (!parseArguments(args)) {
+      return;
+    }
+    start();
+    sleepForever();
+  }
+
+  private void sleepForever() {
+    while (true) {
+      try {
+        Thread.sleep(SLEEP_INTERVAL_MS);
+        if (!dfs.isClusterUp()) {
+          LOG.info(""Cluster is no longer up, exiting"");
+          return;
+        }
+      } catch (InterruptedException _) {
+        // nothing
+      }
+    }
+  }
+
+  /**
+   * Starts DFS as specified in member-variable options. Also writes out
+   * configuration and details, if requested.
+   */
+  public void start() throws IOException, FileNotFoundException {
+    dfs = new MiniDFSCluster.Builder(conf).nameNodePort(nameNodePort)
+                                          .numDataNodes(numDataNodes)
+                                          .startupOption(dfsOpts)
+                                          .build();
+    dfs.waitActive();
+    
+    LOG.info(""Started MiniDFSCluster -- namenode on port ""
+        + dfs.getNameNodePort());
+
+    if (writeConfig != null) {
+      FileOutputStream fos = new FileOutputStream(new File(writeConfig));
+      conf.writeXml(fos);
+      fos.close();
+    }
+
+    if (writeDetails != null) {
+      Map<String, Object> map = new TreeMap<String, Object>();
+      if (dfs != null) {
+        map.put(""namenode_port"", dfs.getNameNodePort());
+      }
+
+      FileWriter fw = new FileWriter(new File(writeDetails));
+      fw.write(new JSON().toJSON(map));
+      fw.close();
+    }
+  }
+
+  /**
+   * Parses arguments and fills out the member variables.
+   * @param args Command-line arguments.
+   * @return true on successful parse; false to indicate that the
+   * program should exit.
+   */
+  private boolean parseArguments(String[] args) {
+    Options options = makeOptions();
+    CommandLine cli;
+    try {
+      CommandLineParser parser = new GnuParser();
+      cli = parser.parse(options, args);
+    } catch(ParseException e) {
+      LOG.warn(""options parsing failed:  ""+e.getMessage());
+      new HelpFormatter().printHelp(""..."", options);
+      return false;
+    }
+
+    if (cli.hasOption(""help"")) {
+      new HelpFormatter().printHelp(""..."", options);
+      return false;
+    }
+    
+    if (cli.getArgs().length > 0) {
+      for (String arg : cli.getArgs()) {
+        LOG.error(""Unrecognized option: "" + arg);
+        new HelpFormatter().printHelp(""..."", options);
+        return false;
+      }
+    }
+
+    // HDFS
+    numDataNodes = intArgument(cli, ""datanodes"", 1);
+    nameNodePort = intArgument(cli, ""nnport"", 0);
+    dfsOpts = cli.hasOption(""format"") ?
+        StartupOption.FORMAT : StartupOption.REGULAR;
+
+    // Runner
+    writeDetails = cli.getOptionValue(""writeDetails"");
+    writeConfig = cli.getOptionValue(""writeConfig"");
+
+    // General
+    conf = new HdfsConfiguration();
+    updateConfiguration(conf, cli.getOptionValues(""D""));
+
+    return true;
+  }
+
+  /**
+   * Updates configuration based on what's given on the command line.
+   *
+   * @param conf2 The configuration object
+   * @param keyvalues An array of interleaved key value pairs.
+   */
+  private void updateConfiguration(Configuration conf2, String[] keyvalues) {
+    int num_confs_updated = 0;
+    if (keyvalues != null) {
+      for (String prop : keyvalues) {
+        String[] keyval = prop.split(""="", 2);
+        if (keyval.length == 2) {
+          conf2.set(keyval[0], keyval[1]);
+          num_confs_updated++;
+        } else {
+          LOG.warn(""Ignoring -D option "" + prop);
+        }
+      }
+    }
+    LOG.info(""Updated "" + num_confs_updated +
+        "" configuration settings from command line."");
+  }
+
+  /**
+   * Extracts an integer argument with specified default value.
+   */
+  private int intArgument(CommandLine cli, String argName, int defaultValue) {
+    String o = cli.getOptionValue(argName);
+    try {
+      if (o != null) {
+        return Integer.parseInt(o);
+      } 
+    } catch (NumberFormatException ex) {
+      LOG.error(""Couldn't parse value ("" + o + "") for option "" 
+          + argName + "". Using default: "" + defaultValue);
+    }
+    
+    return defaultValue;    
+  }
+
+  /**
+   * Starts a MiniDFSClusterManager with parameters drawn from the command line.
+   */
+  public static void main(String[] args) throws IOException {
+    new MiniDFSClusterManager().run(args);
+  }
+}
",HDFS-3167. CLI-based driver for MiniDFSCluster.- Contributed by Henry Robinson.--git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/branch-2@1308160 13f79535-47bb-0310-9956-ffa450edef68-
1529,Java,541aae12ef82767479bcd53afb3681b46dd890a5,,C,spring-projects,spring-framework,"[1, 3, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/org.springframework.web.portlet/src/main/java/org/springframework/web/portlet/mvc/annotation/AnnotationMethodHandlerAdapter.java b/org.springframework.web.portlet/src/main/java/org/springframework/web/portlet/mvc/annotation/AnnotationMethodHandlerAdapter.java
index f6b7c42043..e8fa23d6ac 100644
--- a/org.springframework.web.portlet/src/main/java/org/springframework/web/portlet/mvc/annotation/AnnotationMethodHandlerAdapter.java
+++ b/org.springframework.web.portlet/src/main/java/org/springframework/web/portlet/mvc/annotation/AnnotationMethodHandlerAdapter.java
@@ -601,7 +601,10 @@ public class AnnotationMethodHandlerAdapter extends PortletContentGenerator impl
 				return cookieValue;
 			}
-			else {
+			else if (cookieValue != null) {
 				return cookieValue.getValue();
 			}
+			else {
+				return null;
+			}
 		}
 
",SPR-5802 - NullPointerException when using- @CookieValue annotation--
1532,Java,e8585afa032d2aee0593b238c46799cbb884732d,,A,apache,hadoop,"[13, 654, 0, 1, 281, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 1, 18, 0, 0]","diff --git a/hadoop-yarn-project/CHANGES.txt b/hadoop-yarn-project/CHANGES.txt
index a83cc29faaa..5bd6f8e65b8 100644
--- a/hadoop-yarn-project/CHANGES.txt
+++ b/hadoop-yarn-project/CHANGES.txt
@@ -46,4 +46,7 @@ Release 2.0.5-beta - UNRELEASED
     (kkambatl via tucu)
 
+    YARN-45. Add protocol for schedulers to request containers back from
+    ApplicationMasters. (Carlo Curino, cdouglas)
+
   IMPROVEMENTS
 
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/api/protocolrecords/AllocateResponse.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/api/protocolrecords/AllocateResponse.java
index 0426ee359a6..8da0d95bb2c 100644
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/api/protocolrecords/AllocateResponse.java
+++ b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/api/protocolrecords/AllocateResponse.java
@@ -23,4 +23,5 @@
 import org.apache.hadoop.classification.InterfaceAudience.Private;
 import org.apache.hadoop.classification.InterfaceAudience.Public;
+import org.apache.hadoop.classification.InterfaceStability.Evolving;
 import org.apache.hadoop.classification.InterfaceStability.Stable;
 import org.apache.hadoop.classification.InterfaceStability.Unstable;
@@ -49,4 +50,5 @@
  *     <li>A list of nodes whose status has been updated.</li>
  *     <li>The number of available nodes in a cluster.</li>
+ *     <li>A description of resources requested back by the cluster</li>
  *   </ul>
  * </p>
@@ -153,3 +155,26 @@
   @Unstable
   public void setNumClusterNodes(int numNodes);
+
+  /**
+   * Get the description of containers owned by the AM, but requested back by
+   * the cluster. Note that the RM may have an inconsistent view of the
+   * resources owned by the AM. These messages are advisory, and the AM may
+   * elect to ignore them.
+   *
+   * The message is a snapshot of the resources the RM wants back from the AM.
+   * While demand persists, the RM will repeat its request; applications should
+   * not interpret each message as a request for <emph>additional<emph>
+   * resources on top of previous messages. Resources requested consistently
+   * over some duration may be forcibly killed by the RM.
+   *
+   * @return A specification of the resources to reclaim from this AM.
+   */
+  @Public
+  @Evolving
+  public PreemptionMessage getPreemptionMessage();
+
+  @Private
+  @Unstable
+  public void setPreemptionMessage(PreemptionMessage request);
+
 }
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/api/protocolrecords/PreemptionContainer.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/api/protocolrecords/PreemptionContainer.java
new file mode 100644
index 00000000000..d51d696854b
--- /dev/null
+++ b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/api/protocolrecords/PreemptionContainer.java
@@ -0,0 +1,44 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.yarn.api.protocolrecords;
+
+import org.apache.hadoop.classification.InterfaceAudience.Public;
+import org.apache.hadoop.classification.InterfaceAudience.Private;
+import org.apache.hadoop.classification.InterfaceStability.Evolving;
+import org.apache.hadoop.classification.InterfaceStability.Unstable;
+import org.apache.hadoop.yarn.api.records.ContainerId;
+
+/**
+ * Specific container requested back by the <code>ResourceManager</code>.
+ * @see PreemptionContract
+ * @see StrictPreemptionContract
+ */
+public interface PreemptionContainer {
+
+  /**
+   * @return Container referenced by this handle.
+   */
+  @Public
+  @Evolving
+  public ContainerId getId();
+
+  @Private
+  @Unstable
+  public void setId(ContainerId id);
+
+}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/api/protocolrecords/PreemptionContract.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/api/protocolrecords/PreemptionContract.java
new file mode 100644
index 00000000000..8fc64e5085e
--- /dev/null
+++ b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/api/protocolrecords/PreemptionContract.java
@@ -0,0 +1,73 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.yarn.api.protocolrecords;
+
+import java.util.List;
+import java.util.Set;
+
+import org.apache.hadoop.classification.InterfaceAudience.Private;
+import org.apache.hadoop.classification.InterfaceAudience.Public;
+import org.apache.hadoop.classification.InterfaceStability.Evolving;
+import org.apache.hadoop.classification.InterfaceStability.Unstable;
+
+/**
+ * Description of resources requested back by the <code>ResourceManager</code>.
+ * The <code>ApplicationMaster</code> (AM) can satisfy this request according
+ * to its own priorities to prevent containers from being forcibly killed by
+ * the platform.
+ * @see PreemptionMessage
+ */
+public interface PreemptionContract {
+
+  /**
+   * If the AM releases resources matching these requests, then the {@link
+   * PreemptionContainer}s enumerated in {@link #getContainers()} should not be
+   * evicted from the cluster. Due to delays in propagating cluster state and
+   * sending these messages, there are conditions where satisfied contracts may
+   * not prevent the platform from killing containers.
+   * @return List of {@link PreemptionResourceRequest} to update the
+   * <code>ApplicationMaster</code> about resources requested back by the
+   * <code>ResourceManager</code>.
+   * @see AllocateRequest#setAskList(List)
+   */
+  @Public
+  @Evolving
+  public List<PreemptionResourceRequest> getResourceRequest();
+
+  @Private
+  @Unstable
+  public void setResourceRequest(List<PreemptionResourceRequest> req);
+
+  /**
+   * Assign the set of {@link PreemptionContainer} specifying which containers
+   * owned by the <code>ApplicationMaster</code> that may be reclaimed by the
+   * <code>ResourceManager</code>. If the AM prefers a different set of
+   * containers, then it may checkpoint or kill containers matching the
+   * description in {@link #getResourceRequest}.
+   * @return Set of containers at risk if the contract is not met.
+   */
+  @Public
+  @Evolving
+  public Set<PreemptionContainer> getContainers();
+
+
+  @Private
+  @Unstable
+  public void setContainers(Set<PreemptionContainer> containers);
+
+}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/api/protocolrecords/PreemptionMessage.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/api/protocolrecords/PreemptionMessage.java
new file mode 100644
index 00000000000..a7961fead61
--- /dev/null
+++ b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/api/protocolrecords/PreemptionMessage.java
@@ -0,0 +1,84 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.yarn.api.protocolrecords;
+
+import org.apache.hadoop.classification.InterfaceAudience.Private;
+import org.apache.hadoop.classification.InterfaceAudience.Public;
+import org.apache.hadoop.classification.InterfaceStability.Evolving;
+import org.apache.hadoop.classification.InterfaceStability.Unstable;
+
+/**
+ * A {@link PreemptionMessage} is part of the RM-AM protocol, and it is used by
+ * the RM to specify resources that the RM wants to reclaim from this
+ * <code>ApplicationMaster</code> (AM). The AM receives a {@link
+ * StrictPreemptionContract} message encoding which containers the platform may
+ * forcibly kill, granting it an opportunity to checkpoint state or adjust its
+ * execution plan. The message may also include a {@link PreemptionContract}
+ * granting the AM more latitude in selecting which resources to return to the
+ * cluster.
+ *
+ * The AM should decode both parts of the message. The {@link
+ * StrictPreemptionContract} specifies particular allocations that the RM
+ * requires back. The AM can checkpoint containers' state, adjust its execution
+ * plan to move the computation, or take no action and hope that conditions that
+ * caused the RM to ask for the container will change.
+ *
+ * In contrast, the {@link PreemptionContract} also includes a description of
+ * resources with a set of containers. If the AM releases containers matching
+ * that profile, then the containers enumerated in {@link
+ * PreemptionContract#getContainers()} may not be killed.
+ *
+ * Each preemption message reflects the RM's current understanding of the
+ * cluster state, so a request to return <emph>N</emph> containers may not
+ * reflect containers the AM is releasing, recently exited containers the RM has
+ * yet to learn about, or new containers allocated before the message was
+ * generated. Conversely, an RM may request a different profile of containers in
+ * subsequent requests.
+ *
+ * The policy enforced by the RM is part of the scheduler. Generally, only
+ * containers that have been requested consistently should be killed, but the
+ * details are not specified.
+ */
+@Public
+@Evolving
+public interface PreemptionMessage {
+
+  /**
+   * @return Specific resources that may be killed by the
+   * <code>ResourceManager</code>
+   */
+  @Public
+  @Evolving
+  public StrictPreemptionContract getStrictContract();
+
+  @Private
+  @Unstable
+  public void setStrictContract(StrictPreemptionContract set);
+
+  /**
+   * @return Contract describing resources to return to the cluster.
+   */
+  @Public
+  @Evolving
+  public PreemptionContract getContract();
+
+  @Private
+  @Unstable
+  public void setContract(PreemptionContract contract);
+
+}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/api/protocolrecords/PreemptionResourceRequest.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/api/protocolrecords/PreemptionResourceRequest.java
new file mode 100644
index 00000000000..1187fd8d25f
--- /dev/null
+++ b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/api/protocolrecords/PreemptionResourceRequest.java
@@ -0,0 +1,45 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.yarn.api.protocolrecords;
+
+import org.apache.hadoop.classification.InterfaceAudience.Public;
+import org.apache.hadoop.classification.InterfaceAudience.Private;
+import org.apache.hadoop.classification.InterfaceStability.Evolving;
+import org.apache.hadoop.classification.InterfaceStability.Unstable;
+import org.apache.hadoop.yarn.api.records.ResourceRequest;
+
+/**
+ * Description of resources requested back by the cluster.
+ * @see PreemptionContract
+ * @see AllocateRequest#setAskList(java.util.List)
+ */
+public interface PreemptionResourceRequest {
+
+  /**
+   * @return Resource described in this request, to be matched against running
+   * containers.
+   */
+  @Public
+  @Evolving
+  public ResourceRequest getResourceRequest();
+
+  @Private
+  @Unstable
+  public void setResourceRequest(ResourceRequest req);
+
+}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/api/protocolrecords/StrictPreemptionContract.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/api/protocolrecords/StrictPreemptionContract.java
new file mode 100644
index 00000000000..11d7bb9f68b
--- /dev/null
+++ b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/api/protocolrecords/StrictPreemptionContract.java
@@ -0,0 +1,54 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.yarn.api.protocolrecords;
+
+import java.util.Set;
+
+import org.apache.hadoop.classification.InterfaceAudience.Private;
+import org.apache.hadoop.classification.InterfaceAudience.Public;
+import org.apache.hadoop.classification.InterfaceStability.Evolving;
+import org.apache.hadoop.classification.InterfaceStability.Unstable;
+import org.apache.hadoop.yarn.api.records.ContainerId;
+
+/**
+ * Enumeration of particular allocations to be reclaimed. The platform will
+ * reclaim exactly these resources, so the <code>ApplicationMaster</code> (AM)
+ * may attempt to checkpoint work or adjust its execution plan to accommodate
+ * it. In contrast to {@link PreemptionContract}, the AM has no flexibility in
+ * selecting which resources to return to the cluster.
+ * @see PreemptionMessage
+ */
+@Public
+@Evolving
+public interface StrictPreemptionContract {
+
+  /**
+   * Get the set of {@link PreemptionContainer} specifying containers owned by
+   * the <code>ApplicationMaster</code> that may be reclaimed by the
+   * <code>ResourceManager</code>.
+   * @return the set of {@link ContainerId} to be preempted.
+   */
+  @Public
+  @Evolving
+  public Set<PreemptionContainer> getContainers();
+
+  @Private
+  @Unstable
+  public void setContainers(Set<PreemptionContainer> containers);
+
+}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/api/protocolrecords/impl/pb/AllocateResponsePBImpl.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/api/protocolrecords/impl/pb/AllocateResponsePBImpl.java
index 4643e4ed02e..dac8c73580d 100644
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/api/protocolrecords/impl/pb/AllocateResponsePBImpl.java
+++ b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/api/protocolrecords/impl/pb/AllocateResponsePBImpl.java
@@ -25,4 +25,5 @@
 
 import org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse;
+import org.apache.hadoop.yarn.api.protocolrecords.PreemptionMessage;
 import org.apache.hadoop.yarn.api.records.Container;
 import org.apache.hadoop.yarn.api.records.ContainerStatus;
@@ -40,5 +41,5 @@
 import org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto;
 import org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProtoOrBuilder;
-
+import org.apache.hadoop.yarn.proto.YarnServiceProtos.PreemptionMessageProto;
 
     
@@ -55,4 +56,5 @@
 
   private List<NodeReport> updatedNodes = null;
+  private PreemptionMessage preempt;
   
   
@@ -95,4 +97,7 @@ private synchronized void mergeLocalToBuilder() {
       builder.setLimit(convertToProtoFormat(this.limit));
     }
+    if (this.preempt != null) {
+      builder.setPreempt(convertToProtoFormat(this.preempt));
+    }
   }
 
@@ -218,4 +223,26 @@ public synchronized void setNumClusterNodes(int numNodes) {
   }
 
+  @Override
+  public synchronized PreemptionMessage getPreemptionMessage() {
+    AllocateResponseProtoOrBuilder p = viaProto ? proto : builder;
+    if (this.preempt != null) {
+      return this.preempt;
+    }
+    if (!p.hasPreempt()) {
+      return null;
+    }
+    this.preempt = convertFromProtoFormat(p.getPreempt());
+    return this.preempt;
+  }
+
+  @Override
+  public synchronized void setPreemptionMessage(PreemptionMessage preempt) {
+    maybeInitBuilder();
+    if (null == preempt) {
+      builder.clearPreempt();
+    }
+    this.preempt = preempt;
+  }
+
   // Once this is called. updatedNodes will never be null - until a getProto is
   // called.
@@ -394,3 +421,10 @@ private synchronized ResourceProto convertToProtoFormat(Resource r) {
   }
 
+  private synchronized PreemptionMessagePBImpl convertFromProtoFormat(PreemptionMessageProto p) {
+    return new PreemptionMessagePBImpl(p);
+  }
+
+  private synchronized PreemptionMessageProto convertToProtoFormat(PreemptionMessage r) {
+    return ((PreemptionMessagePBImpl)r).getProto();
+  }
 }  
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/api/protocolrecords/impl/pb/PreemptionContainerPBImpl.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/api/protocolrecords/impl/pb/PreemptionContainerPBImpl.java
new file mode 100644
index 00000000000..624d1270f4b
--- /dev/null
+++ b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/api/protocolrecords/impl/pb/PreemptionContainerPBImpl.java
@@ -0,0 +1,103 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.yarn.api.protocolrecords.impl.pb;
+
+import org.apache.hadoop.yarn.api.protocolrecords.PreemptionContainer;
+import org.apache.hadoop.yarn.api.records.ContainerId;
+import org.apache.hadoop.yarn.api.records.impl.pb.ContainerIdPBImpl;
+import org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto;
+import org.apache.hadoop.yarn.proto.YarnServiceProtos.PreemptionContainerProto;
+import org.apache.hadoop.yarn.proto.YarnServiceProtos.PreemptionContainerProtoOrBuilder;
+
+public class PreemptionContainerPBImpl implements PreemptionContainer {
+
+  PreemptionContainerProto proto =
+    PreemptionContainerProto.getDefaultInstance();
+  PreemptionContainerProto.Builder builder = null;
+
+  boolean viaProto = false;
+  private ContainerId id;
+
+  public PreemptionContainerPBImpl() {
+    builder = PreemptionContainerProto.newBuilder();
+  }
+
+  public PreemptionContainerPBImpl(PreemptionContainerProto proto) {
+    this.proto = proto;
+    viaProto = true;
+  }
+
+  public synchronized PreemptionContainerProto getProto() {
+    mergeLocalToProto();
+    proto = viaProto ? proto : builder.build();
+    viaProto = true;
+    return proto;
+  }
+
+  private void mergeLocalToProto() {
+    if (viaProto)
+      maybeInitBuilder();
+    mergeLocalToBuilder();
+    proto = builder.build();
+    viaProto = true;
+  }
+
+  private void mergeLocalToBuilder() {
+    if (id != null) {
+      builder.setId(convertToProtoFormat(id));
+    }
+  }
+
+  private void maybeInitBuilder() {
+    if (viaProto || builder == null) {
+      builder = PreemptionContainerProto.newBuilder(proto);
+    }
+    viaProto = false;
+  }
+
+  @Override
+  public synchronized ContainerId getId() {
+    PreemptionContainerProtoOrBuilder p = viaProto ? proto : builder;
+    if (id != null) {
+      return id;
+    }
+    if (!p.hasId()) {
+      return null;
+    }
+    id = convertFromProtoFormat(p.getId());
+    return id;
+  }
+
+  @Override
+  public synchronized void setId(final ContainerId id) {
+    maybeInitBuilder();
+    if (null == id) {
+      builder.clearId();
+    }
+    this.id = id;
+  }
+
+  private ContainerIdPBImpl convertFromProtoFormat(ContainerIdProto p) {
+    return new ContainerIdPBImpl(p);
+  }
+
+  private ContainerIdProto convertToProtoFormat(ContainerId t) {
+    return ((ContainerIdPBImpl)t).getProto();
+  }
+
+}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/api/protocolrecords/impl/pb/PreemptionContractPBImpl.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/api/protocolrecords/impl/pb/PreemptionContractPBImpl.java
new file mode 100644
index 00000000000..61534365ca0
--- /dev/null
+++ b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/api/protocolrecords/impl/pb/PreemptionContractPBImpl.java
@@ -0,0 +1,228 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.yarn.api.protocolrecords.impl.pb;
+
+import java.util.ArrayList;
+import java.util.HashSet;
+import java.util.Iterator;
+import java.util.List;
+import java.util.Set;
+
+import org.apache.hadoop.yarn.api.protocolrecords.PreemptionContainer;
+import org.apache.hadoop.yarn.api.protocolrecords.PreemptionContract;
+import org.apache.hadoop.yarn.api.protocolrecords.PreemptionResourceRequest;
+import org.apache.hadoop.yarn.api.protocolrecords.impl.pb.PreemptionResourceRequestPBImpl;
+import org.apache.hadoop.yarn.proto.YarnServiceProtos.PreemptionContainerProto;
+import org.apache.hadoop.yarn.proto.YarnServiceProtos.PreemptionContractProto;
+import org.apache.hadoop.yarn.proto.YarnServiceProtos.PreemptionContractProtoOrBuilder;
+import org.apache.hadoop.yarn.proto.YarnServiceProtos.PreemptionResourceRequestProto;
+
+public class PreemptionContractPBImpl implements PreemptionContract {
+
+  PreemptionContractProto proto = PreemptionContractProto.getDefaultInstance();
+  PreemptionContractProto.Builder builder = null;
+
+  boolean viaProto = false;
+  private Set<PreemptionContainer> containers;
+  private List<PreemptionResourceRequest> resources;
+
+  public PreemptionContractPBImpl() {
+    builder = PreemptionContractProto.newBuilder();
+  }
+
+  public PreemptionContractPBImpl(PreemptionContractProto proto) {
+    this.proto = proto;
+    viaProto = true;
+  }
+
+  public synchronized PreemptionContractProto getProto() {
+    mergeLocalToProto();
+    proto = viaProto ? proto : builder.build();
+    viaProto = true;
+    return proto;
+  }
+
+  private void mergeLocalToProto() {
+    if (viaProto)
+      maybeInitBuilder();
+    mergeLocalToBuilder();
+    proto = builder.build();
+    viaProto = true;
+  }
+
+  private void mergeLocalToBuilder() {
+    if (this.resources != null) {
+      addResourcesToProto();
+    }
+    if (this.containers != null) {
+      addContainersToProto();
+    }
+  }
+
+  private void maybeInitBuilder() {
+    if (viaProto || builder == null) {
+      builder = PreemptionContractProto.newBuilder(proto);
+    }
+    viaProto = false;
+  }
+
+  @Override
+  public synchronized Set<PreemptionContainer> getContainers() {
+    initPreemptionContainers();
+    return containers;
+  }
+
+  @Override
+  public synchronized void setContainers(
+      final Set<PreemptionContainer> containers) {
+    if (null == containers) {
+      builder.clearContainer();
+    }
+    this.containers = containers;
+  }
+
+  @Override
+  public synchronized List<PreemptionResourceRequest> getResourceRequest() {
+    initPreemptionResourceRequests();
+    return resources;
+  }
+
+  @Override
+  public synchronized void setResourceRequest(
+      final List<PreemptionResourceRequest> req) {
+    if (null == resources) {
+      builder.clearResource();
+    }
+    this.resources = req;
+  }
+
+  private void initPreemptionResourceRequests() {
+    if (resources != null) {
+      return;
+    }
+    PreemptionContractProtoOrBuilder p = viaProto ? proto : builder;
+    List<PreemptionResourceRequestProto> list = p.getResourceList();
+    resources = new ArrayList<PreemptionResourceRequest>();
+
+    for (PreemptionResourceRequestProto rr : list) {
+      resources.add(convertFromProtoFormat(rr));
+    }
+  }
+
+  private void addResourcesToProto() {
+    maybeInitBuilder();
+    builder.clearResource();
+    if (null == resources) {
+      return;
+    }
+    Iterable<PreemptionResourceRequestProto> iterable =
+      new Iterable<PreemptionResourceRequestProto>() {
+      @Override
+      public Iterator<PreemptionResourceRequestProto> iterator() {
+        return new Iterator<PreemptionResourceRequestProto>() {
+
+          Iterator<PreemptionResourceRequest> iter = resources.iterator();
+
+          @Override
+          public boolean hasNext() {
+            return iter.hasNext();
+          }
+
+          @Override
+          public PreemptionResourceRequestProto next() {
+            return convertToProtoFormat(iter.next());
+          }
+
+          @Override
+          public void remove() {
+            throw new UnsupportedOperationException();
+
+          }
+        };
+
+      }
+    };
+    builder.addAllResource(iterable);
+  }
+
+  private void initPreemptionContainers() {
+    if (containers != null) {
+      return;
+    }
+    PreemptionContractProtoOrBuilder p = viaProto ? proto : builder;
+    List<PreemptionContainerProto> list = p.getContainerList();
+    containers = new HashSet<PreemptionContainer>();
+
+    for (PreemptionContainerProto c : list) {
+      containers.add(convertFromProtoFormat(c));
+    }
+  }
+
+  private void addContainersToProto() {
+    maybeInitBuilder();
+    builder.clearContainer();
+    if (null == containers) {
+      return;
+    }
+    Iterable<PreemptionContainerProto> iterable =
+      new Iterable<PreemptionContainerProto>() {
+      @Override
+      public Iterator<PreemptionContainerProto> iterator() {
+        return new Iterator<PreemptionContainerProto>() {
+
+          Iterator<PreemptionContainer> iter = containers.iterator();
+
+          @Override
+          public boolean hasNext() {
+            return iter.hasNext();
+          }
+
+          @Override
+          public PreemptionContainerProto next() {
+            return convertToProtoFormat(iter.next());
+          }
+
+          @Override
+          public void remove() {
+            throw new UnsupportedOperationException();
+
+          }
+        };
+
+      }
+    };
+    builder.addAllContainer(iterable);
+  }
+
+  private PreemptionContainerPBImpl convertFromProtoFormat(PreemptionContainerProto p) {
+    return new PreemptionContainerPBImpl(p);
+  }
+
+  private PreemptionContainerProto convertToProtoFormat(PreemptionContainer t) {
+    return ((PreemptionContainerPBImpl)t).getProto();
+  }
+
+  private PreemptionResourceRequestPBImpl convertFromProtoFormat(PreemptionResourceRequestProto p) {
+    return new PreemptionResourceRequestPBImpl(p);
+  }
+
+  private PreemptionResourceRequestProto convertToProtoFormat(PreemptionResourceRequest t) {
+    return ((PreemptionResourceRequestPBImpl)t).getProto();
+  }
+
+}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/api/protocolrecords/impl/pb/PreemptionMessagePBImpl.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/api/protocolrecords/impl/pb/PreemptionMessagePBImpl.java
new file mode 100644
index 00000000000..72a7eb151ff
--- /dev/null
+++ b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/api/protocolrecords/impl/pb/PreemptionMessagePBImpl.java
@@ -0,0 +1,141 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.yarn.api.protocolrecords.impl.pb;
+
+import org.apache.hadoop.yarn.api.protocolrecords.PreemptionContract;
+import org.apache.hadoop.yarn.api.protocolrecords.PreemptionMessage;
+import org.apache.hadoop.yarn.api.protocolrecords.StrictPreemptionContract;
+import org.apache.hadoop.yarn.proto.YarnServiceProtos.PreemptionContractProto;
+import org.apache.hadoop.yarn.proto.YarnServiceProtos.PreemptionMessageProto;
+import org.apache.hadoop.yarn.proto.YarnServiceProtos.PreemptionMessageProtoOrBuilder;
+import org.apache.hadoop.yarn.proto.YarnServiceProtos.StrictPreemptionContractProto;
+
+public class PreemptionMessagePBImpl implements PreemptionMessage {
+
+  PreemptionMessageProto proto = PreemptionMessageProto.getDefaultInstance();
+  PreemptionMessageProto.Builder builder = null;
+
+  boolean viaProto = false;
+  private StrictPreemptionContract strict;
+  private PreemptionContract contract;
+
+  public PreemptionMessagePBImpl() {
+    builder = PreemptionMessageProto.newBuilder();
+  }
+
+  public PreemptionMessagePBImpl(PreemptionMessageProto proto) {
+    this.proto = proto;
+    viaProto = true;
+  }
+
+  public synchronized PreemptionMessageProto getProto() {
+    mergeLocalToProto();
+    proto = viaProto ? proto : builder.build();
+    viaProto = true;
+    return proto;
+  }
+
+  private void mergeLocalToProto() {
+    if (viaProto)
+      maybeInitBuilder();
+    mergeLocalToBuilder();
+    proto = builder.build();
+    viaProto = true;
+  }
+
+  private void mergeLocalToBuilder() {
+    if (strict != null) {
+      builder.setStrictContract(convertToProtoFormat(strict));
+    }
+    if (contract != null) {
+      builder.setContract(convertToProtoFormat(contract));
+    }
+  }
+
+  private void maybeInitBuilder() {
+    if (viaProto || builder == null) {
+      builder = PreemptionMessageProto.newBuilder(proto);
+    }
+    viaProto = false;
+  }
+
+  @Override
+  public synchronized StrictPreemptionContract getStrictContract() {
+    PreemptionMessageProtoOrBuilder p = viaProto ? proto : builder;
+    if (strict != null) {
+      return strict;
+    }
+    if (!p.hasStrictContract()) {
+      return null;
+    }
+    strict = convertFromProtoFormat(p.getStrictContract());
+    return strict;
+  }
+
+  @Override
+  public synchronized void setStrictContract(StrictPreemptionContract strict) {
+    maybeInitBuilder();
+    if (null == strict) {
+      builder.clearStrictContract();
+    }
+    this.strict = strict;
+  }
+
+  @Override
+  public synchronized PreemptionContract getContract() {
+    PreemptionMessageProtoOrBuilder p = viaProto ? proto : builder;
+    if (contract != null) {
+      return contract;
+    }
+    if (!p.hasContract()) {
+      return null;
+    }
+    contract = convertFromProtoFormat(p.getContract());
+    return contract;
+  }
+
+  @Override
+  public synchronized void setContract(final PreemptionContract c) {
+    maybeInitBuilder();
+    if (null == c) {
+      builder.clearContract();
+    }
+    this.contract = c;
+  }
+
+  private StrictPreemptionContractPBImpl convertFromProtoFormat(
+      StrictPreemptionContractProto p) {
+    return new StrictPreemptionContractPBImpl(p);
+  }
+
+  private StrictPreemptionContractProto convertToProtoFormat(
+      StrictPreemptionContract t) {
+    return ((StrictPreemptionContractPBImpl)t).getProto();
+  }
+
+  private PreemptionContractPBImpl convertFromProtoFormat(
+      PreemptionContractProto p) {
+    return new PreemptionContractPBImpl(p);
+  }
+
+  private PreemptionContractProto convertToProtoFormat(
+      PreemptionContract t) {
+    return ((PreemptionContractPBImpl)t).getProto();
+  }
+
+}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/api/protocolrecords/impl/pb/PreemptionResourceRequestPBImpl.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/api/protocolrecords/impl/pb/PreemptionResourceRequestPBImpl.java
new file mode 100644
index 00000000000..8b6ca2d4f60
--- /dev/null
+++ b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/api/protocolrecords/impl/pb/PreemptionResourceRequestPBImpl.java
@@ -0,0 +1,103 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.yarn.api.protocolrecords.impl.pb;
+
+import org.apache.hadoop.yarn.api.protocolrecords.PreemptionResourceRequest;
+import org.apache.hadoop.yarn.api.records.ResourceRequest;
+import org.apache.hadoop.yarn.api.records.impl.pb.ResourceRequestPBImpl;
+import org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto;
+import org.apache.hadoop.yarn.proto.YarnServiceProtos.PreemptionResourceRequestProto;
+import org.apache.hadoop.yarn.proto.YarnServiceProtos.PreemptionResourceRequestProtoOrBuilder;
+
+public class PreemptionResourceRequestPBImpl implements PreemptionResourceRequest {
+
+  PreemptionResourceRequestProto proto =
+    PreemptionResourceRequestProto.getDefaultInstance();
+  PreemptionResourceRequestProto.Builder builder = null;
+
+  boolean viaProto = false;
+  private ResourceRequest rr;
+
+  public PreemptionResourceRequestPBImpl() {
+    builder = PreemptionResourceRequestProto.newBuilder();
+  }
+
+  public PreemptionResourceRequestPBImpl(PreemptionResourceRequestProto proto) {
+    this.proto = proto;
+    viaProto = true;
+  }
+
+  public synchronized PreemptionResourceRequestProto getProto() {
+    mergeLocalToProto();
+    proto = viaProto ? proto : builder.build();
+    viaProto = true;
+    return proto;
+  }
+
+  private void mergeLocalToProto() {
+    if (viaProto)
+      maybeInitBuilder();
+    mergeLocalToBuilder();
+    proto = builder.build();
+    viaProto = true;
+  }
+
+  private void mergeLocalToBuilder() {
+    if (rr != null) {
+      builder.setResource(convertToProtoFormat(rr));
+    }
+  }
+
+  private void maybeInitBuilder() {
+    if (viaProto || builder == null) {
+      builder = PreemptionResourceRequestProto.newBuilder(proto);
+    }
+    viaProto = false;
+  }
+
+  @Override
+  public synchronized ResourceRequest getResourceRequest() {
+    PreemptionResourceRequestProtoOrBuilder p = viaProto ? proto : builder;
+    if (rr != null) {
+      return rr;
+    }
+    if (!p.hasResource()) {
+      return null;
+    }
+    rr = convertFromProtoFormat(p.getResource());
+    return rr;
+  }
+
+  @Override
+  public synchronized void setResourceRequest(final ResourceRequest rr) {
+    maybeInitBuilder();
+    if (null == rr) {
+      builder.clearResource();
+    }
+    this.rr = rr;
+  }
+
+  private ResourceRequestPBImpl convertFromProtoFormat(ResourceRequestProto p) {
+    return new ResourceRequestPBImpl(p);
+  }
+
+  private ResourceRequestProto convertToProtoFormat(ResourceRequest t) {
+    return ((ResourceRequestPBImpl)t).getProto();
+  }
+
+}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/api/protocolrecords/impl/pb/StrictPreemptionContractPBImpl.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/api/protocolrecords/impl/pb/StrictPreemptionContractPBImpl.java
new file mode 100644
index 00000000000..7759ba22c2e
--- /dev/null
+++ b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/api/protocolrecords/impl/pb/StrictPreemptionContractPBImpl.java
@@ -0,0 +1,148 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.yarn.api.protocolrecords.impl.pb;
+
+import java.util.HashSet;
+import java.util.Iterator;
+import java.util.List;
+import java.util.Set;
+
+import org.apache.hadoop.yarn.api.protocolrecords.PreemptionContainer;
+import org.apache.hadoop.yarn.api.protocolrecords.StrictPreemptionContract;
+import org.apache.hadoop.yarn.proto.YarnServiceProtos.PreemptionContainerProto;
+import org.apache.hadoop.yarn.proto.YarnServiceProtos.StrictPreemptionContractProto;
+import org.apache.hadoop.yarn.proto.YarnServiceProtos.StrictPreemptionContractProtoOrBuilder;
+
+public class StrictPreemptionContractPBImpl implements StrictPreemptionContract {
+
+  StrictPreemptionContractProto proto =
+    StrictPreemptionContractProto.getDefaultInstance();
+  StrictPreemptionContractProto.Builder builder = null;
+
+  boolean viaProto = false;
+  private Set<PreemptionContainer> containers;
+
+  public StrictPreemptionContractPBImpl() {
+    builder = StrictPreemptionContractProto.newBuilder();
+  }
+
+  public StrictPreemptionContractPBImpl(StrictPreemptionContractProto proto) {
+    this.proto = proto;
+    viaProto = true;
+  }
+
+  public synchronized StrictPreemptionContractProto getProto() {
+    mergeLocalToProto();
+    proto = viaProto ? proto : builder.build();
+    viaProto = true;
+    return proto;
+  }
+
+  private void mergeLocalToProto() {
+    if (viaProto)
+      maybeInitBuilder();
+    mergeLocalToBuilder();
+    proto = builder.build();
+    viaProto = true;
+  }
+
+  private void mergeLocalToBuilder() {
+    if (this.containers != null) {
+      addContainersToProto();
+    }
+  }
+
+  private void maybeInitBuilder() {
+    if (viaProto || builder == null) {
+      builder = StrictPreemptionContractProto.newBuilder(proto);
+    }
+    viaProto = false;
+  }
+
+  @Override
+  public synchronized Set<PreemptionContainer> getContainers() {
+    initIds();
+    return containers;
+  }
+
+  @Override
+  public synchronized void setContainers(
+      final Set<PreemptionContainer> containers) {
+    if (null == containers) {
+      builder.clearContainer();
+    }
+    this.containers = containers;
+  }
+
+  private void initIds() {
+    if (containers != null) {
+      return;
+    }
+    StrictPreemptionContractProtoOrBuilder p = viaProto ? proto : builder;
+    List<PreemptionContainerProto> list = p.getContainerList();
+    containers = new HashSet<PreemptionContainer>();
+
+    for (PreemptionContainerProto c : list) {
+      containers.add(convertFromProtoFormat(c));
+    }
+  }
+
+  private void addContainersToProto() {
+    maybeInitBuilder();
+    builder.clearContainer();
+    if (containers == null) {
+      return;
+    }
+    Iterable<PreemptionContainerProto> iterable = new Iterable<PreemptionContainerProto>() {
+      @Override
+      public Iterator<PreemptionContainerProto> iterator() {
+        return new Iterator<PreemptionContainerProto>() {
+
+          Iterator<PreemptionContainer> iter = containers.iterator();
+
+          @Override
+          public boolean hasNext() {
+            return iter.hasNext();
+          }
+
+          @Override
+          public PreemptionContainerProto next() {
+            return convertToProtoFormat(iter.next());
+          }
+
+          @Override
+          public void remove() {
+            throw new UnsupportedOperationException();
+
+          }
+        };
+
+      }
+    };
+    builder.addAllContainer(iterable);
+  }
+
+  private PreemptionContainerPBImpl convertFromProtoFormat(PreemptionContainerProto p) {
+    return new PreemptionContainerPBImpl(p);
+  }
+
+  private PreemptionContainerProto convertToProtoFormat(PreemptionContainer t) {
+    return ((PreemptionContainerPBImpl)t).getProto();
+  }
+
+}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/proto/yarn_service_protos.proto b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/proto/yarn_service_protos.proto
index ad3b5f18072..6ac02741bac 100644
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/proto/yarn_service_protos.proto
+++ b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/proto/yarn_service_protos.proto
@@ -67,7 +67,28 @@ message AllocateResponseProto {
   repeated NodeReportProto updated_nodes = 6;
   optional int32 num_cluster_nodes = 7;
+  optional PreemptionMessageProto preempt = 8;
 }
 
+message PreemptionMessageProto {
+  optional StrictPreemptionContractProto strictContract = 1;
+  optional PreemptionContractProto contract = 2;
+}
+
+message StrictPreemptionContractProto {
+  repeated PreemptionContainerProto container = 1;
+}
+
+message PreemptionContractProto {
+  repeated PreemptionResourceRequestProto resource = 1;
+  repeated PreemptionContainerProto container = 2;
+}
+
+message PreemptionContainerProto {
+  optional ContainerIdProto id = 1;
+}
 
+message PreemptionResourceRequestProto {
+  optional ResourceRequestProto resource = 1;
+}
 
 //////////////////////////////////////////////////////
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/src/test/java/org/apache/hadoop/yarn/client/TestAMRMClientAsync.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/src/test/java/org/apache/hadoop/yarn/client/TestAMRMClientAsync.java
index d95ce64f630..ff2c0a441a9 100644
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/src/test/java/org/apache/hadoop/yarn/client/TestAMRMClientAsync.java
+++ b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/src/test/java/org/apache/hadoop/yarn/client/TestAMRMClientAsync.java
@@ -114,5 +114,5 @@ private AllocateResponse createAllocateResponse(
       List<ContainerStatus> completed, List<Container> allocated) {
     AllocateResponse response = BuilderUtils.newAllocateResponse(0, completed, allocated,
-        new ArrayList<NodeReport>(), null, false, 1);
+        new ArrayList<NodeReport>(), null, false, 1, null);
     return response;
   }
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/util/BuilderUtils.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/util/BuilderUtils.java
index f09046e3712..e6699f39278 100644
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/util/BuilderUtils.java
+++ b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/util/BuilderUtils.java
@@ -30,4 +30,5 @@
 import org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest;
 import org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse;
+import org.apache.hadoop.yarn.api.protocolrecords.PreemptionMessage;
 import org.apache.hadoop.yarn.api.records.ApplicationAccessType;
 import org.apache.hadoop.yarn.api.records.ApplicationAttemptId;
@@ -405,5 +406,6 @@ public static AllocateResponse newAllocateResponse(int responseId,
       List<ContainerStatus> completedContainers,
       List<Container> allocatedContainers, List<NodeReport> updatedNodes,
-      Resource availResources, boolean reboot, int numClusterNodes) {
+      Resource availResources, boolean reboot, int numClusterNodes,
+      PreemptionMessage preempt) {
     AllocateResponse response = recordFactory
         .newRecordInstance(AllocateResponse.class);
@@ -415,4 +417,5 @@ public static AllocateResponse newAllocateResponse(int responseId,
     response.setAvailableResources(availResources);
     response.setReboot(reboot);
+    response.setPreemptionMessage(preempt);
 
     return response;
",YARN-45. Add protocol for schedulers to request- containers back from ApplicationMasters. Contributed by Carlo Curino and- Chris Douglas.--git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/branch-2@1479773 13f79535-47bb-0310-9956-ffa450edef68-
1536,Java,ffd554b271debbdb29ac9f130ca6797f4859a1f9,,C,apache,hadoop,"[1, 32, 0, 1, 5, 0, 0, 1, 76, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 0, 0, 0, 0, 0, 0]","diff --git a/hadoop-yarn-project/CHANGES.txt b/hadoop-yarn-project/CHANGES.txt
index 7d48a4fe12a..e34dbbf3c04 100644
--- a/hadoop-yarn-project/CHANGES.txt
+++ b/hadoop-yarn-project/CHANGES.txt
@@ -334,4 +334,8 @@ Release 2.4.0 - UNRELEASED
     vinodkv)
 
+    YARN-1734. Fixed ResourceManager to update the configurations when it
+    transits from standby to active mode so as to assimilate any changes that
+    happened while it was in standby mode. (Xuan Gong via vinodkv)
+
 Release 2.3.1 - UNRELEASED
 
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/AdminService.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/AdminService.java
index 70845c775e4..c53d40f54a1 100644
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/AdminService.java
+++ b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/AdminService.java
@@ -251,8 +251,18 @@ public synchronized void monitorHealth()
   public synchronized void transitionToActive(
       HAServiceProtocol.StateChangeRequestInfo reqInfo) throws IOException {
+    // call refreshAdminAcls before HA state transition
+    // for the case that adminAcls have been updated in previous active RM
+    try {
+      refreshAdminAcls(false);
+    } catch (YarnException ex) {
+      throw new ServiceFailedException(""Can not execute refreshAdminAcls"", ex);
+    }
+
     UserGroupInformation user = checkAccess(""transitionToActive"");
     checkHaStateChange(reqInfo);
     try {
       rm.transitionToActive();
+      // call all refresh*s for active RM to get the updated configurations.
+      refreshAll();
       RMAuditLogger.logSuccess(user.getShortUserName(),
           ""transitionToActive"", ""RMHAProtocolService"");
@@ -269,4 +279,11 @@ public synchronized void transitionToActive(
   public synchronized void transitionToStandby(
       HAServiceProtocol.StateChangeRequestInfo reqInfo) throws IOException {
+    // call refreshAdminAcls before HA state transition
+    // for the case that adminAcls have been updated in previous active RM
+    try {
+      refreshAdminAcls(false);
+    } catch (YarnException ex) {
+      throw new ServiceFailedException(""Can not execute refreshAdminAcls"", ex);
+    }
     UserGroupInformation user = checkAccess(""transitionToStandby"");
     checkHaStateChange(reqInfo);
@@ -407,8 +424,13 @@ public RefreshUserToGroupsMappingsResponse refreshUserToGroupsMappings(
   public RefreshAdminAclsResponse refreshAdminAcls(
       RefreshAdminAclsRequest request) throws YarnException, IOException {
+    return refreshAdminAcls(true);
+  }
+
+  private RefreshAdminAclsResponse refreshAdminAcls(boolean checkRMHAState)
+      throws YarnException, IOException {
     String argName = ""refreshAdminAcls"";
     UserGroupInformation user = checkAcls(argName);
-    
-    if (!isRMActive()) {
+
+    if (checkRMHAState && !isRMActive()) {
       RMAuditLogger.logFailure(user.getShortUserName(), argName,
           adminAcl.toString(), ""AdminService"",
@@ -522,4 +544,22 @@ private synchronized Configuration getConfiguration(Configuration conf,
   }
 
+  private void refreshAll() throws ServiceFailedException {
+    try {
+      refreshQueues(RefreshQueuesRequest.newInstance());
+      refreshNodes(RefreshNodesRequest.newInstance());
+      refreshSuperUserGroupsConfiguration(
+          RefreshSuperUserGroupsConfigurationRequest.newInstance());
+      refreshUserToGroupsMappings(
+          RefreshUserToGroupsMappingsRequest.newInstance());
+      if (getConfig().getBoolean(
+          CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHORIZATION,
+          false)) {
+        refreshServiceAcls(RefreshServiceAclsRequest.newInstance());
+      }
+    } catch (Exception ex) {
+      throw new ServiceFailedException(ex.getMessage());
+    }
+  }
+
   @VisibleForTesting
   public AccessControlList getAccessControlList() {
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/TestRMAdminService.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/TestRMAdminService.java
index e67b81f36f2..60259cddbd5 100644
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/TestRMAdminService.java
+++ b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/TestRMAdminService.java
@@ -35,4 +35,7 @@
 import org.apache.hadoop.fs.FileSystem;
 import org.apache.hadoop.fs.Path;
+import org.apache.hadoop.ha.HAServiceProtocol;
+import org.apache.hadoop.ha.HAServiceProtocol.HAServiceState;
+import org.apache.hadoop.ha.HAServiceProtocol.StateChangeRequestInfo;
 import org.apache.hadoop.security.GroupMappingServiceProvider;
 import org.apache.hadoop.security.Groups;
@@ -41,4 +44,5 @@
 import org.apache.hadoop.security.authorize.ProxyUsers;
 import org.apache.hadoop.security.authorize.ServiceAuthorizationManager;
+import org.apache.hadoop.yarn.conf.HAUtil;
 import org.apache.hadoop.yarn.conf.YarnConfiguration;
 import org.apache.hadoop.yarn.exceptions.YarnException;
@@ -519,4 +523,92 @@ public void testRefreshNodesWithFileSystemBasedConfigurationProvider()
   }
 
+  @Test
+  public void testRMHAWithFileSystemBasedConfiguration() throws IOException,
+      YarnException {
+    StateChangeRequestInfo requestInfo = new StateChangeRequestInfo(
+        HAServiceProtocol.RequestSource.REQUEST_BY_USER);
+    configuration.set(YarnConfiguration.RM_CONFIGURATION_PROVIDER_CLASS,
+        ""org.apache.hadoop.yarn.FileSystemBasedConfigurationProvider"");
+    configuration.setBoolean(YarnConfiguration.RM_HA_ENABLED, true);
+    configuration.setBoolean(YarnConfiguration.AUTO_FAILOVER_ENABLED, false);
+    configuration.set(YarnConfiguration.RM_HA_IDS, ""rm1,rm2"");
+    int base = 100;
+    for (String confKey : YarnConfiguration
+        .getServiceAddressConfKeys(configuration)) {
+      configuration.set(HAUtil.addSuffix(confKey, ""rm1""), ""0.0.0.0:""
+          + (base + 20));
+      configuration.set(HAUtil.addSuffix(confKey, ""rm2""), ""0.0.0.0:""
+          + (base + 40));
+      base = base * 2;
+    }
+    Configuration conf1 = new Configuration(configuration);
+    conf1.set(YarnConfiguration.RM_HA_ID, ""rm1"");
+    Configuration conf2 = new Configuration(configuration);
+    conf2.set(YarnConfiguration.RM_HA_ID, ""rm2"");
+
+    // upload default configurations
+    uploadDefaultConfiguration();
+
+    MockRM rm1 = null;
+    MockRM rm2 = null;
+    try {
+      rm1 = new MockRM(conf1);
+      rm1.init(conf1);
+      rm1.start();
+      Assert.assertTrue(rm1.getRMContext().getHAServiceState()
+          == HAServiceState.STANDBY);
+
+      rm2 = new MockRM(conf2);
+      rm2.init(conf1);
+      rm2.start();
+      Assert.assertTrue(rm2.getRMContext().getHAServiceState()
+          == HAServiceState.STANDBY);
+
+      rm1.adminService.transitionToActive(requestInfo);
+      Assert.assertTrue(rm1.getRMContext().getHAServiceState()
+          == HAServiceState.ACTIVE);
+
+      CapacitySchedulerConfiguration csConf =
+          new CapacitySchedulerConfiguration();
+      csConf.set(""yarn.scheduler.capacity.maximum-applications"", ""5000"");
+      uploadConfiguration(csConf, ""capacity-scheduler.xml"");
+
+      rm1.adminService.refreshQueues(RefreshQueuesRequest.newInstance());
+
+      int maxApps =
+          ((CapacityScheduler) rm1.getRMContext().getScheduler())
+              .getConfiguration().getMaximumSystemApplications();
+      Assert.assertEquals(maxApps, 5000);
+
+      // Before failover happens, the maxApps is
+      // still the default value on the standby rm : rm2
+      int maxAppsBeforeFailOver =
+          ((CapacityScheduler) rm2.getRMContext().getScheduler())
+              .getConfiguration().getMaximumSystemApplications();
+      Assert.assertEquals(maxAppsBeforeFailOver, 10000);
+
+      // Do the failover
+      rm1.adminService.transitionToStandby(requestInfo);
+      rm2.adminService.transitionToActive(requestInfo);
+      Assert.assertTrue(rm1.getRMContext().getHAServiceState()
+          == HAServiceState.STANDBY);
+      Assert.assertTrue(rm2.getRMContext().getHAServiceState()
+          == HAServiceState.ACTIVE);
+
+      int maxAppsAfter =
+          ((CapacityScheduler) rm2.getRMContext().getScheduler())
+              .getConfiguration().getMaximumSystemApplications();
+
+      Assert.assertEquals(maxAppsAfter, 5000);
+    } finally {
+      if (rm1 != null) {
+        rm1.stop();
+      }
+      if (rm2 != null) {
+        rm2.stop();
+      }
+    }
+  }
+
   private String writeConfigurationXML(Configuration conf, String confXMLName)
       throws IOException {
",YARN-1734. Fixed ResourceManager to update the- configurations when it transits from standby to active mode so as to- assimilate any changes that happened while it was in standby mode.- Contributed by Xuan Gong. svn merge --ignore-ancestry -c 1571539 ../../trunk/--git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/branch-2@1571540 13f79535-47bb-0310-9956-ffa450edef68-
1541,Java,8bd2486b519ed6dcdc638843514d9034b7f3c49f,,A,apache,hadoop,"[3, 296, 0, 3, 42, 0, 0, 1, 115, 0, 0, 34, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0]","diff --git a/CHANGES.txt b/CHANGES.txt
index 88ca9c8f0d2..06cf3033d5d 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -476,4 +476,7 @@ Trunk (unreleased changes)
     added in MAPREDUCE-739. (Mahadev Konar via cdouglas)
 
+    HADOOP-6148. Implement a fast, pure Java CRC32 calculator which outperforms
+    java.util.zip.CRC32.  (Todd Lipcon and Scott Carey via szetszwo)
+
   OPTIMIZATIONS
 
diff --git a/src/java/org/apache/hadoop/fs/ChecksumFileSystem.java b/src/java/org/apache/hadoop/fs/ChecksumFileSystem.java
index 72a09bd75f2..6f9701e4d72 100644
--- a/src/java/org/apache/hadoop/fs/ChecksumFileSystem.java
+++ b/src/java/org/apache/hadoop/fs/ChecksumFileSystem.java
@@ -28,4 +28,5 @@
 import org.apache.hadoop.fs.permission.FsPermission;
 import org.apache.hadoop.util.Progressable;
+import org.apache.hadoop.util.PureJavaCrc32;
 import org.apache.hadoop.util.StringUtils;
 
@@ -136,5 +137,5 @@ public ChecksumFSInputChecker(ChecksumFileSystem fs, Path file, int bufferSize)
           throw new IOException(""Not a checksum file: ""+sumFile);
         this.bytesPerSum = sums.readInt();
-        set(fs.verifyChecksum, new CRC32(), bytesPerSum, 4);
+        set(fs.verifyChecksum, new PureJavaCrc32(), bytesPerSum, 4);
       } catch (FileNotFoundException e) {         // quietly ignore
         set(fs.verifyChecksum, null, 1, 0);
@@ -331,5 +332,5 @@ public ChecksumFSOutputSummer(ChecksumFileSystem fs,
                           Progressable progress)
       throws IOException {
-      super(new CRC32(), fs.getBytesPerSum(), 4);
+      super(new PureJavaCrc32(), fs.getBytesPerSum(), 4);
       int bytesPerSum = fs.getBytesPerSum();
       this.datas = fs.getRawFileSystem().create(file, overwrite, bufferSize, 
diff --git a/src/java/org/apache/hadoop/util/DataChecksum.java b/src/java/org/apache/hadoop/util/DataChecksum.java
index 9aa339025b3..eb529bc483e 100644
--- a/src/java/org/apache/hadoop/util/DataChecksum.java
+++ b/src/java/org/apache/hadoop/util/DataChecksum.java
@@ -17,5 +17,5 @@
  */
 
-package org.apache.hadoop.util;
+package org.apache.hadoop.util;
 
 import java.util.zip.Checksum;
@@ -52,5 +52,5 @@ public static DataChecksum newDataChecksum( int type, int bytesPerChecksum ) {
                                CHECKSUM_NULL_SIZE, bytesPerChecksum );
     case CHECKSUM_CRC32 :
-      return new DataChecksum( CHECKSUM_CRC32, new CRC32(), 
+      return new DataChecksum( CHECKSUM_CRC32, new PureJavaCrc32(), 
                                CHECKSUM_CRC32_SIZE, bytesPerChecksum );
     default:
@@ -206,8 +206,8 @@ public int getNumBytesInSum() {
     return inSum;
   }
-  
-  public static final int SIZE_OF_INTEGER = Integer.SIZE / Byte.SIZE;
+  
+  public static final int SIZE_OF_INTEGER = Integer.SIZE / Byte.SIZE;
   static public int getChecksumHeaderSize() {
-    return 1 + SIZE_OF_INTEGER; // type byte, bytesPerChecksum int
+    return 1 + SIZE_OF_INTEGER; // type byte, bytesPerChecksum int
   }
   //Checksum Interface. Just a wrapper around member summer.
diff --git a/src/java/org/apache/hadoop/util/PureJavaCrc32.java b/src/java/org/apache/hadoop/util/PureJavaCrc32.java
new file mode 100644
index 00000000000..206f931b267
--- /dev/null
+++ b/src/java/org/apache/hadoop/util/PureJavaCrc32.java
@@ -0,0 +1,351 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.util;
+
+import java.util.zip.Checksum;
+
+/**
+ * A pure-java implementation of the CRC32 checksum that uses
+ * the same polynomial as the built-in native CRC32.
+ *
+ * This is to avoid the JNI overhead for certain uses of Checksumming
+ * where many small pieces of data are checksummed in succession.
+ *
+ * The current version is ~10x to 1.8x as fast as Sun's native
+ * java.util.zip.CRC32 in Java 1.6
+ *
+ * @see java.util.zip.CRC32
+ */
+public class PureJavaCrc32 implements Checksum {
+
+  /** the current CRC value, bit-flipped */
+  private int crc;
+
+  public PureJavaCrc32() {
+    reset();
+  }
+
+  /** {@inheritDoc} */
+  public long getValue() {
+    return (~crc) & 0xffffffffL;
+  }
+
+  /** {@inheritDoc} */
+  public void reset() {
+    crc = 0xffffffff;
+  }
+
+  /** {@inheritDoc} */
+  public void update(byte[] b, int off, int len) {
+    while(len > 3) {
+      int c0 = crc ^ b[off++];
+      int c1 = (crc >>>= 8) ^ b[off++];
+      int c2 = (crc >>>= 8) ^ b[off++];
+      int c3 = (crc >>>= 8) ^ b[off++];
+      crc = T4[c0 & 0xff] ^ T3[c1 & 0xff] ^ T2[c2 & 0xff] ^ T1[c3 & 0xff];
+      len -= 4;
+    }
+    while(len > 0) {
+      crc = (crc >>> 8) ^ T1[(crc ^ b[off++]) & 0xff];
+      len--;
+    }
+  }
+
+  /** {@inheritDoc} */
+  final public void update(int b) {
+    crc = (crc >>> 8) ^ T1[(crc ^ b) & 0xff];
+  }
+
+  /**
+   * Pre-generated lookup tables. For the code to generate these tables
+   * please see HDFS-297.
+   */
+
+  /** T1[x] is ~CRC(x) */
+  private static final int[] T1 = new int[] {
+    0x0, 0x77073096, 0xee0e612c, 0x990951ba,
+    0x76dc419, 0x706af48f, 0xe963a535, 0x9e6495a3,
+    0xedb8832, 0x79dcb8a4, 0xe0d5e91e, 0x97d2d988,
+    0x9b64c2b, 0x7eb17cbd, 0xe7b82d07, 0x90bf1d91,
+    0x1db71064, 0x6ab020f2, 0xf3b97148, 0x84be41de,
+    0x1adad47d, 0x6ddde4eb, 0xf4d4b551, 0x83d385c7,
+    0x136c9856, 0x646ba8c0, 0xfd62f97a, 0x8a65c9ec,
+    0x14015c4f, 0x63066cd9, 0xfa0f3d63, 0x8d080df5,
+    0x3b6e20c8, 0x4c69105e, 0xd56041e4, 0xa2677172,
+    0x3c03e4d1, 0x4b04d447, 0xd20d85fd, 0xa50ab56b,
+    0x35b5a8fa, 0x42b2986c, 0xdbbbc9d6, 0xacbcf940,
+    0x32d86ce3, 0x45df5c75, 0xdcd60dcf, 0xabd13d59,
+    0x26d930ac, 0x51de003a, 0xc8d75180, 0xbfd06116,
+    0x21b4f4b5, 0x56b3c423, 0xcfba9599, 0xb8bda50f,
+    0x2802b89e, 0x5f058808, 0xc60cd9b2, 0xb10be924,
+    0x2f6f7c87, 0x58684c11, 0xc1611dab, 0xb6662d3d,
+    0x76dc4190, 0x1db7106, 0x98d220bc, 0xefd5102a,
+    0x71b18589, 0x6b6b51f, 0x9fbfe4a5, 0xe8b8d433,
+    0x7807c9a2, 0xf00f934, 0x9609a88e, 0xe10e9818,
+    0x7f6a0dbb, 0x86d3d2d, 0x91646c97, 0xe6635c01,
+    0x6b6b51f4, 0x1c6c6162, 0x856530d8, 0xf262004e,
+    0x6c0695ed, 0x1b01a57b, 0x8208f4c1, 0xf50fc457,
+    0x65b0d9c6, 0x12b7e950, 0x8bbeb8ea, 0xfcb9887c,
+    0x62dd1ddf, 0x15da2d49, 0x8cd37cf3, 0xfbd44c65,
+    0x4db26158, 0x3ab551ce, 0xa3bc0074, 0xd4bb30e2,
+    0x4adfa541, 0x3dd895d7, 0xa4d1c46d, 0xd3d6f4fb,
+    0x4369e96a, 0x346ed9fc, 0xad678846, 0xda60b8d0,
+    0x44042d73, 0x33031de5, 0xaa0a4c5f, 0xdd0d7cc9,
+    0x5005713c, 0x270241aa, 0xbe0b1010, 0xc90c2086,
+    0x5768b525, 0x206f85b3, 0xb966d409, 0xce61e49f,
+    0x5edef90e, 0x29d9c998, 0xb0d09822, 0xc7d7a8b4,
+    0x59b33d17, 0x2eb40d81, 0xb7bd5c3b, 0xc0ba6cad,
+    0xedb88320, 0x9abfb3b6, 0x3b6e20c, 0x74b1d29a,
+    0xead54739, 0x9dd277af, 0x4db2615, 0x73dc1683,
+    0xe3630b12, 0x94643b84, 0xd6d6a3e, 0x7a6a5aa8,
+    0xe40ecf0b, 0x9309ff9d, 0xa00ae27, 0x7d079eb1,
+    0xf00f9344, 0x8708a3d2, 0x1e01f268, 0x6906c2fe,
+    0xf762575d, 0x806567cb, 0x196c3671, 0x6e6b06e7,
+    0xfed41b76, 0x89d32be0, 0x10da7a5a, 0x67dd4acc,
+    0xf9b9df6f, 0x8ebeeff9, 0x17b7be43, 0x60b08ed5,
+    0xd6d6a3e8, 0xa1d1937e, 0x38d8c2c4, 0x4fdff252,
+    0xd1bb67f1, 0xa6bc5767, 0x3fb506dd, 0x48b2364b,
+    0xd80d2bda, 0xaf0a1b4c, 0x36034af6, 0x41047a60,
+    0xdf60efc3, 0xa867df55, 0x316e8eef, 0x4669be79,
+    0xcb61b38c, 0xbc66831a, 0x256fd2a0, 0x5268e236,
+    0xcc0c7795, 0xbb0b4703, 0x220216b9, 0x5505262f,
+    0xc5ba3bbe, 0xb2bd0b28, 0x2bb45a92, 0x5cb36a04,
+    0xc2d7ffa7, 0xb5d0cf31, 0x2cd99e8b, 0x5bdeae1d,
+    0x9b64c2b0, 0xec63f226, 0x756aa39c, 0x26d930a,
+    0x9c0906a9, 0xeb0e363f, 0x72076785, 0x5005713,
+    0x95bf4a82, 0xe2b87a14, 0x7bb12bae, 0xcb61b38,
+    0x92d28e9b, 0xe5d5be0d, 0x7cdcefb7, 0xbdbdf21,
+    0x86d3d2d4, 0xf1d4e242, 0x68ddb3f8, 0x1fda836e,
+    0x81be16cd, 0xf6b9265b, 0x6fb077e1, 0x18b74777,
+    0x88085ae6, 0xff0f6a70, 0x66063bca, 0x11010b5c,
+    0x8f659eff, 0xf862ae69, 0x616bffd3, 0x166ccf45,
+    0xa00ae278, 0xd70dd2ee, 0x4e048354, 0x3903b3c2,
+    0xa7672661, 0xd06016f7, 0x4969474d, 0x3e6e77db,
+    0xaed16a4a, 0xd9d65adc, 0x40df0b66, 0x37d83bf0,
+    0xa9bcae53, 0xdebb9ec5, 0x47b2cf7f, 0x30b5ffe9,
+    0xbdbdf21c, 0xcabac28a, 0x53b39330, 0x24b4a3a6,
+    0xbad03605, 0xcdd70693, 0x54de5729, 0x23d967bf,
+    0xb3667a2e, 0xc4614ab8, 0x5d681b02, 0x2a6f2b94,
+    0xb40bbe37, 0xc30c8ea1, 0x5a05df1b, 0x2d02ef8d
+  };
+
+  /** T2[x] is ~CRC(x followed by one 0x00 byte) */
+  private static final int[] T2 = new int[] {
+    0x0, 0x191b3141, 0x32366282, 0x2b2d53c3,
+    0x646cc504, 0x7d77f445, 0x565aa786, 0x4f4196c7,
+    0xc8d98a08, 0xd1c2bb49, 0xfaefe88a, 0xe3f4d9cb,
+    0xacb54f0c, 0xb5ae7e4d, 0x9e832d8e, 0x87981ccf,
+    0x4ac21251, 0x53d92310, 0x78f470d3, 0x61ef4192,
+    0x2eaed755, 0x37b5e614, 0x1c98b5d7, 0x5838496,
+    0x821b9859, 0x9b00a918, 0xb02dfadb, 0xa936cb9a,
+    0xe6775d5d, 0xff6c6c1c, 0xd4413fdf, 0xcd5a0e9e,
+    0x958424a2, 0x8c9f15e3, 0xa7b24620, 0xbea97761,
+    0xf1e8e1a6, 0xe8f3d0e7, 0xc3de8324, 0xdac5b265,
+    0x5d5daeaa, 0x44469feb, 0x6f6bcc28, 0x7670fd69,
+    0x39316bae, 0x202a5aef, 0xb07092c, 0x121c386d,
+    0xdf4636f3, 0xc65d07b2, 0xed705471, 0xf46b6530,
+    0xbb2af3f7, 0xa231c2b6, 0x891c9175, 0x9007a034,
+    0x179fbcfb, 0xe848dba, 0x25a9de79, 0x3cb2ef38,
+    0x73f379ff, 0x6ae848be, 0x41c51b7d, 0x58de2a3c,
+    0xf0794f05, 0xe9627e44, 0xc24f2d87, 0xdb541cc6,
+    0x94158a01, 0x8d0ebb40, 0xa623e883, 0xbf38d9c2,
+    0x38a0c50d, 0x21bbf44c, 0xa96a78f, 0x138d96ce,
+    0x5ccc0009, 0x45d73148, 0x6efa628b, 0x77e153ca,
+    0xbabb5d54, 0xa3a06c15, 0x888d3fd6, 0x91960e97,
+    0xded79850, 0xc7cca911, 0xece1fad2, 0xf5facb93,
+    0x7262d75c, 0x6b79e61d, 0x4054b5de, 0x594f849f,
+    0x160e1258, 0xf152319, 0x243870da, 0x3d23419b,
+    0x65fd6ba7, 0x7ce65ae6, 0x57cb0925, 0x4ed03864,
+    0x191aea3, 0x188a9fe2, 0x33a7cc21, 0x2abcfd60,
+    0xad24e1af, 0xb43fd0ee, 0x9f12832d, 0x8609b26c,
+    0xc94824ab, 0xd05315ea, 0xfb7e4629, 0xe2657768,
+    0x2f3f79f6, 0x362448b7, 0x1d091b74, 0x4122a35,
+    0x4b53bcf2, 0x52488db3, 0x7965de70, 0x607eef31,
+    0xe7e6f3fe, 0xfefdc2bf, 0xd5d0917c, 0xcccba03d,
+    0x838a36fa, 0x9a9107bb, 0xb1bc5478, 0xa8a76539,
+    0x3b83984b, 0x2298a90a, 0x9b5fac9, 0x10aecb88,
+    0x5fef5d4f, 0x46f46c0e, 0x6dd93fcd, 0x74c20e8c,
+    0xf35a1243, 0xea412302, 0xc16c70c1, 0xd8774180,
+    0x9736d747, 0x8e2de606, 0xa500b5c5, 0xbc1b8484,
+    0x71418a1a, 0x685abb5b, 0x4377e898, 0x5a6cd9d9,
+    0x152d4f1e, 0xc367e5f, 0x271b2d9c, 0x3e001cdd,
+    0xb9980012, 0xa0833153, 0x8bae6290, 0x92b553d1,
+    0xddf4c516, 0xc4eff457, 0xefc2a794, 0xf6d996d5,
+    0xae07bce9, 0xb71c8da8, 0x9c31de6b, 0x852aef2a,
+    0xca6b79ed, 0xd37048ac, 0xf85d1b6f, 0xe1462a2e,
+    0x66de36e1, 0x7fc507a0, 0x54e85463, 0x4df36522,
+    0x2b2f3e5, 0x1ba9c2a4, 0x30849167, 0x299fa026,
+    0xe4c5aeb8, 0xfdde9ff9, 0xd6f3cc3a, 0xcfe8fd7b,
+    0x80a96bbc, 0x99b25afd, 0xb29f093e, 0xab84387f,
+    0x2c1c24b0, 0x350715f1, 0x1e2a4632, 0x7317773,
+    0x4870e1b4, 0x516bd0f5, 0x7a468336, 0x635db277,
+    0xcbfad74e, 0xd2e1e60f, 0xf9ccb5cc, 0xe0d7848d,
+    0xaf96124a, 0xb68d230b, 0x9da070c8, 0x84bb4189,
+    0x3235d46, 0x1a386c07, 0x31153fc4, 0x280e0e85,
+    0x674f9842, 0x7e54a903, 0x5579fac0, 0x4c62cb81,
+    0x8138c51f, 0x9823f45e, 0xb30ea79d, 0xaa1596dc,
+    0xe554001b, 0xfc4f315a, 0xd7626299, 0xce7953d8,
+    0x49e14f17, 0x50fa7e56, 0x7bd72d95, 0x62cc1cd4,
+    0x2d8d8a13, 0x3496bb52, 0x1fbbe891, 0x6a0d9d0,
+    0x5e7ef3ec, 0x4765c2ad, 0x6c48916e, 0x7553a02f,
+    0x3a1236e8, 0x230907a9, 0x824546a, 0x113f652b,
+    0x96a779e4, 0x8fbc48a5, 0xa4911b66, 0xbd8a2a27,
+    0xf2cbbce0, 0xebd08da1, 0xc0fdde62, 0xd9e6ef23,
+    0x14bce1bd, 0xda7d0fc, 0x268a833f, 0x3f91b27e,
+    0x70d024b9, 0x69cb15f8, 0x42e6463b, 0x5bfd777a,
+    0xdc656bb5, 0xc57e5af4, 0xee530937, 0xf7483876,
+    0xb809aeb1, 0xa1129ff0, 0x8a3fcc33, 0x9324fd72
+  };
+
+  /** T3[x] is ~CRC(x followed by two 0x00 bytes) */
+  private static final int[] T3 = new int[] {
+    0x0, 0x1c26a37, 0x384d46e, 0x246be59,
+    0x709a8dc, 0x6cbc2eb, 0x48d7cb2, 0x54f1685,
+    0xe1351b8, 0xfd13b8f, 0xd9785d6, 0xc55efe1,
+    0x91af964, 0x8d89353, 0xa9e2d0a, 0xb5c473d,
+    0x1c26a370, 0x1de4c947, 0x1fa2771e, 0x1e601d29,
+    0x1b2f0bac, 0x1aed619b, 0x18abdfc2, 0x1969b5f5,
+    0x1235f2c8, 0x13f798ff, 0x11b126a6, 0x10734c91,
+    0x153c5a14, 0x14fe3023, 0x16b88e7a, 0x177ae44d,
+    0x384d46e0, 0x398f2cd7, 0x3bc9928e, 0x3a0bf8b9,
+    0x3f44ee3c, 0x3e86840b, 0x3cc03a52, 0x3d025065,
+    0x365e1758, 0x379c7d6f, 0x35dac336, 0x3418a901,
+    0x3157bf84, 0x3095d5b3, 0x32d36bea, 0x331101dd,
+    0x246be590, 0x25a98fa7, 0x27ef31fe, 0x262d5bc9,
+    0x23624d4c, 0x22a0277b, 0x20e69922, 0x2124f315,
+    0x2a78b428, 0x2bbade1f, 0x29fc6046, 0x283e0a71,
+    0x2d711cf4, 0x2cb376c3, 0x2ef5c89a, 0x2f37a2ad,
+    0x709a8dc0, 0x7158e7f7, 0x731e59ae, 0x72dc3399,
+    0x7793251c, 0x76514f2b, 0x7417f172, 0x75d59b45,
+    0x7e89dc78, 0x7f4bb64f, 0x7d0d0816, 0x7ccf6221,
+    0x798074a4, 0x78421e93, 0x7a04a0ca, 0x7bc6cafd,
+    0x6cbc2eb0, 0x6d7e4487, 0x6f38fade, 0x6efa90e9,
+    0x6bb5866c, 0x6a77ec5b, 0x68315202, 0x69f33835,
+    0x62af7f08, 0x636d153f, 0x612bab66, 0x60e9c151,
+    0x65a6d7d4, 0x6464bde3, 0x662203ba, 0x67e0698d,
+    0x48d7cb20, 0x4915a117, 0x4b531f4e, 0x4a917579,
+    0x4fde63fc, 0x4e1c09cb, 0x4c5ab792, 0x4d98dda5,
+    0x46c49a98, 0x4706f0af, 0x45404ef6, 0x448224c1,
+    0x41cd3244, 0x400f5873, 0x4249e62a, 0x438b8c1d,
+    0x54f16850, 0x55330267, 0x5775bc3e, 0x56b7d609,
+    0x53f8c08c, 0x523aaabb, 0x507c14e2, 0x51be7ed5,
+    0x5ae239e8, 0x5b2053df, 0x5966ed86, 0x58a487b1,
+    0x5deb9134, 0x5c29fb03, 0x5e6f455a, 0x5fad2f6d,
+    0xe1351b80, 0xe0f771b7, 0xe2b1cfee, 0xe373a5d9,
+    0xe63cb35c, 0xe7fed96b, 0xe5b86732, 0xe47a0d05,
+    0xef264a38, 0xeee4200f, 0xeca29e56, 0xed60f461,
+    0xe82fe2e4, 0xe9ed88d3, 0xebab368a, 0xea695cbd,
+    0xfd13b8f0, 0xfcd1d2c7, 0xfe976c9e, 0xff5506a9,
+    0xfa1a102c, 0xfbd87a1b, 0xf99ec442, 0xf85cae75,
+    0xf300e948, 0xf2c2837f, 0xf0843d26, 0xf1465711,
+    0xf4094194, 0xf5cb2ba3, 0xf78d95fa, 0xf64fffcd,
+    0xd9785d60, 0xd8ba3757, 0xdafc890e, 0xdb3ee339,
+    0xde71f5bc, 0xdfb39f8b, 0xddf521d2, 0xdc374be5,
+    0xd76b0cd8, 0xd6a966ef, 0xd4efd8b6, 0xd52db281,
+    0xd062a404, 0xd1a0ce33, 0xd3e6706a, 0xd2241a5d,
+    0xc55efe10, 0xc49c9427, 0xc6da2a7e, 0xc7184049,
+    0xc25756cc, 0xc3953cfb, 0xc1d382a2, 0xc011e895,
+    0xcb4dafa8, 0xca8fc59f, 0xc8c97bc6, 0xc90b11f1,
+    0xcc440774, 0xcd866d43, 0xcfc0d31a, 0xce02b92d,
+    0x91af9640, 0x906dfc77, 0x922b422e, 0x93e92819,
+    0x96a63e9c, 0x976454ab, 0x9522eaf2, 0x94e080c5,
+    0x9fbcc7f8, 0x9e7eadcf, 0x9c381396, 0x9dfa79a1,
+    0x98b56f24, 0x99770513, 0x9b31bb4a, 0x9af3d17d,
+    0x8d893530, 0x8c4b5f07, 0x8e0de15e, 0x8fcf8b69,
+    0x8a809dec, 0x8b42f7db, 0x89044982, 0x88c623b5,
+    0x839a6488, 0x82580ebf, 0x801eb0e6, 0x81dcdad1,
+    0x8493cc54, 0x8551a663, 0x8717183a, 0x86d5720d,
+    0xa9e2d0a0, 0xa820ba97, 0xaa6604ce, 0xaba46ef9,
+    0xaeeb787c, 0xaf29124b, 0xad6fac12, 0xacadc625,
+    0xa7f18118, 0xa633eb2f, 0xa4755576, 0xa5b73f41,
+    0xa0f829c4, 0xa13a43f3, 0xa37cfdaa, 0xa2be979d,
+    0xb5c473d0, 0xb40619e7, 0xb640a7be, 0xb782cd89,
+    0xb2cddb0c, 0xb30fb13b, 0xb1490f62, 0xb08b6555,
+    0xbbd72268, 0xba15485f, 0xb853f606, 0xb9919c31,
+    0xbcde8ab4, 0xbd1ce083, 0xbf5a5eda, 0xbe9834ed
+  };
+
+  /** T4[x] is ~CRC(x followed by three 0x00 bytes) */
+  private static final int[] T4 = new int[] {
+    0x0, 0xb8bc6765, 0xaa09c88b, 0x12b5afee,
+    0x8f629757, 0x37def032, 0x256b5fdc, 0x9dd738b9,
+    0xc5b428ef, 0x7d084f8a, 0x6fbde064, 0xd7018701,
+    0x4ad6bfb8, 0xf26ad8dd, 0xe0df7733, 0x58631056,
+    0x5019579f, 0xe8a530fa, 0xfa109f14, 0x42acf871,
+    0xdf7bc0c8, 0x67c7a7ad, 0x75720843, 0xcdce6f26,
+    0x95ad7f70, 0x2d111815, 0x3fa4b7fb, 0x8718d09e,
+    0x1acfe827, 0xa2738f42, 0xb0c620ac, 0x87a47c9,
+    0xa032af3e, 0x188ec85b, 0xa3b67b5, 0xb28700d0,
+    0x2f503869, 0x97ec5f0c, 0x8559f0e2, 0x3de59787,
+    0x658687d1, 0xdd3ae0b4, 0xcf8f4f5a, 0x7733283f,
+    0xeae41086, 0x525877e3, 0x40edd80d, 0xf851bf68,
+    0xf02bf8a1, 0x48979fc4, 0x5a22302a, 0xe29e574f,
+    0x7f496ff6, 0xc7f50893, 0xd540a77d, 0x6dfcc018,
+    0x359fd04e, 0x8d23b72b, 0x9f9618c5, 0x272a7fa0,
+    0xbafd4719, 0x241207c, 0x10f48f92, 0xa848e8f7,
+    0x9b14583d, 0x23a83f58, 0x311d90b6, 0x89a1f7d3,
+    0x1476cf6a, 0xaccaa80f, 0xbe7f07e1, 0x6c36084,
+    0x5ea070d2, 0xe61c17b7, 0xf4a9b859, 0x4c15df3c,
+    0xd1c2e785, 0x697e80e0, 0x7bcb2f0e, 0xc377486b,
+    0xcb0d0fa2, 0x73b168c7, 0x6104c729, 0xd9b8a04c,
+    0x446f98f5, 0xfcd3ff90, 0xee66507e, 0x56da371b,
+    0xeb9274d, 0xb6054028, 0xa4b0efc6, 0x1c0c88a3,
+    0x81dbb01a, 0x3967d77f, 0x2bd27891, 0x936e1ff4,
+    0x3b26f703, 0x839a9066, 0x912f3f88, 0x299358ed,
+    0xb4446054, 0xcf80731, 0x1e4da8df, 0xa6f1cfba,
+    0xfe92dfec, 0x462eb889, 0x549b1767, 0xec277002,
+    0x71f048bb, 0xc94c2fde, 0xdbf98030, 0x6345e755,
+    0x6b3fa09c, 0xd383c7f9, 0xc1366817, 0x798a0f72,
+    0xe45d37cb, 0x5ce150ae, 0x4e54ff40, 0xf6e89825,
+    0xae8b8873, 0x1637ef16, 0x48240f8, 0xbc3e279d,
+    0x21e91f24, 0x99557841, 0x8be0d7af, 0x335cb0ca,
+    0xed59b63b, 0x55e5d15e, 0x47507eb0, 0xffec19d5,
+    0x623b216c, 0xda874609, 0xc832e9e7, 0x708e8e82,
+    0x28ed9ed4, 0x9051f9b1, 0x82e4565f, 0x3a58313a,
+    0xa78f0983, 0x1f336ee6, 0xd86c108, 0xb53aa66d,
+    0xbd40e1a4, 0x5fc86c1, 0x1749292f, 0xaff54e4a,
+    0x322276f3, 0x8a9e1196, 0x982bbe78, 0x2097d91d,
+    0x78f4c94b, 0xc048ae2e, 0xd2fd01c0, 0x6a4166a5,
+    0xf7965e1c, 0x4f2a3979, 0x5d9f9697, 0xe523f1f2,
+    0x4d6b1905, 0xf5d77e60, 0xe762d18e, 0x5fdeb6eb,
+    0xc2098e52, 0x7ab5e937, 0x680046d9, 0xd0bc21bc,
+    0x88df31ea, 0x3063568f, 0x22d6f961, 0x9a6a9e04,
+    0x7bda6bd, 0xbf01c1d8, 0xadb46e36, 0x15080953,
+    0x1d724e9a, 0xa5ce29ff, 0xb77b8611, 0xfc7e174,
+    0x9210d9cd, 0x2aacbea8, 0x38191146, 0x80a57623,
+    0xd8c66675, 0x607a0110, 0x72cfaefe, 0xca73c99b,
+    0x57a4f122, 0xef189647, 0xfdad39a9, 0x45115ecc,
+    0x764dee06, 0xcef18963, 0xdc44268d, 0x64f841e8,
+    0xf92f7951, 0x41931e34, 0x5326b1da, 0xeb9ad6bf,
+    0xb3f9c6e9, 0xb45a18c, 0x19f00e62, 0xa14c6907,
+    0x3c9b51be, 0x842736db, 0x96929935, 0x2e2efe50,
+    0x2654b999, 0x9ee8defc, 0x8c5d7112, 0x34e11677,
+    0xa9362ece, 0x118a49ab, 0x33fe645, 0xbb838120,
+    0xe3e09176, 0x5b5cf613, 0x49e959fd, 0xf1553e98,
+    0x6c820621, 0xd43e6144, 0xc68bceaa, 0x7e37a9cf,
+    0xd67f4138, 0x6ec3265d, 0x7c7689b3, 0xc4caeed6,
+    0x591dd66f, 0xe1a1b10a, 0xf3141ee4, 0x4ba87981,
+    0x13cb69d7, 0xab770eb2, 0xb9c2a15c, 0x17ec639,
+    0x9ca9fe80, 0x241599e5, 0x36a0360b, 0x8e1c516e,
+    0x866616a7, 0x3eda71c2, 0x2c6fde2c, 0x94d3b949,
+    0x90481f0, 0xb1b8e695, 0xa30d497b, 0x1bb12e1e,
+    0x43d23e48, 0xfb6e592d, 0xe9dbf6c3, 0x516791a6,
+    0xccb0a91f, 0x740cce7a, 0x66b96194, 0xde0506f1
+  };
+
+}
diff --git a/src/test/core/org/apache/hadoop/util/TestPureJavaCrc32.java b/src/test/core/org/apache/hadoop/util/TestPureJavaCrc32.java
new file mode 100644
index 00000000000..715d8f620c9
--- /dev/null
+++ b/src/test/core/org/apache/hadoop/util/TestPureJavaCrc32.java
@@ -0,0 +1,171 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.util;
+
+import junit.framework.TestCase;
+import java.util.zip.CRC32;
+import java.util.zip.Checksum;
+import java.util.LinkedHashMap;
+import java.util.Map;
+import java.util.Random;
+
+/**
+ * Unit test to verify that the pure-Java CRC32 algorithm gives
+ * the same results as the built-in implementation.
+ */
+public class TestPureJavaCrc32 extends TestCase {
+  private CRC32 theirs;
+  private PureJavaCrc32 ours;
+
+  public void setUp() {
+    theirs = new CRC32();
+    ours = new PureJavaCrc32();
+  }
+
+  public void testCorrectness() throws Exception {
+    checkSame();
+
+    theirs.update(104);
+    ours.update(104);
+    checkSame();
+
+    checkOnBytes(new byte[] {40, 60, 97, -70}, false);
+    
+    checkOnBytes(""hello world!"".getBytes(""UTF-8""), false);
+
+    for (int i = 0; i < 10000; i++) {
+      byte randomBytes[] = new byte[new Random().nextInt(2048)];
+      new Random().nextBytes(randomBytes);
+      checkOnBytes(randomBytes, false);
+    }
+    
+  }
+
+  private void checkOnBytes(byte[] bytes, boolean print) {
+    theirs.reset();
+    ours.reset();
+    checkSame();
+    
+    for (int i = 0; i < bytes.length; i++) {
+      ours.update(bytes[i]);
+      theirs.update(bytes[i]);
+      checkSame();
+    }
+
+    if (print) {
+      System.out.println(""theirs:\t"" + Long.toHexString(theirs.getValue())
+                         + ""\nours:\t"" + Long.toHexString(ours.getValue()));
+    }
+  
+    theirs.reset();
+    ours.reset();
+    
+    ours.update(bytes, 0, bytes.length);
+    theirs.update(bytes, 0, bytes.length);
+    if (print) {
+      System.out.println(""theirs:\t"" + Long.toHexString(theirs.getValue())
+                         + ""\nours:\t"" + Long.toHexString(ours.getValue()));
+    }
+
+    checkSame();
+    
+    if (bytes.length >= 10) {
+      ours.update(bytes, 5, 5);
+      theirs.update(bytes, 5, 5);
+      checkSame();
+    }
+  }
+
+  private void checkSame() {
+    assertEquals(theirs.getValue(), ours.getValue());
+  }
+
+  /**
+   * Performance tests to compare performance of the Pure Java implementation
+   * to the built-in java.util.zip implementation. This can be run from the
+   * command line with:
+   *
+   *   java -cp path/to/test/classes:path/to/common/classes \
+   *      'org.apache.hadoop.util.TestPureJavaCrc32$PerformanceTest'
+   *
+   * The output is in JIRA table format.
+   */
+  public static class PerformanceTest {
+    public static final int MAX_LEN = 32*1024*1024; // up to 32MB chunks
+    public static final int BYTES_PER_SIZE = MAX_LEN * 4;
+
+    public static LinkedHashMap<String, Checksum> getImplsToTest() {
+      LinkedHashMap<String, Checksum> impls =
+        new LinkedHashMap<String, Checksum>();
+      impls.put(""BuiltIn"", new CRC32());
+      impls.put(""PureJava"", new PureJavaCrc32());
+      return impls;
+    }
+
+    public static void main(String args[]) {
+      LinkedHashMap<String, Checksum> impls = getImplsToTest();
+
+      Random rand = new Random();
+      byte[] bytes = new byte[MAX_LEN];
+      rand.nextBytes(bytes);
+
+
+      // Print header
+      System.out.printf(""||num bytes||"");
+      for (String entry : impls.keySet()) {
+        System.out.printf(entry + "" MB/sec||"");
+      }
+      System.out.printf(""\n"");
+
+      // Warm up implementations to get jit going.
+      for (Map.Entry<String, Checksum> entry : impls.entrySet()) {
+        doBench(""warmUp"" + entry.getKey(),
+                entry.getValue(), bytes, 2, false);
+        doBench(""warmUp"" + entry.getKey(),
+                entry.getValue(), bytes, 2101, false);
+      }
+
+      // Test on a variety of sizes
+      for (int size = 1; size < MAX_LEN; size *= 2) {
+        System.out.printf(""| %d\t|"", size);
+
+        for (Map.Entry<String, Checksum> entry : impls.entrySet()) {
+          System.gc();
+          doBench(entry.getKey(), entry.getValue(), bytes, size, true);
+        }
+        System.out.printf(""\n"");
+      }
+    }
+
+    private static void doBench(String id, Checksum crc,
+                                byte[] bytes, int size, boolean printout) {
+      long st = System.nanoTime();
+      int trials = BYTES_PER_SIZE / size;
+      for (int i = 0; i < trials; i++) {
+        crc.update(bytes, 0, size);
+      }
+      long et = System.nanoTime();
+
+      double mbProcessed = trials * size / 1024.0 / 1024.0;
+      double secsElapsed = (et - st) / 1000000000.0d;
+      if (printout) {
+        System.out.printf(""%.3f \t|"",  mbProcessed / secsElapsed);
+      }
+    }
+  }
+}
",HADOOP-6148. Implement a fast
1542,Java,65a5e2cc46b2c04591aa59b7a85751479a7dbd0b,,A,apache,hadoop,"[5, 256, 8, 3, 28, 0, 0, 1, 82, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0]","diff --git a/hadoop-yarn-project/CHANGES.txt b/hadoop-yarn-project/CHANGES.txt
index 32c042622ce..02b922616b3 100644
--- a/hadoop-yarn-project/CHANGES.txt
+++ b/hadoop-yarn-project/CHANGES.txt
@@ -79,4 +79,7 @@ Release 2.5.0 - UNRELEASED
     Shen via vinodkv)
 
+    YARN-1936. Added security support for the Timeline Client. (Zhijie Shen via
+    vinodkv)
+
   OPTIMIZATIONS
 
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/src/main/java/org/apache/hadoop/yarn/client/api/TimelineClient.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/src/main/java/org/apache/hadoop/yarn/client/api/TimelineClient.java
index a2ed3e70a51..de1d3e2ae53 100644
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/src/main/java/org/apache/hadoop/yarn/client/api/TimelineClient.java
+++ b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/src/main/java/org/apache/hadoop/yarn/client/api/TimelineClient.java
@@ -24,4 +24,5 @@
 import org.apache.hadoop.classification.InterfaceAudience.Public;
 import org.apache.hadoop.classification.InterfaceStability.Unstable;
+import org.apache.hadoop.security.token.Token;
 import org.apache.hadoop.service.AbstractService;
 import org.apache.hadoop.yarn.api.records.timeline.TimelineEntity;
@@ -29,4 +30,5 @@
 import org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl;
 import org.apache.hadoop.yarn.exceptions.YarnException;
+import org.apache.hadoop.yarn.security.client.TimelineDelegationTokenIdentifier;
 
 /**
@@ -66,3 +68,21 @@ public abstract TimelinePutResponse putEntities(
       TimelineEntity... entities) throws IOException, YarnException;
 
+  /**
+   * <p>
+   * Get a delegation token so as to be able to talk to the timeline server in a
+   * secure way.
+   * </p>
+   * 
+   * @param renewer
+   *          Address of the renewer who can renew these tokens when needed by
+   *          securely talking to the timeline server
+   * @return a delegation token ({@link Token}) that can be used to talk to the
+   *         timeline server
+   * @throws IOException
+   * @throws YarnException
+   */
+  @Public
+  public abstract Token<TimelineDelegationTokenIdentifier> getDelegationToken(
+      String renewer) throws IOException, YarnException;
+
 }
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/src/main/java/org/apache/hadoop/yarn/client/api/impl/TimelineClientImpl.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/src/main/java/org/apache/hadoop/yarn/client/api/impl/TimelineClientImpl.java
index 64cc041aaea..5ffe17a24a6 100644
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/src/main/java/org/apache/hadoop/yarn/client/api/impl/TimelineClientImpl.java
+++ b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/src/main/java/org/apache/hadoop/yarn/client/api/impl/TimelineClientImpl.java
@@ -19,10 +19,19 @@
 package org.apache.hadoop.yarn.client.api.impl;
 
+import java.io.File;
 import java.io.IOException;
+import java.net.HttpURLConnection;
 import java.net.URI;
+import java.net.URL;
 import java.util.Arrays;
+import java.util.HashMap;
+import java.util.Map;
 
 import javax.ws.rs.core.MediaType;
 
+import org.apache.commons.cli.CommandLine;
+import org.apache.commons.cli.GnuParser;
+import org.apache.commons.cli.HelpFormatter;
+import org.apache.commons.cli.Options;
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
@@ -30,4 +39,9 @@
 import org.apache.hadoop.classification.InterfaceStability.Unstable;
 import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.io.Text;
+import org.apache.hadoop.security.UserGroupInformation;
+import org.apache.hadoop.security.authentication.client.AuthenticatedURL;
+import org.apache.hadoop.security.authentication.client.AuthenticationException;
+import org.apache.hadoop.security.token.Token;
 import org.apache.hadoop.yarn.api.records.timeline.TimelineEntities;
 import org.apache.hadoop.yarn.api.records.timeline.TimelineEntity;
@@ -36,5 +50,10 @@
 import org.apache.hadoop.yarn.conf.YarnConfiguration;
 import org.apache.hadoop.yarn.exceptions.YarnException;
+import org.apache.hadoop.yarn.exceptions.YarnRuntimeException;
+import org.apache.hadoop.yarn.security.client.TimelineDelegationTokenIdentifier;
+import org.apache.hadoop.yarn.security.client.TimelineDelegationTokenSelector;
+import org.apache.hadoop.yarn.util.timeline.TimelineUtils;
 import org.apache.hadoop.yarn.webapp.YarnJacksonJaxbJsonProvider;
+import org.codehaus.jackson.map.ObjectMapper;
 
 import com.google.common.annotations.VisibleForTesting;
@@ -45,4 +64,6 @@
 import com.sun.jersey.api.client.config.ClientConfig;
 import com.sun.jersey.api.client.config.DefaultClientConfig;
+import com.sun.jersey.client.urlconnection.HttpURLConnectionFactory;
+import com.sun.jersey.client.urlconnection.URLConnectionClientHandler;
 
 @Private
@@ -53,8 +74,16 @@
   private static final String RESOURCE_URI_STR = ""/ws/v1/timeline/"";
   private static final Joiner JOINER = Joiner.on("""");
+  private static Options opts;
+  static {
+    opts = new Options();
+    opts.addOption(""put"", true, ""Put the TimelineEntities in a JSON file"");
+    opts.getOption(""put"").setArgName(""Path to the JSON file"");
+    opts.addOption(""help"", false, ""Print usage"");
+  }
 
   private Client client;
   private URI resURI;
   private boolean isEnabled;
+  private TimelineAuthenticatedURLConnectionFactory urlFactory;
 
   public TimelineClientImpl() {
@@ -62,5 +91,10 @@ public TimelineClientImpl() {
     ClientConfig cc = new DefaultClientConfig();
     cc.getClasses().add(YarnJacksonJaxbJsonProvider.class);
-    client = Client.create(cc);
+    if (UserGroupInformation.isSecurityEnabled()) {
+      urlFactory = new TimelineAuthenticatedURLConnectionFactory();
+      client = new Client(new URLConnectionClientHandler(urlFactory), cc);
+    } else {
+      client = Client.create(cc);
+    }
   }
 
@@ -84,4 +118,7 @@ protected void serviceInit(Configuration conf) throws Exception {
             RESOURCE_URI_STR));
       }
+      if (UserGroupInformation.isSecurityEnabled()) {
+        urlFactory.setService(TimelineUtils.buildTimelineTokenService(conf));
+      }
       LOG.info(""Timeline service address: "" + resURI);
     }
@@ -125,4 +162,11 @@ public TimelinePutResponse putEntities(
   }
 
+  @Override
+  public Token<TimelineDelegationTokenIdentifier> getDelegationToken(
+      String renewer) throws IOException, YarnException {
+    return TimelineAuthenticator.getDelegationToken(resURI.toURL(),
+        urlFactory.token, renewer);
+  }
+
   @Private
   @VisibleForTesting
@@ -134,3 +178,137 @@ public ClientResponse doPostingEntities(TimelineEntities entities) {
   }
 
+  private static class TimelineAuthenticatedURLConnectionFactory
+      implements HttpURLConnectionFactory {
+
+    private AuthenticatedURL.Token token;
+    private TimelineAuthenticator authenticator;
+    private Token<TimelineDelegationTokenIdentifier> dToken;
+    private Text service;
+
+    public TimelineAuthenticatedURLConnectionFactory() {
+      token = new AuthenticatedURL.Token();
+      authenticator = new TimelineAuthenticator();
+    }
+
+    @Override
+    public HttpURLConnection getHttpURLConnection(URL url) throws IOException {
+      try {
+        if (dToken == null) {
+          //TODO: need to take care of the renew case
+          dToken = selectToken();
+          if (LOG.isDebugEnabled()) {
+            LOG.debug(""Timeline delegation token: "" + dToken.toString());
+          }
+        }
+        if (dToken != null) {
+          Map<String, String> params = new HashMap<String, String>();
+          TimelineAuthenticator.injectDelegationToken(params, dToken);
+          url = TimelineAuthenticator.appendParams(url, params);
+          if (LOG.isDebugEnabled()) {
+            LOG.debug(""URL with delegation token: "" + url);
+          }
+        }
+        return new AuthenticatedURL(authenticator).openConnection(url, token);
+      } catch (AuthenticationException e) {
+        LOG.error(""Authentication failed when openning connection ["" + url
+            + ""] with token ["" + token + ""]."", e);
+        throw new IOException(e);
+      }
+    }
+
+    private Token<TimelineDelegationTokenIdentifier> selectToken() {
+      UserGroupInformation ugi;
+      try {
+        ugi = UserGroupInformation.getCurrentUser();
+      } catch (IOException e) {
+        String msg = ""Error when getting the current user"";
+        LOG.error(msg, e);
+        throw new YarnRuntimeException(msg, e);
+      }
+      TimelineDelegationTokenSelector tokenSelector =
+          new TimelineDelegationTokenSelector();
+      return tokenSelector.selectToken(
+          service, ugi.getCredentials().getAllTokens());
+    }
+
+    public void setService(Text service) {
+      this.service = service;
+    }
+
+  }
+
+  public static void main(String[] argv) throws Exception {
+    CommandLine cliParser = new GnuParser().parse(opts, argv);
+    if (cliParser.hasOption(""put"")) {
+      String path = cliParser.getOptionValue(""put"");
+      if (path != null && path.length() > 0) {
+        putTimelineEntitiesInJSONFile(path);
+        return;
+      }
+    }
+    printUsage();
+  }
+
+  /**
+   * Put timeline data in a JSON file via command line.
+   * 
+   * @param path
+   *          path to the {@link TimelineEntities} JSON file
+   */
+  private static void putTimelineEntitiesInJSONFile(String path) {
+    File jsonFile = new File(path);
+    if (!jsonFile.exists()) {
+      System.out.println(""Error: File ["" + jsonFile.getAbsolutePath()
+          + ""] doesn't exist"");
+      return;
+    }
+    ObjectMapper mapper = new ObjectMapper();
+    YarnJacksonJaxbJsonProvider.configObjectMapper(mapper);
+    TimelineEntities entities = null;
+    try {
+      entities = mapper.readValue(jsonFile, TimelineEntities.class);
+    } catch (Exception e) {
+      System.err.println(""Error: "" + e.getMessage());
+      e.printStackTrace(System.err);
+      return;
+    }
+    Configuration conf = new YarnConfiguration();
+    TimelineClient client = TimelineClient.createTimelineClient();
+    client.init(conf);
+    client.start();
+    try {
+      if (UserGroupInformation.isSecurityEnabled()
+          && conf.getBoolean(YarnConfiguration.TIMELINE_SERVICE_ENABLED, false)) {
+        Token<TimelineDelegationTokenIdentifier> token =
+            client.getDelegationToken(
+                UserGroupInformation.getCurrentUser().getUserName());
+        UserGroupInformation.getCurrentUser().addToken(token);
+      }
+      TimelinePutResponse response = client.putEntities(
+          entities.getEntities().toArray(
+              new TimelineEntity[entities.getEntities().size()]));
+      if (response.getErrors().size() == 0) {
+        System.out.println(""Timeline data is successfully put"");
+      } else {
+        for (TimelinePutResponse.TimelinePutError error : response.getErrors()) {
+          System.out.println(""TimelineEntity ["" + error.getEntityType() + "":"" +
+              error.getEntityId() + ""] is not successfully put. Error code: "" +
+              error.getErrorCode());
+        }
+      }
+    } catch (Exception e) {
+      System.err.println(""Error: "" + e.getMessage());
+      e.printStackTrace(System.err);
+    } finally {
+      client.stop();
+    }
+  }
+
+  /**
+   * Helper function to print out usage
+   */
+  private static void printUsage() {
+    new HelpFormatter().printHelp(""TimelineClient"", opts);
+  }
+
 }
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/src/main/java/org/apache/hadoop/yarn/client/api/impl/YarnClientImpl.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/src/main/java/org/apache/hadoop/yarn/client/api/impl/YarnClientImpl.java
index 8a0348b3368..f1a3b6eecea 100644
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/src/main/java/org/apache/hadoop/yarn/client/api/impl/YarnClientImpl.java
+++ b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/src/main/java/org/apache/hadoop/yarn/client/api/impl/YarnClientImpl.java
@@ -20,4 +20,5 @@
 
 import java.io.IOException;
+import java.nio.ByteBuffer;
 import java.util.ArrayList;
 import java.util.EnumSet;
@@ -30,6 +31,11 @@
 import org.apache.hadoop.classification.InterfaceStability.Unstable;
 import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.io.DataInputByteBuffer;
+import org.apache.hadoop.io.DataOutputBuffer;
 import org.apache.hadoop.io.Text;
 import org.apache.hadoop.ipc.RPC;
+import org.apache.hadoop.security.Credentials;
+import org.apache.hadoop.security.UserGroupInformation;
+import org.apache.hadoop.security.token.TokenIdentifier;
 import org.apache.hadoop.yarn.api.ApplicationClientProtocol;
 import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptReportRequest;
@@ -65,4 +71,5 @@
 import org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext;
 import org.apache.hadoop.yarn.api.records.ContainerId;
+import org.apache.hadoop.yarn.api.records.ContainerLaunchContext;
 import org.apache.hadoop.yarn.api.records.ContainerReport;
 import org.apache.hadoop.yarn.api.records.NodeReport;
@@ -75,4 +82,5 @@
 import org.apache.hadoop.yarn.client.ClientRMProxy;
 import org.apache.hadoop.yarn.client.api.AHSClient;
+import org.apache.hadoop.yarn.client.api.TimelineClient;
 import org.apache.hadoop.yarn.client.api.YarnClient;
 import org.apache.hadoop.yarn.client.api.YarnClientApplication;
@@ -83,6 +91,8 @@
 import org.apache.hadoop.yarn.exceptions.YarnRuntimeException;
 import org.apache.hadoop.yarn.security.AMRMTokenIdentifier;
+import org.apache.hadoop.yarn.security.client.TimelineDelegationTokenIdentifier;
 import org.apache.hadoop.yarn.util.ConverterUtils;
 import org.apache.hadoop.yarn.util.Records;
+import org.apache.hadoop.yarn.util.timeline.TimelineUtils;
 
 import com.google.common.annotations.VisibleForTesting;
@@ -98,6 +108,9 @@
   private long asyncApiPollIntervalMillis;
   private long asyncApiPollTimeoutMillis;
-  protected AHSClient historyClient;
+  private AHSClient historyClient;
   private boolean historyServiceEnabled;
+  protected TimelineClient timelineClient;
+  protected Text timelineService;
+  protected boolean timelineServiceEnabled;
 
   private static final String ROOT = ""root"";
@@ -127,8 +140,15 @@ protected void serviceInit(Configuration conf) throws Exception {
       YarnConfiguration.DEFAULT_APPLICATION_HISTORY_ENABLED)) {
       historyServiceEnabled = true;
-      historyClient = AHSClientImpl.createAHSClient();
-      historyClient.init(getConfig());
+      historyClient = AHSClient.createAHSClient();
+      historyClient.init(conf);
     }
 
+    if (conf.getBoolean(YarnConfiguration.TIMELINE_SERVICE_ENABLED,
+        YarnConfiguration.DEFAULT_TIMELINE_SERVICE_ENABLED)) {
+      timelineServiceEnabled = true;
+      timelineClient = TimelineClient.createTimelineClient();
+      timelineClient.init(conf);
+      timelineService = TimelineUtils.buildTimelineTokenService(conf);
+    }
     super.serviceInit(conf);
   }
@@ -142,4 +162,7 @@ protected void serviceStart() throws Exception {
         historyClient.start();
       }
+      if (timelineServiceEnabled) {
+        timelineClient.start();
+      }
     } catch (IOException e) {
       throw new YarnRuntimeException(e);
@@ -156,4 +179,7 @@ protected void serviceStop() throws Exception {
       historyClient.stop();
     }
+    if (timelineServiceEnabled) {
+      timelineClient.stop();
+    }
     super.serviceStop();
   }
@@ -190,4 +216,10 @@ public YarnClientApplication createApplication()
     request.setApplicationSubmissionContext(appContext);
 
+    // Automatically add the timeline DT into the CLC
+    // Only when the security and the timeline service are both enabled
+    if (isSecurityEnabled() && timelineServiceEnabled) {
+      addTimelineDelegationToken(appContext.getAMContainerSpec());
+    }
+
     //TODO: YARN-1763:Handle RM failovers during the submitApplication call.
     rmClient.submitApplication(request);
@@ -239,4 +271,46 @@ public YarnClientApplication createApplication()
   }
 
+  private void addTimelineDelegationToken(
+      ContainerLaunchContext clc) throws YarnException, IOException {
+    org.apache.hadoop.security.token.Token<TimelineDelegationTokenIdentifier> timelineDelegationToken =
+        timelineClient.getDelegationToken(
+            UserGroupInformation.getCurrentUser().getUserName());
+    if (timelineDelegationToken == null) {
+      return;
+    }
+    Credentials credentials = new Credentials();
+    DataInputByteBuffer dibb = new DataInputByteBuffer();
+    ByteBuffer tokens = clc.getTokens();
+    if (tokens != null) {
+      dibb.reset(tokens);
+      credentials.readTokenStorageStream(dibb);
+      tokens.rewind();
+    }
+    // If the timeline delegation token is already in the CLC, no need to add
+    // one more
+    for (org.apache.hadoop.security.token.Token<? extends TokenIdentifier> token : credentials
+        .getAllTokens()) {
+      TokenIdentifier tokenIdentifier = token.decodeIdentifier();
+      if (tokenIdentifier instanceof TimelineDelegationTokenIdentifier) {
+        return;
+      }
+    }
+    credentials.addToken(timelineService, timelineDelegationToken);
+    if (LOG.isDebugEnabled()) {
+      LOG.debug(""Add timline delegation token into credentials: ""
+          + timelineDelegationToken);
+    }
+    DataOutputBuffer dob = new DataOutputBuffer();
+    credentials.writeTokenStorageToStream(dob);
+    tokens = ByteBuffer.wrap(dob.getData(), 0, dob.getLength());
+    clc.setTokens(tokens);
+  }
+
+  @Private
+  @VisibleForTesting
+  protected boolean isSecurityEnabled() {
+    return UserGroupInformation.isSecurityEnabled();
+  }
+
   @Override
   public void killApplication(ApplicationId applicationId)
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/src/test/java/org/apache/hadoop/yarn/client/api/impl/TestYarnClient.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/src/test/java/org/apache/hadoop/yarn/client/api/impl/TestYarnClient.java
index cfee6f78d0c..6407f7a1089 100644
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/src/test/java/org/apache/hadoop/yarn/client/api/impl/TestYarnClient.java
+++ b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/src/test/java/org/apache/hadoop/yarn/client/api/impl/TestYarnClient.java
@@ -26,6 +26,8 @@
 
 import java.io.IOException;
+import java.nio.ByteBuffer;
 import java.security.PrivilegedExceptionAction;
 import java.util.ArrayList;
+import java.util.Collection;
 import java.util.EnumSet;
 import java.util.HashMap;
@@ -34,9 +36,14 @@
 import java.util.Set;
 
-import org.junit.Assert;
-
 import org.apache.commons.io.IOUtils;
 import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.io.DataInputByteBuffer;
+import org.apache.hadoop.io.DataOutputBuffer;
+import org.apache.hadoop.security.Credentials;
+import org.apache.hadoop.security.SecurityUtil;
 import org.apache.hadoop.security.UserGroupInformation;
+import org.apache.hadoop.security.UserGroupInformation.AuthenticationMethod;
+import org.apache.hadoop.security.token.Token;
+import org.apache.hadoop.security.token.TokenIdentifier;
 import org.apache.hadoop.yarn.api.ApplicationClientProtocol;
 import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptReportRequest;
@@ -70,4 +77,5 @@
 import org.apache.hadoop.yarn.api.records.YarnApplicationAttemptState;
 import org.apache.hadoop.yarn.api.records.YarnApplicationState;
+import org.apache.hadoop.yarn.client.api.TimelineClient;
 import org.apache.hadoop.yarn.client.api.YarnClient;
 import org.apache.hadoop.yarn.client.api.YarnClientApplication;
@@ -75,4 +83,5 @@
 import org.apache.hadoop.yarn.exceptions.ApplicationIdNotProvidedException;
 import org.apache.hadoop.yarn.exceptions.YarnException;
+import org.apache.hadoop.yarn.security.client.TimelineDelegationTokenIdentifier;
 import org.apache.hadoop.yarn.server.MiniYARNCluster;
 import org.apache.hadoop.yarn.server.resourcemanager.MockRM;
@@ -80,7 +89,9 @@
 import org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMApp;
 import org.apache.hadoop.yarn.util.Records;
+import org.apache.hadoop.yarn.util.timeline.TimelineUtils;
 import org.apache.log4j.Level;
 import org.apache.log4j.LogManager;
 import org.apache.log4j.Logger;
+import org.junit.Assert;
 import org.junit.Test;
 
@@ -726,3 +737,79 @@ private void testAsyncAPIPollTimeoutHelper(Long valueForTimeout,
     }
   }
+
+  @Test
+  public void testAutomaticTimelineDelegationTokenLoading()
+      throws Exception {
+    Configuration conf = new YarnConfiguration();
+    conf.setBoolean(YarnConfiguration.TIMELINE_SERVICE_ENABLED, true);
+    SecurityUtil.setAuthenticationMethod(AuthenticationMethod.KERBEROS, conf);
+    final Token<TimelineDelegationTokenIdentifier> dToken =
+        new Token<TimelineDelegationTokenIdentifier>();
+    // crate a mock client
+    YarnClientImpl client = new YarnClientImpl() {
+      @Override
+      protected void serviceInit(Configuration conf) throws Exception {
+        if (getConfig().getBoolean(YarnConfiguration.TIMELINE_SERVICE_ENABLED,
+            YarnConfiguration.DEFAULT_TIMELINE_SERVICE_ENABLED)) {
+          timelineServiceEnabled = true;
+          timelineClient = mock(TimelineClient.class);
+          when(timelineClient.getDelegationToken(any(String.class)))
+              .thenReturn(dToken);
+          timelineClient.init(getConfig());
+          timelineService = TimelineUtils.buildTimelineTokenService(getConfig());
+        }
+        this.setConfig(conf);
+      }
+
+      @Override
+      protected void serviceStart() throws Exception {
+        rmClient = mock(ApplicationClientProtocol.class);
+      }
+
+      @Override
+      protected void serviceStop() throws Exception {
+      }
+
+      @Override
+      public ApplicationReport getApplicationReport(ApplicationId appId) {
+        ApplicationReport report = mock(ApplicationReport.class);
+        when(report.getYarnApplicationState())
+            .thenReturn(YarnApplicationState.SUBMITTED);
+        return report;
+      }
+
+      @Override
+      public boolean isSecurityEnabled() {
+        return true;
+      }
+    };
+    client.init(conf);
+    client.start();
+    ApplicationSubmissionContext context =
+        mock(ApplicationSubmissionContext.class);
+    ApplicationId applicationId = ApplicationId.newInstance(0, 1);
+    when(context.getApplicationId()).thenReturn(applicationId);
+    DataOutputBuffer dob = new DataOutputBuffer();
+    Credentials credentials = new Credentials();
+    credentials.writeTokenStorageToStream(dob);
+    ByteBuffer tokens = ByteBuffer.wrap(dob.getData(), 0, dob.getLength());
+    ContainerLaunchContext clc = ContainerLaunchContext.newInstance(
+        null, null, null, null, tokens, null);
+    when(context.getAMContainerSpec()).thenReturn(clc);
+    client.submitApplication(context);
+    // Check whether token is added or not
+    credentials = new Credentials();
+    DataInputByteBuffer dibb = new DataInputByteBuffer();
+    tokens = clc.getTokens();
+    if (tokens != null) {
+      dibb.reset(tokens);
+      credentials.readTokenStorageStream(dibb);
+      tokens.rewind();
+    }
+    Collection<Token<? extends TokenIdentifier>> dTokens =
+        credentials.getAllTokens();
+    Assert.assertEquals(1, dTokens.size());
+    Assert.assertEquals(dToken, dTokens.iterator().next());
+    client.stop();
+  }
 }
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/util/timeline/TimelineUtils.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/util/timeline/TimelineUtils.java
index a62ed4869da..02b5eb4eabd 100644
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/util/timeline/TimelineUtils.java
+++ b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/util/timeline/TimelineUtils.java
@@ -20,7 +20,12 @@
 
 import java.io.IOException;
+import java.net.InetSocketAddress;
 
 import org.apache.hadoop.classification.InterfaceAudience.Public;
 import org.apache.hadoop.classification.InterfaceStability.Evolving;
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.io.Text;
+import org.apache.hadoop.security.SecurityUtil;
+import org.apache.hadoop.yarn.conf.YarnConfiguration;
 import org.apache.hadoop.yarn.webapp.YarnJacksonJaxbJsonProvider;
 import org.codehaus.jackson.JsonGenerationException;
@@ -79,3 +84,25 @@ public static String dumpTimelineRecordtoJSON(Object o, boolean pretty)
   }
 
+  public static InetSocketAddress getTimelineTokenServiceAddress(
+      Configuration conf) {
+    InetSocketAddress timelineServiceAddr = null;
+    if (YarnConfiguration.useHttps(conf)) {
+      timelineServiceAddr = conf.getSocketAddr(
+          YarnConfiguration.TIMELINE_SERVICE_WEBAPP_HTTPS_ADDRESS,
+          YarnConfiguration.DEFAULT_TIMELINE_SERVICE_WEBAPP_HTTPS_ADDRESS,
+          YarnConfiguration.DEFAULT_TIMELINE_SERVICE_WEBAPP_HTTPS_PORT);
+    } else {
+      timelineServiceAddr = conf.getSocketAddr(
+          YarnConfiguration.TIMELINE_SERVICE_WEBAPP_ADDRESS,
+          YarnConfiguration.DEFAULT_TIMELINE_SERVICE_WEBAPP_ADDRESS,
+          YarnConfiguration.DEFAULT_TIMELINE_SERVICE_WEBAPP_PORT);
+    }
+    return timelineServiceAddr;
+  }
+
+  public static Text buildTimelineTokenService(Configuration conf) {
+    InetSocketAddress timelineServiceAddr =
+        getTimelineTokenServiceAddress(conf);
+    return SecurityUtil.buildTokenService(timelineServiceAddr);
+  }
 }
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/applicationhistoryservice/timeline/security/TimelineDelegationTokenSecretManagerService.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/applicationhistoryservice/timeline/security/TimelineDelegationTokenSecretManagerService.java
index fee9eb41cd8..2808dac60da 100644
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/applicationhistoryservice/timeline/security/TimelineDelegationTokenSecretManagerService.java
+++ b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/applicationhistoryservice/timeline/security/TimelineDelegationTokenSecretManagerService.java
@@ -35,4 +35,5 @@
 import org.apache.hadoop.yarn.conf.YarnConfiguration;
 import org.apache.hadoop.yarn.security.client.TimelineDelegationTokenIdentifier;
+import org.apache.hadoop.yarn.util.timeline.TimelineUtils;
 
 /**
@@ -66,15 +67,5 @@ protected void serviceInit(Configuration conf) throws Exception {
     secretManager.startThreads();
 
-    if (YarnConfiguration.useHttps(getConfig())) {
-      serviceAddr = getConfig().getSocketAddr(
-          YarnConfiguration.TIMELINE_SERVICE_WEBAPP_HTTPS_ADDRESS,
-          YarnConfiguration.DEFAULT_TIMELINE_SERVICE_WEBAPP_HTTPS_ADDRESS,
-          YarnConfiguration.DEFAULT_TIMELINE_SERVICE_WEBAPP_HTTPS_PORT);
-    } else {
-      serviceAddr = getConfig().getSocketAddr(
-          YarnConfiguration.TIMELINE_SERVICE_WEBAPP_ADDRESS,
-          YarnConfiguration.DEFAULT_TIMELINE_SERVICE_WEBAPP_ADDRESS,
-          YarnConfiguration.DEFAULT_TIMELINE_SERVICE_WEBAPP_PORT);
-    }
+    serviceAddr = TimelineUtils.getTimelineTokenServiceAddress(getConfig());
     super.init(conf);
   }
",YARN-1936. Added security support for the Timeline- Client. Contributed by Zhijie Shen. svn merge --ignore-ancestry -c 1597153- ../../trunk/--git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/branch-2@1597154 13f79535-47bb-0310-9956-ffa450edef68-
1543,Java,a47d981c6e88178558d3b07fa53c903654a0e321,,A,apache,hadoop,"[2, 765, 0, 0, 34, 0, 0, 1, 153, 0, 0, 25, 0, 0, 0, 0, 0, 1, 14, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0]","diff --git a/hadoop-yarn-project/CHANGES.txt b/hadoop-yarn-project/CHANGES.txt
index 7ab49ac3471..48c97fc26d9 100644
--- a/hadoop-yarn-project/CHANGES.txt
+++ b/hadoop-yarn-project/CHANGES.txt
@@ -478,4 +478,7 @@ Branch YARN-321: Generic ApplicationHistoryService
   devaraj)
 
+  YARN-975. Added a file-system implementation for HistoryStorage. (Zhijie Shen
+  via vinodkv)
+
 Release 2.2.0 - 2013-10-13
 
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/conf/YarnConfiguration.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/conf/YarnConfiguration.java
index dc195858cb8..009dda3c160 100644
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/conf/YarnConfiguration.java
+++ b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/conf/YarnConfiguration.java
@@ -932,4 +932,17 @@
       YARN_PREFIX + ""app.container.log.backups"";
 
+  ////////////////////////////////
+  // AHS Configs
+  ////////////////////////////////
+
+  public static final String AHS_PREFIX = YARN_PREFIX + ""ahs."";
+
+  /** URI for FileSystemApplicationHistoryStore */
+  public static final String FS_HISTORY_STORE_URI = AHS_PREFIX + ""fs-history-store.uri"";
+
+  /** T-file compression types used to compress history data.*/
+  public static final String FS_HISTORY_STORE_COMPRESSION_TYPE = AHS_PREFIX + ""fs-history-store.compression-type"";
+  public static final String DEFAULT_FS_HISTORY_STORE_COMPRESSION_TYPE = ""none"";
+
   ////////////////////////////////
   // Other Configs
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/resources/yarn-default.xml b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/resources/yarn-default.xml
index ba6264e0ae3..b831158460f 100644
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/resources/yarn-default.xml
+++ b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/resources/yarn-default.xml
@@ -1042,4 +1042,21 @@
   </property>
 
+  <!-- Application History Service's Configuration-->
+
+  <property>
+    <description>URI pointing to the location of the FileSystem path where
+    the history will be persisted. This must be supplied when using
+    org.apache.hadoop.yarn.server.applicationhistoryservice.FileSystemApplicationHistoryStore
+    as the value for yarn.resourcemanager.ahs.writer.class</description>
+    <name>yarn.ahs.fs-history-store.uri</name>
+    <value>${hadoop.log.dir}/yarn/system/ahstore</value>
+  </property>
+
+  <property>
+    <description>T-file compression types used to compress history data.</description>
+    <name>yarn.ahs.fs-history-store.compression-type</name>
+    <value>none</value>
+  </property>
+
   <!-- Other configuration -->
   <property>
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/applicationhistoryservice/FileSystemApplicationHistoryStore.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/applicationhistoryservice/FileSystemApplicationHistoryStore.java
new file mode 100644
index 00000000000..b4d97f314db
--- /dev/null
+++ b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/applicationhistoryservice/FileSystemApplicationHistoryStore.java
@@ -0,0 +1,860 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.yarn.server.applicationhistoryservice;
+
+import java.io.DataInput;
+import java.io.DataInputStream;
+import java.io.DataOutput;
+import java.io.DataOutputStream;
+import java.io.IOException;
+import java.util.HashMap;
+import java.util.Map;
+import java.util.Map.Entry;
+import java.util.concurrent.ConcurrentHashMap;
+import java.util.concurrent.ConcurrentMap;
+
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.classification.InterfaceAudience.Public;
+import org.apache.hadoop.classification.InterfaceStability.Unstable;
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.fs.FSDataInputStream;
+import org.apache.hadoop.fs.FSDataOutputStream;
+import org.apache.hadoop.fs.FileStatus;
+import org.apache.hadoop.fs.FileSystem;
+import org.apache.hadoop.fs.Path;
+import org.apache.hadoop.fs.permission.FsPermission;
+import org.apache.hadoop.io.IOUtils;
+import org.apache.hadoop.io.Writable;
+import org.apache.hadoop.io.file.tfile.TFile;
+import org.apache.hadoop.service.AbstractService;
+import org.apache.hadoop.yarn.api.records.ApplicationAttemptId;
+import org.apache.hadoop.yarn.api.records.ApplicationId;
+import org.apache.hadoop.yarn.api.records.ContainerId;
+import org.apache.hadoop.yarn.api.records.FinalApplicationStatus;
+import org.apache.hadoop.yarn.conf.YarnConfiguration;
+import org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos.ApplicationAttemptFinishDataProto;
+import org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos.ApplicationAttemptStartDataProto;
+import org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos.ApplicationFinishDataProto;
+import org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos.ApplicationStartDataProto;
+import org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos.ContainerFinishDataProto;
+import org.apache.hadoop.yarn.proto.ApplicationHistoryServerProtos.ContainerStartDataProto;
+import org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptFinishData;
+import org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptHistoryData;
+import org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptStartData;
+import org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationFinishData;
+import org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData;
+import org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationStartData;
+import org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerFinishData;
+import org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerHistoryData;
+import org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerStartData;
+import org.apache.hadoop.yarn.server.applicationhistoryservice.records.impl.pb.ApplicationAttemptFinishDataPBImpl;
+import org.apache.hadoop.yarn.server.applicationhistoryservice.records.impl.pb.ApplicationAttemptStartDataPBImpl;
+import org.apache.hadoop.yarn.server.applicationhistoryservice.records.impl.pb.ApplicationFinishDataPBImpl;
+import org.apache.hadoop.yarn.server.applicationhistoryservice.records.impl.pb.ApplicationStartDataPBImpl;
+import org.apache.hadoop.yarn.server.applicationhistoryservice.records.impl.pb.ContainerFinishDataPBImpl;
+import org.apache.hadoop.yarn.server.applicationhistoryservice.records.impl.pb.ContainerStartDataPBImpl;
+import org.apache.hadoop.yarn.util.ConverterUtils;
+
+import com.google.protobuf.InvalidProtocolBufferException;
+
+/**
+ * File system implementation of {@link ApplicationHistoryStore}. In this
+ * implementation, one application will have just one file in the file system,
+ * which contains all the history data of one application, and its attempts and
+ * containers. {@link #applicationStarted(ApplicationStartData)} is supposed to
+ * be invoked first when writing any history data of one application and it will
+ * open a file, while {@link #applicationFinished(ApplicationFinishData)} is
+ * supposed to be last writing operation and will close the file.
+ */
+@Public
+@Unstable
+public class FileSystemApplicationHistoryStore extends AbstractService
+    implements ApplicationHistoryStore {
+
+  private static final Log LOG = LogFactory
+      .getLog(FileSystemApplicationHistoryStore.class);
+
+  private static final String ROOT_DIR_NAME = ""ApplicationHistoryDataRoot"";
+  private static final int MIN_BLOCK_SIZE = 256 * 1024;
+  private static final String START_DATA_SUFFIX = ""_start"";
+  private static final String FINISH_DATA_SUFFIX = ""_finish"";
+  private static final FsPermission ROOT_DIR_UMASK =
+      FsPermission.createImmutable((short) 0740);
+  private static final FsPermission HISTORY_FILE_UMASK =
+      FsPermission.createImmutable((short) 0640);
+
+  private FileSystem fs;
+  private Path rootDirPath;
+
+  private ConcurrentMap<ApplicationId, HistoryFileWriter> outstandingWriters =
+      new ConcurrentHashMap<ApplicationId, HistoryFileWriter>();
+
+  public FileSystemApplicationHistoryStore() {
+    super(FileSystemApplicationHistoryStore.class.getName());
+  }
+
+  @Override
+  public void serviceInit(Configuration conf) throws Exception {
+    Path fsWorkingPath = new Path(
+        conf.get(YarnConfiguration.FS_HISTORY_STORE_URI));
+    rootDirPath = new Path(fsWorkingPath, ROOT_DIR_NAME);
+    try {
+      fs = fsWorkingPath.getFileSystem(conf);
+      fs.mkdirs(rootDirPath);
+      fs.setPermission(rootDirPath, ROOT_DIR_UMASK);
+    } catch (IOException e) {
+      LOG.error(""Error when initializing FileSystemHistoryStorage"", e);
+      throw e;
+    }
+    super.serviceInit(conf);
+  }
+
+  @Override
+  public void serviceStop() throws Exception {
+    try {
+      for (Entry<ApplicationId, HistoryFileWriter> entry : outstandingWriters
+          .entrySet()) {
+        entry.getValue().close();
+      }
+      outstandingWriters.clear();
+    } finally {
+      IOUtils.cleanup(LOG, fs);
+    }
+    super.serviceStop();
+  }
+
+  @Override
+  public ApplicationHistoryData getApplication(ApplicationId appId)
+      throws IOException {
+    HistoryFileReader hfReader = getHistoryFileReader(appId);
+    try {
+      boolean readStartData = false;
+      boolean readFinishData = false;
+      ApplicationHistoryData historyData =
+          ApplicationHistoryData.newInstance(
+              appId, null, null, null, null, Long.MIN_VALUE, Long.MIN_VALUE,
+              Long.MAX_VALUE, null, FinalApplicationStatus.UNDEFINED, null);
+      while ((!readStartData || !readFinishData) && hfReader.hasNext()) {
+        HistoryFileReader.Entry entry = hfReader.next();
+        if (entry.key.id.equals(appId.toString())) {
+          if (entry.key.suffix.equals(START_DATA_SUFFIX)) {
+            ApplicationStartData startData =
+                parseApplicationStartData(entry.value);
+            mergeApplicationHistoryData(historyData, startData);
+            readStartData = true;
+          } else if (entry.key.suffix.equals(FINISH_DATA_SUFFIX)) {
+            ApplicationFinishData finishData =
+                parseApplicationFinishData(entry.value);
+            mergeApplicationHistoryData(historyData, finishData);
+            readFinishData = true;
+          }
+        }
+      }
+      if (!readStartData && !readFinishData) {
+        return null;
+      }
+      if (!readStartData) {
+        LOG.warn(""Start information is missing for application "" + appId);
+      }
+      if (!readFinishData) {
+        LOG.warn(""Finish information is missing for application "" + appId);
+      }
+      LOG.info(""Completed reading history information of application "" + appId);
+      return historyData;
+    } catch (IOException e) {
+      LOG.error(""Error when reading history file of application "" + appId);
+      throw e;
+    } finally {
+      hfReader.close();
+    }
+  }
+
+  @Override
+  public Map<ApplicationId, ApplicationHistoryData> getAllApplications()
+      throws IOException {
+    Map<ApplicationId, ApplicationHistoryData> historyDataMap =
+        new HashMap<ApplicationId, ApplicationHistoryData>();
+    FileStatus[] files = fs.listStatus(rootDirPath);
+    for (FileStatus file : files) {
+      ApplicationId appId =
+          ConverterUtils.toApplicationId(file.getPath().getName());
+      try {
+        ApplicationHistoryData historyData = getApplication(appId);
+        if (historyData != null) {
+          historyDataMap.put(appId, historyData);
+        }
+      } catch (IOException e) {
+        // Eat the exception not to disturb the getting the next
+        // ApplicationHistoryData
+        LOG.error(""History information of application "" + appId
+            + "" is not included into the result due to the exception"", e);
+      }
+    }
+    return historyDataMap;
+  }
+
+  @Override
+  public Map<ApplicationAttemptId, ApplicationAttemptHistoryData>
+      getApplicationAttempts(ApplicationId appId) throws IOException {
+    Map<ApplicationAttemptId, ApplicationAttemptHistoryData> historyDataMap =
+        new HashMap<ApplicationAttemptId, ApplicationAttemptHistoryData>();
+    Map<ApplicationAttemptId, StartFinishDataPair<ApplicationAttemptStartData, ApplicationAttemptFinishData>> startFinshDataMap =
+        new HashMap<ApplicationAttemptId, StartFinishDataPair<ApplicationAttemptStartData, ApplicationAttemptFinishData>>();
+    HistoryFileReader hfReader = getHistoryFileReader(appId);
+    try {
+      while (hfReader.hasNext()) {
+        HistoryFileReader.Entry entry = hfReader.next();
+        if (entry.key.id.startsWith(ConverterUtils.APPLICATION_ATTEMPT_PREFIX)) {
+          if (entry.key.suffix.equals(START_DATA_SUFFIX)) {
+            retrieveStartFinishData(appId, entry, startFinshDataMap, true);
+          } else if (entry.key.suffix.equals(FINISH_DATA_SUFFIX)) {
+            retrieveStartFinishData(appId, entry, startFinshDataMap, false);
+          }
+        }
+      }
+      LOG.info(""Completed reading history information of all application""
+          + "" attempts of application "" + appId);
+    } catch (IOException e) {
+      LOG.info(""Error when reading history information of some application""
+          + "" attempts of application "" + appId);
+    } finally {
+      hfReader.close();
+    }
+    for (Map.Entry<ApplicationAttemptId, StartFinishDataPair<ApplicationAttemptStartData, ApplicationAttemptFinishData>> entry : startFinshDataMap
+        .entrySet()) {
+      ApplicationAttemptHistoryData historyData =
+          ApplicationAttemptHistoryData.newInstance(
+              entry.getKey(), null, -1, null, null, null,
+              FinalApplicationStatus.UNDEFINED, null);
+      mergeApplicationAttemptHistoryData(historyData,
+          entry.getValue().startData);
+      mergeApplicationAttemptHistoryData(historyData,
+          entry.getValue().finishData);
+      historyDataMap.put(entry.getKey(), historyData);
+    }
+    return historyDataMap;
+  }
+
+  private
+      void
+      retrieveStartFinishData(
+          ApplicationId appId,
+          HistoryFileReader.Entry entry,
+          Map<ApplicationAttemptId, StartFinishDataPair<ApplicationAttemptStartData, ApplicationAttemptFinishData>> startFinshDataMap,
+          boolean start) throws IOException {
+    ApplicationAttemptId appAttemptId =
+        ConverterUtils.toApplicationAttemptId(entry.key.id);
+    if (appAttemptId.getApplicationId().equals(appId)) {
+      StartFinishDataPair<ApplicationAttemptStartData, ApplicationAttemptFinishData> pair =
+          startFinshDataMap.get(appAttemptId);
+      if (pair == null) {
+        pair =
+            new StartFinishDataPair<ApplicationAttemptStartData, ApplicationAttemptFinishData>();
+        startFinshDataMap.put(appAttemptId, pair);
+      }
+      if (start) {
+        pair.startData = parseApplicationAttemptStartData(entry.value);
+      } else {
+        pair.finishData = parseApplicationAttemptFinishData(entry.value);
+      }
+    }
+  }
+
+  @Override
+  public ApplicationAttemptHistoryData getApplicationAttempt(
+      ApplicationAttemptId appAttemptId) throws IOException {
+    HistoryFileReader hfReader =
+        getHistoryFileReader(appAttemptId.getApplicationId());
+    try {
+      boolean readStartData = false;
+      boolean readFinishData = false;
+      ApplicationAttemptHistoryData historyData =
+          ApplicationAttemptHistoryData.newInstance(
+              appAttemptId, null, -1, null, null, null,
+              FinalApplicationStatus.UNDEFINED, null);
+      while ((!readStartData || !readFinishData) && hfReader.hasNext()) {
+        HistoryFileReader.Entry entry = hfReader.next();
+        if (entry.key.id.equals(appAttemptId.toString())) {
+          if (entry.key.suffix.equals(START_DATA_SUFFIX)) {
+            ApplicationAttemptStartData startData =
+                parseApplicationAttemptStartData(entry.value);
+            mergeApplicationAttemptHistoryData(historyData, startData);
+            readStartData = true;
+          } else if (entry.key.suffix.equals(FINISH_DATA_SUFFIX)) {
+            ApplicationAttemptFinishData finishData =
+                parseApplicationAttemptFinishData(entry.value);
+            mergeApplicationAttemptHistoryData(historyData, finishData);
+            readFinishData = true;
+          }
+        }
+      }
+      if (!readStartData && !readFinishData) {
+        return null;
+      }
+      if (!readStartData) {
+        LOG.warn(""Start information is missing for application attempt ""
+            + appAttemptId);
+      }
+      if (!readFinishData) {
+        LOG.warn(""Finish information is missing for application attempt ""
+            + appAttemptId);
+      }
+      LOG.info(""Completed reading history information of application attempt ""
+          + appAttemptId);
+      return historyData;
+    } catch (IOException e) {
+      LOG.error(""Error when reading history file of application attempt""
+          + appAttemptId);
+      throw e;
+    } finally {
+      hfReader.close();
+    }
+  }
+
+  @Override
+  public ContainerHistoryData getContainer(ContainerId containerId)
+      throws IOException {
+    HistoryFileReader hfReader =
+        getHistoryFileReader(containerId.getApplicationAttemptId()
+            .getApplicationId());
+    try {
+      boolean readStartData = false;
+      boolean readFinishData = false;
+      ContainerHistoryData historyData =
+          ContainerHistoryData.newInstance(containerId, null, null, null,
+              Long.MIN_VALUE, Long.MAX_VALUE, null, null, Integer.MAX_VALUE,
+              null);
+      while ((!readStartData || !readFinishData) && hfReader.hasNext()) {
+        HistoryFileReader.Entry entry = hfReader.next();
+        if (entry.key.id.equals(containerId.toString())) {
+          if (entry.key.suffix.equals(START_DATA_SUFFIX)) {
+            ContainerStartData startData =
+                parseContainerStartData(entry.value);
+            mergeContainerHistoryData(historyData, startData);
+            readStartData = true;
+          } else if (entry.key.suffix.equals(FINISH_DATA_SUFFIX)) {
+            ContainerFinishData finishData =
+                parseContainerFinishData(entry.value);
+            mergeContainerHistoryData(historyData, finishData);
+            readFinishData = true;
+          }
+        }
+      }
+      if (!readStartData && !readFinishData) {
+        return null;
+      }
+      if (!readStartData) {
+        LOG.warn(""Start information is missing for container "" + containerId);
+      }
+      if (!readFinishData) {
+        LOG.warn(""Finish information is missing for container "" + containerId);
+      }
+      LOG.info(""Completed reading history information of container ""
+          + containerId);
+      return historyData;
+    } catch (IOException e) {
+      LOG.error(""Error when reading history file of container "" + containerId);
+      throw e;
+    } finally {
+      hfReader.close();
+    }
+  }
+
+  @Override
+  public ContainerHistoryData getAMContainer(ApplicationAttemptId appAttemptId)
+      throws IOException {
+    ApplicationAttemptHistoryData attemptHistoryData =
+        getApplicationAttempt(appAttemptId);
+    if (attemptHistoryData == null
+        || attemptHistoryData.getMasterContainerId() == null) {
+      return null;
+    }
+    return getContainer(attemptHistoryData.getMasterContainerId());
+  }
+
+  @Override
+  public Map<ContainerId, ContainerHistoryData> getContainers(
+      ApplicationAttemptId appAttemptId) throws IOException {
+    Map<ContainerId, ContainerHistoryData> historyDataMap =
+        new HashMap<ContainerId, ContainerHistoryData>();
+    Map<ContainerId, StartFinishDataPair<ContainerStartData, ContainerFinishData>> startFinshDataMap =
+        new HashMap<ContainerId, StartFinishDataPair<ContainerStartData, ContainerFinishData>>();
+    HistoryFileReader hfReader =
+        getHistoryFileReader(appAttemptId.getApplicationId());
+    try {
+      while (hfReader.hasNext()) {
+        HistoryFileReader.Entry entry = hfReader.next();
+        if (entry.key.id.startsWith(ConverterUtils.CONTAINER_PREFIX)) {
+          if (entry.key.suffix.equals(START_DATA_SUFFIX)) {
+            retrieveStartFinishData(appAttemptId, entry, startFinshDataMap,
+                true);
+          } else if (entry.key.suffix.equals(FINISH_DATA_SUFFIX)) {
+            retrieveStartFinishData(appAttemptId, entry, startFinshDataMap,
+                false);
+          }
+        }
+      }
+      LOG.info(""Completed reading history information of all conatiners""
+          + "" of application attempt "" + appAttemptId);
+    } catch (IOException e) {
+      LOG.info(""Error when reading history information of some containers""
+          + "" of application attempt "" + appAttemptId);
+    } finally {
+      hfReader.close();
+    }
+    for (Map.Entry<ContainerId, StartFinishDataPair<ContainerStartData, ContainerFinishData>> entry : startFinshDataMap
+        .entrySet()) {
+      ContainerHistoryData historyData =
+          ContainerHistoryData.newInstance(entry.getKey(), null, null, null,
+              Long.MIN_VALUE, Long.MAX_VALUE, null, null, Integer.MAX_VALUE,
+              null);
+      mergeContainerHistoryData(historyData, entry.getValue().startData);
+      mergeContainerHistoryData(historyData, entry.getValue().finishData);
+      historyDataMap.put(entry.getKey(), historyData);
+    }
+    return historyDataMap;
+  }
+
+  private
+      void
+      retrieveStartFinishData(
+          ApplicationAttemptId appAttemptId,
+          HistoryFileReader.Entry entry,
+          Map<ContainerId, StartFinishDataPair<ContainerStartData, ContainerFinishData>> startFinshDataMap,
+          boolean start) throws IOException {
+    ContainerId containerId =
+        ConverterUtils.toContainerId(entry.key.id);
+    if (containerId.getApplicationAttemptId().equals(appAttemptId)) {
+      StartFinishDataPair<ContainerStartData, ContainerFinishData> pair =
+          startFinshDataMap.get(containerId);
+      if (pair == null) {
+        pair =
+            new StartFinishDataPair<ContainerStartData, ContainerFinishData>();
+        startFinshDataMap.put(containerId, pair);
+      }
+      if (start) {
+        pair.startData = parseContainerStartData(entry.value);
+      } else {
+        pair.finishData = parseContainerFinishData(entry.value);
+      }
+    }
+  }
+
+  @Override
+  public void applicationStarted(ApplicationStartData appStart)
+      throws IOException {
+    HistoryFileWriter hfWriter =
+        outstandingWriters.get(appStart.getApplicationId());
+    if (hfWriter == null) {
+      Path applicationHistoryFile =
+          new Path(rootDirPath, appStart.getApplicationId().toString());
+      try {
+        hfWriter = new HistoryFileWriter(applicationHistoryFile);
+        LOG.info(""Opened history file of application ""
+            + appStart.getApplicationId());
+      } catch (IOException e) {
+        LOG.error(""Error when openning history file of application ""
+            + appStart.getApplicationId());
+        throw e;
+      }
+      outstandingWriters.put(appStart.getApplicationId(), hfWriter);
+    } else {
+      throw new IOException(""History file of application ""
+          + appStart.getApplicationId() + "" is already opened"");
+    }
+    assert appStart instanceof ApplicationStartDataPBImpl;
+    try {
+      hfWriter.writeHistoryData(new HistoryDataKey(appStart.getApplicationId()
+          .toString(), START_DATA_SUFFIX),
+          ((ApplicationStartDataPBImpl) appStart)
+              .getProto().toByteArray());
+      LOG.info(""Start information of application ""
+          + appStart.getApplicationId() + "" is written"");
+    } catch (IOException e) {
+      LOG.error(""Error when writing start information of application ""
+          + appStart.getApplicationId());
+      throw e;
+    }
+  }
+
+  @Override
+  public void applicationFinished(ApplicationFinishData appFinish)
+      throws IOException {
+    HistoryFileWriter hfWriter =
+        getHistoryFileWriter(appFinish.getApplicationId());
+    assert appFinish instanceof ApplicationFinishDataPBImpl;
+    try {
+      hfWriter.writeHistoryData(
+          new HistoryDataKey(appFinish.getApplicationId().toString(),
+              FINISH_DATA_SUFFIX),
+          ((ApplicationFinishDataPBImpl) appFinish).getProto().toByteArray());
+      LOG.info(""Finish information of application ""
+          + appFinish.getApplicationId() + "" is written"");
+    } catch (IOException e) {
+      LOG.error(""Error when writing finish information of application ""
+          + appFinish.getApplicationId());
+      throw e;
+    } finally {
+      hfWriter.close();
+      outstandingWriters.remove(appFinish.getApplicationId());
+    }
+  }
+
+  @Override
+  public void applicationAttemptStarted(
+      ApplicationAttemptStartData appAttemptStart) throws IOException {
+    HistoryFileWriter hfWriter =
+        getHistoryFileWriter(appAttemptStart.getApplicationAttemptId()
+            .getApplicationId());
+    assert appAttemptStart instanceof ApplicationAttemptStartDataPBImpl;
+    try {
+      hfWriter.writeHistoryData(
+          new HistoryDataKey(appAttemptStart.getApplicationAttemptId()
+              .toString(),
+              START_DATA_SUFFIX),
+          ((ApplicationAttemptStartDataPBImpl) appAttemptStart).getProto()
+              .toByteArray());
+      LOG.info(""Start information of application attempt ""
+          + appAttemptStart.getApplicationAttemptId() + "" is written"");
+    } catch (IOException e) {
+      LOG.error(""Error when writing start information of application attempt ""
+          + appAttemptStart.getApplicationAttemptId());
+      throw e;
+    }
+  }
+
+  @Override
+  public void applicationAttemptFinished(
+      ApplicationAttemptFinishData appAttemptFinish) throws IOException {
+    HistoryFileWriter hfWriter =
+        getHistoryFileWriter(appAttemptFinish.getApplicationAttemptId()
+            .getApplicationId());
+    assert appAttemptFinish instanceof ApplicationAttemptFinishDataPBImpl;
+    try {
+      hfWriter.writeHistoryData(
+          new HistoryDataKey(appAttemptFinish.getApplicationAttemptId()
+              .toString(),
+              FINISH_DATA_SUFFIX),
+          ((ApplicationAttemptFinishDataPBImpl) appAttemptFinish).getProto()
+              .toByteArray());
+      LOG.info(""Finish information of application attempt ""
+          + appAttemptFinish.getApplicationAttemptId() + "" is written"");
+    } catch (IOException e) {
+      LOG.error(""Error when writing finish information of application attempt ""
+          + appAttemptFinish.getApplicationAttemptId());
+      throw e;
+    }
+  }
+
+  @Override
+  public void containerStarted(ContainerStartData containerStart)
+      throws IOException {
+    HistoryFileWriter hfWriter =
+        getHistoryFileWriter(containerStart.getContainerId()
+            .getApplicationAttemptId()
+            .getApplicationId());
+    assert containerStart instanceof ContainerStartDataPBImpl;
+    try {
+      hfWriter.writeHistoryData(
+          new HistoryDataKey(containerStart.getContainerId().toString(),
+              START_DATA_SUFFIX),
+          ((ContainerStartDataPBImpl) containerStart).getProto().toByteArray());
+      LOG.info(""Start information of container ""
+          + containerStart.getContainerId() + "" is written"");
+    } catch (IOException e) {
+      LOG.error(""Error when writing start information of container ""
+          + containerStart.getContainerId());
+      throw e;
+    }
+  }
+
+  @Override
+  public void containerFinished(ContainerFinishData containerFinish)
+      throws IOException {
+    HistoryFileWriter hfWriter =
+        getHistoryFileWriter(containerFinish.getContainerId()
+            .getApplicationAttemptId().getApplicationId());
+    assert containerFinish instanceof ContainerFinishDataPBImpl;
+    try {
+      hfWriter.writeHistoryData(
+          new HistoryDataKey(containerFinish.getContainerId().toString(),
+              FINISH_DATA_SUFFIX),
+          ((ContainerFinishDataPBImpl) containerFinish).getProto()
+              .toByteArray());
+      LOG.info(""Finish information of container ""
+          + containerFinish.getContainerId() + "" is written"");
+    } catch (IOException e) {
+      LOG.error(""Error when writing finish information of container ""
+          + containerFinish.getContainerId());
+    }
+  }
+
+  private static ApplicationStartData parseApplicationStartData(byte[] value)
+      throws InvalidProtocolBufferException {
+    return new ApplicationStartDataPBImpl(
+        ApplicationStartDataProto.parseFrom(value));
+  }
+
+  private static ApplicationFinishData parseApplicationFinishData(byte[] value)
+      throws InvalidProtocolBufferException {
+    return new ApplicationFinishDataPBImpl(
+        ApplicationFinishDataProto.parseFrom(value));
+  }
+
+  private static ApplicationAttemptStartData parseApplicationAttemptStartData(
+      byte[] value) throws InvalidProtocolBufferException {
+    return new ApplicationAttemptStartDataPBImpl(
+        ApplicationAttemptStartDataProto.parseFrom(value));
+  }
+
+  private static ApplicationAttemptFinishData
+      parseApplicationAttemptFinishData(
+          byte[] value) throws InvalidProtocolBufferException {
+    return new ApplicationAttemptFinishDataPBImpl(
+        ApplicationAttemptFinishDataProto.parseFrom(value));
+  }
+
+  private static ContainerStartData parseContainerStartData(byte[] value)
+      throws InvalidProtocolBufferException {
+    return new ContainerStartDataPBImpl(
+        ContainerStartDataProto.parseFrom(value));
+  }
+
+  private static ContainerFinishData parseContainerFinishData(byte[] value)
+      throws InvalidProtocolBufferException {
+    return new ContainerFinishDataPBImpl(
+        ContainerFinishDataProto.parseFrom(value));
+  }
+
+  private static void mergeApplicationHistoryData(
+      ApplicationHistoryData historyData,
+      ApplicationStartData startData) {
+    historyData.setApplicationName(startData.getApplicationName());
+    historyData.setApplicationType(startData.getApplicationType());
+    historyData.setQueue(startData.getQueue());
+    historyData.setUser(startData.getUser());
+    historyData.setSubmitTime(startData.getSubmitTime());
+    historyData.setStartTime(startData.getStartTime());
+  }
+
+  private static void mergeApplicationHistoryData(
+      ApplicationHistoryData historyData,
+      ApplicationFinishData finishData) {
+    historyData.setFinishTime(finishData.getFinishTime());
+    historyData.setDiagnosticsInfo(finishData.getDiagnosticsInfo());
+    historyData.setFinalApplicationStatus(finishData
+        .getFinalApplicationStatus());
+    historyData.setYarnApplicationState(finishData.getYarnApplicationState());
+  }
+
+  private static void mergeApplicationAttemptHistoryData(
+      ApplicationAttemptHistoryData historyData,
+      ApplicationAttemptStartData startData) {
+    historyData.setHost(startData.getHost());
+    historyData.setRPCPort(startData.getRPCPort());
+    historyData.setMasterContainerId(startData.getMasterContainerId());
+  }
+
+  private static void mergeApplicationAttemptHistoryData(
+      ApplicationAttemptHistoryData historyData,
+      ApplicationAttemptFinishData finishData) {
+    historyData.setDiagnosticsInfo(finishData.getDiagnosticsInfo());
+    historyData.setTrackingURL(finishData.getTrackingURL());
+    historyData.setFinalApplicationStatus(finishData
+        .getFinalApplicationStatus());
+    historyData.setYarnApplicationAttemptState(finishData
+        .getYarnApplicationAttemptState());
+  }
+
+  private static void mergeContainerHistoryData(
+      ContainerHistoryData historyData, ContainerStartData startData) {
+    historyData.setAllocatedResource(startData.getAllocatedResource());
+    historyData.setAssignedNode(startData.getAssignedNode());
+    historyData.setPriority(startData.getPriority());
+    historyData.setStartTime(startData.getStartTime());
+  }
+
+  private static void mergeContainerHistoryData(
+      ContainerHistoryData historyData, ContainerFinishData finishData) {
+    historyData.setFinishTime(finishData.getFinishTime());
+    historyData.setDiagnosticsInfo(finishData.getDiagnosticsInfo());
+    historyData.setLogURL(finishData.getLogURL());
+    historyData.setContainerExitStatus(finishData
+        .getContainerExitStatus());
+    historyData.setContainerState(finishData.getContainerState());
+  }
+
+  private HistoryFileWriter getHistoryFileWriter(ApplicationId appId)
+      throws IOException {
+    HistoryFileWriter hfWriter = outstandingWriters.get(appId);
+    if (hfWriter == null) {
+      throw new IOException(""History file of application "" + appId
+          + "" is not opened"");
+    }
+    return hfWriter;
+  }
+
+  private HistoryFileReader getHistoryFileReader(ApplicationId appId)
+      throws IOException {
+    Path applicationHistoryFile = new Path(rootDirPath, appId.toString());
+    if (!fs.exists(applicationHistoryFile)) {
+      throw new IOException(""History file for application "" + appId
+          + "" is not found"");
+    }
+    // The history file is still under writing
+    if (outstandingWriters.containsKey(appId)) {
+      throw new IOException(""History file for application "" + appId
+          + "" is under writing"");
+    }
+    return new HistoryFileReader(applicationHistoryFile);
+  }
+
+  private class HistoryFileReader {
+
+    private class Entry {
+
+      private HistoryDataKey key;
+      private byte[] value;
+
+      public Entry(HistoryDataKey key, byte[] value) {
+        this.key = key;
+        this.value = value;
+      }
+    }
+
+    private FSDataInputStream fsdis;
+    private TFile.Reader reader;
+    private TFile.Reader.Scanner scanner;
+
+    public HistoryFileReader(Path historyFile) throws IOException {
+      FSDataInputStream fsdis = fs.open(historyFile);
+      reader =
+          new TFile.Reader(fsdis, fs.getFileStatus(historyFile).getLen(),
+              getConfig());
+      reset();
+    }
+
+    public boolean hasNext() {
+      return !scanner.atEnd();
+    }
+
+    public Entry next() throws IOException {
+      TFile.Reader.Scanner.Entry entry = scanner.entry();
+      DataInputStream dis = entry.getKeyStream();
+      HistoryDataKey key = new HistoryDataKey();
+      key.readFields(dis);
+      dis = entry.getValueStream();
+      byte[] value = new byte[entry.getValueLength()];
+      dis.read(value);
+      scanner.advance();
+      return new Entry(key, value);
+    }
+
+    public void reset() throws IOException {
+      IOUtils.cleanup(LOG, scanner);
+      scanner = reader.createScanner();
+    }
+
+    public void close() {
+      IOUtils.cleanup(LOG, scanner, reader, fsdis);
+    }
+
+  }
+
+  private class HistoryFileWriter {
+
+    private FSDataOutputStream fsdos;
+    private TFile.Writer writer;
+
+    public HistoryFileWriter(Path historyFile)
+        throws IOException {
+      if (fs.exists(historyFile)) {
+        fsdos = fs.append(historyFile);
+      } else {
+        fsdos = fs.create(historyFile);
+      }
+      fs.setPermission(historyFile, HISTORY_FILE_UMASK);
+      writer =
+          new TFile.Writer(fsdos, MIN_BLOCK_SIZE, getConfig().get(
+              YarnConfiguration.FS_HISTORY_STORE_COMPRESSION_TYPE,
+              YarnConfiguration.DEFAULT_FS_HISTORY_STORE_COMPRESSION_TYPE),
+              null, getConfig());
+    }
+
+    public synchronized void close() {
+      IOUtils.cleanup(LOG, writer, fsdos);
+    }
+
+    public synchronized void writeHistoryData(HistoryDataKey key, byte[] value)
+        throws IOException {
+      DataOutputStream dos = null;
+      try {
+        dos = writer.prepareAppendKey(-1);
+        key.write(dos);
+      } finally {
+        IOUtils.cleanup(LOG, dos);
+      }
+      try {
+        dos = writer.prepareAppendValue(value.length);
+        dos.write(value);
+      } finally {
+        IOUtils.cleanup(LOG, dos);
+      }
+    }
+
+  }
+
+  private static class HistoryDataKey implements Writable {
+
+    private String id;
+
+    private String suffix;
+
+    public HistoryDataKey() {
+      this(null, null);
+    }
+
+    public HistoryDataKey(String id, String suffix) {
+      this.id = id;
+      this.suffix = suffix;
+    }
+
+    @Override
+    public void write(DataOutput out) throws IOException {
+      out.writeUTF(id);
+      out.writeUTF(suffix);
+    }
+
+    @Override
+    public void readFields(DataInput in) throws IOException {
+      id = in.readUTF();
+      suffix = in.readUTF();
+    }
+
+  }
+
+  private static class StartFinishDataPair<S, F> {
+
+    private S startData;
+    private F finishData;
+
+  }
+
+}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/test/java/org/apache/hadoop/yarn/server/applicationhistoryservice/TestFileSystemApplicationHistoryStore.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/test/java/org/apache/hadoop/yarn/server/applicationhistoryservice/TestFileSystemApplicationHistoryStore.java
new file mode 100644
index 00000000000..d4a431f4ecb
--- /dev/null
+++ b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/test/java/org/apache/hadoop/yarn/server/applicationhistoryservice/TestFileSystemApplicationHistoryStore.java
@@ -0,0 +1,198 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.yarn.server.applicationhistoryservice;
+
+import java.io.IOException;
+import java.net.URI;
+
+import junit.framework.Assert;
+
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.fs.FileSystem;
+import org.apache.hadoop.fs.Path;
+import org.apache.hadoop.fs.RawLocalFileSystem;
+import org.apache.hadoop.yarn.api.records.ApplicationAttemptId;
+import org.apache.hadoop.yarn.api.records.ApplicationId;
+import org.apache.hadoop.yarn.api.records.ContainerId;
+import org.apache.hadoop.yarn.api.records.Priority;
+import org.apache.hadoop.yarn.conf.YarnConfiguration;
+import org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationAttemptHistoryData;
+import org.apache.hadoop.yarn.server.applicationhistoryservice.records.ApplicationHistoryData;
+import org.apache.hadoop.yarn.server.applicationhistoryservice.records.ContainerHistoryData;
+import org.junit.After;
+import org.junit.Before;
+import org.junit.Test;
+
+public class TestFileSystemApplicationHistoryStore extends
+    ApplicationHistoryStoreTestUtils {
+
+  private FileSystem fs;
+  private Path fsWorkingPath;
+
+  @Before
+  public void setup() throws Exception {
+    fs = new RawLocalFileSystem();
+    Configuration conf = new Configuration();
+    fs.initialize(new URI(""/""), conf);
+    fsWorkingPath = new Path(""Test"");
+    fs.delete(fsWorkingPath, true);
+    conf.set(YarnConfiguration.FS_HISTORY_STORE_URI, fsWorkingPath.toString());
+    store = new FileSystemApplicationHistoryStore();
+    store.init(conf);
+    store.start();
+  }
+
+  @After
+  public void tearDown() throws Exception {
+    store.stop();
+    fs.delete(fsWorkingPath, true);
+    fs.close();
+  }
+
+  @Test
+  public void testReadWriteHistoryData() throws IOException {
+    testWriteHistoryData(5);
+    testReadHistoryData(5);
+  }
+
+  private void testWriteHistoryData(int num) throws IOException {
+    // write application history data
+    for (int i = 1; i <= num; ++i) {
+      ApplicationId appId = ApplicationId.newInstance(0, i);
+      writeApplicationStartData(appId);
+
+      // write application attempt history data
+      for (int j = 1; j <= num; ++j) {
+        ApplicationAttemptId appAttemptId =
+            ApplicationAttemptId.newInstance(appId, j);
+        writeApplicationAttemptStartData(appAttemptId);
+
+        // write container history data
+        for (int k = 1; k <= num; ++k) {
+          ContainerId containerId = ContainerId.newInstance(appAttemptId, k);
+          writeContainerStartData(containerId);
+          writeContainerFinishData(containerId);
+
+          writeApplicationAttemptFinishData(appAttemptId);
+        }
+      }
+
+      writeApplicationFinishData(appId);
+    }
+  }
+
+  private void testReadHistoryData(int num) throws IOException {
+    // read application history data
+    Assert.assertEquals(num, store.getAllApplications().size());
+    for (int i = 1; i <= num; ++i) {
+      ApplicationId appId = ApplicationId.newInstance(0, i);
+      ApplicationHistoryData appData = store.getApplication(appId);
+      Assert.assertNotNull(appData);
+      Assert.assertEquals(appId.toString(), appData.getApplicationName());
+      Assert.assertEquals(appId.toString(), appData.getDiagnosticsInfo());
+
+      // read application attempt history data
+      Assert.assertEquals(
+          num, store.getApplicationAttempts(appId).size());
+      for (int j = 1; j <= num; ++j) {
+        ApplicationAttemptId appAttemptId =
+            ApplicationAttemptId.newInstance(appId, j);
+        ApplicationAttemptHistoryData attemptData =
+            store.getApplicationAttempt(appAttemptId);
+        Assert.assertNotNull(attemptData);
+        Assert.assertEquals(appAttemptId.toString(), attemptData.getHost());
+        Assert.assertEquals(appAttemptId.toString(),
+            attemptData.getDiagnosticsInfo());
+
+        // read container history data
+        Assert.assertEquals(
+            num, store.getContainers(appAttemptId).size());
+        for (int k = 1; k <= num; ++k) {
+          ContainerId containerId = ContainerId.newInstance(appAttemptId, k);
+          ContainerHistoryData containerData = store.getContainer(containerId);
+          Assert.assertNotNull(containerData);
+          Assert.assertEquals(Priority.newInstance(containerId.getId()),
+              containerData.getPriority());
+          Assert.assertEquals(containerId.toString(),
+              containerData.getDiagnosticsInfo());
+        }
+        ContainerHistoryData masterContainer =
+            store.getAMContainer(appAttemptId);
+        Assert.assertNotNull(masterContainer);
+        Assert.assertEquals(ContainerId.newInstance(appAttemptId, 1),
+            masterContainer.getContainerId());
+      }
+    }
+  }
+
+  @Test
+  public void testWriteAfterApplicationFinish() throws IOException {
+    ApplicationId appId = ApplicationId.newInstance(0, 1);
+    writeApplicationStartData(appId);
+    writeApplicationFinishData(appId);
+    // write application attempt history data
+    ApplicationAttemptId appAttemptId =
+        ApplicationAttemptId.newInstance(appId, 1);
+    try {
+      writeApplicationAttemptStartData(appAttemptId);
+      Assert.fail();
+    } catch (IOException e) {
+      Assert.assertTrue(e.getMessage().contains(""is not opened""));
+    }
+    try {
+      writeApplicationAttemptFinishData(appAttemptId);
+      Assert.fail();
+    } catch (IOException e) {
+      Assert.assertTrue(e.getMessage().contains(""is not opened""));
+    }
+    // write container history data
+    ContainerId containerId = ContainerId.newInstance(appAttemptId, 1);
+    try {
+      writeContainerStartData(containerId);
+      Assert.fail();
+    } catch (IOException e) {
+      Assert.assertTrue(e.getMessage().contains(""is not opened""));
+    }
+    try {
+      writeContainerFinishData(containerId);
+      Assert.fail();
+    } catch (IOException e) {
+      Assert.assertTrue(e.getMessage().contains(""is not opened""));
+    }
+  }
+
+  @Test
+  public void testMassiveWriteContainerHistoryData() throws IOException {
+    long mb = 1024 * 1024;
+    long usedDiskBefore = fs.getContentSummary(fsWorkingPath).getLength() / mb;
+    ApplicationId appId = ApplicationId.newInstance(0, 1);
+    writeApplicationStartData(appId);
+    ApplicationAttemptId appAttemptId =
+        ApplicationAttemptId.newInstance(appId, 1);
+    for (int i = 1; i <= 100000; ++i) {
+      ContainerId containerId = ContainerId.newInstance(appAttemptId, i);
+      writeContainerStartData(containerId);
+      writeContainerFinishData(containerId);
+    }
+    writeApplicationFinishData(appId);
+    long usedDiskAfter = fs.getContentSummary(fsWorkingPath).getLength() / mb;
+    Assert.assertTrue((usedDiskAfter - usedDiskBefore) < 20);
+  }
+
+}
",YARN-975. Added a file-system implementation for- HistoryStorage. Contributed by Zhijie Shen. svn merge --ignore-ancestry -c- 1556727 ../YARN-321--git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/branch-2@1562184 13f79535-47bb-0310-9956-ffa450edef68-
1568,Java,846a05c7d078a6ba05f6ab3643ce6f382de784bc,,P,kiegroup,drools,"[1, 4, 0, 0, 0, 0, 0, 3, 326, 374, 23, 6, 16, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/drools-compiler/src/test/java/org/drools/agent/BaseKnowledgeAgentTest.java b/drools-compiler/src/test/java/org/drools/agent/BaseKnowledgeAgentTest.java
new file mode 100644
index 0000000000..6533b96e76
--- /dev/null
+++ b/drools-compiler/src/test/java/org/drools/agent/BaseKnowledgeAgentTest.java
@@ -0,0 +1,312 @@
+package org.drools.agent;
+
+import java.io.File;
+import java.io.FileNotFoundException;
+import java.io.FileOutputStream;
+import java.io.IOException;
+import java.util.concurrent.CountDownLatch;
+import java.util.concurrent.TimeUnit;
+
+import org.drools.KnowledgeBase;
+import org.drools.core.util.DroolsStreamUtils;
+import org.drools.core.util.FileManager;
+import org.drools.core.util.IoUtils;
+import org.drools.core.util.StringUtils;
+import org.drools.event.knowledgeagent.AfterChangeSetAppliedEvent;
+import org.drools.event.knowledgeagent.AfterChangeSetProcessedEvent;
+import org.drools.event.knowledgeagent.AfterResourceProcessedEvent;
+import org.drools.event.knowledgeagent.BeforeChangeSetAppliedEvent;
+import org.drools.event.knowledgeagent.BeforeChangeSetProcessedEvent;
+import org.drools.event.knowledgeagent.BeforeResourceProcessedEvent;
+import org.drools.event.knowledgeagent.KnowledgeAgentEventListener;
+import org.drools.event.knowledgeagent.KnowledgeBaseUpdatedEvent;
+import org.drools.event.knowledgeagent.ResourceCompilationFailedEvent;
+import org.drools.io.Resource;
+import org.drools.io.ResourceFactory;
+import org.drools.io.impl.ResourceChangeNotifierImpl;
+import org.drools.io.impl.ResourceChangeScannerImpl;
+import org.mortbay.jetty.Server;
+import org.mortbay.jetty.handler.ResourceHandler;
+
+import junit.framework.TestCase;
+
+public abstract class BaseKnowledgeAgentTest extends TestCase {
+    FileManager     fileManager;
+    Server           server;    
+    ResourceChangeScannerImpl scanner;
+
+    @Override
+    protected void setUp() throws Exception {
+        this.fileManager = new FileManager();
+        this.fileManager.setUp();
+        ((ResourceChangeScannerImpl) ResourceFactory.getResourceChangeScannerService()).reset();
+
+        ResourceFactory.getResourceChangeNotifierService().start();
+        
+        // we don't start the scanner, as we call it manually;
+        this.scanner = (ResourceChangeScannerImpl) ResourceFactory.getResourceChangeScannerService();
+
+        this.server = new Server( IoUtils.findPort() );
+        ResourceHandler resourceHandler = new ResourceHandler();
+        resourceHandler.setResourceBase( fileManager.getRootDirectory().getPath() );
+
+        this.server.setHandler( resourceHandler );
+
+        this.server.start();
+    }
+    
+    @Override
+    protected void tearDown() throws Exception {
+        fileManager.tearDown();
+        ResourceFactory.getResourceChangeNotifierService().stop();
+        ((ResourceChangeNotifierImpl) ResourceFactory.getResourceChangeNotifierService()).reset();
+        ((ResourceChangeScannerImpl) ResourceFactory.getResourceChangeScannerService()).reset();
+
+        server.stop();
+    } 
+    
+
+
+    public int getPort() {
+        return this.server.getConnectors()[0].getLocalPort();
+    }
+    
+
+    public void scan(KnowledgeAgent kagent) {
+        // Calls the Resource Scanner and sets up a listener and a latch so we can wait until it's finished processing, instead of using timers
+        final CountDownLatch latch = new CountDownLatch( 1 );
+        
+        KnowledgeAgentEventListener l = new KnowledgeAgentEventListener() {
+            
+            public void resourceCompilationFailed(ResourceCompilationFailedEvent event) {
+            }
+            
+            public void knowledgeBaseUpdated(KnowledgeBaseUpdatedEvent event) {
+            }
+            
+            public void beforeResourceProcessed(BeforeResourceProcessedEvent event) {
+            }
+            
+            public void beforeChangeSetProcessed(BeforeChangeSetProcessedEvent event) {                              
+            }
+            
+            public void beforeChangeSetApplied(BeforeChangeSetAppliedEvent event) {
+            }
+            
+            public void afterResourceProcessed(AfterResourceProcessedEvent event) {
+            }
+            
+            public void afterChangeSetProcessed(AfterChangeSetProcessedEvent event) {
+            }
+            
+            public void afterChangeSetApplied(AfterChangeSetAppliedEvent event) {
+                latch.countDown();
+            }
+        };        
+        
+        kagent.addEventListener( l );
+        
+        this.scanner.scan();
+        
+        try {
+            latch.await( 10, TimeUnit.SECONDS );
+        } catch ( InterruptedException e ) {
+            throw new RuntimeException( ""Unable to wait for latch countdown"", e);
+        }
+        
+        if ( latch.getCount() > 0 ) {            
+            throw new RuntimeException( ""Event for KnowlegeBase update, due to scan, was never received"" );
+        }
+        
+        kagent.removeEventListener( l );
+    }
+    
+    void applyChangeSet(KnowledgeAgent kagent, String xml) {
+        // Calls the Resource Scanner and sets up a listener and a latch so we can wait until it's finished processing, instead of using timers
+        final CountDownLatch latch = new CountDownLatch( 1 );
+        
+        KnowledgeAgentEventListener l = new KnowledgeAgentEventListener() {
+            
+            public void resourceCompilationFailed(ResourceCompilationFailedEvent event) {
+            }
+            
+            public void knowledgeBaseUpdated(KnowledgeBaseUpdatedEvent event) {
+            }
+            
+            public void beforeResourceProcessed(BeforeResourceProcessedEvent event) {
+            }
+            
+            public void beforeChangeSetProcessed(BeforeChangeSetProcessedEvent event) {                              
+            }
+            
+            public void beforeChangeSetApplied(BeforeChangeSetAppliedEvent event) {
+            }
+            
+            public void afterResourceProcessed(AfterResourceProcessedEvent event) {
+            }
+            
+            public void afterChangeSetProcessed(AfterChangeSetProcessedEvent event) {
+            }
+            
+            public void afterChangeSetApplied(AfterChangeSetAppliedEvent event) {
+                latch.countDown();
+            }
+        };        
+        
+        kagent.addEventListener( l );
+        
+        kagent.applyChangeSet( ResourceFactory.newByteArrayResource( xml.getBytes() ) );
+        
+        try {
+            latch.await( 10, TimeUnit.SECONDS );
+        } catch ( InterruptedException e ) {
+            throw new RuntimeException( ""Unable to wait for latch countdown"", e);
+        }
+        
+        if ( latch.getCount() > 0 ) {            
+            throw new RuntimeException( ""Event for KnowlegeBase update, due to scan, was never received"" );
+        }
+        
+        kagent.removeEventListener( l );        
+    }
+    
+    void applyChangeSet(KnowledgeAgent kagent, Resource r) {
+        // Calls the Resource Scanner and sets up a listener and a latch so we can wait until it's finished processing, instead of using timers
+        final CountDownLatch latch = new CountDownLatch( 1 );
+        
+        KnowledgeAgentEventListener l = new KnowledgeAgentEventListener() {
+            
+            public void resourceCompilationFailed(ResourceCompilationFailedEvent event) {
+            }
+            
+            public void knowledgeBaseUpdated(KnowledgeBaseUpdatedEvent event) {
+            }
+            
+            public void beforeResourceProcessed(BeforeResourceProcessedEvent event) {
+            }
+            
+            public void beforeChangeSetProcessed(BeforeChangeSetProcessedEvent event) {                              
+            }
+            
+            public void beforeChangeSetApplied(BeforeChangeSetAppliedEvent event) {
+            }
+            
+            public void afterResourceProcessed(AfterResourceProcessedEvent event) {
+            }
+            
+            public void afterChangeSetProcessed(AfterChangeSetProcessedEvent event) {
+            }
+            
+            public void afterChangeSetApplied(AfterChangeSetAppliedEvent event) {
+                latch.countDown();
+            }
+        };        
+        
+        kagent.addEventListener( l );
+        
+        kagent.applyChangeSet( r );
+        
+        try {
+            latch.await( 10, TimeUnit.SECONDS );
+        } catch ( InterruptedException e ) {
+            throw new RuntimeException( ""Unable to wait for latch countdown"", e);
+        }
+        
+        if ( latch.getCount() > 0 ) {            
+            throw new RuntimeException( ""Event for KnowlegeBase update, due to scan, was never received"" );
+        }
+        
+        kagent.removeEventListener( l );        
+    }   
+    
+
+    public static void writePackage(Object pkg,
+                                     File p1file )throws IOException, FileNotFoundException {
+        if ( p1file.exists() ) {
+            // we want to make sure there is a time difference for lastModified and lastRead checks as Linux and http often round to seconds
+            // http://saloon.javaranch.com/cgi-bin/ubb/ultimatebb.cgi?ubb=get_topic&f=1&t=019789
+            try {
+                Thread.sleep( 1000 );
+            } catch (Exception e) {
+                throw new RuntimeException( ""Unable to sleep"" );
+            }            
+        }
+        FileOutputStream out = new FileOutputStream( p1file );
+        try {
+            DroolsStreamUtils.streamOut( out,
+                                         pkg );
+        } finally {
+            out.close();
+        }
+    }
+
+    public KnowledgeAgent createKAgent(KnowledgeBase kbase) {
+        return createKAgent( kbase, true );
+    }
+    public KnowledgeAgent createKAgent(KnowledgeBase kbase, boolean newInsatnce) {
+        KnowledgeAgentConfiguration aconf = KnowledgeAgentFactory.newKnowledgeAgentConfiguration();
+        aconf.setProperty( ""drools.agent.scanDirectories"",
+                           ""true"" );
+        aconf.setProperty( ""drools.agent.scanResources"",
+                           ""true"" );
+        aconf.setProperty( ""drools.agent.newInstance"",
+                           Boolean.toString( newInsatnce ) );
+
+        KnowledgeAgent kagent = KnowledgeAgentFactory.newKnowledgeAgent(""test agent"",
+                                                                         kbase,
+                                                                         aconf );
+
+        assertEquals( ""test agent"",
+                      kagent.getName() );
+
+        return kagent;
+    }
+    
+    
+    public String createVersionedRule(String packageName, String ruleName, String attribute, String version) {        
+        StringBuilder rule = new StringBuilder();
+        if ( StringUtils.isEmpty( packageName ) ) {
+            rule.append( ""package org.drools.test\n"" );
+        } else {
+            rule.append( ""package "" );
+            rule.append( packageName );
+            rule.append( ""\n"" );
+        }
+        rule.append( ""global java.util.List list\n"" );
+        rule.append( ""rule "" );
+        rule.append( ruleName );
+        rule.append( ""\n"" );
+        if ( !StringUtils.isEmpty( attribute ) ) {
+            rule.append( attribute +""\n"" );    
+        }
+        rule.append( ""when\n"" );
+        rule.append( ""then\n"" );
+        if ( StringUtils.isEmpty( version ) ) {
+            rule.append( ""list.add( drools.getRule().getName() );\n"" );
+        } else {
+            rule.append(""list.add( drools.getRule().getName()+\""-V"" + version + ""\"");\n"");
+        }
+        rule.append( ""end\n"" );
+
+        return rule.toString();       
+    }    
+    
+    public String createVersionedRule(String ruleName, String version) {
+        return createVersionedRule( null, ruleName, null, version );
+    }
+
+    public String createDefaultRule(String name) {
+        return createDefaultRule( name,
+                                  null );
+    }
+
+    public String createDefaultRule(String ruleName,
+                                    String packageName) {
+        return createVersionedRule( null, ruleName, null, null );
+    }  
+    
+    public String createAttributeRule(String ruleName,
+                                      String attribute) {
+        return createVersionedRule( null, ruleName, attribute, null );
+    }     
+}
diff --git a/drools-compiler/src/test/java/org/drools/agent/KnowledgeAgentBinaryDiffTests.java b/drools-compiler/src/test/java/org/drools/agent/KnowledgeAgentBinaryDiffTests.java
index 300214a0ff..b82c18a375 100644
--- a/drools-compiler/src/test/java/org/drools/agent/KnowledgeAgentBinaryDiffTests.java
+++ b/drools-compiler/src/test/java/org/drools/agent/KnowledgeAgentBinaryDiffTests.java
@@ -23,43 +23,5 @@ import org.mortbay.jetty.Server;
 import org.mortbay.jetty.handler.ResourceHandler;
 
-public class KnowledgeAgentBinaryDiffTests extends TestCase {
-
-    FileManager fileManager;
-    private Server server;
-
-    @Override
-    protected void setUp() throws Exception {
-        fileManager = new FileManager();
-        fileManager.setUp();
-        ((ResourceChangeScannerImpl) ResourceFactory.getResourceChangeScannerService()).reset();
-        ResourceFactory.getResourceChangeNotifierService().start();
-        ResourceFactory.getResourceChangeScannerService().start();
-
-        this.server = new Server(0);
-        ResourceHandler resourceHandler = new ResourceHandler();
-        resourceHandler.setResourceBase(fileManager.getRootDirectory().getPath());
-        System.out.println(""root : "" + fileManager.getRootDirectory().getPath());
-
-        server.setHandler(resourceHandler);
-
-        server.start();
-
-        System.out.println(""Server running on port ""+this.getPort());
-    }
-
-    private int getPort(){
-        return this.server.getConnectors()[0].getLocalPort();
-    }
-
-    @Override
-    protected void tearDown() throws Exception {
-        fileManager.tearDown();
-        ResourceFactory.getResourceChangeNotifierService().stop();
-        ResourceFactory.getResourceChangeScannerService().stop();
-        ((ResourceChangeNotifierImpl) ResourceFactory.getResourceChangeNotifierService()).reset();
-        ((ResourceChangeScannerImpl) ResourceFactory.getResourceChangeScannerService()).reset();
-
-        server.stop();
-    }
+public class KnowledgeAgentBinaryDiffTests extends BaseKnowledgeAgentTest {
 
     public void testDifferentDateExpires() throws Exception {
@@ -294,17 +256,7 @@ public class KnowledgeAgentBinaryDiffTests extends TestCase {
 
     public void testDifferentLHS() throws Exception {
+        File f1 = fileManager.write( ""rule1.drl"",
+                                     createDefaultRule( ""rule1"" ) );          
 
-        String header1 = """";
-        header1 += ""package org.drools.test\n"";
-        header1 += ""global java.util.List list\n\n"";
-
-        String rule1 = this.createCommonRule(""rule1"");
-
-
-        File f1 = fileManager.newFile(""rule1.drl"");
-        Writer output = new BufferedWriter(new FileWriter(f1));
-        output.write(header1);
-        output.write(rule1);
-        output.close();
 
         String xml = """";
@@ -316,13 +268,11 @@ public class KnowledgeAgentBinaryDiffTests extends TestCase {
         xml += ""    </add> "";
         xml += ""</change-set>"";
-        File fxml = fileManager.newFile(""changeset.xml"");
-        output = new BufferedWriter(new FileWriter(fxml));
-        output.write(xml);
-        output.close();
+        File fxml = fileManager.write( ""changeset.xml"",
+                                       xml );
 
         KnowledgeBase kbase = KnowledgeBaseFactory.newKnowledgeBase();
-        KnowledgeAgent kagent = this.createKAgent(kbase);
-
-        kagent.applyChangeSet(ResourceFactory.newUrlResource(fxml.toURI().toURL()));
+        KnowledgeAgent kagent = this.createKAgent(kbase, false);
+        
+        applyChangeSet( kagent, ResourceFactory.newUrlResource(fxml.toURI().toURL()) );
 
         StatefulKnowledgeSession ksession = kbase.newStatefulKnowledgeSession();
@@ -336,23 +286,9 @@ public class KnowledgeAgentBinaryDiffTests extends TestCase {
 
         list.clear();
-
-        // have to sleep here as linux lastModified does not do milliseconds
-        // http://saloon.javaranch.com/cgi-bin/ubb/ultimatebb.cgi?ubb=get_topic&f=1&t=019789
-        Thread.sleep(2000);
-
-        //String rule1v3 = this.createCommonRule(""rule1"",""3"");
-        String rule1v2 = """";
-        rule1v2 += ""rule rule1\n"";
-        rule1v2 += ""when\n"";
-        rule1v2 += ""\tString()\n"";
-        rule1v2 += ""then\n"";
-        rule1v2 += ""list.add( drools.getRule().getName()+\""-V2\"");\n"";
-        rule1v2 += ""end\n"";
-
-        output = new BufferedWriter(new FileWriter(f1));
-        output.write(header1);
-        output.write(rule1v2);
-        output.close();
-        Thread.sleep(3000);
+        
+        File f2 = fileManager.write( ""rule1.drl"",
+                                     createVersionedRule( ""rule1"", ""2"" ) );     
+        
+        scan(kagent);
 
         // Use the same session for incremental build test
@@ -366,5 +302,5 @@ public class KnowledgeAgentBinaryDiffTests extends TestCase {
         assertTrue(list.contains(""rule1-V2""));
 
-        kagent.monitorResourceChangeEvents(false);
+        kagent.dispose();
     }
     
@@ -372,16 +308,6 @@ public class KnowledgeAgentBinaryDiffTests extends TestCase {
     public void testDifferentConsequences() throws Exception {
 
-        String header1 = """";
-        header1 += ""package org.drools.test\n"";
-        header1 += ""global java.util.List list\n\n"";
-
-        String rule1 = this.createCommonRule(""rule1"");
-
-
-        File f1 = fileManager.newFile(""rule1.drl"");
-        Writer output = new BufferedWriter(new FileWriter(f1));
-        output.write(header1);
-        output.write(rule1);
-        output.close();
+        File f1 = fileManager.write( ""rule1.drl"",
+                                     createDefaultRule( ""rule1"" ) ); 
 
         String xml = """";
@@ -393,13 +319,11 @@ public class KnowledgeAgentBinaryDiffTests extends TestCase {
         xml += ""    </add> "";
         xml += ""</change-set>"";
-        File fxml = fileManager.newFile(""changeset.xml"");
-        output = new BufferedWriter(new FileWriter(fxml));
-        output.write(xml);
-        output.close();
+        File fxml = fileManager.write( ""changeset.xml"",
+                                       xml );
 
         KnowledgeBase kbase = KnowledgeBaseFactory.newKnowledgeBase();
-        KnowledgeAgent kagent = this.createKAgent(kbase);
-
-        kagent.applyChangeSet(ResourceFactory.newUrlResource(fxml.toURI().toURL()));
+        KnowledgeAgent kagent = this.createKAgent(kbase, false);
+        
+        applyChangeSet( kagent, ResourceFactory.newUrlResource(fxml.toURI().toURL()) );
 
         StatefulKnowledgeSession ksession = kbase.newStatefulKnowledgeSession();
@@ -414,15 +338,8 @@ public class KnowledgeAgentBinaryDiffTests extends TestCase {
         list.clear();
 
-        // have to sleep here as linux lastModified does not do milliseconds
-        // http://saloon.javaranch.com/cgi-bin/ubb/ultimatebb.cgi?ubb=get_topic&f=1&t=019789
-        Thread.sleep(2000);
-
-        String rule1v2 = this.createCommonRule(""rule1"", ""2"");
-
-        output = new BufferedWriter(new FileWriter(f1));
-        output.write(header1);
-        output.write(rule1v2);
-        output.close();
-        Thread.sleep(3000);
+        fileManager.write( ""rule1.drl"",
+                           createVersionedRule( ""rule1"", ""2"" ) );
+        
+        scan( kagent );
 
         // Use the same session for incremental build test
@@ -436,35 +353,10 @@ public class KnowledgeAgentBinaryDiffTests extends TestCase {
         assertTrue(list.contains(""rule1-V2""));
 
-        kagent.monitorResourceChangeEvents(false);
+        kagent.dispose();
     }
 
-
-
-
-
-
-//
-
-    private void differentRuleAttributeTest(String attribute1, String attribute2,RuleAttributeAsserter asserter) throws Exception {
-
-        String header1 = """";
-        header1 += ""package org.drools.test\n"";
-        header1 += ""global java.util.List list\n\n"";
-
-        String rule1 = """";
-        rule1 += ""rule rule1\n"";
-        rule1 += attribute1+""\n"";
-        rule1 += ""when\n"";
-        rule1 += ""\tString()\n"";
-        rule1 += ""then\n"";
-        rule1 += ""list.add( drools.getRule().getName());\n"";
-        rule1 += ""end\n"";
-
-
-        File f1 = fileManager.newFile(""rule1.drl"");
-        Writer output = new BufferedWriter(new FileWriter(f1));
-        output.write(header1);
-        output.write(rule1);
-        output.close();
+    private void differentRuleAttributeTest(String attribute1, String attribute2,RuleAttributeAsserter asserter) throws Exception {        
+        File f1 = fileManager.write( ""rule1.drl"",
+                                     createAttributeRule( ""rule1"", attribute1 ) ); 
 
         String xml = """";
@@ -476,13 +368,11 @@ public class KnowledgeAgentBinaryDiffTests extends TestCase {
         xml += ""    </add> "";
         xml += ""</change-set>"";
-        File fxml = fileManager.newFile(""changeset.xml"");
-        output = new BufferedWriter(new FileWriter(fxml));
-        output.write(xml);
-        output.close();
+        File fxml = fileManager.write( ""changeset.xml"",
+                                       xml );
 
         KnowledgeBase kbase = KnowledgeBaseFactory.newKnowledgeBase();
-        KnowledgeAgent kagent = this.createKAgent(kbase);
+        KnowledgeAgent kagent = this.createKAgent(kbase, false);
 
-        kagent.applyChangeSet(ResourceFactory.newUrlResource(fxml.toURI().toURL()));
+        applyChangeSet( kagent, ResourceFactory.newUrlResource(fxml.toURI().toURL()));
 
         org.drools.rule.Rule rule = (org.drools.rule.Rule) kagent.getKnowledgeBase().getRule(""org.drools.test"", ""rule1"");
@@ -491,80 +381,15 @@ public class KnowledgeAgentBinaryDiffTests extends TestCase {
         asserter.assertRuleAttribute(attribute1, rule);
 
-
-        // have to sleep here as linux lastModified does not do milliseconds
-        // http://saloon.javaranch.com/cgi-bin/ubb/ultimatebb.cgi?ubb=get_topic&f=1&t=019789
-        Thread.sleep(2000);
-
-        String rule1v2 = """";
-        rule1v2 += ""rule rule1\n"";
-        rule1v2 += attribute2+""\n"";
-        rule1v2 += ""when\n"";
-        rule1v2 += ""\tString()\n"";
-        rule1v2 += ""then\n"";
-        rule1v2 += ""list.add( drools.getRule().getName());\n"";
-        rule1v2 += ""end\n"";
-
-        output = new BufferedWriter(new FileWriter(f1));
-        output.write(header1);
-        output.write(rule1v2);
-        output.close();
-        Thread.sleep(3000);
-
+        File f2 = fileManager.write( ""rule1.drl"",
+                                     createAttributeRule( ""rule1"", attribute2 ) );
+        
+        scan( kagent );
+        
         rule = (org.drools.rule.Rule) kagent.getKnowledgeBase().getRule(""org.drools.test"", ""rule1"");
         assertNotNull(rule);
         asserter.assertRuleAttribute(attribute2, rule);
 
-        kagent.monitorResourceChangeEvents(false);
+        kagent.dispose();
     }
-
-    private KnowledgeAgent createKAgent(KnowledgeBase kbase) {
-        ResourceChangeScannerConfiguration sconf = ResourceFactory.getResourceChangeScannerService().newResourceChangeScannerConfiguration();
-        sconf.setProperty(""drools.resource.scanner.interval"", ""2"");
-        ResourceFactory.getResourceChangeScannerService().configure(sconf);
-
-        //System.setProperty(KnowledgeAgentFactory.PROVIDER_CLASS_NAME_PROPERTY_NAME, ""org.drools.agent.impl.KnowledgeAgentProviderImpl"");
-
-        KnowledgeAgentConfiguration aconf = KnowledgeAgentFactory.newKnowledgeAgentConfiguration();
-        aconf.setProperty(""drools.agent.scanDirectories"", ""true"");
-        aconf.setProperty(""drools.agent.scanResources"", ""true"");
-        // Testing incremental build here
-        aconf.setProperty(""drools.agent.newInstance"", ""false"");
-
-
-
-        KnowledgeAgent kagent = KnowledgeAgentFactory.newKnowledgeAgent(
-                ""test agent"", kbase, aconf);
-
-        assertEquals(""test agent"", kagent.getName());
-
-        return kagent;
-    }
-
-    private String createCommonRule(String ruleName) {
-        StringBuilder sb = new StringBuilder();
-        sb.append(""rule "");
-        sb.append(ruleName);
-        sb.append(""\n"");
-        sb.append(""when\n"");
-        sb.append(""then\n"");
-        sb.append(""list.add( drools.getRule().getName() );\n"");
-        sb.append(""end\n"");
-
-        return sb.toString();
-    }    
-
-    private String createCommonRule(String ruleName, String version) {
-        StringBuilder sb = new StringBuilder();
-        sb.append(""rule "");
-        sb.append(ruleName);
-        sb.append(""\n"");
-        sb.append(""when\n"");
-        sb.append(""then\n"");
-        sb.append(""list.add( drools.getRule().getName()+\""-V"" + version + ""\"");\n"");
-        sb.append(""end\n"");
-
-        return sb.toString();
-    }
-
     
 }
diff --git a/drools-compiler/src/test/java/org/drools/agent/KnowledgeAgentTest.java b/drools-compiler/src/test/java/org/drools/agent/KnowledgeAgentTest.java
index 785d746f04..53abceefc0 100644
--- a/drools-compiler/src/test/java/org/drools/agent/KnowledgeAgentTest.java
+++ b/drools-compiler/src/test/java/org/drools/agent/KnowledgeAgentTest.java
@@ -43,191 +43,7 @@ import org.mortbay.jetty.Server;
 import org.mortbay.jetty.handler.ResourceHandler;
 
-public class KnowledgeAgentTest extends TestCase {
+public class KnowledgeAgentTest extends BaseKnowledgeAgentTest {
 
-    FileManager              fileManager;
-    private Server           server;
-    
-    private ResourceChangeScannerImpl scanner;
-
-    @Override
-    protected void setUp() throws Exception {
-        this.fileManager = new FileManager();
-        this.fileManager.setUp();
-        ((ResourceChangeScannerImpl) ResourceFactory.getResourceChangeScannerService()).reset();
-
-        ResourceFactory.getResourceChangeNotifierService().start();
-        
-        // we don't start the scanner, as we call it manually;
-        this.scanner = (ResourceChangeScannerImpl) ResourceFactory.getResourceChangeScannerService();
-
-        this.server = new Server( IoUtils.findPort() );
-        ResourceHandler resourceHandler = new ResourceHandler();
-        resourceHandler.setResourceBase( fileManager.getRootDirectory().getPath() );
-
-        this.server.setHandler( resourceHandler );
-
-        this.server.start();
-    }
-    
-    @Override
-    protected void tearDown() throws Exception {
-        fileManager.tearDown();
-        ResourceFactory.getResourceChangeNotifierService().stop();
-        ((ResourceChangeNotifierImpl) ResourceFactory.getResourceChangeNotifierService()).reset();
-        ((ResourceChangeScannerImpl) ResourceFactory.getResourceChangeScannerService()).reset();
-
-        server.stop();
-    }    
-
-    private int getPort() {
-        return this.server.getConnectors()[0].getLocalPort();
-    }
-    
-    private void scan(KnowledgeAgent kagent) {
-        // Calls the Resource Scanner and sets up a listener and a latch so we can wait until it's finished processing, instead of using timers
-        final CountDownLatch latch = new CountDownLatch( 1 );
-        
-        KnowledgeAgentEventListener l = new KnowledgeAgentEventListener() {
-            
-            public void resourceCompilationFailed(ResourceCompilationFailedEvent event) {
-            }
-            
-            public void knowledgeBaseUpdated(KnowledgeBaseUpdatedEvent event) {
-            }
-            
-            public void beforeResourceProcessed(BeforeResourceProcessedEvent event) {
-            }
-            
-            public void beforeChangeSetProcessed(BeforeChangeSetProcessedEvent event) {                              
-            }
-            
-            public void beforeChangeSetApplied(BeforeChangeSetAppliedEvent event) {
-            }
-            
-            public void afterResourceProcessed(AfterResourceProcessedEvent event) {
-            }
-            
-            public void afterChangeSetProcessed(AfterChangeSetProcessedEvent event) {
-            }
-            
-            public void afterChangeSetApplied(AfterChangeSetAppliedEvent event) {
-                latch.countDown();
-            }
-        };        
-        
-        kagent.addEventListener( l );
-        
-        this.scanner.scan();
-        
-        try {
-            latch.await( 10, TimeUnit.SECONDS );
-        } catch ( InterruptedException e ) {
-            throw new RuntimeException( ""Unable to wait for latch countdown"", e);
-        }
-        
-        if ( latch.getCount() > 0 ) {            
-            throw new RuntimeException( ""Event for KnowlegeBase update, due to scan, was never received"" );
-        }
-        
-        kagent.removeEventListener( l );
-    }
-    
-    void applyChangeSet(KnowledgeAgent kagent, String xml) {
-        // Calls the Resource Scanner and sets up a listener and a latch so we can wait until it's finished processing, instead of using timers
-        final CountDownLatch latch = new CountDownLatch( 1 );
-        
-        KnowledgeAgentEventListener l = new KnowledgeAgentEventListener() {
-            
-            public void resourceCompilationFailed(ResourceCompilationFailedEvent event) {
-            }
-            
-            public void knowledgeBaseUpdated(KnowledgeBaseUpdatedEvent event) {
-            }
-            
-            public void beforeResourceProcessed(BeforeResourceProcessedEvent event) {
-            }
-            
-            public void beforeChangeSetProcessed(BeforeChangeSetProcessedEvent event) {                              
-            }
-            
-            public void beforeChangeSetApplied(BeforeChangeSetAppliedEvent event) {
-            }
-            
-            public void afterResourceProcessed(AfterResourceProcessedEvent event) {
-            }
-            
-            public void afterChangeSetProcessed(AfterChangeSetProcessedEvent event) {
-            }
-            
-            public void afterChangeSetApplied(AfterChangeSetAppliedEvent event) {
-                latch.countDown();
-            }
-        };        
-        
-        kagent.addEventListener( l );
-        
-        kagent.applyChangeSet( ResourceFactory.newByteArrayResource( xml.getBytes() ) );
-        
-        try {
-            latch.await( 10, TimeUnit.SECONDS );
-        } catch ( InterruptedException e ) {
-            throw new RuntimeException( ""Unable to wait for latch countdown"", e);
-        }
-        
-        if ( latch.getCount() > 0 ) {            
-            throw new RuntimeException( ""Event for KnowlegeBase update, due to scan, was never received"" );
-        }
-        
-        kagent.removeEventListener( l );        
-    }
-    
-    void applyChangeSet(KnowledgeAgent kagent, Resource r) {
-        // Calls the Resource Scanner and sets up a listener and a latch so we can wait until it's finished processing, instead of using timers
-        final CountDownLatch latch = new CountDownLatch( 1 );
-        
-        KnowledgeAgentEventListener l = new KnowledgeAgentEventListener() {
-            
-            public void resourceCompilationFailed(ResourceCompilationFailedEvent event) {
-            }
-            
-            public void knowledgeBaseUpdated(KnowledgeBaseUpdatedEvent event) {
-            }
-            
-            public void beforeResourceProcessed(BeforeResourceProcessedEvent event) {
-            }
-            
-            public void beforeChangeSetProcessed(BeforeChangeSetProcessedEvent event) {                              
-            }
-            
-            public void beforeChangeSetApplied(BeforeChangeSetAppliedEvent event) {
-            }
-            
-            public void afterResourceProcessed(AfterResourceProcessedEvent event) {
-            }
-            
-            public void afterChangeSetProcessed(AfterChangeSetProcessedEvent event) {
-            }
-            
-            public void afterChangeSetApplied(AfterChangeSetAppliedEvent event) {
-                latch.countDown();
-            }
-        };        
-        
-        kagent.addEventListener( l );
-        
-        kagent.applyChangeSet( r );
-        
-        try {
-            latch.await( 10, TimeUnit.SECONDS );
-        } catch ( InterruptedException e ) {
-            throw new RuntimeException( ""Unable to wait for latch countdown"", e);
-        }
-        
-        if ( latch.getCount() > 0 ) {            
-            throw new RuntimeException( ""Event for KnowlegeBase update, due to scan, was never received"" );
-        }
-        
-        kagent.removeEventListener( l );        
-    }    
+ 
 
 
@@ -862,69 +678,3 @@ public class KnowledgeAgentTest extends TestCase {
     }
 
-    private static void writePackage(Object pkg,
-                                     File p1file )throws IOException, FileNotFoundException {
-        if ( p1file.exists() ) {
-            // we want to make sure there is a time difference for lastModified and lastRead checks as Linux and http often round to seconds
-            // http://saloon.javaranch.com/cgi-bin/ubb/ultimatebb.cgi?ubb=get_topic&f=1&t=019789
-            try {
-                Thread.sleep( 1000 );
-            } catch (Exception e) {
-                throw new RuntimeException( ""Unable to sleep"" );
-            }            
-        }
-        FileOutputStream out = new FileOutputStream( p1file );
-        try {
-            DroolsStreamUtils.streamOut( out,
-                                         pkg );
-        } finally {
-            out.close();
-        }
-    }
-
-    private KnowledgeAgent createKAgent(KnowledgeBase kbase) {
-        KnowledgeAgentConfiguration aconf = KnowledgeAgentFactory.newKnowledgeAgentConfiguration();
-        aconf.setProperty( ""drools.agent.scanDirectories"",
-                           ""true"" );
-        aconf.setProperty( ""drools.agent.scanResources"",
-                           ""true"" );
-        aconf.setProperty( ""drools.agent.newInstance"",
-                           ""true"" );
-
-        KnowledgeAgent kagent = KnowledgeAgentFactory.newKnowledgeAgent(""test agent"",
-                                                                         kbase,
-                                                                         aconf );
-
-        assertEquals( ""test agent"",
-                      kagent.getName() );
-
-        return kagent;
-    }
-
-    private String createDefaultRule(String name) {
-        return this.createDefaultRule( name,
-                                       null );
-    }
-
-    private String createDefaultRule(String name,
-                                     String packageName) {
-        StringBuilder rule = new StringBuilder();
-        if ( packageName == null ) {
-            rule.append( ""package org.drools.test\n"" );
-        } else {
-            rule.append( ""package "" );
-            rule.append( packageName );
-            rule.append( ""\n"" );
-        }
-        rule.append( ""global java.util.List list\n"" );
-        rule.append( ""rule "" );
-        rule.append( name );
-        rule.append( ""\n"" );
-        rule.append( ""when\n"" );
-        rule.append( ""then\n"" );
-        rule.append( ""list.add( drools.getRule().getName() );\n"" );
-        rule.append( ""end\n"" );
-
-        return rule.toString();
-    }
-
 }
diff --git a/drools-core/src/main/java/org/drools/io/impl/ResourceChangeScannerImpl.java b/drools-core/src/main/java/org/drools/io/impl/ResourceChangeScannerImpl.java
index ef830e29d0..1fb5c11c70 100644
--- a/drools-core/src/main/java/org/drools/io/impl/ResourceChangeScannerImpl.java
+++ b/drools-core/src/main/java/org/drools/io/impl/ResourceChangeScannerImpl.java
@@ -111,4 +111,8 @@ public class ResourceChangeScannerImpl
             }
         }
+    }       
+
+    public Map<Resource, Set<ResourceChangeNotifier>> getResources() {
+        return resources;
     }
 
@@ -162,4 +166,5 @@ public class ResourceChangeScannerImpl
                     long lastModified = ((InternalResource) resource).getLastModified();
                     long lastRead = ((InternalResource) resource).getLastRead();
+                    
                     if ( lastModified == 0 ) {
                         this.listener.debug( ""ResourceChangeScanner removed resource="" + resource );
",JBRULES-2817 Make the KnowledgeAgent Tests more- robust and faster--git-svn-id: https://svn.jboss.org/repos/labs/labs/jbossrules/trunk@36213 c60d74c8-e8f6-0310-9e8f-d4a2fc68ab70-
1573,Java,d9d05e0b057335f3d1c7923cbee9d37c3a528d01,,C,kiegroup,drools,"[3, 26, 0, 11, 0, 0, 2, 8, 145, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","diff --git a/drools-core/src/main/java/org/drools/base/ClassFieldExtractorFactory.java b/drools-core/src/main/java/org/drools/base/ClassFieldExtractorFactory.java
index 55618a8397..1d1d3b2615 100644
--- a/drools-core/src/main/java/org/drools/base/ClassFieldExtractorFactory.java
+++ b/drools-core/src/main/java/org/drools/base/ClassFieldExtractorFactory.java
@@ -30,7 +30,7 @@ import org.drools.asm.Opcodes;
 
 /**
- * 
+ * This is an alternative to FieldAccessorGenerator.
  * @author Alexander Bagerman
- * 
+ * TODO: Use this instead of FieldAccessorGenerator - it should be able to be more efficient.
  */
 
@@ -56,5 +56,5 @@ public class ClassFieldExtractorFactory {
 			// generating byte array to create target class
 			byte[] bytes = dump(originalClassName, className, getterName,
-					typeName, fieldType);
+					typeName, fieldType, clazz.isInterface());
 			// use bytes to get a class 
 			ByteArrayClassLoader classLoader = new ByteArrayClassLoader(Thread
@@ -87,5 +87,5 @@ public class ClassFieldExtractorFactory {
 
 	private static byte[] dump(String originalClassName, String className,
-			String getterName, String typeName, Class fieldType)
+			String getterName, String typeName, Class fieldType, boolean isInterface)
 			throws Exception {
 
@@ -143,6 +143,13 @@ public class ClassFieldExtractorFactory {
 			mv.visitVarInsn(Opcodes.ALOAD, 1);
 			mv.visitTypeInsn(Opcodes.CHECKCAST, originalClassName);
-			mv.visitMethodInsn(Opcodes.INVOKEVIRTUAL, originalClassName,
-					getterName, ""()"" + primitiveTypeTag);
+            
+            if (isInterface) {
+                mv.visitMethodInsn(Opcodes.INVOKEINTERFACE, originalClassName,
+                                    getterName, ""()"" + primitiveTypeTag);
+                
+            } else {
+    			mv.visitMethodInsn(Opcodes.INVOKEVIRTUAL, originalClassName,
+    					getterName, ""()"" + primitiveTypeTag);
+            }
 			mv.visitMethodInsn(Opcodes.INVOKESPECIAL, typeName, ""<init>"", ""(""
 					+ primitiveTypeTag + "")V"");
@@ -165,6 +172,11 @@ public class ClassFieldExtractorFactory {
 			mv.visitVarInsn(Opcodes.ALOAD, 1);
 			mv.visitTypeInsn(Opcodes.CHECKCAST, originalClassName);
-			mv.visitMethodInsn(Opcodes.INVOKEVIRTUAL, originalClassName,
-					getterName, ""()L"" + typeName + "";"");
+            if (isInterface) {
+                mv.visitMethodInsn(Opcodes.INVOKEINTERFACE, originalClassName,
+                                    getterName, ""()L"" + typeName + "";"");
+            } else {
+    			mv.visitMethodInsn(Opcodes.INVOKEVIRTUAL, originalClassName,
+    					getterName, ""()L"" + typeName + "";"");
+            }
 			mv.visitInsn(Opcodes.ARETURN);
 			Label l1 = new Label();
diff --git a/drools-core/src/main/java/org/drools/util/asm/ClassFieldInspector.java b/drools-core/src/main/java/org/drools/util/asm/ClassFieldInspector.java
index 2df9374346..fde561e938 100644
--- a/drools-core/src/main/java/org/drools/util/asm/ClassFieldInspector.java
+++ b/drools-core/src/main/java/org/drools/util/asm/ClassFieldInspector.java
@@ -100,5 +100,5 @@ public class ClassFieldInspector {
             //only want public methods that start with 'get' or 'is'
             //and have no args, and return a value
-            if (access == Opcodes.ACC_PUBLIC) {
+            if ((access & Opcodes.ACC_PUBLIC) > 0) {
                 if (desc.startsWith( ""()"" ) && ( name.startsWith(""get"") || name.startsWith(""is"") ) ) {
                     try {
@@ -106,6 +106,6 @@ public class ClassFieldInspector {
                         if (method.getReturnType() != void.class) {
                             int fieldIndex = methodList.size();
-                            methodList.add(method);
-                            addToMapping(method, fieldIndex);
+                            methodList.add(method);                                
+                            addToMapping(method.getName(), fieldIndex);
                         }
                     } catch (NoSuchMethodException e) {
@@ -187,6 +187,6 @@ public class ClassFieldInspector {
 
 
-        private void addToMapping(Method method, int index) {
-            String name = method.getName();
+        private void addToMapping(String name, int index) {
+
             if (name.startsWith(""is"")) {
                 this.fieldNameMap.put(calcFieldName( name, 2 ), new Integer(index));
diff --git a/drools-core/src/main/java/org/drools/util/asm/FieldAccessorGenerator.java b/drools-core/src/main/java/org/drools/util/asm/FieldAccessorGenerator.java
index 515298e54b..0889a01413 100644
--- a/drools-core/src/main/java/org/drools/util/asm/FieldAccessorGenerator.java
+++ b/drools-core/src/main/java/org/drools/util/asm/FieldAccessorGenerator.java
@@ -113,5 +113,5 @@ public class FieldAccessorGenerator {
             doConstructor( cw );
             
-            doMethods( cw, Type.getInternalName(targetClass), getters );
+            doMethods( cw, Type.getInternalName(targetClass), getters, targetClass.isInterface());
 
             cw.visitEnd();
@@ -120,5 +120,5 @@ public class FieldAccessorGenerator {
         }
 
-        private static void doMethods(ClassWriter cw, String targetType, Method[] getters) {
+        private static void doMethods(ClassWriter cw, String targetType, Method[] getters, boolean isInterface) {
             
              
@@ -163,10 +163,11 @@ public class FieldAccessorGenerator {
             //START switch items
             for (int i= 0; i < getters.length; i++) {
+                
                 Method method = getters[i];
                 if (method.getReturnType().isPrimitive()) {
                     doSwitchItemBoxed( mv, switchItems[i],
-                                       target, targetType, method.getName(), method.getReturnType());                    
+                                       target, targetType, method.getName(), method.getReturnType(), isInterface);                    
                 } else {
-                    doSwitchItemObject(mv, switchItems[i], target, targetType, method.getName(), method.getReturnType());
+                    doSwitchItemObject(mv, switchItems[i], target, targetType, method.getName(), method.getReturnType(), isInterface);
                 }
             }            
@@ -187,5 +188,5 @@ public class FieldAccessorGenerator {
         private static void doSwitchItemBoxed(MethodVisitor mv, Label switchItem,
                                               int target, String targetType, String targetMethod,
-                                              Class scalarType) {
+                                              Class scalarType, boolean isInterface) {
             Class boxType = null;
             boxType = getBoxType( scalarType );
@@ -198,8 +199,17 @@ public class FieldAccessorGenerator {
             mv.visitVarInsn( ALOAD,
                              target );
-            mv.visitMethodInsn( INVOKEVIRTUAL,
-                                targetType,
-                                targetMethod,
-                                ""()"" + scalarDescriptor );
+            if (isInterface) {
+                mv.visitMethodInsn( INVOKEINTERFACE,
+                                    targetType,
+                                    targetMethod,
+                                    ""()"" + scalarDescriptor );
+                
+            } else {
+                mv.visitMethodInsn( INVOKEVIRTUAL,
+                                    targetType,
+                                    targetMethod,
+                                    ""()"" + scalarDescriptor );
+                
+            }
             mv.visitMethodInsn( INVOKESPECIAL,
                                 internalBoxName,
@@ -238,5 +248,6 @@ public class FieldAccessorGenerator {
         /** A regular switch item, which doesn't require boxing */
         private static void doSwitchItemObject(MethodVisitor mv, Label label,
-                                         int target, String targetType, String targetMethod, Class returnClass) {
+                                         int target, String targetType, 
+                                         String targetMethod, Class returnClass, boolean isInterface) {
             
             String returnType = ""()"" + Type.getDescriptor(returnClass);
@@ -244,8 +255,15 @@ public class FieldAccessorGenerator {
             mv.visitVarInsn( ALOAD,
                              target );
-            mv.visitMethodInsn( INVOKEVIRTUAL,
-                                targetType,
-                                targetMethod,
-                                returnType );
+            if (isInterface) {
+                mv.visitMethodInsn( INVOKEINTERFACE,
+                                    targetType,
+                                    targetMethod,
+                                    returnType );
+            } else {
+                mv.visitMethodInsn( INVOKEVIRTUAL,
+                                    targetType,
+                                    targetMethod,
+                                    returnType );
+            }
             mv.visitInsn( ARETURN );
         }
diff --git a/drools-core/src/test/java/org/drools/base/ClassFieldExtractorFactoryTest.java b/drools-core/src/test/java/org/drools/base/ClassFieldExtractorFactoryTest.java
new file mode 100644
index 0000000000..9317c4b299
--- /dev/null
+++ b/drools-core/src/test/java/org/drools/base/ClassFieldExtractorFactoryTest.java
@@ -0,0 +1,39 @@
+package org.drools.base;
+
+import org.drools.spi.FieldExtractor;
+import org.drools.util.asm.TestAbstract;
+import org.drools.util.asm.TestAbstractImpl;
+import org.drools.util.asm.TestInterface;
+import org.drools.util.asm.TestInterfaceImpl;
+
+import junit.framework.TestCase;
+
+public class ClassFieldExtractorFactoryTest extends TestCase {
+
+    public void testIt() throws Exception {
+        FieldExtractor ex = ClassFieldExtractorFactory.getClassFieldExtractor( TestBean.class, ""name"" );
+        assertEquals(0, ex.getIndex());
+        assertEquals(""michael"", ex.getValue( new TestBean() ));
+        ex = ClassFieldExtractorFactory.getClassFieldExtractor( TestBean.class, ""age"" );
+        assertEquals(1, ex.getIndex());
+        assertEquals(new Integer(42), ex.getValue( new TestBean() ));
+        
+    }
+    
+    public void testInterface() throws Exception {
+        FieldExtractor ex = ClassFieldExtractorFactory.getClassFieldExtractor( TestInterface.class, ""something"" );
+        assertEquals(0, ex.getIndex());
+        assertEquals(""foo"", ex.getValue( new TestInterfaceImpl() ));
+    }
+    
+    public void testAbstract() throws Exception {
+        FieldExtractor ex = ClassFieldExtractorFactory.getClassFieldExtractor( TestAbstract.class, ""something"" );
+        assertEquals(0, ex.getIndex());
+        assertEquals(""foo"", ex.getValue( new TestAbstractImpl() ));
+    }   
+    
+    
+
+    
+}
+
diff --git a/drools-core/src/test/java/org/drools/base/TestBean.java b/drools-core/src/test/java/org/drools/base/TestBean.java
new file mode 100644
index 0000000000..2c1bf9dc40
--- /dev/null
+++ b/drools-core/src/test/java/org/drools/base/TestBean.java
@@ -0,0 +1,14 @@
+package org.drools.base;
+
+public class TestBean {
+    private String name = ""michael"";
+    private int age = 42;
+
+    public String getName() {
+        return name;
+    }        
+    
+    public int getAge() {
+        return age;
+    }
+}
diff --git a/drools-core/src/test/java/org/drools/util/asm/ClassFieldInspectorTest.java b/drools-core/src/test/java/org/drools/util/asm/ClassFieldInspectorTest.java
index adb768215a..c7de4fe3fd 100644
--- a/drools-core/src/test/java/org/drools/util/asm/ClassFieldInspectorTest.java
+++ b/drools-core/src/test/java/org/drools/util/asm/ClassFieldInspectorTest.java
@@ -24,4 +24,35 @@ public class ClassFieldInspectorTest extends TestCase {
     }
     
+
+    public void testInterface() throws Exception {
+        ClassFieldInspector ext = new ClassFieldInspector( TestInterface.class );
+        assertEquals(2, ext.getPropertyGetters().size());
+        assertEquals(""getSomething"", ((Method) ext.getPropertyGetters().get(0)).getName());
+        assertEquals(""getAnother"", ((Method) ext.getPropertyGetters().get(1)).getName());
+        
+      
+        
+        Map names = ext.getFieldNames();
+        assertNotNull(names);
+        assertEquals(2, names.size());
+        assertEquals(0, ((Integer)names.get(""something"")).intValue());
+        assertEquals(1, ((Integer)names.get(""another"")).intValue());
+        
+    }
+    
+    public void testAbstract() throws Exception {
+        ClassFieldInspector ext = new ClassFieldInspector( TestAbstract.class );
+        assertEquals(2, ext.getPropertyGetters().size());
+        assertEquals(""getSomething"", ((Method) ext.getPropertyGetters().get(0)).getName());
+        assertEquals(""getAnother"", ((Method) ext.getPropertyGetters().get(1)).getName());
+        
+        Map names = ext.getFieldNames();
+        assertNotNull(names);
+        assertEquals(2, names.size());
+        assertEquals(0, ((Integer)names.get(""something"")).intValue());
+        assertEquals(1, ((Integer)names.get(""another"")).intValue());
+        
+    }    
+    
     static class Person {
         private boolean happy;
diff --git a/drools-core/src/test/java/org/drools/util/asm/FieldAccessorGeneratorTest.java b/drools-core/src/test/java/org/drools/util/asm/FieldAccessorGeneratorTest.java
index 1d780e0c70..442fea486b 100644
--- a/drools-core/src/test/java/org/drools/util/asm/FieldAccessorGeneratorTest.java
+++ b/drools-core/src/test/java/org/drools/util/asm/FieldAccessorGeneratorTest.java
@@ -47,3 +47,44 @@ public class FieldAccessorGeneratorTest extends TestCase {
     }
     
+    public void testInterface() throws Exception {
+        FieldAccessorGenerator gen = FieldAccessorGenerator.getInstance();
+        FieldAccessorMap map = gen.newInstanceFor(TestInterface.class);
+        FieldAccessor ac = map.getFieldAccessor();
+        assertNotNull(ac);
+        
+        TestInterface obj = new TestInterfaceImpl();
+        
+        assertEquals(""foo"", (String)ac.getFieldByIndex(obj, 0));
+        assertEquals(42, ((Integer)ac.getFieldByIndex(obj, 1)).intValue());
+        
+        Integer index = (Integer) map.getFieldNameMap().get(""something"");
+        assertEquals(0, index.intValue());
+        
+        index = (Integer) map.getFieldNameMap().get(""another"");
+        assertEquals(1, index.intValue());
+        
+        
+    }    
+    
+    public void testAbstract() throws Exception {
+        FieldAccessorGenerator gen = FieldAccessorGenerator.getInstance();
+        FieldAccessorMap map = gen.newInstanceFor(TestAbstract.class);
+        FieldAccessor ac = map.getFieldAccessor();
+        assertNotNull(ac);
+        
+        TestAbstract obj = new TestAbstractImpl();
+        
+        assertEquals(42, ((Integer)ac.getFieldByIndex(obj, 1)).intValue());
+        assertEquals(""foo"", (String)ac.getFieldByIndex(obj, 0));
+        
+        
+        Integer index = (Integer) map.getFieldNameMap().get(""something"");
+        assertEquals(0, index.intValue());
+        
+        index = (Integer) map.getFieldNameMap().get(""another"");
+        assertEquals(1, index.intValue());
+        
+        
+    }     
+    
 }
diff --git a/drools-core/src/test/java/org/drools/util/asm/TestAbstract.java b/drools-core/src/test/java/org/drools/util/asm/TestAbstract.java
new file mode 100644
index 0000000000..a603dacc1b
--- /dev/null
+++ b/drools-core/src/test/java/org/drools/util/asm/TestAbstract.java
@@ -0,0 +1,10 @@
+package org.drools.util.asm;
+
+public abstract class TestAbstract {
+
+    public abstract String getSomething();
+    public int getAnother() {
+        return 42;
+    }
+    
+}
diff --git a/drools-core/src/test/java/org/drools/util/asm/TestAbstractImpl.java b/drools-core/src/test/java/org/drools/util/asm/TestAbstractImpl.java
new file mode 100644
index 0000000000..2dad1e6f57
--- /dev/null
+++ b/drools-core/src/test/java/org/drools/util/asm/TestAbstractImpl.java
@@ -0,0 +1,9 @@
+package org.drools.util.asm;
+
+public class TestAbstractImpl extends TestAbstract {
+
+    public String getSomething() {
+        return ""foo"";
+    }
+
+}
diff --git a/drools-core/src/test/java/org/drools/util/asm/TestInterface.java b/drools-core/src/test/java/org/drools/util/asm/TestInterface.java
new file mode 100644
index 0000000000..c61d2fbd7a
--- /dev/null
+++ b/drools-core/src/test/java/org/drools/util/asm/TestInterface.java
@@ -0,0 +1,8 @@
+package org.drools.util.asm;
+
+public interface TestInterface {
+
+    public String getSomething();
+    public int getAnother();
+    
+}
diff --git a/drools-core/src/test/java/org/drools/util/asm/TestInterfaceImpl.java b/drools-core/src/test/java/org/drools/util/asm/TestInterfaceImpl.java
new file mode 100644
index 0000000000..58fa21c438
--- /dev/null
+++ b/drools-core/src/test/java/org/drools/util/asm/TestInterfaceImpl.java
@@ -0,0 +1,15 @@
+package org.drools.util.asm;
+
+public class TestInterfaceImpl
+    implements
+    TestInterface {
+
+    public String getSomething() {
+        return ""foo"";
+    }
+
+    public int getAnother() {
+        return 42;
+    }
+
+}
",JBRULES-85--git-svn-id: https://svn.jboss.org/repos/labs/trunk/labs/jbossrules@3162 c60d74c8-e8f6-0310-9e8f-d4a2fc68ab70-
